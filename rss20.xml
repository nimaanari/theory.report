<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>AI and Aaronson&amp;#8217;s Law of Dark Irony</title>
  <guid>https://scottaaronson.blog/?p=7278</guid>
  <link>https://scottaaronson.blog/?p=7278</link>
  <description>
    &lt;p&gt;The major developments in human history are &lt;em&gt;always&lt;/em&gt; steeped in dark ironies.  Yes, that&amp;#8217;s my Law of Dark Irony, the whole thing.&lt;/p&gt;



&lt;p&gt;I don&amp;#8217;t know why it&amp;#8217;s true, but it certainly seems to be.  Taking WWII as the archetypal example, let&amp;#8217;s enumerate just the more obvious ones:&lt;/p&gt;



&lt;ul&gt;
&lt;li&gt;After the carnage of WWI, the world&amp;#8217;s most sensitive and thoughtful people (many of them) learned the lesson that they should oppose war at any cost.  This attitude let Germany rearm and set the stage for WWII.&lt;/li&gt;



&lt;li&gt;Hitler, who was neither tall nor blond, wished to establish the worldwide domination of tall, blond Aryans &amp;#8230; and do so via an alliance with the Japanese.&lt;/li&gt;



&lt;li&gt;The Nazis touted the dream of eugenically perfecting the human race, then perpetrated a genocide against a tiny group that had produced Einstein, von Neumann, Wigner, Ulam, and Tarski.&lt;/li&gt;



&lt;li&gt;The Jews were murdered using a chemical&amp;#8212;&lt;a href=&quot;https://en.wikipedia.org/wiki/Zyklon_B&quot;&gt;Zyklon B&lt;/a&gt;&amp;#8212;developed in part by the Jewish chemist Fritz Haber.&lt;/li&gt;



&lt;li&gt;The Allied force that made the greatest sacrifice in lives to defeat Hitler was Stalin&amp;#8217;s USSR, &lt;em&gt;another&lt;/em&gt; of history&amp;#8217;s most murderous and horrifying regimes.&lt;/li&gt;



&lt;li&gt;The man who rallied the free world to defeat Nazism, Winston Churchill, was himself a racist colonialist, whose views would be (and regularly are) denounced as &amp;#8220;Nazi&amp;#8221; on modern college campuses.&lt;/li&gt;



&lt;li&gt;The WWII legacy that would go on to threaten humanity&amp;#8217;s existence&amp;#8212;the Bomb&amp;#8212;was created in what the scientists believed was a desperate race to &lt;em&gt;save&lt;/em&gt; humanity.  Then Hitler was defeated before the Bomb was ready, and it turned out the Nazis were never even close to building their own Bomb, and the Bomb was used instead against Japan.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;When I think about the scenarios where superintelligent AI destroys the world, they rarely seem to do enough justice to the Law of Dark Irony.  It&amp;#8217;s like: OK, AI is created to serve humanity, and instead it turns on humanity and destroys it.  Great, that&amp;#8217;s &lt;em&gt;one&lt;/em&gt; dark irony.  One.  What other dark ironies could there be?  How about:&lt;/p&gt;



&lt;ul&gt;
&lt;li&gt;For decades, the Yudkowskyans warned about the dangers of superintelligence.  So far, by all accounts, the great practical effect of these warnings has been to inspire the founding of both DeepMind and OpenAI, the entities that Yudkowskyans believe are locked into a race to &lt;em&gt;realize&lt;/em&gt; those dangers.&lt;/li&gt;



&lt;li&gt;Maybe AIs will displace humans &amp;#8230; and they&amp;#8217;ll &lt;em&gt;deserve&lt;/em&gt; to, since they won&amp;#8217;t be quite as wretched and cruel as we are.  (This is basically the plot of &lt;em&gt;Westworld&lt;/em&gt;, or at least of its first couple seasons, which Dana and I are now belatedly watching.)&lt;/li&gt;



&lt;li&gt;Maybe the world will get destroyed by what Yudkowsky calls a &lt;a href=&quot;https://arbital.com/p/pivotal/&quot;&gt;&amp;#8220;pivotal act&amp;#8221;&lt;/a&gt;: an act meant to &lt;em&gt;safeguard&lt;/em&gt; the world from takeover from an unaligned AGI, for example by taking it over with an aligned AGI first.  (I seriously worry about this; it&amp;#8217;s a pretty obvious one.)&lt;/li&gt;



&lt;li&gt;Maybe AI will get the idea to take over the world, but only because it&amp;#8217;s been trained on generations of science fiction and decades of Internet discussion worrying about the possibility of AI taking over the world.  (I&amp;#8217;m far from the first to notice this possibility.)&lt;/li&gt;



&lt;li&gt;Maybe AI will indeed destroy the world, but it will do so &amp;#8220;by mistake,&amp;#8221; while trying to &lt;em&gt;save&lt;/em&gt; the world, or by taking a calculated gamble to save the world that fails.  (A commenter on my last post &lt;a href=&quot;https://scottaaronson.blog/?p=7266#comment-1949890&quot;&gt;brought this one up&lt;/a&gt;.)&lt;/li&gt;



&lt;li&gt;Maybe humanity will successfully coordinate to pause AGI development, and then promptly be destroyed by &lt;em&gt;something else&lt;/em&gt;&amp;#8212;runaway climate change, an accidental nuclear exchange&amp;#8212;that the AGI, had it been created, would&amp;#8217;ve prevented.  (This, of course, would be directly analogous to one of the great dark ironies of all time: the one where decades of antinuclear activism, intended to save the planet, has instead doomed us to destroy the earth by oil and coal.)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Readers: which &lt;em&gt;other&lt;/em&gt; possible dark ironies have I missed?&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 02:27:52 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>Complexity and asymptotics of structure constants</title>
  <guid>http://arxiv.org/abs/2305.02553</guid>
  <link>http://arxiv.org/abs/2305.02553</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Panova_G/0/1/0/all/0/1&quot;&gt;Greta Panova&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Kostka, Littlewood-Richardson, Kronecker, and plethysm coefficients are
fundamental quantities in algebraic combinatorics, yet many natural questions
about them stay unanswered for more than 80 years. Kronecker and plethysm
coefficients lack ``nice formulas&#39;&#39;, a notion that can be formalized using
computational complexity theory. Beyond formulas and combinatorial
interpretations, we can attempt to understand their asymptotic behavior in
various regimes, and inequalities they could satisfy. Understanding these
quantities has applications beyond combinatorics. On the one hand, the
asymptotics of structure constants is closely related to understanding the
[limit] behavior of vertex and tiling models in statistical mechanics. More
recently, these structure constants have been involved in establishing
computational complexity lower bounds and separation of complexity classes like
VP vs VNP, the algebraic analogs of P vs NP in arithmetic complexity theory.
Here we discuss the outstanding problems related to asymptotics, positivity,
and complexity of structure constants focusing mostly on the Kronecker
coefficients of the symmetric group and, less so, on the plethysm coefficients.
&lt;/p&gt;
&lt;p&gt;This expository paper is based on the talk presented at the Open Problems in
Algebraic Combinatorics coneference in May 2022.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>On the parameterized complexity of the Perfect Phylogeny problem</title>
  <guid>http://arxiv.org/abs/2305.02800</guid>
  <link>http://arxiv.org/abs/2305.02800</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vlas_J/0/1/0/all/0/1&quot;&gt;Jorke M. de Vlas&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper categorizes the parameterized complexity of the algorithmic
problems Perfect Phylogeny and Triangulating Colored Graphs. We show that they
are complete for the parameterized complexity class XALP using a reduction from
Tree-chained Multicolor Independent Set and a proof of membership. We introduce
the problem Triangulating Multicolored Graphs as a stepping stone and prove
XALP-completeness for this problem as well. We also show that, assuming the
Exponential Time Hypothesis, there exists no algorithm that solves any of these
problems in time $f(k) n^{o(k)}$, where $n$ is the input size, $k$ the
parameter, and $f$ any computable function.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>All Kronecker coefficients are reduced Kronecker coefficients</title>
  <guid>http://arxiv.org/abs/2305.03003</guid>
  <link>http://arxiv.org/abs/2305.03003</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ikenmeyer_C/0/1/0/all/0/1&quot;&gt;Christian Ikenmeyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Panova_G/0/1/0/all/0/1&quot;&gt;Greta Panova&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We settle the question of where exactly the reduced Kronecker coefficients
lie on the spectrum between the Littlewood-Richardson and Kronecker
coefficients by showing that every Kronecker coefficient of the symmetric group
is equal to a reduced Kronecker coefficient by an explicit construction. This
implies the equivalence of a question by Stanley from 2000 and a question by
Kirillov from 2004 about combinatorial interpretations of these two families of
coefficients. Moreover, as a corollary, we deduce that deciding the positivity
of reduced Kronecker coefficients is $NP$-hard, and computing them is
$\#P$-hard under parsimonious many-one reductions.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Online Geometric Covering and Piercing</title>
  <guid>http://arxiv.org/abs/2305.02445</guid>
  <link>http://arxiv.org/abs/2305.02445</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+De_M/0/1/0/all/0/1&quot;&gt;Minati De&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1&quot;&gt;Saksham Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kallepalli_S/0/1/0/all/0/1&quot;&gt;Sarat Varma Kallepalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Satyam Singh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the online version of the piercing set problem, where geometric
objects arrive one by one, and the online algorithm must maintain a valid
piercing set for the already arrived objects by making irrevocable decisions.
It is easy to observe that any deterministic online algorithm that solves this
problem has a competitive ratio of at least $\Omega(n)$, which even holds when
the objects are intervals. This paper considers the piercing set problem when
objects are bounded scaled. We propose deterministic algorithms for bounded
scaled fat objects. Piercing translated copies of an object is equivalent to
the unit covering problem, which is well-studied in the online setup.
Surprisingly, no upper bound of the competitive ratio was known for the unit
covering problem when unit objects are anything other than balls and
hypercubes. Our result gives an upper bound of the competitive ratio for the
unit covering problem for various unit objects. For fixed-oriented hypercubes
in $\mathbb{R}^d$ with the scaling factor in the range $[1,k]$, we propose an
algorithm having a competitive ratio of at most~$3^d\log_2 k+2^d$. In the end,
we show a lower bound of the competitive ratio for bounded scaled objects of
various types like $\alpha$-fat objects in $\mathbb{R}^2$, axis-aligned
hypercubes in $\mathbb{R}^d$, and balls in $\mathbb{R}^2$ and~$\mathbb{R}^3$.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Towards Stratified Space Learning: 2-complexes</title>
  <guid>http://arxiv.org/abs/2305.02724</guid>
  <link>http://arxiv.org/abs/2305.02724</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bleile_Y/0/1/0/all/0/1&quot;&gt;Yossi Bokor Bleile&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we consider a simple class of stratified spaces --
2-complexes. We present an algorithm that learns the abstract structure of an
embedded 2-complex from a point cloud sampled from it. We use tools and
inspiration from computational geometry, algebraic topology, and topological
data analysis and prove the correctness of the identified abstract structure
under assumptions on the embedding.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Impossibility of Depth Reduction in Explainable Clustering</title>
  <guid>http://arxiv.org/abs/2305.02850</guid>
  <link>http://arxiv.org/abs/2305.02850</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1&quot;&gt;Chengyuan Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gavva_S/0/1/0/all/0/1&quot;&gt;Surya Teja Gavva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+S%2E_K/0/1/0/all/0/1&quot;&gt;Karthik C. S.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_P/0/1/0/all/0/1&quot;&gt;Parth Patel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1&quot;&gt;Adarsh Srinivasan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Over the last few years Explainable Clustering has gathered a lot of
attention. Dasgupta et al. [ICML&#39;20] initiated the study of explainable k-means
and k-median clustering problems where the explanation is captured by a
threshold decision tree which partitions the space at each node using axis
parallel hyperplanes. Recently, Laber et al. [Pattern Recognition&#39;23] made a
case to consider the depth of the decision tree as an additional complexity
measure of interest.
&lt;/p&gt;
&lt;p&gt;In this work, we prove that even when the input points are in the Euclidean
plane, then any depth reduction in the explanation incurs unbounded loss in the
k-means and k-median cost. Formally, we show that there exists a data set X in
the Euclidean plane, for which there is a decision tree of depth k-1 whose
k-means/k-median cost matches the optimal clustering cost of X, but every
decision tree of depth less than k-1 has unbounded cost w.r.t. the optimal cost
of clustering. We extend our results to the k-center objective as well, albeit
with weaker guarantees.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Perfect Sampling for Hard Spheres from Strong Spatial Mixing</title>
  <guid>http://arxiv.org/abs/2305.02450</guid>
  <link>http://arxiv.org/abs/2305.02450</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anand_K/0/1/0/all/0/1&quot;&gt;Konrad Anand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gobel_A/0/1/0/all/0/1&quot;&gt;Andreas G&amp;#xf6;bel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pappik_M/0/1/0/all/0/1&quot;&gt;Marcus Pappik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perkins_W/0/1/0/all/0/1&quot;&gt;Will Perkins&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We provide a perfect sampling algorithm for the hard-sphere model on subsets
of $\mathbb{R}^d$ with expected running time linear in the volume under the
assumption of strong spatial mixing. A large number of perfect and approximate
sampling algorithms have been devised to sample from the hard-sphere model, and
our perfect sampling algorithm is efficient for a range of parameters for which
only efficient approximate samplers were previously known and is faster than
these known approximate approaches. Our methods also extend to the more general
setting of Gibbs point processes interacting via finite-range, repulsive
potentials.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Efficient Caching with Reserves via Marking</title>
  <guid>http://arxiv.org/abs/2305.02508</guid>
  <link>http://arxiv.org/abs/2305.02508</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahimpur_S/0/1/0/all/0/1&quot;&gt;Sharat Ibrahimpur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purohit_M/0/1/0/all/0/1&quot;&gt;Manish Purohit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svitkina_Z/0/1/0/all/0/1&quot;&gt;Zoya Svitkina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vee_E/0/1/0/all/0/1&quot;&gt;Erik Vee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Joshua R. Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Online caching is among the most fundamental and well-studied problems in the
area of online algorithms. Innovative algorithmic ideas and analysis --
including potential functions and primal-dual techniques -- give insight into
this still-growing area. Here, we introduce a new analysis technique that first
uses a potential function to upper bound the cost of an online algorithm and
then pairs that with a new dual-fitting strategy to lower bound the cost of an
offline optimal algorithm. We apply these techniques to the Caching with
Reserves problem recently introduced by Ibrahimpur et al. [10] and give an
O(log k)-competitive fractional online algorithm via a marking strategy, where
k denotes the size of the cache. We also design a new online rounding algorithm
that runs in polynomial time to obtain an O(log k)-competitive randomized
integral algorithm. Additionally, we provide a new, simple proof for randomized
marking for the classical unweighted paging problem.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Prefix Sorting DFAs: a Recursive Algorithm</title>
  <guid>http://arxiv.org/abs/2305.02526</guid>
  <link>http://arxiv.org/abs/2305.02526</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotumaccio_N/0/1/0/all/0/1&quot;&gt;Nicola Cotumaccio&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the past thirty years, numerous algorithms for building the suffix array
of a string have been proposed. In 2021, the notion of suffix array was
extended from strings to DFAs, and it was shown that the resulting data
structure can be built in $ O(m^2 + n^{5/2}) $ time, where $ n $ is the number
of states and $ m $ is the number of edges [SODA 2021]. Recently, algorithms
running in $ O(mn) $ and $ O(n^2\log n) $ time have been described [CPM 2023].
&lt;/p&gt;
&lt;p&gt;In this paper, we improve the previous bounds by proposing an $ O(n^2) $
recursive algorithm inspired by Farach&#39;s algorithm for building a suffix tree
[FOCS 1997]. To this end, we provide insight into the rich lexicographic and
combinatorial structure of a graph, so contributing to the fascinating journey
which might lead to solve the long-standing open problem of building the suffix
tree of a graph.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On the Unreasonable Effectiveness of Single Vector Krylov Methods for Low-Rank Approximation</title>
  <guid>http://arxiv.org/abs/2305.02535</guid>
  <link>http://arxiv.org/abs/2305.02535</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyer_R/0/1/0/all/0/1&quot;&gt;Raphael A. Meyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1&quot;&gt;Cameron Musco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1&quot;&gt;Christopher Musco&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Krylov subspace methods are a ubiquitous tool for computing near-optimal rank
$k$ approximations of large matrices. While &quot;large block&quot; Krylov methods with
block size at least $k$ give the best known theoretical guarantees, block size
one (a single vector) or a small constant is often preferred in practice.
Despite their popularity, we lack theoretical bounds on the performance of such
&quot;small block&quot; Krylov methods for low-rank approximation.
&lt;/p&gt;
&lt;p&gt;We address this gap between theory and practice by proving that small block
Krylov methods essentially match all known low-rank approximation guarantees
for large block methods. Via a black-box reduction we show, for example, that
the standard single vector Krylov method run for $t$ iterations obtains the
same spectral norm and Frobenius norm error bounds as a Krylov method with
block size $\ell \geq k$ run for $O(t/\ell)$ iterations, up to a logarithmic
dependence on the smallest gap between sequential singular values. That is, for
a given number of matrix-vector products, single vector methods are essentially
as effective as any choice of large block size.
&lt;/p&gt;
&lt;p&gt;By combining our result with tail-bounds on eigenvalue gaps in random
matrices, we prove that the dependence on the smallest singular value gap can
be eliminated if the input matrix is perturbed by a small random matrix.
Further, we show that single vector methods match the more complex algorithm of
[Bakshi et al. `22], which combines the results of multiple block sizes to
achieve an improved algorithm for Schatten $p$-norm low-rank approximation.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Nearly-Linear Time and Streaming Algorithms for Outlier-Robust PCA</title>
  <guid>http://arxiv.org/abs/2305.02544</guid>
  <link>http://arxiv.org/abs/2305.02544</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1&quot;&gt;Ilias Diakonikolas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1&quot;&gt;Daniel M. Kane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pensia_A/0/1/0/all/0/1&quot;&gt;Ankit Pensia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pittas_T/0/1/0/all/0/1&quot;&gt;Thanasis Pittas&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study principal component analysis (PCA), where given a dataset in
$\mathbb{R}^d$ from a distribution, the task is to find a unit vector $v$ that
approximately maximizes the variance of the distribution after being projected
along $v$. Despite being a classical task, standard estimators fail drastically
if the data contains even a small fraction of outliers, motivating the problem
of robust PCA. Recent work has developed computationally-efficient algorithms
for robust PCA that either take super-linear time or have sub-optimal error
guarantees. Our main contribution is to develop a nearly-linear time algorithm
for robust PCA with near-optimal error guarantees. We also develop a
single-pass streaming algorithm for robust PCA with memory usage nearly-linear
in the dimension.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>$\alpha_i$-Metric Graphs: Radius, Diameter and all Eccentricities</title>
  <guid>http://arxiv.org/abs/2305.02545</guid>
  <link>http://arxiv.org/abs/2305.02545</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_F/0/1/0/all/0/1&quot;&gt;Feodor F. Dragan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ducoffe_G/0/1/0/all/0/1&quot;&gt;Guillaume Ducoffe&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We extend known results on chordal graphs and distance-hereditary graphs to
much larger graph classes by using only a common metric property of these
graphs. Specifically, a graph is called $\alpha_i$-metric ($i\in \mathcal{N}$)
if it satisfies the following $\alpha_i$-metric property for every vertices
$u,w,v$ and $x$: if a shortest path between $u$ and $w$ and a shortest path
between $x$ and $v$ share a terminal edge $vw$, then $d(u,x)\geq d(u,v) +
d(v,x)-i$. Roughly, gluing together any two shortest paths along a common
terminal edge may not necessarily result in a shortest path but yields a
``near-shortest&#39;&#39; path with defect at most $i$. It is known that
$\alpha_0$-metric graphs are exactly ptolemaic graphs, and that chordal graphs
and distance-hereditary graphs are $\alpha_i$-metric for $i=1$ and $i=2$,
respectively. We show that an additive $O(i)$-approximation of the radius, of
the diameter, and in fact of all vertex eccentricities of an $\alpha_i$-metric
graph can be computed in total linear time. Our strongest results are obtained
for $\alpha_1$-metric graphs, for which we prove that a central vertex can be
computed in subquadratic time, and even better in linear time for so-called
$(\alpha_1,\Delta)$-metric graphs (a superclass of chordal graphs and of plane
triangulations with inner vertices of degree at least $7$). The latter answers
a question raised in (Dragan, IPL, 2020). Our algorithms follow from new
results on centers and metric intervals of $\alpha_i$-metric graphs. In
particular, we prove that the diameter of the center is at most $3i+2$ (at most
$3$, if $i=1$). The latter partly answers a question raised in (Yushmanov &amp;amp;
Chepoi, Mathematical Problems in Cybernetics, 1991).
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Hyperbolic Extension of Kadison-Singer Type Results</title>
  <guid>http://arxiv.org/abs/2305.02566</guid>
  <link>http://arxiv.org/abs/2305.02566</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Ruizhe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinzhi Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In 2013, Marcus, Spielman, and Srivastava resolved the famous Kadison-Singer
conjecture. It states that for $n$ independent random vectors $v_1,\cdots, v_n$
that have expected squared norm bounded by $\epsilon$ and are in the isotropic
position in expectation, there is a positive probability that the determinant
polynomial $\det(xI - \sum_{i=1}^n v_iv_i^\top)$ has roots bounded by $(1 +
\sqrt{\epsilon})^2$. An interpretation of the Kadison-Singer theorem is that we
can always find a partition of the vectors $v_1,\cdots,v_n$ into two sets with
a low discrepancy in terms of the spectral norm (in other words, rely on the
determinant polynomial).
&lt;/p&gt;
&lt;p&gt;In this paper, we provide two results for a broader class of polynomials, the
hyperbolic polynomials. Furthermore, our results are in two generalized
settings:
&lt;/p&gt;
&lt;p&gt;$\bullet$ The first one shows that the Kadison-Singer result requires a
weaker assumption that the vectors have a bounded sum of hyperbolic norms.
&lt;/p&gt;
&lt;p&gt;$\bullet$ The second one relaxes the Kadison-Singer result&#39;s distribution
assumption to the Strongly Rayleigh distribution.
&lt;/p&gt;
&lt;p&gt;To the best of our knowledge, the previous results only support determinant
polynomials [Anari and Oveis Gharan&#39;14, Kyng, Luh and Song&#39;20]. It is unclear
whether they can be generalized to a broader class of polynomials. In addition,
we also provide a sub-exponential time algorithm for constructing our results.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Shannon meets Gray: Noise-robust, Low-sensitivity Codes with Applications in Differential Privacy</title>
  <guid>http://arxiv.org/abs/2305.02816</guid>
  <link>http://arxiv.org/abs/2305.02816</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lolck_D/0/1/0/all/0/1&quot;&gt;David Rasmussen Lolck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pagh_R/0/1/0/all/0/1&quot;&gt;Rasmus Pagh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Integer data is typically made differentially private by adding noise from a
Discrete Laplace (or Discrete Gaussian) distribution. We study the setting
where differential privacy of a counting query is achieved using bit-wise
randomized response, i.e., independent, random bit flips on the encoding of the
query answer.
&lt;/p&gt;
&lt;p&gt;Binary error-correcting codes transmitted through noisy channels with
independent bit flips are well-studied in information theory. However, such
codes are unsuitable for differential privacy since they have (by design) high
sensitivity, i.e., neighboring integers have encodings with a large Hamming
distance. Gray codes show that it is possible to create an efficient
sensitivity 1 encoding, but are also not suitable for differential privacy due
to lack of noise-robustness.
&lt;/p&gt;
&lt;p&gt;Our main result is that it is possible, with a constant rate code, to
simultaneously achieve the sensitivity of Gray codes and the noise-robustness
of error-correcting codes (down to the noise level required for differential
privacy). An application of this new encoding of the integers is a faster,
space-optimal differentially private data structure for histograms.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Local Computation Algorithms for Hypergraph Coloring -- following Beck&#39;s approach (full version)</title>
  <guid>http://arxiv.org/abs/2305.02831</guid>
  <link>http://arxiv.org/abs/2305.02831</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dorobisz_A/0/1/0/all/0/1&quot;&gt;Andrzej Dorobisz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozik_J/0/1/0/all/0/1&quot;&gt;Jakub Kozik&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We investigate local computation algorithms (LCA) for two-coloring of
$k$-uniform hypergraphs. We focus on hypergraph instances that satisfy
strengthened assumption of the Lov\&#39;{a}sz Local Lemma of the form $2^{1-\alpha
k} (\Delta+1) \mathrm{e} &amp;lt; 1$, where $\Delta$ is the bound on the maximum edge
degree. The main question which arises here is for how large $\alpha$ there
exists an LCA that is able to properly color such hypergraphs in
polylogarithmic time per query. We describe briefly how upgrading the classical
sequential procedure of Beck from 1991 with Moser and Tardos&#39; RESAMPLE yields
polylogarithmic LCA that works for $\alpha$ up to $1/4$. Then, we present an
improved procedure that solves wider range of instances by allowing $\alpha$ up
to $1/3$.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Near-Optimal Compact Routing and Decomposition Schemes for Planar Graphs</title>
  <guid>http://arxiv.org/abs/2305.02854</guid>
  <link>http://arxiv.org/abs/2305.02854</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dou_J/0/1/0/all/0/1&quot;&gt;Jinfeng Dou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gotte_T/0/1/0/all/0/1&quot;&gt;Thorsten G&amp;#xf6;tte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hillebrandt_H/0/1/0/all/0/1&quot;&gt;Henning Hillebrandt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheideler_C/0/1/0/all/0/1&quot;&gt;Christian Scheideler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Werthmann_J/0/1/0/all/0/1&quot;&gt;Julian Werthmann&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of computing compact routing tables for a (weighted)
planar graph $G:= (V, E,w)$ in the PRAM, CONGEST, and the novel HYBRID
communication model. We present algorithms with polylogarithmic work and
communication that are almost optimal in all relevant parameters, i.e.,
computation time, table sizes, and stretch. All algorithms are heavily
randomized, and all our bounds hold w.h.p. For a given parameter $\epsilon&amp;gt;0$,
our scheme computes labels of size $\widetilde{O}(\epsilon^{-1})$ and is
computed in $\widetilde{O}(\epsilon^{-2})$ time and $\widetilde{O}(n)$ work in
the PRAM and a HYBRID model and $\widetilde{O}(\epsilon^{-2} \cdot HD)$ (Here,
$HD$ denotes the network&#39;s hop-diameter) time in CONGEST. The stretch of the
resulting routing scheme is $1+\epsilon$. To achieve these results, we extend
the divide-and-conquer framework of Li and Parter [STOC &#39;19] and combine it
with state-of-the-art distributed distance approximation algorithms [STOC &#39;22].
Furthermore, we provide a distributed decomposition scheme, which may be of
independent interest.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Coloring tournaments with few colors: Algorithms and complexity</title>
  <guid>http://arxiv.org/abs/2305.02922</guid>
  <link>http://arxiv.org/abs/2305.02922</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klingelhoefer_F/0/1/0/all/0/1&quot;&gt;Felix Klingelhoefer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Newman_A/0/1/0/all/0/1&quot;&gt;Alantha Newman&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A k-coloring of a tournament is a partition of its vertices into k acyclic
sets. Deciding if a tournament is 2-colorable is NP-hard. A natural problem,
akin to that of coloring a 3-colorable graph with few colors, is to color a
2-colorable tournament with few colors. This problem does not seem to have been
addressed before, although it is a special case of coloring a 2-colorable
3-uniform hypergraph with few colors, which is a well-studied problem with
super-constant lower bounds.
&lt;/p&gt;
&lt;p&gt;We present an efficient decomposition lemma for tournaments and show that it
can be used to design polynomial-time algorithms to color various classes of
tournaments with few colors, including an algorithm to color a 2-colorable
tournament with ten colors. For the classes of tournaments considered, we
complement our upper bounds with strengthened lower bounds, painting a
comprehensive picture of the algorithmic and complexity aspects of coloring
tournaments.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>What Else Can Voronoi Diagrams Do For Diameter In Planar Graphs?</title>
  <guid>http://arxiv.org/abs/2305.02946</guid>
  <link>http://arxiv.org/abs/2305.02946</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abboud_A/0/1/0/all/0/1&quot;&gt;Amir Abboud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozes_S/0/1/0/all/0/1&quot;&gt;Shay Mozes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weimann_O/0/1/0/all/0/1&quot;&gt;Oren Weimann&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Voronoi diagrams technique was introduced by Cabello to compute the
diameter of planar graphs in subquadratic time. We present novel applications
of this technique in static, fault-tolerant, and partially-dynamic undirected
unweighted planar graphs, as well as some new limitations.
&lt;/p&gt;
&lt;p&gt;1. In the static case, we give $n^{3+o(1)}/D^2$ and $\tilde{O}(n\cdot D^2)$
time algorithms for computing the diameter of a planar graph $G$ with diameter
$D$. These are faster than the state of the art $\tilde{O}(n^{5/3})$ when
$D&amp;lt;n^{1/3}$ or $D&amp;gt;n^{2/3}$.
&lt;/p&gt;
&lt;p&gt;2. In the fault-tolerant setting, we give an $n^{7/3+o(1)}$ time algorithm
for computing the diameter of $G\setminus \{e\}$ for every edge $e$ in $G$ (the
replacement diameter problem). Compared to the naive $\tilde{O}(n^{8/3})$ time
algorithm that runs the static algorithm for every edge.
&lt;/p&gt;
&lt;p&gt;3. In the incremental setting, where we wish to maintain the diameter while
while adding edges, we present an algorithm with total running time
$n^{7/3+o(1)}$. Compared to the naive $\tilde{O}(n^{8/3})$ time algorithm that
runs the static algorithm after every update.
&lt;/p&gt;
&lt;p&gt;4. We give a lower bound (conditioned on the SETH) ruling out an amortized
$O(n^{1-\varepsilon})$ update time for maintaining the diameter in {\em
weighted} planar graph. The lower bound holds even for incremental or
decremental updates.
&lt;/p&gt;
&lt;p&gt;Our upper bounds are obtained by novel uses and manipulations of Voronoi
diagrams. These include maintaining the Voronoi diagram when edges of the graph
are deleted, allowing the sites of the Voronoi diagram to lie on a BFS tree
level (rather than on boundaries of $r$-division), and a new reduction from
incremental diameter to incremental {\em distance oracles} that could be of
interest beyond planar graphs. Our lower bound is the first lower bound for a
dynamic planar graph problem that is conditioned on the SETH.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Convergence to Lexicographically Optimal Base in a (Contra)Polymatroid and Applications to Densest Subgraph and Tree Packing</title>
  <guid>http://arxiv.org/abs/2305.02987</guid>
  <link>http://arxiv.org/abs/2305.02987</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harb_E/0/1/0/all/0/1&quot;&gt;Elfarouk Harb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quanrud_K/0/1/0/all/0/1&quot;&gt;Kent Quanrud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chekuri_C/0/1/0/all/0/1&quot;&gt;Chandra Chekuri&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Boob et al. [1] described an iterative peeling algorithm called Greedy++ for
the Densest Subgraph Problem (DSG) and conjectured that it converges to an
optimum solution. Chekuri, Quanrud, and Torres [2] extended the algorithm to
general supermodular density problems (of which DSG is a special case) and
proved that the resulting algorithm Super-Greedy++ (and hence also Greedy++)
converges. In this paper, we revisit the convergence proof and provide a
different perspective. This is done via a connection to Fujishige&#39;s quadratic
program for finding a lexicographically optimal base in a (contra)polymatroid
[3], and a noisy version of the Frank-Wolfe method from convex optimisation
[4,5]. This gives us a simpler convergence proof, and also shows a stronger
property that Super-Greedy++ converges to the optimal dense decomposition
vector, answering a question raised in Harb et al. [6]. A second contribution
of the paper is to understand Thorup&#39;s work on ideal tree packing and greedy
tree packing [7,8] via the Frank-Wolfe algorithm applied to find a
lexicographically optimum base in the graphic matroid. This yields a simpler
and transparent proof. The two results appear disparate but are unified via
Fujishige&#39;s result and convex optimisation.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Ranking and unranking bordered and unbordered words</title>
  <guid>http://arxiv.org/abs/2305.03000</guid>
  <link>http://arxiv.org/abs/2305.03000</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gabric_D/0/1/0/all/0/1&quot;&gt;Daniel Gabric&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A \emph{border} of a word $w$ is a word that is both a non-empty proper
prefix and suffix of $w$. If $w$ has a border, then it is said to be
\emph{bordered}; otherwise, it is said to be \emph{unbordered}. The main
results of this paper are the first algorithms to rank and unrank length-$n$
bordered and unbordered words over a $k$-letter alphabet. We show that ranking
bordered and unbordered words can be done in $O(kn^3)$ time using $O(n)$ space,
and unranking them can be done in $O(n^4k\log k)$ time using $O(n)$ space.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-05 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A TTIC Talk</title>
  <guid>https://rjlipton.wpcomstaging.com/?p=21598</guid>
  <link>https://rjlipton.wpcomstaging.com/2023/05/04/a-ttic-talk/</link>
  <description>
    &lt;p&gt;
Julia Chuzhoy is a professor at &lt;a href=&quot;https://home.ttic.edu/~cjulia/&quot;&gt;TTIC&lt;/a&gt;&amp;#8212;the Toyota Technological Institute at Chicago. She is giving a talk this Friday at TTIC, 6045 S. Kenwood Avenue in the 5th Floor, Room 530. Her title is, &amp;#8220;On Fixing Some Issues with Expanders.&amp;#8221; An associated &lt;a href=&quot;https://home.ttic.edu/~cjulia/papers/APSP-expanders.pdf&quot;&gt;paper&lt;/a&gt; by her, however, has a much longer title. &lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/05/04/a-ttic-talk/jc-2/&quot; rel=&quot;attachment wp-att-21600&quot;&gt;&lt;img data-attachment-id=&quot;21600&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/05/04/a-ttic-talk/jc-2/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/jc.jpeg?fit=221%2C228&amp;amp;ssl=1&quot; data-orig-size=&quot;221,228&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;jc&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/jc.jpeg?fit=221%2C228&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/jc.jpeg?fit=221%2C228&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/jc.jpeg?resize=221%2C228&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;221&quot; height=&quot;228&quot; class=&quot;aligncenter size-full wp-image-21600&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
Ken and I wrote a &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2015/06/08/minor-insights-are-useful/&quot;&gt;post&lt;/a&gt; on her work a while ago in 2015. That was on a joint result with Chandra Chekuri. He is the Paul and Cynthia Sayles Professor at UIUC. &lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/05/04/a-ttic-talk/cc-2/&quot; rel=&quot;attachment wp-att-21601&quot;&gt;&lt;img data-attachment-id=&quot;21601&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/05/04/a-ttic-talk/cc-2/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/cc.jpeg?fit=201%2C251&amp;amp;ssl=1&quot; data-orig-size=&quot;201,251&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;cc&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/cc.jpeg?fit=201%2C251&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/cc.jpeg?fit=201%2C251&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/cc.jpeg?resize=160%2C200&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;160&quot; height=&quot;200&quot; class=&quot;aligncenter wp-image-21601&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;H2&gt; A Well-Connected Talk &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
I am visiting TTIC till Friday and have to then return to home. So I will have to miss her talk. I hope it is well-connected enough that some of it gets back to me. Let me know how it goes. &lt;/p&gt;
&lt;p&gt;
I believe the main thrust of her talk should interest many since it attends to an important issue. The concept of expander graph is wonderful and has great connections to other areas of combinatorics, but the condition is costly to instantiate and verify and may go beyond what many algorithms truly need for good performance. Her method to weaken-and-sidestep the requirements, centered around a notion of &lt;em&gt;well-connected&lt;/em&gt; graphs, should help extend applications of the general technology. She says:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; We believe that the use of well-connected graphs instead of expanders in various dynamic distance-based problems (such as APSP in general graphs) has the potential of providing much stronger guarantees, since we are no longer necessarily restricted to superlogarithmic approximation factors. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Enjoy the talk. I think the results that follow from weakening expanders could be quite powerful. &lt;/p&gt;
&lt;p&gt;
&lt;p class=&quot;authors&quot;&gt;By rjlipton&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 23:25:49 UTC</pubDate>
  <author>Richard Lipton</author>
</item>

<item>
  <title>TR23-065 |  From Grassmannian to Simplicial High-Dimensional Expanders | 

	Louis Golowich</title>
  <guid>https://eccc.weizmann.ac.il/report/2023/065</guid>
  <link>https://eccc.weizmann.ac.il/report/2023/065</link>
  <description>
    In this paper, we present a new construction of simplicial complexes of subpolynomial degree with arbitrarily good local spectral expansion. Previously, the only known high-dimensional expanders (HDXs) with arbitrarily good expansion and less than polynomial degree were based on one of two constructions, namely Ramanujan complexes and coset complexes. In contrast, our construction is a Cayley complex over the group $\mathbb{F}_2^k$, with Cayley generating set given by a Grassmannian HDX.

  Our construction is in part motivated by a coding-theoretic interpretation of Grassmannian HDXs that we present, which provides a formal connection between Grassmannian HDXs, simplicial HDXs, and LDPC codes. We apply this interpretation to prove a general characterization of the 1-homology groups over $\mathbb{F}_2$ of Cayley simplicial complexes over $\mathbb{F}_2^k$. Using this result, we construct simplicial complexes on $N$ vertices with arbitrarily good local expansion for which the dimension of the 1-homology group grows as $\Omega(\log^2N)$. No prior constructions in the literature have been shown to achieve as large a 1-homology group.
  </description>
  <pubDate>2023-05-04 13:54:49 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Breaking Ground in Isomorphism Testing: A Leap Forward for a Bottleneck Case of Group Isomorphism</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-7182332023085822484</guid>
  <link>https://blog.computationalcomplexity.org/2023/05/breaking-ground-in-isomorphism-testing.html</link>
  <description>
    &lt;p&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;&lt;i&gt;Guest post by Josh Grochow and &lt;/i&gt;&lt;/span&gt;&lt;span style=&quot;font-family: Arial;&quot;&gt;&lt;span style=&quot;font-size: 14.6667px; white-space: pre-wrap;&quot;&gt;&lt;i&gt;Youming Qiao&lt;/i&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;There has, quietly, been somewhat of a breakthrough in isomorphism testing. No, not as big as Babai&#39;s 2016 &lt;/span&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.03547&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Graph Isomorphism in Quasipolynomial Time&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;. But a first foothold in climbing a wall for which no one had gotten much off the ground before. The result, due to &lt;/span&gt;&lt;a href=&quot;https://arxiv.org/abs/2303.15412&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Xiaorui Sun in this year&#39;s STOC&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;, is an algorithm for testing isomorphism of a certain class of groups - p-groups of class 2 and exponent p if you must know, but we&#39;ll get to that - in time \(n^{O(\log^{5/6} n)}\) where n is the order of the group. To understand why we&#39;re excited about this we have to tell a bit of a story.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;span id=&quot;docs-internal-guid-259ecb6b-7fff-b1a3-e5ab-283b928791b9&quot;&gt;&lt;p dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;In the 1970s, when Graph Isomorphism was still a mystery, people also thought more widely about isomorphism testing of other combinatorial and algebraic structures. For finite groups of order n, Robert Tarjan realized that there is an \(n^{\log n+O(1)}\)-time algorithm, simply because a group of order n has a generating set of size \(\log n\). This observation was recorded by Gary Miller in a &lt;/span&gt;&lt;a href=&quot;https://doi.org/10.1145/800133.804331&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;paper in STOC&#39;78&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;, and independently realized by &lt;/span&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/abs/pii/B9780080129754500114&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Felsch and Neubser&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;. A natural question is then whether Group Isomorphism can be solved in time poly(n) where n is the group order.&lt;/span&gt;&lt;/p&gt;&lt;br /&gt;&lt;p dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Not only is this question natural from the perspective of studying groups computationally, it is also natural from the perspective of &lt;/span&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-style: italic; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Graph&lt;/span&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt; Isomorphism. For Group Isomorphism reduces to Graph Isomorphism in polynomial-time (as does the isomorphism problem for any finite algebraic or relational structure, see &lt;/span&gt;&lt;a href=&quot;https://doi.org/10.1007/BF02104746&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Zemlyachenko, Korneenko, &amp;amp; Tyshkevich&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;). While this has been known for a long time, Babais result on Graph Isomorphism brings the running times quite close: \(n^{O(\log^2 n)}\) for graphs, and \(n^{O(\log n)}\) for groups. So not only does Group Isomorphism stand in the way of getting Graph Isomorphism into P, but in our current state of knowledge, it even stands in the way of shaving off more than a single log in the exponent of the runtime.&lt;/span&gt;&lt;/p&gt;&lt;br /&gt;&lt;p dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Since the general Group Isomorphism problem seems difficult, attention turned to special classes of groups. It was not hard to see that isomorphism of Abelian groups could be computed in polynomial time. However, a group class that is just one step away from Abelian - groups G where, when you mod out by the center Z(G), whats left is Abelian -&amp;nbsp; turned out to be difficult. Such groups are called class-2 nilpotent, and in one sense, their&amp;nbsp; group-theoretic structure is relatively straightforward: both G/Z(G) and Z(G) are Abelian. Yet, to devise an efficient isomorphism testing procedure turned out to be extremely difficult (see e.g. &lt;/span&gt;&lt;a href=&quot;https://doi.org/10.1016/0022-0000(91)90012-T&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Garzon-Zalcstein&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;, &lt;/span&gt;&lt;a href=&quot;https://doi.org/10.1016/j.tcs.2015.05.036&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Rosenbaum-Wagner&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;, &lt;/span&gt;&lt;a href=&quot;https://www.math.auckland.ac.nz/~obrien/research/isom.pdf&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;OBrien&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;, &lt;/span&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0021869309004463&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Wilson&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;), to the point that this is usually considered as a bottleneck for putting Group Isomorphism in P.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;br /&gt;&lt;p dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Among class-2 nilpotent groups, the key case to resolve is widely believed, &lt;/span&gt;&lt;a href=&quot;https://cstheory.stackexchange.com/a/42551/129&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;for several reasons&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;, to be p-groups of class 2 and exponent p. In such groups, both the center Z(G) and quotient G/Z(G) are elementary abelian, i.e., of the form \((Z_p)^d\). Despite having an even simpler group-theoretic structure, this group class still turns out to be difficult! For a long time, the asymptotic growth of the exponent of the runtime for solving this restricted problem has not improved over the \(n^{\log n+O(1)}\)-time algorithm, which works for all groups.&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;br /&gt;&lt;p dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Xiaorui Suns result represents the first substantial improvement, cracking open this decades-old quest. His algorithm runs in time \(n^{O(\log^{5/6} n)}\), and its techniques are indeed novel. The starting point of this algorithm is to consider the following equivalent problem in (multi)linear algebra: let \(f, g:Z_p^d \times Z_p^d \rightarrow Z_p^e\) be two skew-symmetric bilinear maps. Do there exist change of bases A in \(GL(d, p)\) and B in \(GL(e, p)\), such that for all \(u, v\) in \(Z_p^d\), \(f(A(u), A(v))=B(g(u, v))\)?&lt;/span&gt;&lt;/p&gt;&lt;br /&gt;&lt;p dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;a href=&quot;https://www.jstor.org/stable/1989886&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Baers Correspondence&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt; sets up an equivalence of categories between p-groups of class 2 and exponent p, and skew-symmetric bilinear maps over \(Z_p\). This viewpoint allows Xiaorui to use multilinear algebra to study the structure of these bilinear maps. He also crucially depends on a result of &lt;/span&gt;&lt;a href=&quot;https://doi.org/10.1137/18M1165682&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Ivanyos and Qiao&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;, which built on &lt;/span&gt;&lt;a href=&quot;https://doi.org/10.1016/j.jalgebra.2009.07.029&quot; style=&quot;text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Wilsons use&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt; of involutive algebras in this context. He also uses the individualization-and-refinement technique (but for matrix spaces, not graphs!), a characterization of spaces of matrices of low rank, and reducing a tensor to a semi-canonical form part of which is somewhat reminiscent of the Tucker decomposition.&lt;/span&gt;&lt;/p&gt;&lt;br /&gt;&lt;p dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;All this results in an algorithm which solves the above problem on bilinear maps in time \(p^{(d+e)^{1.8} \log p}\). For groups of order \(p^n\) with \(\log_p(n)\) larger than \(\log^5 p\), Baers Correspondence then says that this algorithm does it; when \(\log_p n\) is smaller than \(log^5 p,\) he can fall back on the generator-enumerator algorithm, since the number of generators is at most \(log_p n\).&lt;/span&gt;&lt;/p&gt;&lt;br /&gt;&lt;p dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;For us, who have been working on Group Isomorphism for more than a decade, Xiaoruis result represents an exciting development on this classic algorithmic problem, and we look forward to seeing more progress in this direction in the near future.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr /&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;&lt;a href=&quot;https://doi.org/10.1016/j.tcs.2015.05.036&quot; style=&quot;font-family: &amp;quot;Times New Roman&amp;quot;; font-size: medium; text-decoration-line: none; white-space: normal;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Rosenbaum &amp;amp; Wagner&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline;&quot;&gt; improved the exponent to \(\frac{1}{2}\log {p(n)} + O(1)\), and later improved to \(\frac{1}{4}\log {p(n)} + O(1)\) for all groups, see p.5 of &lt;/span&gt;&lt;a href=&quot;https://arxiv.org/abs/1609.08253&quot; style=&quot;font-family: &amp;quot;Times New Roman&amp;quot;; font-size: medium; text-decoration-line: none; white-space: normal;&quot;&gt;&lt;span style=&quot;color: #1155cc; font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Le Gall &amp;amp; Rosenbaum&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-family: Arial; font-size: 11pt; font-variant-alternates: normal; font-variant-east-asian: normal; font-variant-numeric: normal; vertical-align: baseline;&quot;&gt;. In 2014, at a conference on Groups, Computation, and Geometry organized by Wilson, Brooksbank, Hulpke, Kantor, and Penttila, it was concluded that modern practical methods, such as those used in GAP and MAGMA, still take \(n^{O(\log n)}\) steps in the worst case.&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;/p&gt;&lt;/span&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 11:12:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>PhD Student at Department of Computer and Information Science, Linkping University (apply by May 28, 2023)</title>
  <guid>http://cstheory-jobs.org/2023/05/04/phd-student-at-department-of-computer-and-information-science-linkoping-university-apply-by-may-28-2023/</guid>
  <link>https://cstheory-jobs.org/2023/05/04/phd-student-at-department-of-computer-and-information-science-linkoping-university-apply-by-may-28-2023/</link>
  <description>
    &lt;p&gt;Linkping University advertises one (1) position as PhD student in Computer Science. The PhD student will be supervised by prof. Peter Jonsson. The research for the advertised position is in the area of parameterized complexity of constraint satisfaction problems (CSP).&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://liu.se/en/work-at-liu/vacancies/21872&quot;&gt;https://liu.se/en/work-at-liu/vacancies/21872&lt;/a&gt;&lt;br /&gt;
Email: peter.jonsson@liu.se&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 09:18:29 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Construction of Decision Trees and Acyclic Decision Graphs from Decision Rule Systems</title>
  <guid>http://arxiv.org/abs/2305.01721</guid>
  <link>http://arxiv.org/abs/2305.01721</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durdymyradov_K/0/1/0/all/0/1&quot;&gt;Kerven Durdymyradov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moshkov_M/0/1/0/all/0/1&quot;&gt;Mikhail Moshkov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Decision trees and systems of decision rules are widely used as classifiers,
as a means for knowledge representation, and as algorithms. They are among the
most interpretable models for data analysis. The study of the relationships
between these two models can be seen as an important task of computer science.
Methods for transforming decision trees into systems of decision rules are
simple and well-known. In this paper, we consider the inverse transformation
problem, which is not trivial. We study the complexity of constructing decision
trees and acyclic decision graphs representing decision trees from decision
rule systems, and we discuss the possibility of not building the entire
decision tree, but describing the computation path in this tree for the given
input.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Complexity and Enumeration in Models of Genome Rearrangement</title>
  <guid>http://arxiv.org/abs/2305.01851</guid>
  <link>http://arxiv.org/abs/2305.01851</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Bailey_L/0/1/0/all/0/1&quot;&gt;Lora Bailey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Blake_H/0/1/0/all/0/1&quot;&gt;Heather Smith Blake&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Cochran_G/0/1/0/all/0/1&quot;&gt;Garner Cochran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Fox_N/0/1/0/all/0/1&quot;&gt;Nathan Fox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Levet_M/0/1/0/all/0/1&quot;&gt;Michael Levet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Mahmoud_R/0/1/0/all/0/1&quot;&gt;Reem Mahmoud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Matson_E/0/1/0/all/0/1&quot;&gt;Elizabeth Matson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Singgih_I/0/1/0/all/0/1&quot;&gt;Inne Singgih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Stadnyk_G/0/1/0/all/0/1&quot;&gt;Grace Stadnyk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Widemann_A/0/1/0/all/0/1&quot;&gt;Alexander Widemann&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we examine the computational complexity of enumeration in
certain genome rearrangement models. We first show that the Pairwise
Rearrangement problem in the Single Cut-and-Join model (Bergeron, Medvedev, &amp;amp;
Stoye, J. Comput. Biol. 2010) is $\#\textsf{P}$-complete under polynomial-time
Turing reductions. Next, we show that in the Single Cut or Join model (Feijao &amp;amp;
Meidanis, IEEE ACM Trans. Comp. Biol. Bioinf. 2011), the problem of enumerating
all medians ($\#$Median) is logspace-computable ($\textsf{FL}$), improving upon
the previous polynomial-time ($\textsf{FP}$) bound of Mikl\&#39;os &amp;amp; Smith (RECOMB
2015).
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>$P\not=NP$ relative to a $P$-complete oracle</title>
  <guid>http://arxiv.org/abs/2305.02226</guid>
  <link>http://arxiv.org/abs/2305.02226</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Czerwinski_R/0/1/0/all/0/1&quot;&gt;Reiner Czerwinski&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The $P$ versus $NP$ problem is still unsolved. But there are several oracles
with $P$ unequal $NP$ relative to them. Here we will prove, that $P\not=NP$
relative to a $P$-complete oracle. In this paper, we use padding arguments as
the proof method. The padding arguments are not bounded by a computable
function. Such as we can use methods from computability theory to separate
complexity classes.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The Impacts of Dimensionality, Diffusion, and Directedness on Intrinsic Cross-Model Simulation in Tile-Based Self-Assembly</title>
  <guid>http://arxiv.org/abs/2305.01877</guid>
  <link>http://arxiv.org/abs/2305.01877</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hader_D/0/1/0/all/0/1&quot;&gt;Daniel Hader&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patitz_M/0/1/0/all/0/1&quot;&gt;Matthew J. Patitz&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Algorithmic self-assembly occurs when disorganized components autonomously
combine to form structures and, by their design and the dynamics of the system,
are forced to follow the execution of algorithms. Motivated by applications in
DNA-nanotechnology, investigations in algorithmic tile-based self-assembly have
blossomed into a mature theory with research leveraging tools from
computability theory, complexity theory, information theory, and graph theory
to develop a wide range of models and show that many are computationally
universal, while also exposing powers and limitations of each. Beyond
computational universality, the abstract Tile Assembly Model (aTAM) was shown
to be intrinsically universal (IU), a strong notion of completeness where a
single tile set is capable of simulating all systems within the model; however,
this result required non-deterministic tile attachments. This was later
confirmed necessary when it was shown that the class of directed aTAM systems
is not IU. Building on these results to further investigate the impacts of
other dynamics, Hader et al. examined several tile-assembly models which varied
across (1) the numbers of dimensions used, (2) restrictions based on diffusion
of tiles through space, and (3) whether each system is directed, and showed
which models are IU. Such results have shed much light on the roles of various
aspects of the dynamics of tile-assembly and their effects on the intrinsic
universality of each model. Here we provide direct comparisons of the various
models by considering intrinsic simulations between models. We show that in
some cases one model is more powerful than another, and in others, pairs of
models have mutually exclusive capabilities. This comparison helps to expose
the impacts of these three important aspects and further helps define a
hierarchy of tile-assembly models.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>A Lightweight CNN-Transformer Model for Learning Traveling Salesman Problems</title>
  <guid>http://arxiv.org/abs/2305.01883</guid>
  <link>http://arxiv.org/abs/2305.01883</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_M/0/1/0/all/0/1&quot;&gt;Minseop Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jaeseung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jibum Kim&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Transformer-based models show state-of-the-art performance even for
large-scale Traveling Salesman Problems (TSPs). However, they are based on
fully-connected attention models and suffer from large computational complexity
and GPU memory usage. We propose a lightweight CNN-Transformer model based on a
CNN embedding layer and partial self-attention. Our CNN-Transformer model is
able to better learn spatial features from input data using a CNN embedding
layer compared with the standard Transformer models. It also removes
considerable redundancy in fully connected attention models using the proposed
partial self-attention. Experiments show that the proposed model outperforms
other state-of-the-art Transformer-based models in terms of TSP solution
quality, GPU memory usage, and inference time. Our model consumes approximately
20% less GPU memory usage and has 45% faster inference time compared with other
state-of-the-art Transformer-based models. Our code is publicly available at
https://github.com/cm8908/CNN_Transformer3
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Approximate Evaluation of Quantitative Second Order Queries</title>
  <guid>http://arxiv.org/abs/2305.02056</guid>
  <link>http://arxiv.org/abs/2305.02056</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dreier_J/0/1/0/all/0/1&quot;&gt;Jan Dreier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganian_R/0/1/0/all/0/1&quot;&gt;Robert Ganian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamm_T/0/1/0/all/0/1&quot;&gt;Thekla Hamm&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Courcelle&#39;s theorem and its adaptations to cliquewidth have shaped the field
of exact parameterized algorithms and are widely considered the archetype of
algorithmic meta-theorems. In the past decade, there has been growing interest
in developing parameterized approximation algorithms for problems which are not
captured by Courcelle&#39;s theorem and, in particular, are considered not
fixed-parameter tractable under the associated widths.
&lt;/p&gt;
&lt;p&gt;We develop a generalization of Courcelle&#39;s theorem that yields efficient
approximation schemes for any problem that can be captured by an expanded logic
we call Blocked CMSO, capable of making logical statements about the sizes of
set variables via so-called weight comparisons. The logic controls weight
comparisons via the quantifier-alternation depth of the involved variables,
allowing full comparisons for zero-alternation variables and limited
comparisons for one-alternation variables. We show that the developed framework
threads the very needle of tractability: on one hand it can describe a broad
range of approximable problems, while on the other hand we show that the
restrictions of our logic cannot be relaxed under well-established complexity
assumptions.
&lt;/p&gt;
&lt;p&gt;The running time of our approximation scheme is polynomial in
$1/\varepsilon$, allowing us to fully interpolate between faster approximate
algorithms and slower exact algorithms. This provides a unified framework to
explain the tractability landscape of graph problems parameterized by treewidth
and cliquewidth, as well as classical non-graph problems such as Subset Sum and
Knapsack.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>$L$ is unequal $NL$ under the Strong Exponential Time Hypothesis</title>
  <guid>http://arxiv.org/abs/2305.02271</guid>
  <link>http://arxiv.org/abs/2305.02271</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Czerwinski_R/0/1/0/all/0/1&quot;&gt;Reiner Czerwinski&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Due to Savitch&#39;s theorem we know $NL\subseteq DSPACE(\log^2(n))$. To show
this upper bound, Savitch constructed an algorithm with $O(\log^2(n))$ space on
the working tape. We will show that Savitch&#39;s algorithm also described a lower
bound under the Strong Exponential Time Hypothesis. Every algorithm for the
Connectivity Problem needs $O(\log^2(n))$ space in this case.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On the Fine-Grained Complexity of Small-Size Geometric Set Cover and Discrete $k$-Center for Small $k$</title>
  <guid>http://arxiv.org/abs/2305.01892</guid>
  <link>http://arxiv.org/abs/2305.01892</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1&quot;&gt;Timothy M. Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1&quot;&gt;Qizheng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yuancheng Yu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the time complexity of the discrete $k$-center problem and related
(exact) geometric set cover problems when $k$ or the size of the cover is
small. We obtain a plethora of new results:
&lt;/p&gt;
&lt;p&gt;- We give the first subquadratic algorithm for rectilinear discrete 3-center
in 2D, running in $\widetilde{O}(n^{3/2})$ time.
&lt;/p&gt;
&lt;p&gt;- We prove a lower bound of $\Omega(n^{4/3-\delta})$ for rectilinear discrete
3-center in 4D, for any constant $\delta&amp;gt;0$, under a standard hypothesis about
triangle detection in sparse graphs.
&lt;/p&gt;
&lt;p&gt;- Given $n$ points and $n$ weighted axis-aligned unit squares in 2D, we give
the first subquadratic algorithm for finding a minimum-weight cover of the
points by 3 unit squares, running in $\widetilde{O}(n^{8/5})$ time. We also
prove a lower bound of $\Omega(n^{3/2-\delta})$ for the same problem in 2D,
under the well-known APSP Hypothesis. For arbitrary axis-aligned rectangles in
2D, our upper bound is $\widetilde{O}(n^{7/4})$.
&lt;/p&gt;
&lt;p&gt;- We prove a lower bound of $\Omega(n^{2-\delta})$ for Euclidean discrete
2-center in 13D, under the Hyperclique Hypothesis. This lower bound nearly
matches the straightforward upper bound of $\widetilde{O}(n^\omega)$, if the
matrix multiplication exponent $\omega$ is equal to 2.
&lt;/p&gt;
&lt;p&gt;- We similarly prove an $\Omega(n^{k-\delta})$ lower bound for Euclidean
discrete $k$-center in $O(k)$ dimensions for any constant $k\ge 3$, under the
Hyperclique Hypothesis. This lower bound again nearly matches known upper
bounds if $\omega=2$.
&lt;/p&gt;
&lt;p&gt;- We also prove an $\Omega(n^{2-\delta})$ lower bound for the problem of
finding 2 boxes to cover the largest number of points, given $n$ points and $n$
boxes in 12D. This matches the straightforward near-quadratic upper bound.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Streaming Edge Coloring with Asymptotically Optimal Colors</title>
  <guid>http://arxiv.org/abs/2305.01714</guid>
  <link>http://arxiv.org/abs/2305.01714</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behnezhad_S/0/1/0/all/0/1&quot;&gt;Soheil Behnezhad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saneian_M/0/1/0/all/0/1&quot;&gt;Mohammad Saneian&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a graph $G$, an edge-coloring is an assignment of colors to edges of
$G$ such that any two edges sharing an endpoint receive different colors. By
Vizing&#39;s celebrated theorem, any graph of maximum degree $\Delta$ needs at
least $\Delta$ and at most $(\Delta + 1)$ colors to be properly edge colored.
In this paper, we study edge colorings in the streaming setting. The edges
arrive one by one in an arbitrary order. The algorithm takes a single pass over
the input and must output a solution using a much smaller space than the input
size. Since the output of edge coloring is as large as its input, the assigned
colors should also be reported in a streaming fashion.
&lt;/p&gt;
&lt;p&gt;The streaming edge coloring problem has been studied in a series of works
over the past few years. The main challenge is that the algorithm cannot
&quot;remember&quot; all the color assignments that it returns. To ensure the validity of
the solution, existing algorithms use many more colors than Vizing&#39;s bound.
Namely, in $n$-vertex graphs, the state-of-the-art algorithm with
$\widetilde{O}(n s)$ space requires $O(\Delta^2/s + \Delta)$ colors. Note, in
particular, that for an asymptotically optimal $O(\Delta)$ coloring, this
algorithm requires $\Omega(n\Delta)$ space which is as large as the input.
Whether such a coloring can be achieved with sublinear space has been left
open.
&lt;/p&gt;
&lt;p&gt;In this paper, we answer this question in the affirmative. We present a
randomized algorithm that returns an asymptotically optimal $O(\Delta)$ edge
coloring using $\widetilde{O}(n \sqrt{\Delta})$ space. More generally, our
algorithm returns a proper $O(\Delta^{1.5}/s + \Delta)$ edge coloring with
$\widetilde{O}(n s)$ space, improving prior algorithms for the whole range of
$s$.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Connectivity Queries under Vertex Failures: Not Optimal, but Practical</title>
  <guid>http://arxiv.org/abs/2305.01756</guid>
  <link>http://arxiv.org/abs/2305.01756</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kosinas_E/0/1/0/all/0/1&quot;&gt;Evangelos Kosinas&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We revisit once more the problem of designing an oracle for answering
connectivity queries in undirected graphs in the presence of vertex failures.
Specifically, given an undirected graph $G$ with $n$ vertices and $m$ edges and
an integer $d_{\star}\ll n$, the goal is to preprocess the graph in order to
construct a data structure $\mathcal{D}$ such that, given a set of vertices $F$
with $|F|=d\leq d_{\star}$, we can derive an oracle from $\mathcal{D}$ that can
efficiently answer queries of the form &quot;is $x$ connected with $y$ in
$G\setminus F$?&quot;. Very recently, Long and Saranurak (FOCS 2022) provided a
solution to this problem that is almost optimal with respect to the
preprocessing time, the space usage, the update time, and the query time.
However, their solution is highly complicated, and it seems very difficult to
be implemented efficiently. Furthermore, it does not settle the complexity of
the problem in the regime where $d_{\star}$ is a constant. Here, we provide a
much simpler solution to this problem, that uses only textbook data structures.
Our algorithm is deterministic, it has preprocessing time and space complexity
$O(d_{\star}m\log n)$, update time $O(d^4 \log n)$, and query time $O(d)$.
These bounds compare very well with the previous best, especially considering
the simplicity of our approach. In fact, if we assume that $d_{\star}$ is a
constant ($d_{\star}\geq 4$), then our algorithm improves on the
state-of-the-art in every respect, except space. Nevertheless, even our space
usage in this case is almost linear. Finally, the data structure that we
provide is flexible with respect to $d_{\star}$: it can be adapted to increases
and decreases, in time and space that are almost proportional to the change in
$d_{\star}$ and the size of the graph.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Experimental Design for Any $p$-Norm</title>
  <guid>http://arxiv.org/abs/2305.01942</guid>
  <link>http://arxiv.org/abs/2305.01942</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lau_L/0/1/0/all/0/1&quot;&gt;Lap Chi Lau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Robert Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hong Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider a general $p$-norm objective for experimental design problems
that captures some well-studied objectives (D/A/E-design) as special cases. We
prove that a randomized local search approach provides a unified algorithm to
solve this problem for all $p$. This provides the first approximation algorithm
for the general $p$-norm objective, and a nice interpolation of the best known
bounds of the special cases.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Computing paths of large rank in planar frameworks deterministically</title>
  <guid>http://arxiv.org/abs/2305.01993</guid>
  <link>http://arxiv.org/abs/2305.01993</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1&quot;&gt;Fedor V. Fomin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golovach_P/0/1/0/all/0/1&quot;&gt;Petr A. Golovach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korhonen_T/0/1/0/all/0/1&quot;&gt;Tuukka Korhonen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stamoulis_G/0/1/0/all/0/1&quot;&gt;Giannos Stamoulis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A framework consists of an undirected graph $G$ and a matroid $M$ whose
elements correspond to the vertices of $G$. Recently, Fomin et al. [SODA 2023]
and Eiben et al. [ArXiV 2023] developed parameterized algorithms for computing
paths of rank $k$ in frameworks. More precisely, for vertices $s$ and $t$ of
$G$, and an integer $k$, they gave FPT algorithms parameterized by $k$ deciding
whether there is an $(s,t)$-path in $G$ whose vertex set contains a subset of
elements of $M$ of rank $k$. These algorithms are based on Schwartz-Zippel
lemma for polynomial identity testing and thus are randomized, and therefore
the existence of a deterministic FPT algorithm for this problem remains open.
We present the first deterministic FPT algorithm that solves the problem in
frameworks whose underlying graph $G$ is planar. While the running time of our
algorithm is worse than the running times of the recent randomized algorithms,
our algorithm works on more general classes of matroids. In particular, this is
the first FPT algorithm for the case when matroid $M$ is represented over
rationals. Our main technical contribution is the nontrivial adaptation of the
classic irrelevant vertex technique to frameworks to reduce the given instance
to one of bounded treewidth. This allows us to employ the toolbox of
representative sets to design a dynamic programming procedure solving the
problem efficiently on instances of bounded treewidth.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Approximating Long Cycle Above Dirac&#39;s Guarantee</title>
  <guid>http://arxiv.org/abs/2305.02011</guid>
  <link>http://arxiv.org/abs/2305.02011</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1&quot;&gt;Fedor F. Fomin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golovach_P/0/1/0/all/0/1&quot;&gt;Petr A. Golovach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sagunov_D/0/1/0/all/0/1&quot;&gt;Danil Sagunov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simonov_K/0/1/0/all/0/1&quot;&gt;Kirill Simonov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Parameterization above (or below) a guarantee is a successful concept in
parameterized algorithms. The idea is that many computational problems admit
``natural&#39;&#39; guarantees bringing to algorithmic questions whether a better
solution (above the guarantee) could be obtained efficiently. The above
guarantee paradigm has led to several exciting discoveries in the areas of
parameterized algorithms and kernelization. We argue that this paradigm could
bring forth fresh perspectives on well-studied problems in approximation
algorithms. Our example is the longest cycle problem. One of the oldest results
in extremal combinatorics is the celebrated Dirac&#39;s theorem from 1952. Dirac&#39;s
theorem provides the following guarantee on the length of the longest cycle:
for every 2-connected n-vertex graph G with minimum degree \delta(G)\leq n/2,
the length of a longest cycle L is at least 2\delta(G). Thus, the ``essential&#39;&#39;
part in finding the longest cycle is in approximating the ``offset&#39;&#39; k = L - 2
\delta(G). The main result of this paper is the above-guarantee approximation
theorem for k. Informally, the theorem says that approximating the offset k is
not harder than approximating the total length L of a cycle. In other words,
for any (reasonably well-behaved) function f, a polynomial time algorithm
constructing a cycle of length f(L) in an undirected graph with a cycle of
length L, yields a polynomial time algorithm constructing a cycle of length
2\delta(G)+\Omega(f(k)).
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Algorithmic Theory of Qubit Routing</title>
  <guid>http://arxiv.org/abs/2305.02059</guid>
  <link>http://arxiv.org/abs/2305.02059</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1&quot;&gt;Takehiro Ito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakimura_N/0/1/0/all/0/1&quot;&gt;Naonori Kakimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamiyama_N/0/1/0/all/0/1&quot;&gt;Naoyuki Kamiyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1&quot;&gt;Yusuke Kobayashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okamoto_Y/0/1/0/all/0/1&quot;&gt;Yoshio Okamoto&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The qubit routing problem, also known as the swap minimization problem, is a
(classical) combinatorial optimization problem that arises in the design of
compilers of quantum programs. We study the qubit routing problem from the
viewpoint of theoretical computer science, while most of the existing studies
investigated the practical aspects. We concentrate on the linear nearest
neighbor (LNN) architectures of quantum computers, in which the graph topology
is a path. Our results are three-fold. (1) We prove that the qubit routing
problem is NP-hard. (2) We give a fixed-parameter algorithm when the number of
two-qubit gates is a parameter. (3) We give a polynomial-time algorithm when
each qubit is involved in at most one two-qubit gate.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>An Efficient Algorithm for All-Pairs Bounded Edge Connectivity</title>
  <guid>http://arxiv.org/abs/2305.02132</guid>
  <link>http://arxiv.org/abs/2305.02132</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akmal_S/0/1/0/all/0/1&quot;&gt;Shyan Akmal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1&quot;&gt;Ce Jin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Our work concerns algorithms for an unweighted variant of Maximum Flow. In
the All-Pairs Connectivity (APC) problem, we are given a graph $G$ on $n$
vertices and $m$ edges, and are tasked with computing the maximum number of
edge-disjoint paths from $s$ to $t$ (equivalently, the size of a minimum
$(s,t)$-cut) in $G$, for all pairs of vertices $(s,t)$. Although over
undirected graphs APC can be solved in essentially optimal $n^{2+o(1)}$ time,
the true time complexity of APC over directed graphs remains open: this problem
can be solved in $\tilde{O}(m^\omega)$ time, where $\omega \in [2, 2.373)$ is
the exponent of matrix multiplication, but no matching conditional lower bound
is known.
&lt;/p&gt;
&lt;p&gt;We study a variant of APC called the $k$-Bounded All Pairs Connectivity
($k$-APC) problem. In this problem, we are given an integer $k$ and graph $G$,
and are tasked with reporting the size of a minimum $(s,t)$-cut only for pairs
$(s,t)$ of vertices with a minimum cut size less than $k$ (if the minimum
$(s,t)$-cut has size at least $k$, we just report it is &quot;large&quot; instead of
computing the exact value).
&lt;/p&gt;
&lt;p&gt;We present an algorithm solving $k$-APC in directed graphs in
$\tilde{O}((kn)^\omega)$ time. This runtime is $\tilde O(n^\omega)$ for all $k$
polylogarithmic in $n$, which is essentially optimal under popular conjectures
from fine-grained complexity. Previously, this runtime was only known for $k\le
2$ [Georgiadis et al., ICALP 2017].
&lt;/p&gt;
&lt;p&gt;We also study a variant of $k$-APC, the $k$-Bounded All-Pairs Vertex
Connectivity ($k$-APVC) problem, which considers internally vertex-disjoint
paths instead of edge-disjoint paths. We present an algorithm solving $k$-APVC
in directed graphs in $\tilde{O}(k^2n^\omega)$ time. Previous work solved an
easier version of the $k$-APVC problem in $\tilde O((kn)^\omega)$ time [Abboud
et al, ICALP 2019].
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Random Shreier graphs of the general linear group over finite fields and expanders</title>
  <guid>http://arxiv.org/abs/2305.02154</guid>
  <link>http://arxiv.org/abs/2305.02154</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Caillat_Grenier_G/0/1/0/all/0/1&quot;&gt;Geoffroy Caillat-Grenier&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper we discuss potentially practical ways to produce expander
graphs with good spectral properties and a compact description. We focus on
several classes of uniform and bipartite expander graphs defined as random
Schreier graphs of the general linear group over the finite field of size two.
We perform numerical experiments and show that such constructions produce
spectral expanders that can be useful for practical applications. To find a
theoretical explanation of the observed experimental results, we used the
method of moments to prove upper bounds for the expected second largest
eigenvalue of the random Schreier graphs used in our constructions. We focus on
bounds for which it is difficult to study the asymptotic behaviour but it is
possible to compute non-trivial conclusions for relatively small graphs with
parameters from our numerical experiments (e.g., with less than 2^200 vertices
and degree at least logarithmic in the number of vertices).
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Minimum Chain Cover in Almost Linear Time</title>
  <guid>http://arxiv.org/abs/2305.02166</guid>
  <link>http://arxiv.org/abs/2305.02166</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caceres_M/0/1/0/all/0/1&quot;&gt;Manuel Caceres&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A minimum chain cover (MCC) of a $k$-width directed acyclic graph (DAG) $G =
(V, E)$ is a set of $k$ chains (paths in the transitive closure) of $G$ such
that every vertex appears in at least one chain in the cover. The
state-of-the-art solutions for MCC run in time $\tilde{O}(k(|V|+|E|))$
[M\&quot;akinen et at., TALG], $O(T_{MF}(|E|) + k|V|)$, $O(k^2|V| + |E|)$ [C\&#39;aceres
et al., SODA 2022], $\tilde{O}(|V|^{3/2} + |E|)$ [Kogan and Parter, ICALP 2022]
and $\tilde{O}(T_{MCF}(|E|) + \sqrt{k}|V|)$ [Kogan and Parter, SODA 2023],
where $T_{MF}(|E|)$ and $T_{MCF}(|E|)$ are the running times for solving
maximum flow (MF) and minimum-cost flow (MCF), respectively.
&lt;/p&gt;
&lt;p&gt;In this work we present an algorithm running in time $O(T_{MF}(|E|) +
(|V|+|E|)\log{k})$. By considering the recent result for solving MF [Chen et
al., FOCS 2022] our algorithm is the first running in almost linear time.
Moreover, our techniques are deterministic and derive a deterministic
near-linear time algorithm for MCC if the same is provided for MF. At the core
of our solution we use a modified version of the mergeable dictionaries [Farach
and Thorup, Algorithmica], [Iacono and \&quot;Ozkan, ICALP 2010] data structure
boosted with the SIZE-SPLIT operation and answering queries in amortized
logarithmic time, which can be of independent interest.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Learning-Augmented Online TSP on Rings, Trees, Flowers and (almost) Everywhere Else</title>
  <guid>http://arxiv.org/abs/2305.02169</guid>
  <link>http://arxiv.org/abs/2305.02169</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bampis_E/0/1/0/all/0/1&quot;&gt;Evripidis Bampis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Escoffier_B/0/1/0/all/0/1&quot;&gt;Bruno Escoffier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouleakis_T/0/1/0/all/0/1&quot;&gt;Themis Gouleakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hahn_N/0/1/0/all/0/1&quot;&gt;Niklas Hahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakis_K/0/1/0/all/0/1&quot;&gt;Kostas Lakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahkarami_G/0/1/0/all/0/1&quot;&gt;Golnoosh Shahkarami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xefteris_M/0/1/0/all/0/1&quot;&gt;Michalis Xefteris&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the Online Traveling Salesperson Problem (OLTSP) with predictions.
In OLTSP, a sequence of initially unknown requests arrive over time at points
(locations) of a metric space. The goal is, starting from a particular point of
the metric space (the origin), to serve all these requests while minimizing the
total time spent. The server moves with unit speed or is &quot;waiting&quot; (zero speed)
at some location. We consider two variants: in the open variant, the goal is
achieved when the last request is served. In the closed one, the server
additionally has to return to the origin. We adopt a prediction model,
introduced for OLTSP on the line, in which the predictions correspond to the
locations of the requests and extend it to more general metric spaces.
&lt;/p&gt;
&lt;p&gt;We first propose an oracle-based algorithmic framework, inspired by previous
work. This framework allows us to design online algorithms for general metric
spaces that provide competitive ratio guarantees which, given perfect
predictions, beat the best possible classical guarantee (consistency).
Moreover, they degrade gracefully along with the increase in error
(smoothness), but always within a constant factor of the best known competitive
ratio in the classical case (robustness).
&lt;/p&gt;
&lt;p&gt;Having reduced the problem to designing suitable efficient oracles, we
describe how to achieve this for general metric spaces as well as specific
metric spaces (rings, trees and flowers), the resulting algorithms being
tractable in the latter case. The consistency guarantees of our algorithms are
tight in almost all cases, and their smoothness guarantees only suffer a linear
dependency on the error, which we show is necessary. Finally, we provide
robustness guarantees improving previous results.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A $4/3$ Approximation for $2$-Vertex-Connectivity</title>
  <guid>http://arxiv.org/abs/2305.02240</guid>
  <link>http://arxiv.org/abs/2305.02240</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bosch_Calvo_M/0/1/0/all/0/1&quot;&gt;Miguel Bosch-Calvo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grandoni_F/0/1/0/all/0/1&quot;&gt;Fabrizio Grandoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ameli_A/0/1/0/all/0/1&quot;&gt;Afrouz Jabal Ameli&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The 2-Vertex-Connected Spanning Subgraph problem (2VCSS) is among the most
basic NP-hard (Survivable) Network Design problems: we are given an
(unweighted) undirected graph $G$. Our goal is to find a subgraph $S$ of $G$
with the minimum number of edges which is $2$-vertex-connected, namely $S$
remains connected after the deletion of an arbitrary node. 2VCSS is
well-studied in terms of approximation algorithms, and the current best
(polynomial-time) approximation factor is $10/7$ by Heeger and Vygen [SIDMA&#39;17]
(improving on earlier results by Khuller and Vishkin [STOC&#39;92] and Garg,
Vempala and Singla [SODA&#39;93]).
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Triangle Counting with Local Edge Differential Privacy</title>
  <guid>http://arxiv.org/abs/2305.02263</guid>
  <link>http://arxiv.org/abs/2305.02263</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eden_T/0/1/0/all/0/1&quot;&gt;Talya Eden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Quanquan C. Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raskhodnikova_S/0/1/0/all/0/1&quot;&gt;Sofya Raskhodnikova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1&quot;&gt;Adam Smith&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Many deployments of differential privacy in industry are in the local model,
where each party releases its private information via a differentially private
randomizer. We study triangle counting in the noninteractive and interactive
local model with edge differential privacy (that, intuitively, requires that
the outputs of the algorithm on graphs that differ in one edge be
indistinguishable). In this model, each party&#39;s local view consists of the
adjacency list of one vertex.
&lt;/p&gt;
&lt;p&gt;In the noninteractive model, we prove that additive $\Omega(n^2)$ error is
necessary, where $n$ is the number of nodes. This lower bound is our main
technical contribution. It uses a reconstruction attack with a new class of
linear queries and a novel mix-and-match strategy of running the local
randomizers with different completions of their adjacency lists. It matches the
additive error of the algorithm based on Randomized Response, proposed by
Imola, Murakami and Chaudhuri (USENIX2021) and analyzed by Imola, Murakami and
Chaudhuri (CCS2022) for constant $\varepsilon$. We use a different
postprocessing of Randomized Response and provide tight bounds on the variance
of the resulting algorithm.
&lt;/p&gt;
&lt;p&gt;In the interactive setting, we prove a lower bound of $\Omega(n^{3/2})$ on
the additive error. Previously, no hardness results were known for interactive,
edge-private algorithms in the local model, except for those that follow
trivially from the results for the central model. Our work significantly
improves on the state of the art in differentially private graph analysis in
the local model.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Mechanisms: Inside or In-Between?</title>
  <guid>https://blog.simons.berkeley.edu/?p=920</guid>
  <link>https://blog.simons.berkeley.edu/2023/05/mechanisms-inside-or-in-between/</link>
  <description>
    by Issa Kohler-Hausmann (Senior Law and Society Fellow, Spring 2022, Simons Institute)1 This work was made possible by the Simons Institutes Causality program in the spring of 2022, where I was the Law and Society fellow and had the opportunity &amp;#8230; &lt;a href=&quot;https://blog.simons.berkeley.edu/2023/05/mechanisms-inside-or-in-between/&quot;&gt;Continue reading &lt;span class=&quot;meta-nav&quot;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;p class=&quot;authors&quot;&gt;By Simons Institute Editor&lt;/p&gt;
  </description>
  <pubDate>2023-05-04 00:00:00 UTC</pubDate>
  <author>Simons Institute Blog</author>
</item>

<item>
  <title>Postdocs at Aalto University (apply by June 1, 2023)</title>
  <guid>http://cstheory-jobs.org/2023/05/03/postdocs-at-aalto-university-apply-by-june-1-2023/</guid>
  <link>https://cstheory-jobs.org/2023/05/03/postdocs-at-aalto-university-apply-by-june-1-2023/</link>
  <description>
    &lt;p&gt;The research group of Jukka Suomela at Aalto University is looking for postdoctoral researchers to work on the foundations of distributed and parallel computing.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://research.cs.aalto.fi/da/jobs/&quot;&gt;https://research.cs.aalto.fi/da/jobs/&lt;/a&gt;&lt;br /&gt;
Email: jukka.suomela@aalto.fi&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2023-05-03 20:30:59 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>TR23-064 |   On the Lower Bound on the Length of Relaxed Locally Decodable Codes | 

	Oded Goldreich</title>
  <guid>https://eccc.weizmann.ac.il/report/2023/064</guid>
  <link>https://eccc.weizmann.ac.il/report/2023/064</link>
  <description>
    We revisit the known proof of the lower bound on the length of relaxed locally decodable codes, providing an arguably simpler exposition that yields a slightly better lower bound for the non-adaptive case and a weaker bound in the general case.

Recall that a locally decodable code is an error correcting code that allows for the recovery of any desired bit in the message based on a constant number of randomly selected bits in the possibly corrupted codeword.
The relaxed version requires correct recovery only in case of actual codewords, while requiring that for strings that are (only) close to the code, with high probability, the local decoder outputs either the correct value or a special failure symbol (but not a wrong value). 

The lower bounds we prove are $n\geq k^{1+\Omega(1/q^2)}$ for the non-adaptive case and $n\geq k^{1+\Omega(1/q^3)}$ for the general case, where $k$ denotes the message length, $n$ denotes the length of the codewords, and $q$ denotes the (constant) number of queries.
  </description>
  <pubDate>2023-05-03 14:52:01 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Questions and Concerns About Google&#39;s Quantum Supremacy Claim</title>
  <guid>http://arxiv.org/abs/2305.01064</guid>
  <link>http://arxiv.org/abs/2305.01064</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kalai_G/0/1/0/all/0/1&quot;&gt;Gil Kalai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rinott_Y/0/1/0/all/0/1&quot;&gt;Yosef Rinott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Shoham_T/0/1/0/all/0/1&quot;&gt;Tomer Shoham&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In October 2019, Nature published a paper [6] describing an experimental work
that was performed at Google. The paper claims to demonstrate quantum
(computational) supremacy on a 53-qubit quantum computer. Since then we have
been involved in a long-term project to study various statistical aspects of
the Google experiment. In [30] we studied Google&#39;s statistical framework that
we found to be very sound and offered some technical improvements. This
document describes three main concerns (based on statistical analysis) about
the Google 2019 experiment. The first concern is that the data do not agree
with Google&#39;s noise model (or any other specific model). The second concern is
that a crucial simple formula for a priori estimation of the fidelity seems to
involve an unexpected independence assumption, and yet it gives very accurate
predictions. The third concern is about statistical properties of the
calibration process.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-03 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Coverability in VASS Revisited: Improving Rackoff&#39;s Bound to Obtain Conditional Optimality</title>
  <guid>http://arxiv.org/abs/2305.01581</guid>
  <link>http://arxiv.org/abs/2305.01581</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kunnemann_M/0/1/0/all/0/1&quot;&gt;Marvin K&amp;#xfc;nnemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazowiecki_F/0/1/0/all/0/1&quot;&gt;Filip Mazowiecki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schutze_L/0/1/0/all/0/1&quot;&gt;Lia Sch&amp;#xfc;tze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinclair_Banks_H/0/1/0/all/0/1&quot;&gt;Henry Sinclair-Banks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wegrzycki_K/0/1/0/all/0/1&quot;&gt;Karol W&amp;#x119;grzycki&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Seminal results establish that the coverability problem for Vector Addition
Systems with States (VASS) is in EXPSPACE (Rackoff, &#39;78) and is EXPSPACE-hard
already under unary encodings (Lipton, &#39;76). More precisely, Rosier and Yen
later utilise Rackoff&#39;s bounding technique to show that if coverability holds
then there is a run of length at most $n^{2^{\mathcal{O}(d \log d)}}$, where
$d$ is the dimension and $n$ is the size of the given unary VASS. Earlier,
Lipton showed that there exist instances of coverability in $d$-dimensional
unary VASS that are only witnessed by runs of length at least
$n^{2^{\Omega(d)}}$. Our first result closes this gap. We improve the upper
bound by removing the twice-exponentiated $\log(d)$ factor, thus matching
Lipton&#39;s lower bound. This closes the corresponding gap for the exact space
required to decide coverability. This also yields a deterministic
$n^{2^{\mathcal{O}(d)}}$-time algorithm for coverability. Our second result is
a matching lower bound, that there does not exist a deterministic
$n^{2^{o(d)}}$-time algorithm, conditioned upon the Exponential Time
Hypothesis.
&lt;/p&gt;
&lt;p&gt;When analysing coverability, a standard proof technique is to consider VASS
with bounded counters. Bounded VASS make for an interesting and popular model
due to strong connections with timed automata. Withal, we study a natural
setting where the counter bound is linear in the size of the VASS. Here the
trivial exhaustive search algorithm runs in $\mathcal{O}(n^{d+1})$-time. We
give evidence to this being near-optimal. We prove that in dimension one this
trivial algorithm is conditionally optimal, by showing that $n^{2-o(1)}$-time
is required under the $k$-cycle hypothesis. In general fixed dimension $d$, we
show that $n^{d-2-o(1)}$-time is required under the 3-uniform hyperclique
hypothesis.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-03 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

</channel>
</rss>
