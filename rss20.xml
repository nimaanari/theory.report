<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>A Moment-Matching Approach to Testable Learning and a New Characterization of Rademacher Complexity</title>
  <guid>http://arxiv.org/abs/2211.13312</guid>
  <link>http://arxiv.org/abs/2211.13312</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gollakota_A/0/1/0/all/0/1&quot;&gt;Aravind Gollakota&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1&quot;&gt;Adam R. Klivans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1&quot;&gt;Pravesh K. Kothari&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A remarkable recent paper by Rubinfeld and Vasilyan (2022) initiated the
study of \emph{testable learning}, where the goal is to replace hard-to-verify
distributional assumptions (such as Gaussianity) with efficiently testable ones
and to require that the learner succeed whenever the unknown distribution
passes the corresponding test. In this model, they gave an efficient algorithm
for learning halfspaces under testable assumptions that are provably satisfied
by Gaussians.
&lt;/p&gt;
&lt;p&gt;In this paper we give a powerful new approach for developing algorithms for
testable learning using tools from moment matching and metric distances in
probability. We obtain efficient testable learners for any concept class that
admits low-degree \emph{sandwiching polynomials}, capturing most important
examples for which we have ordinary agnostic learners. We recover the results
of Rubinfeld and Vasilyan as a corollary of our techniques while achieving
improved, near-optimal sample complexity bounds for a broad range of concept
classes and distributions.
&lt;/p&gt;
&lt;p&gt;Surprisingly, we show that the information-theoretic sample complexity of
testable learning is tightly characterized by the Rademacher complexity of the
concept class, one of the most well-studied measures in statistical learning
theory. In particular, uniform convergence is necessary and sufficient for
testable learning. This leads to a fundamental separation from (ordinary)
distribution-specific agnostic learning, where uniform convergence is
sufficient but not necessary.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>On the Complexity of Counterfactual Reasoning</title>
  <guid>http://arxiv.org/abs/2211.13447</guid>
  <link>http://arxiv.org/abs/2211.13447</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yunqiu Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yizuo Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darwiche_A/0/1/0/all/0/1&quot;&gt;Adnan Darwiche&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the computational complexity of counterfactual reasoning in relation
to the complexity of associational and interventional reasoning on structural
causal models (SCMs). We show that counterfactual reasoning is no harder than
associational or interventional reasoning on fully specified SCMs in the
context of two computational frameworks. The first framework is based on the
notion of treewidth and includes the classical variable elimination and
jointree algorithms. The second framework is based on the more recent and
refined notion of causal treewidth which is directed towards models with
functional dependencies such as SCMs. Our results are constructive and based on
bounding the (causal) treewidth of twin networks -- used in standard
counterfactual reasoning that contemplates two worlds, real and imaginary -- to
the (causal) treewidth of the underlying SCM structure. In particular, we show
that the latter (causal) treewidth is no more than twice the former plus one.
Hence, if associational or interventional reasoning is tractable on a fully
specified SCM then counterfactual reasoning is tractable too. We extend our
results to general counterfactual reasoning that requires contemplating more
than two worlds and discuss applications of our results to counterfactual
reasoning with a partially specified SCM that is coupled with data. We finally
present empirical results that measure the gap between the complexities of
counterfactual reasoning and associational/interventional reasoning on random
SCMs.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Communication Complexity of Inner Product in Symmetric Normed Spaces</title>
  <guid>http://arxiv.org/abs/2211.13473</guid>
  <link>http://arxiv.org/abs/2211.13473</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andoni_A/0/1/0/all/0/1&quot;&gt;Alexandr Andoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1&quot;&gt;Jaros&amp;#x142;aw B&amp;#x142;asiok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filtser_A/0/1/0/all/0/1&quot;&gt;Arnold Filtser&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce and study the communication complexity of computing the inner
product of two vectors, where the input is restricted w.r.t. a norm $N$ on the
space $\mathbb{R}^n$. Here, Alice and Bob hold two vectors $v,u$ such that
$\|v\|_N\le 1$ and $\|u\|_{N^*}\le 1$, where $N^*$ is the dual norm. They want
to compute their inner product $\langle v,u \rangle$ up to an $\varepsilon$
additive term. The problem is denoted by $\mathrm{IP}_N$.
&lt;/p&gt;
&lt;p&gt;We systematically study $\mathrm{IP}_N$, showing the following results:
&lt;/p&gt;
&lt;p&gt;- For any symmetric norm $N$, given $\|v\|_N\le 1$ and $\|u\|_{N^*}\le 1$
there is a randomized protocol for $\mathrm{IP}_N$ using
$\tilde{\mathcal{O}}(\varepsilon^{-6} \log n)$ bits -- we will denote this by
$\mathcal{R}_{\varepsilon,1/3}(\mathrm{IP}_{N}) \leq
\tilde{\mathcal{O}}(\varepsilon^{-6} \log n)$.
&lt;/p&gt;
&lt;p&gt;- One way communication complexity
$\overrightarrow{\mathcal{R}}(\mathrm{IP}_{\ell_p})\leq\mathcal{O}(\varepsilon^{-\max(2,p)}\cdot
\log\frac n\varepsilon)$, and a nearly matching lower bound
$\overrightarrow{\mathcal{R}}(\mathrm{IP}_{\ell_p}) \geq
\Omega(\varepsilon^{-\max(2,p)})$ for $\varepsilon^{-\max(2,p)} \ll n$.
&lt;/p&gt;
&lt;p&gt;- One way communication complexity $\overrightarrow{\mathcal{R}}(N)$ for a
symmetric norm $N$ is governed by embeddings $\ell_\infty^k$ into $N$.
Specifically, while a small distortion embedding easily implies a lower bound
$\Omega(k)$, we show that, conversely, non-existence of such an embedding
implies protocol with communication $k^{\mathcal{O}(\log \log k)} \log^2 n$.
&lt;/p&gt;
&lt;p&gt;- For arbitrary origin symmetric convex polytope $P$, we show
$\mathcal{R}(\mathrm{IP}_{N}) \le\mathcal{O}(\varepsilon^{-2} \log
\mathrm{xc}(P))$, where $N$ is the unique norm for which $P$ is a unit ball,
and $\mathrm{xc}(P)$ is the extension complexity of $P$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Many bounded versions of undecidable problems are NP-hard</title>
  <guid>http://arxiv.org/abs/2211.13532</guid>
  <link>http://arxiv.org/abs/2211.13532</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Klingler_A/0/1/0/all/0/1&quot;&gt;Andreas Klingler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Eyden_M/0/1/0/all/0/1&quot;&gt;Mirte van der Eyden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Stengele_S/0/1/0/all/0/1&quot;&gt;Sebastian Stengele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Reinhart_T/0/1/0/all/0/1&quot;&gt;Tobias Reinhart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Cuevas_G/0/1/0/all/0/1&quot;&gt;Gemma De las Cuevas&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Several physically inspired problems have been proven undecidable; examples
are the spectral gap problem and the membership problem for quantum
correlations. Most of these results rely on reductions from a handful of
undecidable problems, such as the halting problem, the tiling problem, the Post
correspondence problem or the matrix mortality problem. All these problems have
a common property: they have an NP-hard bounded version. This work establishes
a relation between undecidable unbounded problems and their bounded NP-hard
versions. Specifically, we show that NP-hardness of a bounded version follows
easily from the reduction of the unbounded problems. This leads to new and
simpler proofs of the NP-hardness of bounded version of the Post correspondence
problem, the matrix mortality problem, the positivity of matrix product
operators, the reachability problem, the tiling problem, and the ground state
energy problem. This work sheds light on the intractability of problems in
theoretical physics and on the computational consequences of bounding a
parameter.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Parallel Repetition for the GHZ Game: Exponential Decay</title>
  <guid>http://arxiv.org/abs/2211.13741</guid>
  <link>http://arxiv.org/abs/2211.13741</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braverman_M/0/1/0/all/0/1&quot;&gt;Mark Braverman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khot_S/0/1/0/all/0/1&quot;&gt;Subhash Khot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1&quot;&gt;Dor Minzer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that the value of the $n$-fold repeated GHZ game is at most
$2^{-\Omega(n)}$, improving upon the polynomial bound established by Holmgren
and Raz. Our result is established via a reduction to approximate subgroup type
questions from additive combinatorics.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Quantum Adversarial Learning in Emulation of Monte-Carlo Methods for Max-cut Approximation: QAOA is not optimal</title>
  <guid>http://arxiv.org/abs/2211.13767</guid>
  <link>http://arxiv.org/abs/2211.13767</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Unsal_C/0/1/0/all/0/1&quot;&gt;Cem M. Unsal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Brady_L/0/1/0/all/0/1&quot;&gt;Lucas T. Brady&lt;/a&gt;&lt;/p&gt;&lt;p&gt;One of the leading candidates for near-term quantum advantage is the class of
Variational Quantum Algorithms, but these algorithms suffer from classical
difficulty in optimizing the variational parameters as the number of parameters
increases. Therefore, it is important to understand the expressibility and
power of various ans\&quot;atze to produce target states and distributions. To this
end, we apply notions of emulation to Variational Quantum Annealing and the
Quantum Approximate Optimization Algorithm (QAOA) to show that QAOA is
outperformed by variational annealing schedules with equivalent numbers of
parameters. Our Variational Quantum Annealing schedule is based on a novel
polynomial parameterization that can be optimized in a similar gradient-free
way as QAOA, using the same physical ingredients. In order to compare the
performance of ans\&quot;atze types, we have developed statistical notions of
Monte-Carlo methods. Monte-Carlo methods are computer programs that generate
random variables that approximate a target number that is computationally hard
to calculate exactly. While the most well-known Monte-Carlo method is
Monte-Carlo integration (e.g. Diffusion Monte-Carlo or path-integral quantum
Monte-Carlo), QAOA is itself a Monte-Carlo method that finds good solutions to
NP-complete problems such as Max-cut. We apply these statistical Monte-Carlo
notions to further elucidate the theoretical framework around these quantum
algorithms.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Approximating the chromatic polynomial is as hard as computing it exactly</title>
  <guid>http://arxiv.org/abs/2211.13790</guid>
  <link>http://arxiv.org/abs/2211.13790</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bencs_F/0/1/0/all/0/1&quot;&gt;Ferenc Bencs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huijben_J/0/1/0/all/0/1&quot;&gt;Jeroen Huijben&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regts_G/0/1/0/all/0/1&quot;&gt;Guus Regts&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that for any non-real algebraic number $q$ such that $|q-1|&amp;gt;1$ or
$\Re(q)&amp;gt;\frac{3}{2}$ it is \textsc{\#P}-hard to compute a multiplicative (resp.
additive) approximation to the absolute value (resp. argument) of the chromatic
polynomial evaluated at $q$ on planar graphs. This implies
\textsc{\#P}-hardness for all non-real algebraic $q$ on the family of all
graphs. We moreover prove several hardness results for $q$ such that $|q-1|\leq
1$.
&lt;/p&gt;
&lt;p&gt;Our hardness results are obtained by showing that a polynomial time algorithm
for approximately computing the chromatic polynomial of a planar graph at
non-real algebraic $q$ (satisfying some properties) leads to a polynomial time
algorithm for \emph{exactly} computing it, which is known to be hard by a
result of Vertigan. Many of our results extend in fact to the more general
partition function of the random cluster model, a well known reparametrization
of the Tutte polynomial.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Improved Elekes-Szab\&#39;o type estimates using proximity</title>
  <guid>http://arxiv.org/abs/2211.13294</guid>
  <link>http://arxiv.org/abs/2211.13294</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Solymosi_J/0/1/0/all/0/1&quot;&gt;Jozsef Solymosi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zahl_J/0/1/0/all/0/1&quot;&gt;Joshua Zahl&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove a new Elekes-Szab\&#39;o type estimate on the size of the intersection
of a Cartesian product $A\times B\times C$ with an algebraic surface $\{f=0\}$
over the reals. In particular, if $A,B,C$ are sets of $N$ real numbers and $f$
is a trivariate polynomial, then either $f$ has a special form that encodes
additive group structure (for example $f(x,y,x) = x + y - z$), or $A \times
B\times C \cap\{f=0\}$ has cardinality $O(N^{12/7})$. This is an improvement
over the previously bound $O(N^{11/6})$. We also prove an asymmetric version of
our main result, which yields an Elekes-Ronyai type expanding polynomial
estimate with exponent $3/2$. This has applications to questions in
combinatorial geometry related to the Erd\H{o}s distinct distances problem.
&lt;/p&gt;
&lt;p&gt;Like previous approaches to the problem, we rephrase the question as a $L^2$
estimate, which can be analyzed by counting additive quadruples. The latter
problem can be recast as an incidence problem involving points and curves in
the plane. The new idea in our proof is that we use the order structure of the
reals to restrict attention to a smaller collection of proximate additive
quadruples.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Reduction Algorithms for Persistence Diagrams of Networks: CoralTDA and PrunIT</title>
  <guid>http://arxiv.org/abs/2211.13708</guid>
  <link>http://arxiv.org/abs/2211.13708</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akcora_C/0/1/0/all/0/1&quot;&gt;Cuneyt Gurcan Akcora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kantarcioglu_M/0/1/0/all/0/1&quot;&gt;Murat Kantarcioglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gel_Y/0/1/0/all/0/1&quot;&gt;Yulia R. Gel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coskunuzer_B/0/1/0/all/0/1&quot;&gt;Baris Coskunuzer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Topological data analysis (TDA) delivers invaluable and complementary
information on the intrinsic properties of data inaccessible to conventional
methods. However, high computational costs remain the primary roadblock
hindering the successful application of TDA in real-world studies, particularly
with machine learning on large complex networks.
&lt;/p&gt;
&lt;p&gt;Indeed, most modern networks such as citation, blockchain, and online social
networks often have hundreds of thousands of vertices, making the application
of existing TDA methods infeasible. We develop two new, remarkably simple but
effective algorithms to compute the exact persistence diagrams of large graphs
to address this major TDA limitation. First, we prove that $(k+1)$-core of a
graph $\mathcal{G}$ suffices to compute its $k^{th}$ persistence diagram,
$PD_k(\mathcal{G})$. Second, we introduce a pruning algorithm for graphs to
compute their persistence diagrams by removing the dominated vertices. Our
experiments on large networks show that our novel approach can achieve
computational gains up to 95%.
&lt;/p&gt;
&lt;p&gt;The developed framework provides the first bridge between the graph theory
and TDA, with applications in machine learning of large complex networks. Our
implementation is available at
https://github.com/cakcora/PersistentHomologyWithCoralPrunit
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Space-efficient RLZ-to-LZ77 conversion</title>
  <guid>http://arxiv.org/abs/2211.13254</guid>
  <link>http://arxiv.org/abs/2211.13254</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1&quot;&gt;Travis Gagie&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Consider a text $T [1..n]$ prefixed by a reference sequence $R = T
[1..\ell]$. We show how, given $R$ and the $z&#39;$-phrase relative Lempel-Ziv
parse of $T [\ell + 1..n]$ with respect to $R$, we can build the LZ77 parse of
$T$ in $n\,\mathrm{polylog} (n)$ time and $O (\ell + z&#39;)$ total space.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Learning and Testing Latent-Tree Ising Models Efficiently</title>
  <guid>http://arxiv.org/abs/2211.13291</guid>
  <link>http://arxiv.org/abs/2211.13291</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1&quot;&gt;Davin Choo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dagan_Y/0/1/0/all/0/1&quot;&gt;Yuval Dagan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1&quot;&gt;Constantinos Daskalakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kandiros_A/0/1/0/all/0/1&quot;&gt;Anthimos Vardis Kandiros&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We provide time- and sample-efficient algorithms for learning and testing
latent-tree Ising models, i.e. Ising models that may only be observed at their
leaf nodes. On the learning side, we obtain efficient algorithms for learning a
tree-structured Ising model whose leaf node distribution is close in Total
Variation Distance, improving on the results of prior work. On the testing
side, we provide an efficient algorithm with fewer samples for testing whether
two latent-tree Ising models have leaf-node distributions that are close or far
in Total Variation distance. We obtain our algorithms by showing novel
localization results for the total variation distance between the leaf-node
distributions of tree-structured Ising models, in terms of their marginals on
pairs of leaves.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A fast and simple $O (z \log n)$-space index for finding approximately longest common substrings</title>
  <guid>http://arxiv.org/abs/2211.13434</guid>
  <link>http://arxiv.org/abs/2211.13434</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fagan_N/0/1/0/all/0/1&quot;&gt;Nick Fagan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Jorge Hermo Gonz&amp;#xe1;lez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1&quot;&gt;Travis Gagie&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We describe how, given a text $T [1..n]$ and a positive constant $\epsilon$,
we can build a simple $O (z \log n)$-space index, where $z$ is the number of
phrases in the LZ77 parse of $T$, such that later, given a pattern $P [1..m]$,
in $O (m \log \log z + \mathrm{polylog} (m + z))$ time and with high
probability we can find a substring of $P$ that occurs in $T$ and whose length
is at least a $(1 - \epsilon)$-fraction of the length of a longest common
substring of $P$ and $T$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Differentially Private Heatmaps</title>
  <guid>http://arxiv.org/abs/2211.13454</guid>
  <link>http://arxiv.org/abs/2211.13454</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1&quot;&gt;Badih Ghazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Junfeng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohlhoff_K/0/1/0/all/0/1&quot;&gt;Kai Kohlhoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Ravi Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1&quot;&gt;Pasin Manurangsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Navalpakkam_V/0/1/0/all/0/1&quot;&gt;Vidhya Navalpakkam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valliappan_N/0/1/0/all/0/1&quot;&gt;Nachiappan Valliappan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the task of producing heatmaps from users&#39; aggregated data while
protecting their privacy. We give a differentially private (DP) algorithm for
this task and demonstrate its advantages over previous algorithms on real-world
datasets.
&lt;/p&gt;
&lt;p&gt;Our core algorithmic primitive is a DP procedure that takes in a set of
distributions and produces an output that is close in Earth Mover&#39;s Distance to
the average of the inputs. We prove theoretical bounds on the error of our
algorithm under a certain sparsity assumption and that these are near-optimal.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Estimation of Similarity between DNA Sequences and Its Graphical Representation</title>
  <guid>http://arxiv.org/abs/2211.13462</guid>
  <link>http://arxiv.org/abs/2211.13462</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mondal_P/0/1/0/all/0/1&quot;&gt;Probir Mondal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Bioinformatics, which is now a well known field of study, originated in the
context of biological sequence analysis. Recently graphical representation
takes place for the research on DNA sequence. Research in biological sequence
is mainly based on the function and its structure. Bioinformatics finds wide
range of applications specifically in the domain of molecular biology which
focuses on the analysis of molecules viz. DNA, RNA, Protein etc. In this
review, we mainly deal with the similarity analysis between sequences and
graphical representation of DNA sequence.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Towards Better Bounds for Finding Quasi-Identifiers</title>
  <guid>http://arxiv.org/abs/2211.13882</guid>
  <link>http://arxiv.org/abs/2211.13882</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hildebrant_R/0/1/0/all/0/1&quot;&gt;Ryan Hildebrant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc-Tung Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ta_D/0/1/0/all/0/1&quot;&gt;Duy-Hoang Ta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vu_H/0/1/0/all/0/1&quot;&gt;Hoa T. Vu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We revisit the problem of finding small $\epsilon$-separation keys introduced
by Motwani and Xu (VLDB 07). In this problem, the input is $m$-dimensional
tuples $x_1,x_2,\ldots,x_n $. The goal is to find a small subset of coordinates
that separates at least $(1-\epsilon){n \choose 2}$ pairs of tuples. They
provided a fast algorithm that runs on $\Theta(m/\epsilon)$ tuples sampled
uniformly at random. We show that the sample size can be improved to
$\Theta(m/\sqrt{\epsilon})$. Our algorithm also enjoys a faster running time.
To obtain this result, we provide upper and lower bounds on the sample size to
solve the following decision problem. Given a subset of coordinates $A$, reject
if $A$ separates fewer than $(1-\epsilon){n \choose 2}$ pairs, and accept if
$A$ separates all pairs. The algorithm must be correct with probability at
least $1-\delta$ for all $A$. We show that for algorithms based on sampling:
&lt;/p&gt;
&lt;p&gt;- $\Theta(m/\sqrt{\epsilon})$ samples are sufficient and necessary so that
$\delta \leq e^{-m}$ and
&lt;/p&gt;
&lt;p&gt;- $\Omega(\sqrt{\frac{\log m}{\epsilon}})$ samples are necessary so that
$\delta$ is a constant.
&lt;/p&gt;
&lt;p&gt;Our analysis is based on a constrained version of the balls-into-bins
problem. We believe our analysis may be of independent interest. We also study
a related problem that asks for the following sketching algorithm: with given
parameters $\alpha,k$ and $\epsilon$, the algorithm takes a subset of
coordinates $A$ of size at most $k$ and returns an estimate of the number of
unseparated pairs in $A$ up to a $(1\pm\epsilon)$ factor if it is at least
$\alpha {n \choose 2}$. We show that even for constant $\alpha$ and success
probability, such a sketching algorithm must use $\Omega(mk \log
\epsilon^{-1})$ bits of space; on the other hand, uniform sampling yields a
sketch of size $\Theta(\frac{mk \log m}{\alpha \epsilon^2})$ for this purpose.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Synthesis Cost-Optimal Targeted Mutant Protein Libraries</title>
  <guid>http://arxiv.org/abs/2211.13898</guid>
  <link>http://arxiv.org/abs/2211.13898</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papamichail_D/0/1/0/all/0/1&quot;&gt;Dimitris Papamichail&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Febinger_M/0/1/0/all/0/1&quot;&gt;Madeline Febinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Almeda_S/0/1/0/all/0/1&quot;&gt;Shm Almeda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papamichail_G/0/1/0/all/0/1&quot;&gt;Georgios Papamichail&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Protein variant libraries produced by site-directed mutagenesis are a useful
tool utilized by protein engineers to explore variants with potentially
improved properties, such as activity and stability. These libraries are
commonly built by selecting residue positions and alternative beneficial
mutations for each position. All possible combinations are then constructed and
screened, by incorporating degenerate codons at mutation sites. These
degenerate codons often encode additional unwanted amino acids or even STOP
codons. Our study aims to take advantage of annealing based recombination of
oligonucleotides during synthesis and utilize multiple degenerate codons per
mutation site to produce targeted protein libraries devoid of unwanted
variants. Toward this goal we created an algorithm to calculate the minimum
number of degenerate codons necessary to specify any given amino acid set, and
a dynamic programming method that uses this algorithm to optimally partition a
DNA target sequence with degeneracies into overlapping oligonucleotides, such
that the total cost of synthesis of the target mutant protein library is
minimized. Computational experiments show that, for a modest increase in DNA
synthesis costs, beneficial variant yields in produced mutant libraries are
increased by orders of magnitude, an effect particularly pronounced in large
combinatorial libraries.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Combining Constructive and Perturbative Deep Learning Algorithms for the Capacitated Vehicle Routing Problem</title>
  <guid>http://arxiv.org/abs/2211.13922</guid>
  <link>http://arxiv.org/abs/2211.13922</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Torres_R/0/1/0/all/0/1&quot;&gt;Roberto Garc&amp;#xed;a-Torres&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macias_Infante_A/0/1/0/all/0/1&quot;&gt;Alitzel Adriana Macias-Infante&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conant_Pablos_S/0/1/0/all/0/1&quot;&gt;Santiago Enrique Conant-Pablos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortiz_Bayliss_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Carlos Ortiz-Bayliss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Terashima_Marin_H/0/1/0/all/0/1&quot;&gt;Hugo Terashima-Mar&amp;#xed;n&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Capacitated Vehicle Routing Problem is a well-known NP-hard problem that
poses the challenge of finding the optimal route of a vehicle delivering
products to multiple locations. Recently, new efforts have emerged to create
constructive and perturbative heuristics to tackle this problem using Deep
Learning. In this paper, we join these efforts to develop the Combined Deep
Constructor and Perturbator, which combines two powerful constructive and
perturbative Deep Learning-based heuristics, using attention mechanisms at
their core. Furthermore, we improve the Attention Model-Dynamic for the
Capacitated Vehicle Routing Problem by proposing a memory-efficient algorithm
that reduces its memory complexity by a factor of the number of nodes. Our
method shows promising results. It demonstrates a cost improvement in common
datasets when compared against other multiple Deep Learning methods. It also
obtains close results to the state-of-the art heuristics from the Operations
Research field. Additionally, the proposed memory efficient algorithm for the
Attention Model-Dynamic model enables its use in problem instances with more
than 100 nodes.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>TR22-170 |  The Complexity of the Shortest Vector Problem | 

	Huck Bennett</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/170</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/170</link>
  <description>
    Computational problems on point lattices play a central role in many areas of computer science including integer programming, coding theory, cryptanalysis, and especially the design of secure cryptosystems. In this survey, we present known results and open questions related to the complexity of the most important of these problems, the Shortest Vector Problem (SVP).
  </description>
  <pubDate>2022-11-27 05:46:17 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Postdoc at University of Toronto (apply by December 15, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/26/postdoc-at-university-of-toronto-apply-by-december-15-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/26/postdoc-at-university-of-toronto-apply-by-december-15-2022/</link>
  <description>
    &lt;p&gt;The theory group at the University of Toronto anticipates up to three postdoctoral positions beginning September 2023. We seek candidates from all areas of theoretical computer science including algorithms, complexity theory, cryptography, differential privacy, distributed computing, graph theory, quantum computing, and theoretical aspects of machine learning.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.cs.toronto.edu/theory/positions.html&quot;&gt;https://www.cs.toronto.edu/theory/positions.html&lt;/a&gt;&lt;br /&gt;
Email: sachdeva@cs.toronto.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-26 17:07:36 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>TR22-169 |  Extractors for Images of Varieties | 

	Zeyu Guo, 

	Ben Lee Volk, 

	Akhil Jalan, 

	David Zuckerman</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/169</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/169</link>
  <description>
    We construct explicit deterministic extractors for polynomial images of varieties, that is, distributions sampled by applying a low-degree polynomial map $f : \mathbb{F}_q^r \to \mathbb{F}_q^n$ to an element sampled uniformly at random from a $k$-dimensional variety $V \subseteq \mathbb{F}_q^r$. This class of sources generalizes both polynomial sources, studied by Dvir, Gabizon and Wigderson (FOCS 2007, Comput. Complex. 2009), and variety sources, studied by Dvir (CCC 2009, Comput. Complex. 2012).

  Assuming certain natural non-degeneracy conditions on the map $f$ and the variety $V$, which in particular ensure that the source has enough min-entropy, we extract almost all the min-entropy of the distribution. Unlike the Dvir-Gabizon-Wigderson and Dvir results, our construction works over large enough finite fields of arbitrary characteristic. One key part of our construction is an improved deterministic rank extractor for varieties. As a by-product, we obtain explicit Noether normalization lemmas for affine varieties and affine algebras.

  Additionally, we generalize a construction of affine extractors with exponentially small error due to Bourgain, Dvir and Leeman (Comput. Complex. 2016) by extending it to all finite prime fields of quasipolynomial size.
  </description>
  <pubDate>2022-11-26 12:06:05 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Postdoc at National University of Singapore (apply by February 15, 2023)</title>
  <guid>http://cstheory-jobs.org/2022/11/24/postdoc-at-national-university-of-singapore-apply-by-february-15-2023/</guid>
  <link>https://cstheory-jobs.org/2022/11/24/postdoc-at-national-university-of-singapore-apply-by-february-15-2023/</link>
  <description>
    &lt;p&gt;Postdoc positions hosted by Prashant Nalini Vasudevan. Looking for candidates with a strong background in theory interested in the foundations of cryptography, information-theoretic cryptography, or related areas of complexity theory and algorithms. See website for more details.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.comp.nus.edu.sg/~prashant/ads.html&quot;&gt;https://www.comp.nus.edu.sg/~prashant/ads.html&lt;/a&gt;&lt;br /&gt;
Email: prashant@comp.nus.edu.sg&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 11:49:05 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>TR22-168 |  A Proof of the Generalized Union-Closed Set Conjecture assuming the Union-Closed Set Conjecture | 

	Zubayir Kazi</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/168</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/168</link>
  <description>
    Abstract The Union Closed Set Conjecture states that if a set system X\subseteq\mathcal{P}([n]) is closed under pairwise unions, then there exists a\in[n] in at least half of the sets of X. We show that there is a very natural generalization of the union closed set conjecture which gives a lower bound for k-set subsets of [n]. This a stronger version of a Conjecture of (Nagel, 2022). We then prove the Conjecture conditional on the Union Closed Set Conjecture using invariants of Union-Closed sets. Additionally, we prove that there exists a k-set in .38^{k}|F| sets of a union closed set X for every n\geq k&amp;gt;0 using the recent improvements in (Gilmer, 2022) and (Alweiss et al, 2022). We explain why our result suggests a lack of sharpness of the original conjecture.
  </description>
  <pubDate>2022-11-24 10:14:14 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Two Round HotStuff</title>
  <guid>https://decentralizedthoughts.github.io/2022-11-24-two-round-HS/</guid>
  <link>https://decentralizedthoughts.github.io/2022-11-24-two-round-HS/</link>
  <description>
    In the first part of this post we describe a single-shot variation of Two Round HotStuff (see the HotStuff v1 paper) using Locked Broadcast that follows a similar path as our previous post on Paxos and Linear PBFT. In the second part, we describe a fully pipelined multi-shot State Machine...
  </description>
  <pubDate>2022-11-24 09:00:00 UTC</pubDate>
  <author>Decentralized Thoughts</author>
</item>

<item>
  <title>TCS+ talk: Wednesday, November 30 â€” Nicole Wein, DIMACS</title>
  <guid>http://tcsplus.wordpress.com/?p=649</guid>
  <link>https://tcsplus.wordpress.com/2022/11/23/tcs-talk-wednesday-november-30-nicole-wein-dimacs/</link>
  <description>
    &lt;p&gt;&lt;/p&gt;


&lt;p&gt;The next TCS+ talk will take place this coming Wednesday, November 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). &lt;a href=&quot;http://people.csail.mit.edu/nwein/&quot;&gt;&lt;strong&gt;Nicole Wein&lt;/strong&gt;&lt;/a&gt; from DIMACS will speak about &amp;#8220;&lt;em&gt;Online List Labeling: Breaking the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Clog%5E2+n&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Clog%5E2+n&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5E2+n&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;log^2 n&quot; class=&quot;latex&quot; /&gt; Barrier&lt;/em&gt;&amp;#8221; (abstract below).&lt;/p&gt;
&lt;p&gt;You can reserve a spot as an individual or a group to join us live by signing up on &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/next-tcs-talk&quot;&gt;the online form&lt;/a&gt;. Registration is &lt;em&gt;not&lt;/em&gt; required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/past-talks&quot;&gt;on our website&lt;/a&gt; afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/suggest-a-talk&quot;&gt;suggest&lt;/a&gt; a possible topic or speaker, please see &lt;a href=&quot;https://sites.google.com/view/tcsplus/&quot;&gt;the website&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;Abstract: The online list labeling problem is a basic primitive in data structures. The goal is to store a dynamically-changing set of n items in an array of m slots, while keeping the elements in sorted order. To do so, some items may need to be moved over time, and the goal is to minimize the number of items moved per insertion/deletion. When &lt;img src=&quot;https://s0.wp.com/latex.php?latex=m+%3D+Cn&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=m+%3D+Cn&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m+%3D+Cn&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;m = Cn&quot; class=&quot;latex&quot; /&gt; for some constant &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%3E1&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%3E1&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3E1&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C&amp;gt;1&quot; class=&quot;latex&quot; /&gt;, an upper bound of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%28%5Clog%5E2+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%28%5Clog%5E2+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28%5Clog%5E2+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(&amp;#92;log^2 n)&quot; class=&quot;latex&quot; /&gt; items moved per insertion/deletion has been known since 1981. There is a matching lower bound for deterministic algorithms, but for randomized algorithms, the best known lower bound is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;Omega(&amp;#92;log n)&quot; class=&quot;latex&quot; /&gt;, leaving a gap between upper and lower bounds. We improve the upper bound, providing a randomized data structure with expected &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%28%5Clog%5E%7B3%2F2%7D+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%28%5Clog%5E%7B3%2F2%7D+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28%5Clog%5E%7B3%2F2%7D+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(&amp;#92;log^{3/2} n)&quot; class=&quot;latex&quot; /&gt; items moved per insertion/deletion.&lt;/p&gt;
&lt;p&gt;Joint work with Michael Bender, Alexander Conway, Martin Farach-Colton, Hanna Komlos, and William Kuszmaul&lt;/p&gt;
&lt;/blockquote&gt;&lt;p class=&quot;authors&quot;&gt;By plustcs&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 04:20:07 UTC</pubDate>
  <author>TCS+ Seminar Series</author>
</item>

<item>
  <title>Shortest Odd Paths in Conservative Graphs: Connections and Complexity</title>
  <guid>http://arxiv.org/abs/2211.12862</guid>
  <link>http://arxiv.org/abs/2211.12862</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlotter_I/0/1/0/all/0/1&quot;&gt;Ildik&amp;#xf3; Schlotter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sebo_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe1;s Seb&amp;#x151;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present some reductions between optimization problems for undirected
conservative graphs, that is, edge-weighted graphs without negative cycles. We
settle the complexity of some of them, and exhibit some remaining challenges.
Our key result is that the shortest odd path problem between two given
vertices, and its variants, such as the shortest odd cycle problem through a
given vertex, turn out to be NP-hard, deciding a long-standing question by
Lov\&#39;asz (Open Problem 27 in Schrijver&#39;s book, 2003), in the negative. The
complexity of finding a shortest odd cycle for conservative weights or of
finding an odd $T$-join of minimum cardinality remains open. We finally relate
these problems to relevant, solved or hopeful variants.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The Stochastic Arrival Problem</title>
  <guid>http://arxiv.org/abs/2211.12982</guid>
  <link>http://arxiv.org/abs/2211.12982</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webster_T/0/1/0/all/0/1&quot;&gt;Thomas Webster&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study a new modification of the Arrival problem, which allows for nodes
that exhibit random as well as controlled behaviour, in addition to switching
nodes. We study the computational complexity of these extensions, building on
existing work on Reachability Switching Games. In particular, we show for
versions of the arrival problem involving just switching and random nodes it is
\PP{}-hard to decide if their value is greater than a half and we give a PSPACE
decision algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>On the Complexity of Finding a Diverse and Representative Committee using a Monotone, Separable Positional Multiwinner Voting Rule</title>
  <guid>http://arxiv.org/abs/2211.13217</guid>
  <link>http://arxiv.org/abs/2211.13217</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Relia_K/0/1/0/all/0/1&quot;&gt;Kunal Relia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Fairness in multiwinner elections, a growing line of research in
computational social choice, primarily concerns the use of constraints to
ensure fairness. Recent work proposed a model to find a diverse \emph{and}
representative committee and studied the model&#39;s computational aspects.
However, the work gave complexity results under major assumptions on how the
candidates and the voters are grouped. Here, we close this gap and classify the
complexity of finding a diverse and representative committee using a monotone,
separable positional multiwinner voting rule, conditioned \emph{only} on the
assumption that P $\neq$ NP.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Deterministic Approximation Algorithms for Volumes of Spectrahedra</title>
  <guid>http://arxiv.org/abs/2211.12541</guid>
  <link>http://arxiv.org/abs/2211.12541</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dogan_M/0/1/0/all/0/1&quot;&gt;Mahmut Levent Do&amp;#x11f;an&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leake_J/0/1/0/all/0/1&quot;&gt;Jonathan Leake&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravichandran_M/0/1/0/all/0/1&quot;&gt;Mohan Ravichandran&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give a method for computing asymptotic formulas and approximations for the
volumes of spectrahedra, based on the maximum-entropy principle from
statistical physics. The method gives an approximate volume formula based on a
single convex optimization problem of minimizing $-\log \det P$ over the
spectrahedron. Spectrahedra can be described as affine slices of the convex
cone of positive semi-definite (PSD) matrices, and the method yields efficient
deterministic approximation algorithms and asymptotic formulas whenever the
number of affine constraints is sufficiently dominated by the dimension of the
PSD cone.
&lt;/p&gt;
&lt;p&gt;Our approach is inspired by the work of Barvinok and Hartigan who used an
analogous framework for approximately computing volumes of polytopes.
Spectrahedra, however, possess a remarkable feature not shared by polytopes, a
new fact that we also prove: central sections of the set of density matrices
(the quantum version of the simplex) all have asymptotically the same volume.
This allows for very general approximation algorithms, which apply to large
classes of naturally occurring spectrahedra.
&lt;/p&gt;
&lt;p&gt;We give two main applications of this method. First, we apply this method to
what we call the &quot;multi-way Birkhoff spectrahedron&quot; and obtain an explicit
asymptotic formula for its volume. This spectrahedron is the set of quantum
states with maximal entanglement (i.e., the quantum states having univariant
quantum marginals equal to the identity matrix) and is the quantum analog of
the multi-way Birkhoff polytope. Second, we apply this method to explicitly
compute the asymptotic volume of central sections of the set of density
matrices.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Complexity Framework For Forbidden Subgraphs</title>
  <guid>http://arxiv.org/abs/2211.12887</guid>
  <link>http://arxiv.org/abs/2211.12887</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Johnson_M/0/1/0/all/0/1&quot;&gt;Matthew Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Martin_B/0/1/0/all/0/1&quot;&gt;Barnaby Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Oostveen_J/0/1/0/all/0/1&quot;&gt;Jelle J. Oostveen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pandey_S/0/1/0/all/0/1&quot;&gt;Sukanya Pandey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Paulusma_D/0/1/0/all/0/1&quot;&gt;Dani&amp;#xeb;l Paulusma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Smith_S/0/1/0/all/0/1&quot;&gt;Siani Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Leeuwen_E/0/1/0/all/0/1&quot;&gt;Erik Jan van Leeuwen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For any finite set $\mathcal{H} = \{H_1,\ldots,H_p\}$ of graphs, a graph is
$\mathcal{H}$-subgraph-free if it does not contain any of $H_1,\ldots,H_p$ as a
subgraph. We propose a meta-theorem to classify if problems are &quot;efficiently
solvable&quot; or &quot;computationally hard&quot; on $\mathcal{H}$-subgraph-free graphs. The
conditions are that the problem should be efficiently solvable on graphs of
bounded treewidth, computationally hard on subcubic graphs, and computational
hardness is preserved under edge subdivision. We show that all problems
satisfying these conditions are efficiently solvable if $\mathcal{H}$ contains
a disjoint union of one or more paths and subdivided claws, and are
computationally hard otherwise. To illustrate the broad applicability of our
framework, we study covering or packing problems, network design problems and
width parameter problems. We apply the framework to obtain a dichotomy between
polynomial-time solvability and NP-completeness. For other problems we obtain a
dichotomy between almost-linear-time solvability and having no
subquadratic-time algorithm (conditioned on some hardness hypotheses). In this
way we strengthen results in the literature.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Quantum-Classical Tradeoffs in the Random Oracle Model</title>
  <guid>http://arxiv.org/abs/2211.12954</guid>
  <link>http://arxiv.org/abs/2211.12954</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hamoudi_Y/0/1/0/all/0/1&quot;&gt;Yassine Hamoudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qipeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sinha_M/0/1/0/all/0/1&quot;&gt;Makrand Sinha&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study tradeoffs between quantum and classical queries for hybrid
algorithms that have black-box access to a random oracle. Although there are
several established techniques for proving query lower bounds for both quantum
and classical algorithms, there is no such widely applicable technique for
hybrid algorithms and the optimal tradeoffs for many fundamental problems are
still unknown $\unicode{x2013}$ an optimal tradeoff for the search problem was
only shown recently by Rosmanis, although not in the random oracle model. For
another fundamental problem, collision finding, the optimal tradeoff was not
known.
&lt;/p&gt;
&lt;p&gt;In this work, we develop a framework for recording a query transcript for
quantum-classical algorithms that represents the knowledge gained by the
algorithm. The main feature of this framework is to allow us to record queries
in two incompatible bases $\unicode{x2013}$ classical queries in the standard
basis and quantum queries in the Fourier basis $\unicode{x2013}$ in a
consistent way. We call the framework the hybrid compressed oracle as it
naturally interpolates between the classical way of recording queries and the
compressed oracle framework of Zhandry for recording quantum queries. We
demonstrate its applicability by giving a simpler proof of the optimal
quantum-classical tradeoff for search and by showing an optimal tradeoff for
collision finding.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Scalable and Effective Conductance-based Graph Clustering</title>
  <guid>http://arxiv.org/abs/2211.12511</guid>
  <link>http://arxiv.org/abs/2211.12511</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Longlong Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Rong-Hua Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_T/0/1/0/all/0/1&quot;&gt;Tao Jia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Conductance-based graph clustering has been recognized as a fundamental
operator in numerous graph analysis applications. Despite the significant
success of conductance-based graph clustering, existing algorithms are either
hard to obtain satisfactory clustering qualities, or have high time and space
complexity to achieve provable clustering qualities. To overcome these
limitations, we devise a powerful \textit{peeling}-based graph clustering
framework \textit{PCon}. We show that many existing solutions can be reduced to
our framework. Namely, they first define a score function for each vertex, then
iteratively remove the vertex with the smallest score. Finally, they output the
result with the smallest conductance during the peeling process. Based on our
framework, we propose two novel algorithms \textit{PCon\_core} and
\emph{PCon\_de} with linear time and space complexity, which can efficiently
and effectively identify clusters from massive graphs with more than a few
billion edges. Surprisingly, we prove that \emph{PCon\_de} can identify
clusters with near-constant approximation ratio, resulting in an important
theoretical improvement over the well-known quadratic Cheeger bound. Empirical
results on real-life and synthetic datasets show that our algorithms can
achieve 5$\sim$42 times speedup with a high clustering accuracy, while using
1.4$\sim$7.8 times less memory than the baseline algorithms.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>SAH: Shifting-aware Asymmetric Hashing for Reverse $k$-Maximum Inner Product Search</title>
  <guid>http://arxiv.org/abs/2211.12751</guid>
  <link>http://arxiv.org/abs/2211.12751</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qiang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tung_A/0/1/0/all/0/1&quot;&gt;Anthony K. H. Tung&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper investigates a new yet challenging problem called Reverse
$k$-Maximum Inner Product Search (R$k$MIPS). Given a query (item) vector, a set
of item vectors, and a set of user vectors, the problem of R$k$MIPS aims to
find a set of user vectors whose inner products with the query vector are one
of the $k$ largest among the query and item vectors. We propose the first
subquadratic-time algorithm, i.e., Shifting-aware Asymmetric Hashing (SAH), to
tackle the R$k$MIPS problem. To speed up the Maximum Inner Product Search
(MIPS) on item vectors, we design a shifting-invariant asymmetric
transformation and develop a novel sublinear-time Shifting-Aware Asymmetric
Locality Sensitive Hashing (SA-ALSH) scheme. Furthermore, we devise a new
blocking strategy based on the Cone-Tree to effectively prune user vectors (in
a batch). We prove that SAH achieves a theoretical guarantee for solving the
RMIPS problem. Experimental results on five real-world datasets show that SAH
runs 4$\sim$8$\times$ faster than the state-of-the-art methods for R$k$MIPS
while achieving F1-scores of over 90\%. The code is available at
\url{https://github.com/HuangQiang/SAH}.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Worst-Case to Expander-Case Reductions</title>
  <guid>http://arxiv.org/abs/2211.12833</guid>
  <link>http://arxiv.org/abs/2211.12833</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abboud_A/0/1/0/all/0/1&quot;&gt;Amir Abboud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wallheimer_N/0/1/0/all/0/1&quot;&gt;Nathan Wallheimer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In recent years, the expander decomposition method was used to develop many
graph algorithms, resulting in major improvements to longstanding complexity
barriers. This powerful hammer has led the community to (1) believe that most
problems are as easy on worst-case graphs as they are on expanders, and (2)
suspect that expander decompositions are the key to breaking the remaining
longstanding barriers in fine-grained complexity.
&lt;/p&gt;
&lt;p&gt;We set out to investigate the extent to which these two things are true (and
for which problems). Towards this end, we put forth the concept of worst-case
to expander-case self-reductions. We design a collection of such reductions for
fundamental graph problems, verifying belief (1) for them. The list includes
$k$-Clique, $4$-Cycle, Maximum Cardinality Matching, Vertex-Cover, and Minimum
Dominating Set. Interestingly, for most (but not all) of these problems the
proof is via a simple gadget reduction, not via expander decompositions,
showing that this hammer is effectively useless against the problem and
contradicting (2).
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Branch-and-Bound with Barrier: Dominance and Suboptimality Detection for DD-Based Branch-and-Bound</title>
  <guid>http://arxiv.org/abs/2211.13118</guid>
  <link>http://arxiv.org/abs/2211.13118</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coppe_V/0/1/0/all/0/1&quot;&gt;Vianney Copp&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gillard_X/0/1/0/all/0/1&quot;&gt;Xavier Gillard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaus_P/0/1/0/all/0/1&quot;&gt;Pierre Schaus&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The branch-and-bound algorithm based on decision diagrams introduced by
Bergman et al. in 2016 is a framework for solving discrete optimization
problems with a dynamic programming formulation. It works by compiling a series
of bounded-width decision diagrams that can provide lower and upper bounds for
any given subproblem. Eventually, every part of the search space will be either
explored or pruned by the algorithm, thus proving optimality. This paper
presents new ingredients to speed up the search by exploiting the structure of
dynamic programming models. The key idea is to prevent the repeated exploration
of nodes corresponding to the same dynamic programming states by storing and
querying thresholds in a data structure called the Barrier. These thresholds
are based on dominance relations between partial solutions previously found.
They can be further strengthened by integrating the filtering techniques
introduced by Gillard et al. in 2021. Computational experiments show that the
pruning brought by the Barrier allows to significantly reduce the number of
nodes expanded by the algorithm. This results in more benchmark instances of
difficult optimization problems being solved in less time while using narrower
decision diagrams.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>2023 Summer Research Intern at Adobe Research at Adobe Research (apply by February 1, 2023)</title>
  <guid>http://cstheory-jobs.org/2022/11/23/2023-summer-research-intern-at-adobe-research-at-adobe-research-apply-by-february-1-2023/</guid>
  <link>https://cstheory-jobs.org/2022/11/23/2023-summer-research-intern-at-adobe-research-at-adobe-research-apply-by-february-1-2023/</link>
  <description>
    &lt;p&gt;Summer (TCS) Research Intern positions are available to work with Zhao Song at Adobe Research. The position is for 3-4 months in summer 2023, start date flexible. CV and a recommendation letter from Ph.D. advisor is required to be sent before ddl.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.adobe.com/careers/university/internships.html&quot;&gt;https://www.adobe.com/careers/university/internships.html&lt;/a&gt;&lt;br /&gt;
Email: zsong@adobe.com&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 23:16:50 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>TR22-167 |  Parallel Repetition for the GHZ Game: Exponential Decay | 

	Mark Braverman, 

	Subhash Khot, 

	Dor Minzer</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/167</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/167</link>
  <description>
    We show that the value of the $n$-fold repeated GHZ game is at most $2^{-\Omega(n)}$, improving upon the polynomial bound established by Holmgren and Raz. Our result is established via a reduction to approximate subgroup type questions from additive combinatorics.
  </description>
  <pubDate>2022-11-23 22:17:41 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>FACULTY (ANY RANK) at PENN STATE (apply by November 15, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/23/faculty-any-rank-at-penn-state-apply-by-november-15-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/23/faculty-any-rank-at-penn-state-apply-by-november-15-2022/</link>
  <description>
    &lt;p&gt;Applications are invited for tenure-track positions at all levels across all areas of theoretical computer science. Review of applications started on 11/15/2022 and will continue until the positions is filled.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/23484&quot;&gt;https://academicjobsonline.org/ajo/jobs/23484&lt;/a&gt;&lt;br /&gt;
Email: ablanca@cse.psu.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 15:58:56 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>TR22-166 |  Characterizing the Multi-Pass Streaming Complexity for Solving Boolean CSPs Exactly | 

	Raghuvansh Saxena, 

	Gillat Kol, 

	Dmitry Paramonov, 

	Huacheng Yu</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/166</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/166</link>
  <description>
    We study boolean constraint satisfaction problems (CSPs) $\mathrm{Max}\text{-}\mathrm{CSP}^f_n$ for all predicates $f: \{ 0, 1 \} ^k \to \{ 0, 1 \}$. In these problems, given an integer $v$ and a list of constraints over $n$ boolean variables, each obtained by applying $f$ to a sequence of literals, we wish to decide if there is an assignment to the variables that satisfies at least $v$ constraints. We consider these problems in the streaming model, where the algorithm makes a small number of passes over the list of constraints.

Our first and main result is the following complete characterization: For every predicate $f$, the streaming space complexity of the $\mathrm{Max}\text{-}\mathrm{CSP}^f_n$ problem is $\tilde{\Theta}(n^{\mathrm{deg}(f)})$, where $\mathrm{deg}(f)$ is the degree of $f$ when viewed as a multilinear polynomial. While the upper bound is obtained by a (very simple) one-pass streaming algorithm, our lower bound shows that a better space complexity is impossible even with constant-pass streaming algorithms. 

Building on our techniques, we are also able to get an optimal $\Omega(n^2)$ lower bound on the space complexity of constant-pass streaming algorithms for the well studied $\mathrm{Max}\text{-}\mathrm{CUT}$ problem, even though it is not technically a $\mathrm{Max}\text{-}\mathrm{CSP}^f_n$ problem as, e.g., negations of variables and repeated constraints are not allowed.
  </description>
  <pubDate>2022-11-23 07:12:10 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Dismantling Quantum Hype with Tim Nguyen</title>
  <guid>https://scottaaronson.blog/?p=6830</guid>
  <link>https://scottaaronson.blog/?p=6830</link>
  <description>
    &lt;p&gt;Happy Thanksgiving to my American readers!  While I enjoy a family holiday-week vacation in exotic Dallas&amp;#8212;and yes, I &lt;em&gt;will&lt;/em&gt; follow up on my old &lt;a href=&quot;https://scottaaronson.blog/?p=1596&quot;&gt;JFK post&lt;/a&gt; by visiting Dealey Plaza&amp;#8212;please enjoy the following Thanksgiving victuals:&lt;/p&gt;



&lt;p&gt;I recently recorded a 3-hour (!) YouTube video with &lt;a href=&quot;https://timothynguyen.org/&quot;&gt;Timothy Nguyen&lt;/a&gt;, host of the &lt;a href=&quot;https://timothynguyen.org/videos/#cartesian-cafe&quot;&gt;Cartesian Cafe&lt;/a&gt;.  Our episode is entitled &lt;a href=&quot;https://www.youtube.com/watch?v=qs0D9sdbKPU&quot;&gt;Quantum Computing: Dismantling the Hype&lt;/a&gt;.  In it, I teach a sort of &lt;em&gt;extremely&lt;/em&gt; compressed version of my &lt;a href=&quot;https://www.scottaaronson.com/qclec.pdf&quot;&gt;undergraduate Intro to Quantum Information Science course&lt;/a&gt;, unburdening myself about whatever Tim prompts me to explain: the basic rules of quantum information, &lt;a href=&quot;https://en.wikipedia.org/wiki/Quantum_circuit&quot;&gt;quantum circuits&lt;/a&gt;, the &lt;a href=&quot;https://arxiv.org/abs/1712.06349&quot;&gt;quantum black-box model&lt;/a&gt;, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Deutsch%E2%80%93Jozsa_algorithm&quot;&gt;Deutsch-Jozsa algorithm&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/BQP&quot;&gt;BQP&lt;/a&gt; and its relationship to classical complexity classes, and sampling-based quantum supremacy experiments.  This is a lot more technical than an average podcast, a lot &lt;em&gt;less&lt;/em&gt; technical than an actual course, and hopefully just right for some nonempty subset of readers.&lt;/p&gt;



&lt;p&gt;Outside of his podcasting career, some of you might recognize Nguyen as the coauthor, with Theo Polya, of a &lt;a href=&quot;https://timothynguyen.files.wordpress.com/2021/02/geometric_unity.pdf&quot;&gt;rebuttal of &amp;#8220;Geometric Unity.&amp;#8221;&lt;/a&gt;  This latter is the proposal by the financier, podcaster, and leading &amp;#8220;Intellectual Dark Web&amp;#8221; figure &lt;a href=&quot;https://en.wikipedia.org/wiki/Eric_Weinstein&quot;&gt;Eric Weinstein&lt;/a&gt; for a unified theory of particle physics.  Now, I slightly know Weinstein, and have even found him fascinating, eloquent, and correct about various issues.  So, in an &lt;a href=&quot;https://www.youtube.com/watch?v=wd-0COLM8oc&quot;&gt;addendum to the main video&lt;/a&gt;, Nguyen chats with me about his experience critiquing Weinstein&amp;#8217;s theory, and also about something where my knowledge is far greater: namely, my &lt;a href=&quot;https://arxiv.org/abs/quant-ph/0206089&quot;&gt;2002 rebuttal&lt;/a&gt; of some of the central claims in Stephen Wolfram&amp;#8217;s &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/A_New_Kind_of_Science&quot;&gt;A New Kind of Science&lt;/a&gt;&lt;/em&gt;, and whether there are any updates to that story twenty years later.&lt;/p&gt;



&lt;p&gt;Enjoy!&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 04:12:34 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>Celeste is PSPACE-hard</title>
  <guid>http://arxiv.org/abs/2211.11839</guid>
  <link>http://arxiv.org/abs/2211.11839</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chung_L/0/1/0/all/0/1&quot;&gt;Lily Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demaine_E/0/1/0/all/0/1&quot;&gt;Erik D. Demaine&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We investigate the complexity of the platform video game Celeste. We prove
that navigating Celeste is PSPACE-hard in five different ways, corresponding to
different subsets of the game mechanics. In particular, we prove the game
PSPACE-hard even without player input.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Quantum algorithms and the power of forgetting</title>
  <guid>http://arxiv.org/abs/2211.12447</guid>
  <link>http://arxiv.org/abs/2211.12447</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Childs_A/0/1/0/all/0/1&quot;&gt;Andrew M. Childs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Coudron_M/0/1/0/all/0/1&quot;&gt;Matthew Coudron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gilani_A/0/1/0/all/0/1&quot;&gt;Amin Shiraz Gilani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The so-called welded tree problem provides an example of a black-box problem
that can be solved exponentially faster by a quantum walk than by any classical
algorithm. Given the name of a special ENTRANCE vertex, a quantum walk can find
another distinguished EXIT vertex using polynomially many queries, though
without finding any particular path from ENTRANCE to EXIT. It has been an open
problem for twenty years whether there is an efficient quantum algorithm for
finding such a path, or if the path-finding problem is hard even for quantum
computers. We show that a natural class of efficient quantum algorithms
provably cannot find a path from ENTRANCE to EXIT. Specifically, we consider
algorithms that, within each branch of their superposition, always store a set
of vertex labels that form a connected subgraph including the ENTRANCE, and
that only provide these vertex labels as inputs to the oracle. While this does
not rule out the possibility of a quantum algorithm that efficiently finds a
path, it is unclear how an algorithm could benefit by deviating from this
behavior. Our no-go result suggests that, for some problems, quantum algorithms
must necessarily forget the path they take to reach a solution in order to
outperform classical computation.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Exponential separations using guarded extension variables</title>
  <guid>http://arxiv.org/abs/2211.12456</guid>
  <link>http://arxiv.org/abs/2211.12456</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yolcu_E/0/1/0/all/0/1&quot;&gt;Emre Yolcu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heule_M/0/1/0/all/0/1&quot;&gt;Marijn J.H. Heule&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the complexity of proof systems augmenting resolution with inference
rules that allow, given a formula $\Gamma$ in conjunctive normal form, deriving
clauses that are not necessarily logically implied by $\Gamma$ but whose
addition to $\Gamma$ preserves satisfiability. When the derived clauses are
allowed to introduce variables not occurring in $\Gamma$, the systems we
consider become equivalent to extended resolution. We are concerned with the
versions of these systems without new variables. They are called BC${}^-$,
RAT${}^-$, SBC${}^-$, and GER${}^-$, denoting respectively blocked clauses,
resolution asymmetric tautologies, set-blocked clauses, and generalized
extended resolution. Each of these systems formalizes some restricted version
of the ability to make assumptions that hold &quot;without loss of generality,&quot;
which is commonly used informally to simplify or shorten proofs.
&lt;/p&gt;
&lt;p&gt;Except for SBC${}^-$, these systems are known to be exponentially weaker than
extended resolution. They are, however, all equivalent to it under a relaxed
notion of simulation that allows the translation of the formula along with the
proof when moving between proof systems. By taking advantage of this fact, we
construct formulas that separate RAT${}^-$ from GER${}^-$ and vice versa. With
the same strategy, we also separate SBC${}^-$ from RAT${}^-$. Additionally, we
give polynomial-size SBC${}^-$ proofs of the pigeonhole principle, which
separates SBC${}^-$ from GER${}^-$ by a previously known lower bound. These
results also separate the three systems from BC${}^-$ since they all simulate
it. We thus give an almost complete picture of their relative strengths.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The Tight Spanning Ratio of the Rectangle Delaunay Triangulation</title>
  <guid>http://arxiv.org/abs/2211.11987</guid>
  <link>http://arxiv.org/abs/2211.11987</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renssen_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe8; van Renssen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sha_Y/0/1/0/all/0/1&quot;&gt;Yuan Sha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yucheng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_S/0/1/0/all/0/1&quot;&gt;Sampson Wong&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Spanner construction is a well-studied problem and Delaunay triangulations
are among the most popular spanners. Tight bounds are known if the Delaunay
triangulation is constructed using an equilateral triangle, a square, or a
regular hexagon. However, all other shapes have remained elusive. In this paper
we extend the restricted class of spanners for which tight bounds are known. We
prove that Delaunay triangulations constructed using rectangles with aspect
ratio $\A$ have spanning ratio at most $\sqrt{2} \sqrt{1+\A^2 + \A \sqrt{\A^2 +
1}}$, which matches the known lower bound.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Edge Multiway Cut and Node Multiway Cut are NP-complete on subcubic graphs</title>
  <guid>http://arxiv.org/abs/2211.12203</guid>
  <link>http://arxiv.org/abs/2211.12203</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1&quot;&gt;Matthew Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_B/0/1/0/all/0/1&quot;&gt;Barnaby Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1&quot;&gt;Siani Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1&quot;&gt;Sukanya Pandey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paulusma_D/0/1/0/all/0/1&quot;&gt;Daniel Paulusma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leeuwen_E/0/1/0/all/0/1&quot;&gt;Erik Jan van Leeuwen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that Edge Multiway Cut (also called Multiterminal Cut) and Node
Multiway Cut are NP-complete on graphs of maximum degree $3$ (also known as
subcubic graphs). This improves on a previous degree bound of $11$. Our
NP-completeness result holds even for subcubic graphs that are planar.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Labeled Nearest Neighbor Search and Metric Spanners via Locality Sensitive Orderings</title>
  <guid>http://arxiv.org/abs/2211.11846</guid>
  <link>http://arxiv.org/abs/2211.11846</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filtser_A/0/1/0/all/0/1&quot;&gt;Arnold Filtser&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Chan, Har-Peled, and Jones [SICOMP 2020] developed locality-sensitive
orderings (LSO) for Euclidean space. A $(\tau,\rho)$-LSO is a collection
$\Sigma$ of orderings such that for every $x,y\in\mathbb{R}^d$ there is an
ordering $\sigma\in\Sigma$, where all the points between $x$ and $y$ w.r.t.
$\sigma$ are in the $\rho$-neighborhood of either $x$ or $y$. In essence, LSO
allow one to reduce problems to the $1$-dimensional line. Later, Filtser and Le
[STOC 2022] developed LSO&#39;s for doubling metrics, general metric spaces, and
minor free graphs.
&lt;/p&gt;
&lt;p&gt;For Euclidean and doubling spaces, the number of orderings in the LSO is
exponential in the dimension, which made them mainly useful for the low
dimensional regime. In this paper, we develop new LSO&#39;s for Euclidean,
$\ell_p$, and doubling spaces that allow us to trade larger stretch for a much
smaller number of orderings. We then use our new LSO&#39;s (as well as the previous
ones) to construct path reporting low hop spanners, fault tolerant spanners,
reliable spanners, and light spanners for different metric spaces.
&lt;/p&gt;
&lt;p&gt;While many nearest neighbor search (NNS) data structures were constructed for
metric spaces with implicit distance representations (where the distance
between two metric points can be computed using their names, e.g. Euclidean
space), for other spaces almost nothing is known. In this paper we initiate the
study of the labeled NNS problem, where one is allowed to artificially assign
labels (short names) to metric points. We use LSO&#39;s to construct efficient
labeled NNS data structures in this model.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Towards Optimal Coreset Construction for $(k,z)$-Clustering: Breaking the Quadratic Dependency on $k$</title>
  <guid>http://arxiv.org/abs/2211.11923</guid>
  <link>http://arxiv.org/abs/2211.11923</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lingxiao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xuan Wu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Constructing small-sized coresets for various clustering problems has
attracted significant attention recently. We provide efficient coreset
construction algorithms for $(k, z)$-Clustering with improved coreset sizes in
several metric spaces. In particular, we provide an
$\tilde{O}_z(k^{(2z+2)/(z+2)}\varepsilon^{-2})$-sized coreset for $(k,
z)$-Clustering for all $z\geq 1$ in Euclidean space, improving upon the best
known $\tilde{O}_z(k^2\varepsilon^{-2})$ size upper bound [Cohen-Addad, Larsen,
Saulpic, Schwiegelshohn. STOC&#39;22], breaking the quadratic dependency on $k$ for
the first time (when $k\leq \varepsilon^{-1}$). For example, our coreset size
for Euclidean $k$-Median is $\tilde{O}(k^{4/3} \varepsilon^{-2})$, improving
the best known result $\tilde{O}(\min\left\{k^2\varepsilon^{-2},
k\varepsilon^{-3}\right\})$ by a factor $k^{2/3}$ when $k\leq
\varepsilon^{-1}$; for Euclidean $k$-Means, our coreset size is
$\tilde{O}(k^{3/2} \varepsilon^{-2})$, improving the best known result
$\tilde{O}(\min\left\{k^2\varepsilon^{-2}, k\varepsilon^{-4}\right\})$ by a
factor $k^{1/2}$ when $k\leq \varepsilon^{-2}$. We also obtain optimal or
improved coreset sizes for general metric space, metric space with bounded
doubling dimension, and shortest path metric when the underlying graph has
bounded treewidth, for all $z\geq 1$. Our algorithm largely follows the
framework developed by Cohen-Addad et al. with some minor but useful changes.
Our technical contribution mainly lies in the analysis. An important
improvement in our analysis is a new notion of $\alpha$-covering of distance
vectors with a novel error metric, which allows us to provide a tighter
variance bound. Another useful technical ingredient is terminal embedding with
additive errors, for bounding the covering number in the Euclidean case.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>String Covering: A Survey</title>
  <guid>http://arxiv.org/abs/2211.11856</guid>
  <link>http://arxiv.org/abs/2211.11856</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mhaskar_N/0/1/0/all/0/1&quot;&gt;Neerja Mhaskar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smyth_W/0/1/0/all/0/1&quot;&gt;W. F. Smyth&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The study of strings is an important combinatorial field that precedes the
digital computer. Strings can be very long, trillions of letters, so it is
important to find compact representations. Here we first survey various forms
of one potential compaction methodology, the cover of a given string x,
initially proposed in a simple form in 1990, but increasingly of interest as
more sophisticated variants have been discovered. We then consider covering by
a seed; that is, a cover of a superstring of x. We conclude with many proposals
for research directions that could make significant contributions to string
processing in future.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Upper and Lower Bounds on the Smoothed Complexity of the Simplex Method</title>
  <guid>http://arxiv.org/abs/2211.11860</guid>
  <link>http://arxiv.org/abs/2211.11860</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huiberts_S/0/1/0/all/0/1&quot;&gt;Sophie Huiberts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yin Tat Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinzhi Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The simplex method for linear programming is known to be highly efficient in
practice, and understanding its performance from a theoretical perspective is
an active research topic. The framework of smoothed analysis, first introduced
by Spielman and Teng (JACM &#39;04) for this purpose, defines the smoothed
complexity of solving a linear program with $d$ variables and $n$ constraints
as the expected running time when Gaussian noise of variance $\sigma^2$ is
added to the LP data. We prove that the smoothed complexity of the simplex
method is $O(\sigma^{-3/2} d^{13/4}\log^{7/4} n)$, improving the dependence on
$1/\sigma$ compared to the previous bound of $O(\sigma^{-2} d^2\sqrt{\log n})$.
We accomplish this through a new analysis of the \emph{shadow bound}, key to
earlier analyses as well. Illustrating the power of our new method, we use our
method to prove a nearly tight upper bound on the smoothed complexity of
two-dimensional polygons.
&lt;/p&gt;
&lt;p&gt;We also establish the first non-trivial lower bound on the smoothed
complexity of the simplex method, proving that the \emph{shadow vertex simplex
method} requires at least $\Omega \Big(\min \big(\sigma^{-1/2}
d^{-1/2}\log^{-1/4} d,2^d \big) \Big)$ pivot steps with high probability. A key
part of our analysis is a new variation on the extended formulation for the
regular $2^k$-gon. We end with a numerical experiment that suggests this
analysis could be further improved.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Quasi-stable Coloring for Graph Compression: Approximating Max-Flow, Linear Programs, and Centrality</title>
  <guid>http://arxiv.org/abs/2211.11912</guid>
  <link>http://arxiv.org/abs/2211.11912</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kayali_M/0/1/0/all/0/1&quot;&gt;Moe Kayali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suciu_D/0/1/0/all/0/1&quot;&gt;Dan Suciu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We propose quasi-stable coloring, an approximate version of stable coloring.
Stable coloring, also called color refinement, is a well-studied technique in
graph theory for classifying vertices, which can be used to build compact,
lossless representations of graphs. However, its usefulness is limited due to
its reliance on strict symmetries. Real data compresses very poorly using color
refinement. We propose the first, to our knowledge, approximate color
refinement scheme, which we call quasi-stable coloring. By using approximation,
we alleviate the need for strict symmetry, and allow for a tradeoff between the
degree of compression and the accuracy of the representation. We study three
applications: Linear Programming, Max-Flow, and Betweenness Centrality, and
provide theoretical evidence in each case that a quasi-stable coloring can lead
to good approximations on the reduced graph. Next, we consider how to compute a
maximal quasi-stable coloring: we prove that, in general, this problem is
NP-hard, and propose a simple, yet effective algorithm based on heuristics.
Finally, we evaluate experimentally the quasi-stable coloring technique on
several real graphs and applications, comparing with prior approximation
techniques.
&lt;/p&gt;
&lt;p&gt;A reference implementation and the experiment code are available at
https://github.com/mkyl/QuasiStableColors.jl
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Online facility location with timed-requests and congestion</title>
  <guid>http://arxiv.org/abs/2211.11961</guid>
  <link>http://arxiv.org/abs/2211.11961</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1&quot;&gt;Arghya Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaze_R/0/1/0/all/0/1&quot;&gt;Rahul Vaze&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The classic online facility location problem deals with finding the optimal
set of facilities in an online fashion when demand requests arrive one at a
time and facilities need to be opened to service these requests. In this work,
we study two variants of the online facility location problem; (1) timed
requests and (2) congestion. Both of these variants are motivated by the
applications to real life and the previously known results on online facility
location cannot be directly adapted to analyse them.
&lt;/p&gt;
&lt;p&gt;Timed requests : In this variant, each demand request is a pair $(x,t)$ where
the $x$ is the standard location of the demand while $t$ is the corresponding
weight of the request. The cost of servicing request $(x,t)$ at facility $F$ is
$t\cdot d(x,F&#39;)$ where $F&#39;$ is the set of facilities available at the time of
request $(x,t)$. For this variant, we present an online algorithm attaining a
competitive ratio of $\mathcal{O}(\log n)$ in the secretarial model for the
timed requests and show that it is optimal.
&lt;/p&gt;
&lt;p&gt;Congestion : The congestion variant considers the case when there is an
additional congestion cost that grows with the number of requests served by
each request. For this variant, when the congestion cost is a monomial, we show
that there exists an algorithm attaining a constant competitive ratio. This
constant is a function of the exponent of the monomial and the facility opening
cost but independent of the number of requests.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

</channel>
</rss>
