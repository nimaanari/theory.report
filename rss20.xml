<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>Irreducibility of Recombination Markov Chains in the Triangular Lattice</title>
  <guid>http://arxiv.org/abs/2305.17239</guid>
  <link>http://arxiv.org/abs/2305.17239</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cannon_S/0/1/0/all/0/1&quot;&gt;Sarah Cannon&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the United States, regions are frequently divided into districts for the
purpose of electing representatives. How the districts are drawn can affect
who&#39;s elected, and drawing districts to give an advantage to a certain group is
known as gerrymandering. It can be surprisingly difficult to detect
gerrymandering, but one algorithmic method is to compare a current districting
plan to a large number of randomly sampled plans to see whether it is an
outlier. Recombination Markov chains are often used for this random sampling:
randomly choose two districts, consider their union, and split this union in a
new way. This works well in practice, but the theory behind it remains
underdeveloped. For example, it&#39;s not known if recombination Markov chains are
irreducible, that is, if recombination moves suffice to move from any
districting plan to any other.
&lt;/p&gt;
&lt;p&gt;Irreducibility of recombination Markov chains can be formulated as a graph
problem: for a graph $G$, is the space of all partitions of $G$ into $k$
connected subgraphs ($k$ districts) connected by recombination moves? We
consider three simply connected districts and district sizes $k_1\pm 1$
vertices, $k_2\pm 1$ vertices, and $k3\pm 1$ vertices. We prove for arbitrarily
large triangular regions in the triangular lattice, recombination Markov chains
are irreducible. This is the first proof of irreducibility under tight district
size constraints for recombination Markov chains beyond small or trivial
examples.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Differentially private low-dimensional representation of high-dimensional data</title>
  <guid>http://arxiv.org/abs/2305.17148</guid>
  <link>http://arxiv.org/abs/2305.17148</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yiyun He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strohmer_T/0/1/0/all/0/1&quot;&gt;Thomas Strohmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vershynin_R/0/1/0/all/0/1&quot;&gt;Roman Vershynin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yizhe Zhu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Differentially private synthetic data provide a powerful mechanism to enable
data analysis while protecting sensitive information about individuals.
However, when the data lie in a high-dimensional space, the accuracy of the
synthetic data suffers from the curse of dimensionality. In this paper, we
propose a differentially private algorithm to generate low-dimensional
synthetic data efficiently from a high-dimensional dataset with a utility
guarantee with respect to the Wasserstein distance. A key step of our algorithm
is a private principal component analysis (PCA) procedure with a near-optimal
accuracy bound that circumvents the curse of dimensionality. Different from the
standard perturbation analysis using the Davis-Kahan theorem, our analysis of
private PCA works without assuming the spectral gap for the sample covariance
matrix.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Clip-OGD: An Experimental Design for Adaptive Neyman Allocation in Sequential Experiments</title>
  <guid>http://arxiv.org/abs/2305.17187</guid>
  <link>http://arxiv.org/abs/2305.17187</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dai_J/0/1/0/all/0/1&quot;&gt;Jessica Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gradu_P/0/1/0/all/0/1&quot;&gt;Paula Gradu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Harshaw_C/0/1/0/all/0/1&quot;&gt;Christopher Harshaw&lt;/a&gt;&lt;/p&gt;&lt;p&gt;From clinical development of cancer therapies to investigations into partisan
bias, adaptive sequential designs have become increasingly popular method for
causal inference, as they offer the possibility of improved precision over
their non-adaptive counterparts. However, even in simple settings (e.g. two
treatments) the extent to which adaptive designs can improve precision is not
sufficiently well understood. In this work, we study the problem of Adaptive
Neyman Allocation in a design-based potential outcomes framework, where the
experimenter seeks to construct an adaptive design which is nearly as efficient
as the optimal (but infeasible) non-adaptive Neyman design, which has access to
all potential outcomes. Motivated by connections to online optimization, we
propose Neyman Ratio and Neyman Regret as two (equivalent) performance measures
of adaptive designs for this problem. We present Clip-OGD, an adaptive design
which achieves $\widetilde{O}(\sqrt{T})$ expected Neyman regret and thereby
recovers the optimal Neyman variance in large samples. Finally, we construct a
conservative variance estimator which facilitates the development of
asymptotically valid confidence intervals. To complement our theoretical
results, we conduct simulations using data from a microeconomic experiment.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>DotHash: Estimating Set Similarity Metrics for Link Prediction and Document Deduplication</title>
  <guid>http://arxiv.org/abs/2305.17310</guid>
  <link>http://arxiv.org/abs/2305.17310</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nunes_I/0/1/0/all/0/1&quot;&gt;Igor Nunes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heddes_M/0/1/0/all/0/1&quot;&gt;Mike Heddes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verges_P/0/1/0/all/0/1&quot;&gt;Pere Verg&amp;#xe9;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abraham_D/0/1/0/all/0/1&quot;&gt;Danny Abraham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veidenbaum_A/0/1/0/all/0/1&quot;&gt;Alexander Veidenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nicolau_A/0/1/0/all/0/1&quot;&gt;Alexandru Nicolau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Givargis_T/0/1/0/all/0/1&quot;&gt;Tony Givargis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Metrics for set similarity are a core aspect of several data mining tasks. To
remove duplicate results in a Web search, for example, a common approach looks
at the Jaccard index between all pairs of pages. In social network analysis, a
much-celebrated metric is the Adamic-Adar index, widely used to compare node
neighborhood sets in the important problem of predicting links. However, with
the increasing amount of data to be processed, calculating the exact similarity
between all pairs can be intractable. The challenge of working at this scale
has motivated research into efficient estimators for set similarity metrics.
The two most popular estimators, MinHash and SimHash, are indeed used in
applications such as document deduplication and recommender systems where large
volumes of data need to be processed. Given the importance of these tasks, the
demand for advancing estimators is evident. We propose DotHash, an unbiased
estimator for the intersection size of two sets. DotHash can be used to
estimate the Jaccard index and, to the best of our knowledge, is the first
method that can also estimate the Adamic-Adar index and a family of related
metrics. We formally define this family of metrics, provide theoretical bounds
on the probability of estimate errors, and analyze its empirical performance.
Our experimental results indicate that DotHash is more accurate than the other
estimators in link prediction and detecting duplicate documents with the same
complexity and similar comparison time.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Seeding with Differentially Private Network Information</title>
  <guid>http://arxiv.org/abs/2305.16590</guid>
  <link>http://arxiv.org/abs/2305.16590</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahimian_M/0/1/0/all/0/1&quot;&gt;M. Amin Rahimian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Fang-Yi Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hurtado_C/0/1/0/all/0/1&quot;&gt;Carlos Hurtado&lt;/a&gt;&lt;/p&gt;&lt;p&gt;When designing interventions in public health, development, and education,
decision makers rely on social network data to target a small number of people,
capitalizing on peer effects and social contagion to bring about the most
welfare benefits to the population. Developing new methods that are
privacy-preserving for network data collection and targeted interventions is
critical for designing sustainable public health and development interventions
on social networks. In a similar vein, social media platforms rely on network
data and information from past diffusions to organize their ad campaign and
improve the efficacy of targeted advertising. Ensuring that these network
operations do not violate users&#39; privacy is critical to the sustainability of
social media platforms and their ad economies. We study privacy guarantees for
influence maximization algorithms when the social network is unknown, and the
inputs are samples of prior influence cascades that are collected at random.
Building on recent results that address seeding with costly network
information, our privacy-preserving algorithms introduce randomization in the
collected data or the algorithm output, and can bound each node&#39;s (or group of
nodes&#39;) privacy loss in deciding whether or not their data should be included
in the algorithm input. We provide theoretical guarantees of the seeding
performance with a limited sample size subject to differential privacy budgets
in both central and local privacy regimes. Simulations on synthetic and
empirical network datasets reveal the diminishing value of network information
with decreasing privacy budget in both regimes.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-29 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>A Unified Approach for Maximizing Continuous DR-submodular Functions</title>
  <guid>http://arxiv.org/abs/2305.16671</guid>
  <link>http://arxiv.org/abs/2305.16671</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedramfar_M/0/1/0/all/0/1&quot;&gt;Mohammad Pedramfar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quinn_C/0/1/0/all/0/1&quot;&gt;Christopher John Quinn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1&quot;&gt;Vaneet Aggarwal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper presents a unified approach for maximizing continuous
DR-submodular functions that encompasses a range of settings and oracle access
types. Our approach includes a Frank-Wolfe type offline algorithm for both
monotone and non-monotone functions, with different restrictions on the general
convex set. We consider settings where the oracle provides access to either the
gradient of the function or only the function value, and where the oracle
access is either deterministic or stochastic. We determine the number of
required oracle accesses in all cases. Our approach gives new/improved results
for nine out of the sixteen considered cases, avoids computationally expensive
projections in two cases, with the proposed framework matching performance of
state-of-the-art approaches in the remaining five cases. Notably, our approach
for the stochastic function value-based oracle enables the first regret bounds
with bandit feedback for stochastic DR-submodular functions.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-29 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Polylogarithmic Approximation for Robust s-t Path</title>
  <guid>http://arxiv.org/abs/2305.16439</guid>
  <link>http://arxiv.org/abs/2305.16439</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Chenyang Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Ruilong Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The paper revisits the robust $s$-$t$ path problem, one of the most
fundamental problems in robust optimization. In the problem, we are given a
directed graph with $n$ vertices and $k$ distinct cost functions (scenarios)
defined over edges, and aim to choose an $s$-$t$ path such that the total cost
of the path is always provable no matter which scenario is realized. With the
view of each cost function being associated with an agent, our goal is to find
a common $s$-$t$ path minimizing the maximum objective among all agents, and
thus create a fair solution for them. The problem is hard to approximate within
$o(\log k)$ by any quasi-polynomial time algorithm unless $\mathrm{NP}
\subseteq \mathrm{DTIME}(n^{\mathrm{poly}\log n})$, and the best approximation
ratio known to date is $\widetilde{O}(\sqrt{n})$ which is based on the natural
flow linear program. A longstanding open question is whether we can achieve a
polylogarithmic approximation even when a quasi-polynomial running time is
allowed.
&lt;/p&gt;
&lt;p&gt;We give the first polylogarithmic approximation for robust $s$-$t$ path since
the problem was proposed more than two decades ago. In particular, we introduce
a $O(\log n \log k)$-approximate algorithm running in quasi-polynomial time.
The algorithm is built on a novel linear program formulation for a
decision-tree-type structure which enables us to get rid of the
$\Omega(\max\{k,\sqrt{n}\})$ integrality gap of the natural flow LP. Further,
we also consider some well-known graph classes, e.g., graphs with bounded
treewidth, and show that the polylogarithmic approximation can be achieved
polynomially on these graphs. We hope the new proposed techniques in the paper
can offer new insights into the robust $s$-$t$ path problem and related
problems in robust optimization.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Sliding Window Sum Algorithms for Deep Neural Networks</title>
  <guid>http://arxiv.org/abs/2305.16513</guid>
  <link>http://arxiv.org/abs/2305.16513</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Snytsar_R/0/1/0/all/0/1&quot;&gt;Roman Snytsar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Sliding window sums are widely used for string indexing, hashing and time
series analysis. We have developed a family of the generic vectorized sliding
sum algorithms that provide speedup of O(P/w) for window size $w$ and number of
processors P. For a sum with a commutative operator the speedup is improved to
O(P/log(w)). Even more important, our algorithms exhibit efficient memory
access patterns. In this paper we study the application of the sliding sum
algorithms to the training and inference of the Deep Neural Networks. We
demonstrate how both pooling and convolution primitives could be expressed as
sliding sums and evaluated by the compute kernels with the shared structure. We
show that the sliding sum convolution kernels are more efficient than the
commonly used GEMM kernels on the CPU, and could even outperform their GPU
counterparts.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Efficient Computation of Quantiles over Joins</title>
  <guid>http://arxiv.org/abs/2305.16525</guid>
  <link>http://arxiv.org/abs/2305.16525</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tziavelis_N/0/1/0/all/0/1&quot;&gt;Nikolaos Tziavelis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carmeli_N/0/1/0/all/0/1&quot;&gt;Nofar Carmeli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gatterbauer_W/0/1/0/all/0/1&quot;&gt;Wolfgang Gatterbauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimelfeld_B/0/1/0/all/0/1&quot;&gt;Benny Kimelfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riedewald_M/0/1/0/all/0/1&quot;&gt;Mirek Riedewald&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present efficient algorithms for Quantile Join Queries, abbreviated as
%JQ. A %JQ asks for the answer at a specified relative position (e.g., 50% for
the median) under some ordering over the answers to a Join Query (JQ). Our goal
is to avoid materializing the set of all join answers, and to achieve
quasilinear time in the size of the database, regardless of the total number of
answers. A recent dichotomy result rules out the existence of such an algorithm
for a general family of queries and orders. Specifically, for acyclic JQs
without self-joins, the problem becomes intractable for ordering by sum
whenever we join more than two relations (and these joins are not trivial
intersections). Moreover, even for basic ranking functions beyond sum, such as
min or max over different attributes, so far it is not known whether there is
any nontrivial tractable %JQ. In this work, we develop a new approach to
solving %JQ. Our solution uses two subroutines: The first one needs to select
what we call a &quot;pivot answer&quot;. The second subroutine partitions the space of
query answers according to this pivot, and continues searching in one partition
that is represented as new %JQ over a new database. For pivot selection, we
develop an algorithm that works for a large class of ranking functions that are
appropriately monotone. The second subroutine requires a customized
construction for the specific ranking function at hand. We show the benefit and
generality of our approach by using it to establish several new complexity
results. First, we prove the tractability of min and max for all acyclic JQs,
thereby resolving the above question. Second, we extend the previous %JQ
dichotomy for sum to all partial sums. Third, we handle the intractable cases
of sum by devising a deterministic approximation scheme that applies to every
acyclic JQ.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>CARAMEL: A Succinct Read-Only Lookup Table via Compressed Static Functions</title>
  <guid>http://arxiv.org/abs/2305.16545</guid>
  <link>http://arxiv.org/abs/2305.16545</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coleman_B/0/1/0/all/0/1&quot;&gt;Benjamin Coleman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramos_D/0/1/0/all/0/1&quot;&gt;David Torres Ramos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakshman_V/0/1/0/all/0/1&quot;&gt;Vihan Lakshman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1&quot;&gt;Chen Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1&quot;&gt;Anshumali Shrivastava&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Lookup tables are a fundamental structure in many data processing and systems
applications. Examples include tokenized text in NLP, quantized embedding
collections in recommendation systems, integer sketches for streaming data, and
hash-based string representations in genomics. With the increasing size of
web-scale data, such applications often require compression techniques that
support fast random $O(1)$ lookup of individual parameters directly on the
compressed data (i.e. without blockwise decompression in RAM). While the
community has proposd a number of succinct data structures that support queries
over compressed representations, these approaches do not fully leverage the
low-entropy structure prevalent in real-world workloads to reduce space.
Inspired by recent advances in static function construction techniques, we
propose a space-efficient representation of immutable key-value data, called
CARAMEL, specifically designed for the case where the values are multi-sets. By
carefully combining multiple compressed static functions, CARAMEL occupies
space proportional to the data entropy with low memory overheads and minimal
lookup costs. We demonstrate 1.25-16x compression on practical lookup tasks
drawn from real-world systems, improving upon established techniques, including
a production-grade read-only database widely used for development within
Amazon.com.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Sublinear-Space Streaming Algorithms for Estimating Graph Parameters on Sparse Graphs</title>
  <guid>http://arxiv.org/abs/2305.16815</guid>
  <link>http://arxiv.org/abs/2305.16815</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiuge Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chitnis_R/0/1/0/all/0/1&quot;&gt;Rajesh Chitnis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eades_P/0/1/0/all/0/1&quot;&gt;Patrick Eades&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wirth_A/0/1/0/all/0/1&quot;&gt;Anthony Wirth&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we design sub-linear space streaming algorithms for estimating
three fundamental parameters -- maximum independent set, minimum dominating set
and maximum matching -- on sparse graph classes, i.e., graphs which satisfy
$m=O(n)$ where $m,n$ is the number of edges, vertices respectively. Each of the
three graph parameters we consider can have size $\Omega(n)$ even on sparse
graph classes, and hence for sublinear-space algorithms we are restricted to
parameter estimation instead of attempting to find a solution.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On Nov 10, 2014 the TV show Scorpion mentions Software that is like ChatGPT for Music</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-7380998070167715843</guid>
  <link>https://blog.computationalcomplexity.org/2023/05/on-nov-10-2014-tv-show-scorpion.html</link>
  <description>
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Scorpion is a TV show that ran from 2014 to 2018. It involves a group of brilliant (to say the least) but socially awkward (to say the least) people who help the government battle threats and/or solve crimes.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The episode &lt;i&gt;Risky Business &lt;/i&gt;aired on Nov 10, 2014 (episode 8).&amp;nbsp;&lt;/p&gt;&lt;p&gt;In the episode someone wrote a program that (in todays terminology) scrapes the web for all pop songs that were hits for the last 50 years and creates hits that share those properties and hence will be popular. And it works!&amp;nbsp;&lt;/p&gt;&lt;p&gt;1) The episode says that if the fans of group X find out that they didn&#39;t create their own music, but its computer generated, then sales will drop. This may be true but I am not quite sure WHY its true. If I LIKE&amp;nbsp; listening to a song, I will still like it even if I know it was computer generated.&amp;nbsp;&lt;/p&gt;&lt;p&gt;2) While they didn&#39;t go into any detail about what the program does, it SOUNDS a lot like ChatGPT to me.&amp;nbsp;&lt;/p&gt;&lt;p&gt;3) Could ChatGPT do that now? Has it already? Lance happened to read an earlier version of this post and emailed me a link which says this is already happening to some extent. The link is&amp;nbsp;&lt;a href=&quot;https://www.nytimes.com/2023/04/19/arts/music/ai-drake-the-weeknd-fake.html?unlocked_article_code=EAbzgrrnYPlWWP8bMw7TdZYabKqbPRK84bx8yi2YwEHpQL7iuKUpJ4Qz7F-3STJMP9li11P1y0MRNGBRdHwJJtYjQS1-vDsLZpn6mAbWoPQmcevIRg665mw3n_e_OyjFTK2Cfe928mnnK5RCGYm4giIv5zNMqz5vp8FA0s3jW2wuD7je4PnTDMRBBBo1VD4hISgqnGogiyyYYpBXE4rTebEjqyFvtakYxQ-lkjgNfAVShci0Q60FIgfnPk4oP-b8l1kXST71XbBsi2GjeJI1EVRv5HFcFz3IrKhHd5AJnehEXoAwCK-6ycaaWNwD1yxUcTT1kF_sXBrs8jfqFNFUsCHhv-U5&amp;amp;smid=url-share&quot;&gt;here&lt;/a&gt;&amp;nbsp;but might be behind a paywall. (Note- My spellchecker DOES think paywall is a word. Yeah! It also thinks that spellchecker is a word. Yeah!)&lt;/p&gt;&lt;p&gt;4) Is it impressive that the shows writers predicted this kind of technology way back in 2014?&amp;nbsp;&lt;/p&gt;&lt;p&gt;5) In the real world would someone be murdered because they are going to reveal that group X&#39;s songs were not authentic? Either TV has far more murders than the real world OR on TV they just get caught more often. I would like to think that TV has far more murders (see &lt;a href=&quot;https://www.dailymail.co.uk/news/article-2191990/Murder-capital-world-Quiet-seaside-town-Cabot-Cove-named-dangerous-place-Earth.html&quot;&gt;here&lt;/a&gt;). It certainly has far more &lt;i&gt;interesting&lt;/i&gt; murders.&amp;nbsp;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </description>
  <pubDate>2023-05-28 19:34:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>TR23-077 |  Batch Proofs are Statistically Hiding | 

	Nir Bitansky, 

	Chethan Kamath, 

	Omer Paneth, 

	Ron Rothblum, 

	Prashant Nalini Vasudevan</title>
  <guid>https://eccc.weizmann.ac.il/report/2023/077</guid>
  <link>https://eccc.weizmann.ac.il/report/2023/077</link>
  <description>
    Batch proofs are proof systems that convince a verifier that $x_1,\dots, x_t \in  L$, for some $NP$ language $L$, with communication that is much shorter than sending the $t$ witnesses. In the case of statistical soundness (where the cheating prover is unbounded but honest prover is efficient), interactive batch proofs are known for $UP$, the class of unique witness $NP$ languages. In the case of computational soundness (aka arguments, where both honest and dishonest provers are efficient), non-interactive solutions are now known for all of $NP$, assuming standard cryptographic assumptions. We study the necessary conditions for the existence of batch proofs in these two settings. Our main results are as follows.

1. Statistical Soundness: the existence of a statistically-sound batch proof for $L$ implies that $L$ has a statistically witness indistinguishable ($SWI$) proof, with inverse polynomial $SWI$ error, and a non-uniform honest prover. The implication is unconditional for public-coin protocols and relies on one-way functions in the private-coin case.

This poses a barrier for achieving batch proofs beyond $UP$ (where witness indistinguishability is trivial). In particular, assuming that $NP$ does not have $SWI$ proofs, batch proofs for all of $NP$ do not exist. This motivates further study of the complexity class $SWI$, which, in contrast to the related class $SZK$, has been largely left unexplored.

2. Computational Soundness: the existence of batch arguments ($BARG$s) for $NP$, together with one-way functions, implies the existence of statistical zero-knowledge ($SZK$) arguments for $NP$ with roughly the same number of rounds, an inverse polynomial zero-knowledge error, and non-uniform honest prover.

    Thus, constant-round interactive $BARG$s from one-way functions would yield constant-round $SZK$ arguments from one-way functions. This would be surprising as $SZK$ arguments are currently only known assuming constant-round statistically-hiding commitments (which in turn are unlikely to follow from one-way functions).

3. Non-interactive: the existence of non-interactive $BARG$s for $NP$ and one-way functions, implies non-interactive statistical zero-knowledge arguments ($NISZKA$) for $NP$, with negligible soundness error, inverse polynomial zero-knowledge error, and non-uniform honest prover. Assuming also lossy public-key encryption, the statistical zero-knowledge error can be made negligible. We further show that $BARG$s satisfying a notion of honest somewhere extractability imply lossy public key encryption.

All of our results stem from a common framework showing how to transform a batch protocol for a language $L$ into an $SWI$ protocol for $L$.
  </description>
  <pubDate>2023-05-27 08:16:05 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>TCS+ talk: Wednesday, May 31 — Paul Gölz, Harvard University</title>
  <guid>http://tcsplus.wordpress.com/?p=691</guid>
  <link>https://tcsplus.wordpress.com/2023/05/26/tcs-talk-wednesday-may-31-paul-golz-harvard-university/</link>
  <description>
    &lt;p&gt;The next TCS+ talk will take place this coming Wednesday, May 31th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). &lt;strong&gt;Paul Gölz&lt;/strong&gt; from Harvard University will speak about &amp;#8220;&lt;em&gt;News from Algorithmic Democracy: Proportional Representation for Preferences and Demographics&lt;/em&gt;&amp;#8221; (abstract below).&lt;/p&gt;
&lt;p&gt;You can reserve a spot as an individual or a group to join us live by signing up on &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/next-tcs-talk&quot;&gt;the online form&lt;/a&gt;. Registration is &lt;em&gt;not&lt;/em&gt; required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/past-talks&quot;&gt;on our website&lt;/a&gt; afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/suggest-a-talk&quot;&gt;suggest&lt;/a&gt; a possible topic or speaker, please see &lt;a href=&quot;https://sites.google.com/view/tcsplus/&quot;&gt;the website&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class=&quot;wp-block-quote&quot;&gt;&lt;p&gt;Abstract: How do you fill a knapsack with city projects to fund, in a way that aligns with voters’ preferences? And how do you choose a committee that represents the population’s makeup in terms of gender, age, etc.? Both questions are central to experiments with new forms of democracy in practice, and both have spurred an exploration for the right algorithms in computational social choice. In this talk, I will survey advances along these thrusts: proposed algorithms, guarantees offered and sought after, as well as technical challenges and connections.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;authors&quot;&gt;By plustcs&lt;/p&gt;
  </description>
  <pubDate>2023-05-26 06:40:08 UTC</pubDate>
  <author>TCS+ Seminar Series</author>
</item>

<item>
  <title>On the Weisfeiler-Leman dimension of permutation graphs</title>
  <guid>http://arxiv.org/abs/2305.15861</guid>
  <link>http://arxiv.org/abs/2305.15861</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jin Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gavrilyuk_A/0/1/0/all/0/1&quot;&gt;Alexander L. Gavrilyuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ponomarenko_I/0/1/0/all/0/1&quot;&gt;Ilia Ponomarenko&lt;/a&gt;&lt;/p&gt;&lt;p&gt;It is proved that the Weisfeiler-Leman dimension of the class of permutation
graphs is at most 18. Previously it was only known that this dimension is
finite (Gru{\ss}ien, 2017).
&lt;/p&gt;
  </description>
  <pubDate>2023-05-26 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>A Fast Algorithm for Consistency Checking Partially Ordered Time</title>
  <guid>http://arxiv.org/abs/2305.15917</guid>
  <link>http://arxiv.org/abs/2305.15917</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eriksson_L/0/1/0/all/0/1&quot;&gt;Leif Eriksson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lagerkvist_V/0/1/0/all/0/1&quot;&gt;Victor Lagerkvist&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Partially ordered models of time occur naturally in applications where agents
or processes cannot perfectly communicate with each other, and can be traced
back to the seminal work of Lamport. In this paper we consider the problem of
deciding if a (likely incomplete) description of a system of events is
consistent, the network consistency problem for the point algebra of partially
ordered time (POT). While the classical complexity of this problem has been
fully settled, comparably little is known of the fine-grained complexity of POT
except that it can be solved in $O^*((0.368n)^n)$ time by enumerating ordered
partitions. We construct a much faster algorithm with a run-time bounded by
$O^*((0.26n)^n)$. This is achieved by a sophisticated enumeration of structures
similar to total orders, which are then greedily expanded toward a solution.
While similar ideas have been explored earlier for related problems it turns
out that the analysis for POT is non-trivial and requires significant new
ideas.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-26 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Improved Algorithms for Allen&#39;s Interval Algebra by Dynamic Programming with Sublinear Partitioning</title>
  <guid>http://arxiv.org/abs/2305.15950</guid>
  <link>http://arxiv.org/abs/2305.15950</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eriksson_L/0/1/0/all/0/1&quot;&gt;Leif Eriksson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lagerkvist_V/0/1/0/all/0/1&quot;&gt;Victor Lagerkvist&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Allen&#39;s interval algebra is one of the most well-known calculi in qualitative
temporal reasoning with numerous applications in artificial intelligence.
Recently, there has been a surge of improvements in the fine-grained complexity
of NP-hard reasoning tasks, improving the running time from the naive
$2^{O(n^2)}$ to $O^*((1.0615n)^{n})$, with even faster algorithms for unit
intervals a bounded number of overlapping intervals (the $O^*(\cdot)$ notation
suppresses polynomial factors). Despite these improvements the best known lower
bound is still only $2^{o(n)}$ (under the exponential-time hypothesis) and
major improvements in either direction seemingly require fundamental advances
in computational complexity. In this paper we propose a novel framework for
solving NP-hard qualitative reasoning problems which we refer to as dynamic
programming with sublinear partitioning. Using this technique we obtain a major
improvement of $O^*((\frac{cn}{\log{n}})^{n})$ for Allen&#39;s interval algebra. To
demonstrate that the technique is applicable to more domains we apply it to a
problem in qualitative spatial reasoning, the cardinal direction point algebra,
and solve it in $O^*((\frac{cn}{\log{n}})^{2n/3})$ time. Hence, not only do we
significantly advance the state-of-the-art for NP-hard qualitative reasoning
problems, but obtain a novel algorithmic technique that is likely applicable to
many problems where $2^{O(n)}$ time algorithms are unlikely.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-26 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>An exponential bound for simultaneous embeddings of planar graphs</title>
  <guid>http://arxiv.org/abs/2305.15721</guid>
  <link>http://arxiv.org/abs/2305.15721</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Goenka_R/0/1/0/all/0/1&quot;&gt;Ritesh Goenka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Semnani_P/0/1/0/all/0/1&quot;&gt;Pardis Semnani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yip_C/0/1/0/all/0/1&quot;&gt;Chi Hoi Yip&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that there are $O(n \cdot 4^{n/11})$ planar graphs on $n$ vertices
which do not admit a simultaneous straight-line embedding on any $n$-point set
in the plane. In particular, this improves the best known bound $O(n!)$
significantly.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-26 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Smoothed Complexity of SWAP in Local Graph Partitioning</title>
  <guid>http://arxiv.org/abs/2305.15804</guid>
  <link>http://arxiv.org/abs/2305.15804</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1&quot;&gt;Chenghao Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vlatakis_Gkaragkounis_E/0/1/0/all/0/1&quot;&gt;Emmanouil-Vasileios Vlatakis-Gkaragkounis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yannakakis_M/0/1/0/all/0/1&quot;&gt;Mihalis Yannakakis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give the first quasipolynomial upper bound $\phi n^{\text{polylog}(n)}$
for the smoothed complexity of the SWAP algorithm for local Graph Partitioning
(also known as Bisection Width), where $n$ is the number of nodes in the graph
and $\phi$ is a parameter that measures the magnitude of perturbations applied
on its edge weights. More generally, we show that the same quasipolynomial
upper bound holds for the smoothed complexity of the 2-FLIP algorithm for any
binary Maximum Constraint Satisfaction Problem, including local Max-Cut, for
which similar bounds were only known for $1$-FLIP. Our results are based on an
analysis of cycles formed in long sequences of double flips, showing that it is
unlikely for every move in a long sequence to incur a positive but small
improvement in the cut weight.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-26 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Adaptive Data Analysis in a Balanced Adversarial Model</title>
  <guid>http://arxiv.org/abs/2305.15452</guid>
  <link>http://arxiv.org/abs/2305.15452</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nissim_K/0/1/0/all/0/1&quot;&gt;Kobbi Nissim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1&quot;&gt;Uri Stemmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsfadia_E/0/1/0/all/0/1&quot;&gt;Eliad Tsfadia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In adaptive data analysis, a mechanism gets $n$ i.i.d. samples from an
unknown distribution $D$, and is required to provide accurate estimations to a
sequence of adaptively chosen statistical queries with respect to $D$. Hardt
and Ullman (FOCS 2014) and Steinke and Ullman (COLT 2015) showed that in
general, it is computationally hard to answer more than $\Theta(n^2)$ adaptive
queries, assuming the existence of one-way functions.
&lt;/p&gt;
&lt;p&gt;However, these negative results strongly rely on an adversarial model that
significantly advantages the adversarial analyst over the mechanism, as the
analyst, who chooses the adaptive queries, also chooses the underlying
distribution $D$. This imbalance raises questions with respect to the
applicability of the obtained hardness results -- an analyst who has complete
knowledge of the underlying distribution $D$ would have little need, if at all,
to issue statistical queries to a mechanism which only holds a finite number of
samples from $D$.
&lt;/p&gt;
&lt;p&gt;We consider more restricted adversaries, called \emph{balanced}, where each
such adversary consists of two separated algorithms: The \emph{sampler} who is
the entity that chooses the distribution and provides the samples to the
mechanism, and the \emph{analyst} who chooses the adaptive queries, but does
not have a prior knowledge of the underlying distribution. We improve the
quality of previous lower bounds by revisiting them using an efficient
\emph{balanced} adversary, under standard public-key cryptography assumptions.
We show that these stronger hardness assumptions are unavoidable in the sense
that any computationally bounded \emph{balanced} adversary that has the
structure of all known attacks, implies the existence of public-key
cryptography.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-26 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Trading Prophets</title>
  <guid>http://arxiv.org/abs/2305.15566</guid>
  <link>http://arxiv.org/abs/2305.15566</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Correa_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Correa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cristi_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s Cristi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutting_P/0/1/0/all/0/1&quot;&gt;Paul D&amp;#xfc;tting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1&quot;&gt;Mohammad Hajiaghayi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olkowski_J/0/1/0/all/0/1&quot;&gt;Jan Olkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schewior_K/0/1/0/all/0/1&quot;&gt;Kevin Schewior&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work we initiate the study of buy-and-sell prophet inequalities. We
start by considering what is arguably the most fundamental setting. In this
setting the online algorithm observes a sequence of prices one after the other.
At each time step, the online algorithm can decide to buy and pay the current
price if it does not hold the item already; or it can decide to sell and
collect the current price as a reward if it holds the item.
&lt;/p&gt;
&lt;p&gt;We show that for i.i.d. prices a single-threshold online algorithm achieves
at least $1/2$ of the expected profit of the optimal offline algorithm and we
prove that this is optimal. For non-i.i.d. prices in random order, where prices
are no longer independent, we give a single-threshold online algorithm that
achieves at least a $1/16$ fraction of the expected profit of the optimal
offline algorithm. We also show that for this setting no online algorithm can
yield a better than $1/3$ approximation, and thus establish a formal separation
from the i.i.d. case. On the other hand, we present a threshold-based online
algorithm for this setting that yields a $1/2-o(1)$ approximation. For
non-i.i.d. prices no approximation is possible.
&lt;/p&gt;
&lt;p&gt;We use the results for these base cases to solve a variety of more complex
settings. For instance, we show a $1/2-o(1)$ approximation for settings where
prices are affiliated and the online algorithm has only access to a single
sample. We also extend our upper and lower bounds for the single item case to
$k$ items, and thus in particular show that it is impossible to achieve
$1-o(1)$ approximations. For the budgeted version, where fractions of an item
can be bought, and gains can be reinvested, we show a constant-factor
approximation to the optimal offline algorithm&#39;s growth rate. In a setting with
$k$ item types and price streams, we achieve a $\Omega(1/k)$ approximation for
the unit-capacity case, which is optimal.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-26 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Maximum Weight Independent Set in Graphs with no Long Claws in Quasi-Polynomial Time</title>
  <guid>http://arxiv.org/abs/2305.15738</guid>
  <link>http://arxiv.org/abs/2305.15738</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gartland_P/0/1/0/all/0/1&quot;&gt;Peter Gartland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lokshtanov_D/0/1/0/all/0/1&quot;&gt;Daniel Lokshtanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masarik_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;&amp;#x161; Masa&amp;#x159;&amp;#xed;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1&quot;&gt;Marcin Pilipczuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#x142; Pilipczuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rzazewski_P/0/1/0/all/0/1&quot;&gt;Pawe&amp;#x142; Rz&amp;#x105;&amp;#x17c;ewski&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that the \textsc{Maximum Weight Independent Set} problem
(\textsc{MWIS}) can be solved in quasi-polynomial time on $H$-free graphs
(graphs excluding a fixed graph $H$ as an induced subgraph) for every $H$ whose
every connected component is a path or a subdivided claw (i.e., a tree with at
most three leaves). This completes the dichotomy of the complexity of
\textsc{MWIS} in $\mathcal{F}$-free graphs for any finite set $\mathcal{F}$ of
graphs into NP-hard cases and cases solvable in quasi-polynomial time, and
corroborates the conjecture that the cases not known to be NP-hard are actually
polynomial-time solvable.
&lt;/p&gt;
&lt;p&gt;The key graph-theoretic ingredient in our result is as follows. Fix an
integer $t \geq 1$. Let $S_{t,t,t}$ be the graph created from three paths on
$t$ edges by identifying one endpoint of each path into a single vertex. We
show that, given a graph $G$, one can in polynomial time find either an induced
$S_{t,t,t}$ in $G$, or a balanced separator consisting of $\Oh(\log |V(G)|)$
vertex neighborhoods in $G$, or an extended strip decomposition of $G$ (a
decomposition almost as useful for recursion for \textsc{MWIS} as a partition
into connected components) with each particle of weight multiplicatively
smaller than the weight of $G$. This is a strengthening of a result of Majewski
et al.\ [ICALP~2022] which provided such an extended strip decomposition only
after the deletion of $\Oh(\log |V(G)|)$ vertex neighborhoods. To reach the
final result, we employ an involved branching strategy that relies on the
structural lemma presented above.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-26 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Maximizing Neutrality in News Ordering</title>
  <guid>http://arxiv.org/abs/2305.15790</guid>
  <link>http://arxiv.org/abs/2305.15790</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Advani_R/0/1/0/all/0/1&quot;&gt;Rishi Advani&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papotti_P/0/1/0/all/0/1&quot;&gt;Paolo Papotti&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asudeh_A/0/1/0/all/0/1&quot;&gt;Abolfazl Asudeh&lt;/a&gt; (1) ((1) University of Illinois Chicago, (2) EURECOM)&lt;/p&gt;&lt;p&gt;The detection of fake news has received increasing attention over the past
few years, but there are more subtle ways of deceiving one&#39;s audience. In
addition to the content of news stories, their presentation can also be made
misleading or biased. In this work, we study the impact of the ordering of news
stories on audience perception. We introduce the problems of detecting
cherry-picked news orderings and maximizing neutrality in news orderings. We
prove hardness results and present several algorithms for approximately solving
these problems. Furthermore, we provide extensive experimental results and
present evidence of potential cherry-picking in the real world.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-26 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Guide for Students Presenting their First Talk</title>
  <guid>http://adamsheffer.wordpress.com/?p=5802</guid>
  <link>https://adamsheffer.wordpress.com/2023/05/25/a-guide-for-students-presenting-their-first-talk/</link>
  <description>
    I wrote a guide for undergraduate students who prepare to present their first math talk, for participants of the Polymath Jr Program and the NYC Discrete Math REU. I wanted to also share the guide here for two reasons: Click here for the pdf file. To the many friends who helped preparing this, THANK YOU! [&amp;#8230;]&lt;p class=&quot;authors&quot;&gt;By Adam Sheffer&lt;/p&gt;
  </description>
  <pubDate>2023-05-25 23:25:23 UTC</pubDate>
  <author>Adam Sheffer</author>
</item>

<item>
  <title>Finding Primes Pseudodeterministically</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-1455510985147072060</guid>
  <link>https://blog.computationalcomplexity.org/2023/05/finding-primes-pseudodeterministically.html</link>
  <description>
    &lt;p&gt;In 2003, Agrawal, Kayal and Saxena showed that primality testing is in P, i.e., you could test for primes without using any randomness.&lt;/p&gt;&lt;p&gt;What if you want to find a prime? Specifically given a number m in binary, can you find a prime p &amp;gt; m in time polynomial in the length of m. In 2009 I&amp;nbsp;&lt;a href=&quot;https://blog.computationalcomplexity.org/2009/08/finding-primes.html&quot;&gt;posted&lt;/a&gt;&amp;nbsp;about a polymath project to find a deterministic algorithm for finding primes and the problem remains open today.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Likely you could just try m+1,m+2, ... until you find a prime but whether that is bounded by a polynomial number of steps is a big open question in number theory. You can choose random numbers between m and 2m and find one in expected polytime given the &lt;a href=&quot;https://en.wikipedia.org/wiki/Prime_number_theorem&quot;&gt;prime number theorem&lt;/a&gt;. This algorithm will likely output a different prime every time you run it.&lt;/p&gt;&lt;p&gt;There&#39;s a &lt;a href=&quot;https://eccc.weizmann.ac.il/report/2023/076/&quot;&gt;new paper&lt;/a&gt; by&amp;nbsp;Lijie Chen, Zhenjian Lu, Igor Carboni Oliveira, Hanlin Ren and Rahul Santhanam that solves this problem pseudodeterministically for infinitely many inputs. This is a randomized polynomial-time algorithm B that for infinitely many n, there is a specific prime p between 2&lt;sup&gt;n&lt;/sup&gt; and 2&lt;sup&gt;n+1&lt;/sup&gt; such that B(1&lt;sup&gt;n&lt;/sup&gt;) outputs p with high probability. With high probability you will get the same prime every time you run the algorithm!&lt;/p&gt;&lt;p&gt;The proof uses a win-win kind of argument, if a certain algorithm fails to work you can use that to derandomize. Making that argument work requires bootstrapping on variants of previous pseudorandom generator and hitting sets constructions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Almost surely there is a deterministic polytime algorithm for finding primes. But for now the new result of Chen et al. is a nice stop in that direction.&amp;nbsp;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2023-05-25 13:17:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>Test your intuition 52: Can you predict the ratios of ones?</title>
  <guid>http://gilkalai.wordpress.com/?p=24359</guid>
  <link>https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/</link>
  <description>
    &lt;p&gt;Here is a problem I heard from Zachary Chase and Yuval Peres. Bob choses a sequences of zeroes and ones of length &lt;img src=&quot;https://s0.wp.com/latex.php?latex=N&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=N&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;N&quot; class=&quot;latex&quot; /&gt;. The bits are presented to Alice one by one. Alice&amp;#8217;s task is to choose, at a certain time of her choice, some number &lt;img src=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;K&quot; class=&quot;latex&quot; /&gt; (smaller than the number of unseen bits) and to predict the fraction of ones in the next &lt;img src=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;K&quot; class=&quot;latex&quot; /&gt; bits. Alice wins if her prediction deviates by at most 0.01 from the correct ratio.&lt;/p&gt;
&lt;h3&gt;Test your intuition 52: Assuming that &lt;img src=&quot;https://s0.wp.com/latex.php?latex=N&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=N&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;N&quot; class=&quot;latex&quot; /&gt; is sufficiently large, is it possible for Alice to achieve this task with probability greater than 0.99?&lt;/h3&gt;
&lt;p&gt;&lt;span style=&quot;color: #0000ff&quot;&gt;Clarification: we assume Bob’s sequence is fixed, and the randomness is over a probabilistic strategy chosen by Alice.&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </description>
  <pubDate>2023-05-25 08:33:58 UTC</pubDate>
  <author>Gil Kalai</author>
</item>

<item>
  <title>Supermodular Rank: Set Function Decomposition and Optimization</title>
  <guid>http://arxiv.org/abs/2305.14632</guid>
  <link>http://arxiv.org/abs/2305.14632</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sonthalia_R/0/1/0/all/0/1&quot;&gt;Rishi Sonthalia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Seigal_A/0/1/0/all/0/1&quot;&gt;Anna Seigal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Montufar_G/0/1/0/all/0/1&quot;&gt;Guido Montufar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We define the supermodular rank of a function on a lattice. This is the
smallest number of terms needed to decompose it into a sum of supermodular
functions. The supermodular summands are defined with respect to different
partial orders. We characterize the maximum possible value of the supermodular
rank and describe the functions with fixed supermodular rank. We analogously
define the submodular rank. We use submodular decompositions to optimize set
functions. Given a bound on the submodular rank of a set function, we formulate
an algorithm that splits an optimization problem into submodular subproblems.
We show that this method improves the approximation ratio guarantees of several
algorithms for monotone set function maximization and ratio of set functions
minimization, at a computation overhead that depends on the submodular rank.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-25 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Engineering Rank/Select Data Structures for Big-Alphabet Strings</title>
  <guid>http://arxiv.org/abs/2305.14461</guid>
  <link>http://arxiv.org/abs/2305.14461</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arroyuelo_D/0/1/0/all/0/1&quot;&gt;Diego Arroyuelo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carmona_G/0/1/0/all/0/1&quot;&gt;Gabriel Carmona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larranaga_H/0/1/0/all/0/1&quot;&gt;H&amp;#xe9;ctor Larra&amp;#xf1;aga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riveros_F/0/1/0/all/0/1&quot;&gt;Francisco Riveros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sepulveda_E/0/1/0/all/0/1&quot;&gt;Erick Sep&amp;#xfa;lveda&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Big-alphabet strings are common in several scenarios such as information
retrieval and natural-language processing. The efficient storage and processing
of such strings usually introduces several challenges that are not witnessed in
smaller-alphabets strings. This paper studies the efficient implementation of
one of the most effective approaches for dealing with big-alphabet strings,
namely the \emph{alphabet-partitioning} approach. The main contribution is a
compressed data structure that supports the fundamental operations rank and
select efficiently. We show experimental results that indicate that our
implementation outperforms the current realizations of the
alphabet-partitioning approach. In particular, the time for operation select
can be improved by about 80%, using only 11% more space than current
alphabet-partitioning schemes. We also show the impact of our data structure on
several applications, like the intersection of inverted lists (where
improvements of up to 60% are achieved, using only 2% of extra space), the
representation of run-length compressed strings, and the
distributed-computation processing of rank and select operations.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-25 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Deterministic Algorithmic Approaches to Solve Generalised Wordle</title>
  <guid>http://arxiv.org/abs/2305.14756</guid>
  <link>http://arxiv.org/abs/2305.14756</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lahiri_A/0/1/0/all/0/1&quot;&gt;Aditya Lahiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1&quot;&gt;Naigam Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1&quot;&gt;Shivaank Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nandakumar_V/0/1/0/all/0/1&quot;&gt;Vignesh Nandakumar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Wordle is a single-player word-based game where the objective is to guess the
5-letter word in a maximum of 6 tries. The game was released to the public in
October 2021 and has since gained popularity with people competing against each
other to maintain daily streaks and guess the word in a minimum number of
tries. There have been works using probabilistic and reinforcement learning
based approaches to solve the game. Our work aims to formulate and analyze
deterministic algorithms that can solve the game and minimize the number of
turns required to guess the word and do so for any generalized setting of the
game. As a simplifying assumption, for our analysis of all the algorithms we
present, we assume that all letters will be unique in any word which is part of
our vocabulary. We propose two algorithms to play Wordle - one a greedy based
approach, and other based on Cliques. The Greedy approach is applicable for
both hard and easy modes of Wordle, while the Clique formation based approach
only works on the Easy mode. We present our analysis on both approaches one by
one, next.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-25 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Theory Jobs 2023</title>
  <guid>http://grigory.github.io/blog/theory-jobs-2023</guid>
  <link>http://grigory.github.io/blog/theory-jobs-2023/</link>
  <description>
    &lt;p&gt;&lt;a href=&quot;https://docs.google.com/spreadsheets/d/1-_IMSqElpovmhKsOZTAZ92L3FHJTLmnmvqJSOXsSI-8/edit?usp=sharing&quot;&gt;Here is a link&lt;/a&gt; to a crowdsourced spreadsheet created to collect information about theory hires this year. 
Rules for the spreadsheet have been copied from previous years and all edits to the document are anonymized. Please, feel free to contact me directly or post a comment if you have any suggestions about the rules.&lt;/p&gt;
&lt;ul&gt;
 &lt;li&gt;You are welcome to add yourself, or people your department has hired. &lt;/li&gt;
 &lt;li&gt;Separate sheets for faculty, industry and postdocs/visitors. &lt;/li&gt;
 &lt;li&gt;Hires should be connected to theoretical computer science, broadly defined.&lt;/li&gt;
 &lt;li&gt;Only add jobs that you are &lt;b&gt;absolutely sure have been offered and accepted&lt;/b&gt;. This is not the place for speculation and rumors. Please, be particularly careful when adding senior hires (people who already have an academic or industrial job) -- end dates of their current positions might be still in the future. &lt;/li&gt;
&lt;/ul&gt;


  &lt;p&gt;&lt;a href=&quot;http://grigory.github.io/blog/theory-jobs-2023/&quot;&gt;Theory Jobs 2023&lt;/a&gt; was originally published by Grigory Yaroslavtsev at &lt;a href=&quot;http://grigory.github.io/blog&quot;&gt;The Big Data Theory&lt;/a&gt; on May 25, 2023.&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Grigory Yaroslavtsev&lt;/p&gt;
  </description>
  <pubDate>2023-05-25 00:00:00 UTC</pubDate>
  <author>Grigory Yaroslavtsev</author>
</item>

<item>
  <title>Congratulations, Dr. Frishberg!</title>
  <guid>https://11011110.github.io/blog/2023/05/24/congratulations-dr-frishberg</guid>
  <link>https://11011110.github.io/blog/2023/05/24/congratulations-dr-frishberg.html</link>
  <description>
    &lt;p&gt;My student &lt;a href=&quot;https://www.ics.uci.edu/~dfrishbe/&quot;&gt;Daniel Frishberg&lt;/a&gt; successfully passed his dissertation defense today!&lt;/p&gt;

&lt;p&gt;I’ve written here already about several of our joint papers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;“&lt;a href=&quot;/blog/2019/02/21/mutual-nearest-neighbors.html&quot;&gt;New applications of nearest-neighbor chains: Euclidean TSP and motorcycle graphs&lt;/a&gt;” (with Mamano, Efrat, Goodrich, Kobourov, Matias, and Polishchuk, &lt;a href=&quot;https://doi.org/10.4230/LIPIcs.ISAAC.2019.51&quot;&gt;ISAAC 2019&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;“&lt;a href=&quot;/blog/2019/01/29/simplifying-task-milestone.html&quot;&gt;Simplifying activity-on-edge graphs&lt;/a&gt; (with Havvaei, &lt;a href=&quot;https://doi.org/10.4230/LIPIcs.SWAT.2020.24&quot;&gt;SWAT 2020&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;“&lt;a href=&quot;/blog/2020/05/03/hanoi-vs-sierpinski.html&quot;&gt;On the treewidth of Hanoi graphs&lt;/a&gt;” (with Maxwell, &lt;a href=&quot;https://doi.org/10.4230/LIPIcs.FUN.2021.13&quot;&gt;FUN 2020&lt;/a&gt; and &lt;a href=&quot;https://doi.org/10.1016/j.tcs.2021.12.014&quot;&gt;&lt;em&gt;Theor. Comput. Sci.&lt;/em&gt; 2022&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;“&lt;a href=&quot;/blog/2021/07/10/angles-arc-triangles.html&quot;&gt;Angles of arc-polygons and Lombardi drawings of cacti&lt;/a&gt;” (with Osegueda, &lt;a href=&quot;https://projects.cs.dal.ca/cccg2021/wordpress/wp-content/uploads/2021/08/CCCG2021.pdf&quot;&gt;CCCG 2021&lt;/a&gt; and &lt;a href=&quot;https://doi.org/10.1016/j.comgeo.2023.101982&quot;&gt;&lt;em&gt;Comp. Geom. Theory &amp;amp; Applications&lt;/em&gt; 2023&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;“&lt;a href=&quot;/blog/2022/07/21/flipping-until-lost.html&quot;&gt;Improved mixing for the convex polygon triangulation flip walk&lt;/a&gt;” (ICALP 2023, to appear)&lt;/li&gt;
  &lt;li&gt;“&lt;a href=&quot;/blog/2021/11/14/random-independent-sets.html&quot;&gt;Rapid mixing of the hardcore Glauber dynamics and other Markov chains in bounded-treewidth graphs&lt;/a&gt;” (not yet published)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Several more are on the way but not yet announced. As is typical for our students, the earlier ones involved more of my intervention, the last two were mostly Daniel’s work, and I’m not even likely to be a coauthor on the upcoming ones: the pattern we want to see developing in a new doctorate. The dissertation incorporates the last two of the papers listed above. Most of our students combine three papers to form a dissertation, and the Hanoi graph work would have fit thematically, but just with the two Daniel included it already had plenty of material.&lt;/p&gt;

&lt;p&gt;The ICALP reviewers told us that we’ve been underselling one of the results in that paper, on the expansion of the associahedron, so I thought I’d elaborate on that a little more here. An &lt;a href=&quot;https://en.wikipedia.org/wiki/Associahedron&quot;&gt;associahedron&lt;/a&gt; is a graph whose vertices represent triangulations of a convex polygon (or binary search trees on a given set of keys) and whose edges represent “flips” that remove and replace one diagonal in a triangulation (or that perform a single binary tree rotation). There’s a lot we don’t know about associahedra still, including how to calculate shortest paths (“flip distance”) between vertices efficiently.&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;/blog/assets/2006/fg6.png&quot; alt=&quot;Flip graph of a hexagon&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The version of expansion we’re using is &lt;a href=&quot;https://en.wikipedia.org/wiki/Expander_graph&quot;&gt;edge expansion&lt;/a&gt;,&lt;/p&gt;

\[\min_{X\subset V(G)}\frac{\vert\partial X\vert}{\min(\vert X\vert,\vert V(G)\setminus X\vert)},\]

&lt;p&gt;where \(\partial X\) represents the set of edges having one endpoint in \(X\). There are many other graphs of local moves in state spaces that, like the associahedron, can also be given the structure of the vertices and edges of a convex polytope, and in many such cases these have constant expansion. In fact, Milena Mihail and Umesh Vazirani conjectured some time prior to 1992 that every polytope whose vertex coordinates are all 0 or 1 has expansion at least one (for this history see e.g. Kaibel, “On the Expansion of
Graphs of 0/1-Polytopes”, &lt;a href=&quot;https://arxiv.org/abs/math/0112146&quot;&gt;arXiv:math/0112146&lt;/a&gt;), and it was a big breakthrough in 2018 when &lt;a href=&quot;https://gilkalai.wordpress.com/2018/12/12/nima-anari-kuikui-liu-shayan-oveis-gharan-and-cynthia-vinzant-solved-the-mihail-vazirani-conjecture/&quot;&gt;Nima Anari, Kuikui Liu, Shayan Oveis Gharan, and Cynthia Vinzant proved it for flip graphs of matroids&lt;/a&gt; (&lt;a href=&quot;https://arxiv.org/abs/1811.01816&quot;&gt;arXiv:1811.01816&lt;/a&gt;). The associahedra are not 0-1 polytopes, but one can still ask what their expansion is. The ICALP paper gets within a logarithmic factor of the right answer: it proves that the expansion is \(\Omega\bigl(1/(\sqrt n\log n)\bigr)\) and \(O(1/\sqrt n)\). The lower bound is the part that fits into the machinery of Daniel’s thesis, but it is the upper bound that the referees told us we were underselling. It is the first time we have seen that the expansion of the associahedron is smaller than a constant.&lt;/p&gt;

&lt;p&gt;To prove this upper bound (in appendix C of &lt;a href=&quot;https://arxiv.org/abs/2207.09972&quot;&gt;arXiv:2207.09972&lt;/a&gt;), we merely have to find a partition of the space of all triangulations into two subsets with few edges connecting them. This partition is defined very simply, as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For each triangulation, look at the triangle containing the center point of the polygon.&lt;/li&gt;
  &lt;li&gt;This triangle has three sides. Define their “length” combinatorially, as the number of polygon sides they cut off. Thus, the three lengths sum to \(n\), and the shortest is at most \(n/3\).&lt;/li&gt;
  &lt;li&gt;Put a triangulation into one side of the partition when its central triangle has a very short side, of length less than \(n/6\), and into the other side of the partition otherwise.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are always three flips that move one of the vertices of the central triangle, unless the short side is only one edge long. But short motions of these vertices are likelier than long ones, enough so to keep the expansion small. The details involve doing some sums with Catalan numbers.&lt;/p&gt;

&lt;p&gt;The next step for Daniel will be to start an assistant professor position at Cal Poly in San Luis Obispo in the fall.&lt;/p&gt;

&lt;p&gt;Congratulations, Daniel!&lt;/p&gt;

&lt;p&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/110427368041366794&quot;&gt;Discuss on Mastodon&lt;/a&gt;)&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </description>
  <pubDate>2023-05-24 21:06:00 UTC</pubDate>
  <author>David Eppstein</author>
</item>

<item>
  <title>TR23-076 |  Polynomial-Time Pseudodeterministic Construction of Primes | 

	Lijie Chen, 

	Zhenjian Lu, 

	Igor Carboni Oliveira, 

	Hanlin Ren, 

	Rahul Santhanam</title>
  <guid>https://eccc.weizmann.ac.il/report/2023/076</guid>
  <link>https://eccc.weizmann.ac.il/report/2023/076</link>
  <description>
    A randomized algorithm for a search problem is *pseudodeterministic* if it produces a fixed canonical solution to the search problem with high probability. In their seminal work on the topic, Gat and Goldwasser posed as their main open problem whether prime numbers can be pseudodeterministically constructed in polynomial time. 

We provide a positive solution to this question in the infinitely-often regime. In more detail, we give an *unconditional* polynomial-time randomized algorithm $B$ such that, for infinitely many values of $n$, $B(1^n)$ outputs a canonical $n$-bit prime $p_n$ with high probability. More generally, we prove that for every dense property $Q$ of strings that can be decided in polynomial time, there is an infinitely-often pseudodeterministic polynomial-time construction of strings satisfying $Q$. This improves upon a subexponential-time construction of Oliveira and Santhanam.  

Our construction uses several new ideas, including a novel bootstrapping technique for pseudodeterministic constructions, and a quantitative optimization of the uniform hardness-randomness framework of Chen and Tell, using a variant of the Shaltiel--Umans generator.
  </description>
  <pubDate>2023-05-24 13:56:30 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>On the number of tangencies among 1-intersecting curves</title>
  <guid>http://arxiv.org/abs/2305.13807</guid>
  <link>http://arxiv.org/abs/2305.13807</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ackerman_E/0/1/0/all/0/1&quot;&gt;Eyal Ackerman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Keszegh_B/0/1/0/all/0/1&quot;&gt;Bal&amp;#xe1;zs Keszegh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $\cal C$ be a set of curves in the plane such that no three curves in
$\cal C$ intersect at a single point and every pair of curves in $\cal C$
intersect at exactly one point which is either a crossing or a touching point.
According to a conjecture of J\&#39;anos Pach the number of pairs of curves in
$\cal C$ that touch each other is $O(|{\cal C}|)$. We prove this conjecture for
$x$-monotone curves.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-24 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Error-Tolerant Exact Query Learning of Finite Set Partitions with Same-Cluster Oracle</title>
  <guid>http://arxiv.org/abs/2305.13402</guid>
  <link>http://arxiv.org/abs/2305.13402</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DePavia_A/0/1/0/all/0/1&quot;&gt;Adela Frances DePavia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campo_O/0/1/0/all/0/1&quot;&gt;Olga Medrano Mart&amp;#xed;n del Campo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tani_E/0/1/0/all/0/1&quot;&gt;Erasmo Tani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper initiates the study of active learning for exact recovery of
partitions exclusively through access to a same-cluster oracle in the presence
of bounded adversarial error. We first highlight a novel connection between
learning partitions and correlation clustering. Then we use this connection to
build a R\&#39;enyi-Ulam style analytical framework for this problem, and prove
upper and lower bounds on its worst-case query complexity. Further, we bound
the expected performance of a relevant randomized algorithm. Finally, we study
the relationship between adaptivity and query complexity for this problem and
related variants.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-24 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Differentially Private Medians and Interior Points for Non-Pathological Data</title>
  <guid>http://arxiv.org/abs/2305.13440</guid>
  <link>http://arxiv.org/abs/2305.13440</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aliakbarpour_M/0/1/0/all/0/1&quot;&gt;Maryam Aliakbarpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silver_R/0/1/0/all/0/1&quot;&gt;Rose Silver&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1&quot;&gt;Thomas Steinke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ullman_J/0/1/0/all/0/1&quot;&gt;Jonathan Ullman&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We construct differentially private estimators with low sample complexity
that estimate the median of an arbitrary distribution over $\mathbb{R}$
satisfying very mild moment conditions. Our result stands in contrast to the
surprising negative result of Bun et al. (FOCS 2015) that showed there is no
differentially private estimator with any finite sample complexity that returns
any non-trivial approximation to the median of an arbitrary distribution.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-24 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>The First Proven Performance Guarantees for the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) on a Combinatorial Optimization Problem</title>
  <guid>http://arxiv.org/abs/2305.13459</guid>
  <link>http://arxiv.org/abs/2305.13459</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cerf_S/0/1/0/all/0/1&quot;&gt;Sacha Cerf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1&quot;&gt;Benjamin Doerr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hebras_B/0/1/0/all/0/1&quot;&gt;Benjamin Hebras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahane_Y/0/1/0/all/0/1&quot;&gt;Yakob Kahane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wietheger_S/0/1/0/all/0/1&quot;&gt;Simon Wietheger&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Non-dominated Sorting Genetic Algorithm-II (NSGA-II) is one of the most
prominent algorithms to solve multi-objective optimization problems. Recently,
the first mathematical runtime guarantees have been obtained for this
algorithm, however only for synthetic benchmark problems.
&lt;/p&gt;
&lt;p&gt;In this work, we give the first proven performance guarantees for a classic
optimization problem, the NP-complete bi-objective minimum spanning tree
problem. More specifically, we show that the NSGA-II with population size $N
\ge 4((n-1) w_{\max} + 1)$ computes all extremal points of the Pareto front in
an expected number of $O(m^2 n w_{\max} \log(n w_{\max}))$ iterations, where
$n$ is the number of vertices, $m$ the number of edges, and $w_{\max}$ is the
maximum edge weight in the problem instance. This result confirms, via
mathematical means, the good performance of the NSGA-II observed empirically.
It also shows that mathematical analyses of this algorithm are not only
possible for synthetic benchmark problems, but also for more complex
combinatorial optimization problems.
&lt;/p&gt;
&lt;p&gt;As a side result, we also obtain a new analysis of the performance of the
global SEMO algorithm on the bi-objective minimum spanning tree problem, which
improves the previous best result by a factor of $|F|$, the number of extremal
points of the Pareto front, a set that can be as large as $n w_{\max}$. The
main reason for this improvement is our observation that both multi-objective
evolutionary algorithms find the different extremal points in parallel rather
than sequentially, as assumed in the previous proofs.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-24 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Single-Pass Pivot Algorithm for Correlation Clustering. Keep it simple!</title>
  <guid>http://arxiv.org/abs/2305.13560</guid>
  <link>http://arxiv.org/abs/2305.13560</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakrabarty_S/0/1/0/all/0/1&quot;&gt;Sayak Chakrabarty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makarychev_K/0/1/0/all/0/1&quot;&gt;Konstantin Makarychev&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that a simple single-pass semi-streaming variant of the Pivot
algorithm for Correlation Clustering gives a (3 + {\epsilon})-approximation
using O(n/{\epsilon}) words of memory. This is a slight improvement over the
recent results of Cambus, Kuhn, Lindy, Pai, and Uitto, who gave a (3 +
{\epsilon})-approximation using O(n log n) words of memory, and Behnezhad,
Charikar, Ma, and Tan, who gave a 5-approximation using O(n) words of memory.
One of the main contributions of this paper is that both the algorithm and its
analysis are very simple, and also the algorithm is easy to implement.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-24 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Parameterized Complexity Classification for Interval Constraints</title>
  <guid>http://arxiv.org/abs/2305.13889</guid>
  <link>http://arxiv.org/abs/2305.13889</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dabrowski_K/0/1/0/all/0/1&quot;&gt;Konrad K. Dabrowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jonsson_P/0/1/0/all/0/1&quot;&gt;Peter Jonsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ordyniak_S/0/1/0/all/0/1&quot;&gt;Sebastian Ordyniak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osipov_G/0/1/0/all/0/1&quot;&gt;George Osipov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1&quot;&gt;Marcin Pilipczuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1&quot;&gt;Roohani Sharma&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Constraint satisfaction problems form a nicely behaved class of problems that
lends itself to complexity classification results. From the point of view of
parameterized complexity, a natural task is to classify the parameterized
complexity of MinCSP problems parameterized by the number of unsatisfied
constraints. In other words, we ask whether we can delete at most $k$
constraints, where $k$ is the parameter, to get a satisfiable instance. In this
work, we take a step towards classifying the parameterized complexity for an
important infinite-domain CSP: Allen&#39;s interval algebra (IA). This CSP has
closed intervals with rational endpoints as domain values and employs a set $A$
of 13 basic comparison relations such as ``precedes&#39;&#39; or ``during&#39;&#39; for
relating intervals. IA is a highly influential and well-studied formalism
within AI and qualitative reasoning that has numerous applications in, for
instance, planning, natural language processing and molecular biology. We
provide an FPT vs. W[1]-hard dichotomy for MinCSP$(\Gamma)$ for all $\Gamma
\subseteq A$. IA is sometimes extended with unions of the relations in $A$ or
first-order definable relations over $A$, but extending our results to these
cases would require first solving the parameterized complexity of Directed
Symmetric Multicut, which is a notorious open problem. Already in this limited
setting, we uncover connections to new variants of graph cut and separation
problems. This includes hardness proofs for simultaneous cuts or feedback arc
set problems in directed graphs, as well as new tractable cases with algorithms
based on the recently introduced flow augmentation technique. Given the
intractability of MinCSP$(A)$ in general, we then consider (parameterized)
approximation algorithms and present a factor-$2$ fpt-approximation algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-24 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Early Theory</title>
  <guid>https://rjlipton.wpcomstaging.com/?p=21638</guid>
  <link>https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/</link>
  <description>
    &lt;p&gt;
&lt;font color=&quot;#0044cc&quot;&gt;&lt;br /&gt;
&lt;em&gt;&amp;#8220;Everything is interesting&amp;#8221;&lt;/em&gt;&lt;br /&gt;
&lt;font color=&quot;#000000&quot;&gt;&lt;/p&gt;
&lt;p&gt;
Susan Graham is a Distinguished Professor of Electrical Engineering and Computer Science Emerita at the University of California, Berkeley. I have known Graham for decades&amp;#8212;and am happy to report she is still active. &lt;/p&gt;
&lt;p&gt;
She was a &lt;a href=&quot;https://obamawhitehouse.archives.gov/administration/eop/ostp/pcast/about/members&quot;&gt;member&lt;/a&gt; of the President&amp;#8217;s Council of Advisors on Science and Technology (PCAST) during the Obama Administration. She served alongside Bill Press of Austin, who is &lt;a href=&quot;https://obamawhitehouse.archives.gov/administration/eop/ostp/pcast/about/members&quot;&gt;still&lt;/a&gt; on PCAST&amp;#8212;alongside Terry Tao among names we know. &lt;/p&gt;
&lt;p&gt;
Graham has maintained involvements in the performing arts. She is an &lt;a href=&quot;https://calperformances.org/about/trustees/&quot;&gt;Officer&lt;/a&gt; on the Board of Trustees of &lt;a href=&quot;https://calperformances.org/&quot;&gt;Cal Performances&lt;/a&gt;. She also served on the Board of Overseers of the Curtis Institute of Music in Philadelphia until they reorganized in 2016. She has also had a long association with Harvard, She was referring to committee memberships when she was &lt;a href=&quot;https://www.harvardmagazine.com/2011/09/and-then-there-were-10&quot;&gt;quoted&lt;/a&gt; for the subtitle above, but her words &amp;#8220;everything is interesting&amp;#8221; apply more widely in our field.&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/sg-2/&quot; rel=&quot;attachment wp-att-21640&quot;&gt;&lt;img data-attachment-id=&quot;21640&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/sg-2/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?fit=200%2C200&amp;amp;ssl=1&quot; data-orig-size=&quot;200,200&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;sg&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?fit=200%2C200&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?fit=200%2C200&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?resize=200%2C200&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;200&quot; class=&quot;aligncenter size-full wp-image-21640&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?w=200&amp;amp;ssl=1 200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?resize=150%2C150&amp;amp;ssl=1 150w&quot; sizes=&quot;(max-width: 200px) 100vw, 200px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Her Work &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Graham has done seminal research in compiler code generation and optimization. She was elected a member of the National Academy of Engineering in 1993 for contributions to the theory and practice of compiler construction and for leadership in the computer science community. And was awarded the 2009 IEEE John von Neumann Medal for &amp;#8220;contributions to programming language design and implementation and for exemplary service to the discipline of computer science.&amp;#8221;&lt;/p&gt;
&lt;p&gt;
The nexus with programming languages was arguably &lt;em&gt;the&lt;/em&gt; initial focus of computer science theory in the years before 1965, when Juris Hartmanis and Richard Stearns founded computational complexity on Turing machines. See the &lt;a href=&quot;https://cs.brown.edu/people/jsavage/papers/09_ch5.pdf&quot;&gt;history&lt;/a&gt; penned by John Savage, Alan Selman, and Carl Smith for a neat summary. &lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/jsascs/&quot; rel=&quot;attachment wp-att-21641&quot;&gt;&lt;img data-attachment-id=&quot;21641&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/jsascs/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?fit=546%2C191&amp;amp;ssl=1&quot; data-orig-size=&quot;546,191&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;JSASCS&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?fit=300%2C105&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?fit=546%2C191&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?resize=362%2C128&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;362&quot; height=&quot;128&quot; class=&quot;aligncenter wp-image-21641&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?w=546&amp;amp;ssl=1 546w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?resize=300%2C105&amp;amp;ssl=1 300w&quot; sizes=&quot;(max-width: 362px) 100vw, 362px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
They point out:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; After the early recognition of the relevance of the theory of formal languages to the practice of compiler construction, theoretical computer science became a cornerstone of virtually every computer science undergraduate degree program. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Susan&amp;#8217;s first &lt;a href=&quot;https://ieeexplore.ieee.org/document/4569647&quot;&gt;paper&lt;/a&gt; appeared at the conference now named FOCS in 1970. It was titled, &amp;#8220;Extended Precedence Languages, Bounded Right Context Languages, and Deterministic Languages.&amp;#8221; Rather than invent a new complexity class, as even ChatGPT picked up on our common vice &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/04/01/the-chatgpt-conundrum/&quot;&gt;recently&lt;/a&gt;, she more economically collapsed some classes together. &lt;/p&gt;
&lt;p&gt;
The combination of &amp;#8220;theoretical and practical interest&amp;#8221; as mentioned in her paper carried through to much other work in programming languages and their implementations, software tools and development environments, and needs of high-performance computing. Her work with students on the Berkeley Unix project led to their &lt;a href=&quot;https://docs-archive.freebsd.org/44doc/psd/18.gprof/paper.pdf&quot;&gt;paper&lt;/a&gt; on the program profiling tool &lt;a href=&quot;https://en.wikipedia.org/wiki/Gprof&quot;&gt;gprof&lt;/a&gt;. This is considered one of the classic papers from the Programming Language Design and Implementation (PLDI) conferences.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Graham is terrific. I only hope that she is able to help us better understand theory of all types. &lt;/p&gt;
&lt;p&gt;
&lt;p class=&quot;authors&quot;&gt;By rjlipton&lt;/p&gt;
  </description>
  <pubDate>2023-05-23 02:48:30 UTC</pubDate>
  <author>Richard Lipton</author>
</item>

<item>
  <title>Nearly Optimal Algorithms for Testing and Learning Quantum Junta Channels</title>
  <guid>http://arxiv.org/abs/2305.12097</guid>
  <link>http://arxiv.org/abs/2305.12097</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bao_Z/0/1/0/all/0/1&quot;&gt;Zongbo Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yao_P/0/1/0/all/0/1&quot;&gt;Penghui Yao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problems of testing and learning quantum $k$-junta channels,
which are $n$-qubit to $n$-qubit quantum channels acting non-trivially on at
most $k$ out of $n$ qubits and leaving the rest of qubits unchanged. We show
the following.
&lt;/p&gt;
&lt;p&gt;1. An $\widetilde{O}\left(\sqrt{k}\right)$-query algorithm to distinguish
whether the given channel is $k$-junta channel or is far from any $k$-junta
channels, and a lower bound $\Omega\left(\sqrt{k}\right)$ on the number of
queries;
&lt;/p&gt;
&lt;p&gt;2. An $\widetilde{O}\left(4^k\right)$-query algorithm to learn a $k$-junta
channel, and a lower bound $\Omega\left(4^k/k\right)$ on the number of queries.
&lt;/p&gt;
&lt;p&gt;This answers an open problem raised by Chen et al. (2023). In order to settle
these problems, we develop a Fourier analysis framework over the space of
superoperators and prove several fundamental properties, which extends the
Fourier analysis over the space of operators introduced in Montanaro and
Osborne (2010).
&lt;/p&gt;
  </description>
  <pubDate>2023-05-23 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>On the approximability and energy-flow modeling of the electric vehicle sharing problem</title>
  <guid>http://arxiv.org/abs/2305.12176</guid>
  <link>http://arxiv.org/abs/2305.12176</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_W/0/1/0/all/0/1&quot;&gt;Welverton R. Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Usberti_F/0/1/0/all/0/1&quot;&gt;F&amp;#xe1;bio L. Usberti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schouery_R/0/1/0/all/0/1&quot;&gt;Rafael C. S. Schouery&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The electric vehicle sharing problem (EVSP) arises from the planning and
operation of one-way electric car-sharing systems. It aims to maximize the
total rental time of a fleet of electric vehicles while ensuring that all the
demands of the customer are fulfilled. In this paper, we expand the knowledge
on the complexity of the EVSP by showing that it is NP-hard to approximate it
to within a factor of $n^{1-\epsilon}$ in polynomial time, for any $\epsilon &amp;gt;
0$, where $n$ denotes the number of customers, unless P = NP. In addition, we
also show that the problem does not have a monotone structure, which can be
detrimental to the development of heuristics employing constructive strategies.
Moreover, we propose a novel approach for the modeling of the EVSP based on
energy flows in the network. Based on the new model, we propose a relax-and-fix
strategy and an exact algorithm that uses a warm-start solution obtained from
our heuristic approach. We report computational results comparing our
formulation with the best-performing formulation in the literature. The results
show that our formulation outperforms the previous one concerning the number of
optimal solutions obtained, optimality gaps, and computational times.
Previously, $32.7\%$ of the instances remained unsolved (within a time limit of
one hour) by the best-performing formulation in the literature, while our
formulation obtained optimal solutions for all instances. To stress our
approaches, two more challenging new sets of instances were generated, for
which we were able to solve $49.5\%$ of the instances, with an average
optimality gap of $2.91\%$ for those not solved optimally.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-23 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>OPTWIN: Drift identification with optimal sub-windows</title>
  <guid>http://arxiv.org/abs/2305.11942</guid>
  <link>http://arxiv.org/abs/2305.11942</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tosi_M/0/1/0/all/0/1&quot;&gt;Mauro Dalle Lucca Tosi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Theobald_M/0/1/0/all/0/1&quot;&gt;Martin Theobald&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Online Learning (OL) is a field of research that is increasingly gaining
attention both in academia and industry. One of the main challenges of OL is
the inherent presence of concept drifts, which are commonly defined as
unforeseeable changes in the statistical properties of an incoming data stream
over time. The detection of concept drifts typically involves analyzing the
error rates produced by an underlying OL algorithm in order to identify if a
concept drift occurred or not, such that the OL algorithm can adapt
accordingly. Current concept-drift detectors perform very well, i.e., with low
false negative rates, but they still tend to exhibit high false positive rates
in the concept-drift detection. This may impact the performance of the learner
and result in an undue amount of computational resources spent on retraining a
model that actually still performs within its expected range. In this paper, we
propose OPTWIN, our &quot;OPTimal WINdow&quot; concept drift detector. OPTWIN uses a
sliding window of events over an incoming data stream to track the errors of an
OL algorithm. The novelty of OPTWIN is to consider both the means and the
variances of the error rates produced by a learner in order to split the
sliding window into two provably optimal sub-windows, such that the split
occurs at the earliest event at which a statistically significant difference
according to either the $t$- or the $f$-tests occurred. We assessed OPTWIN over
the MOA framework, using ADWIN, DDM, EDDM, STEPD and ECDD as baselines over 7
synthetic and real-world datasets, and in the presence of both sudden and
gradual concept drifts. In our experiments, we show that OPTWIN surpasses the
F1-score of the baselines in a statistically significant manner while
maintaining a lower detection delay and saving up to 21% of time spent on
retraining the models.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-23 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Stretch-width</title>
  <guid>http://arxiv.org/abs/2305.12023</guid>
  <link>http://arxiv.org/abs/2305.12023</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1&quot;&gt;&amp;#xc9;douard Bonnet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duron_J/0/1/0/all/0/1&quot;&gt;Julien Duron&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce a new parameter, called stretch-width, that we show sits
strictly between clique-width and twin-width. Unlike the reduced parameters
[BKW &#39;22], planar graphs and polynomial subdivisions do not have bounded
stretch-width. This leaves open the possibility of efficient algorithms for a
broad fragment of problems within Monadic Second-Order (MSO) logic on graphs of
bounded stretch-width. In this direction, we prove that graphs of bounded
maximum degree and bounded stretch-width have at most logarithmic treewidth. As
a consequence, in classes of bounded stretch-width, Maximum Independent Set can
be solved in subexponential time $2^{O(n^{4/5} \log n)}$ on $n$-vertex graphs,
and, if further the maximum degree is bounded, Existential Counting Modal Logic
[Pilipczuk &#39;11] can be model-checked in polynomial time. We also give a
polynomial-time $O(\text{OPT}^2)$-approximation for the stretch-width of
symmetric $0,1$-matrices or ordered graphs. Somewhat unexpectedly, we prove
that exponential subdivisions of bounded-degree graphs have bounded
stretch-width. This allows to complement the logarithmic upper bound of
treewidth with a matching lower bound. We leave as open the existence of an
efficient approximation algorithm for the stretch-width of unordered graphs, if
the exponential subdivisions of all graphs have bounded stretch-width, and if
graphs of bounded stretch-width have logarithmic clique-width (or rank-width).
&lt;/p&gt;
  </description>
  <pubDate>2023-05-23 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Distortion in metric matching with ordinal preferences</title>
  <guid>http://arxiv.org/abs/2305.12119</guid>
  <link>http://arxiv.org/abs/2305.12119</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anari_N/0/1/0/all/0/1&quot;&gt;Nima Anari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charikar_M/0/1/0/all/0/1&quot;&gt;Moses Charikar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramakrishnan_P/0/1/0/all/0/1&quot;&gt;Prasanna Ramakrishnan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Suppose that we have $n$ agents and $n$ items which lie in a shared metric
space. We would like to match the agents to items such that the total distance
from agents to their matched items is as small as possible. However, instead of
having direct access to distances in the metric, we only have each agent&#39;s
ranking of the items in order of distance. Given this limited information, what
is the minimum possible worst-case approximation ratio (known as the
distortion) that a matching mechanism can guarantee?
&lt;/p&gt;
&lt;p&gt;Previous work by Caragiannis et al. proved that the (deterministic) Serial
Dictatorship mechanism has distortion at most $2^n - 1$. We improve this by
providing a simple deterministic mechanism that has distortion $O(n^2)$. We
also provide the first nontrivial lower bound on this problem, showing that any
matching mechanism (deterministic or randomized) must have worst-case
distortion $\Omega(\log n)$.
&lt;/p&gt;
&lt;p&gt;In addition to these new bounds, we show that a large class of truthful
mechanisms derived from Deferred Acceptance all have worst-case distortion at
least $2^n - 1$, and we find an intriguing connection between thin matchings
(analogous to the well-known thin trees conjecture) and the distortion gap
between deterministic and randomized mechanisms.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-23 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Perspective on complexity measures targetting read-once branching programs</title>
  <guid>http://arxiv.org/abs/2305.11276</guid>
  <link>http://arxiv.org/abs/2305.11276</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yaqiao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McKenzie_P/0/1/0/all/0/1&quot;&gt;Pierre McKenzie&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A model of computation for which reasonable yet still incomplete lower bounds
are known is the read-once branching program. Here variants of complexity
measures successful in the study of read-once branching programs are defined
and studied. Some new or simpler proofs of known bounds are uncovered.
Branching program resources and the new measures are compared extensively. The
new variants are developed in part in the hope of tackling read-k branching
programs for the tree evaluation problem studied in Cook et al. Other
computation problems are studied as well. In particular, a common view of a
function studied by Gal and a function studied by Bollig and Wegener leads to
the general combinatorics of blocking sets. Technical combinatorial results of
independent interest are obtained. New leads towards further progress are
discussed. An exponential lower bound for non-deterministic read-k branching
programs for the GEN function is also derived, independently from the new
measures.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-22 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Making $\textsf{IP}=\textsf{PSPACE}$ Practical: Efficient Interactive Protocols for BDD Algorithms</title>
  <guid>http://arxiv.org/abs/2305.11813</guid>
  <link>http://arxiv.org/abs/2305.11813</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Couillard_E/0/1/0/all/0/1&quot;&gt;Eszter Couillard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Czerner_P/0/1/0/all/0/1&quot;&gt;Philipp Czerner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esparza_J/0/1/0/all/0/1&quot;&gt;Javier Esparza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumdar_R/0/1/0/all/0/1&quot;&gt;Rupak Majumdar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that interactive protocols between a prover and a verifier, a
well-known tool of complexity theory, can be used in practice to certify the
correctness of automated reasoning tools.
&lt;/p&gt;
&lt;p&gt;Theoretically, interactive protocols exist for all $\textsf{PSPACE}$
problems. The verifier of a protocol checks the prover&#39;s answer to a problem
instance in polynomial time, with polynomially many bits of communication, and
with exponentially small probability of error. (The prover may need exponential
time.) Existing interactive protocols are not used in practice because their
provers use naive algorithms, inefficient even for small instances, that are
incompatible with practical implementations of automated reasoning.
&lt;/p&gt;
&lt;p&gt;We bridge the gap between theory and practice by means of a novel interactive
protocol whose prover uses BDDs. We consider the problem of counting the number
of assignments to a QBF instance ($\#\textrm{CP}$), which has a natural
BDD-based algorithm. We give an interactive protocol for $\#\textrm{CP}$ whose
prover is implemented on top of an extended BDD library. The prover has only a
linear overhead in computation time over the natural algorithm.
&lt;/p&gt;
&lt;p&gt;We have implemented our protocol in $\textsf{blic}$, a certifying tool for
$\#\textrm{CP}$. Experiments on standard QBF benchmarks show that \blic\ is
competitive with state-of-the-art QBF-solvers. The run time of the verifier is
negligible. While loss of absolute certainty can be concerning, the error
probability in our experiments is at most $10^{-10}$ and reduces to $10^{-10k}$
by repeating the verification $k$ times.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-22 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Complexity of Neural Network Training and ETR: Extensions with Effectively Continuous Functions</title>
  <guid>http://arxiv.org/abs/2305.11833</guid>
  <link>http://arxiv.org/abs/2305.11833</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hankala_T/0/1/0/all/0/1&quot;&gt;Teemu Hankala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hannula_M/0/1/0/all/0/1&quot;&gt;Miika Hannula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kontinen_J/0/1/0/all/0/1&quot;&gt;Juha Kontinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Virtema_J/0/1/0/all/0/1&quot;&gt;Jonni Virtema&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the complexity of the problem of training neural networks defined
via various activation functions. The training problem is known to be
existsR-complete with respect to linear activation functions and the ReLU
activation function. We consider the complexity of the problem with respect to
the sigmoid activation function and other effectively continuous functions. We
show that these training problems are polynomial-time many-one bireducible to
the existential theory of the reals extended with the corresponding activation
functions. In particular, we establish that the sigmoid activation function
leads to the existential theory of the reals with the exponential function. It
is thus open, and equivalent with the decidability of the existential theory of
the reals with the exponential function, whether training neural networks using
the sigmoid activation function is algorithmically solvable. In contrast, we
obtain that the training problem is undecidable if sinusoidal activation
functions are considered. Finally, we obtain general upper bounds for the
complexity of the training problem in the form of low levels of the
arithmetical hierarchy.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-22 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Engineering an algorithm for constructing low-stretch geometric graphs with near-greedy average-degrees</title>
  <guid>http://arxiv.org/abs/2305.11312</guid>
  <link>http://arxiv.org/abs/2305.11312</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shariful_F/0/1/0/all/0/1&quot;&gt;FNU Shariful&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weathers_J/0/1/0/all/0/1&quot;&gt;Justin Weathers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1&quot;&gt;Anirban Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narasimhan_G/0/1/0/all/0/1&quot;&gt;Giri Narasimhan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We design and engineer Fast-Sparse-Spanner, a simple and practical (fast and
memory-efficient) algorithm for constructing sparse low stretch-factor
geometric graphs on large pointsets in the plane. To our knowledge, this is the
first practical algorithm to construct fast low stretch-factor graphs on large
pointsets with average-degrees (hence, the number of edges) competitive with
that of greedy-spanners, the sparsest known class of Euclidean geometric
spanners.
&lt;/p&gt;
&lt;p&gt;To evaluate our implementation in terms of computation speed, memory usage,
and quality of output, we performed extensive experiments with synthetic and
real-world pointsets, and by comparing it to our closest competitor Bucketing,
the fastest known greedy-spanner algorithm for pointsets in the plane, devised
by Alewijnse et al. (Algorithmica, 2017). We always found that
Fast-Sparse-Spanner generated near-greedy t-spanners while being fast and
memory-efficient. Our experiment with constructing a 1.1-spanner on a large
synthetic pointset with 128K points uniformly distributed within a square shows
more than a 41-fold speedup with roughly a third of the memory usage of that of
Bucketing, but with only a 3% increase in the average-degree of the resulting
graph. In terms of diameter, the graphs generated by Fast-Sparse-Spanner beat
greedy-spanners in most cases (have substantially lower diameter) while
maintaining near-greedy average-degree.
&lt;/p&gt;
&lt;p&gt;As a byproduct of our research, we design and engineer Fast-Stretch-Factor, a
practical parallelizable algorithm that can measure the stretch-factor of any
graph generated by Fast-Sparse-Spanner. Our experiments show that it is much
faster than the naive Dijkstra-based stretch-factor measurement algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-22 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Advancing Front Mapping</title>
  <guid>http://arxiv.org/abs/2305.11552</guid>
  <link>http://arxiv.org/abs/2305.11552</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Livesu_M/0/1/0/all/0/1&quot;&gt;Marco Livesu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present Advancing Front Mapping (AFM), a provably robust algorithm for the
computation of surface mappings to simple base domains. Given an input mesh and
a convex or star-shaped target domain, AFM installs a (possibly refined)
version of the input connectivity into the target shape, generating a
piece-wise linear mapping between them. The algorithm is inspired by the
advancing front meshing paradigm, which is revisited to operate on two
embeddings at once, thus becoming a tool for compatible mesh generation. AFM
extends the capabilities of existing robust approaches, such as Tutte or
Progressive Embedding, by providing the same theoretical guarantees of
injectivity and at the same time introducing two key advantages: support for a
broader set of target domains (star-shaped polygons) and local mesh refinement,
which is used to automatically open the space of solutions in case a valid
mapping to the target domain does not exist. AFM relies solely on two
topological operators (triangle split and flip) and on the computation of
segment intersections, thus permitting to compute provably injective mappings
without solving any numerical problem. This makes the algorithm predictable and
easy to implement, debug and deploy. We validated the capabilities of AFM by
testing it on 36K input cases, showing that its theoretical guarantees nicely
transition to a robust and practical implementation.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-22 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Improved and Partially-Tight Lower Bounds for Message-Passing Implementations of Multiplicity Queues</title>
  <guid>http://arxiv.org/abs/2305.11286</guid>
  <link>http://arxiv.org/abs/2305.11286</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_A/0/1/0/all/0/1&quot;&gt;Anh Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talmage_E/0/1/0/all/0/1&quot;&gt;Edward Talmage&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A multiplicity queue is a concurrently-defined data type which relaxes the
conditions of a linearizable FIFO queue to allow concurrent Dequeue instances
to return the same value. It would seem that this should allow faster
implementations, as processes should not need to wait as long to learn about
concurrent operations at remote processes and previous work has shown that
multiplicity queues are computationally less complex than the unrelaxed
version. Intriguingly, recent work has shown that there is, in fact, not much
speedup possible versus an unrelaxed queue implementation. Seeking to
understand this difference between intuition and real behavior, we extend that
work, increasing the lower bound for uniform algorithms. Further, we outline a
path forward toward building proofs for even higher lower bounds, allowing us
to hypothesize that the worst-case time to Dequeue approaches maximum message
delay, which is similar to the time required for an unrelaxed Dequeue. We also
give an upper bound for a special case to show that our bounds are tight at
that point. To achieve our lower bounds, we use extended shifting arguments,
which have been rarely used but allow larger lower bounds than traditional
shifting arguments. We use these in series of inductive indistinguishability
proofs which allow us to extend our proofs beyond the usual limitations of
shifting arguments. This proof structure is an interesting contribution
independently of the main result, as developing new lower bound proof
techniques may have many uses in future work.
&lt;/p&gt;
  </description>
  <pubDate>2023-05-22 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

</channel>
</rss>
