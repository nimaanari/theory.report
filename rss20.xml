<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>Parameterized Approaches to Orthogonal Compaction</title>
  <guid>http://arxiv.org/abs/2210.05019</guid>
  <link>http://arxiv.org/abs/2210.05019</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Didimo_W/0/1/0/all/0/1&quot;&gt;Walter Didimo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Siddharth Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kindermann_P/0/1/0/all/0/1&quot;&gt;Philipp Kindermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liotta_G/0/1/0/all/0/1&quot;&gt;Giuseppe Liotta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolff_A/0/1/0/all/0/1&quot;&gt;Alexander Wolff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zehavi_M/0/1/0/all/0/1&quot;&gt;Meirav Zehavi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Orthogonal graph drawings are used in applications such as UML diagrams, VLSI
layout, cable plans, and metro maps. We focus on drawing planar graphs and
assume that we are given an \emph{orthogonal representation} that describes the
desired shape, but not the exact coordinates of a drawing. Our aim is to
compute an orthogonal drawing on the grid that has minimum area among all grid
drawings that adhere to the given orthogonal representation.
&lt;/p&gt;
&lt;p&gt;This problem is called orthogonal compaction (OC) and is known to be NP-hard,
even for orthogonal representations of cycles [Evans et al., 2022]. We
investigate the complexity of OC with respect to several parameters. Among
others, we show that OC is fixed-parameter tractable with respect to the most
natural of these parameters, namely, the number of \emph{kitty corners} of the
orthogonal representation: the presence of pairs of kitty corners in an
orthogonal representation makes the OC problem hard. Informally speaking, a
pair of kitty corners is a pair of reflex corners of a face that point at each
other. Accordingly, the number of kitty corners is the number of corners that
are involved in some pair of kitty corners.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Crack Modeling via Minimum-Weight Surfaces in 3d Voronoi Diagrams</title>
  <guid>http://arxiv.org/abs/2210.05093</guid>
  <link>http://arxiv.org/abs/2210.05093</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1&quot;&gt;Christian Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Redenbach_C/0/1/0/all/0/1&quot;&gt;Claudia Redenbach&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Shortest paths play an important role in mathematical modeling and image
processing. Usually, shortest path problems are formulated on planar graphs
that consist of vertices and weighted arcs. In this context, one is interested
in finding a path of minimum weight from a start vertex to an end vertex. The
concept of minimum-weight surfaces extends shortest paths to 3d. The
minimum-weight surface problem is formulated on a cellular complex with
weighted facets. A cycle on the arcs of the complex serves as input and one is
interested in finding a surface of minimum weight bounded by that cycle. In
practice, minimum-weight surfaces can be used to segment 3d images. Vice versa,
it is possible to use them as a modeling tool for geometric structures such as
cracks. In this work, we present an approach for using minimum-weight surfaces
in bounded Voronoi diagrams to generate synthetic 3d images of cracks.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Persistence Diagram Bundles: A Multidimensional Generalization of Vineyards</title>
  <guid>http://arxiv.org/abs/2210.05124</guid>
  <link>http://arxiv.org/abs/2210.05124</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hickok_A/0/1/0/all/0/1&quot;&gt;Abigail Hickok&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A persistence diagram (PD) summarizes the persistent homology of a
filtration. I introduce the concept of a persistence diagram bundle, which is
the space of PDs associated with a fibered filtration function (a set $\{f_t:
\mathcal{K}^t \to \mathbb{R}\}_{t \in \mathcal{T}}$ of filtrations
parameterized by a topological space $\mathcal{T}$). Special cases include
vineyards, the persistent homology transform, and fibered barcodes of
multiparameter persistence modules. I prove that if $\mathcal{T}$ is a compact
$n$-dimensional manifold, then for generic fibered filtration functions,
$\mathcal{T}$ is stratified such that within each $n$-dimensional stratum $S$,
there is a single PD &quot;template&quot; (a list of birth and death simplices) that can
be used to obtain $PD(f_t)$ for any $t \in S$. I also show that not every local
section can be extended to a global section. Consequently, the points in the
PDs do not typically trace out separate manifolds as $t \in \mathcal{T}$
varies; this is unlike a vineyard, in which the points in the PDs trace out
curves (&quot;vines&quot;).
&lt;/p&gt;
  </description>
  <pubDate>2022-10-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Morphing Planar Graph Drawings Through 3D</title>
  <guid>http://arxiv.org/abs/2210.05384</guid>
  <link>http://arxiv.org/abs/2210.05384</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buchin_K/0/1/0/all/0/1&quot;&gt;Kevin Buchin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_W/0/1/0/all/0/1&quot;&gt;Will Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frati_F/0/1/0/all/0/1&quot;&gt;Fabrizio Frati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kostitsyna_I/0/1/0/all/0/1&quot;&gt;Irina Kostitsyna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loffler_M/0/1/0/all/0/1&quot;&gt;Maarten L&amp;#xf6;ffler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ophelders_T/0/1/0/all/0/1&quot;&gt;Tim Ophelders&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolff_A/0/1/0/all/0/1&quot;&gt;Alexander Wolff&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we investigate crossing-free 3D morphs between planar
straight-line drawings. We show that, for any two (not necessarily
topologically equivalent) planar straight-line drawings of an $n$-vertex planar
graph, there exists a piecewise-linear crossing-free 3D morph with $O(n^2)$
steps that transforms one drawing into the other. We also give some evidence
why it is difficult to obtain a linear lower bound (which exists in 2D) for the
number of steps of a crossing-free 3D morph.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Hierarchical Categories in Colored Searching</title>
  <guid>http://arxiv.org/abs/2210.05403</guid>
  <link>http://arxiv.org/abs/2210.05403</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Afshani_P/0/1/0/all/0/1&quot;&gt;Peyman Afshani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Killman_R/0/1/0/all/0/1&quot;&gt;Rasmus Killman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1&quot;&gt;Kasper Green Larsen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In colored range counting (CRC), the input is a set of points where each
point is assigned a ``color&#39;&#39; (or a ``category&#39;&#39;) and the goal is to store them
in a data structure such that the number of distinct categories inside a given
query range can be counted efficiently. CRC has strong motivations as it allows
data structure to deal with categorical data. However, colors (i.e., the
categories) in the CRC problem do not have any internal structure, whereas this
is not the case for many datasets in practice where hierarchical categories
exists or where a single input belongs to multiple categories. Motivated by
these, we consider variants of the problem where such structures can be
represented. We define two variants of the problem called hierarchical range
counting (HCC) and sub-category colored range counting (SCRC) and consider
hierarchical structures that can either be a DAG or a tree. We show that the
two problems on some special trees are in fact equivalent to other well-known
problems in the literature. Based on these, we also give efficient data
structures when the underlying hierarchy can be represented as a tree. We show
a conditional lower bound for the general case when the existing hierarchy can
be any DAG, through reductions from the orthogonal vectors problem.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Hierarchical Grouping Algorithm for the Multi-Vehicle Dial-a-Ride Problem</title>
  <guid>http://arxiv.org/abs/2210.05000</guid>
  <link>http://arxiv.org/abs/2210.05000</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1&quot;&gt;Kelin Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Florio_A/0/1/0/all/0/1&quot;&gt;Alexandre M. Florio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1&quot;&gt;Syamantak Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xiangyu Guo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Ride-sharing is an essential aspect of modern urban mobility. In this paper,
we consider a classical problem in ride-sharing - the Multi-Vehicle Dial-a-Ride
Problem (Multi-Vehicle DaRP). Given a fleet of vehicles with a fixed capacity
stationed at various locations and a set of ride requests specified by origins
and destinations, the goal is to serve all requests such that no vehicle is
assigned more passengers than its capacity at any point along its trip. We
propose an algorithm HRA, which is the first non-trivial approximation
algorithm for the Multi-Vehicle DaRP. The main technical contribution is to
reduce the Multi-Vehicle DaRP to a certain capacitated partitioning problem,
which we solve using a novel hierarchical grouping algorithm. Experimental
results show that the vehicle routes produced by our algorithm not only exhibit
less total travel distance compared to state-of-the-art baselines, but also
enjoy a small in-transit latency, which crucially relates to riders&#39; traveling
times. This suggests that HRA enhances rider experience while being
energy-efficient.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Evaluation of the Quality of Exercises for the Data Structures&#39; eTextbook and Find the Difficult Topics Using Item Response Theory and Logged Data Analysis</title>
  <guid>http://arxiv.org/abs/2210.05294</guid>
  <link>http://arxiv.org/abs/2210.05294</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elrahman_A/0/1/0/all/0/1&quot;&gt;Ahmed Abd Elrahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soliman_T/0/1/0/all/0/1&quot;&gt;Taysir Hassan A Soliman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farghally_M/0/1/0/all/0/1&quot;&gt;Mohammed F. Farghally&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taloba_A/0/1/0/all/0/1&quot;&gt;Ahmed I. Taloba&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The growing dependence on eTextbooks and Massive Open Online Courses (MOOCs)
has led to an increase in the amount of students&#39; learning data. By carefully
analyzing this data, educators can identify difficult exercises, and evaluate
the quality of the exercises when teaching a particular topic. In this study,
an analysis of log data from the use of a semester of the OpenDSA eTextbook was
offered to identify the most difficult data structure course exercises and to
evaluate the quality of the course exercises. Our study is based on analyzing
students&#39; responses to the course exercises. To identify the difficult
exercises, we applied two different approaches, the first of which involved
analyzing student responses to exercises using item response theory (IRT)
analysis and a latent trait model (LTM) technique, and the second involved
determining which exercises were more difficult based on how students
interacted with them. We computed different measures for every exercise such
that difficulty level, trial and error, and hint ratio. We generated an item
characteristics curve, item information curve, and test information function
for each exercise. To evaluate the quality of the exercises, we applied the IRT
analysis to the students&#39; responses to the exercises and, we computed the
difficulty and discrimination index for each exercise. We classified whether
the exercise is good or poor based on these two measures. Our findings showed
that the exercises that related to algorithm analysis topics represented most
of the difficult exercises that students struggle with, and there existing six
exercises out of 56 exercises are classified as poor exercises which could be
rejected or improved. Some of these poor exercises do not differentiate between
students with different abilities; the others give preference to low-ability
students to answer these exercises over high-ability students.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Enhancing Branch-and-Bound for Multi-Objective 0-1 Programming</title>
  <guid>http://arxiv.org/abs/2210.05385</guid>
  <link>http://arxiv.org/abs/2210.05385</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forget_N/0/1/0/all/0/1&quot;&gt;Nicolas Forget&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parragh_S/0/1/0/all/0/1&quot;&gt;Sophie N. Parragh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the bi-objective branch-and-bound literature, a key ingredient is
objective branching, i.e. to create smaller and disjoint sub-problems in the
objective space, obtained from the partial dominance of the lower bound set by
the upper bound set. When considering three or more objective functions,
however, applying objective branching becomes more complex, and its benefit has
so far been unclear. In this paper, we investigate several ingredients which
allow to better exploit objective branching in a multi-objective setting. We
extend the idea of probing to multiple objectives, enhance it in several ways,
and show that when coupled with objective branching, it results in significant
speed-ups in terms of CPU times. We also investigate cut generation based on
the objective branching constraints. Besides, we generalize the best-bound idea
for node selection to multiple objectives and we show that the proposed rules
outperform the, in the multi-objective literature, commonly employed
depth-first and breadth-first strategies. We also analyze problem specific
branching rules. We test the proposed ideas on available benchmark instances
for three problem classes with three and four objectives, namely the
capacitated facility location problem, the uncapacitated facility location
problem, and the knapsack problem. Our enhanced multi-objective
branch-and-bound algorithm outperforms the best existing branch-and-bound based
approach and is the first to obtain competitive and even slightly better
results than a state-of-the-art objective space search method on a subset of
the problem classes.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Parallel solutions for preemptive makespan scheduling on two identical machines</title>
  <guid>http://arxiv.org/abs/2210.05543</guid>
  <link>http://arxiv.org/abs/2210.05543</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Epstein_L/0/1/0/all/0/1&quot;&gt;Leah Epstein&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider online preemptive scheduling of jobs arriving one by one, to be
assigned to two identical machines, with the goal of makespan minimization. We
study the effect of selecting the best solution out of two independent
solutions constructed in parallel in an online fashion. Two cases are analyzed,
where one case is purely online, and in the other one jobs are presented sorted
by non-increasing sizes. We show that using two solutions rather than one
improves the performance significantly, but that an optimal solution cannot be
obtained for any constant number of solutions constructed in parallel. Our
algorithms have the best possible competitive ratios out of algorithms for each
one of the classes.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>News for September 2022</title>
  <guid>https://ptreview.sublinear.info/?p=1763</guid>
  <link>https://ptreview.sublinear.info/2022/10/news-for-september-2022/</link>
  <description>
    &lt;p&gt;Apologies for the delay! Another quiet month in the property testing world, with only one paper (that we found). If we missed any, let us know in the comments!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;On Interactive Proofs of Proximity with Proof-Oblivious Queries&lt;/strong&gt;, by Oded Goldreich, Guy Rothblum, and Tal Skverer (&lt;a href=&quot;https://eccc.weizmann.ac.il/report/2022/124/&quot;&gt;ECCC&lt;/a&gt;). Interactive Proofs of Proximity (IPPs) are the &amp;#8220;interactive&amp;#8221; version of property testers, where the algorithm can both query the input and interact with an all-knowing (but untrusted) prover. In this work, the authors study the power of a specific and natural type of &amp;#8220;adaptivity&amp;#8221; for IPPs, asking what happens when the choice of queries and the interaction with the prover are independent, or restricted. That is, what happens when these two aspects of the IPP algorithm are in separate &amp;#8220;modules&amp;#8221;? Can we still test various properties as efficiently? The paper proves various results in under several models (=restrictions between the two &amp;#8220;modules&amp;#8221;), focusing on the intermediate restriction where the two modules (queries to the input and interaction with the prover) are separate (no interaction), but have access to shared randomness.&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Clement Canonne&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 23:31:03 UTC</pubDate>
  <author>Property Testing Review</author>
</item>

<item>
  <title>Principal Researcher (postdoctoral) at The University of Chicago (apply by January 14, 2023)</title>
  <guid>http://cstheory-jobs.org/2022/10/11/principal-researcher-postdoctoral-at-the-university-of-chicago-apply-by-january-14-2023/</guid>
  <link>https://cstheory-jobs.org/2022/10/11/principal-researcher-postdoctoral-at-the-university-of-chicago-apply-by-january-14-2023/</link>
  <description>
    &lt;p&gt;The candidate will be given the opportunity to pursue a broad research agenda with Prof. Bryon Aragam at the intersection of statistics and machine learning and will ideally have a background in at least one of the following areas: latent variable models, deep generative models, causal inference, nonparametric statistics, learning theory, or graphical models.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.chicagobooth.edu/-/media/faculty/research-professional-program/job-ads/2022-23/principal_researcher_aragam_announcement_2022.pdf&quot;&gt;https://www.chicagobooth.edu/-/media/faculty/research-professional-program/job-ads/2022-23/principal_researcher_aragam_announcement_2022.pdf&lt;/a&gt;&lt;br /&gt;
Email: bryon@chicagobooth.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 19:39:19 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Test Your intuition 51</title>
  <guid>http://gilkalai.wordpress.com/?p=23377</guid>
  <link>https://gilkalai.wordpress.com/2022/10/11/test-your-intuition-51/</link>
  <description>
    &lt;p&gt;&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;


&lt;p&gt;Suppose that &lt;img src=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;K&quot; class=&quot;latex&quot; /&gt; and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;L&quot; class=&quot;latex&quot; /&gt; are two compact convex sets in space. Suppose that &lt;img src=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;K&quot; class=&quot;latex&quot; /&gt; &lt;span style=&quot;color:#0000ff;&quot;&gt;&lt;strong&gt;contains&lt;/strong&gt;&lt;/span&gt; &lt;img src=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;L&quot; class=&quot;latex&quot; /&gt;. Now consider two quantities&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=X&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=X&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;X&quot; class=&quot;latex&quot; /&gt; is the average volume of a simplex forms by four points in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;K&quot; class=&quot;latex&quot; /&gt; drawn uniformly at random.&lt;/li&gt;
&lt;li&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=Y&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=Y&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;Y&quot; class=&quot;latex&quot; /&gt; is the average volume of a simplex forms by four points in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;L&quot; class=&quot;latex&quot; /&gt; drawn uniformly at random.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;TYI: Is it always the case that X ≥ Y?&lt;/h3&gt;&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 09:05:53 UTC</pubDate>
  <author>Gil Kalai</author>
</item>

<item>
  <title>Postdoc  at Technion (apply by December 31, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/10/11/postdoc-at-technion-apply-by-december-31-2022/</guid>
  <link>https://cstheory-jobs.org/2022/10/11/postdoc-at-technion-apply-by-december-31-2022/</link>
  <description>
    &lt;p&gt;Candidates with a strong publication record in top venues in distributed computing (broadly interpreted) or algorithms in general are welcome to apply. To apply, send the following to Mrs. Hila Mizrahi at hilamiz@cs.technion.ac.il: 1. CV (PDF)&lt;br /&gt;
2. 1-2 page research statement (PDF)&lt;br /&gt;
3. Contact details of 3 references (email plaintext)&lt;br /&gt;
4. Expected graduation date, if applicable (email plaintext)&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://ckeren.net.technion.ac.il/&quot;&gt;https://ckeren.net.technion.ac.il/&lt;/a&gt;&lt;br /&gt;
Email: hilamiz@cs.technion.ac.il&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 08:13:20 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Edge deletion to tree-like graph classes</title>
  <guid>http://arxiv.org/abs/2210.03839</guid>
  <link>http://arxiv.org/abs/2210.03839</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koch_I/0/1/0/all/0/1&quot;&gt;Ivo Koch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pardal_N/0/1/0/all/0/1&quot;&gt;Nina Pardal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_V/0/1/0/all/0/1&quot;&gt;Vinicius Fernandes dos Santos&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For a fixed property (graph class) $\Pi$, given a graph $G$ and an integer
$k$, the $\Pi$-deletion problem consists in deciding if we can turn $G$ into a
graph with the property $\Pi$ by deleting at most $k$ edges of $G$. The
$\Pi$-deletion problem is known to be NP-hard for most of the well-studied
graph classes (such as chordal, interval, bipartite, planar, comparability and
permutation graphs, among others), with the notable exception of trees.
Motivated by this fact, in this work we study the deletion problem for some
classes close to trees. We obtain NP-hardness results for several classes of
sparse graphs, for which we prove that deletion is hard even when the input is
a bipartite graph. In addition, we give sufficient structural conditions for
the graph class $\Pi$ for NP-hardness. In the case of deletion to cactus, we
show that the problem becomes tractable when the input is chordal, and we give
polynomial-time algorithms for quasi-threshold graphs.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Automata Equipped with Auxiliary Data Structures and Regular Realizability Problems</title>
  <guid>http://arxiv.org/abs/2210.03934</guid>
  <link>http://arxiv.org/abs/2210.03934</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rubtsov_A/0/1/0/all/0/1&quot;&gt;Alexander Rubtsov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vyalyi_M/0/1/0/all/0/1&quot;&gt;Mikhail Vyalyi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider general computational models: one-way and two-way finite
automata, and logarithmic space Turing machines, all equipped with an auxiliary
data structure (ADS). The definition of an ADS is based on the language of
protocols of work with the ADS. We describe the connection of automata-based
models with ``Balloon automata&#39;&#39; that are another general formalization of
automata equipped with an ADS presented by Hopcroft and Ullman in 1967.
&lt;/p&gt;
&lt;p&gt;This definition establishes the connection between the non-emptiness problem
for one-way automata with ADS, languages recognizable by nondeterministic
log-space Turing machines equipped with the same ADS, and a regular
realizability problem (NRR) for the language of ADS&#39; protocols. The NRR problem
is to verify whether the regular language on the input has a non-empty
intersection with the language of protocols. The computational complexity of
these problems (and languages) is the same up to log-space reductions.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The FBHHRBNRSSSHK-Algorithm for Multiplication in $\mathbb{Z}_2^{5\times5}$ is still not the end of the story 2</title>
  <guid>http://arxiv.org/abs/2210.04045</guid>
  <link>http://arxiv.org/abs/2210.04045</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kauers_M/0/1/0/all/0/1&quot;&gt;Manuel Kauers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moosbauer_J/0/1/0/all/0/1&quot;&gt;Jakob Moosbauer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In response to a recent Nature article which announced an algorithm for
multiplying $5\times5$-matrices over $\mathbb{Z}_2$ with only 96
multiplications, two fewer than the previous record, we present an algorithm
that does the job with only 95 multiplications.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>An Efficient and Continuous Voronoi Density Estimator</title>
  <guid>http://arxiv.org/abs/2210.03964</guid>
  <link>http://arxiv.org/abs/2210.03964</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marchetti_G/0/1/0/all/0/1&quot;&gt;Giovanni Luca Marchetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Polianskii_V/0/1/0/all/0/1&quot;&gt;Vladislav Polianskii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Varava_A/0/1/0/all/0/1&quot;&gt;Anastasiia Varava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pokorny_F/0/1/0/all/0/1&quot;&gt;Florian T. Pokorny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kragic_D/0/1/0/all/0/1&quot;&gt;Danica Kragic&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce a non-parametric density estimator deemed Radial Voronoi Density
Estimator (RVDE). RVDE is grounded in the geometry of Voronoi tessellations and
as such benefits from local geometric adaptiveness and broad convergence
properties. Due to its radial definition RVDE is moreover continuous and
computable in linear time with respect to the dataset size. This amends for the
main shortcomings of previously studied VDEs, which are highly discontinuous
and computationally expensive. We provide a theoretical study of the modes of
RVDE as well as an empirical investigation of its performance on
high-dimensional data. Results show that RVDE outperforms other non-parametric
density estimators, including recently introduced VDEs.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>APUD(1,1) Recognition in Polynomial Time</title>
  <guid>http://arxiv.org/abs/2210.04090</guid>
  <link>http://arxiv.org/abs/2210.04090</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cagirici_D/0/1/0/all/0/1&quot;&gt;Deniz A&amp;#x11f;ao&amp;#x11f;lu &amp;#xc7;a&amp;#x11f;&amp;#x131;r&amp;#x131;c&amp;#x131;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cagirici_O/0/1/0/all/0/1&quot;&gt;Onur &amp;#xc7;a&amp;#x11f;&amp;#x131;r&amp;#x131;c&amp;#x131;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A unit disk graph is the intersection graph of a set of disk of unit radius
in the Euclidean plane. In 1998, Breu and Kirkpatrick showed that the
recognition problem for unit disk graphs is NP-hard. Given $k$ horizontal and
$m$ vertical lines, an APUD($k,m$) is a unit disk graph such that each unit
disk is centered either on a given horizontal or vertical line.
\c{C}a\u{g}{\i}r{\i}c{\i} showed in 2020 that APUD($k,m$) recognition is
NP-hard. In this paper, we show that APUD($1,1$) recognition is polynomial time
solvable.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Developable Quad Meshes</title>
  <guid>http://arxiv.org/abs/2210.04099</guid>
  <link>http://arxiv.org/abs/2210.04099</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inza_V/0/1/0/all/0/1&quot;&gt;Victor Ceballos Inza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rist_F/0/1/0/all/0/1&quot;&gt;Florian Rist&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wallner_J/0/1/0/all/0/1&quot;&gt;Johannes Wallner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pottmann_H/0/1/0/all/0/1&quot;&gt;Helmut Pottmann&lt;/a&gt;&lt;/p&gt;&lt;p&gt;There are different ways to capture the property of a surface being
developable, i.e., it can be mapped to a planar domain without stretching or
tearing. Contributions range from special parametrizations to
discrete-isometric mappings. So far, a local criterion expressing the
developability of general quad meshes has been lacking. In this paper, we
propose a new and efficient discrete developability criterion that is based on
a property well-known from differential geometry, namely a rank-deficient
second fundamental form. This criterion is expressed in terms of the canonical
checkerboard patterns inscribed in a quad mesh which already was successful in
describing discrete-isometric mappings. In combination with standard global
optimization procedures, we are able to perform developable lofting,
approximation, and design. The meshes we employ are combinatorially regular
quad meshes with isolated singularities but are otherwise not required to
follow any special curves. They are thus easily embedded into a design workflow
involving standard operations like re-meshing, trimming, and merging
operations.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>A Finite Algorithm for the Realizabilty of a Delaunay Triangulation</title>
  <guid>http://arxiv.org/abs/2210.03932</guid>
  <link>http://arxiv.org/abs/2210.03932</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1&quot;&gt;Akanksha Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1&quot;&gt;Saket Saurabh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zehavi_M/0/1/0/all/0/1&quot;&gt;Meirav Zehavi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The \emph{Delaunay graph} of a point set $P \subseteq \mathbb{R}^2$ is the
plane graph with the vertex-set $P$ and the edge-set that contains $\{p,p&#39;\}$
if there exists a disc whose intersection with $P$ is exactly $\{p,p&#39;\}$.
Accordingly, a triangulated graph $G$ is \emph{Delaunay realizable} if there
exists a triangulation of the Delaunay graph of some $P \subseteq
\mathbb{R}^2$, called a \emph{Delaunay triangulation} of $P$, that is
isomorphic to $G$. The objective of \textsc{Delaunay Realization} is to compute
a point set $P \subseteq \mathbb{R}^2$ that realizes a given graph $G$ (if such
a $P$ exists). Known algorithms do not solve \textsc{Delaunay Realization} as
they are non-constructive. Obtaining a constructive algorithm for
\textsc{Delaunay Realization} was mentioned as an open problem by Hiroshima et
al.~\cite{hiroshima2000}. We design an $n^{\mathcal{O}(n)}$-time constructive
algorithm for \textsc{Delaunay Realization}. In fact, our algorithm outputs
sets of points with {\em integer} coordinates.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>An Approximation Algorithm for Distance-Constrained Vehicle Routing on Trees</title>
  <guid>http://arxiv.org/abs/2210.03811</guid>
  <link>http://arxiv.org/abs/2210.03811</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dufay_M/0/1/0/all/0/1&quot;&gt;Marc Dufay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathieu_C/0/1/0/all/0/1&quot;&gt;Claire Mathieu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hang Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the Distance-constrained Vehicle Routing Problem (DVRP), we are given a
graph with integer edge weights, a depot, a set of $n$ terminals, and a
distance constraint $D$. The goal is to find a minimum number of tours starting
and ending at the depot such that those tours together cover all the terminals
and the length of each tour is at most $D$.
&lt;/p&gt;
&lt;p&gt;The DVRP on trees is of independent interest, because it is equivalent to the
virtual machine packing problem on trees studied by Sindelar et al. [SPAA&#39;11].
We design a simple and natural approximation algorithm for the tree DVRP,
parameterized by $\varepsilon &amp;gt;0$. We show that its approximation ratio is
$\alpha + \varepsilon$, where $\alpha \approx 1.691$, and in addition, that our
analysis is essentially tight. The running time is polynomial in $n$ and $D$.
The approximation ratio improves on the ratio of 2 due to Nagarajan and Ravi
[Networks&#39;12].
&lt;/p&gt;
&lt;p&gt;The main novelty of this paper lies in the analysis of the algorithm. It
relies on a reduction from the tree DVRP to the bounded space online bin
packing problem via a new notion of reduced length.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>How to Make Your Approximation Algorithm Private: A Black-Box Differentially-Private Transformation for Tunable Approximation Algorithms of Functions with Low Sensitivity</title>
  <guid>http://arxiv.org/abs/2210.03831</guid>
  <link>http://arxiv.org/abs/2210.03831</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blocki_J/0/1/0/all/0/1&quot;&gt;Jeremiah Blocki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grigorescu_E/0/1/0/all/0/1&quot;&gt;Elena Grigorescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_T/0/1/0/all/0/1&quot;&gt;Tamalika Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Samson Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We develop a framework for efficiently transforming certain approximation
algorithms into differentially-private variants, in a black-box manner. Our
results focus on algorithms A that output an approximation to a function f of
the form $(1-a)f(x)-k &amp;lt;= A(x) &amp;lt;= (1+a)f(x)+k$, where 0&amp;lt;=a &amp;lt;1 is a parameter
that can be``tuned&quot; to small-enough values while incurring only a poly blowup
in the running time/space. We show that such algorithms can be made DP without
sacrificing accuracy, as long as the function f has small global sensitivity.
We achieve these results by applying the smooth sensitivity framework developed
by Nissim, Raskhodnikova, and Smith (STOC 2007).
&lt;/p&gt;
&lt;p&gt;Our framework naturally applies to transform non-private FPRAS (resp. FPTAS)
algorithms into $(\epsilon,\delta)$-DP (resp. $\epsilon$-DP) approximation
algorithms. We apply our framework in the context of sublinear-time and
sublinear-space algorithms, while preserving the nature of the algorithm in
meaningful ranges of the parameters. Our results include the first (to the best
of our knowledge) $(\epsilon,\delta)$-edge DP sublinear-time algorithm for
estimating the number of triangles, the number of connected components, and the
weight of a MST of a graph, as well as a more efficient algorithm (while
sacrificing pure DP in contrast to previous results) for estimating the average
degree of a graph. In the area of streaming algorithms, our results include
$(\epsilon,\delta)$-DP algorithms for estimating L_p-norms, distinct elements,
and weighted MST for both insertion-only and turnstile streams. Our
transformation also provides a private version of the smooth histogram
framework, which is commonly used for converting streaming algorithms into
sliding window variants, and achieves a multiplicative approximation to many
problems, such as estimating L_p-norms, distinct elements, and the length of
the longest increasing subsequence.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Dynamic Tensor Product Regression</title>
  <guid>http://arxiv.org/abs/2210.03961</guid>
  <link>http://arxiv.org/abs/2210.03961</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_A/0/1/0/all/0/1&quot;&gt;Aravind Reddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lichen Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work, we initiate the study of \emph{Dynamic Tensor Product
Regression}. One has matrices $A_1\in \mathbb{R}^{n_1\times d_1},\ldots,A_q\in
\mathbb{R}^{n_q\times d_q}$ and a label vector $b\in \mathbb{R}^{n_1\ldots
n_q}$, and the goal is to solve the regression problem with the design matrix
$A$ being the tensor product of the matrices $A_1, A_2, \dots, A_q$ i.e.
$\min_{x\in \mathbb{R}^{d_1\ldots d_q}}~\|(A_1\otimes \ldots\otimes
A_q)x-b\|_2$. At each time step, one matrix $A_i$ receives a sparse change, and
the goal is to maintain a sketch of the tensor product $A_1\otimes\ldots
\otimes A_q$ so that the regression solution can be updated quickly.
Recomputing the solution from scratch for each round is very slow and so it is
important to develop algorithms which can quickly update the solution with the
new design matrix. Our main result is a dynamic tree data structure where any
update to a single matrix can be propagated quickly throughout the tree. We
show that our data structure can be used to solve dynamic versions of not only
Tensor Product Regression, but also Tensor Product Spline regression (which is
a generalization of ridge regression) and for maintaining Low Rank
Approximations for the tensor product.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Order Selection Problems in Hiring Pipelines</title>
  <guid>http://arxiv.org/abs/2210.04059</guid>
  <link>http://arxiv.org/abs/2210.04059</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Epstein_B/0/1/0/all/0/1&quot;&gt;Boris Epstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1&quot;&gt;Will Ma&lt;/a&gt; (Columbia University)&lt;/p&gt;&lt;p&gt;Motivated by hiring pipelines, we study two order selection problems in which
applicants for a finite set of positions must be interviewed or made offers
sequentially. There is a finite time budget for interviewing or making offers,
and a stochastic realization after each decision, leading to
computationally-challenging problems. In the first problem we study sequential
interviewing, and show that a computationally-tractable, non-adaptive policy
that must make offers immediately after interviewing is approximately optimal,
assuming offerees always accept their offers. In the second problem, we assume
that applicants have already been interviewed but only accept offers with some
probability; we develop a computationally-tractable policy that makes offers
for the different positions in parallel, which is approximately optimal even
relative to a policy that does not need to make parallel offers. Our two
results both generalize and improve the guarantees in the work of Purohit et
al. on hiring algorithms, from 1/2 and 1/4 to approximation factors that are at
least 1-1/e.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>IcebergHT: High Performance PMEM Hash Tables Through Stability and Low Associativity</title>
  <guid>http://arxiv.org/abs/2210.04068</guid>
  <link>http://arxiv.org/abs/2210.04068</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandey_P/0/1/0/all/0/1&quot;&gt;Prashant Pandey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bender_M/0/1/0/all/0/1&quot;&gt;Michael A. Bender&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conway_A/0/1/0/all/0/1&quot;&gt;Alex Conway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farach_Colton_M/0/1/0/all/0/1&quot;&gt;Mart&amp;#xed;n Farach-Colton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuszmaul_W/0/1/0/all/0/1&quot;&gt;William Kuszmaul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tagliavini_G/0/1/0/all/0/1&quot;&gt;Guido Tagliavini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnson_R/0/1/0/all/0/1&quot;&gt;Rob Johnson&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Modern hash table designs strive to minimize space while maximizing speed.
The most important factor in speed is the number of cache lines accessed during
updates and queries. This is especially important on PMEM, which is slower than
DRAM and in which writes are more expensive than reads. This paper proposes two
stronger design objectives: stability and low-associativity. A stable hash
table doesn&#39;t move items around, and a hash table has low associativity if
there are only a few locations where an item can be stored. Low associativity
ensures that queries need to examine only a few memory locations, and stability
ensures that insertions write to very few cache lines. Stability also
simplifies scaling and crash safety.
&lt;/p&gt;
&lt;p&gt;We present IcebergHT, a fast, crash-safe, concurrent, and space-efficient
hash table for PMEM based on the design principles of stability and low
associativity. IcebergHT combines in-memory metadata with a new hashing
technique, iceberg hashing, that is (1) space efficient, (2) stable, and (3)
supports low associativity. In contrast, existing hash-tables either modify
numerous cache lines during insertions (e.g. cuckoo hashing), access numerous
cache lines during queries (e.g. linear probing), or waste space (e.g.
chaining). Moreover, the combination of (1)-(3) yields several emergent
benefits: IcebergHT scales better than other hash tables, supports
crash-safety, and has excellent performance on PMEM (where writes are
particularly expensive).
&lt;/p&gt;
  </description>
  <pubDate>2022-10-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>THREE-YEAR AND TENURE-TRACK POSITIONS at TTIC (apply by December 1, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/10/10/three-year-and-tenure-track-positions-at-ttic-apply-by-december-1-2022/</guid>
  <link>https://cstheory-jobs.org/2022/10/10/three-year-and-tenure-track-positions-at-ttic-apply-by-december-1-2022/</link>
  <description>
    &lt;p&gt;TTIC invites applications for the following faculty positions: research assistant professor (3-year term), tenure-track assistant professor, full or associate professor, and visiting professor. Applicants for research assistant professor positions (RAPs) are encouraged to simultaneously apply for the TTIC RAP program and the Simons-Berkeley Research Fellowship.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.ttic.edu/faculty-hiring/&quot;&gt;https://www.ttic.edu/faculty-hiring/&lt;/a&gt;&lt;br /&gt;
Email: recruiting@ttic.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-10-10 18:07:37 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Lecturer in Verification at University of Sheffield (apply by October 14, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/10/10/lecturer-in-verification-at-university-of-sheffield-apply-by-october-14-2022/</guid>
  <link>https://cstheory-jobs.org/2022/10/10/lecturer-in-verification-at-university-of-sheffield-apply-by-october-14-2022/</link>
  <description>
    &lt;p&gt;We seek candidates with an outstanding record in the logical and mathematical foundations of computing, including hardware and software verification. You will work within the Verification Group, a well-established group in the Department of Computer Science. Our research range from the mathematical and logical foundations of computing to practical verification methods and tools to support these.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.jobs.ac.uk/job/CTU424/lecturer-in-verification&quot;&gt;https://www.jobs.ac.uk/job/CTU424/lecturer-in-verification&lt;/a&gt;&lt;br /&gt;
Email: g.j.brown@sheffield.ac.uk&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-10-10 12:26:03 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Will Strassen&#39;s Matrix Mult Alg ever be practical?</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-8978327258415406646</guid>
  <link>http://blog.computationalcomplexity.org/2022/10/will-strassens-matrix-mult-alg-ever-be.html</link>
  <description>
    &lt;p&gt;All time bounds are asymptotic and really O-of.&lt;/p&gt;&lt;p&gt;Recall that Strassen found a clever way to multiply&amp;nbsp; two 2x2 matrices with 7 mults (and lots of adds)&amp;nbsp; leading to a matrix mult alg in n^{\log_2 7} = n^{2.87...}&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Recently (see&amp;nbsp;&lt;a href=&quot;https://www.newscientist.com/article/2340343-deepmind-ai-finds-new-way-to-multiply-numbers-and-speed-up-computers/&quot;&gt;here&lt;/a&gt;) a deep-mind-AI found a way to multiply&amp;nbsp; two 4x4 matrices with 47 mults (and lots of adds) leading to a matrix mult alg in n^{\log_4 47} = n^{2.777...}&amp;nbsp;&lt;/p&gt;&lt;p&gt;Much better is known, see our blog posts&amp;nbsp;&lt;a href=&quot;https://blog.computationalcomplexity.org/2011/11/matrix-mult-you-heard-it-here-third.html&quot;&gt;here&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&quot;https://blog.computationalcomplexity.org/2015/06/when-do-we-care-about-small-improvements.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;The more advanced algorithms are complicated and have large constants so will never be practical. But Strassen&#39;s result, and now the new algorithm, SEEM to me they could be practical.&lt;/p&gt;&lt;p&gt;(ADDED LATER- many of the comments inform me that Strassen IS practical and IS being used. Great! Now we know!)&lt;/p&gt;&lt;p&gt;Thoughts about Strassen that also apply to the&amp;nbsp; new algorithm.&amp;nbsp;&lt;/p&gt;&lt;p&gt;1) n has to be large for Strassen to given an improvement. But as we deal with larger data sets the value of n is getting larger.&amp;nbsp;&lt;/p&gt;&lt;p&gt;2) People are mostly interested in sparse matrices for which there are better methods. I&#39;ve heard that for a while- but is it still true? I thought ML used dense matrices.&amp;nbsp;&lt;/p&gt;&lt;p&gt;3) Strassen is hard to code up. Actually it doesn&#39;t look that hard to code up. However, I have never tried to code it up, so maybe there are subtle points there.&lt;/p&gt;&lt;p&gt;4) Strassen only works on matrices of size 2^n x 2^n. You can pad matrices out but that might kill whatever time advantage you get. (The new alg only works on&amp;nbsp; 4^n x 4^n).&amp;nbsp;&lt;/p&gt;&lt;p&gt;5) Strassen uses recursion and there is &lt;i&gt;the hidden cost of recursion&lt;/i&gt;. I think that is a think of the past and our younger readers do not know what I am talking about.&amp;nbsp;&lt;/p&gt;&lt;p&gt;6) (This is obvious) the recursion would only go down to a certain level and THEN you would use ordinary Matrix Mult. This may also add time.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;I suspect that 2 and 4 are the most important reasons Strassen (or the new algorithm) is not practical BUT I would like to hear your thoughts?&lt;/p&gt;&lt;p&gt;Does any package NOW use Strassen&#39;s Algorithm?&lt;/p&gt;&lt;p&gt;Side Note: I like to ask students if they think there is a better-than-cubic algorithm for Matrix Mult. They do not. Then I show it to them and tell them THIS is why LOWER BOUNDS are hard. You have to show that NO, nobody clever will find a trick you hadn&#39;t thought of.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </description>
  <pubDate>2022-10-10 04:03:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>Treewidth-aware Reductions of Normal ASP to SAT -- Is Normal ASP Harder than SAT after All?</title>
  <guid>http://arxiv.org/abs/2210.03553</guid>
  <link>http://arxiv.org/abs/2210.03553</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hecher_M/0/1/0/all/0/1&quot;&gt;Markus Hecher&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Answer Set Programming (ASP) is a paradigm for modeling and solving problems
for knowledge representation and reasoning. There are plenty of results
dedicated to studying the hardness of (fragments of) ASP. So far, these studies
resulted in characterizations in terms of computational complexity as well as
in fine-grained insights presented in form of dichotomy-style results, lower
bounds when translating to other formalisms like propositional satisfiability
(SAT), and even detailed parameterized complexity landscapes. A generic
parameter in parameterized complexity originating from graph theory is the
so-called treewidth, which in a sense captures structural density of a program.
Recently, there was an increase in the number of treewidth-based solvers
related to SAT. While there are translations from (normal) ASP to SAT, no
reduction that preserves treewidth or at least keeps track of the treewidth
increase is known. In this paper we propose a novel reduction from normal ASP
to SAT that is aware of the treewidth, and guarantees that a slight increase of
treewidth is indeed sufficient. Further, we show a new result establishing
that, when considering treewidth, already the fragment of normal ASP is
slightly harder than SAT (under reasonable assumptions in computational
complexity). This also confirms that our reduction probably cannot be
significantly improved and that the slight increase of treewidth is
unavoidable. Finally, we present an empirical study of our novel reduction from
normal ASP to SAT, where we compare treewidth upper bounds that are obtained
via known decomposition heuristics. Overall, our reduction works better with
these heuristics than existing translations.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-10 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Boolean symmetric vs. functional PCSP dichotomy</title>
  <guid>http://arxiv.org/abs/2210.03343</guid>
  <link>http://arxiv.org/abs/2210.03343</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakajima_T/0/1/0/all/0/1&quot;&gt;Tamio-Vesa Nakajima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zivny_S/0/1/0/all/0/1&quot;&gt;Stanislav &amp;#x17d;ivn&amp;#xfd;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a 3-uniform hypergraph $(V,E)$ that is promised to admit a
$\{0,1\}$-colouring such that every edge contains exactly one $1$, can one find
a $d$-colouring $h:V\to \{0,1,\ldots,d-1\}$ such that $h(e)\in R$ for every
$e\in E$? This can be cast as a promise constraint satisfaction problem (PCSP)
of the form $\operatorname{PCSP}(1-in-3,\mathbf{B})$, where $\mathbf{B}$
defines the relation $R$, and is an example of
$\operatorname{PCSP}(\mathbf{A},\mathbf{B})$, where $\mathbf{A}$ (and thus wlog
also $\mathbf{B}$) is symmetric. The computational complexity of such problems
is understood for $\mathbf{A}$ and $\mathbf{B}$ on Boolean domains by the work
of Ficak, Kozik, Ol\v{s}\&#39;{a}k, and Stankiewicz [ICALP&#39;19].
&lt;/p&gt;
&lt;p&gt;As our first result, we establish a dichotomy for
$\operatorname{PCSP}(\mathbf{A},\mathbf{B})$, where $\mathbf{A}$ is Boolean and
symmetric and $\mathbf{B}$ is functional (on a domain of any size); i.e, all
but one element of any tuple in a relation in $\mathbf{B}$ determine the last
element. This includes PCSPs of the form
$\operatorname{PCSP}(q-in-r,\mathbf{B})$, where $\mathbf{B}$ is functional,
thus making progress towards a classification of
$\operatorname{PCSP}(1-in-3,\mathbf{B})$, which were studied by Barto,
Battistelli, and Berg [STACS&#39;21] for $\mathbf{B}$ on three-element domains.
&lt;/p&gt;
&lt;p&gt;As our second result, we show that for
$\operatorname{PCSP}(\mathbf{A},\mathbf{B})$, where $\mathbf{A}$ contains a
single Boolean symmetric relation and $\mathbf{B}$ is arbitrary (and thus not
necessarily functional), the combined basic linear programmin relaxation (BLP)
and the affine integer programming relaxation (AIP) of Brakensiek et al.
[SICOMP&#39;20] is no more powerful than the (in general strictly weaker) AIP
relaxation of Brakensiek and Guruswami [SICOMP&#39;21].
&lt;/p&gt;
  </description>
  <pubDate>2022-10-10 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>The Power of Greedy for Online Minimum Cost Matching on the Line</title>
  <guid>http://arxiv.org/abs/2210.03166</guid>
  <link>http://arxiv.org/abs/2210.03166</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balkanksi_E/0/1/0/all/0/1&quot;&gt;Eric Balkanksi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faenza_Y/0/1/0/all/0/1&quot;&gt;Yuri Faenza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perivier_N/0/1/0/all/0/1&quot;&gt;Noemie Perivier&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the online minimum cost matching problem on the line, in which
there are $n$ servers and, at each of $n$ time steps, a request arrives and
must be irrevocably matched to a server that has not yet been matched to, with
the goal of minimizing the sum of the distances between the matched pairs.
Despite achieving a worst-case competitive ratio that is exponential in $n$,
the simple greedy algorithm, which matches each request to its nearest
available free server, performs very well in practice. A major question is thus
to explain greedy&#39;s strong empirical performance. In this paper, we aim to
understand the performance of greedy over instances that are at least partially
random. When both the requests and the servers are drawn uniformly and
independently from $[0,1]$, we show that greedy is constant competitive, which
improves over the previously best-known $O(\sqrt{n})$ bound. We extend this
constant competitive ratio to a setting with a linear excess of servers, which
improves over the previously best-known $O(\log^3{n})$ bound. We moreover show
that in the semi-random model where the requests are still drawn uniformly and
independently but where the servers are chosen adversarially, greedy achieves
an $O(\log{n})$ competitive ratio. When the requests arrive in a random order
but are chosen adversarially, it was previously known that greedy is
$O(n)$-competitive. Even though this one-sided randomness allows a large
improvement in greedy&#39;s competitive ratio compared to the model where requests
are adversarial and arrive in a random order, we show that it is not sufficient
to obtain a constant competitive ratio by giving a tight $\Omega(\log{n})$
lower bound. These results invite further investigation about how much
randomness is necessary and sufficient to obtain strong theoretical guarantees
for the greedy algorithm for online minimum cost matching, on the line and
beyond.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-10 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>LazyFox: Fast and parallelized overlapping community detection in large graphs</title>
  <guid>http://arxiv.org/abs/2210.03211</guid>
  <link>http://arxiv.org/abs/2210.03211</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garrels_T/0/1/0/all/0/1&quot;&gt;Tim Garrels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khodabakhsh_A/0/1/0/all/0/1&quot;&gt;Athar Khodabakhsh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renard_B/0/1/0/all/0/1&quot;&gt;Bernhard Y. Renard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baum_K/0/1/0/all/0/1&quot;&gt;Katharina Baum&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The detection of communities in graph datasets provides insight about a
graph&#39;s underlying structure and is an important tool for various domains such
as social sciences, marketing, traffic forecast, and drug discovery. While most
existing algorithms provide fast approaches for community detection, their
results usually contain strictly separated communities. However, most datasets
would semantically allow for or even require overlapping communities that can
only be determined at much higher computational cost. We build on an efficient
algorithm, Fox, that detects such overlapping communities. Fox measures the
closeness of a node to a community by approximating the count of triangles
which that node forms with that community. We propose LazyFox, a multi-threaded
version of the Fox algorithm, which provides even faster detection without an
impact on community quality. This allows for the analyses of significantly
larger and more complex datasets. LazyFox enables overlapping community
detection on complex graph datasets with millions of nodes and billions of
edges in days instead of weeks. As part of this work, LazyFox&#39;s implementation
was published and is available as a tool under an MIT licence at
https://github.com/TimGarrels/LazyFox.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-10 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Latent Matrices for Tensor Network Decomposition and to Tensor Completion</title>
  <guid>http://arxiv.org/abs/2210.03392</guid>
  <link>http://arxiv.org/abs/2210.03392</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1&quot;&gt;Peilin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1&quot;&gt;Weijun Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qinbin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1&quot;&gt;Guoxu Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The prevalent fully-connected tensor network (FCTN) has achieved excellent
success to compress data. However, the FCTN decomposition suffers from slow
computational speed when facing higher-order and large-scale data. Naturally,
there arises an interesting question: can a new model be proposed that
decomposes the tensor into smaller ones and speeds up the computation of the
algorithm? This work gives a positive answer by formulating a novel
higher-order tensor decomposition model that utilizes latent matrices based on
the tensor network structure, which can decompose a tensor into smaller-scale
data than the FCTN decomposition, hence we named it Latent Matrices for Tensor
Network Decomposition (LMTN). Furthermore, three optimization algorithms,
LMTN-PAM, LMTN-SVD and LMTN-AR, have been developed and applied to the
tensor-completion task. In addition, we provide proofs of theoretical
convergence and complexity analysis for these algorithms. Experimental results
show that our algorithm has the effectiveness in both deep learning dataset
compression and higher-order tensor completion, and that our LMTN-SVD algorithm
is 3-6 times faster than the FCTN-PAM algorithm and only a 1.8 points accuracy
drop.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-10 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Postdocs, matrix multiplication, and WSJ: yet more shorties</title>
  <guid>https://scottaaronson.blog/?p=6745</guid>
  <link>https://scottaaronson.blog/?p=6745</link>
  <description>
    &lt;p&gt;I&amp;#8217;m proud to say that &lt;a href=&quot;https://twitter.com/nickrhj&quot;&gt;Nick Hunter-Jones&lt;/a&gt; and &lt;a href=&quot;https://matteoippoliti.com/&quot;&gt;Matteo Ippoliti&lt;/a&gt;&amp;#8212;both of whom work at the interface between quantum information science and condensed-matter physics (Nick closer to the former and Matteo to the latter)&amp;#8212;have joined the physics faculty at UT Austin this year.  And Nick, Matteo, and I are jointly seeking postdocs to start in Fall 2023!  &lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/23104&quot;&gt;Please check out our call for applications here.&lt;/a&gt;  The deadline is December 1; you apply through AcademicJobsOnline rather than by emailing me as in past years.&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;The big news in AI and complexity theory this week was DeepMind&amp;#8217;s &lt;a href=&quot;https://www.deepmind.com/blog/discovering-novel-algorithms-with-alphatensor&quot;&gt;AlphaTensor&lt;/a&gt;, and its automated discovery of new algorithms for matrix multiplication.  (&lt;a href=&quot;https://www.nature.com/articles/s41586-022-05172-4&quot;&gt;See here for the &lt;em&gt;Nature&lt;/em&gt; paper.&lt;/a&gt;)  More concretely, they&amp;#8217;ve used AI to discover (among other things) an algorithm for multiplying 4×4 matrices, over finite fields of characteristic 2, using only 47 scalar multiplications.  This beats the 49=7×7 that you&amp;#8217;d get from &lt;a href=&quot;https://en.wikipedia.org/wiki/Strassen_algorithm&quot;&gt;Strassen&amp;#8217;s algorithm&lt;/a&gt;.  There are other improvements for other matrix dimensions, many of which work over fields of other characteristics.&lt;/p&gt;



&lt;p&gt;Since I&amp;#8217;ve seen confusion about the point on social media: this does &lt;em&gt;not&lt;/em&gt; improve over the best known asymptotic exponent for matrix multiplication, which over any field, still stands at the human-discovered 2.373 (meaning, we know how to multiply two N×N matrices in O(N&lt;sup&gt;2.373&lt;/sup&gt;) time, but not faster).  But it &lt;em&gt;does&lt;/em&gt; asymptotically improve over Strassen&amp;#8217;s O(N&lt;sup&gt;2.81&lt;/sup&gt;) algorithm from 1968, conceivably even in a way that could have practical relevance for multiplying hundreds-by-hundreds or thousands-by-thousands matrices over F&lt;sub&gt;2&lt;/sub&gt;.&lt;/p&gt;



&lt;p&gt;Way back in 2007, I &lt;a href=&quot;http://www.scottaaronson.com/talks/wildidea.ppt&quot;&gt;gave a talk&lt;/a&gt; at MIT CSAIL&amp;#8217;s &amp;#8220;Wild and Crazy Ideas Session,&amp;#8221; where I explicitly proposed to use computer search to look for faster algorithms for 4×4 and 5×5 matrix multiplication.  The response I got at the time was that it was hopeless, since the search space was already too huge.  Of course, that was before the deep learning revolution.&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;This morning, the &lt;em&gt;Wall Street Journal&lt;/em&gt; published an &lt;a href=&quot;https://www.wsj.com/articles/china-competing-us-quantum-computing-11664997892&quot;&gt;article by Karen Hao&lt;/a&gt; about competition between China and the US in quantum computing.  Unfortunately paywalled, but includes the following passage:&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;&lt;p&gt;Meanwhile, American academics say it’s gotten harder for Chinese students to obtain visas to conduct quantum research in the U.S. “It’s become common knowledge that when Chinese students or postdocs come to the U.S., they can’t say they’re doing quantum computing,” says Scott Aaronson, director of the Quantum Information Center at the University of Texas, Austin.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 16:01:53 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>Faculty at University of Cambridge (apply by November 28, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/10/07/faculty-at-university-of-cambridge-apply-by-november-28-2022/</guid>
  <link>https://cstheory-jobs.org/2022/10/07/faculty-at-university-of-cambridge-apply-by-november-28-2022/</link>
  <description>
    &lt;p&gt;The Department of Computer Science and Technology at the University of Cambridge is seeking to recruit a new faculty member at the Assistant or Associate Professor level who can contribute to research and teaching in the area of Algorithms and Complexity.&lt;/p&gt;
&lt;p&gt;The appointment will be from 1 September 2023 or as soon as possible thereafter.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.jobs.cam.ac.uk/job/37368/&quot;&gt;https://www.jobs.cam.ac.uk/job/37368/&lt;/a&gt;&lt;br /&gt;
Email: anuj.dawar@cl.cam.ac.uk&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 10:57:47 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>postdoc positions in Algorithms and Complexity at Algorithms and Compleixty Group, IRIF, Paris, France (apply by November 1, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/10/07/postdoc-positions-in-algorithms-and-complexity-at-algorithms-and-compleixty-group-irif-paris-france-apply-by-november-1-2022/</guid>
  <link>https://cstheory-jobs.org/2022/10/07/postdoc-positions-in-algorithms-and-complexity-at-algorithms-and-compleixty-group-irif-paris-france-apply-by-november-1-2022/</link>
  <description>
    &lt;p&gt;The Algorithms and Complexity group of IRIF ( &lt;a href=&quot;https://www.irif.fr/en/equipes/algocomp/index&quot;&gt;https://www.irif.fr/en/equipes/algocomp/index&lt;/a&gt; ), Paris, France, is seeking excellent candidates for one or more postdoctoral positions in classical and quantum computing, with a usual starting date of September-October 2023 (but possibly negotiable). Knowledge of French is not necessary.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.irif.fr/en/postes/postdoc&quot;&gt;https://www.irif.fr/en/postes/postdoc&lt;/a&gt;&lt;br /&gt;
Email: adiro@irif.fr&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 08:36:39 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Transformers Implement First-Order Logic with Majority Quantifiers</title>
  <guid>http://arxiv.org/abs/2210.02671</guid>
  <link>http://arxiv.org/abs/2210.02671</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1&quot;&gt;William Merrill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1&quot;&gt;Ashish Sabharwal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Characterizing the implicit structure of the computation within neural
networks is a foundational problem in the area of deep learning
interpretability. Can their inner decision process be captured symbolically in
some familiar logic? We show that any transformer neural network can be
translated into an equivalent fixed-size first-order logic formula which may
also use majority quantifiers. The idea is to simulate transformers with highly
uniform threshold circuits and leverage known theoretical connections between
circuits and logic. Our findings also reveal the surprising fact that the
entire transformer computation can be reduced merely to the division of two
(large) integers. While our results are most pertinent for transformers, they
apply equally to a broader class of neural network architectures, namely those
with a fixed-depth uniform computation graph made up of standard neural net
components, which includes feedforward and convolutional networks.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>NLTS Hamiltonians from classical LTCs</title>
  <guid>http://arxiv.org/abs/2210.02999</guid>
  <link>http://arxiv.org/abs/2210.02999</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhiyang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nirkhe_C/0/1/0/all/0/1&quot;&gt;Chinmay Nirkhe&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We provide a completely self-contained construction of a family of NLTS
Hamiltonians [Freedman and Hastings, 2014] based on ideas from [Anshu,
Breuckmann, and Nirkhe, 2022], [Cross, He, Natarajan, Szegedy, and Zhu, 2022]
and [Eldar and Harrow, 2017]. Crucially, it does not require optimal-parameter
quantum LDPC codes and can be built from simple classical LTCs such as the
repetition code on an expander graph. Furthermore, it removes the constant-rate
requirement from the construction of Anshu, Breuckmann, and Nirkhe.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Romeo and Juliet Meeting in Forest Like Regions</title>
  <guid>http://arxiv.org/abs/2210.02582</guid>
  <link>http://arxiv.org/abs/2210.02582</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Misra_N/0/1/0/all/0/1&quot;&gt;Neeldhara Misra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mulpuri_M/0/1/0/all/0/1&quot;&gt;Manas Mulpuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tale_P/0/1/0/all/0/1&quot;&gt;Prafullkumar Tale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viramgami_G/0/1/0/all/0/1&quot;&gt;Gaurav Viramgami&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The game of rendezvous with adversaries is a game on a graph played by two
players: Facilitator and Divider. Facilitator has two agents and Divider has a
team of $k \ge 1$ agents. While the initial positions of Facilitator&#39;s agents
are fixed, Divider gets to select the initial positions of his agents. Then,
they take turns to move their agents to adjacent vertices (or stay put) with
Facilitator&#39;s goal to bring both her agents at same vertex and Divider&#39;s goal
to prevent it. The computational question of interest is to determine if
Facilitator has a winning strategy against Divider with $k$ agents. Fomin,
Golovach, and Thilikos [WG, 2021] introduced this game and proved that it is
PSPACE-hard and co-W[2]-hard parameterized by the number of agents.
&lt;/p&gt;
&lt;p&gt;This hardness naturally motivates the structural parameterization of the
problem. The authors proved that it admits an FPT algorithm when parameterized
by the modular width and the number of allowed rounds. However, they left open
the complexity of the problem from the perspective of other structural
parameters. In particular, they explicitly asked whether the problem admits an
FPT or XP-algorithm with respect to the treewidth of the input graph. We answer
this question in the negative and show that Rendezvous is co-NP-hard even for
graphs of constant treewidth. Further, we show that the problem is co-W[1]-hard
when parameterized by the feedback vertex set number and the number of agents,
and is unlikely to admit a polynomial kernel when parameterized by the vertex
cover number and the number of agents. Complementing these hardness results, we
show that the Rendezvous is FPT when parameterized by both the vertex cover
number and the solution size. Finally, for graphs of treewidth at most two and
girds, we show that the problem can be solved in polynomial time.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>$(1-\epsilon)$-approximate fully dynamic densest subgraph: linear space and faster update time</title>
  <guid>http://arxiv.org/abs/2210.02611</guid>
  <link>http://arxiv.org/abs/2210.02611</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chekuri_C/0/1/0/all/0/1&quot;&gt;Chandra Chekuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quanrud_K/0/1/0/all/0/1&quot;&gt;Kent Quanrud&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of maintaining a $(1-\epsilon)$-approximation to the
densest subgraph (DSG) in an undirected multigraph as it undergoes edge
insertions and deletions (the fully dynamic setting). Sawlani and Wang [SW20]
developed a data structure that, for any given $\epsilon &amp;gt; 0$, maintains a
$(1-\epsilon)$-approximation with $O(\log^4 n/\epsilon^6)$ worst-case update
time for edge operations, and $O(1)$ query time for reporting the density
value. Their data structure was the first to achieve near-optimal
approximation, and improved previous work that maintained a $(1/4 - \epsilon)$
approximation in amortized polylogarithmic update time [BHNT15]. In this paper
we develop a data structure for $(1-\epsilon)$-approximate DSG that improves
the one from [SW20] in two aspects. First, the data structure uses linear space
improving the space bound in [SW20] by a logarithmic factor. Second, the data
structure maintains a $(1-\epsilon)$-approximation in amortized $O(\log^2
n/\epsilon^4)$ time per update while simultaneously guaranteeing that the worst
case update time is $O(\log^3 n \log \log n/\epsilon^6)$. We believe that the
space and update time improvements are valuable for current large scale graph
data sets. The data structure extends in a natural fashion to hypergraphs and
yields improvements in space and update times over recent work [BBCG22] that
builds upon [SW20].
&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Cooperative Coverage with a Leader and a Wingmate in Communication-Constrained Environments</title>
  <guid>http://arxiv.org/abs/2210.02628</guid>
  <link>http://arxiv.org/abs/2210.02628</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hari_S/0/1/0/all/0/1&quot;&gt;Sai Krishna Kanth Hari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rathinam_S/0/1/0/all/0/1&quot;&gt;Sivakumar Rathinam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darbha_S/0/1/0/all/0/1&quot;&gt;Swaroop Darbha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casbeer_D/0/1/0/all/0/1&quot;&gt;David W. Casbeer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider a mission framework in which two unmanned vehicles (UVs), a
leader and a wingmate, are required to provide cooperative coverage of an
environment while being within a short communication range. This framework
finds applications in underwater and/or military domains, where certain
constraints are imposed on communication by either the application or the
environment. An important objective of missions within this framework is to
minimize the total travel and communication costs of the leader-wingmate duo.
In this paper, we propose and formulate the problem of finding routes for the
UVs that minimize the sum of their travel and communication costs as a network
optimization problem of the form of a binary program (BP). The BP is
computationally expensive, with the time required to compute optimal solutions
increasing rapidly with the problem size. To address this challenge, here, we
propose two algorithms, an approximation algorithm and a heuristic algorithm,
to solve large-scale instances of the problem swiftly. We demonstrate the
effectiveness and the scalability of these algorithms through an analysis of
extensive numerical simulations performed over 500 instances, with the number
of targets in the instances ranging from 6 to 100.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>What Can We Compute in a Single Round of the Congested Clique?</title>
  <guid>http://arxiv.org/abs/2210.02638</guid>
  <link>http://arxiv.org/abs/2210.02638</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_P/0/1/0/all/0/1&quot;&gt;Peter Robinson&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the computational power of one-round distributed algorithms in the
congested clique model. We show that any one-round algorithm that computes a
minimum spanning tree (MST) in the unicast congested clique must use a link
bandwidth of $\Omega(\log^3 n)$ bits in the worst case. This is the first round
complexity lower bound in the unicast congested clique for a problem where the
output size is small, i.e., $O(n\log n)$ bits. Our main technical contribution
is to investigate one-round algorithms in the broadcast congested clique and,
equivalently, the distributed graph sketching model where the nodes send their
message to a referee who computes the output. First, we present a tight lower
bound of $\Omega(n)$ bits for the message size of computing a breadth-first
search tree. Then, we prove that computing a $k$-edge connected spanning
subgraph ($k$-ECSS) requires messages of size at least $\Omega \left(
k\log^2(n/k) \right)$. We also show that verifying whether a given vertex
coloring forms a weak 2-coloring of the input graph requires messages of
$\Omega(n^{1/3}\log^{2/3}n)$ bits, and the same lower bound holds for verifying
whether a subset of nodes forms a maximal independent set or a minimal
dominating set. Interestingly, it turns out that the same class of lower bound
graphs for the distributed sketching model is versatile enough to yield a space
lower bound of $\Omega(n^2)$ bits for verifying symmetry breaking problems such
as weak $2$-coloring in the fully dynamic turnstile model, where the input
arrives as a stream of edges. We also (nearly) settle the space complexity of
the $k$-ECSS problem in the streaming model by extending the work of Kapralov
et al. (FOCS 2017): We prove a communication complexity lower bound for a
direct sum variant of the $\text{UR}_k^{\subset}$ problem and show that this
implies $\Omega(k\,n\log^2(n/k))$ bits of memory for computing a $k$-ECSS.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Orthogonal Non-negative Matrix Factorization: a Maximum-Entropy-Principle Approach</title>
  <guid>http://arxiv.org/abs/2210.02672</guid>
  <link>http://arxiv.org/abs/2210.02672</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basiri_S/0/1/0/all/0/1&quot;&gt;Salar Basiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapadia_M/0/1/0/all/0/1&quot;&gt;Mustafa Kapadia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salapaka_S/0/1/0/all/0/1&quot;&gt;Srinivasa Salapaka&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we introduce a new methodology to solve the orthogonal
non-negative matrix factorization (ONMF) problem, where the objective is to
approximate an input data matrix by the product of two non-negative matrices,
the features matrix and the mixing matrix, while one of them is orthogonal. We
show how the ONMF can be interpreted as a specific facility-location problem
(FLP), and adapt a maximum-entropy-principle based solution for FLP to the ONMF
problem. The proposed approach guarantees orthogonality of the features or the
mixing matrix, while ensuring that both of the matrix factors are non-negative.
Also, the features (mixing) matrix has exactly one non-zero element across each
row (column), providing the maximum sparsity of the orthogonal factor. This
enables a semantic interpretation of the underlying data matrix using
non-overlapping features. The experiments on synthetic data and a standard
microarray dataset demonstrate significant improvements in terms of sparsity
and orthogonality scores of features (mixing) matrices, while achieving
approximately the same or better (up to 3%) reconstruction errors.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Paging with Succinct Predictions</title>
  <guid>http://arxiv.org/abs/2210.02775</guid>
  <link>http://arxiv.org/abs/2210.02775</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antoniadis_A/0/1/0/all/0/1&quot;&gt;Antonios Antoniadis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boyar_J/0/1/0/all/0/1&quot;&gt;Joan Boyar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elias_M/0/1/0/all/0/1&quot;&gt;Marek Eli&amp;#xe1;&amp;#x161;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Favrholdt_L/0/1/0/all/0/1&quot;&gt;Lene M. Favrholdt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoeksma_R/0/1/0/all/0/1&quot;&gt;Ruben Hoeksma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1&quot;&gt;Kim S. Larsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polak_A/0/1/0/all/0/1&quot;&gt;Adam Polak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simon_B/0/1/0/all/0/1&quot;&gt;Bertrand Simon&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Paging is a prototypical problem in the area of online algorithms. It has
also played a central role in the development of learning-augmented algorithms
-- a recent line of research that aims to ameliorate the shortcomings of
classical worst-case analysis by giving algorithms access to predictions. Such
predictions can typically be generated using a machine learning approach, but
they are inherently imperfect. Previous work on learning-augmented paging has
investigated predictions on (i) when the current page will be requested again
(reoccurrence predictions), (ii) the current state of the cache in an optimal
algorithm (state predictions), (iii) all requests until the current page gets
requested again, and (iv) the relative order in which pages are requested.
&lt;/p&gt;
&lt;p&gt;We study learning-augmented paging from the new perspective of requiring the
least possible amount of predicted information. More specifically, the
predictions obtained alongside each page request are limited to one bit only.
We consider two natural such setups: (i) discard predictions, in which the
predicted bit denotes whether or not it is ``safe&#39;&#39; to evict this page, and
(ii) phase predictions, where the bit denotes whether the current page will be
requested in the next phase (for an appropriate partitioning of the input into
phases). We develop algorithms for each of the two setups that satisfy all
three desirable properties of learning-augmented algorithms -- that is, they
are consistent, robust and smooth -- despite being limited to a one-bit
prediction per request. We also present lower bounds establishing that our
algorithms are essentially best possible.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Sequentially Swapping Tokens: Further on Graph Classes</title>
  <guid>http://arxiv.org/abs/2210.02835</guid>
  <link>http://arxiv.org/abs/2210.02835</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiya_H/0/1/0/all/0/1&quot;&gt;Hironori Kiya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okada_Y/0/1/0/all/0/1&quot;&gt;Yuto Okada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ono_H/0/1/0/all/0/1&quot;&gt;Hirotaka Ono&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Otachi_Y/0/1/0/all/0/1&quot;&gt;Yota Otachi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the following variant of the 15 puzzle. Given a graph and two token
placements on the vertices, we want to find a walk of the minimum length (if
any exists) such that the sequence of token swappings along the walk obtains
one of the given token placements from the other one. This problem was
introduced as Sequential Token Swapping by Yamanaka et al. [JGAA 2019], who
showed that the problem is intractable in general but polynomial-time solvable
for trees, complete graphs, and cycles. In this paper, we present a
polynomial-time algorithm for block-cactus graphs, which include all previously
known cases. We also present general tools for showing the hardness of problem
on restricted graph classes such as chordal graphs and chordal bipartite
graphs. We also show that the problem is hard on grids and king&#39;s graphs, which
are the graphs corresponding to the 15 puzzle and its variant with relaxed
moves.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Scalable Experimental Bounds for Entangled Quantum State Fidelities</title>
  <guid>http://arxiv.org/abs/2210.03048</guid>
  <link>http://arxiv.org/abs/2210.03048</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Aktar_S/0/1/0/all/0/1&quot;&gt;Shamminuj Aktar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bartschi_A/0/1/0/all/0/1&quot;&gt;Andreas B&amp;#xe4;rtschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Badawy_A/0/1/0/all/0/1&quot;&gt;Abdel-Hameed A. Badawy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Eidenbenz_S/0/1/0/all/0/1&quot;&gt;Stephan Eidenbenz&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Estimating the state preparation fidelity of highly entangled states on noisy
intermediate-scale quantum (NISQ) devices is an important task for benchmarking
and application considerations. Unfortunately, exact fidelity measurements
quickly become prohibitively expensive, as they scale exponentially as O(3^N)
for N-qubit states, using full state tomography with measurements in all Pauli
bases combinations.
&lt;/p&gt;
&lt;p&gt;However, it is known [Somma et.al. 2006] that the complexity can be
drastically reduced when looking at fidelity lower bounds for states that
exhibit symmetries, such as Dicke States and GHZ States. For larger states,
these bounds have so far not been tight enough to provide reasonable
estimations on today&#39;s (2022) NISQ devices. In this work, for the first time
and more than 15 years after the theoretical introduction, we report meaningful
lower bounds for the state preparation fidelity of all Dicke States up to N=10
and all GHZ states up to N=20 on Quantinuum H1 ion-trap systems using efficient
implementations of recently proposed scalable circuits for these states.
&lt;/p&gt;
&lt;p&gt;For example, we give state preparation fidelity lower bounds of (i) 0.46 for
the Dicke State |D10,5&amp;gt; and (ii) 0.73 for the GHZ State |G20&amp;gt;. These match or
exceed exact fidelity records recently achieved on superconducting systems for
the much smaller states |D6,3&amp;gt; and |G5&amp;gt;, respectively. Furthermore, we provide
evidence that for large Dicke States |DN,N/2&amp;gt;, we can resort to a GHZ-based
approximate state preparation to achieve better fidelity.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-07 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>The Google Supremacy Experiment: Data, Information, Discussions, and Three Questions.</title>
  <guid>http://gilkalai.wordpress.com/?p=23316</guid>
  <link>https://gilkalai.wordpress.com/2022/10/07/the-google-supremacy-experiment-data-information-discussions-and-three-questions/</link>
  <description>
    &lt;p&gt;&lt;/p&gt;


&lt;p&gt;Yosi Rinott, Tomer Shoham, and I  wrote a manuscript regarding our study of the Google 2019 supremacy experiment. This is still a draft and comments or corrections are most welcome. (The paper already incorporates a few comments by the Google team; October 11, 2022: a new version is posted based on  excellent comments and many corrections by Carsten &lt;span class=&quot;qu&quot; role=&quot;gridcell&quot;&gt;&lt;span class=&quot;gD&quot;&gt;Voelkmann.&lt;/span&gt;&lt;/span&gt;)&lt;/p&gt;
&lt;h3&gt;&lt;a href=&quot;https://gilkalai.files.wordpress.com/2022/10/cc22a19.pdf&quot;&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;Google’s 2019 “Quantum Supremacy” Claims: &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;Data, Documentation, &amp;amp; Discussion&lt;/span&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;by Gil Kalai, Yosef Rinott, and Tomer Shoham&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; In October 2019, &lt;/span&gt;&lt;/em&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;Nature &lt;/span&gt;&lt;em&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;published a paper describing an exper&lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;imental work that took place at Google. The paper claims to demon&lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;strate quantum (computational) supremacy on a 53-qubit quantum &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;computer.&lt;/span&gt; &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;Since September 2019 the authors have been involved in &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;a long-term project to study various statistical aspects of the Google &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;experiment.&lt;/span&gt; &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;In particular, we have been trying to gather the rele&lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;vant data and information, to reconstruct and verify those parts of &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;the Google 2019 supremacy experiments that are based on classical &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;computations (unless they require too heavy computation), and to &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;put the data under statistical analysis. We have now (August 2022) &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;concluded the part relating to the gathering of data and information &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;needed for our study of the 2019 Google experiment, and this docu&lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;ment describes the available data and information for the Google 2019 &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;experiment and some of our results and plans.&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The manuscript describes the stage of gathering data and information needed for our study and our analysis based on this data will be described separately. Statistical analysis of the Google experiment is already described in our Statistical Science paper  &lt;a href=&quot;https://gilkalai.files.wordpress.com/2022/08/sts836.pdf&quot;&gt;Statistical Aspects of the Quantum Supremacy Demonstration.&lt;/a&gt; (In this paper we mainly rely on data of 12-qubit and 14-qubit circuits.) Some preliminary statistical analysis is also given in Sections 6 and 7 of my paper  &lt;a href=&quot;https://gilkalai.files.wordpress.com/2020/08/laws-blog2.pdf&quot;&gt;The argument against quantum computers, the quantum laws of nature, and Google’s supremacy claims&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;em&gt;Quo Vadis&lt;/em&gt; random circuit sampling&lt;em&gt;&lt;span dir=&quot;ltr&quot;&gt;?&lt;/span&gt;&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;Here are three concrete questions about &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;random circuit sampling of a quantum circuit&lt;/span&gt; &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;C&lt;/span&gt; &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;of the kind discussed in the Google &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;paper &lt;span style=&quot;color:#ff0000;&quot;&gt;&lt;strong&gt;with&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;&lt;strong&gt; &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;22 qubits and depth&lt;/span&gt; &lt;/strong&gt;&lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;&lt;strong&gt;14&lt;/strong&gt;&lt;/span&gt;. These three questions refer, of course, to the ability of current &lt;span style=&quot;color:#0000ff;&quot;&gt;quantum computers&lt;/span&gt;  (it is quite easy to achieve them with classical simulations). &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;br role=&quot;presentation&quot; /&gt;&lt;em&gt;&lt;strong&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;1. Can humanity produce at present samples which are good approxima&lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;tions of the Google noise model or any other specific noise model?&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;2. Has humanity reached the ability to produce samples for quantum circuit &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;C&lt;/span&gt; &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;with&lt;/span&gt; fidelity according to the &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;linear cross entropy&lt;/span&gt; &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;fidelity-estimator above 0.15?&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;3. Has humanity reached the ability to predict, for a quantum circuit&lt;/span&gt; &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;C&lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;, &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;with good accuracy, the&lt;/span&gt; &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;linear cross entropy&lt;/span&gt; &lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;fidelity estimator based on the fidelity &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;of the individual components of this circuit?&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;The findings of our Statistical Science paper &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;indicate that the answer to the first ques&lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;tion is negative. The Google supremacy paper itself and subsequent confirmations &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;present a strong case for a positive answer to the other two questions (even for larger circuits). However, &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;there are remaining doubts and concerns that need to be carefully checked, &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;and not enough replications to regard the answer as a solid yes.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;How to check a 20-qubit quantum computer?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.gov.il/en/departments/general/iia-to-establish-israeli-quantum-computing-center-17-jul-2022&quot;&gt;It was announced&lt;/a&gt; recently that Israel is going to build a quantum computer. It is an interesting question to find a methodology to confirm that a 10-qubit, 20-qubit or 50-qubit quantum computer genuinely performs quantum computation or rather that the experimental data represents classical computation. In our Statistical Science paper we offered a certain blind experiment mechanism, but it still requires that classical simulation be much slower than quantum computing.&lt;/p&gt;
&lt;p&gt;In the new paper we also propose a mechanism for letting other groups test calibration methods (which are crucial ingredients in such experiments) on the Sycamore QC or other NISQ computers. In our discussions, the Google team endorsed both these proposals for future experiments. (See Section 5 of the new manuscript.)&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </description>
  <pubDate>2022-10-06 21:26:21 UTC</pubDate>
  <author>Gil Kalai</author>
</item>

<item>
  <title>Postdoc at IST Austria (apply by November 15, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/10/06/postdoc-at-ist-austria-apply-by-november-15-2022/</guid>
  <link>https://cstheory-jobs.org/2022/10/06/postdoc-at-ist-austria-apply-by-november-15-2022/</link>
  <description>
    &lt;p&gt;We are looking for three outstanding, highly-motivated postdoctoral researchers interested in working on combinatorial algorithm, especially in dynamic settings.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://ist.ac.at/en/job/postdoc-research-group-monika-henzinger/&quot;&gt;https://ist.ac.at/en/job/postdoc-research-group-monika-henzinger/&lt;/a&gt;&lt;br /&gt;
Email: monika.henzinger@ist.ac.at&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-10-06 19:12:28 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Art and Technology</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-6131043346672536750</guid>
  <link>http://blog.computationalcomplexity.org/2022/10/art-and-technology.html</link>
  <description>
    &lt;p&gt;Last weekend I went to one of Chicago&#39;s jewels, the Art Institute, and saw the opening of a new exhibit by Berlin-based artist Josephine Pryde entitled &lt;a href=&quot;https://www.artic.edu/exhibitions/2932/the-vibrating-slab&quot;&gt;The Vibrating Slab&lt;/a&gt;&amp;nbsp;referring mainly to the phone that constantly tries to gain our attention. The exhibit used photographs and sculptures to tie smart phones to prehistoric rocks. No pictures here because ironically they didn&#39;t allow us to take photos with our &quot;slabs&quot;.&lt;/p&gt;&lt;p&gt;After I saw the Pryde exhibit I went to see the artist herself give a presentation. She related a story where she talked about going to the movies and seeing &lt;a href=&quot;https://www.imdb.com/title/tt1745960&quot;&gt;Top Gun: Maverick&lt;/a&gt;, not knowing it is a new release. Tom Cruise, who&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/watch?v=PJqbivkm0Ms&quot;&gt;controlled a computer with hand movements&lt;/a&gt;&amp;nbsp;in Minority Report, goes old-school in Maverick. Cruise and several young actors, through various plot contrivances, flew 20th century planes in a movie that could have taken place in the 90s. According to IMBD, at the insistence of Tom Cruise, minimal green screen and CGI aerial shots exist in the film, and even the close up cockpit shots were taken during real in-flight sequences. Old school indeed. Kind of the opposite of say the Disney series &lt;a href=&quot;https://www.imdb.com/title/tt8111088/&quot;&gt;The Mandalorian&lt;/a&gt;&amp;nbsp;filmed in a soundstage with everything generated by CGI.&lt;/p&gt;&lt;p&gt;Pryde&#39;s exhibit looked at the interaction with technology as art. Upstairs from Pryde&#39;s exhibit was art from technology, a &lt;a href=&quot;https://www.artic.edu/exhibitions/9705/david-hockney-the-arrival-of-spring-normandy-2020&quot;&gt;series of prints&lt;/a&gt; that David Hockney created on another slab, the iPad, in Normandy during the early days of the Covid pandemic.&amp;nbsp;&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://artic-web.imgix.net/b8c0f3d0-2abc-4c17-9aba-629d8536e90d/IPD-2221.jpg?rect=0%2C0%2C3564%2C2490&amp;amp;auto=format%2Ccompress&amp;amp;q=80&amp;amp;fit=crop&amp;amp;crop=faces%2Cedges%2Centropy&amp;amp;w=1600&amp;amp;h=1118&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;559&quot; data-original-width=&quot;800&quot; height=&quot;280&quot; src=&quot;https://artic-web.imgix.net/b8c0f3d0-2abc-4c17-9aba-629d8536e90d/IPD-2221.jpg?rect=0%2C0%2C3564%2C2490&amp;amp;auto=format%2Ccompress&amp;amp;q=80&amp;amp;fit=crop&amp;amp;crop=faces%2Cedges%2Centropy&amp;amp;w=1600&amp;amp;h=1118&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;No. 340, 21st May 2020 - David Hockney&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div&gt;&lt;p&gt;On the way from Pryde&#39;s exhibit to the lecture I passed through the Art Institute&#39;s impressionism collection and compared real Monets with the fake one I created with Dall-E. Monet manages to capture a detailed scene with broad brush strokes--if you zoom in the detail disappears. Dall-E can&#39;t quite pull that off.&lt;/p&gt;&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://www.artic.edu/iiif/2/d39b1026-7d8d-6e6a-738e-8a136b1a0033/full/843,/0/default.jpg&quot; style=&quot;clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;770&quot; data-original-width=&quot;800&quot; height=&quot;308&quot; src=&quot;https://www.artic.edu/iiif/2/d39b1026-7d8d-6e6a-738e-8a136b1a0033/full/843,/0/default.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://www.artic.edu/artworks/14634/vetheuil&quot;&gt;Vétheuil&lt;/a&gt;&amp;nbsp;by Monet&lt;br /&gt;&lt;br /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZ6-EWvauVOODiC3Q6NtPqk34MFd8yF-m0Pr8qms48vtunPrdnclEYpSdFnlm691u7vTf4qU7EkPCOSaY8NSmfxh6FYsgKUN5QWaAzirVQDaX_Y9kZarqcyCtUafapja3KIy3k6bUd9SrlL83yCOnayQgseDMD3xcCwfPzvb0kimeKIr8FDw/s1024/DALL%C2%B7E%202022-09-17%2014.00.36%20-%20Schloss%20Dagstuhl%20in%20the%20style%20of%20monet.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1024&quot; data-original-width=&quot;1024&quot; height=&quot;320&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZ6-EWvauVOODiC3Q6NtPqk34MFd8yF-m0Pr8qms48vtunPrdnclEYpSdFnlm691u7vTf4qU7EkPCOSaY8NSmfxh6FYsgKUN5QWaAzirVQDaX_Y9kZarqcyCtUafapja3KIy3k6bUd9SrlL83yCOnayQgseDMD3xcCwfPzvb0kimeKIr8FDw/w320-h320/DALL%C2%B7E%202022-09-17%2014.00.36%20-%20Schloss%20Dagstuhl%20in%20the%20style%20of%20monet.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Monet Dagsthul by Dall-E&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;/div&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2022-10-06 13:40:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>A Counterexample to a Directed KKL Inequality</title>
  <guid>http://arxiv.org/abs/2210.02035</guid>
  <link>http://arxiv.org/abs/2210.02035</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dubroff_Q/0/1/0/all/0/1&quot;&gt;Quentin Dubroff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nadimpalli_S/0/1/0/all/0/1&quot;&gt;Shivam Nadimpalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Narayanan_B/0/1/0/all/0/1&quot;&gt;Bhargav Narayanan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that the natural directed analogues of the KKL theorem [KKL88] and
the Eldan--Gross inequality [EG20] from the analysis of Boolean functions fail
to hold. This is in contrast to several other isoperimetric inequalities on the
Boolean hypercube (such as the Poincare inequality, Margulis&#39;s inequality
[Mar74] and Talagrand&#39;s inequality [Tal93]) for which directed strengthenings
have recently been established.
&lt;/p&gt;
  </description>
  <pubDate>2022-10-06 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

</channel>
</rss>
