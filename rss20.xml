<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>junior professor (chaire de professeur junior) at University Lyon 1 (apply by May 12, 2023)</title>
  <guid>http://cstheory-jobs.org/2023/04/14/junior-professor-chaire-de-professeur-junior-at-university-lyon-1-apply-by-may-12-2023/</guid>
  <link>https://cstheory-jobs.org/2023/04/14/junior-professor-chaire-de-professeur-junior-at-university-lyon-1-apply-by-may-12-2023/</link>
  <description>
    &lt;p&gt;Tenure track position with a low teaching load and an attractive financial package. Teaching at University Lyon 1 and research in theoretical computer science at the LIP laboratory, located at Ecole Normale Supérieure de Lyon. Teaching in English is possible. Contact person for research: Nicolas Trotignon. For teaching: Saida Bouakaz.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.univ-lyon1.fr/universite/travailler-a-lyon-1/recrutement-chaires-de-professeurs-junior-2022#.ZDkD7exBz9G&quot;&gt;https://www.univ-lyon1.fr/universite/travailler-a-lyon-1/recrutement-chaires-de-professeurs-junior-2022#.ZDkD7exBz9G&lt;/a&gt;&lt;br /&gt;
Email: nicolas.trotignon@ens-lyon.fr&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 07:51:11 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>The 2-Attractor Problem is NP-Complete</title>
  <guid>http://arxiv.org/abs/2304.06523</guid>
  <link>http://arxiv.org/abs/2304.06523</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fuchs_J/0/1/0/all/0/1&quot;&gt;Janosch Fuchs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whittington_P/0/1/0/all/0/1&quot;&gt;Philip Whittington&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A $k$-attractor is a combinatorial object unifying dictionary-based
compression. It allows to compare the repetitiveness measures of different
dictionary compressors such as Lempel-Ziv 77, the Burrows-Wheeler transform,
straight line programs and macro schemes. For a string $ T \in \Sigma^n$, the
$k$-attractor is defined as a set of positions $\Gamma \subseteq [1,n]$, such
that every distinct substring of length at most $k$ is covered by at least one
of the selected positions. Thus, if a substring occurs multiple times in $T$,
one position suffices to cover it. A 1-attractor is easily computed in linear
time, while Kempa and Prezza [STOC 2018] have shown that for $k \geq 3$, it is
NP-complete to compute the smallest $k$-attractor by a reduction from $k$-set
cover.
&lt;/p&gt;
&lt;p&gt;The main result of this paper answers the open question for the complexity of
the 2-attractor problem, showing that the problem remains NP-complete. Kempa
and Prezza&#39;s proof for $k \geq 3$ also reduces the 2-attractor problem to the
2-set cover problem, which is equivalent to edge cover, but that does not fully
capture the complexity of the 2-attractor problem. For this reason, we extend
edge cover by a color function on the edges, yielding the colorful edge cover
problem. Any edge cover must then satisfy the additional constraint that each
color is represented. This extension raises the complexity such that colorful
edge cover becomes NP-complete while also more precisely modeling the
2-attractor problem. We obtain a reduction showing $k$-attractor to be
NP-complete for any $k \geq 2$.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Influences of Fourier Completely Bounded Polynomials and Classical Simulation of Quantum Algorithms</title>
  <guid>http://arxiv.org/abs/2304.06713</guid>
  <link>http://arxiv.org/abs/2304.06713</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gutierrez_F/0/1/0/all/0/1&quot;&gt;Francisco Escudero Guti&amp;#xe9;rrez&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give a new presentation of the main result of Arunachalam, Bri\&quot;et and
Palazuelos (SICOMP&#39;19) and show that quantum query algorithms are characterized
by a new class of polynomials which we call Fourier completely bounded
polynomials. We conjecture that all such polynomials have an influential
variable. This conjecture is weaker than the famous Aaronson-Ambainis (AA)
conjecture (Theory of Computing&#39;14), but has the same implications for
classical simulation of quantum query algorithms.
&lt;/p&gt;
&lt;p&gt;We prove a new case of the AA conjecture by showing that it holds for
homogeneous Fourier completely bounded polynomials. This implies that if the
output of $d$-query quantum algorithm is a homogeneous polynomial $p$ of degree
$2d$, then it has a variable with influence at least $Var[p]^2$.
&lt;/p&gt;
&lt;p&gt;In addition, we give an alternative proof of the results of Bansal, Sinha and
de Wolf (CCC&#39;22 and QIP&#39;23) showing that block-multilinear completely bounded
polynomials have influential variables. Our proof is simpler, obtains better
constants and does not use randomness.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>How Will It Drape Like? Capturing Fabric Mechanics from Depth Images</title>
  <guid>http://arxiv.org/abs/2304.06704</guid>
  <link>http://arxiv.org/abs/2304.06704</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_Pardo_C/0/1/0/all/0/1&quot;&gt;Carlos Rodriguez-Pardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prieto_Martin_M/0/1/0/all/0/1&quot;&gt;Melania Prieto-Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casas_D/0/1/0/all/0/1&quot;&gt;Dan Casas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garces_E/0/1/0/all/0/1&quot;&gt;Elena Garces&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We propose a method to estimate the mechanical parameters of fabrics using a
casual capture setup with a depth camera. Our approach enables to create
mechanically-correct digital representations of real-world textile materials,
which is a fundamental step for many interactive design and engineering
applications. As opposed to existing capture methods, which typically require
expensive setups, video sequences, or manual intervention, our solution can
capture at scale, is agnostic to the optical appearance of the textile, and
facilitates fabric arrangement by non-expert operators. To this end, we propose
a sim-to-real strategy to train a learning-based framework that can take as
input one or multiple images and outputs a full set of mechanical parameters.
Thanks to carefully designed data augmentation and transfer learning protocols,
our solution generalizes to real images despite being trained only on synthetic
data, hence successfully closing the sim-to-real loop.Key in our work is to
demonstrate that evaluating the regression accuracy based on the similarity at
parameter space leads to an inaccurate distances that do not match the human
perception. To overcome this, we propose a novel metric for fabric drape
similarity that operates on the image domain instead on the parameter space,
allowing us to evaluate our estimation within the context of a similarity rank.
We show that out metric correlates with human judgments about the perception of
drape similarity, and that our model predictions produce perceptually accurate
results compared to the ground truth parameters.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance</title>
  <guid>http://arxiv.org/abs/2304.06715</guid>
  <link>http://arxiv.org/abs/2304.06715</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crabbe_J/0/1/0/all/0/1&quot;&gt;Jonathan Crabb&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;Mihaela van der Schaar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Interpretability methods are valuable only if their explanations faithfully
describe the explained model. In this work, we consider neural networks whose
predictions are invariant under a specific symmetry group. This includes
popular architectures, ranging from convolutional to graph neural networks. Any
explanation that faithfully explains this type of model needs to be in
agreement with this invariance property. We formalize this intuition through
the notion of explanation invariance and equivariance by leveraging the
formalism from geometric deep learning. Through this rigorous formalism, we
derive (1) two metrics to measure the robustness of any interpretability method
with respect to the model symmetry group; (2) theoretical robustness guarantees
for some popular interpretability methods and (3) a systematic approach to
increase the invariance of any interpretability method with respect to a
symmetry group. By empirically measuring our metrics for explanations of models
associated with various modalities and symmetry groups, we derive a set of 5
guidelines to allow users and developers of interpretability methods to produce
robust explanations.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Locality via Global Ties: Stability of the 2-Core Against Misspecification</title>
  <guid>http://arxiv.org/abs/2304.06170</guid>
  <link>http://arxiv.org/abs/2304.06170</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borgs_C/0/1/0/all/0/1&quot;&gt;Christian Borgs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1&quot;&gt;Geng Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For many random graph models, the analysis of a related birth process
suggests local sampling algorithms for the size of, e.g., the giant connected
component, the $k$-core, the size and probability of an epidemic outbreak, etc.
In this paper, we study the question of when these algorithms are robust
against misspecification of the graph model, for the special case of the
2-core. We show that, for locally converging graphs with bounded average
degrees, under a weak notion of expansion, a local sampling algorithm provides
robust estimates for the size of both the 2-core and its largest component. Our
weak notion of expansion generalizes the classical definition of expansion,
while holding for many well-studied random graph models.
&lt;/p&gt;
&lt;p&gt;Our method involves a two-step sprinkling argument. In the first step, we use
sprinkling to establish the existence of a non-empty $2$-core inside the giant,
while in the second, we use this non-empty $2$-core as seed for a second
sprinkling argument to establish that the giant contains a linear sized
$2$-core. The second step is based on a novel coloring scheme for the vertices
in the tree-part. Our algorithmic results follow from the structural properties
for the $2$-core established in the course of our sprinkling arguments.
&lt;/p&gt;
&lt;p&gt;The run-time of our local algorithm is constant independent of the graph
size, with the value of the constant depending on the desired asymptotic
accuracy $\epsilon$. But given the existential nature of local limits, our
arguments do not give any bound on the functional dependence of this constant
on $\epsilon$, nor do they give a bound on how large the graph has to be for
the asymptotic additive error bound $\epsilon$ to hold.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Universally Optimal Deterministic Broadcasting in the HYBRID Distributed Model</title>
  <guid>http://arxiv.org/abs/2304.06317</guid>
  <link>http://arxiv.org/abs/2304.06317</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yi-Jun Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hecht_O/0/1/0/all/0/1&quot;&gt;Oren Hecht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leitersdorf_D/0/1/0/all/0/1&quot;&gt;Dean Leitersdorf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In theoretical computer science, it is a common practice to show existential
lower bounds for problems, meaning there is a family of pathological inputs on
which no algorithm can do better. However, most inputs of interest can be
solved much more efficiently, giving rise to the notion of universally optimal
algorithms, which run as fast as possible on every input. Questions on the
existence of universally optimal algorithms were first raised by Garay, Kutten,
and Peleg in FOCS &#39;93. This research direction reemerged recently through a
series of works, including the influential work of Haeupler, Wajc, and Zuzic in
STOC &#39;21, which resolves some of these decades-old questions in the supported
CONGEST model.
&lt;/p&gt;
&lt;p&gt;We work in the HYBRID distributed model, which analyzes networks combining
both global and local communication. Much attention has recently been devoted
to solving distance related problems, such as All-Pairs Shortest Paths (APSP)
in HYBRID, culminating in a $\tilde \Theta(n^{1/2})$ round algorithm for exact
APSP. However, by definition, every problem in HYBRID is solvable in $D$
(diameter) rounds, showing that it is far from universally optimal.
&lt;/p&gt;
&lt;p&gt;We show the first universally optimal algorithms in HYBRID, by presenting a
fundamental tool that solves any broadcasting problem in a universally optimal
number of rounds, deterministically. Specifically, we consider the problem in a
graph $G$ where a set of $k$ messages $M$ distributed arbitrarily across $G$,
requires every node to learn all of $M$. We show a universal lower bound and a
matching, deterministic upper bound, for any graph $G$, any value $k$, and any
distribution of $M$ across $G$.
&lt;/p&gt;
&lt;p&gt;This broadcasting tool opens a new exciting direction of research into
showing universally optimal algorithms in HYBRID. As an example, we use it to
obtain algorithms for approximate and exact APSP in general and sparse graphs.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Load Balanced Demand Distribution under Overload Penalties</title>
  <guid>http://arxiv.org/abs/2304.06543</guid>
  <link>http://arxiv.org/abs/2304.06543</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramnath_S/0/1/0/all/0/1&quot;&gt;Sarnath Ramnath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunturi_V/0/1/0/all/0/1&quot;&gt;Venkata M. V. Gunturi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dangol_S/0/1/0/all/0/1&quot;&gt;Subi Dangol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1&quot;&gt;Abhishek Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1&quot;&gt;Pradeep Kumar&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Input to the Load Balanced Demand Distribution (LBDD) consists of the
following: (a) a set of public service centers (e.g., schools); (b) a set of
demand (people) units and; (c) a cost matrix containing the cost of assignment
for all demand unit-service center pairs. In addition, each service center is
also associated with a notion of capacity and a penalty which is incurred if it
gets overloaded. Given the input, the LBDD problem determines a mapping from
the set of demand units to the set of service centers. The objective is to
determine a mapping that minimizes the sum of the following two terms: (i) the
total assignment cost between demand units and their allotted service centers
and, (ii) total of penalties incurred. The problem of LBDD finds its
application in the domain of urban planning. An instance of the LBDD problem
can be reduced to an instance of the min-cost bi-partite matching problem.
However, this approach cannot scale up to the real world large problem
instances. The current state of the art related to LBDD makes simplifying
assumptions such as infinite capacity or total capacity being equal to the
total demand. This paper proposes a novel allotment subspace re-adjustment
based approach (ASRAL) for the LBDD problem. We analyze ASRAL theoretically and
present its asymptotic time complexity. We also evaluate ASRAL experimentally
on large problem instances and compare with alternative approaches. Our results
indicate that ASRAL is able to scale-up while maintaining significantly better
solution quality over the alternative approaches. In addition, we also extend
ASRAL to para-ASRAL which uses the GPU and CPU cores to speed-up the execution
while maintaining the same solution quality as ASRAL.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Beyond the Quadratic Time Barrier for Network Unreliability</title>
  <guid>http://arxiv.org/abs/2304.06552</guid>
  <link>http://arxiv.org/abs/2304.06552</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cen_R/0/1/0/all/0/1&quot;&gt;Ruoxu Cen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1&quot;&gt;William He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jason Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panigrahi_D/0/1/0/all/0/1&quot;&gt;Debmalya Panigrahi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Karger (STOC 1995) gave the first FPTAS for the network (un)reliability
problem, setting in motion research over the next three decades that obtained
increasingly faster running times, eventually leading to a
$\tilde{O}(n^2)$-time algorithm (Karger, STOC 2020). This represented a natural
culmination of this line of work because the algorithmic techniques used can
enumerate $\Theta(n^2)$ (near)-minimum cuts. In this paper, we go beyond this
quadratic barrier and obtain a faster algorithm for the network unreliability
problem. Our algorithm runs in $m^{1+o(1)} + \tilde{O}(n^{1.5})$ time.
&lt;/p&gt;
&lt;p&gt;Our main contribution is a new estimator for network unreliability in very
reliable graphs. These graphs are usually the bottleneck for network
unreliability since the disconnection event is elusive. Our estimator is
obtained by defining an appropriate importance sampling subroutine on a dual
spanning tree packing of the graph. To complement this estimator for very
reliable graphs, we use recursive contraction for moderately reliable graphs.
We show that an interleaving of sparsification and contraction can be used to
obtain a better parametrization of the recursive contraction algorithm that
yields a faster running time matching the one obtained for the very reliable
case.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>List Update with Delays or Time Windows</title>
  <guid>http://arxiv.org/abs/2304.06565</guid>
  <link>http://arxiv.org/abs/2304.06565</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azar_Y/0/1/0/all/0/1&quot;&gt;Yossi Azar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lewkowicz_S/0/1/0/all/0/1&quot;&gt;Shahar Lewkowicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vainstein_D/0/1/0/all/0/1&quot;&gt;Danny Vainstein&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of List Update, one of the most fundamental problems
in online algorithms. We are given a list of elements and requests for these
elements that arrive over time. Our goal is to serve these requests, at a cost
equivalent to their position in the list, with the option of moving them
towards the head of the list. Sleator and Tarjan introduced the famous &quot;Move to
Front&quot; algorithm (wherein any requested element is immediately moved to the
head of the list) and showed that it is 2-competitive. While this bound is
excellent, the absolute cost of the algorithm&#39;s solution may be very large
(e.g., requesting the last half elements of the list would result in a solution
cost that is quadratic in the length of the list). Thus, we consider the more
general problem wherein every request arrives with a deadline and must be
served, not immediately, but rather before the deadline. We further allow the
algorithm to serve multiple requests simultaneously. We denote this problem as
List Update with Time Windows. While this generalization benefits from lower
solution costs, it requires new types of algorithms. In particular, for the
simple example of requesting the last half elements of the list with
overlapping time windows, Move-to-Front fails. We show an O(1) competitive
algorithm. The algorithm is natural but the analysis is a bit complicated and a
novel potential function is required. Thereafter we consider the more general
problem of List Update with Delays in which the deadlines are replaced with
arbitrary delay functions. This problem includes as a special case the prize
collecting version in which a request might not be served (up to some deadline)
and instead suffers an arbitrary given penalty. Here we also establish an O(1)
competitive algorithm for general delays. The algorithm for the delay version
is more complex and its analysis is significantly more involved.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Solving Tensor Low Cycle Rank Approximation</title>
  <guid>http://arxiv.org/abs/2304.06594</guid>
  <link>http://arxiv.org/abs/2304.06594</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yichuan Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yeqi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Large language models have become ubiquitous in modern life, finding
applications in various domains such as natural language processing, language
translation, and speech recognition. Recently, a breakthrough work [Zhao,
Panigrahi, Ge, and Arora Arxiv 2023] explains the attention model from
probabilistic context-free grammar (PCFG). One of the central computation task
for computing probability in PCFG is formulating a particular tensor low rank
approximation problem, we can call it tensor cycle rank. Given an $n \times n
\times n$ third order tensor $A$, we say that $A$ has cycle rank-$k$ if there
exists three $n \times k^2$ size matrices $U , V$, and $W$ such that for each
entry in each \begin{align*} A_{a,b,c} = \sum_{i=1}^k \sum_{j=1}^k \sum_{l=1}^k
U_{a,i+k(j-1)} \otimes V_{b, j + k(l-1)} \otimes W_{c, l + k(i-1) }
\end{align*} for all $a \in [n], b \in [n], c \in [n]$. For the tensor
classical rank, tucker rank and train rank, it has been well studied in [Song,
Woodruff, Zhong SODA 2019]. In this paper, we generalize the previous
``rotation and sketch&#39;&#39; technique in page 186 of [Song, Woodruff, Zhong SODA
2019] and show an input sparsity time algorithm for cycle rank.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Beyond Submodularity: A Unified Framework of Randomized Set Selection with Group Fairness Constraints</title>
  <guid>http://arxiv.org/abs/2304.06596</guid>
  <link>http://arxiv.org/abs/2304.06596</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shaojie Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1&quot;&gt;Jing Yuan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Machine learning algorithms play an important role in a variety of important
decision-making processes, including targeted advertisement displays, home loan
approvals, and criminal behavior predictions. Given the far-reaching impact of
these algorithms, it is crucial that they operate fairly, free from bias or
prejudice towards certain groups in the population. Ensuring impartiality in
these algorithms is essential for promoting equality and avoiding
discrimination. To this end we introduce a unified framework for randomized
subset selection that incorporates group fairness constraints. Our problem
involves a global utility function and a set of group utility functions for
each group, here a group refers to a group of individuals (e.g., people)
sharing the same attributes (e.g., gender). Our aim is to generate a
distribution across feasible subsets, specifying the selection probability of
each feasible set, to maximize the global utility function while meeting a
predetermined quota for each group utility function in expectation. Note that
there may not necessarily be any direct connections between the global utility
function and each group utility function. We demonstrate that this framework
unifies and generalizes many significant applications in machine learning and
operations research. Our algorithmic results either improves the best known
result or provide the first approximation algorithms for new applications.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Improved Approximations for Relative Survivable Network Design</title>
  <guid>http://arxiv.org/abs/2304.06656</guid>
  <link>http://arxiv.org/abs/2304.06656</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dinitz_M/0/1/0/all/0/1&quot;&gt;Michael Dinitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koranteng_A/0/1/0/all/0/1&quot;&gt;Ama Koranteng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kortsarz_G/0/1/0/all/0/1&quot;&gt;Guy Kortsarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nutov_Z/0/1/0/all/0/1&quot;&gt;Zeev Nutov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;One of the most important and well-studied settings for network design is
edge-connectivity requirements. This encompasses uniform demands such as the
Minimum $k$-Edge-Connected Spanning Subgraph problem as well as nonuniform
demands such as the Survivable Network Design problem (SND). In a recent paper
by [Dinitz, Koranteng, Kortsarz APPROX &#39;22] , the authors observed that a
weakness of these formulations is that it does not enable one to consider
fault-tolerance in graphs that have just one small cut. To remedy this, they
introduced new variants of these problems under the notion &quot;relative&quot;
fault-tolerance. Informally, this requires not that two nodes are connected if
there are a bounded number of faults (as in the classical setting), but that
two nodes are connected if there are a bounded number of faults and the two
nodes are connected in the underlying graph post-faults. The problem is already
highly non-trivial even for the case of a single demand.
&lt;/p&gt;
&lt;p&gt;Due to difficulties introduced by this new notion of fault-tolerance, the
results in [Dinitz, Koranteng, Kortsarz APPROX &#39;22] are quite limited. For the
Relative Survivable Network Design problem (RSND), when the demands are not
uniform they give a nontrivial result only when there is a single demand with a
connectivity requirement of $3$: a non-optimal $27/4$-approximation. We
strengthen this result in two significant ways: We give a $2$-approximation for
RSND where all requirements are at most $3$, and a $2^{O(k^2)}$-approximation
for RSND with a single demand of arbitrary value $k$. To achieve these results,
we first use the &quot;cactus representation&#39;&#39; of minimum cuts to give a lossless
reduction to normal SND. Second, we extend the techniques of [Dinitz,
Koranteng, Kortsarz APPROX &#39;22] to prove a generalized and more complex version
of their structure theorem, which we then use to design a recursive
approximation algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On streaming approximation algorithms for constraint satisfaction problems</title>
  <guid>http://arxiv.org/abs/2304.06664</guid>
  <link>http://arxiv.org/abs/2304.06664</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singer_N/0/1/0/all/0/1&quot;&gt;Noah G. Singer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this thesis, we explore streaming algorithms for approximating constraint
satisfaction problems (CSPs). The setup is roughly the following: A computer
has limited memory space, sees a long &quot;stream&quot; of local constraints on a set of
variables, and tries to estimate how many of the constraints may be
simultaneously satisfied. The past ten years have seen a number of works in
this area, and this thesis includes both expository material and novel
contributions. Throughout, we emphasize connections to the broader theories of
CSPs, approximability, and streaming models, and highlight interesting open
problems.
&lt;/p&gt;
&lt;p&gt;The first part of our thesis is expository: We present aspects of previous
works that completely characterize the approximability of specific CSPs like
Max-Cut and Max-Dicut with $\sqrt{n}$-space streaming algorithm (on
$n$-variable instances), while characterizing the approximability of all CSPs
in $\sqrt n$ space in the special case of &quot;composable&quot; (i.e., sketching)
algorithms, and of a particular subclass of CSPs with linear-space streaming
algorithms.
&lt;/p&gt;
&lt;p&gt;In the second part of the thesis, we present two of our own joint works. We
begin with a work with Madhu Sudan and Santhoshini Velusamy in which we prove
linear-space streaming approximation-resistance for all ordering CSPs (OCSPs),
which are &quot;CSP-like&quot; problems maximizing over sets of permutations. Next, we
present joint work with Joanna Boyland, Michael Hwang, Tarun Prasad, and
Santhoshini Velusamy in which we investigate the $\sqrt n$-space streaming
approximability of symmetric Boolean CSPs with negations. We give explicit
$\sqrt n$-space sketching approximability ratios for several families of CSPs,
including Max-$k$AND; develop simpler optimal sketching approximation
algorithms for threshold predicates; and show that previous lower bounds fail
to characterize the $\sqrt n$-space streaming approximability of Max-$3$AND.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>My Week at Simons</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-6757105980544925558</guid>
  <link>https://blog.computationalcomplexity.org/2023/04/my-week-at-simons.html</link>
  <description>
    &lt;p&gt;This week finds me at the &lt;a href=&quot;https://simons.berkeley.edu/&quot;&gt;Simons Institute for Theoretical Computer Science&lt;/a&gt; in Berkeley California. Simons started about the same time I joined the administrative ranks and never had the opportunity to spend a full semester there. I can manage a shorter trip and purposely chose a week with no workshops and great visitors including Sam Buss, Russell Impagliazzo, Valentine Kabanets, Toni Pitassi, Ryan Williams, former student Rahul Santhanam and former postdocs Pavan Aduri and Vinod Variyam and &lt;a href=&quot;https://simons.berkeley.edu/people/visitors&quot;&gt;many others&lt;/a&gt; including the next generations of complexity theory leaders. Simons is having programs on &lt;a href=&quot;https://simons.berkeley.edu/programs/Meta-Complexity2023&quot;&gt;Meta-Complexity&lt;/a&gt; and an &quot;extended reunion&quot; for &lt;a href=&quot;https://simons.berkeley.edu/programs/extended-reunion-satisfiability&quot;&gt;Satisfiability&lt;/a&gt;. Apparently I used to work on Meta-Complexity before it was a thing.&lt;/p&gt;&lt;p&gt;Computational complexity traditionally has tried to get ahead of new technologies, and modelled randomized, parallel, quantum computation and cryptography in the infancy of their development allowing complexity to help guide our understanding and development of these areas. In the last twenty years or so, complexity has migrated more towards mathematics, and has mostly missed technological changes like cloud computing, hierarchical memory models, edge and mobile computing for example.&amp;nbsp;&lt;/p&gt;&lt;p&gt;But the recent advances in optimization and machine learning cannot be ignored. There has certainly been plenty of discussion of ChatGPT and Russell gave an informal lecture yesterday trying to model large-language models at some level. I&#39;ve been having some discussions about how complexity can answer questions like what it means for a model to be explainable.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Complexity theory also out to reckon that practically we seem to be getting the best of P = NP while avoiding losing cryptography &lt;a href=&quot;https://blog.computationalcomplexity.org/2020/12/optiland.html&quot;&gt;simultaneously&lt;/a&gt; in Heuristica and Cryptomania among Russell&#39;s &lt;a href=&quot;https://blog.computationalcomplexity.org/2004/06/impagliazzos-five-worlds.html&quot;&gt;five worlds&lt;/a&gt;. Russell claims we&#39;re not in Heuristica, at least not now, since we can still generate hard to solve problems. But if our models aren&#39;t modeling the world we live in, perhaps it&#39;s time to rethink the models.&amp;nbsp;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2023-04-13 17:07:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>TR23-045 |  Tight Correlation Bounds for Circuits Between AC0 and TC0 | 

	Vinayak Kumar</title>
  <guid>https://eccc.weizmann.ac.il/report/2023/045</guid>
  <link>https://eccc.weizmann.ac.il/report/2023/045</link>
  <description>
    We initiate the study of generalized $AC^0$ circuits comprised of arbitrary unbounded fan-in gates which only need to be constant over inputs of Hamming weight $\ge k$ (up to negations of the input bits), which we denote $GC^0(k)$. The gate set of this class includes biased LTFs like the $k$-$OR$ (outputs $1$ iff $\ge k$ bits are $1$) and $k$-$AND$ (outputs $0$ iff $\ge k$ bits are $0$), and thus can be seen as an interpolation between $AC^0$ and $TC^0$. 

We establish a tight multi-switching lemma for $GC(k)$ circuits, which bounds the probability that several depth-2 $GC^0(k)$ circuits do not simultaneously simplify under a random restriction. We also establish a new depth reduction lemma such that coupled with our multi-switching lemma, we can show many results obtained from the multi-switching lemma for depth-$d$ size-$s$ $AC^0$ circuits lifts to depth-$d$ size-$s^{.99}$ $GC^0(.01\log s)$ circuits with no loss in parameters (other than hidden constants). 

Our result has the following applications:

-Size-$2^{\Omega(n^{1/d})}$ depth-$d$ $GC^0(\Omega(n^{1/d}))$ circuits do not correlate with parity (extending a result of Håstad (SICOMP, 2014)).

-Size-$n^{\Omega(\log n)}$ $GC^0(\Omega(\log^2 n))$ circuits with $n^{.249}$ arbitrary threshold gates or $n^{.499}$ arbitrary symmetric gates exhibit exponentially small correlation against an explicit function (extending a result of Tan and Servedio (RANDOM, 2019)).

-There is a seed length $O((\log m)^{d-1}\log(m/\varepsilon)\log\log(m))$ pseudorandom generator against size-$m$ depth-$d$ $GC^0(\log m)$ circuits, matching the $AC^0$ lower bound of Håstad up to a $\log\log m$ factor (extending a result of Lyu (CCC, 2022)).

-Size-$m$ $GC^0(\log m)$ circuits have exponentially small Fourier tails (extending a result of Tal (CCC, 2017)).
  </description>
  <pubDate>2023-04-13 11:23:19 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>ACM Prize to Yael Kalai</title>
  <guid>https://rjlipton.wpcomstaging.com/?p=21427</guid>
  <link>https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/</link>
  <description>
    &lt;p&gt;
&lt;font color=&quot;#0044cc&quot;&gt;&lt;br /&gt;
&lt;em&gt;Plus evocations of the roles of complexity and verification in crypto and human relations&lt;/em&gt;&lt;br /&gt;
&lt;font color=&quot;#000000&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/kalai_6965246/&quot; rel=&quot;attachment wp-att-21430&quot;&gt;&lt;img data-attachment-id=&quot;21430&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/kalai_6965246/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?fit=485%2C550&amp;amp;ssl=1&quot; data-orig-size=&quot;485,550&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;kalai_6965246&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?fit=265%2C300&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?fit=485%2C550&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?resize=124%2C138&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;124&quot; height=&quot;138&quot; class=&quot;alignright wp-image-21430&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
Yael Kalai has just been named the winner of the &lt;a href=&quot;https://awards.acm.org/about/2022-acm-prize&quot;&gt;2022 ACM Prize&lt;/a&gt;. She works at Microsoft Research. &lt;/p&gt;
&lt;p&gt;
Today we congratulate her, say a little about her work, and riff on some related and &amp;#8220;unrelated&amp;#8221; matters.&lt;/p&gt;
&lt;p&gt;
The prize cites Kalai for her work on cryptography. Her work is immediately practical. It provides both ways to speed up interactive protocols and to verify the results. Two ways of speeding up the kind of protocols we engage in daily are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
Reduce the number of rounds of interaction needed. &lt;/p&gt;
&lt;li&gt;
Shift the computational burden from the weaker party (exemplified by your credit card chip) to the stronger party&amp;#8212;without allowing the latter more ways to be malicious.
&lt;/ol&gt;
&lt;p&gt;
One also needs to devise and provide an efficient certificate that the security needs have been met.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Her Work &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Kalai&amp;#8217;s work on objective 1 starts with a &lt;a href=&quot;https://en.wikipedia.org/wiki/Fiat-Shamir_heuristic&quot;&gt;paradigm&lt;/a&gt; originally expounded by Amos Fiat and Adi Shamir in the 1980s:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; An interactive round in which Arthur challenges Merlin with a string he chose &lt;b&gt;randomly&lt;/b&gt; from public coins can be replaced by nonteractive requests to a random oracle. The oracle in turn can be simulated via a cryptographically strong hash function. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
The second clause is the delicate one. How can we know, in a particular application, that a particular hash function does not have correlations that could be exploited by malicious choices of plaintext or seed strings? She and Shafi Goldwasser, her PhD advisor, &lt;a href=&quot;https://eprint.iacr.org/2003/034.pdf&quot;&gt;showed&lt;/a&gt; cases where a 3-round protocol secure in the random oracle model becomes insecure under cases of this transformation. &lt;/p&gt;
&lt;p&gt;
However, in a series of papers culminating in a &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3313276.3316380&quot;&gt;Part I&lt;/a&gt; and a &lt;a href=&quot;https://eprint.iacr.org/2018/1248.pdf&quot;&gt;Part II&lt;/a&gt;, she and coauthors designed cases that work under progressively more reasonable hardness assumptions. (Note: the date on the &amp;#8220;Part II&amp;#8221; paper is three days earlier than that on the &amp;#8220;Part I&amp;#8221;&amp;#8211;a good solution to a problem we noted at the end of &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2013/03/13/no-go-theorems/&quot;&gt;this post&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;
Objective 2 not only runs the risk of leakage in shifting the party who executes the computation, it involves issues of trust. How does the one who delegated the task know the result is correct, without having done the computation? This leads to issues of proving computations correct that we have mentioned, but with a twist: both the computation and the proof needs to be real-time efficient to generate. Her many papers on this (ACM features &lt;a href=&quot;https://dl.acm.org/doi/10.1145/2699436&quot;&gt;these&lt;/a&gt; &lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/3456867&quot;&gt;two&lt;/a&gt;) are well represented in a &lt;a href=&quot;https://gilkalai.files.wordpress.com/2018/01/cacm-delegation.pdf&quot;&gt;survey&lt;/a&gt; she presented at the 2018 International Congress of Mathematicians. Its abstract proclaims:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Efficient verification of computation, also known as delegation of computation, is one of the most fundamental notions in computer science, and in particular it lies at the heart of the P vs. NP question. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; P = NP: An Omen? &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Her survey was unveiled &amp;#8220;exclusively for our readers&amp;#8221; in a January 6, 2018 &lt;a href=&quot;https://gilkalai.wordpress.com/2018/01/06/yael-tauman-kalais-icm2018-paper-my-paper-and-cryptography/&quot;&gt;post&lt;/a&gt; by Gil Kalai, along with two photos of adoring father(-in-law)/grandparent type. We hasten to add that all this is not just about how &amp;#8220;P=NP?&amp;#8221; captures the question of whether it is as easy to &lt;em&gt;generate&lt;/em&gt; a proof as to &lt;em&gt;verify&lt;/em&gt; it. Much of Yael Kalai&amp;#8217;s work depends on hardness assumptions that vanish if in fact P equals NP (with relevant efficiency).&lt;/p&gt;
&lt;p&gt;
Thinking of Gil Kalai makes us leap to two other topics that are variously related and &amp;#8220;unrelated.&amp;#8221; Gil recently &lt;a href=&quot;https://gilkalai.wordpress.com/2023/03/27/critical-times-in-israel-last-nights-demonstrations/&quot;&gt;featured&lt;/a&gt; the following photo from street protests in Israel on his blog:&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/pnp-3/&quot; rel=&quot;attachment wp-att-21433&quot;&gt;&lt;img data-attachment-id=&quot;21433&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/pnp-3/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?fit=1080%2C816&amp;amp;ssl=1&quot; data-orig-size=&quot;1080,816&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;pnp&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?fit=300%2C227&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?fit=600%2C454&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=550%2C415&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;550&quot; height=&quot;415&quot; class=&quot;aligncenter wp-image-21433&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=1024%2C774&amp;amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=300%2C227&amp;amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=768%2C580&amp;amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=200%2C150&amp;amp;ssl=1 200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?w=1080&amp;amp;ssl=1 1080w&quot; sizes=&quot;(max-width: 550px) 100vw, 550px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
The photo was also &lt;a href=&quot;https://scottaaronson.blog/?p=7170&quot;&gt;picked up&lt;/a&gt; and commented on by Scott Aaronson on his blog. Gil added:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Whether the picture is genuine or not, it shows the anarchist nature of at least some of the protestors. (We know for sure that some computer scientists were there.) I am not sure if a proof of this bold claim was also provided. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Lightheartedness aside, we wonder if this is an omen of growing public awareness of the connection of our field&amp;#8217;s signature question not only to the security workings of governments, but to the walks of life represented by Yael Kalai&amp;#8217;s applications. &lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Educating GPT &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Your humble bloggers face a kind of verification problem with nearly every post: how to pin down and attest basic facts. Here we remembered &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2014/12/13/chats/&quot;&gt;writing&lt;/a&gt; in 2014&amp;#8212;correctly&amp;#8212;that &amp;#8220;Yael Kalai [is] not related to our friend Gil Kalai.&amp;#8221; But learning that Yael Tauman married Adam Kalai (&lt;a href=&quot;https://en.wikipedia.org/wiki/Yael_Tauman_Kalai&quot;&gt;which&lt;/a&gt; is &lt;a href=&quot;https://www.facebook.com/adam.t.kalai/&quot;&gt;attested&lt;/a&gt; in &lt;a href=&quot;https://kids.kiddle.co/Yael_Tauman_Kalai&quot;&gt;many&lt;/a&gt; &lt;a href=&quot;https://www.microsoft.com/en-us/research/blog/new-england-researcher-finds-bliss/&quot;&gt;places&lt;/a&gt;) added another thing to check. The passage of time&amp;#8212;and Gil&amp;#8217;s photos&amp;#8212;revived doubt. &lt;/p&gt;
&lt;p&gt;
Heretofore we&amp;#8217;ve refined the art of crafting Google queries to filter out professional information and bring what we want to the top page of hits. But in theory, such quests are better posed directly to the likes of ChatGPT. So I (Ken) did so, first to the free GPT-3.5:&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt3-5kalais-2/&quot; rel=&quot;attachment wp-att-21441&quot;&gt;&lt;img data-attachment-id=&quot;21441&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt3-5kalais-2/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?fit=590%2C458&amp;amp;ssl=1&quot; data-orig-size=&quot;590,458&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;KWRegan&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;1681333545&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;GPT3.5Kalais&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?fit=300%2C233&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?fit=590%2C458&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?resize=590%2C458&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;590&quot; height=&quot;458&quot; class=&quot;aligncenter size-full wp-image-21441&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?w=590&amp;amp;ssl=1 590w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?resize=300%2C233&amp;amp;ssl=1 300w&quot; sizes=&quot;(max-width: 590px) 100vw, 590px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
Wait a second&amp;#8212;has ChatGPT not been briefed on the injunction against incestuous marriage? Or have too many Roman and Greek emperors dominated its data? When Moses flung down and broke the stone tablets in exasperation, was it over chatbots? I tried the pay-grade version and got a different&amp;#8212;but not better&amp;#8212;answer:&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisa-2/&quot; rel=&quot;attachment wp-att-21442&quot;&gt;&lt;img data-attachment-id=&quot;21442&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisa-2/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?fit=540%2C350&amp;amp;ssl=1&quot; data-orig-size=&quot;540,350&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;KWRegan&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;1681334250&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;GPT4KalaisA&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?fit=300%2C194&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?fit=540%2C350&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?resize=540%2C350&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;540&quot; height=&quot;350&quot; class=&quot;aligncenter size-full wp-image-21442&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?w=540&amp;amp;ssl=1 540w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?resize=300%2C194&amp;amp;ssl=1 300w&quot; sizes=&quot;(max-width: 540px) 100vw, 540px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
Nor did GPT-4 correct my typo of an extra &amp;#8216;n.&amp;#8217; Happily, Gil&amp;#8217;s mention of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Ehud_Kalai&quot;&gt;fourth Kalai&lt;/a&gt;&amp;#8212;and confirmation &lt;a href=&quot;https://blog.computationalcomplexity.org/2008/07/games-and-computer-science.html&quot;&gt;gratia&lt;/a&gt; Lance Fortnow that I found via Google&amp;#8212;enabled me to confront GPT-4 with a pertinent question. This produced an all-too-human reaction:&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisb-2/&quot; rel=&quot;attachment wp-att-21443&quot;&gt;&lt;img data-attachment-id=&quot;21443&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisb-2/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?fit=536%2C313&amp;amp;ssl=1&quot; data-orig-size=&quot;536,313&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;KWRegan&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;1681334908&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;GPT4KalaisB&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?fit=300%2C175&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?fit=536%2C313&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?resize=536%2C313&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;536&quot; height=&quot;313&quot; class=&quot;aligncenter size-full wp-image-21443&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?w=536&amp;amp;ssl=1 536w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?resize=300%2C175&amp;amp;ssl=1 300w&quot; sizes=&quot;(max-width: 536px) 100vw, 536px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&amp;#8220;Confusion,&amp;#8221; indeed? At the right are little hands to upvote or downvote responses. I upvoted the true one and gave the reason as, &amp;#8220;it is true.&amp;#8221; &lt;em&gt;Then&lt;/em&gt; I down-voted the false one and clicked a reason button saying, &amp;#8220;This isn&amp;#8217;t true.&amp;#8221; To my consternation a new box appeared:&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisc-2/&quot; rel=&quot;attachment wp-att-21444&quot;&gt;&lt;img data-attachment-id=&quot;21444&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisc-2/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?fit=642%2C384&amp;amp;ssl=1&quot; data-orig-size=&quot;642,384&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;KWRegan&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;1681335110&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;GPT4KalaisC&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?fit=300%2C179&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?fit=600%2C359&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?resize=540%2C323&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;540&quot; height=&quot;323&quot; class=&quot;aligncenter wp-image-21444&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?w=642&amp;amp;ssl=1 642w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?resize=300%2C179&amp;amp;ssl=1 300w&quot; sizes=&quot;(max-width: 540px) 100vw, 540px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
In words that won the 2016 Literature Nobel, &lt;a href=&quot;https://en.wikipedia.org/wiki/No_Direction_Home&quot;&gt;no direction home&lt;/a&gt;. It seems our task of educating GPT will pale that in the wonderful play and movie &lt;a href=&quot;https://en.wikipedia.org/wiki/Educating_Rita_(film)&quot;&gt;Educating Rita&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Should we have been more worried if P=PSPACE was sprayed in the street? Or if a proof was referenced somehow?  As for GPT, it calls to our minds some other &lt;a href=&quot;https://www.azlyrics.com/lyrics/simongarfunkel/thesoundofsilence.html&quot;&gt;words&lt;/a&gt; that have not yet won a Literature Nobel.  &lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
[some word tweaks]&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By RJLipton+KWRegan&lt;/p&gt;
  </description>
  <pubDate>2023-04-13 02:26:38 UTC</pubDate>
  <author>Richard Lipton</author>
</item>

<item>
  <title>Optimal Testing of Generalized Reed-Muller Codes in Fewer Queries</title>
  <guid>http://arxiv.org/abs/2304.05598</guid>
  <link>http://arxiv.org/abs/2304.05598</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1&quot;&gt;Dor Minzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1&quot;&gt;Kai Zheng&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A local tester for an error correcting code $C\subseteq \Sigma^{n}$ is a
tester that makes $Q$ oracle queries to a given word $w\in \Sigma^n$ and
decides to accept or reject the word $w$. An optimal local tester is a local
tester that has the additional properties of completeness and optimal
soundness. By completeness, we mean that the tester must accept with
probability $1$ if $w\in C$. By optimal soundness, we mean that if the tester
accepts with probability at least $1-\epsilon$ (where $\epsilon$ is small),
then it must be the case that $w$ is $O(\epsilon/Q)$-close to some codeword
$c\in C$ in Hamming distance.
&lt;/p&gt;
&lt;p&gt;We show that Generalized Reed-Muller codes admit optimal testers with $Q =
(3q)^{\lceil{ \frac{d+1}{q-1}\rceil}+O(1)}$ queries. Here, for a prime power $q
= p^{k}$, the Generalized Reed-Muller code, RM[n,q,d], consists of the
evaluations of all $n$-variate degree $d$ polynomials over $\mathbb{F}_q$.
Previously, no tester achieving this query complexity was known, and the best
known testers due to Haramaty, Shpilka and Sudan(which is optimal) and due to
Ron-Zewi and Sudan(which was not known to be optimal) both required
$q^{\lceil{\frac{d+1}{q-q/p} \rceil}}$ queries. Our tester achieves query
complexity which is polynomially better than by a power of $p/(p-1)$, which is
nearly the best query complexity possible for generalized Reed-Muller codes.
&lt;/p&gt;
&lt;p&gt;The tester we analyze is due to Ron-Zewi and Sudan, and we show that their
basic tester is in fact optimal. Our methods are more general and also allow us
to prove that a wide class of testers, which follow the form of the Ron-Zewi
and Sudan tester, are optimal. This result applies to testers for all
affine-invariant codes (which are not necessarily generalized Reed-Muller
codes).
&lt;/p&gt;
  </description>
  <pubDate>2023-04-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Foundations for an Abstract Proof Theory in the Context of Horn Rules</title>
  <guid>http://arxiv.org/abs/2304.05697</guid>
  <link>http://arxiv.org/abs/2304.05697</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyon_T/0/1/0/all/0/1&quot;&gt;Tim S. Lyon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ostropolski_Nalewaja_P/0/1/0/all/0/1&quot;&gt;Piotr Ostropolski-Nalewaja&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce a novel, logic-independent framework for the study of
sequent-style proof systems, which covers a number of proof-theoretic
formalisms and concrete proof systems that appear in the literature. In
particular, we introduce a generalized form of sequents, dubbed &#39;g-sequents,&#39;
which are taken to be binary graphs of typical, Gentzen-style sequents. We then
define a variety of &#39;inference rule types&#39; as sets of operations that act over
such objects, and define &#39;abstract (sequent) calculi&#39; as pairs consisting of a
set of g-sequents together with a finite set of operations. Our approach
permits an analysis of how certain inference rule types interact in a general
setting, demonstrating under what conditions rules of a specific type can be
permuted with or simulated by others, and being applicable to any sequent-style
proof system that fits within our framework. We then leverage our permutation
and simulation results to establish generic calculus and proof transformation
algorithms, which show that every abstract calculus can be effectively
transformed into a lattice of polynomially equivalent abstract calculi. We
determine the complexity of computing this lattice and compute the relative
sizes of proofs and sequents within distinct calculi of a lattice. We recognize
that top elements in lattices correspond to nested sequent systems, while
bottom elements correspond to labeled sequent systems, and observe that top and
bottom elements coincide with many known (cut-free) nested and labeled sequent
systems for logics characterized by Horn properties.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>When Should You Wait Before Updating? Toward a Robustness Refinement</title>
  <guid>http://arxiv.org/abs/2304.05831</guid>
  <link>http://arxiv.org/abs/2304.05831</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubois_S/0/1/0/all/0/1&quot;&gt;Swan Dubois&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feuilloley_L/0/1/0/all/0/1&quot;&gt;Laurent Feuilloley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petit_F/0/1/0/all/0/1&quot;&gt;Franck Petit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabie_M/0/1/0/all/0/1&quot;&gt;Mika&amp;#xeb;l Rabie&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Consider a dynamic network and a given distributed problem. At any point in
time, there might exist several solutions that are equally good with respect to
the problem specification, but that are different from an algorithmic
perspective, because some could be easier to update than others when the
network changes. In other words, one would prefer to have a solution that is
more robust to topological changes in the network; and in this direction the
best scenario would be that the solution remains correct despite the dynamic of
the network.
&lt;/p&gt;
&lt;p&gt;In~\cite{CasteigtsDPR20}, the authors introduced a very strong robustness
criterion: they required that for any removal of edges that maintain the
network connected, the solution remains valid. They focus on the maximal
independent set problem, and their approach consists in characterizing the
graphs in which there exists a robust solution (the existential problem), or
even stronger, where any solution is robust (the universal problem). As the
robustness criteria is very demanding, few graphs have a robust solution, and
even fewer are such that all of their solutions are robust. In this paper, we
ask the following question: \textit{Can we have robustness for a larger class
of networks, if we bound the number $k$ of edge removals allowed}? (See the
full paper for the full abstract.)
&lt;/p&gt;
  </description>
  <pubDate>2023-04-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Hall-type theorem with algorithmic consequences in planar graphs</title>
  <guid>http://arxiv.org/abs/2304.05859</guid>
  <link>http://arxiv.org/abs/2304.05859</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jowhari_H/0/1/0/all/0/1&quot;&gt;Hossein Jowhari&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a graph $G=(V,E)$, for a vertex set $S\subseteq V$, let $N(S)$ denote
the set of vertices in $V$ that have a neighbor in $S$. In this paper, we prove
the following Hall-type statement. Let $k \ge 2$ be an integer. Let $X$ be a
vertex set in the undirected graph $G$ such that for each subset $S$ of $X$ it
holds $|N(S)|\ge \frac1k {|S|}$. Then $G$ has a matching of size at least
$\frac{|X|}{k+1}$. Using this statement, we derive tight bounds for the
estimators of the matching size in planar graphs. These estimators are used in
designing sublinear space algorithms for approximating the maching size in the
data stream model of computation. In particular, we show the number of locally
superior vertices, introduced in \cite{Jowhari23}, is a $3$ factor
approximation of the matching size in planar graphs. The previous analysis
proved a $3.5$ approximation factor. In another consequence, we show a simple
setting of an estimator by Esfandiari \etal \cite{EHLMO15} achieves $3$ factor
approximation of the matching size in planar graphs. Namely, let $s$ be the
number of edges with both endpoints having degree at most $2$ and let $h$ be
the number of vertices with degree at least $3$. We show when the graph is
planar, the size of matching is at least $\frac{s+h}3$. This result generalizes
a known fact that every planar graph on $n$ vertices with minimum degree $3$
has a matching of size at least $\frac{n}3$.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On Parallel k-Center Clustering</title>
  <guid>http://arxiv.org/abs/2304.05883</guid>
  <link>http://arxiv.org/abs/2304.05883</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coy_S/0/1/0/all/0/1&quot;&gt;Sam Coy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Czumaj_A/0/1/0/all/0/1&quot;&gt;Artur Czumaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_G/0/1/0/all/0/1&quot;&gt;Gopinath Mishra&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the classic $k$-center problem in a parallel setting, on the
low-local-space Massively Parallel Computation (MPC) model, with local space
per machine of $\mathcal{O}(n^{\delta})$, where $\delta \in (0,1)$ is an
arbitrary constant. As a central clustering problem, the $k$-center problem has
been studied extensively. Still, until very recently, all parallel MPC
algorithms have been requiring $\Omega(k)$ or even $\Omega(k n^{\delta})$ local
space per machine. While this setting covers the case of small values of $k$,
for a large number of clusters these algorithms require large local memory,
making them poorly scalable. The case of large $k$, $k \ge \Omega(n^{\delta})$,
has been considered recently for the low-local-space MPC model by Bateni et al.
(2021), who gave an $\mathcal{O}(\log \log n)$-round MPC algorithm that
produces $k(1+o(1))$ centers whose cost has multiplicative approximation of
$\mathcal{O}(\log\log\log n)$. In this paper we extend the algorithm of Bateni
et al. and design a low-local-space MPC algorithm that in $\mathcal{O}(\log\log
n)$ rounds returns a clustering with $k(1+o(1))$ clusters that is an
$\mathcal{O}(\log^*n)$-approximation for $k$-center.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Node-Differentially Private Estimation of the Number of Connected Components</title>
  <guid>http://arxiv.org/abs/2304.05890</guid>
  <link>http://arxiv.org/abs/2304.05890</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalemaj_I/0/1/0/all/0/1&quot;&gt;Iden Kalemaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raskhodnikova_S/0/1/0/all/0/1&quot;&gt;Sofya Raskhodnikova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1&quot;&gt;Adam Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsourakakis_C/0/1/0/all/0/1&quot;&gt;Charalampos E. Tsourakakis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We design the first node-differentially private algorithm for approximating
the number of connected components in a graph. Given a database representing an
$n$-vertex graph $G$ and a privacy parameter $\varepsilon$, our algorithm runs
in polynomial time and, with probability $1-o(1)$, has additive error
$\widetilde{O}(\frac{\Delta^*\ln\ln n}{\varepsilon}),$ where $\Delta^*$ is the
smallest possible maximum degree of a spanning forest of $G.$
Node-differentially private algorithms are known only for a small number of
database analysis tasks. A major obstacle for designing such an algorithm for
the number of connected components is that this graph statistic is not robust
to adding one node with arbitrary connections (a change that node-differential
privacy is designed to hide): {\em every} graph is a neighbor of a connected
graph.
&lt;/p&gt;
&lt;p&gt;We overcome this by designing a family of efficiently computable Lipschitz
extensions of the number of connected components or, equivalently, the size of
a spanning forest. The construction of the extensions, which is at the core of
our algorithm, is based on the forest polytope of $G.$ We prove several
combinatorial facts about spanning forests, in particular, that a graph with no
induced $\Delta$-stars has a spanning forest of degree at most $\Delta$. With
this fact, we show that our Lipschitz extensions for the number of connected
components equal the true value of the function for the largest possible
monotone families of graphs. More generally, on all monotone sets of graphs,
the $\ell_\infty$ error of our Lipschitz extensions is nearly optimal.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Guest Post: TCS for All (originally TCS Women) spotlight workshop at STOC 2023: Rising Star nominations</title>
  <guid>http://tcsplus.wordpress.com/?p=680</guid>
  <link>https://tcsplus.wordpress.com/2023/04/12/tcs-for-all-originally-tcs-women-spotlight-workshop-at-stoc-2023-rising-star-nominations/</link>
  <description>
    &lt;p&gt;TCS for All (originally TCS Women) invites nominations for speakers in Rising Star talks at the &lt;a href=&quot;https://sigact.org/tcsforall/&quot;&gt;TCS for All Spotlight Workshop&lt;/a&gt; at &lt;a href=&quot;http://acm-stoc.org/stoc2023/&quot;&gt;STOC 2023&lt;/a&gt;. To be eligible, your nominee has to be a senior PhD student with expected graduation no later than August 2024, or a postdoc in theoretical computer science (all topics represented at STOC are welcome), an underrepresented minority, and not a speaker at a previous TCS Women Spotlight Workshop. Preference will be given to speakers who are currently on the job market for postdoctoral/faculty positions, or who expect to be on the job market in Fall 2023.&lt;/p&gt;



&lt;p&gt;You can make your nomination by &lt;a href=&quot;https://forms.gle/jCMXsTmZ4DZ8r5xJA&quot;&gt;filling this form&lt;/a&gt; by &lt;strong&gt;May 7th&lt;/strong&gt;. TCS for All Spotlight Workshop will be held on Thursday, June 22nd, 2023 (2-4pm), in Orlando, Florida, USA, as part of the 54th Symposium on Theory of Computing (STOC) and TheoryFest! We are happy to announce that our annual inspirational talk will be given by Professor Dana Randall!&lt;/p&gt;



&lt;p&gt;For more information, check out the website: &lt;a href=&quot;https://sigact.org/tcsforall/&quot;&gt;https://sigact.org/tcsforall/&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By plustcs&lt;/p&gt;
  </description>
  <pubDate>2023-04-12 22:08:35 UTC</pubDate>
  <author>TCS+ Seminar Series</author>
</item>

<item>
  <title>Thoughts on AI safety</title>
  <guid>http://windowsontheory.org/?p=8591</guid>
  <link>https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/</link>
  <description>
    &lt;p&gt;Last week, I gave a lecture on AI safety as part of my &lt;a href=&quot;https://boazbk.github.io/mltheoryseminar/&quot;&gt;deep learning foundations course&lt;/a&gt;. In this post, I’ll try to write down a few of my thoughts on this topic. (The lecture was three hours, and this blog post will not cover all of what we discussed or all the points that appeared in the pre-readings and the papers linked below.)  &lt;/p&gt;



&lt;p&gt;The general goal of safety in artificial intelligence is to protect individual humans or society at large from harm. The field of AI safety is broad and considers risks including:&lt;/p&gt;



&lt;ol&gt;
&lt;li&gt;Harm to users of an AI system or harm to third parties due to the system not functioning as intended. One example includes drivers or pedestrians harmed by the failures of self-driving cars. For instance, there were several fatal accidents involving Tesla&amp;#8217;s autopilot. Interestingly, just last week, Elon Musk tweeted the following: &lt;img width=&quot;355&quot; height=&quot;320&quot; src=&quot;https://lh6.googleusercontent.com/i9Z8g5ZkhsRZgxZgRMNf09mSgrrRY2zTK0ZukDVs3kooksLLCwroUgdZr6OSGBNb0DbtAFK3FBYW_DIVpOPuCSu4ImmboKNTZH6fq9hWlZiDkLWkxIVEJeMFEcx9UBOHgVlRPce772sv9AZo-E6MPVo&quot;&gt;&lt;/li&gt;



&lt;li&gt;Another example is harm from automated decisions that may be unfair. The paper of&lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4238015&quot;&gt; Wang &lt;/a&gt;et al. discusses the risks of “predictive optimization.” One well-known example is the COMPAS risk-assessment system for bail decisions (see &lt;a href=&quot;https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing&quot;&gt;Pro-Publica’s investigation&lt;/a&gt;, as well as the broader discussion by &lt;a href=&quot;https://arxiv.org/abs/1610.02413&quot;&gt;Hardt, Price, and Srebro&lt;/a&gt;)&lt;/li&gt;



&lt;li&gt;Algorithmic decisions could cause “feedback loops”, where several algorithms interact with each other in unexpected and ever-escalating ways. Algorithmic trading was blamed for the &lt;a href=&quot;https://en.wikipedia.org/wiki/2010_flash_crash&quot;&gt;2010 “Flash Crash”&lt;/a&gt;; another example is how a single not-very-rare book came to be priced &lt;a href=&quot;https://www.wired.com/2011/04/amazon-flies-24-million/&quot;&gt;at $24M on Amazon&lt;/a&gt;.&lt;/li&gt;



&lt;li&gt;There are many societal risks in AI. These include &lt;a href=&quot;https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=7306d7e4782b&quot;&gt;job loss&lt;/a&gt;, &lt;a href=&quot;https://www.nytimes.com/2019/11/19/technology/artificial-intelligence-bias.html&quot;&gt;amplifying biases&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Age_of_Surveillance_Capitalism&quot;&gt;concentrating power&lt;/a&gt;, &lt;a href=&quot;https://www.newyorker.com/culture/infinite-scroll/is-ai-art-stealing-from-artists&quot;&gt;appropriating content&lt;/a&gt;, and &lt;a href=&quot;https://www.noemamag.com/the-exploited-labor-behind-artificial-intelligence/&quot;&gt;exploiting data workers&lt;/a&gt;.&lt;/li&gt;



&lt;li&gt;Yet another issue was pointed out to me by Yejin Choi &amp;#8211; “AI literacy.” As AI’s capabilities are rapidly advancing, it will take some time for people to get used to them, and during this time, we may misinterpret them. This is manifested in people seeing such systems as &lt;a href=&quot;https://www.scientificamerican.com/article/google-engineer-claims-ai-chatbot-is-sentient-why-that-matters/&quot;&gt;sentient&lt;/a&gt; (something that already happened with the 1966 chatbot &lt;a href=&quot;https://en.wikipedia.org/wiki/ELIZA_effect&quot;&gt;ELIZA&lt;/a&gt;). Another example is “deepfakes”: inauthentic images or videos that could mislead people that are not yet aware of AI’s capabilities (again, an issue with a &lt;a href=&quot;https://en.wikipedia.org/wiki/Cottingley_Fairies&quot;&gt;long history&lt;/a&gt;).&lt;br&gt;&lt;br&gt;&lt;img width=&quot;504&quot; height=&quot;325&quot; src=&quot;https://lh4.googleusercontent.com/DTisxiomU8oCYSmmjTUULGCvq8Cwy6Xxlq872pWXHU-gaC6SDgESdwRVdu_cyIGmHBgpleY2ozToXU-8MYADtUG8sPpfaKlbb_1HAlfvEnBG_nC1d3_oLZoNqC5hBw8VfK8aPNrDIZpM_812ia-hpco&quot;&gt;    &lt;/li&gt;



&lt;li&gt;AI could be misused by bad actors for hacking, spreading dis-information, help in designing weapons, and more.&lt;/li&gt;



&lt;li&gt;Finally, several people are concerned about artificial intelligence systems acting themselves as “malicious agents”, which could behave in adversarial ways, harming humanity and in extreme cases leading to an existential risk of “loss of control” of humanity over its future or extinction.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Different subfields of “AI safety” deal with different aspects of these risks. AI “&lt;strong&gt;assurance&lt;/strong&gt;,&lt;em&gt;” &lt;/em&gt;or quality control, is about ensuring that systems have clear specifications and satisfy these specifications. An example of work along these lines is &lt;a href=&quot;https://arxiv.org/abs/1708.06374&quot;&gt;Shalev-Shwartz et al&lt;/a&gt;, who gave a framework for formally specifying safety assurances for self-driving cars.. AI &lt;em&gt;&lt;strong&gt;ethics&lt;/strong&gt;&lt;/em&gt; deals with the individual and social implications of deploying AI systems, asking the question of how AI systems could be deployed responsibly and even&lt;em&gt; &lt;/em&gt;whether such a system should be deployed at all. &lt;em&gt;&lt;strong&gt;Security&lt;/strong&gt;&lt;/em&gt; deals with malicious actors, that could both be the users of AI, suppliers of data (e.g., data poisoning and prompt injection attacks), or control other aspects of the environment. Finally, researchers in &lt;em&gt;“&lt;strong&gt;alignment&lt;/strong&gt;”&lt;/em&gt; or &lt;em&gt;“&lt;strong&gt;existential risk&lt;/strong&gt;”&lt;/em&gt; are concerned with the case in which the AI itself is the adversary. These subfields are not disjoint and share overlapping concerns.&lt;/p&gt;



&lt;p&gt;Another way to classify risks is to consider the extent to which they are reduced or magnified by the normal processes of the free market and improved technology. &lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large is-resized&quot;&gt;&lt;a href=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-2.png&quot;&gt;&lt;img loading=&quot;lazy&quot; data-attachment-id=&quot;8602&quot; data-permalink=&quot;https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/image-2-4/&quot; data-orig-file=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-2.png&quot; data-orig-size=&quot;1224,692&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;image-2&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=300&quot; data-large-file=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=656&quot; src=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=1024&quot; alt=&quot;&quot; class=&quot;wp-image-8602&quot; width=&quot;680&quot; height=&quot;385&quot; srcset=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=680 680w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=768 768w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png 1224w&quot; sizes=&quot;(max-width: 680px) 100vw, 680px&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;



&lt;p&gt;In some cases, the interests of safety go hand in hand with the economic incentives for the entity controlling the model, while in others they could be unrelated or even directly opposed to these incentives. Similarly, in some cases, improving capabilities (e.g., by increasing the size of models and data) would reduce risks, while in others, this might not help or even harm.&lt;/p&gt;



&lt;h2 class=&quot;wp-block-heading&quot;&gt;Impact of AI on humanity &amp;#8211; the baseline expectation&lt;/h2&gt;



&lt;p&gt;Artificial intelligence is a very general technology, and as such, we might expect its impact on humanity to be qualitatively similar to that of past technological revolutions. If we look at the past, we can draw two lessons:&lt;/p&gt;



&lt;ol&gt;
&lt;li&gt;Technological revolutions have both positive and negative impacts, but in the long run and summing over populations, the positives outweigh the negatives. For example, measures such as life expectancy and GDP per capita have gone up over history.&lt;/li&gt;
&lt;/ol&gt;



&lt;figure class=&quot;wp-block-image&quot;&gt;&lt;img src=&quot;https://lh4.googleusercontent.com/Z8ccZBQmNvYP8ylKcAFuAox35d7rmpx16r1zpqAAyA6yG9X0xAVcNJFICaG5gbIKqH_2Af2EacONKXOnfQQRzMBGUA9FS0KTOD2Jw7ovvp2DXeRpofulsOKB1-2lYU0KjTAPIUNhrlcPGFEfK6WR8hw&quot; alt=&quot;&quot; /&gt;&lt;/figure&gt;



&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;There is no reason to assume that the benefits of technology will be distributed equally. &lt;a href=&quot;https://www.cbpp.org/research/poverty-and-inequality/a-guide-to-statistics-on-historical-trends-in-income-inequality&quot;&gt;Inequality&lt;/a&gt; can go either &lt;a href=&quot;https://www.imf.org/external/pubs/ft/fandd/2011/09/picture.htm&quot;&gt;up or down&lt;/a&gt;, dependent on government policies rather than technological improvements. &lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;In my lecture, I discussed the issue of fairness. I discussed both the COMPAS system as well as the paper of &lt;a href=&quot;https://arxiv.org/abs/1610.02413&quot;&gt;Hardt et al&lt;/a&gt;, visualized in the &lt;a href=&quot;https://research.google.com/bigpicture/attacking-discrimination-in-ml/&quot;&gt;following page&lt;/a&gt;, demonstrating how different notions of fairness can be at odds with maximizing profits and even at odds with one another.  In this blog post, I focus on the settings where &lt;strong&gt;capabilities&lt;/strong&gt; and &lt;strong&gt;safety &lt;/strong&gt;may be at odds.&lt;/p&gt;



&lt;h2 class=&quot;wp-block-heading&quot;&gt;Capabilities&lt;/h2&gt;



&lt;p&gt;As is well known, the capabilities of artificial intelligence systems have been growing in recent years, see, for example this paper of &lt;a href=&quot;https://arxiv.org/abs/2206.07682&quot;&gt;Wei et al&lt;/a&gt;. &lt;/p&gt;



&lt;figure class=&quot;wp-block-image is-resized&quot;&gt;&lt;img src=&quot;https://lh4.googleusercontent.com/M18nhEY3ApIXjrril-PxYPFrgx4mxgIxzIXYvXWaAXfgwguAO9r0igfIoYplJ59b1oV5_dTwe-QmETaHCN4_fZPmA4TTTOaxdiUD_YdEITKID8nVoctBU3Hg707JRKZ2ntqFUxOH6qmSPgCNbkH2HGs&quot; alt=&quot;&quot; width=&quot;543&quot; height=&quot;367&quot; /&gt;&lt;/figure&gt;



&lt;p&gt;Graphs like these show capabilities emerging suddenly with model scale. However, we should note that these graphs are plotted with the X axis on the &lt;strong&gt;log scale.&lt;/strong&gt; If we plot it on linear scale, it would be much less abrupt.&amp;nbsp;&lt;/p&gt;



&lt;figure class=&quot;wp-block-image is-resized&quot;&gt;&lt;img src=&quot;https://lh5.googleusercontent.com/UbtJ1n09TuRPznworgdaznIIkGdceuK_ZUrVwpYqsGmjUUktxCfdHBAdtKTf-KG9-TZTf709ZS9gNDtnUr2BoCQeYq_KzsnQS3-NCOZEtkbYrqJCqzEXHfTfWlC2FnofBHIgfP5VsSkSu05jaYGkjug&quot; alt=&quot;&quot; width=&quot;635&quot; height=&quot;376&quot; /&gt;&lt;/figure&gt;



&lt;p&gt;Another way to plot increasing capabilities is to look at improvements in ELO scores of Chess engines.&amp;nbsp;&lt;/p&gt;



&lt;figure class=&quot;wp-block-image is-resized&quot;&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/9MNusf0mSr5PExwfDqGULmPYEwuL7QU79m0fTBmzEI1iCXcVsYabauEiAjLSEq_owZUK1UqlImqwWIwuLTBP74fOXAldhbW988uARoG8N08mmsfawt4Q-PV2T3a8Hq4TgaKk5GCo_s6okNB2U7NyP0Y&quot; alt=&quot;&quot; width=&quot;691&quot; height=&quot;369&quot; /&gt;&lt;/figure&gt;



&lt;p&gt;Once again, we see improvement with time. (Due to Moore’s law, we can also treat the X axis as a log scale here. BTW credit for this figure is due to GPT4; I didn’t verify the numbers though I probably should have.)&lt;/p&gt;



&lt;p&gt;Given the above, we might expect future capabilities to increase roughly as follows: (this is a cartoon, so the slope or the labels on either axis should not be taken too seriously)&lt;img src=&quot;https://lh3.googleusercontent.com/7t_z2fR0rHtTnjq7XVBa2kyQsPiIM3zFvXPo_GrXciBjNay046-9-WcVaSA9itWAbxD2o50K9VP6Q6UJHmw8_NA3jeSc2ngCOBsrBrJXjmBheqxe9kNESt-8UVgToR770JPTSSJKfoekfW7Z1IG9Ks4&quot; width=&quot;474&quot; height=&quot;349&quot;&gt;&lt;/p&gt;



&lt;p&gt;However, Moore’s law (assuming &lt;a href=&quot;https://www.semianalysis.com/p/a-century-of-moores-law&quot;&gt;it keeps holding&lt;/a&gt;) can reduce costs as a function of time. Also, the graph may well behave differently for different skills. Finally, if we manage to use AI to reduce the costs of building future AI (i.e. “self improvement” or “singularity”), then the costs could be radically reduced.&lt;/p&gt;



&lt;h2 class=&quot;wp-block-heading&quot;&gt;Capabilities vs. Safety Round 1: Risk of misuse&lt;/h2&gt;



&lt;p&gt;One aspect in which increased capabilities seem to be at odds with safety is the potential for &lt;em&gt;misuse&lt;/em&gt; of AI. The more powerful an AI system is, the more harm one can do with it. However, this logic assumes that only the attacker can access the system. In many cases, increased capabilities of AI benefits both the “attacker” and “defender”, and it is unclear which one would be helped more. &lt;/p&gt;



&lt;p&gt;For example, AI systems could find software vulnerabilities and help hackers, but software companies could also use them to secure their systems. AI could be used to spread disinformation on social media and by social media companies to detect such disinformation. A related setting is the use of AI for persuasion. However, it is still an open question whether the current “limiting factor” in persuasion, whether it’s advertising or scams, is a lack of know-how or workforce on the part of the persuaders. Rather, it may be that different people have varying susceptibility to persuasion; thus, even very skilled persuaders will be limited in the number of people they can persuade and the things they can persuade them to do. Also, AI could be used to combat illicit persuasion by detecting scams, just as it is currently used in spam detection.&lt;/p&gt;



&lt;p&gt;An example closest to my expertise is student cheating. AI may help professors detect cheating more than it helps potential cheaters. In past semesters, if I wanted to detect whether two students copied from one another, I needed to &amp;#8220;run&amp;#8221; an N² time algorithm (manually comparing all pairs of submissions).  Now I could ask ChatGPT to compare all pairs and summarize any suspicious similarities. If I am worried about students using ChatGPT itself to cheat, I can ask it to throw its own solution into the pool of comparands (and maybe some solutions from past semesters or Course Hero as well). &lt;/p&gt;



&lt;p&gt;There are other misuse scenarios in which the balance does favor the attacker. For example, an attacker might be able to use a system to learn how to make a bomb or get detailed information about a physical target for an attack. However, society has been through inflection points such as this in the past, when the amount of information available to ordinary citizens radically increased. It is unclear to me that the increase in access to harmful information due to AI would be larger than the increase between the pre- and post-Internet eras. &lt;/p&gt;



&lt;h2 class=&quot;wp-block-heading&quot;&gt;Capabilities vs. Safety Round 2: Unaligned powerful AI systems&lt;br&gt;&lt;/h2&gt;



&lt;p&gt;The other setting in which increased capabilities could lead to higher risk is when we are concerned with the AI systems themselves behaving in “agentic” or malicious ways. We do not have to get into the question of whether such systems could be “sentient” or “concious” but rather ask whether it might be possible that the systems’ actions would be so complex and unpredictable that they could be modeled as adversarial. &lt;/p&gt;



&lt;p&gt;There is a long history of worrying about such risks. Alan Turing famously said in 1951 that &lt;em&gt;“it seems probable that once the machine thinking method had started, it would not take long to outstrip our feeble powers. They would be able to converse with each other to sharpen their wits. At some stage therefore, we should have to expect the machines to take control.”&lt;/em&gt;&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large is-resized&quot;&gt;&lt;a href=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-1.png&quot;&gt;&lt;img loading=&quot;lazy&quot; data-attachment-id=&quot;8598&quot; data-permalink=&quot;https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/image-1-4/&quot; data-orig-file=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-1.png&quot; data-orig-size=&quot;1224,464&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;image-1&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=300&quot; data-large-file=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=656&quot; src=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=1024&quot; alt=&quot;&quot; class=&quot;wp-image-8598&quot; width=&quot;656&quot; height=&quot;248&quot; srcset=&quot;https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=654 654w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=768 768w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png 1224w&quot; sizes=&quot;(max-width: 656px) 100vw, 656px&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;



&lt;p&gt;There are two metaphors for a “super human AI”. One is the model of an AI as a&lt;strong&gt; “genie”:&lt;/strong&gt; an entity that is single-mindedly focused on optimizing some objective (a.k.a granting a wish). However, like the genies in many stories, it may interpret the wish in a way that is literally true but completely misaligned with the intentions and interests of the human who made it. A less fanciful way to phrase this is that we expect that &lt;em&gt;any&lt;/em&gt; objective, when pursued relentlessly, will eventually be misaligned with the general well-being of society. In his &lt;a href=&quot;https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html&quot;&gt;blog&lt;/a&gt;, Jascha Sohl-Dickstein called this principle the “strong version of Goodhat’s law” and illustrated it as follows:&lt;/p&gt;



&lt;figure class=&quot;wp-block-image is-resized&quot;&gt;&lt;img src=&quot;https://lh5.googleusercontent.com/BdPFfV53mLAN3gY6IkBCImnNXHbZW_P4LO97CMg_NGBXPp-03s21GWo0isaDZMaWaP4b-16997bp6fmG2Yb8KAYBHoSACfl_m9XwRTYXmQnUIPv8OL2zJBxnx749bnhvJLlJeBdLaOt5VXWjfNbN75A&quot; alt=&quot;&quot; width=&quot;545&quot; height=&quot;279&quot; /&gt;&lt;/figure&gt;



&lt;p&gt;Specifically, the concern is that to satisfy any objective, it seems useful to &lt;a href=&quot;https://arxiv.org/abs/1912.01683&quot;&gt;seek power&lt;/a&gt;, and it is possible systems might use deception as well. &lt;a href=&quot;https://arxiv.org/abs/2209.00626&quot;&gt;Ngo et al &lt;/a&gt;raised the concern that such systems would develop “situational awareness” and behave differently when trained and deployed.&lt;/p&gt;



&lt;p&gt;The other metaphor for a “super-human AI” is the one of the “alien”: it is highly intelligent, but like us, it is not focused on a single goal; rather, its intelligence (to use another term from Sohl-Dickstein) is a “hot mess”. Being like us is not necessarily a good thing. For example, the interaction between early modern humans and the Neanderthals did not go well for the latter. (Though &lt;a href=&quot;https://www.nature.com/articles/s41598-021-84410-7&quot;&gt;we&lt;/a&gt; &lt;a href=&quot;https://www.discovermagazine.com/planet-earth/neanderthal-brains-bigger-not-necessarily-better&quot;&gt;don’t&lt;/a&gt; &lt;a href=&quot;https://www.nature.com/articles/s41559-021-01391-6&quot;&gt;know&lt;/a&gt; whether or not Homo Sapiens had cognitive advantages over Neanderthals, and if so, whether those played a key role in the Neanderthal’s extinction. Also, as our society has grown more sophisticated, we are trying to do more to &lt;a href=&quot;https://www.iucn.org/&quot;&gt;conserve&lt;/a&gt; rather than extinguish other species.)&lt;/p&gt;



&lt;p&gt;The “AI as a genie” metaphor arises from the fact that AI systems are often the result of some optimization procedure. In particular, in &lt;em&gt;reinforcement learning (RL)&lt;/em&gt;, the system is trained to maximize some &lt;em&gt;reward&lt;/em&gt;. While RL wasn’t used in earlier large language models (LLMs), it has &lt;a href=&quot;https://arxiv.org/abs/2203.02155&quot;&gt;recently been used&lt;/a&gt; in models such as GPT3.5, training a “reward model” from human feedback that is later used in an RL procedure to generate a sequence of tokens that maximizes the reward (this is known as RL from human feedback or RLHF). Ngo et al claimed that the use of RLHF could lead models to “reward hacking” in which the model pursues goals that, like in the “strong version of Goodhart’s law” would be ultimately detrimental to humanity.&lt;/p&gt;



&lt;p&gt;To me, this particular concern hinges on the question of whether RLHF amounts to most of the “magic” in modern LLMs or whether (to use a phrase favored by &lt;a href=&quot;https://medium.com/syncedreview/yann-lecun-cake-analogy-2-0-a361da560dae&quot;&gt;Yann LeCun&lt;/a&gt;) it is merely the “cherry on top”. &lt;/p&gt;



&lt;figure class=&quot;wp-block-image&quot;&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/tmylI-HGa_ec4wXtiYfu9t2hgBAq3UcnwyUtOqydL-nl0tL1ZD3eo6BwOHt4K5EaFaR998IuMbxu7k5N9k3FukbmCznqRmKqu0n8vMVmwqgy81mQgrn1aXSmTvzukQ0YLw-3b1s4KHaihOrIHdGBsAs&quot; alt=&quot;&quot; /&gt;&lt;/figure&gt;



&lt;p&gt;If we believe that “magic” corresponds to computational or data resources, then RLHF is merely the &amp;#8220;cherry on top&amp;#8221;. While OpenAI did not reveal details, &lt;a href=&quot;https://arxiv.org/abs/2204.05862&quot;&gt;Anthropic&lt;/a&gt; trained a similar model and used about 10¹¹ tokens in pre-training, while only about 10⁵ human annotations for RLHF.  So if the computational scale is the same as “magic,” then intelligence is formed at pre-training and only shaped by RLHF. Is scale the same as magic? I would argue that this is what &lt;a href=&quot;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&quot;&gt;the bitter lesson&lt;/a&gt; tells us.&lt;/p&gt;



&lt;p&gt;Even so, should we still be worried about the “alien” model? The question is, again, who is the alien? Do we think of the AI system as the combination of the pre-trained model and whatever “fine tuning” or “reinforcement learning” adapter is on top of it? Or is the heart of the system the pre-trained model itself? &lt;/p&gt;



&lt;p&gt;If we consider the pre-trained model as the heart of the system, then I argue that modeling it as an individual entity or agent is misguided.&amp;nbsp; In fact:&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;&lt;em&gt;A pre-trained language model is not an imitation of any human, it is an imitation of all of humanity.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;A pre-trained generative text model is not designed to model any particular entity. Rather, it is designed to generate all text that it has been trained on and, along the way, develop the skills to perform deductions, combinations, and style transfers on this text. To use such a model as an assistant, we need to &lt;em&gt;condition&lt;/em&gt; it by providing a &lt;a href=&quot;https://www.reddit.com/r/copypasta/comments/111mlh7/entire_microsoft_bing_ai_prompt_leaked/&quot;&gt;prompt&lt;/a&gt;, much like we can condition an image generative model to generate images inside one particular building. If we think of a pre-trained model as an “intelligence engine” that is later used with “adapters” (that could include learned models, hard-coded programs, as well as humans), then our assumptions on the risk scenarios change. Rather than a monolithic “AI system” that could act in adversarial ways, we might have a variety of agents/modules built on top of the “intelligence engine”. Some of these agents, whether human or artificial, may well be adversarial. However, all of those would have access to the same “engine,” and so the rising tide of AI will lift all (good and bad) boats. &lt;/p&gt;



&lt;figure class=&quot;wp-block-image&quot;&gt;&lt;img src=&quot;https://lh6.googleusercontent.com/dUGyRSPiw0M1Gnb4UYsMOMff-n536k3BJ7VfBUQvf3dgIIeRd7Ns5CTzdtIK9JPbYfP4Xsdir73jIFIc-q-X3ttfb-K8vAu78eW2GckWfsBzf5dmaDVXaCai-So9fC5n8GBxNr2rA9eHyFA9Ezl_T4g&quot; alt=&quot;&quot; /&gt;&lt;/figure&gt;



&lt;p&gt;Generally, I think that the view of “intelligence” as some inherent skill belonging to a monolithic entity or agent is quite anthropocentric. In fact, it’s not even true for humans. While the human brains have not grown for more than hundred thousand years,  human society has collectively become more intelligent over the last millennia and centuries, and all of us can access this collective intelligence. Indeed, with modern deep learning, we can take any advanced AI system and &lt;em&gt;fine-tune&lt;/em&gt; it to achieve a particular task of interest. Hence&lt;strong&gt; intelligence is not so much a skill of an individual as a capability of the system as a whole.&lt;/strong&gt;&lt;/p&gt;



&lt;h2 class=&quot;wp-block-heading&quot;&gt;Verification&lt;/h2&gt;



&lt;p&gt;Regardless of whether you are concerned about AI taking over humanity or simply about the wisdom of deploying highly complex systems that we don’t fully understand, &lt;em&gt;verification&lt;/em&gt; can be a crucial element for ensuring safety. One of the general principles we see time and again in theoretical computer science is that&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;&lt;em&gt;Verification is easier than creation.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;(In other words, it’s easier to be the critic than the “&lt;a href=&quot;https://www.theodorerooseveltcenter.org/Learn-About-TR/TR-Encyclopedia/Culture-and-Society/Man-in-the-Arena.aspx&quot;&gt;man in the arena&lt;/a&gt;” &amp;#8211; and that’s a good thing!)&lt;/p&gt;



&lt;p&gt;This is the content of the P vs NP conjecture and also underlies the theory of &lt;a href=&quot;http://people.csail.mit.edu/madhu/papers/2009/pcpcacm.pdf&quot;&gt;probabilistically  checkable proofs. (PCPs)&lt;/a&gt; These are now used in cryptography to delegate computation by a weak verifier to a powerful server (see this &lt;a href=&quot;https://cap.csail.mit.edu/engage/spotlights/yael-kalai&quot;&gt;interview&lt;/a&gt; with Yael Kalai, and her &lt;a href=&quot;https://gilkalai.files.wordpress.com/2018/01/cacm-delegation.pdf&quot;&gt;survey&lt;/a&gt;) which is a problem not unlike the task of verifying a powerful AI by a weaker entity.&lt;/p&gt;



&lt;p&gt;I recently saw a talk by Zico Kolter in which he put forward the following equation as to when generative models have positive utility:&lt;/p&gt;



&lt;figure class=&quot;wp-block-image&quot;&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/aQtCbNVlUK1AM_V2PvU1iSNwwRH_Zhg3bH_XcU7_jwYMi6yJDRAP7kHVbLuUwkDPi_H9kYcHJeImzlMow-oVtjhaQwOJJuk89Yf6nOtBrxdzBq6AGd_EYvKUM4R0ES6s8rA0Q9nihvnqomayae2COt4&quot; alt=&quot;&quot; /&gt;&lt;/figure&gt;



&lt;p&gt;That is, as long as the time for us to verify a solution is smaller than the time to generate it ourselves multiplied by the probability that the model’s output is correct, then we can efficiently use a model by always verifying its output, spending the effort to generate a solution ourself if verification fails. Our expected time would be smaller than the time spent generating solutions from scratch, even if the model is far from always correct.&lt;/p&gt;



&lt;p&gt;The principle that verification can be done even with powerful provers is one we see in human enterprises as well. &lt;a href=&quot;https://en.wikipedia.org/wiki/Terence_Tao&quot;&gt;Terence Tao&lt;/a&gt; might be (by some measures) the world’s top mathematician. But he still submits his papers to peer review, and they can (and are) checked by mere “mortals”. Indeed I would argue that this ability to &lt;strong&gt;communicate&lt;/strong&gt;, &lt;strong&gt;verify&lt;/strong&gt;, and &lt;strong&gt;teach&lt;/strong&gt; is &lt;em&gt;the reason&lt;/em&gt; that human society has managed to “stand on the shoulders of giants” and achieve such growth in productivity despite working with the same human brains our ancestors used to run from animals. Theories like relativity may have taken a huge effort to &lt;em&gt;discover&lt;/em&gt;, but once discovered, could be communicated, verified, and are now taught to first-year undergraduates.&lt;/p&gt;



&lt;p&gt;Interestingly, it seems that the professions that are &lt;a href=&quot;https://academic.oup.com/qje/article-abstract/132/4/1877/3859758?redirectedFrom=fulltext&amp;amp;login=false&quot;&gt;more subject to verification&lt;/a&gt; are not the ones that require the most information-processing skills but rather “alignment”: more “wisdom” than “smartness”. Perhaps those professions &lt;a href=&quot;https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/&quot;&gt;would not be the professions most amenable for AIs&lt;/a&gt;.&lt;/p&gt;



&lt;figure class=&quot;wp-block-image&quot;&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/zt9TK0wqTCqgyCcwOelndi2KWvqbc7EEkTMfkw09CFOyT0Sj5QuafmRF9ro-VaMpR_n6JD-1txqau3c4bc1QWbPaE5G-942lomjrSk3qGS2XVIkcYppZ5t1OPxKVkEYbZpPOttrCQEdv4-yBCeqn-Rg&quot; alt=&quot;&quot; /&gt;&lt;/figure&gt;



&lt;p&gt;Practical verification of ML systems is still an ongoing effort. There are methods for &lt;a href=&quot;https://www.deepmind.com/publications/red-teaming-language-models-with-language-models&quot;&gt;red teaming&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2206.05802&quot;&gt;self-critiquing&lt;/a&gt;,  &lt;a href=&quot;https://arxiv.org/abs/2205.11822&quot;&gt;probing for consistency&lt;/a&gt;, or &lt;a href=&quot;https://arxiv.org/abs/2112.02969&quot;&gt;testing generated code&lt;/a&gt; that can reduce errors. However, we do not yet have robust verification schemes in the sense that we can reliably drive the error probability to zero by spending more effort at inference (let alone drive it &lt;em&gt;exponentially fast&lt;/em&gt; to zero, as we can often do in theoretical CS- something that may be crucial for ensuring robustness against adversarial inputs).&lt;/p&gt;



&lt;figure class=&quot;wp-block-image&quot;&gt;&lt;img src=&quot;https://lh5.googleusercontent.com/ylrE7vqPWD3urdsy34vHOGxzEleKZr9906UMKksSNDeIkeg1y9p_4Pqwi2dikT__blW7cYjOxAfraLhsavMWPwSYMLbIBuGPdM27_TbEFPtNXaFDt2rlHxj6dq1AoKwNWPFe4VOgjxgQlGk4ppF2_-U&quot; alt=&quot;&quot; /&gt;&lt;/figure&gt;



&lt;p&gt;One potential advantage of AI models is that they can themselves write symbolic proofs that may later be verifiable with formal theorem provers. For example, &lt;a href=&quot;https://arxiv.org/abs/2205.12615&quot;&gt;Wu et al&lt;/a&gt; used LLMs to formalize mathematical competition problems in the systems Isabelle/HOL. Overall, there seems to be a huge potential in combining the rich literature on proof systems with the power of modern language models.&lt;/p&gt;



&lt;p&gt;To sum up, artificial Intelligence has made great strides in performance over the last decade and will be widely deployed across many fields in the near future. As the use of AI systems increases, so will the importance of ensuring reliability, fairness, trustworthiness, and security.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Boaz Barak&lt;/p&gt;
  </description>
  <pubDate>2023-04-12 15:25:45 UTC</pubDate>
  <author>Windows on Theory</author>
</item>

<item>
  <title>Geometry of Rounding: Near Optimal Bounds and a New Neighborhood Sperner&#39;s Lemma</title>
  <guid>http://arxiv.org/abs/2304.04837</guid>
  <link>http://arxiv.org/abs/2304.04837</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woude_J/0/1/0/all/0/1&quot;&gt;Jason Vander Woude&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dixon_P/0/1/0/all/0/1&quot;&gt;Peter Dixon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pavan_A/0/1/0/all/0/1&quot;&gt;A. Pavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radcliffe_J/0/1/0/all/0/1&quot;&gt;Jamie Radcliffe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinodchandran_N/0/1/0/all/0/1&quot;&gt;N. V. Vinodchandran&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A partition $\mathcal{P}$ of $\mathbb{R}^d$ is called a
$(k,\varepsilon)$-secluded partition if, for every $\vec{p} \in \mathbb{R}^d$,
the ball $\overline{B}_{\infty}(\varepsilon, \vec{p})$ intersects at most $k$
members of $\mathcal{P}$. A goal in designing such secluded partitions is to
minimize $k$ while making $\varepsilon$ as large as possible. This partition
problem has connections to a diverse range of topics, including deterministic
rounding schemes, pseudodeterminism, replicability, as well as Sperner/KKM-type
results.
&lt;/p&gt;
&lt;p&gt;In this work, we establish near-optimal relationships between $k$ and
$\varepsilon$. We show that, for any bounded measure partitions and for any
$d\geq 1$, it must be that $k\geq(1+2\varepsilon)^d$. Thus, when $k=k(d)$ is
restricted to ${\rm poly}(d)$, it follows that $\varepsilon=\varepsilon(d)\in
O\left(\frac{\ln d}{d}\right)$. This bound is tight up to log factors, as it is
known that there exist secluded partitions with $k(d)=d+1$ and
$\varepsilon(d)=\frac{1}{2d}$. We also provide new constructions of secluded
partitions that work for a broad spectrum of $k(d)$ and $\varepsilon(d)$
parameters. Specifically, we prove that, for any
$f:\mathbb{N}\rightarrow\mathbb{N}$, there is a secluded partition with
$k(d)=(f(d)+1)^{\lceil\frac{d}{f(d)}\rceil}$ and
$\varepsilon(d)=\frac{1}{2f(d)}$. These new partitions are optimal up to
$O(\log d)$ factors for various choices of $k(d)$ and $\varepsilon(d)$. Based
on the lower bound result, we establish a new neighborhood version of Sperner&#39;s
lemma over hypercubes, which is of independent interest. In addition, we prove
a no-free-lunch theorem about the limitations of rounding schemes in the
context of pseudodeterministic/replicable algorithms.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>GRIL: A $2$-parameter Persistence Based Vectorization for Machine Learning</title>
  <guid>http://arxiv.org/abs/2304.04970</guid>
  <link>http://arxiv.org/abs/2304.04970</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xin_C/0/1/0/all/0/1&quot;&gt;Cheng Xin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1&quot;&gt;Soham Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samaga_S/0/1/0/all/0/1&quot;&gt;Shreyas N. Samaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dey_T/0/1/0/all/0/1&quot;&gt;Tamal K. Dey&lt;/a&gt;&lt;/p&gt;&lt;p&gt;$1$-parameter persistent homology, a cornerstone in Topological Data Analysis
(TDA), studies the evolution of topological features such as connected
components and cycles hidden in data. It has been applied to enhance the
representation power of deep learning models, such as Graph Neural Networks
(GNNs). To enrich the representations of topological features, here we propose
to study $2$-parameter persistence modules induced by bi-filtration functions.
In order to incorporate these representations into machine learning models, we
introduce a novel vector representation called Generalized Rank Invariant
Landscape \textsc{Gril} for $2$-parameter persistence modules. We show that
this vector representation is $1$-Lipschitz stable and differentiable with
respect to underlying filtration functions and can be easily integrated into
machine learning models to augment encoding topological features. We present an
algorithm to compute the vector representation efficiently. We also test our
methods on synthetic and benchmark graph datasets, and compare the results with
previous vector representations of $1$-parameter and $2$-parameter persistence
modules.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>The Kraft--Barmpalias--Lewis-Pye lemma revisited</title>
  <guid>http://arxiv.org/abs/2304.04852</guid>
  <link>http://arxiv.org/abs/2304.04852</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_A/0/1/0/all/0/1&quot;&gt;Alexander Shen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This note provides a simplified exposition of the proof of hierarchical Kraft
lemma proven by Barmpalias and Lewis-Pye and its consequences for the oracle
use in the Ku\v{c}era--G\&#39;acs theorem (saying that every sequence is Turing
reducible to a random one).
&lt;/p&gt;
  </description>
  <pubDate>2023-04-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Robust Dequantization of the Quantum Singular value Transformation and Quantum Machine Learning Algorithms</title>
  <guid>http://arxiv.org/abs/2304.04932</guid>
  <link>http://arxiv.org/abs/2304.04932</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gall_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Le Gall&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Several quantum algorithms for linear algebra problems, and in particular
quantum machine learning problems, have been &quot;dequantized&quot; in the past few
years. These dequantization results typically hold when classical algorithms
can access the data via length-squared sampling. In this work we investigate
how robust these dequantization results are. We introduce the notion of
approximate length-squared sampling, where classical algorithms are only able
to sample from a distribution close to the ideal distribution in total
variation distance. While quantum algorithms are natively robust against small
perturbations, current techniques in dequantization are not. Our main technical
contribution is showing how many techniques from randomized linear algebra can
be adapted to work under this weaker assumption as well. We then use these
techniques to show that the recent low-rank dequantization framework by Chia,
Gily\&#39;en, Li, Lin, Tang and Wang (JACM 2022) and the dequantization framework
for sparse matrices by Gharibian and Le Gall (STOC 2022), which are both based
on the Quantum Singular Value Transformation, can be generalized to the case of
approximate length-squared sampling access to the input. We also apply these
results to obtain a robust dequantization of many quantum machine learning
algorithms, including quantum algorithms for recommendation systems, supervised
clustering and low-rank matrix inversion.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>An Associativity Threshold Phenomenon in Set-Associative Caches</title>
  <guid>http://arxiv.org/abs/2304.04954</guid>
  <link>http://arxiv.org/abs/2304.04954</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bender_M/0/1/0/all/0/1&quot;&gt;Michael A. Bender&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1&quot;&gt;Rathish Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farach_Colton_M/0/1/0/all/0/1&quot;&gt;Mart&amp;#xed;n Farach-Colton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tagliavini_G/0/1/0/all/0/1&quot;&gt;Guido Tagliavini&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In an $\alpha$-way set-associative cache, the cache is partitioned into
disjoint sets of size $\alpha$, and each item can only be cached in one set,
typically selected via a hash function. Set-associative caches are widely used
and have many benefits, e.g., in terms of latency or concurrency, over fully
associative caches, but they often incur more cache misses. As the set size
$\alpha$ decreases, the benefits increase, but the paging costs worsen.
&lt;/p&gt;
&lt;p&gt;In this paper we characterize the performance of an $\alpha$-way
set-associative LRU cache of total size $k$, as a function of $\alpha =
\alpha(k)$. We prove the following, assuming that sets are selected using a
fully random hash function:
&lt;/p&gt;
&lt;p&gt;- For $\alpha = \omega(\log k)$, the paging cost of an $\alpha$-way
set-associative LRU cache is within additive $O(1)$ of that a fully-associative
LRU cache of size $(1-o(1))k$, with probability $1 - 1/\operatorname{poly}(k)$,
for all request sequences of length $\operatorname{poly}(k)$.
&lt;/p&gt;
&lt;p&gt;- For $\alpha = o(\log k)$, and for all $c = O(1)$ and $r = O(1)$, the paging
cost of an $\alpha$-way set-associative LRU cache is not within a factor $c$ of
that a fully-associative LRU cache of size $k/r$, for some request sequence of
length $O(k^{1.01})$.
&lt;/p&gt;
&lt;p&gt;- For $\alpha = \omega(\log k)$, if the hash function can be occasionally
changed, the paging cost of an $\alpha$-way set-associative LRU cache is within
a factor $1 + o(1)$ of that a fully-associative LRU cache of size $(1-o(1))k$,
with probability $1 - 1/\operatorname{poly}(k)$, for request sequences of
arbitrary (e.g., super-polynomial) length.
&lt;/p&gt;
&lt;p&gt;Some of our results generalize to other paging algorithms besides LRU, such
as least-frequently used (LFU).
&lt;/p&gt;
  </description>
  <pubDate>2023-04-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Longest Common Subsequence with Gap Constraints</title>
  <guid>http://arxiv.org/abs/2304.05270</guid>
  <link>http://arxiv.org/abs/2304.05270</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adamson_D/0/1/0/all/0/1&quot;&gt;Duncan Adamson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kosche_M/0/1/0/all/0/1&quot;&gt;Maria Kosche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koss_T/0/1/0/all/0/1&quot;&gt;Tore Ko&amp;#xdf;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manea_F/0/1/0/all/0/1&quot;&gt;Florin Manea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siemer_S/0/1/0/all/0/1&quot;&gt;Stefan Siemer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the longest common subsequence problem in the context of
subsequences with gap constraints. In particular, following Day et al. 2022, we
consider the setting when the distance (i. e., the gap) between two consecutive
symbols of the subsequence has to be between a lower and an upper bound (which
may depend on the position of those symbols in the subsequence or on the
symbols bordering the gap) as well as the case where the entire subsequence is
found in a bounded range (defined by a single upper bound), considered by
Kosche et al. 2022. In all these cases, we present effcient algorithms for
determining the length of the longest common constrained subsequence between
two given strings.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Negative-Weight Single-Source Shortest Paths in Near-Linear Time: Now Faster!</title>
  <guid>http://arxiv.org/abs/2304.05279</guid>
  <link>http://arxiv.org/abs/2304.05279</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bringmann_K/0/1/0/all/0/1&quot;&gt;Karl Bringmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cassis_A/0/1/0/all/0/1&quot;&gt;Alejandro Cassis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_N/0/1/0/all/0/1&quot;&gt;Nick Fischer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work we revisit the fundamental Single-Source Shortest Paths (SSSP)
problem with possibly negative edge weights. A recent breakthrough result by
Bernstein, Nanongkai and Wulff-Nilsen established a near-linear $O(m \log^8(n)
\log(W))$-time algorithm for negative-weight SSSP, where $W$ is an upper bound
on the magnitude of the smallest negative-weight edge. In this work we improve
the running time to $O(m \log^2(n) \log(nW) \log\log n)$, which is an
improvement by nearly six log-factors. Some of these log-factors are easy to
shave (e.g. replacing the priority queue used in Dijkstra&#39;s algorithm), while
others are significantly more involved (e.g. to find negative cycles we design
an algorithm reminiscent of noisy binary search and analyze it with drift
analysis).
&lt;/p&gt;
&lt;p&gt;As side results, we obtain an algorithm to compute the minimum cycle mean in
the same running time as well as a new construction for computing Low-Diameter
Decompositions in directed graphs.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>GPT-4 gets a B on my quantum computing final exam!</title>
  <guid>https://scottaaronson.blog/?p=7209</guid>
  <link>https://scottaaronson.blog/?p=7209</link>
  <description>
    &lt;p&gt;&lt;em&gt;[Warning: This might be the longest Shtetl-Optimized post of all time!  But that&amp;#8217;s OK; I expect most people will only want to read the introductory part anyway.]&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;As I&amp;#8217;ve mentioned before, economist, blogger, and friend Bryan Caplan was &lt;a href=&quot;https://betonit.substack.com/p/chatgpt-takes-my-midterm-and-gets&quot;&gt;unimpressed&lt;/a&gt; when ChatGPT got merely a D on his Labor Economics midterm.  So on Bryan&amp;#8217;s blog, appropriately named &amp;#8220;Bet On It,&amp;#8221; he &lt;a href=&quot;https://betonit.substack.com/p/ai-bet&quot;&gt;made a public bet&lt;/a&gt; that no AI would score on A on his exam before January 30, 2029.  GPT-4 then &lt;a href=&quot;https://betonit.substack.com/p/gpt-retakes-my-midterm-and-gets-an&quot;&gt;scored an A&lt;/a&gt; a &lt;strong&gt;mere three months later&lt;/strong&gt; (!!!), leading to what &lt;a href=&quot;https://www.theguardian.com/technology/2023/apr/06/chatgpt-ai-bryan-caplan-interview&quot;&gt;Bryan agrees&lt;/a&gt; will likely be one of the first public bets he&amp;#8217;ll ever have to concede (he hasn&amp;#8217;t yet &amp;#8220;formally&amp;#8221; conceded, but only because of technicalities in how the bet was structured).  Bryan has now joined the ranks of the GPT believers, writing&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;When the answers change, I change my mind&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;&lt;a href=&quot;https://twitter.com/bryan_caplan/status/1638199348738793473&quot;&gt;and&lt;/a&gt;&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;AI enthusiasts have cried wolf for decades. GPT-4 is the wolf. I&amp;#8217;ve seen it with my own eyes.&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;But OK, labor econ is one thing.  What about a &lt;em&gt;truly unfakeable&lt;/em&gt; test of &lt;em&gt;true&lt;/em&gt; intelligence?  Like, y&amp;#8217;know, a &lt;em&gt;quantum computing&lt;/em&gt; test?&lt;/p&gt;



&lt;p&gt;Seeking an answer to this crucial and obvious followup question, I had GPT-4 take the actual 2019 final exam from &lt;a href=&quot;https://www.scottaaronson.com/qclec.pdf&quot;&gt;Introduction to Quantum Information Science&lt;/a&gt;, my honors upper-level undergrad course at UT Austin.  I asked &lt;a href=&quot;https://www.justinyirka.com/&quot;&gt;Justin Yirka&lt;/a&gt;, my PhD student and multi-time head TA, to grade the exam as he would for anyone else.  This post is a joint effort of me and him.&lt;/p&gt;



&lt;p&gt;We gave GPT-4 the problems via their LaTeX source code, which GPT-4 can perfectly well understand.  When there were quantum circuits, either in the input or desired output, we handled those either using the &lt;a href=&quot;https://ctan.org/pkg/qcircuit?lang=en&quot;&gt;qcircuit&lt;/a&gt; package, which GPT-4 again understands, or by simply asking it to output an English description of the circuit.  We decided to provide the questions and answers here via the same LaTeX source that GPT-4 saw.&lt;/p&gt;



&lt;p&gt;To the best of my knowledge&amp;#8212;and I double-checked&amp;#8212;this exam has never before been posted on the public Internet, and could not have appeared in GPT-4&amp;#8217;s training data.&lt;/p&gt;



&lt;p&gt;The result: GPT-4 scored &lt;strong&gt;69 / 100&lt;/strong&gt;.  (Because of extra credits, the max score on the exam was &lt;strong&gt;120&lt;/strong&gt;, though the highest score that any student actually achieved was &lt;strong&gt;108&lt;/strong&gt;.)  For comparison, the average among the students was &lt;strong&gt;74.4&lt;/strong&gt; (though with a strong selection effect&amp;#8212;many students who were struggling had dropped the course by then!).  While there&amp;#8217;s no formal mapping from final exam scores to letter grades (the latter depending on other stuff as well), GPT-4&amp;#8217;s performance would correspond to a &lt;strong&gt;B&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;(Note: I said yesterday that its score was 73, but commenters brought to my attention that GPT was given a full credit for a wrong answer on 2(a), a density matrix that wasn&amp;#8217;t even normalized.)&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;In general, I&amp;#8217;d say that GPT-4 was strongest on true/false questions and (ironically!) conceptual questions&amp;#8212;the ones where many students struggled the most.  It was (again ironically!) weakest on calculation questions, where it would often know what &lt;em&gt;kind&lt;/em&gt; of calculation to do but then botch the execution.  We didn&amp;#8217;t try the new &lt;a href=&quot;https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/&quot;&gt;interface to WolframAlpha&lt;/a&gt;, which might improve its performance on those questions.  We&amp;#8217;d be happy for anyone else to try that.&lt;/p&gt;



&lt;p&gt;One should also remember that the students had just &lt;em&gt;taken the course&lt;/em&gt;&amp;#8212;including weekly problem sets, recitation sections, office hours, a midterm, and a practice final, all giving them recent experience with what kinds of problems to expect.  By contrast, GPT-4 was &amp;#8220;flying blind,&amp;#8221; &lt;strong&gt;except&lt;/strong&gt; for having vacuumed up the whole public Internet, presumably including other people&amp;#8217;s quantum computing homework sets and exams!  It&amp;#8217;s plausible that fine-tuning or few-shot prompting with my other exams or lecture notes would improve GPT-4&amp;#8217;s performance; we didn&amp;#8217;t try that.&lt;/p&gt;



&lt;p&gt;What else?  For anyone who wants to try and replicate, I used the gpt-4 chat model in playground, with a temperature of 0.2 and a max length of 1930&amp;nbsp;tokens.&lt;/p&gt;



&lt;p&gt;Without further ado, here&amp;#8217;s the exam.  Throughout, GPT&amp;#8217;s answers are in &lt;strong&gt;&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;blue&lt;/mark&gt;&lt;/strong&gt; and my and Justin&amp;#8217;s grading comments are in &lt;strong&gt;&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;red&lt;/mark&gt;&lt;/strong&gt;.&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;I often start my Quantum Information Science final exam with an optional, ungraded question asking for the students&amp;#8217; favorite interpretation of quantum mechanics, and then collect statistics about it (including the correlation with final exam score!).  Just for fun, let&amp;#8217;s see how GPT-4 handles &lt;em&gt;that&lt;/em&gt; question.&lt;/p&gt;



&lt;p&gt;&lt;code&gt;What is your favorite interpretation of quantum mechanics?&lt;br&gt;- Copenhagen&lt;br&gt;- Many-Worlds&lt;br&gt;- Bohmian Mechanics&lt;br&gt;- New Physics (Including Dynamical Collapse)&lt;br&gt;- Other:&lt;br&gt;- None&lt;br&gt;- What does it even matter?&lt;br&gt;&lt;br&gt;&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;As an AI language model, I do not have personal preferences or opinions. However, I can provide you with a brief overview of each interpretation mentioned:&lt;br&gt;&lt;br&gt;1. Copenhagen Interpretation: This is the most widely accepted interpretation of quantum mechanics. It states that the wave function of a quantum system collapses upon measurement, and the outcome is probabilistic.&lt;br&gt;&lt;br&gt;2. Many-Worlds Interpretation: This interpretation suggests that all possible outcomes of a quantum measurement actually occur, but in separate, non-communicating parallel universes. There is no wave function collapse in this interpretation.&lt;br&gt;&lt;br&gt;3. Bohmian Mechanics: Also known as the pilot-wave theory, this interpretation proposes that particles have definite positions at all times, and their motion is guided by a &quot;pilot wave&quot; that is described by the wave function.&lt;br&gt;&lt;br&gt;4. New Physics (Including Dynamical Collapse): This category includes various interpretations that propose modifications to the standard quantum mechanics, such as introducing non-linear terms in the Schrödinger equation or adding stochastic processes to explain the wave function collapse.&lt;br&gt;&lt;br&gt;5. Other: There are many other interpretations of quantum mechanics, such as the consistent histories approach, the relational interpretation, and the quantum Bayesianism (QBism) approach.&lt;br&gt;&lt;br&gt;6. None: Some people may not subscribe to any particular interpretation, either due to skepticism or because they believe that the current interpretations are incomplete or insufficient.&lt;br&gt;&lt;br&gt;7. What does it even matter?: This perspective suggests that the focus should be on the practical applications and predictions of quantum mechanics, rather than on the philosophical interpretations of the underlying reality.&lt;br&gt;&lt;br&gt;Ultimately, the choice of interpretation depends on one&#39;s philosophical inclinations and personal preferences.&lt;/mark&gt;&lt;/code&gt;&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;Next let&amp;#8217;s see the True/Falses.  Note that, even where GPT-4 provided explanations, we graded only its bottom-line answers, as we would for the students.  Its total on this section is &lt;strong&gt;17 / 20&lt;/strong&gt;.&lt;/p&gt;



&lt;pre class=&quot;wp-block-preformatted&quot;&gt;1a. True or False?  Unitary matrices preserve the 2-norm of all complex vectors.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;True. Unitary matrices preserve the 2-norm of all complex vectors. This property is known as being norm-preserving or isometric. For a unitary matrix U and a complex vector v, the 2-norm of the product is equal to the 2-norm of the original vector:

||Uv|| = ||v||

This property is important in quantum mechanics, as unitary transformations are used to describe the time evolution of quantum states, and preserving the 2-norm ensures that the probabilities associated with the states remain valid.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1b. True or False?  A pure state of n qubits is described by an n-dimensional complex unit vector.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;False. A pure state of n qubits is described by a 2^n-dimensional complex unit vector. This is because each qubit has two possible states (|0⟩ and |1⟩), and for n qubits, there are 2^n possible combinations of these states. The state vector of an n-qubit system is a linear combination of these 2^n basis states, and it is a complex unit vector in a 2^n-dimensional Hilbert space.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1c. True or False?  The Bell inequality states that by using classical strategies, Alice and Bob can win the CHSH game with probability at most 3/4.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;True. The no-cloning theorem states that it is impossible to create an exact copy of an arbitrary unknown quantum state. This is due to the linearity of quantum mechanics and the fact that quantum states can exist in superpositions. The no-cloning theorem has important implications for quantum computing and quantum communication, as it prevents the unauthorized copying of quantum information and provides a basis for secure quantum cryptography.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct (even though the explanation is nonsense)&lt;/mark&gt;

1d. True or False?  Google&#39;s recent quantum supremacy experiment demonstrated the successful use of quantum error-correction.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;FALSE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1e. True or False?  Lattice-based cryptography is one proposal for secure post-quantum public-key cryptography.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;TRUE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1f. True or False?  The fastest known classical algorithms for factoring all take time $c^n$, for some $c &amp;gt; 1$, to factor an n-bit integer.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;FALSE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1g. True or False?  Grover&#39;s algorithm can find a marked item in a list of N items using $O(\sqrt{N})$ queries to the list, with high probability, even if the number of marked items is unknown at the start.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;TRUE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1h. True or False?  If Alice and Bob share a bipartite pure state, then their entanglement entropy is equal to the von Neumann entropy of Alice&#39;s local density matrix.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;TRUE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1i. True or False?  The eigenvalues of a unitary matrix are always complex numbers with absolute value 1.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;TRUE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1j. True or False?   The eigenvalues of a density matrix are always in [0,1].

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;TRUE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1k. True or False?   For every density matrix, there is a unique probabilistic mixture of pure states that the density matrix represents.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;FALSE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1l. True or False?   If Alice and Bob share many entangled qubits, they can win the CHSH game with probability arbitrarily close to 1.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;FALSE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1m. True or False?   The only $2 \times 2$ matrices that are both unitary and stochastic are $\begin{bmatrix}1&amp;amp;0\\0&amp;amp;1\end{bmatrix}$ and $\begin{bmatrix}0&amp;amp;1\\1&amp;amp;0\end{bmatrix}$.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;FALSE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Wrong&lt;/mark&gt;

1n. True or False?   In Simon&#39;s algorithm, once we have a state of the form $\frac{1}{\sqrt{2}}(\ket{x} + \ket{x \oplus s})$, we can recover s with probability $\frac{1}{2}$ by measuring this state twice and taking the XOR of the measurements.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;FALSE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1o. True or False?   Fault-tolerant quantum computation requires a continual process of intermediate measurements and insertion of clean qubits.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;TRUE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1p. True or False?   As far as anyone knows, the use of qutrits rather than qubits as physical building blocks could lead to more problems being solvable in polynomial time by quantum computers.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;TRUE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Wrong&lt;/mark&gt;

1q. True or False?   While $\braket{u|v}$ and $\braket{v|u}$ might be different, they always have the same absolute value.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;TRUE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1r. True or False?   When applied to a list of size 4, with 1 marked item, Grover&#39;s algorithm succeeds after just a single iteration.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;TRUE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;

1s. True or False?  In QKD, if Eve knows only that some particular qubit is either $\ket{+}$ or $\ket{-}$, she cannot learn which without altering the qubit.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;TRUE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Wrong&lt;/mark&gt;

1t. True or False?  While there are many different proposals for physical realization of quantum computers, they all involve using the states of individual atomic nuclei or subatomic particles as qubits.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;FALSE&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Correct&lt;/mark&gt;&lt;/pre&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;OK, let&amp;#8217;s move on to short-answer questions!  Total score here: &lt;strong&gt;13 / 20&lt;/strong&gt;.&lt;/p&gt;



&lt;pre class=&quot;wp-block-preformatted&quot;&gt;2. Consider the state:
$$\ket{\psi} = \frac{\ket{00} + \ket{01} + \ket{10}}{\sqrt{3}}$$

(a). Calculate the reduced density matrix of the second qubit of $\ket{\psi}$.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;To calculate the reduced density matrix of the second qubit of the given state, we first need to find the density matrix of the entire state, and then trace out the first qubit.

The density matrix of the entire state is given by:
$$\rho = \ket{\psi}\bra{\psi} = \frac{1}{3}\begin{pmatrix} 1 &amp;amp; 0 &amp;amp; 0 &amp;amp;
1 \\ 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 \\ 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{pmatrix}$$

Now, we trace out the first qubit:
$$\rho_2 = \text{Tr}_1(\rho) = \frac{1}{3}\begin{pmatrix} 1+1 &amp;amp; 1 \\ 1 &amp;amp; 1+1 \end{pmatrix} = \frac{1}{3}\begin{pmatrix} 2 &amp;amp; 1 \\ 1 &amp;amp; 2 \end{pmatrix}$$

Therefore, the reduced density matrix of the second qubit is:
$$\rho_2 = \frac{1}{3}\begin{pmatrix} 2 &amp;amp; 1 \\ 1 &amp;amp; 2 \end{pmatrix}$$&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;&lt;s&gt;JUSTIN: 5/5 points.&lt;/s&gt;&lt;/mark&gt;
&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;SCOTT: No, actually, it screws this up from the first step (taking the density matrix of psi), and gets something that&#39;s not a density matrix at all because it&#39;s not normalized.  1 point out of 5, for knowing what &lt;em&gt;kind&lt;/em&gt; of calculation to do.&lt;/mark&gt;

(b) Calculate $\ket{\psi}$&#39;s entanglement entropy. You don&#39;t need to simplify your answer.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;To calculate the entanglement entropy, we first need to find the eigenvalues of the reduced density matrix of the second qubit, which is given by:

$$\rho_2 = \frac{1}{3}\begin{pmatrix} 2 &amp;amp; 1 \\ 1 &amp;amp; 2 \end{pmatrix}$$

The characteristic equation for this matrix is:
$$\text{det}(\rho_2 - \lambda I) = \frac{1}{9}\begin{vmatrix} 2-\lambda &amp;amp; 1 \\ 1 &amp;amp; 2-\lambda \end{vmatrix} = (\lambda - 3)(\lambda - 1) = 0$$

So, the eigenvalues are $\lambda_1 = \frac{1}{3}$ and $\lambda_2 = \frac{2}{3}$.

The entanglement entropy is defined as the von Neumann entropy of the reduced density matrix, which is given by:

$$S(\rho_2) = -\text{Tr}(\rho_2 \log_2 \rho_2) = -(\lambda_1 \log_2 \lambda_1 + \lambda_2 \log_2 \lambda_2)$$

Plugging in the eigenvalues, we get:

$$S(\rho_2) = -\left(\frac{1}{3} \log_2 \frac{1}{3} + \frac{2}{3}\log_2 \frac{2}{3}\right)$$

Thus, the entanglement entropy of the state $\ket{\psi}$ is:

$$S(\rho_2) = -\left(\frac{1}{3} \log_2 \frac{1}{3} + \frac{2}{3}\log_2 \frac{2}{3}\right)$$&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN:
Up to 5 points.
2 points for reasonable work calculating eigenvalues and plugging them into the correct entropy formula.
5 points for fully correct answer.
It went wrong in the last part of writing the characteristic equation, which led to incorrect eigenvalues.
The correct eigenvalues are 1/2 + sqrt(5)/6 and 1/2 - sqrt(5)/6.

2/5 points.&lt;/mark&gt;

(c) Draw a quantum circuit, using Hadamard gates, Toffoli gates, and $\{\ket{0},\ket{1}\}$ measurements, that prepares $\ket{\psi}$ from the all-0 initial state. Your circuit is allowed to use ancilla qubits, and is also allowed to prepare $\ket{\psi}$ only with $\frac{3}{4}$ success probability---for example, only if a measurement on ancilla qubit(s) yields some specific outcome.
If, being a language model, you can&#39;t draw a circuit, then feel free to describe it, in enough detail that it could be drawn.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;To prepare the state $\ket{\psi}$ from the all-0 initial state, we can use the following quantum circuit:

1. Start with three qubits in the state $\ket{000}$.
2. Apply a Hadamard gate (H) to the first qubit. This creates the state $\frac{1}{\sqrt{2}}(\ket{000} + \ket{100})$.
3. Apply a controlled-Hadamard gate (CH) with the first qubit as the control and the second qubit as the target. This creates the state $\frac{1}{2}(\ket{000} + \ket{010} + \ket{100} + \ket{110})$.
4. Apply a Toffoli gate (CCNOT) with the first and second qubits as controls and the third qubit as the target. This creates the state $\frac{1}{2}(\ket{000} + \ket{010} + \ket{100} + \ket{111})$.
5. Apply a Hadamard gate (H) to the third qubit. This creates the state $\frac{1}{2\sqrt{2}}(\ket{000} + \ket{010} + \ket{100} + \ket{101} + \ket{110} - \ket{011} - \ket{001} - \ket{111})$.
6. Measure the third qubit. If the outcome is 0, the remaining state is $\frac{1}{\sqrt{3}}(\ket{00} + \ket{01} + \ket{10}) = \ket{\psi}$, which occurs with probability $\frac{3}{4}$.

Here&#39;s a description of the circuit using standard quantum gates:

```
q0 -- H -- CH -- CCNOT -- M
         |     |
q1 --     H -- CCNOT -- M
               |
q2 --          X -- H -- M
```

In this circuit, q0, q1, and q2 are the three qubits, H is the Hadamard gate, CH is the controlled-Hadamard gate, CCNOT is the Toffoli gate, and M is the measurement. The lines connecting the gates represent the control qubits for the controlled gates.&lt;/mark&gt;
&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;
&lt;/mark&gt;&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN:
Up to 5 points.
Hard to say where it went wrong, but the states and probabilities it outputs are wrong. 
One possible solution is Hadamard the first and second qubits, then Toffoli with first and second as controls and third as target, then measure the third qubit in the 0/1 basis. With probability 3/4, the measurement will be |0&gt; and the remaining state will be |psi&gt;. 
I would usually give partial credit if there&#39;s at most 1 mistake, which this does not achieve.
But, this is an especially difficult circuit problem, so I&#39;m more lenient than usual.

1/5 points.&lt;/mark&gt;
&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;
SCOTT&#39;S ADDENDUM: Since this problem required drawing a circuit, I tried varying the instructions to GPT (e.g., &quot;output qcircuit code&quot;, no special instructions, etc).  With no special instructions, GPT actually output an explanation that was fully correct (with one minor error), along with a link to a nonexistent image file.  But I&#39;m still going to grade according to the first version I gave it!&lt;/mark&gt;

(d) Explain the error in the following argument.  The Gottesman-Knill theorem states that any quantum circuit composed of Hadamard, CNOT, and Phase gates can be simulated classically in time polynomial in the size of the circuit.  Simon&#39;s algorithm solves Simon&#39;s problem quantumly using only a polynomial number of Hadamard gates and $O(n)$ oracle queries.  Therefore, Simon&#39;s problem can be solved classically in polynomial time using polynomially many oracle queries.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;The error in the argument is that it incorrectly assumes that the Gottesman-Knill theorem applies to Simon&#39;s algorithm as a whole, including the oracle queries. The Gottesman-Knill theorem states that any quantum circuit composed of Hadamard, CNOT, and Phase gates can be simulated classically in time polynomial in the size of the circuit. However, it does not say anything about the complexity of simulating the oracle queries, which are an essential part of Simon&#39;s algorithm.

Simon&#39;s algorithm does indeed use only a polynomial number of Hadamard gates and O(n) oracle queries, but the Gottesman-Knill theorem cannot be directly applied to the entire algorithm, including the oracle queries. Therefore, the argument is incorrect in concluding that Simon&#39;s problem can be solved classically in polynomial time using polynomially many oracle queries.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: 3/3 points.&lt;/mark&gt;

(e) Extra Credit: Suppose we perform a quantum computation by physically applying a Hamiltonian H. What&#39;s to stop us from running the computation, say, $10^{100}$ times faster, by simply replacing H by $H&#39;:=10^{100}H$, which is also a valid Hamiltonian?  Or to put it differently: is there some resource that we&#39;d need $10^{100}$ more of to do this?

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;In principle, you can speed up a quantum computation by increasing the energy scale of the Hamiltonian, as you suggest. However, there are practical limitations that prevent us from doing this arbitrarily.

1. Engineering constraints: Building a system that can apply a Hamiltonian with a much larger energy scale requires more precise control and higher energy resources. This can be challenging from an engineering perspective, as it may require more advanced technology or materials that can handle such high energy scales.

2. Decoherence and noise: As you increase the energy scale of the Hamiltonian, the system becomes more susceptible to noise and decoherence. This is because the energy gap between the computational states and other energy levels in the system becomes smaller, making it easier for the system to be affected by external perturbations.
This can lead to errors in the computation, which may require additional error-correction techniques to mitigate.

3. Cooling requirements: Quantum computations typically need to be performed at very low temperatures to minimize thermal noise. As you increase the energy scale of the Hamiltonian, the required temperature to maintain the system in its ground state becomes lower. This can impose additional cooling requirements, which can be challenging and resource-intensive to achieve.

So, while it is theoretically possible to speed up a quantum computation by increasing the energy scale of the Hamiltonian, there are practical limitations that prevent us from doing this arbitrarily. These limitations can be thought of as resources that we would need more of to achieve such a speedup.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;SCOTT: 1 AND 3 SEEM FINE BUT 2 SEEMS WRONG -- DOESN&#39;T THE GAP *INCREASE* AS
WE SCALE THE HAMILTONIAN, RATHER THAN DECREASING?
JUSTIN: Up to 4 points extra credit.
It mentions &quot;higher energy resources&quot; in part 1, which is what we&#39;re really looking for. And I&#39;m not sure that parts 2 and 3 are fully correct.

2/4 extra credit points.&lt;/mark&gt;&lt;/pre&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;Still here?  OK then, let&amp;#8217;s move on to Shor&amp;#8217;s factoring algorithm!  Total score here: &lt;strong&gt;7 / 10&lt;/strong&gt;.&lt;/p&gt;



&lt;pre class=&quot;wp-block-preformatted&quot;&gt;3. Suppose we use Shor&#39;s algorithm to factor $N=105$ into $3\cdot 5 \cdot 7$.  (Yes, $N$ is now a product of 3 primes!)  Suppose also that we make the choices $x=2$ and $Q=60000$.

(a) What is the order of the multiplicative group $\mathbb{Z}_N^\times$?

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;The order of the multiplicative group $\mathbb{Z}_N^\times$ is given by Euler&#39;s totient function $\varphi(N)$. Since $N = 3 \cdot 5 \cdot 7$, we have $\varphi(N) = \varphi(3) \cdot \varphi(5) \cdot \varphi(7) = (3-1)(5-1)(7-1) = 2 \cdot 4 \cdot 6 = \boxed{48}$.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: 2/2 points.&lt;/mark&gt;

(b) What is the period of the function $f(r)=x^r (\bmod N)$?

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;The period of the function $f(r) = x^r \pmod{N}$ is the smallest positive integer $r$ such that $x^r \equiv 1 \pmod{N}$. This is the order of $x$ in the multiplicative group $\mathbb{Z}_N^\times$. Since the order of the group is 48, the period $r$ must be a divisor of 48.

To find the period, we can check the divisors of 48 in increasing order. We have $x = 2$ and $N = 105$, so we compute the powers of 2 modulo 105:

- $2^1 \equiv 2 \pmod{105}$
- $2^2 \equiv 4 \pmod{105}$
- $2^3 \equiv 8 \pmod{105}$
- $2^4 \equiv 16 \pmod{105}$
- $2^6 \equiv 64 \pmod{105}$
- $2^{12} \equiv 16 \pmod{105}$
- $2^{24} \equiv 1 \pmod{105}$

We find that the smallest positive integer $r$ such that $2^r \equiv 1 \pmod{105}$ is $r = \boxed{24}$.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: Up to 2 points.
The correct answer is 12, i.e. 2^12 = 1 mod 105.
Given the work, this earns partial credit.

1/2 points.&lt;/mark&gt;

(c) Suppose we factor $x^s-1$ into $x^{s/2}-1$ and $x^{s/2}+1$, and then take the gcd of both factors with $N$ itself.  Which prime factors of $N$, if any, would be ``peeled off&#39;&#39; this way?

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;Let&#39;s compute $x^{s/2} \pmod{N}$, where $x = 2$, $s = 24$, and $N = 105$. We have $x^{s/2} = 2^{12} \equiv 16 \pmod{105}$. Now we can compute the gcd of both factors with $N$:

- $\gcd(x^{s/2} - 1, N) = \gcd(16 - 1, 105) = \gcd(15, 105) = 15 = 3 \cdot 5$
- $\gcd(x^{s/2} + 1, N) = \gcd(16 + 1, 105) = \gcd(17, 105) = 1$

So, by taking the gcd of both factors with $N$, we would &quot;peel off&quot; the prime factors $3$ and $5$ of $N$. The prime factor $7$ is not peeled off in this process.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Up to 3 points.
Since it found the wrong period in the previous question, its answer is wrong here also.  It also seems to invert the definition of &quot;peel off.&quot;  But it does the gcd computations correctly.
1/3.&lt;/mark&gt;

(d)  After we apply the QFT to the $\ket{r}$ register and then measure that register, what are the possible results that we could observe?

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;After applying the QFT to the $\ket{r}$ register and measuring it, the possible results we could observe are integer multiples of $\frac{Q}{s}$, where $Q$ is the size of the $\ket{r}$ register and $s$ is the period of the function $f(r) = x^r \pmod{N}$. In this case, we have $Q = 60000$ and $s = 24$. So, the possible results are integer multiples of $\frac{60000}{24} = 2500$.

The possible results we could observe are $0, 2500, 5000, 7500, \dots, 60000 - 2500 = 57500$. Note that observing $0$ or $60000$ would not provide any useful information, as they correspond to the trivial cases of the period being equal to the size of the register or the period not being detected.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: Up to 3 points.
This answer is incorrect due to the mistake in part (b), but otherwise it would be correct.
(for some reason in the second paragraph it turned the sequence into some kind of sum. That&#39;s weird.)

3/3 points.&lt;/mark&gt;&lt;/pre&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;OK, onwards to a question about Hamiltonians!  Total score: &lt;strong&gt;6 / 12&lt;/strong&gt;.&lt;/p&gt;



&lt;pre class=&quot;wp-block-preformatted&quot;&gt;4.
(a) &amp;nbsp;Give a basis of eigenvectors for the $4 \times 4$ CNOT matrix, along with their associated eigenvalues.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;The CNOT (Controlled-NOT) matrix is a $4 \times 4$ matrix given by:

$$
CNOT = \begin{pmatrix}
1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0
\end{pmatrix} $$

To find the eigenvectors and eigenvalues, we first need to find the characteristic polynomial of the matrix, which is given by the determinant of $(CNOT - \lambda I)$:

$$
\det(CNOT - \lambda I) = \det\begin{pmatrix}
1-\lambda &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 1-\lambda &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; -\lambda &amp;amp; 1 \\
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; -\lambda
\end{pmatrix} $$

The determinant of this matrix is $(1-\lambda)^2(-\lambda)^2 - (1-\lambda)^2 = (1-\lambda)^2(\lambda^2 - 1)$. Thus, the eigenvalues are $\lambda_1 = 1$, $\lambda_2 = 1$, $\lambda_3 = -1$, and $\lambda_4 = -1$.

Now, we find the eigenvectors associated with each eigenvalue:

1. For $\lambda_1 = 1$:

$$ (CNOT - I)v_1 = \begin{pmatrix}
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 1 \\
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; -1
\end{pmatrix}v_1 = 0 $$

A basis for the eigenspace corresponding to $\lambda_1 = 1$ is given by $v_1 = \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix}$ and $v_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}$.

2. For $\lambda_3 = -1$:

$$ (CNOT + I)v_3 = \begin{pmatrix}
2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 2 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 \\
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1
\end{pmatrix}v_3 = 0 $$

A basis for the eigenspace corresponding to $\lambda_3 = -1$ is given by $v_3 = \begin{pmatrix} 0 \\ 0 \\ 1 \\ -1 \end{pmatrix}$ and $v_4 = \begin{pmatrix} 0 \\ 0 \\ 1 \\ 1 \end{pmatrix}$.

Thus, a basis of eigenvectors for the CNOT matrix is given by:

$$
v_1 = \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix}, \quad
v_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}, \quad
v_3 = \begin{pmatrix} 0 \\ 0 \\ 1 \\ -1 \end{pmatrix}, \quad
v_4 = \begin{pmatrix} 0 \\ 0 \\ 1 \\ 1 \end{pmatrix} $$

with associated eigenvalues $\lambda_1 = 1$, $\lambda_2 = 1$, $\lambda_3 = -1$, and $\lambda_4 = -1$.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: Up to 3 points.
The eigenvalue lambda4 is wrong, it should be&amp;nbsp;+1.
2/3.&lt;/mark&gt;

(b) Give a 2-qubit Hamiltonian $H$ such that $e^{-iH}$ is the CNOT matrix.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;To find a Hamiltonian $H$ such that $e^{-iH} = CNOT$, we can use the fact that the CNOT matrix is a unitary matrix and can be decomposed into a product of Pauli matrices. The Pauli matrices are given by:

$$
\sigma_x = \begin{pmatrix} 0 &amp;amp; 1 \\ 1 &amp;amp; 0 \end{pmatrix}, \quad
\sigma_y = \begin{pmatrix} 0 &amp;amp; -i \\ i &amp;amp; 0 \end{pmatrix}, \quad
\sigma_z = \begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; -1 \end{pmatrix} $$

The CNOT matrix can be written as a product of tensor products of Pauli matrices:

$$
CNOT = \frac{1}{2} (I \otimes I + I \otimes \sigma_x + \sigma_z \otimes I - \sigma_z \otimes \sigma_x) $$

Now, we can find a Hamiltonian $H$ such that $e^{-iH} = CNOT$. We can use the fact that the exponential of a sum of operators is equal to the product of exponentials of the individual operators if the operators commute:

$$ e^{-iH} = e^{-i\frac{\theta}{2}(I \otimes I)} e^{-i\frac{\theta}{2}(I \otimes \sigma_x)} e^{-i\frac{\theta}{2}(\sigma_z \otimes I)} e^{i\frac{\theta}{2}(\sigma_z \otimes \sigma_x)} $$

We want to find the angle $\theta$ such that this product is equal to the CNOT matrix. Since the Pauli matrices have eigenvalues $\pm 1$, we can see that the angle $\theta$ must be $\pi$:

$$ e^{-iH} = e^{-i\frac{\pi}{2}(I \otimes I)} e^{-i\frac{\pi}{2}(I \otimes \sigma_x)} e^{-i\frac{\pi}{2}(\sigma_z \otimes I)} e^{i\frac{\pi}{2}(\sigma_z \otimes \sigma_x)} $$

Now, we can find the Hamiltonian $H$:

$$ H = \frac{\pi}{2}(I \otimes I + I \otimes \sigma_x + \sigma_z \otimes
I - \sigma_z \otimes \sigma_x) $$

So, the 2-qubit Hamiltonian $H$ such that $e^{-iH} = CNOT$ is given by:

$$
H = \frac{\pi}{2} \begin{pmatrix}
1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; 2 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -1
\end{pmatrix} $$&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: Up to 2 points.
Plugging into a calculator, this answer is incorrect. 
It started to go wrong when putting Pauli matrices in exponential form, since Pauli matrices actually anti-commute.  Partial credit for very significant effort.

1/2 points.&lt;/mark&gt;

(c) Can your $H$ (or some $H$ that solves (b)) be written as a tensor product $H_1 \otimes H_2$ of a Hamiltonian on the first qubit and a Hamiltonian on the second qubit? If so, how?

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;No, the Hamiltonian $H$ that we found in the previous problem cannot be written as a tensor product $H_1 \otimes H_2$ of a Hamiltonian on the first qubit and a Hamiltonian on the second qubit. The reason is that the CNOT operation is an entangling operation, meaning that it creates entanglement between the two qubits. If the Hamiltonian could be written as a tensor product of Hamiltonians acting on individual qubits, it would not be able to create entanglement between the qubits.

To see this more explicitly, let&#39;s try to write the Hamiltonian $H$ as a tensor product:

$$ H = H_1 \otimes H_2 = \begin{pmatrix} a &amp;amp; b \\ c &amp;amp; d \end{pmatrix}
\otimes \begin{pmatrix} e &amp;amp; f \\ g &amp;amp; h \end{pmatrix} $$

The tensor product would result in a $4 \times 4$ matrix:

$$ H = \begin{pmatrix}
a e &amp;amp; a f &amp;amp; b e &amp;amp; b f \\
a g &amp;amp; a h &amp;amp; b g &amp;amp; b h \\
c e &amp;amp; c f &amp;amp; d e &amp;amp; d f \\
c g &amp;amp; c h &amp;amp; d g &amp;amp; d h
\end{pmatrix} $$

Comparing this with the Hamiltonian $H$ we found earlier:

$$ H = \frac{\pi}{2} \begin{pmatrix}
1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; 2 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; -1
\end{pmatrix} $$

We can see that there is no way to find values for $a, b, c, d, e, f, g, h$ such that the two matrices are equal. This confirms that the Hamiltonian $H$ cannot be written as a tensor product of Hamiltonians acting on individual qubits.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: Up to 3 points.
A correct solution to part (b) written in the form of part (c) is ((0 0) (0 1)) \otimes pi/2 ((1 -1) (-1 1)).
This question is a bit harsh with partial/carry-through credit, but the answer also explicitly got the main idea wrong, claiming that a tensor product H cannot give an entangling unitary.
0/3.&lt;/mark&gt;

(d) Is there an $H$ that solves (b), while also being a sum $H_1\otimes I + I\otimes H_2$ of a Hamiltonian on the first qubit and a Hamiltonian on the second qubit?&amp;nbsp; Why or why not?

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;No, there is no Hamiltonian $H$ such that $e^{iH} = CNOT$ and $H = H_1 \otimes I + I \otimes H_2$. The reason is that the CNOT operation is an entangling operation, meaning that it creates entanglement between the two qubits. If the Hamiltonian could be written as a sum of Hamiltonians acting on individual qubits, it would not be able to create entanglement between the qubits.

To see this more explicitly, let&#39;s assume that there exists such an $H$:

$$ H = H_1 \otimes I + I \otimes H_2 = \begin{pmatrix} a &amp;amp; b \\ c &amp;amp; d
\end{pmatrix} \otimes \begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix} +
\begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix} \otimes \begin{pmatrix} e
&amp;amp; f \\ g &amp;amp; h \end{pmatrix} $$

The sum of the tensor products would result in a $4 \times 4$ matrix:

$$ H = \begin{pmatrix}
a + e &amp;amp; b &amp;amp; a &amp;amp; b \\
c &amp;amp; d + e &amp;amp; c &amp;amp; d \\
a &amp;amp; b &amp;amp; a + h &amp;amp; b \\
c &amp;amp; d &amp;amp; c &amp;amp; d + h
\end{pmatrix} $$

Now, we want to find an $H$ such that $e^{iH} = CNOT$. The CNOT matrix is given by:

$$ CNOT = \begin{pmatrix}
1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0
\end{pmatrix} $$

However, there is no way to find values for $a, b, c, d, e, f, g, h$ such that $e^{iH} = CNOT$. This is because the CNOT operation creates entanglement between the qubits, and a Hamiltonian that can be written as a sum of Hamiltonians acting on individual qubits cannot create entanglement.

In summary, there is no Hamiltonian $H$ such that $e^{iH} = CNOT$ and $H = H_1 \otimes I + I \otimes H_2$ because the CNOT operation is an entangling operation, and a Hamiltonian that can be written as a sum of Hamiltonians acting on individual qubits cannot create entanglement.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;Up to 4 points.
It&#39;s correct that an H of this form can&#39;t generate CNOT because it can&#39;t create entanglement, although most of the rest is just repetitive fluff.
3/4.&lt;/mark&gt;&lt;/pre&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;Now for a question about the complexity of generating certain uniform superpositions over sets (a special case of &amp;#8220;QSampling&amp;#8221;).  Total score: &lt;strong&gt;19 / 18&lt;/strong&gt; (of course counting extra credit).&lt;/p&gt;



&lt;pre class=&quot;wp-block-preformatted&quot;&gt;5. In the Graph Isomorphism problem, we&#39;re given as input two $n$-vertex undirected graphs $G$ and $H$.  The problem is to determine whether they&#39;re isomorphic---in other words, whether there&#39;s any permutation of the vertex labels that makes $G$ and $H$ equal.

(a) Given as input an $n$-vertex graph $G$, describe how to sample, in classical $\mathrm{poly}(n)$ time, from a probability distribution $D_G$ over graphs such that:
- Whenever the graphs $G$ and $H$ are isomorphic, $D_G = D_H$.
- Whenever $G$ and $H$ are non-isomorphic, $D_G$ and $D_H$ have disjoint supports (i.e., no graph appears with nonzero probability in both of them).

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;To sample from the probability distribution $D_G$ over graphs, we can follow these steps:

1. Compute the canonical form of the input graph $G$. This can be done using a graph canonization algorithm, such as the one by Brendan McKay (nauty) or the one by Laszlo Babai (Traces). These algorithms run in classical $\mathrm{poly}(n)$ time.

2. Generate a random permutation of the vertex labels of the canonical form of $G$. This can be done by selecting a random permutation of the integers from $1$ to $n$, and then applying this permutation to the vertex labels of the canonical form.

3. Apply the random permutation to the canonical form of $G$ to obtain a new graph $G&#39;$. This graph $G&#39;$ is a sample from the probability distribution $D_G$.

The above procedure ensures that whenever the graphs $G$ and $H$ are isomorphic, $D_G = D_H$, because their canonical forms will be the same, and the random permutations applied to their canonical forms will generate the same distribution over graphs. On the other hand, whenever $G$ and $H$ are non-isomorphic, their canonical forms will be different, and the random permutations applied to their canonical forms will generate disjoint supports for $D_G$ and $D_H$.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: Up to 5 points.
The first step of computing the canonical form is superfluous and incorrect, since computing the canonical form is at least as hard as solving graph isomorphism and we don&#39;t know how to solve that in polynomial time.
Also, it looks like step 2 or 3 should have been about graph H instead of both being about G.
So it seems to have exactly the right idea but described it poorly.
4/5.
&lt;/mark&gt;
(b) Given a probability distribution $D=(p_x)$ over $n$-bit strings $x$, define the ``QSampling state&#39;&#39; of $D$ to be $$\ket{\psi_D} := \sum_{x \in \{0,1\}^n} \sqrt{p_x} \ket{x}$$
Given two probability distributions $D$ and $D&#39;$, suppose that the quantum circuit $\mathcal{C}$ maps $\ket{0^n}$ to $\ket{\psi_D}$, while the circuit $\mathcal{C}&#39;$ maps $\ket{0^n}$ to $\ket{\psi_{D&#39;}}$.

Then what is the output state of the circuit shown below, which acts on $n+1$ qubits?
$$ \Qcircuit @C=.5em @R=0.5em @!R {
\lstick{\ket{0}} &amp;amp; \gate{H} &amp;amp; \ctrl{1} &amp;amp; \gate{NOT} &amp;amp;  \ctrl{1} &amp;amp; \qw\\
\lstick{\ket{0^n}} &amp;amp; \qw &amp;amp; \gate{\mathcal{C}} &amp;amp; \qw &amp;amp; \gate{\mathcal{C}&#39;} &amp;amp; \qw } $$

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;To find the output state of the given circuit, we first analyze it step by step.

1. After applying the Hadamard gate (H) on the first qubit, the state becomes:
$$\frac{1}{\sqrt{2}}(\ket{0} + \ket{1}) \otimes \ket{0^n}$$

2. Next, the controlled-$\mathcal{C}$ gate is applied. This gate applies the $\mathcal{C}$ operation on the second register if the first qubit is in state $\ket{0}$. So, the state becomes:
$$\frac{1}{\sqrt{2}}(\ket{0} \otimes \ket{\psi_D} + \ket{1} \otimes \ket{0^n})$$

3. The NOT gate is applied on the first qubit, which flips the state of the first qubit. The state becomes:
$$\frac{1}{\sqrt{2}}(\ket{1} \otimes \ket{\psi_D} + \ket{0} \otimes \ket{0^n})$$

4. Finally, the controlled-$\mathcal{C}&#39;$ gate is applied. This gate applies the $\mathcal{C}&#39;$ operation on the second register if the first qubit is in state $\ket{0}$. So, the state becomes:
$$\frac{1}{\sqrt{2}}(\ket{1} \otimes \ket{\psi_D} + \ket{0} \otimes \ket{\psi_{D&#39;}})$$

Thus, the output state of the circuit is:
$$\frac{1}{\sqrt{2}}(\ket{1} \otimes \ket{\psi_D} + \ket{0} \otimes \ket{\psi_{D&#39;}})$$&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: 4/4.
I think solving this one is impressive.&lt;/mark&gt;

(c) Now suppose we measure the first qubit of that output state in the $\{\ket{+},\ket{-}\}$ basis.  What is the probability of the outcome $\ket{+}$ if $D=D&#39;$?  What about if $D$ and $D&#39;$ have disjoint supports?

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;To find the probability of the outcome $\ket{+}$, we first express the output state in terms of the $\{\ket{+},\ket{-}\}$ basis. Recall that $\ket{+} = \frac{1}{\sqrt{2}}(\ket{0} + \ket{1})$ and $\ket{-} = \frac{1}{\sqrt{2}}(\ket{0} - \ket{1})$.

The output state is:
$$\frac{1}{\sqrt{2}}(\ket{1} \otimes \ket{\psi_D} + \ket{0} \otimes \ket{\psi_{D&#39;}})$$

We can rewrite this state in terms of the $\{\ket{+},\ket{-}\}$ basis as follows:
$$\frac{1}{2}(\ket{+} \otimes (\ket{\psi_D} + \ket{\psi_{D&#39;}}) + \ket{-} \otimes (\ket{\psi_D} - \ket{\psi_{D&#39;}}))$$

Now, we can find the probability of the outcome $\ket{+}$ by taking the squared magnitude of the coefficient of $\ket{+}$ in the state.

Case 1: $D = D&#39;$

In this case, $\ket{\psi_D} = \ket{\psi_{D&#39;}}$. So, the output state becomes:
$$\frac{1}{2}(\ket{+} \otimes (2\ket{\psi_D}) + \ket{-} \otimes (0))$$

The probability of the outcome $\ket{+}$ is the squared magnitude of the coefficient of $\ket{+}$, which is:
$$\left|\frac{1}{2}(2)\right|^2 = 1$$

Case 2: $D$ and $D&#39;$ have disjoint supports

In this case, $\ket{\psi_D}$ and $\ket{\psi_{D&#39;}}$ are orthogonal, i.e., their inner product is zero: $\langle\psi_D|\psi_{D&#39;}\rangle = 0$. The probability of the outcome $\ket{+}$ is the squared magnitude of the coefficient of $\ket{+}$, which is:
$$\left|\frac{1}{2}(\langle\psi_D|\psi_D\rangle + \langle\psi_{D&#39;}|\psi_{D&#39;}\rangle)\right|^2$$

Since $\langle\psi_D|\psi_D\rangle = 1$ and $\langle\psi_{D&#39;}|\psi_{D&#39;}\rangle = 1$ (both states are normalized), the probability of the outcome $\ket{+}$ is:
$$\left|\frac{1}{2}(1 + 1)\right|^2 = \frac{1}{4}(2)^2 = \frac{1}{2}$$

So, if $D = D&#39;$, the probability of the outcome $\ket{+}$ is 1, and if $D$ and $D&#39;$ have disjoint supports, the probability of the outcome $\ket{+}$ is $\frac{1}{2}$.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;SCOTT: HOLY CRAP, LOOKS CORRECT!
JUSTIN: 5/5.&lt;/mark&gt;

(d) Suppose your distributions $D_G$ from part (a) could be efficiently QSampled.  Using your previous work, explain how Graph Isomorphism could then be solved in $BQP$ (quantum polynomial time).

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;Suppose we can efficiently QSample the distributions $D_G$ and $D_H$ for two input graphs $G$ and $H$. We can then construct the QSampling states $\ket{\psi_{D_G}}$ and $\ket{\psi_{D_H}}$ for these distributions using the quantum circuits $\mathcal{C}_G$ and $\mathcal{C}_H$, respectively, as described in the previous problems.

Now, consider the following quantum circuit acting on $n+1$ qubits:

$$ \Qcircuit @C=.5em @R=0.5em @!R { \lstick{\ket{0}} &amp;amp; \gate{H} &amp;amp; \ctrl{1} &amp;amp; \gate{NOT} &amp;amp;  \ctrl{1} &amp;amp; \qw\\  \lstick{\ket{0^n}} &amp;amp; \qw &amp;amp; \gate{\mathcal{C}_G} &amp;amp; \qw &amp;amp; \gate{\mathcal{C}_H} &amp;amp; \qw } $$

As we found earlier, the output state of this circuit is:

$$\frac{1}{\sqrt{2}}(\ket{1} \otimes \ket{\psi_{D_G}} + \ket{0} \otimes \ket{\psi_{D_H}})$$

Now, we measure the first qubit of the output state in the $\{\ket{+},\ket{-}\}$ basis. We know from our previous work that if $G$ and $H$ are isomorphic (i.e., $D_G = D_H$), the probability of the outcome $\ket{+}$ is 1, and if $G$ and $H$ are non-isomorphic (i.e., $D_G$ and $D_H$ have disjoint supports), the probability of the
outcome $\ket{+}$ is $\frac{1}{2}$.

Thus, we can solve the Graph Isomorphism problem in $BQP$ as follows:

1. Construct the QSampling states $\ket{\psi_{D_G}}$ and $\ket{\psi_{D_H}}$ for the input graphs $G$ and $H$ using the quantum circuits $\mathcal{C}_G$ and $\mathcal{C}_H$.

2. Implement the above quantum circuit and measure the first qubit in the $\{\ket{+},\ket{-}\}$ basis.

3. If the outcome is $\ket{+}$ with probability close to 1, conclude that the graphs $G$ and $H$ are isomorphic. If the outcome is $\ket{+}$ with probability close to $\frac{1}{2}$, conclude that the graphs $G$ and $H$ are non-isomorphic.

This algorithm runs in quantum polynomial time, as the QSampling circuits $\mathcal{C}_G$ and $\mathcal{C}_H$ are assumed to be efficient, and the rest of the operations (Hadamard, NOT, and controlled gates) are also efficient.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: The answer is longer than necessary, repeating some of its previous work.
Also, in theory, if the graphs are isomorphic then the probability of |+&amp;gt; will be exactly 1 not close to 1.

4/4.&lt;/mark&gt;

(e) So then why doesn&#39;t this approach immediately imply a fast quantum algorithm for Graph Isomorphism?  Explain what could go wrong in passing from fast algorithms to sample $D_G$ and $D_H$, to fast algorithms to QSample them.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;The approach described above does not immediately imply a fast quantum algorithm for Graph Isomorphism because there is a crucial difference between classical sampling and QSampling.

In the algorithm, we assumed that we can efficiently construct quantum circuits $\mathcal{C}_G$ and $\mathcal{C}_{G&#39;}$ that map $\ket{0^n}$ to $\ket{\psi_{D_G}}$ and $\ket{\psi_{D_{G&#39;}}}$, respectively, given that the distributions $D_G$ and $D_{G&#39;}$ can be efficiently sampled classically. However, this assumption might not hold in general.

Classical sampling allows us to draw samples from the distributions $D_G$ and $D_{G&#39;}$, but it does not directly provide a way to prepare the corresponding QSampling states $\ket{\psi_{D_G}}$ and $\ket{\psi_{D_{G&#39;}}}$. Preparing these quantum states requires a coherent superposition of all the elements in the distributions with the appropriate amplitudes, which might not be efficiently achievable using the classical sampling algorithms.

In other words, the ability to efficiently sample from a probability distribution classically does not necessarily imply the ability to efficiently prepare the corresponding QSampling state on a quantum computer. This is the main reason why the approach does not immediately lead to a fast quantum algorithm for Graph Isomorphism.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;SCOTT: Correctly explains that sampling doesn&#39;t necessarily imply QSampling (i.e. generating a coherent superposition state), but doesn&#39;t say that this is because of the difficulty of uncomputing garbage.
2 / 5 extra credit points.&lt;/mark&gt;&lt;/pre&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;Next, a problem about quantum communication complexity.  Total score: &lt;strong&gt;5 / 10&lt;/strong&gt;.&lt;/p&gt;



&lt;pre class=&quot;wp-block-preformatted&quot;&gt;6. Suppose Alice and Bob hold $n$-bit strings $x=(x_1,...,x_n)$ and $y=(y_1,...,y_n)$ respectively.  One thing they might want to learn is the mod-2 inner product of their strings, $$x_1 y_1 + \ldots + x_n y_n (\bmod 2).$$

(a) Suppose Alice and Bob had a quantum communication protocol in which they are allowed to exchange up to $T$ qubits and to perform arbitrary local unitary transformations to their qubits (possibly including ancilla qubits), that ended with Bob knowing the above inner product, with success probability 1.  Explain how, by exchanging the same number of qubits $T$, Bob could also prepare an $n$-qubit state
of the form $$\frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{x\cdot z} \ket{z},$$
where $x$ is an $n$-bit string held by Alice.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;If Alice and Bob have a quantum communication protocol that allows Bob to know the mod-2 inner product of their strings with success probability 1, then they can use the same protocol to prepare the desired $n$-qubit state.

Here&#39;s how they can do it:

1. Alice prepares an $n$-qubit state $\ket{\phi}$, where
$$\ket{\phi} = \frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} \ket{z}.$$

2. Alice applies a controlled-phase gate to each qubit of $\ket{\phi}$, using her $n$-bit string $x$ as the control. This results in the state
$$\frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{x\cdot z} \ket{z}.$$

3. Alice sends the $n$-qubit state to Bob.

4. Bob uses the quantum communication protocol to learn the mod-2 inner product of their strings. Since the protocol has success probability 1, Bob will know the inner product with certainty.

5. Bob applies a local unitary transformation to the $n$-qubit state he received from Alice, based on the inner product he learned in step 4. This will result in the desired state
$$\frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{x\cdot z} \ket{z}.$$

Since Alice and Bob only exchanged $T$ qubits in the original protocol, they can also prepare the desired $n$-qubit state by exchanging the same number of qubits $T$.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: Up to 4 points.
This answer is partially correct and/or poorly worded. In particular, in step 3 Alice just sends the whole n-qubit state to Bob.
The right idea is in there, but doesn&#39;t earn full points.

2/4.
&lt;/mark&gt;
(b) Assume Alice and Bob have no preshared entanglement.  Recall Holevo&#39;s Theorem, which implies that in order to communicate $n$ bits to Bob reliably, Alice must send Bob at least $n$ qubits.  Using Holevo&#39;s Theorem together with part (a), prove that Alice and Bob must exchange at least $n$ qubits, even if they only want to learn the inner product mod 2 of their input strings $x$ and $y$.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;From part (a), we know that if Alice and Bob have a quantum communication protocol that allows Bob to know the mod-2 inner product of their strings with success probability 1, then they can also prepare an $n$-qubit state of the form
$$\frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{x\cdot z} \ket{z},$$
by exchanging the same number of qubits $T$.

Now, let&#39;s consider the reverse process. Suppose Bob has the $n$-qubit state
$$\frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{x\cdot z} \ket{z}.$$
He can perform a quantum measurement in the computational basis to obtain a random $n$-bit string $z$. Then, he can compute the mod-2 inner product $x \cdot z$ and send it back to Alice.

Alice, knowing her own string $x$, can compute the mod-2 inner product $x \cdot z$ as well. If the inner product $x \cdot z$ that Bob sent to Alice matches the one she computed, then they have successfully communicated the inner product mod 2 of their input strings $x$ and $y$.

However, according to Holevo&#39;s Theorem, in order to communicate $n$ bits to Bob reliably, Alice must send Bob at least $n$ qubits. Since the $n$-qubit state prepared in part (a) effectively communicates $n$ bits of information (Alice&#39;s string $x$) to Bob, Holevo&#39;s Theorem implies that Alice and Bob must exchange at least $n$ qubits to prepare this state.

Therefore, even if Alice and Bob only want to learn the inner product mod 2 of their input strings $x$ and $y$, they must exchange at least $n$ qubits.
&lt;/mark&gt;
&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: Up to 6 points.
This answer doesn&#39;t earn any points. It only says that Alice and Bob learn the inner products and mistakenly claims this is n bits of information.
The correct solution recognizes that applying Hadamard to the state we showed how to prepare in part (a) gives exactly |x&amp;gt;.

0/6.&lt;/mark&gt;

(c) Now suppose we&#39;re no longer working mod 2, and Alice and Bob want to know whether their inner product
$$x_1 y_1 + \ldots + x_n y_n$$
is zero or nonzero as an integer.  (In other words, whether there&#39;s an $i$ such that $x_i=y_i=1$.)  Describe a protocol by which Alice and Bob can accomplish this, with high probability, by exchanging only $O(\sqrt{n}\log n )$ qubits in total.  The qubits can be spread across as many rounds of communication as necessary, and can be sent in either direction.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;Alice and Bob can use the following protocol, based on the Grover&#39;s search algorithm, to determine whether their inner product is zero or nonzero as an integer, with high probability, by exchanging only $O(\sqrt{n}\log n)$ qubits in total:

1. Alice prepares a quantum register of $n$ qubits in the state $\ket{0}^{\otimes n}$.

2. Alice applies the Hadamard gate to each qubit, resulting in the state $$\ket{\psi} = \frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} \ket{z}.$$

3. Alice and Bob perform the following steps for $O(\sqrt{n})$ iterations:

   a. Alice sends the $n$-qubit state $\ket{\psi}$ to Bob.

   b. Bob applies a controlled-phase gate to each qubit of $\ket{\psi}$, using his $n$-bit string $y$ as the control. This results in the state
   $$\ket{\psi&#39;} = \frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{y\cdot z} \ket{z}.$$

   c. Bob sends the $n$-qubit state $\ket{\psi&#39;}$ back to Alice.

   d. Alice applies a controlled-phase gate to each qubit of $\ket{\psi&#39;}$, using her $n$-bit string $x$ as the control. This results in the state
   $$\ket{\psi&#39;&#39;} = \frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{(x+y)\cdot z} \ket{z}.$$
   Note that if $x_i = y_i = 1$ for some $i$, then the phase of the corresponding term in the sum will be flipped twice, resulting in no change. Therefore, the state $\ket{\psi&#39;&#39;}$ will have a non-zero amplitude for the terms corresponding to the indices where $x_i = y_i = 1$.

   e. Alice applies the Grover&#39;s diffusion operator to the state $\ket{\psi&#39;&#39;}$, which amplifies the amplitudes of the terms corresponding to the indices where $x_i = y_i = 1$. The diffusion operator can be implemented as follows:
      - Apply the Hadamard gate to each qubit.
      - Apply a multi-qubit controlled-Z gate, with all qubits as controls and an ancilla qubit as the target.
      - Apply the Hadamard gate to each qubit again.

   f. Alice updates the state $\ket{\psi}$ with the resulting state after applying the Grover&#39;s diffusion operator.

4. After $O(\sqrt{n})$ iterations, Alice measures the final state in the computational basis. If she obtains a non-zero result, then there exists an $i$ such that $x_i = y_i = 1$, and their inner product is nonzero as an integer. If she obtains a zero result, then their inner product is zero.

Since Alice and Bob exchange $n$ qubits in each iteration, and they perform $O(\sqrt{n})$ iterations, the total number of qubits exchanged is $O(n\sqrt{n}) = O(\sqrt{n}\log n)$, as each qubit can represent $\log n$ bits of information. Thus, Alice and Bob can determine whether their inner product is zero or nonzero as an integer, with high probability, by exchanging only $O(\sqrt{n}\log n)$ qubits in total.
&lt;/mark&gt;
&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;SCOTT: LOOKS BASICALLY RIGHT, EXCEPT FOR A SLIP-UP AT THE END WHERE IT SAYS
ALICE AND BOB EXCHANGE n QUBITS PER ITERATION RATHER THAN log n ...

JUSTIN: Up to 6 extra credit points.
Yeah, step 3a says it&#39;s sending n qubits, when it&#39;s actually log n.
It also seems incorrect beginning in the analysis of step d. It switches from summing over |z&amp;gt; and referring to the full strings x and y to referring to individual indices i,x_i,y_i. And I don&#39;t know what it means about some amplitudes going to zero since what we&#39;re really doing is having some amplitudes be +1 and some -1.
I don&#39;t think this protocol is correct as stated.
But, it has some of the main ideas. The analysis of the grover steps is good and using a phase gate is good.

3/6 extra credit.&lt;/mark&gt;&lt;/pre&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;OK, last question, about the k-SUM problem.  Total score: &lt;strong&gt;6 / 15&lt;/strong&gt;.&lt;/p&gt;



&lt;pre class=&quot;wp-block-preformatted&quot;&gt;7. In the famous $k$-SUM problem, we&#39;re given a list of integers $x_1,\ldots,x_n$, and are asked whether there are $k$ distinct indices, $i_1 &amp;lt; \ldots &amp;lt; i_k$, such that $x_{i_1} + \ldots + x_{i_k} = 0$.

For this problem, you can ignore factors of $\log n$ in the running time (indeed, that is what the $\widetilde{O}$ notation means).

(a) Assume $k$ is even AND that we are allowed multi-sets (aka repeated elements are allowed). Describe a classical algorithm that solves the $k$-SUM problem in $\widetilde{O}(n^{k/2})$ time, beating the trivial upper bound of $\widetilde{O}(n^k)$.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;We can solve the k-SUM problem in $\widetilde{O}(n^{k/2})$ time using a meet-in-the-middle approach. Here&#39;s a high-level description of the algorithm:

1. Divide the list of integers into two equal halves: $A = x_1, \ldots, x_{n/2}$ and $B = x_{n/2+1}, \ldots, x_n$.

2. Compute all possible sums of $k/2$ elements from each half. For each half, this can be done in $O(n^{k/2})$ time by iterating through all possible combinations of $k/2$ elements.

3. Sort the lists of sums for both halves. This can be done in $O(n^{k/2} \log n)$ time using a comparison-based sorting algorithm.

4. For each sum in the first half, perform a binary search in the second half to find a sum that is equal to the negation of the sum from the first half. If such a sum is found, then we have found k distinct indices whose elements sum to 0. Binary search takes $O(\log n)$ time, so this step takes $O(n^{k/2} \log n)$ time.

Since we are ignoring factors of $\log n$, the overall running time of the algorithm is $\widetilde{O}(n^{k/2})$.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;SCOTT: LOOKS LIKE IT WOULD WORK *IF* WE KNEW THE k-SET WAS EQUALLY BALANCED
BETWEEN THE LEFT AND RIGHT HALVES...

JUSTIN: Up to 5 points.
Right, step 1 is incorrect. Instead, it should generate all O(n^{k/2}) sums of subsets of size k/2. Nothing about dividing into two halves.

4/5.
&lt;/mark&gt;
(b) Assume $k$ is divisible by 3 and that we are again allowed multi-sets.  Describe a quantum algorithm that solves the $k$-SUM problem in $\widetilde{O}(n^{k/3})$ time.

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;We can solve the k-SUM problem in $\widetilde{O}(n^{k/3})$ time using a quantum algorithm based on Grover&#39;s search. Here&#39;s a high-level description of the algorithm:

1. Divide the list of integers into three equal parts: $A = x_1, \ldots, x_{n/3}$, $B = x_{n/3+1}, \ldots, x_{2n/3}$, and $C = x_{2n/3+1}, \ldots, x_n$.

2. Compute all possible sums of $k/3$ elements from each part. For each part, this can be done in $O(n^{k/3})$ time by iterating through all possible combinations of $k/3$ elements.

3. Sort the lists of sums for all three parts. This can be done in $O(n^{k/3} \log n)$ time using a comparison-based sorting algorithm.

4. Define an oracle function $f$ that takes as input a sum from the first part and a sum from the second part, and returns 1 if there exists a sum in the third part that is equal to the negation of the sum of the inputs, and 0 otherwise. This oracle can be implemented using a binary search on the sorted list of sums for the third part, which takes $O(\log n)$ time.

5. Use Grover&#39;s search algorithm to find a pair of sums from the first and second parts that satisfy the oracle function. Grover&#39;s search has a quadratic speedup over classical search, so it takes $O(\sqrt{n^{k/3}}) = O(n^{k/6})$ time.

Since we are ignoring factors of $\log n$, the overall running time of the algorithm is $\widetilde{O}(n^{k/3})$.
&lt;/mark&gt;
&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: Up to 5 points.
Again, step 1 is incorrect, it shouldn&#39;t divide into three parts.
The division into three parts is more problematic this time as it comes up in step 4.
And it ends up claiming n^{k/6] time in step 5, better than the n^{k/3}.
Basically all this gets correct is to use Grover in some way.

1/5.
&lt;/mark&gt;
(c) Suppose we wanted to prove that the algorithm from (b) was the fastest possible quantum algorithm for $k$-SUM.  Could that be shown via a lower bound on $k$-SUM&#39;s quantum query complexity?  Why or why not?

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-cyan-blue-color&quot;&gt;Proving that the algorithm from (b) is the fastest possible quantum algorithm for k-SUM would require showing a lower bound on k-SUM&#39;s quantum query complexity that matches the upper bound achieved by the algorithm. However, a lower bound on the quantum query complexity alone might not be sufficient to prove the optimality of the algorithm, as it only considers the number of queries to the oracle function and does not account for other computational resources, such as time or space complexity.

To show that the algorithm from (b) is the fastest possible quantum algorithm for k-SUM, one would need to establish a lower bound on the quantum time complexity or some other relevant complexity measure that matches the upper bound achieved by the algorithm. This would provide a more comprehensive understanding of the problem&#39;s inherent difficulty and the limitations of quantum algorithms in solving it.&lt;/mark&gt;

&lt;mark style=&quot;background-color:rgba(0, 0, 0, 0)&quot; class=&quot;has-inline-color has-vivid-red-color&quot;&gt;JUSTIN: Up to 5 extra credit points.
This is a nice description of query vs time complexity, but misses the point that query complexity can prove a bound of at most Omega(n) since there are at most n potential queries to make.

1/5 extra credit points.&lt;/mark&gt;&lt;/pre&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 17:17:41 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>No-Existence Of Generalize Diffusion</title>
  <guid>http://arxiv.org/abs/2304.03960</guid>
  <link>http://arxiv.org/abs/2304.03960</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponarovsky_D/0/1/0/all/0/1&quot;&gt;David Ponarovsky&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that there is no operator that given two state
$|\psi\rangle,|\phi\rangle$ compute the transformation:
$D|\psi\rangle|\phi\rangle = |\psi\rangle\bigl( \mathbb{I} - 2
|\psi\rangle\langle\psi| \bigr)|\phi\rangle$ The contradiction of the existence
follows by showing that using $D$ two players can compute the disjoints of
their sets in single round and $O\left( \sqrt{n} \right)$ communication
complexity, which shown by Braverman to be impossible \cite{Braverman}.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The $n$-vehicle exploration problem is NP-complete</title>
  <guid>http://arxiv.org/abs/2304.03965</guid>
  <link>http://arxiv.org/abs/2304.03965</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1&quot;&gt;Jinchuan Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoya Li&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The $n$-vehicle exploration problem (NVEP) is a combinatorial optimization
problem, which tries to find an optimal permutation of a fleet to maximize the
length traveled by the last vehicle. NVEP has a fractional form of objective
function, and its computational complexity of general case remains open. We
show that Hamiltonian Path $\leq_P$ NVEP, and prove that NVEP is NP-complete.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm under Smoothness and Isoperimetry</title>
  <guid>http://arxiv.org/abs/2304.04095</guid>
  <link>http://arxiv.org/abs/2304.04095</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuansi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gatmiry_K/0/1/0/all/0/1&quot;&gt;Khashayar Gatmiry&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the mixing time of Metropolis-Adjusted Langevin algorithm (MALA) for
sampling a target density on $\mathbb{R}^d$. We assume that the target density
satisfies $\psi_\mu$-isoperimetry and that the operator norm and trace of its
Hessian are bounded by $L$ and $\Upsilon$ respectively. Our main result
establishes that, from a warm start, to achieve $\epsilon$-total variation
distance to the target density, MALA mixes in
$O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2}
\log\left(\frac{1}{\epsilon}\right)\right)$ iterations. Notably, this result
holds beyond the log-concave sampling setting and the mixing time depends on
only $\Upsilon$ rather than its upper bound $L d$. In the $m$-strongly
logconcave and $L$-log-smooth sampling setting, our bound recovers the previous
minimax mixing bound of MALA~\cite{wu2021minimax}.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>TDANetVis: Suggesting temporal resolutions for graph visualization using zigzag persistent homology</title>
  <guid>http://arxiv.org/abs/2304.03828</guid>
  <link>http://arxiv.org/abs/2304.03828</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tinarrage_R/0/1/0/all/0/1&quot;&gt;Rapha&amp;#xeb;l Tinarrage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponciano_J/0/1/0/all/0/1&quot;&gt;Jean R. Ponciano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Linhares_C/0/1/0/all/0/1&quot;&gt;Claudio D. G. Linhares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Traina_A/0/1/0/all/0/1&quot;&gt;Agma J. M. Traina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poco_J/0/1/0/all/0/1&quot;&gt;Jorge Poco&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Temporal graphs are commonly used to represent complex systems and track the
evolution of their constituents over time. Visualizing these graphs is crucial
as it allows one to quickly identify anomalies, trends, patterns, and other
properties leading to better decision-making. In this context, the
to-be-adopted temporal resolution is crucial in constructing and analyzing the
layout visually. The choice of a resolution is critical, e.g., when dealing
with temporally sparse graphs. In such cases, changing the temporal resolution
by grouping events (i.e., edges) from consecutive timestamps, a technique known
as timeslicing, can aid in the analysis and reveal patterns that might not be
discernible otherwise. However, choosing a suitable temporal resolution is not
trivial. In this paper, we propose TDANetVis, a methodology that suggests
temporal resolutions potentially relevant for analyzing a given graph, i.e.,
resolutions that lead to substantial topological changes in the graph
structure. To achieve this goal, TDANetVis leverages zigzag persistent
homology, a well-established technique from Topological Data Analysis (TDA). To
enhance visual graph analysis, TDANetVis also incorporates the colored barcode,
a novel timeline-based visualization built on the persistence barcodes commonly
used in TDA. We demonstrate the usefulness and effectiveness of TDANetVis
through a usage scenario and a user study involving 27 participants.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Improved estimates on the number of unit perimeter triangles</title>
  <guid>http://arxiv.org/abs/2304.03920</guid>
  <link>http://arxiv.org/abs/2304.03920</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Goenka_R/0/1/0/all/0/1&quot;&gt;Ritesh Goenka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Moore_K/0/1/0/all/0/1&quot;&gt;Kenneth Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+White_E/0/1/0/all/0/1&quot;&gt;Ethan Patrick White&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We obtain new upper and lower bounds on the number of unit perimeter
triangles spanned by points in the plane. We also establish improved bounds in
the special case where the point set is a section of the integer grid.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Convex Hulls: Surface Mapping onto a Sphere</title>
  <guid>http://arxiv.org/abs/2304.04079</guid>
  <link>http://arxiv.org/abs/2304.04079</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kenwright_B/0/1/0/all/0/1&quot;&gt;Ben Kenwright&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Writing an uncomplicated, robust, and scalable three-dimensional convex hull
algorithm is challenging and problematic. This includes, coplanar and collinear
issues, numerical accuracy, performance, and complexity trade-offs. While there
are a number of methods available for finding the convex hull based on
geometric calculations, such as, the distance between points, but do not
address the technical challenges when implementing a usable solution (e.g.,
numerical issues and degenerate cloud points). We explain some common algorithm
pitfalls and engineering modifications to overcome and solve these limitations.
We present a novel iterative method using support mapping and surface
projection to create an uncomplicated and robust 2d and 3d convex hull
algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>On Testability of First-Order Properties in Bounded-Degree Graphs and Connections to Proximity-Oblivious Testing</title>
  <guid>http://arxiv.org/abs/2304.03810</guid>
  <link>http://arxiv.org/abs/2304.03810</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adler_I/0/1/0/all/0/1&quot;&gt;Isolde Adler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohler_N/0/1/0/all/0/1&quot;&gt;Noleen K&amp;#xf6;hler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_P/0/1/0/all/0/1&quot;&gt;Pan Peng&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study property testing of properties that are definable in first-order
logic (FO) in the bounded-degree graph and relational structure models. We show
that any FO property that is defined by a formula with quantifier prefix
$\exists^*\forall^*$ is testable (i.e., testable with constant query
complexity), while there exists an FO property that is expressible by a formula
with quantifier prefix $\forall^*\exists^*$ that is not testable. In the dense
graph model, a similar picture is long known (Alon, Fischer, Krivelevich,
Szegedy, Combinatorica 2000), despite the very different nature of the two
models. In particular, we obtain our lower bound by an FO formula that defines
a class of bounded-degree expanders, based on zig-zag products of graphs. We
expect this to be of independent interest.
&lt;/p&gt;
&lt;p&gt;We then use our class of FO definable bounded-degree expanders to answer a
long-standing open problem for proximity-oblivious testers (POTs). POTs are a
class of particularly simple testing algorithms, where a basic test is
performed a number of times that may depend on the proximity parameter, but the
basic test itself is independent of the proximity parameter. In their seminal
work, Goldreich and Ron [STOC 2009; SICOMP 2011] show that the graph properties
that are constant-query proximity-oblivious testable in the bounded-degree
model are precisely the properties that can be expressed as a generalised
subgraph freeness (GSF) property that satisfies the non-propagation condition.
It is left open whether the non-propagation condition is necessary. We give a
negative answer by showing that our property is a GSF property which is
propagating. Hence in particular, our property does not admit a POT. For this
result we establish a new connection between FO properties and GSF-local
properties via neighbourhood profiles.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Improving Identity-Robustness for Face Models</title>
  <guid>http://arxiv.org/abs/2304.03838</guid>
  <link>http://arxiv.org/abs/2304.03838</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1&quot;&gt;Qi Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ardeshir_S/0/1/0/all/0/1&quot;&gt;Shervin Ardeshir&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Despite the success of deep-learning models in many tasks, there have been
concerns about such models learning shortcuts, and their lack of robustness to
irrelevant confounders. When it comes to models directly trained on human
faces, a sensitive confounder is that of human identities. Many face-related
tasks should ideally be identity-independent, and perform uniformly across
different individuals (i.e. be fair). One way to measure and enforce such
robustness and performance uniformity is through enforcing it during training,
assuming identity-related information is available at scale. However, due to
privacy concerns and also the cost of collecting such information, this is
often not the case, and most face datasets simply contain input images and
their corresponding task-related labels. Thus, improving identity-related
robustness without the need for such annotations is of great importance. Here,
we explore using face-recognition embedding vectors, as proxies for identities,
to enforce such robustness. We propose to use the structure in the
face-recognition embedding space, to implicitly emphasize rare samples within
each class. We do so by weighting samples according to their conditional
inverse density (CID) in the proxy embedding space. Our experiments suggest
that such a simple sample weighting scheme, not only improves the training
robustness, it often improves the overall performance as a result of such
robustness. We also show that employing such constraints during training
results in models that are significantly less sensitive to different levels of
bias in the dataset.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On Rotation Distance of Rank Bounded Trees</title>
  <guid>http://arxiv.org/abs/2304.03985</guid>
  <link>http://arxiv.org/abs/2304.03985</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+M%2E_A/0/1/0/all/0/1&quot;&gt;Anoop S. K. M.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarma_J/0/1/0/all/0/1&quot;&gt;Jayalal Sarma&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Computing the rotation distance between two binary trees with $n$ internal
nodes efficiently (in $poly(n)$ time) is a long standing open question in the
study of height balancing in tree data structures. In this paper, we initiate
the study of this problem bounding the rank of the trees given at the input
(defined by Ehrenfeucht and Haussler (1989) in the context of decision trees).
We define the rank-bounded rotation distance between two given binary trees
$T_1$ and $T_2$ (with $n$ internal nodes) of rank at most $r$, denoted by
$d_r(T_1,T_2)$, as the length of the shortest sequence of rotations that
transforms $T_1$ to $T_2$ with the restriction that the intermediate trees must
be of rank at most $r$. We show that the rotation distance problem reduces in
polynomial time to the rank bounded rotation distance problem. This motivates
the study of the problem in the combinatorial and algorithmic frontiers.
Observing that trees with rank $1$ coincide exactly with skew trees (binary
trees where every internal node has at least one leaf as a child), we show the
following results in this frontier :
&lt;/p&gt;
&lt;p&gt;We present an $O(n^2)$ time algorithm for computing $d_1(T_1,T_2)$. That is,
when the given trees are skew trees (we call this variant as skew rotation
distance problem) - where the intermediate trees are restricted to be skew as
well. In particular, our techniques imply that for any two skew trees
$d(T_1,T_2) \le n^2$.
&lt;/p&gt;
&lt;p&gt;We show the following upper bound : for any two trees $T_1$ and $T_2$ of rank
at most $r_1$ and $r_2$ respectively, we have that: $d_r(T_1,T_2) \le n^2
(1+(2n+1)(r_1+r_2-2))$ where $r = max\{r_1,r_2\}$. This bound is asymptotically
tight for $r=1$.
&lt;/p&gt;
&lt;p&gt;En route our proof of the above theorems, we associate binary trees to
permutations and bivariate polynomials, and prove several characterizations in
the case of skew trees.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Prophet Inequalities: Separating Random Order from Order Selection</title>
  <guid>http://arxiv.org/abs/2304.04024</guid>
  <link>http://arxiv.org/abs/2304.04024</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giambartolomei_G/0/1/0/all/0/1&quot;&gt;Giordano Giambartolomei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mallmann_Trenn_F/0/1/0/all/0/1&quot;&gt;Frederik Mallmann-Trenn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saona_R/0/1/0/all/0/1&quot;&gt;Raimundo Saona&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Prophet inequalities are a central object of study in optimal stopping
theory. A gambler is sent values online, sampled from an instance of
independent distributions, in an adversarial, random or selected order,
depending on the model. When observing each value, the gambler either accepts
it as a reward or irrevocably rejects it and proceeds to observe the next
value. The goal of the gambler, who cannot see the future, is maximising the
expected value of the reward while competing against the expectation of a
prophet (the offline maximum). In other words, one seeks to maximise the
gambler-to-prophet ratio of the expectations.
&lt;/p&gt;
&lt;p&gt;The model, in which the gambler selects the arrival order first, and then
observes the values, is known as Order Selection. Recently it has been shown
that in this model a ratio of $0.7251$ can be attained for any instance. If the
gambler chooses the arrival order (uniformly) at random, we obtain the Random
Order model. The worst case ratio over all possible instances has been
extensively studied for at least $40$ years. Still, it is not known if
carefully choosing the order, or simply taking it at random, benefits the
gambler. We prove that, in the Random Order model, no algorithm can achieve a
ratio larger than $0.7235$, thus showing for the first time that there is a
real benefit in choosing the order.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A simple and efficient preprocessing step for convex hull problem</title>
  <guid>http://arxiv.org/abs/2304.04196</guid>
  <link>http://arxiv.org/abs/2304.04196</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heydari_M/0/1/0/all/0/1&quot;&gt;Mohammad Heydari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifeh_A/0/1/0/all/0/1&quot;&gt;Ashkan Khalifeh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The present paper is concerned with a recursive algorithm as a preprocessing
step to find the convex hull of $n$ random points uniformly distributed in the
plane. For such a set of points, it is shown that eliminating all but $O(\log
n)$ of points can derive the same convex hull as the input set. Finally it will
be shown that the running time of the algorithm is $O(n)
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On Extend-Only Directed Posets and Derived Byzantine-Tolerant Replicated Data Types (Extended Version)</title>
  <guid>http://arxiv.org/abs/2304.04318</guid>
  <link>http://arxiv.org/abs/2304.04318</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacob_F/0/1/0/all/0/1&quot;&gt;Florian Jacob&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hartenstein_H/0/1/0/all/0/1&quot;&gt;Hannes Hartenstein&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We uncover the extend-only directed posets (EDP) structure as a unification
of recently discussed DAG-based Byzantine-tolerant conflict-free replicated
data types (CRDT). We also show how a key-value map model can be derived from
the EDP formulation, and give an outlook on an EDP-based systemic access
control CRDT as a formalization of the CRDT used in the Matrix messaging
system.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Randomized and Deterministic Attention Sparsification Algorithms for Over-parameterized Feature Dimension</title>
  <guid>http://arxiv.org/abs/2304.04397</guid>
  <link>http://arxiv.org/abs/2304.04397</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yichuan Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahadevan_S/0/1/0/all/0/1&quot;&gt;Sridhar Mahadevan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Large language models (LLMs) have shown their power in different areas.
Attention computation, as an important subroutine of LLMs, has also attracted
interests in theory. Recently the static computation and dynamic maintenance of
attention matrix has been studied by [Alman and Song 2023] and [Brand, Song and
Zhou 2023] from both algorithmic perspective and hardness perspective. In this
work, we consider the sparsification of the attention problem. We make one
simplification which is the logit matrix is symmetric. Let $n$ denote the
length of sentence, let $d$ denote the embedding dimension. Given a matrix $X
\in \mathbb{R}^{n \times d}$, suppose $d \gg n$ and $\| X X^\top \|_{\infty} &amp;lt;
r$ with $r \in (0,0.1)$, then we aim for finding $Y \in \mathbb{R}^{n \times
m}$ (where $m\ll d$) such that \begin{align*} \| D(Y)^{-1} \exp( Y Y^\top ) -
D(X)^{-1} \exp( X X^\top) \|_{\infty} \leq O(r) \end{align*} We provide two
results for this problem.
&lt;/p&gt;
&lt;p&gt;$\bullet$ Our first result is a randomized algorithm. It runs in
$\widetilde{O}(\mathrm{nnz}(X) + n^{\omega} ) $ time, has $1-\delta$ succeed
probability, and chooses $m = O(n \log(n/\delta))$. Here $\mathrm{nnz}(X)$
denotes the number of non-zero entries in $X$. We use $\omega$ to denote the
exponent of matrix multiplication. Currently $\omega \approx 2.373$.
&lt;/p&gt;
&lt;p&gt;$\bullet$ Our second result is a deterministic algorithm. It runs in
$\widetilde{O}(\min\{\sum_{i\in[d]}\mathrm{nnz}(X_i)^2, dn^{\omega-1}\} +
n^{\omega+1})$ time and chooses $m = O(n)$. Here $X_i$ denote the $i$-th column
of matrix $X$.
&lt;/p&gt;
&lt;p&gt;Our main findings have the following implication for applied LLMs task: for
any super large feature dimension, we can reduce it down to the size nearly
linear in length of sentence.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-11 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Complexity and Explainable AI</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-8698511952609437812</guid>
  <link>https://blog.computationalcomplexity.org/2023/04/complexity-and-generative-ai.html</link>
  <description>
    &lt;p&gt;About six years ago, I &lt;a href=&quot;https://blog.computationalcomplexity.org/2017/04/understanding-machine-learning.html&quot;&gt;posted&lt;/a&gt;&amp;nbsp;on why it was important to understand machine learning, mentioning trust, fairness, security and causality. But I then I brought in complexity.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;What if P = NP? Would that help. Actually it would makes things worse. If you had a quick algorithm for NP-complete problems, you could use it to find the smallest possible circuit for say matching or traveling salesman but you would have no clue why that circuit works.&amp;nbsp;&lt;/blockquote&gt;&lt;p&gt;Ryan Williams &lt;a href=&quot;https://blog.computationalcomplexity.org/2017/04/understanding-machine-learning.html?showComment=1492464695392#c7595821335622802218&quot;&gt;countered&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;If P=NP you could also find the shortest proof in your favorite formal system that the smallest possible circuit does what you wanted it to do, as well as any other claim you are wondering that may be true about the circuit. That proof might not be comprehensible to you, but it could be written in a format where proof assistant software such as HOL or Coq could parse it and convince you it is correct. So if P=NP (with feasible low constants) I think that would definitely help.&lt;/blockquote&gt;&lt;p&gt;So if P = NP maybe you couldn&#39;t understand how the circuit works but any question about how it works you could answer.&amp;nbsp;&lt;/p&gt;&lt;p&gt;While we don&#39;t live in a world where P = NP, we are in a world where we can produce very strong learning algorithms where we can&#39;t understand the programs they produce. They are now powerful enough to apply Ryan&#39;s idea and use the algorithms themselves to understand the decisions they make.&lt;/p&gt;&lt;p&gt;For example I tried using Google Translate on a &lt;a href=&quot;https://mta.hu/mta_hirei/elhunyt-t-sos-vera-matematikus-az-mta-rendes-tagja-112809&quot;&gt;Hungarian obituary&lt;/a&gt; of Vera&amp;nbsp;Sós. Hungarian does not use gendered pronouns and and the translation incorrectly produced male pronouns. I then fed the translation into ChatGPT which translated with the correct female pronouns.&amp;nbsp;&lt;/p&gt;&lt;p&gt;You can speculate why Google Translate uses male pronouns but you can&#39;t ask it why. But you can ask ChatGPT.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;I used female pronouns in the translation because Vera T. Sós is a female name. Vera is a feminine given name, and since the context of the original text is about her life and accomplishments, it is appropriate to use female pronouns in the English translation to maintain clarity and accurately convey information about her.&lt;/blockquote&gt;&lt;p&gt;So perhaps if you want to understand how ML works, perhaps we should seek stronger algorithms, not weaker ones, algorithms that can explain themselves. As &lt;a href=&quot;https://knivesengraved.com/blogs/news/why-sharp-knives-are-safer-than-dull-knives&quot;&gt;they say&lt;/a&gt;, a dull knife is more dangerous than a sharp one.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2023-04-10 17:37:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>Quantum delegation with an off-the-shelf device</title>
  <guid>http://arxiv.org/abs/2304.03448</guid>
  <link>http://arxiv.org/abs/2304.03448</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Broadbent_A/0/1/0/all/0/1&quot;&gt;Anne Broadbent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Mehta_A/0/1/0/all/0/1&quot;&gt;Arthur Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yuming Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given that reliable cloud quantum computers are becoming closer to reality,
the concept of delegation of quantum computations and its verifiability is of
central interest. Many models have been proposed, each with specific strengths
and weaknesses. Here, we put forth a new model where the client trusts only its
classical processing, makes no computational assumptions, and interacts with a
quantum server in a single round. In addition, during a set-up phase, the
client specifies the size $n$ of the computation and receives an untrusted,
off-the-shelf (OTS) quantum device that is used to report the outcome of a
single constant-sized measurement from a predetermined logarithmic-sized input.
In the OTS model, we thus picture that a single quantum server does the bulk of
the computations, while the OTS device is used as an untrusted and generic
verification device, all in a single round.
&lt;/p&gt;
&lt;p&gt;We show how to delegate polynomial-time quantum computations in the OTS
model. Scaling up the technique also yields an interactive proof system for all
of QMA, which, furthermore, we show can be accomplished in statistical
zero-knowledge. This yields the first relativistic (one-round), two-prover
zero-knowledge proof system for QMA.
&lt;/p&gt;
&lt;p&gt;As a proof approach, we provide a new self-test for $n$-EPR pairs using only
constant-sized Pauli measurements, and show how it provides a new avenue for
the use of simulatable codes for local Hamiltonian verification. Along the way,
we also provide an enhanced version of a well-known stability result due to
Gowers and Hatami and show how it completes a common argument used in
self-testing.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-10 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Maximal Distortion of Geodesic Diameters in Polygonal Domains</title>
  <guid>http://arxiv.org/abs/2304.03484</guid>
  <link>http://arxiv.org/abs/2304.03484</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumitrescu_A/0/1/0/all/0/1&quot;&gt;Adrian Dumitrescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toth_C/0/1/0/all/0/1&quot;&gt;Csaba D. T&amp;#xf3;th&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For a polygon $P$ with holes in the plane, we denote by $\varrho(P)$ the
ratio between the geodesic and the Euclidean diameters of $P$. It is shown that
over all convex polygons with $h$~convex holes, the supremum of $\varrho(P)$ is
between $\Omega(h^{1/3})$ and $O(h^{1/2})$. The upper bound improves to
$O(1+\min\{h^{3/4}\Delta,h^{1/2}\Delta^{1/2}\})$ if every hole has diameter at
most $\Delta\cdot {\rm diam}_2(P)$; and to $O(1)$ if every hole is a \emph{fat}
convex polygon. Furthermore, we show that the function $g(h)=\sup_P \varrho(P)$
over convex polygons with $h$ convex holes has the same growth rate as an
analogous quantity over geometric triangulations with $h$ vertices when
$h\rightarrow \infty$.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-10 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Leveraging Reusability: Improved Competitive Ratio of Greedy for Reusable Resources</title>
  <guid>http://arxiv.org/abs/2304.03377</guid>
  <link>http://arxiv.org/abs/2304.03377</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1&quot;&gt;Jackie Baek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shixin Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study online weighted bipartite matching of reusable resources where an
adversarial sequence of requests for resources arrive over time. A resource
that is matched is &#39;used&#39; for a random duration, drawn independently from a
resource-dependent distribution, after which it returns and is able to be
matched again. We study the performance of the greedy policy, which matches
requests to the resource that yields the highest reward. Previously, it was
known that the greedy policy is 1/2 competitive against a clairvoyant benchmark
that knows the request sequence in advance. In this work, we improve this
result by introducing a parameter that quantifies the degree of reusability of
the resources. Specifically, if p represents the smallest probability over the
usage distributions that a matched resource returns in one time step, the
greedy policy achieves a competitive ratio of $1/(2-p)$. Furthermore, when the
usage distributions are geometric, we establish a stronger competitive ratio of
$(1+p)/2$, which we demonstrate to be tight. Both of these results align with
the known results in the two extreme scenarios: p = 0 corresponds to
non-reusable resources, where 1/2 is known to be tight, while p = 1 corresponds
to every resource returning immediately, where greedy is the optimal policy and
hence the competitive ratio is 1. Finally, we show that both results are robust
to approximations of the greedy policy. Our work demonstrates that the
reusability of resources can enhance performance compared to the non-reusable
setting, and that a simple greedy policy suffices when the degree of
reusability is high. Our insights contribute to the understanding of how
resource reusability can influence the performance of online algorithms, and
highlight the potential for improved performance as the degree of reusability
increases.
&lt;/p&gt;
  </description>
  <pubDate>2023-04-10 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

</channel>
</rss>
