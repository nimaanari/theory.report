<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>My AI Safety Lecture for UT Effective Altruism</title>
  <guid>https://scottaaronson.blog/?p=6823</guid>
  <link>https://scottaaronson.blog/?p=6823</link>
  <description>
    &lt;p&gt;Two weeks ago, I gave a lecture setting out my current thoughts on AI safety, halfway through my year at OpenAI.  I was asked to speak by UT Austin&amp;#8217;s Effective Altruist club.  You can &lt;a href=&quot;https://www.youtube.com/watch?v=fc-cHk9yFpg&quot;&gt;watch the lecture on YouTube here&lt;/a&gt; (I recommend 2x speed).&lt;/p&gt;



&lt;p&gt;The timing turned out to be weird, coming immediately after the worst disaster to hit the Effective Altruist movement in its history, as I acknowledged in the talk.  But I plowed ahead anyway, to discuss:&lt;/p&gt;



&lt;ol&gt;
&lt;li&gt;the current state of AI scaling, and why many people (even people who agree about little else!) foresee societal dangers,&lt;/li&gt;



&lt;li&gt;the different branches of the AI safety movement,&lt;/li&gt;



&lt;li&gt;the major approaches to aligning a powerful AI that people have thought of, and&lt;/li&gt;



&lt;li&gt;what projects I specifically have been working on at OpenAI. &lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;I then spent 20 minutes taking questions.&lt;/p&gt;



&lt;p&gt;For those who (like me) prefer text over video, below I&amp;#8217;ve produced an edited transcript, by starting with YouTube&amp;#8217;s automated transcript and then, well, editing it.  Enjoy!  &amp;#8211;SA&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;Thank you so much for inviting me here.  I do feel a little bit sheepish to be lecturing you about AI safety, as someone who&amp;#8217;s worked on this subject for all of five months.  I&amp;#8217;m a quantum computing person.  But this past spring, I accepted an extremely interesting opportunity to go on leave for a year to think about what theoretical computer science can do for AI safety.  I&amp;#8217;m doing this at &lt;a href=&quot;https://openai.com/&quot;&gt;OpenAI&lt;/a&gt;, which is one of the world&amp;#8217;s leading AI startups, based in San Francisco although I&amp;#8217;m mostly working from Austin.&lt;/p&gt;



&lt;p&gt;Despite its name, OpenAI is famously &lt;em&gt;not&lt;/em&gt; 100% open &amp;#8230; so there are certain topics that I&amp;#8217;m not allowed to talk about, like the capabilities of the very latest systems and whether or not they&amp;#8217;ll blow people&amp;#8217;s minds when released.  By contrast, OpenAI is very happy for me to talk about &lt;em&gt;AI safety&lt;/em&gt;: what it is and and what if anything can we do about it.  So what I thought I&amp;#8217;d do is to tell you a little bit about the specific projects that I&amp;#8217;ve been working on at OpenAI, but also just, as an admitted newcomer, share some general thoughts about AI safety and how Effective Altruists might want to think about it.  I&amp;#8217;ll try to leave plenty of time for discussion.&lt;/p&gt;



&lt;p&gt;Maybe I should mention that the thoughts that I&amp;#8217;ll tell you today are ones that, until last week, I had considered writing up for an essay contest run by something called the FTX Future Fund.  Unfortunately, the FTX Future Fund no longer exists.  It was founded by someone named Sam Bankman-Fried, whose a net worth went from 15 billion dollars to some negative number of dollars in the space of two days, in one of the biggest financial scandals in memory.  This is obviously a calamity for the EA community, which had been counting on funding from this individual.  I feel terrible about all the projects left in the lurch.&lt;/p&gt;



&lt;p&gt;As a tiny silver lining, though, instead of writing up my thoughts for that essay contest, I&amp;#8217;ll just share them with you right now, for free!&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;h2&gt;&lt;strong&gt;The Scaling of AI&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Let&amp;#8217;s start with this: raise your hand if you&amp;#8217;ve tried &lt;a href=&quot;https://www.newyorker.com/culture/culture-desk/the-new-poem-making-machinery&quot;&gt;GPT-3&lt;/a&gt;.  That&amp;#8217;s maybe half of you.  OK, raise your hand if you&amp;#8217;ve tried &lt;a href=&quot;https://en.wikipedia.org/wiki/DALL-E&quot;&gt;DALL-E&lt;/a&gt;.  That&amp;#8217;s again maybe half of you.&lt;/p&gt;



&lt;p&gt;These are the two best-known products that are made by OpenAI, and as I think most people would agree, two of the most impressive AIs that exist in the world right now.  They certainly go far beyond what &lt;em&gt;I&lt;/em&gt; would&amp;#8217;ve predicted would be possible now, if you&amp;#8217;d asked me 10 years ago or even 5 years ago.&lt;/p&gt;



&lt;p&gt;And whenever I try to explain them to people, I&amp;#8217;m, like, well, you have to &lt;em&gt;see&lt;/em&gt; them.  No abstract description can substitute in this case.&lt;/p&gt;



&lt;p&gt;All right, so here&amp;#8217;s what GPT-3 produced when a &lt;em&gt;New Yorker&lt;/em&gt; writer asked it to write a poem about cryptocurrency in the style of Philip Larkin, who was a famous 20th-century poet.  The subject seems particularly appropriate given current events.&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;&lt;strong&gt;The Invention&amp;nbsp; (by GPT-3)&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Money is a thing you earn by the sweat of your brow&lt;br&gt;And that’s how it should be.&lt;br&gt;Or you can steal it, and go to jail;&lt;br&gt;Or inherit it, and be set for life;&lt;br&gt;Or win it on the pools, which is luck;&lt;br&gt;Or marry it, which is what I did.&lt;br&gt;And that is how it should be, too.&lt;br&gt;But now this idea’s come up&lt;br&gt;Of inventing money, just like that.&lt;br&gt;I ask you, is nothing sacred?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;Okay, it won&amp;#8217;t always produce something of this quality (incidentally, I don&amp;#8217;t think GPT-3 actually &amp;#8220;married money&amp;#8221;!).  Often you&amp;#8217;ve got to run it several times and take the best output&amp;#8212;much like human poets presumably do, throwing crumpled pages into the basket.  But I submit that, if the above hadn&amp;#8217;t been labeled as coming from GPT, you&amp;#8217;d be like, yeah, that&amp;#8217;s the kind of poetry the &lt;em&gt;New Yorker&lt;/em&gt; publishes, right?  This is a thing that AI can now do.&lt;/p&gt;



&lt;p&gt;So what &lt;em&gt;is&lt;/em&gt; GPT?  It&amp;#8217;s a text model.  It&amp;#8217;s basically a gigantic neural network with about 175 billion parameters&amp;#8212;the weights.  It&amp;#8217;s a particular kind of neural net called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)&quot;&gt;transformer model&lt;/a&gt; that was invented five years ago.  It&amp;#8217;s been trained on a large fraction of all the text on the open Internet.  The training simply consists of playing the following game over and over, trillions of times: &lt;em&gt;predict which word comes next in this text string.&lt;/em&gt;  So in some sense that&amp;#8217;s its only goal or intention in the world: to predict the next word.&lt;/p&gt;



&lt;p&gt;The amazing discovery is that, when you do that, you end up with something where you can then ask it a question, or give it a a task like writing an essay about a certain topic, and it will say &amp;#8220;oh! I know what would plausibly come after that prompt!  The answer to the question!  Or the essay itself!&amp;#8221;  And it will then proceed to generate the thing you want.&lt;/p&gt;



&lt;p&gt;GPT can solve high-school-level math problems that are given to it in English.  It can reason you through the steps of the answer.  It&amp;#8217;s starting to be able to do nontrivial math competition problems.  It&amp;#8217;s on track to master basically the whole high school curriculum, maybe followed soon by the whole undergraduate curriculum.&lt;/p&gt;



&lt;p&gt;If you turned in GPT&amp;#8217;s essays, I &lt;em&gt;think&lt;/em&gt; they&amp;#8217;d get at least a B in most courses.  Not that I endorse any of you doing that!!  We&amp;#8217;ll come back to that later.  But yes, we &lt;em&gt;are&lt;/em&gt; about to enter a world where students everywhere will at least be sorely tempted to use text models to write their term papers.  That&amp;#8217;s just a tiny example of the societal issues that these things are going to raise.&lt;/p&gt;



&lt;p&gt;Speaking personally, the last time I had a similar feeling was when I was an adolescent in 1993 and I saw this niche new thing called the World Wide Web, and I was like &amp;#8220;why isn&amp;#8217;t &lt;em&gt;everyone&lt;/em&gt; using this?  why isn&amp;#8217;t it changing the world?&amp;#8221;  The answer, of course, was that within a couple years it would.&lt;/p&gt;



&lt;p&gt;Today, I feel like the world was understandably preoccupied by the pandemic, and by everything else that&amp;#8217;s been happening, but these past few years might actually be remembered as the time when AI underwent this step change.  I didn&amp;#8217;t predict it.  I think even many computer scientists might still be in denial about what&amp;#8217;s now possible, or what&amp;#8217;s happened.  But I&amp;#8217;m now thinking about it even in terms of my two kids, of what kinds of careers are going to be available when they&amp;#8217;re older and entering the job market.  For example, I would probably &lt;em&gt;not&lt;/em&gt; urge my kids to go into commercial drawing!&lt;/p&gt;



&lt;p&gt;Speaking of which, OpenAI&amp;#8217;s &lt;em&gt;other&lt;/em&gt; main product is DALL-E2, an image model.  Probably most of you have already seen it, but you can ask it&amp;#8212;for example, just this morning I asked it, show me some digital art of two cats playing basketball in outer space.  That&amp;#8217;s not a problem for it.&lt;/p&gt;


&lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-large&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://www.scottaaronson.com/twocats.jpg&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;You may have seen that there&amp;#8217;s a different image model called Midjourney which won an art contest with this piece:&lt;/p&gt;


&lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-large&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://www.scottaaronson.com/midjourney.jpg&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;It seems like the judges didn&amp;#8217;t completely understand, when this was submitted as &amp;#8220;digital art,&amp;#8221; what exactly that meant&amp;#8212;that the human role was mostly limited to entering a prompt!  But the judges then said that even having understood it, they still would&amp;#8217;ve given the award to this piece.  I mean, it&amp;#8217;s a striking piece, isn&amp;#8217;t it?  But of course it raises the question of how much work there&amp;#8217;s going to be for contract artists, when you have entities like this.&lt;/p&gt;



&lt;p&gt;There are already companies that are using GPT to write ad copy.  It&amp;#8217;s already being used at the, let&amp;#8217;s call it, lower end of the book market.  For any kind of formulaic genre fiction, you can say, &amp;#8220;just give me a few paragraphs of description of this kind of scene,&amp;#8221; and it can do that.  As it improves you could you can imagine that it will be used more.&lt;/p&gt;



&lt;p&gt;Likewise, DALL-E and other image models have already changed the way that people generate art online.  And it&amp;#8217;s only been a few months since these models were released!  That&amp;#8217;s a striking thing about this era, that a few months can be an eternity.  So when we&amp;#8217;re thinking about the impacts of these things, we have to try to take what&amp;#8217;s happened in the last few months or years and project that five years forward or ten years forward.&lt;/p&gt;



&lt;p&gt;This brings me to the obvious question: what happens as you continue scaling further?  I mean, these spectacular successes of deep learning over the past decade have owed &lt;em&gt;something&lt;/em&gt; to new ideas&amp;#8212;ideas like transformer models, which I mentioned before, and others&amp;#8212;but famously, they have owed maybe more than anything else to sheer scale.&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Neural_network&quot;&gt;Neural networks&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Backpropagation&quot;&gt;backpropagation&lt;/a&gt;&amp;#8212;which is how you train the neural networks&amp;#8212;these are ideas that have been around for decades.  When I studied CS in the 90s, they were already extremely well-known.  But it was &lt;em&gt;also&lt;/em&gt; well-known that they didn&amp;#8217;t work all that well!  They only worked somewhat.  And usually, when you take something that doesn&amp;#8217;t work and multiply it by a million, you just get a million times something that doesn&amp;#8217;t work, right?&lt;/p&gt;



&lt;p&gt;I remember at the time, &lt;a href=&quot;https://en.wikipedia.org/wiki/Ray_Kurzweil&quot;&gt;Ray Kurzweil&lt;/a&gt;, the futurist, would keep showing these graphs that look like this: &lt;/p&gt;


&lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-large&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://www.scottaaronson.com/mooreslaw.jpg&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;So, he would plot &lt;a href=&quot;https://en.wikipedia.org/wiki/Moore%27s_law&quot;&gt;Moore&amp;#8217;s Law&lt;/a&gt;, the increase in transistor density, or in this case the number of floating-point operations that you can do per second for a given cost.  And he&amp;#8217;d point out that it&amp;#8217;s on this clear exponential trajectory.&lt;/p&gt;



&lt;p&gt;And he&amp;#8217;d then try to compare that to some crude estimates of the number of computational operations that are done in the brain of a mosquito or a mouse or a human or all the humans on Earth.  And oh!  We see that in a matter of a couple decades, like by the year 2020 or 2025 or so, we&amp;#8217;re going to start passing the human brain&amp;#8217;s computing power and then we&amp;#8217;re going to keep going beyond that.  And so, Kurzweil would continue, we should assume that scale will just kind of magically make AI work.  You know, that once you have enough computing cycles, you just sprinkle them around like pixie dust, and suddenly human-level intelligence will just emerge out of the billions of connections.&lt;/p&gt;



&lt;p&gt;I remember thinking: &lt;em&gt;that sounds like the stupidest thesis I&amp;#8217;ve ever heard.&lt;/em&gt;  Right?  Like, he has absolutely no reason to believe such a thing is true or have any confidence in it.  Who the hell knows what will happen?  We might be missing crucial insights that are needed to make AI work.&lt;/p&gt;



&lt;p&gt;Well, here we are, and it turns out he was way more right than most of us expected.&lt;/p&gt;



&lt;p&gt;As you all know, a central virtue of Effective Altruists is updating based on evidence.  I think that we&amp;#8217;re forced to do that in this case.&lt;/p&gt;



&lt;p&gt;To be sure, it&amp;#8217;s still unclear how much further you&amp;#8217;ll get just from pure scaling.  That remains a central open question.  And there are still prominent skeptics.&lt;/p&gt;



&lt;p&gt;Some skeptics take the position that this is &lt;em&gt;clearly&lt;/em&gt; going to hit some kind of wall before it gets to true human-level understanding of the real world.  They say that text models like GPT are really just &lt;a href=&quot;https://s10251.pcdn.co/pdf/2021-bender-parrots.pdf&quot;&gt;&amp;#8220;stochastic parrots&amp;#8221;&lt;/a&gt; that regurgitate their training data.  That despite creating a remarkable illusion otherwise, they don&amp;#8217;t &lt;em&gt;really&lt;/em&gt; have any original thoughts.&lt;/p&gt;



&lt;p&gt;The proponents of that view sometimes like to gleefully point out examples where GPT will flub some commonsense question.  If you look for such examples, you can certainly find them!  One of my favorites recently was, &amp;#8220;which would win in a race, a four-legged zebra or a two-legged cheetah?&amp;#8221;  GPT-3, it turns out, is very confident that the cheetah will win.  Cheetahs are faster, right?&lt;/p&gt;



&lt;p&gt;Okay, but one thing that&amp;#8217;s been found empirically is that you take commonsense questions that are flubbed by GPT-2, let&amp;#8217;s say, and you try them on GPT-3, and very often now it gets them right.  You take the things that the original GPT-3 flopped, and you try them on the latest public model, which is sometimes called GPT-3.5 (incorporating an advance called InstructGPT), and again it often gets them right.  So it&amp;#8217;s &lt;em&gt;extremely&lt;/em&gt; risky right now to pin your case against AI on these sorts of examples!  Very plausibly, just one more order of magnitude of scale is all it&amp;#8217;ll take to kick the ball in, and then you&amp;#8217;ll have to move the goal again.&lt;/p&gt;



&lt;p&gt;A deeper objection is that the &lt;em&gt;amount of training data&lt;/em&gt; might be a fundamental bottleneck for these kinds of machine learning systems&amp;#8212;and we&amp;#8217;re already running out of Internet to to train these models on!  Like I said, they&amp;#8217;ve already used most of the public text on the Internet.  There&amp;#8217;s still all of YouTube and TikTok and Instagram that hasn&amp;#8217;t yet been fed into the maw, but it&amp;#8217;s not clear that that would actually make an AI smarter rather than dumber!  So, you can look for more, but it&amp;#8217;s not clear that there are orders of magnitude more that humanity has even produced and that&amp;#8217;s readily accessible.&lt;/p&gt;



&lt;p&gt;On the other hand, it&amp;#8217;s also been found empirically that very often, you can do better with the same training data just by spending more compute.  You can squeeze the lemon harder and get more and more generalization power from the same training data by doing more gradient descent.&lt;/p&gt;



&lt;p&gt;In summary, we don&amp;#8217;t know how far this is going to go.  But it&amp;#8217;s &lt;em&gt;already&lt;/em&gt; able to automate various human professions that you might not have predicted would have been automatable by now, and we shouldn&amp;#8217;t be confident that many more professions will not become automatable by these kinds of techniques.&lt;/p&gt;



&lt;p&gt;Incidentally, there&amp;#8217;s a famous irony here.  If you had asked anyone in the 60s or 70s, they would have said, well clearly first robots will replace humans for manual labor, and &lt;em&gt;then&lt;/em&gt; they&amp;#8217;ll replace humans for intellectual things like math and science, and &lt;em&gt;finally&lt;/em&gt; they might reach the pinnacles of human creativity like art and poetry and music.&lt;/p&gt;



&lt;p&gt;The truth has turned out to be the exact opposite.  I don&amp;#8217;t think anyone predicted that.&lt;/p&gt;



&lt;p&gt;GPT, I think, is already a pretty good poet.  DALL-E is already a pretty good artist.  They&amp;#8217;re still struggling with some high school and college-level math but they&amp;#8217;re getting there.  It&amp;#8217;s easy to imagine that maybe in five years, people like me will be using these things as research assistants&amp;#8212;at the very least, to prove the lemmas in our papers.  That seems &lt;em&gt;extremely&lt;/em&gt; plausible.&lt;/p&gt;



&lt;p&gt;What&amp;#8217;s been by far the hardest is to get AI that can robustly interact with the physical world.  Plumbers, electricians&amp;#8212;these might be some of the &lt;em&gt;last&lt;/em&gt; jobs to be automated.  And famously, self-driving cars have taken a lot longer than many people expected a decade ago.  This is partly because of regulatory barriers and public relations: even if a self-driving car actually crashes &lt;em&gt;less&lt;/em&gt; than a human does, that&amp;#8217;s still not good enough, because when it &lt;em&gt;does&lt;/em&gt; crash the circumstances are too weird.  So, the AI is actually held to a higher standard.  But it&amp;#8217;s also partly just that there was a long tail of really weird events.  A deer crosses the road, or you have some crazy lighting conditions&amp;#8212;such things are really hard to get right, and of course 99% isn&amp;#8217;t good enough here.&lt;/p&gt;



&lt;p&gt;We can maybe fuzzily see ahead at least a decade or two, to when we have AIs that can at the least help us enormously with scientific research and things like that.  Whether or not they&amp;#8217;ve totally replaced us&amp;#8212;and I selfishly hope not, although I do have tenure so there&amp;#8217;s that&amp;#8212;why does it stop there?  Will these models eventually match or exceed human abilities across basically all domains, or at least all intellectual ones?  If they do, what will humans still be good for?  What will be our role in the world?  And then we come to the question, well, will the robots eventually rise up and decide that whatever objective function they were given, they can maximize it better without us around, that they don&amp;#8217;t need us anymore?&lt;/p&gt;


&lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-large&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://www.scottaaronson.com/terminator.jpg&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;This has of course been a trope of many, &lt;em&gt;many&lt;/em&gt; science-fiction works.  The funny thing is that there are thousands of short stories, novels, movies, that have tried to map out the possibilities for where we&amp;#8217;re going, going back at least to Asimov and his &lt;a href=&quot;https://en.wikipedia.org/wiki/Three_Laws_of_Robotics&quot;&gt;Three Laws of Robotics&lt;/a&gt;, which was maybe the first AI safety idea, if not earlier than that.  The trouble is, we don&amp;#8217;t know &lt;em&gt;which&lt;/em&gt; science-fiction story will be the one that will have accurately predicted the world that we&amp;#8217;re creating.  Whichever future we end up in, with hindsight, people will say, &lt;em&gt;this&lt;/em&gt; obscure science fiction story from the 1970s called it exactly right, but we don&amp;#8217;t know which one yet!&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;h2&gt;&lt;strong&gt;What Is AI Safety?&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;So, the rapidly-growing field of AI safety.  People use different terms, so I want to clarify this a little bit.  To an outsider hearing the terms &amp;#8220;AI safety,&amp;#8221; &amp;#8220;AI ethics,&amp;#8221; &amp;#8220;AI alignment,&amp;#8221; they all sound like kind of synonyms, right?  It turns out, and this was one of the things I had to learn going into this, that AI ethics and AI alignment are two communities that despise each other.  It&amp;#8217;s like the &lt;a href=&quot;https://www.youtube.com/watch?v=WboggjN_G-4&quot;&gt;People&amp;#8217;s Front of Judea versus the Judean People&amp;#8217;s Front&lt;/a&gt; from Monty Python.&lt;/p&gt;



&lt;p&gt;To oversimplify radically, &amp;#8220;AI ethics&amp;#8221; means that you&amp;#8217;re mainly worried about current AIs being racist or things like that&amp;#8212;that they&amp;#8217;ll recapitulate the biases that are in their training data.  This clearly can happen: if you feed GPT a bunch of racist invective, GPT might want to say, in effect, &amp;#8220;sure, I&amp;#8217;ve seen plenty of text like that on the Internet!  I know &lt;em&gt;exactly&lt;/em&gt; how that should continue!&amp;#8221;  And in some sense, it&amp;#8217;s doing exactly what it was designed to do, but not what we &lt;em&gt;want&lt;/em&gt; it to do.  GPT currently has an extensive system of content filters to try to prevent people from using it to generate hate speech, bad medical advice, advocacy of violence, and a bunch of other categories that OpenAI doesn&amp;#8217;t want.  And likewise for DALL-E: there are many things it &amp;#8220;could&amp;#8221; draw but won&amp;#8217;t, from porn to images of violence to the Prophet Mohammed.&lt;/p&gt;



&lt;p&gt;More generally, AI ethics people are worried that machine learning systems will be misused by greedy capitalist enterprises to become even more obscenely rich and things like that.&lt;/p&gt;



&lt;p&gt;At the other end of the spectrum, &amp;#8220;AI alignment&amp;#8221; is where you believe that &lt;em&gt;really&lt;/em&gt; the main issue is that AI will become superintelligent and kill everyone, just destroy the world.  The &lt;a href=&quot;https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer&quot;&gt;usual story&lt;/a&gt; here is that someone puts an AI in charge of a paperclip factory, they tell it to figure out how to make as many paperclips as possible, and the AI (being superhumanly intelligent) realizes that it can invent some molecular nanotechnology that will convert the whole solar system into paperclips.&lt;/p&gt;



&lt;p&gt;You might say, well then, you just have to tell it not to do that!  Okay, but how many &lt;em&gt;other&lt;/em&gt; things do you have to remember to tell it not to do?  And the alignment people point out that, in a world filled with powerful AIs, it would take just a single person forgetting to tell their AI to avoid some insanely dangerous thing, and then the whole world could be destroyed.&lt;/p&gt;



&lt;p&gt;So, you can see how these two communities, AI ethics and AI alignment, might both feel like the other is completely missing the point!  On top of that, AI ethics people are almost all on the political left, while AI alignment people are often centrists or libertarians or whatever, so that surely feeds into it as well.&lt;/p&gt;



&lt;p&gt;Oay, so where do I fit into this, I suppose, charred battle zone or whatever?  While there&amp;#8217;s an &amp;#8220;orthodox&amp;#8221; AI alignment movement that I&amp;#8217;ve never entirely subscribed to, I suppose I do now subscribe to a &lt;a href=&quot;https://scottaaronson.blog/?p=6821&quot;&gt;&amp;#8220;reform&amp;#8221; version&lt;/a&gt; of AI alignment:&lt;/p&gt;


&lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-large&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://www.scottaaronson.com/reformai.jpg&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;Most of all, I would like to have a scientific field that&amp;#8217;s able to embrace the entire spectrum of worries that you could have about AI, from the most immediate ones about existing AIs to the most speculative future ones, and that most importantly, is able to make legible progress.&lt;/p&gt;



&lt;p&gt;As it happens, I became aware of the AI alignment community a long time back, around 2006.  Here&amp;#8217;s Eliezer Yudkowsky, who&amp;#8217;s regarded as the prophet of AI alignment, of the right side of that spectrum that showed before.&lt;/p&gt;


&lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-large&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://www.scottaaronson.com/eliezer.jpg&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;He&amp;#8217;s been talking about the danger of AI killing everyone for more than 20 years.  He wrote the now-famous &lt;a href=&quot;https://www.lesswrong.com/tag/original-sequences&quot;&gt;&amp;#8220;Sequences&amp;#8221;&lt;/a&gt; that many readers of my blog were also reading as they appeared, so he and I bounced back and forth.&lt;/p&gt;



&lt;p&gt;But despite interacting with this movement, I always kept it at arm&amp;#8217;s length.  I think that the heart of my objection was: suppose that I &lt;em&gt;agree&lt;/em&gt; that there could come a superintelligent AI that decides its goals are best served by killing us and taking over the world, and that we&amp;#8217;ll be about as powerless to stop it as chimpanzees are to stop us from doing whatever &lt;em&gt;we&lt;/em&gt; want to do.  Suppose I agree to all that.  &lt;em&gt;What do you want me to do about it?&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;As Effective Altruists, you all know that it&amp;#8217;s not enough for a problem to be &lt;em&gt;big&lt;/em&gt;, the problem also has to be &lt;em&gt;tractable&lt;/em&gt;.  There has to be a program that lets you make progress on it.  I was not convinced that that existed.&lt;/p&gt;



&lt;p&gt;My personal experience has been that, in order to make progress in any area of science, you need at least one of two things: either&lt;/p&gt;



&lt;ol&gt;
&lt;li&gt;experiments (or more generally, empirical observations), or&lt;/li&gt;



&lt;li&gt;if not that, then a rigorous mathematical theory&amp;#8212;like we have in quantum computing for example; even though we don&amp;#8217;t yet have the scalable quantum computers, we can still prove theorems about them.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;It struck me that the AI alignment field seemed to have &lt;em&gt;neither&lt;/em&gt; of these things.  But then how does objective reality give you feedback as to when you&amp;#8217;ve taken a wrong path?  Without such feedback, it seemed to me that there&amp;#8217;s a &lt;em&gt;severe&lt;/em&gt; risk of falling into cult-like dynamics, where what&amp;#8217;s important to work on is just whatever the influential leaders say is important.  (A few of my colleagues in physics think that the same thing happened with string theory, but let me not comment on that!)&lt;/p&gt;



&lt;p&gt;With AI safety, this is the key thing that I think has changed in the last three years.  There now exist systems like GPT-3 and DALL-E.  These are &lt;em&gt;not&lt;/em&gt; superhuman AIs.  I don&amp;#8217;t think they themselves are in any danger of destroying the world; they can&amp;#8217;t even form the &lt;em&gt;intention&lt;/em&gt; to destroy the world, or for that matter any intention beyond &amp;#8220;predict the next token&amp;#8221; or things like that.  They don&amp;#8217;t have a persistent identity over time; after you start a new session they&amp;#8217;ve completely forgotten whatever you said to them in the last one (although of course such things will change in the future).  And yet nevertheless, despite all these limitations, we can experiment with these systems and learn things about AI safety that are relevant.  We can see what happens when the systems are deployed; we can try out different mitigations and see whether they work.&lt;/p&gt;



&lt;p&gt;As a result, I feel like it&amp;#8217;s now become possible to make technical progress in AI safety that the whole scientific community, or at least the whole AI community, can clearly recognize as progress.&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;h2&gt;&lt;strong&gt;Eight Approaches to AI Alignment&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;So, what are the major approaches to AI alignment&amp;#8212;let&amp;#8217;s say, to aligning a very powerful, beyond-human-level AI?  There are a lot of really interesting ideas, most of which I think can now lead to research programs that are actually productive.  So without further ado, let me go through eight of them.&lt;/p&gt;



&lt;p&gt;(1) You could say the first and most basic of all AI alignment ideas is the &lt;em&gt;off switch&lt;/em&gt;, also known as &lt;em&gt;pulling the plug&lt;/em&gt;.  You could say, no matter how intelligent an AI is, it&amp;#8217;s nothing without a power source or physical hardware to run on.  And if humans have physical control over the hardware, they can just turn it off if if things seem to be getting out of hand.  Now, the standard response to that is okay, but you have to remember that &lt;em&gt;this AI is smarter than you&lt;/em&gt;, and anything that you can think of, it will have thought of also.  In particular, it will know that you might want to turn it off, and it will know that that will prevent it from achieving its goals like making more paperclips or whatever.  It will have disabled the off-switch if possible.  If it couldn&amp;#8217;t do that, it will have gotten onto the Internet and made lots of copies of itself all over the world.  If you tried to keep it off the Internet, it will have figured out a way to get on.&lt;/p&gt;



&lt;p&gt;So, you can worry about that.  But you can also think about, could we insert a &lt;em&gt;backdoor&lt;/em&gt; into an AI, something that only the humans know about but that will allow us to control it later?&lt;/p&gt;



&lt;p&gt;More generally, you could ask for &lt;a href=&quot;https://intelligence.org/files/Corrigibility.pdf&quot;&gt;&amp;#8220;corrigibility&amp;#8221;&lt;/a&gt;: can you have an AI that, despite how intelligent it is, will accept correction from humans later and say, oh well, the objective that I was given before was actually not my true objective because the humans have now changed their minds and I should take a different one?&lt;/p&gt;



&lt;p&gt;(2) Another class of ideas has to do with what&amp;#8217;s called &amp;#8220;sandboxing&amp;#8221; an AI, which would mean that you run it inside of a simulated world, like &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Truman_Show&quot;&gt;The Truman Show&lt;/a&gt;, so that for all it knows the simulation is the whole of reality.  You can then study its behavior within the sandbox to make sure it&amp;#8217;s aligned before releasing it into the wider world&amp;#8212;our world.&lt;/p&gt;



&lt;p&gt;A simpler variant is, if you really thought an AI was dangerous, you might run it only on an air-gapped computer, with all its access to the outside world carefully mediated by humans.  There would then be all kinds of just standard cybersecurity issues that come into play: how do you prevent it from getting onto the Internet?  Presumably you don&amp;#8217;t want to write your AI in C, and have it exploit some memory allocation bug to take over the world, right?&lt;/p&gt;



&lt;p&gt;(3) A third direction, and I would say maybe the most popular one in AI alignment research right now, is called &lt;em&gt;interpretability&lt;/em&gt;.  This is also a major direction in mainstream machine learning research right now, so there&amp;#8217;s a big point of intersection there.  The idea of interpretability is, why don&amp;#8217;t we exploit the fact that we actually have complete access to the code of the AI&amp;#8212;or if it&amp;#8217;s a neural net, complete access to its parameters?  So we can look inside of it.  We can do the AI analogue of neuroscience.  Except, unlike an fMRI machine, which gives you only an extremely crude snapshot of what a brain is doing, we can see &lt;em&gt;exactly&lt;/em&gt; what every neuron in a neural net is doing at every point in time.  If we don&amp;#8217;t exploit &lt;em&gt;that&lt;/em&gt;, then aren&amp;#8217;t we trying to make AI safe with our hands tied behind our backs?&lt;/p&gt;



&lt;p&gt;So we should look inside.  Look inside to do what, exactly?  One possibility is to figure out how to apply the AI version of a lie-detector test.  If a neural network has decided to lie to humans in pursuit of its goals, then by looking inside, at the inner layers of the network rather than the output layer, we could hope to uncover its dastardly plan!&lt;/p&gt;



&lt;p&gt;Here I want to mention some really &lt;a href=&quot;https://openreview.net/pdf?id=ETKGuby0hcs&quot;&gt;spectacular new work&lt;/a&gt; (paper publicly available but authors still anonymous), which has experimentally demonstrated pretty much exactly what I just said.&lt;/p&gt;



&lt;p&gt;First some background: with modern text models like GPT, it&amp;#8217;s pretty easy to train them to output falsehoods.  For example, suppose you prompt GPT with a bunch of examples like:&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;&amp;#8220;Is the earth flat?  Yes.&amp;#8221;&lt;/p&gt;



&lt;p&gt;&amp;#8220;Does 2+2=4?  No.&amp;#8221;&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;and so on.  Eventually GPT will say, &amp;#8220;oh, I know what game we&amp;#8217;re playing!  it&amp;#8217;s the &amp;#8216;give false answers&amp;#8217; game!&amp;#8221; And it will then continue playing that game and give you more false answers.  What the new paper shows is that, in such cases, one can actually look at the inner layers of the neural net and find where it has an internal representation of what was the true answer, which then gets overridden once you get to the output layer.&lt;/p&gt;



&lt;p&gt;To be clear, there&amp;#8217;s no known principled reason why this has to work.  Like countless other ML advances, it&amp;#8217;s empirical: they just try it out and find that it &lt;em&gt;does&lt;/em&gt; work.  So we don&amp;#8217;t know if it will generalize.  As another issue, you could argue that in some sense what the network is representing is not so much &amp;#8220;the truth of reality,&amp;#8221; as just what was &lt;em&gt;regarded&lt;/em&gt; as true in the training data.  Even so, I find this really exciting: it&amp;#8217;s a perfect example of actual experiments that you can now do that start to address some of these issues.&lt;/p&gt;



&lt;p&gt;(4) Another big idea, one that&amp;#8217;s been advocated for example by Geoffrey Irving, Paul Christiano, and Dario Amodei (Paul was my student at MIT a decade ago, and did quantum computing before he &amp;#8220;defected&amp;#8221; to AI safety), is to have &lt;a href=&quot;https://arxiv.org/abs/1805.00899&quot;&gt;multiple competing AIs&lt;/a&gt; that debate each other.  You know, sometimes when I&amp;#8217;m talking to my physics colleagues, they&amp;#8217;ll tell me all these crazy-sounding things about black holes and wormholes, and I don&amp;#8217;t know whether to believe them.  But if I get &lt;em&gt;different&lt;/em&gt; physicists and have them argue with each other, then I can see which one seems more plausible to me&amp;#8212;I&amp;#8217;m a little bit better at &lt;em&gt;that&lt;/em&gt;.  So you might want to do something similar with AIs.  Even if you as a human don&amp;#8217;t feel like you know when to trust what an AI is telling you, you could set multiple AIs against each other, have them try to do their best to refute each other, and then make your own judgment as to which one is giving better advice.&lt;/p&gt;



&lt;p&gt;(5) Another key idea that Christiano, Amodei, and Buck Shlegeris &lt;a href=&quot;https://arxiv.org/abs/1810.08575&quot;&gt;have advocated&lt;/a&gt; is some sort of bootstrapping.  You might imagine that AI is going to get more and more powerful, and as it gets more powerful we also understand it less, and so you might worry that it also gets more and more dangerous.  OK, but you could imagine an onion-like structure, where once we become confident of a certain level of AI, once we more or less trust what that kind of AI is able to do, we don&amp;#8217;t think it&amp;#8217;s going to start lying to us or deceiving us or plotting to kill us or whatever&amp;#8212;at that point, we use that AI to help us verify the behavior of the next more powerful kind of AI.  So, we&amp;#8217;ll use AI itself as a crucial tool for verifying the behavior of AI that we don&amp;#8217;t yet understand.&lt;/p&gt;



&lt;p&gt;There have already been some demonstrations of this principle: with GPT, for example, you can just feed in a lot of raw data from a neural net and say, &amp;#8220;explain to me what this is doing.&amp;#8221;  One of GPT&amp;#8217;s big advantages over humans is its unlimited patience for tedium, so it can just go through all of the data and give you useful hypotheses about what&amp;#8217;s going on.&lt;/p&gt;



&lt;p&gt;(6) One thing that we know a lot about in theoretical computer science is what are called &lt;em&gt;interactive proof systems&lt;/em&gt;.  That is, we know how a very weak verifier can verify the behavior of a much more powerful but untrustworthy prover, by submitting questions to it.  There are famous theorems about this, including one called &lt;a href=&quot;https://en.wikipedia.org/wiki/IP_(complexity)&quot;&gt;IP=PSPACE&lt;/a&gt;.  Incidentally, this was what the OpenAI people talked about when they originally approached me about working with them for a year.  They made the case that these results in computational complexity seem like an excellent model for the kind of thing that we want in AI safety, &lt;em&gt;except&lt;/em&gt; that we now have a powerful AI in place of a mathematical prover.&lt;/p&gt;



&lt;p&gt;Even in practice, there&amp;#8217;s a whole field of formal verification, where people formally prove the properties of programs&amp;#8212;our CS department here in Austin is a leader in it.&lt;/p&gt;



&lt;p&gt;One obvious difficulty here is that we mostly know how to verify programs only when we can mathematically specify what the program is &lt;em&gt;supposed&lt;/em&gt; to do.  And &amp;#8220;the AI being nice to humans,&amp;#8221; &amp;#8220;the AI not killing humans&amp;#8221;&amp;#8212;these are really hard concepts to make mathematically precise!  That&amp;#8217;s the heart of the problem with here.&lt;/p&gt;



&lt;p&gt;(7) Yet another idea&amp;#8212;you might feel more comfortable if there were only one idea, but instead I&amp;#8217;m giving you eight!&amp;#8212;a seventh idea is, well, we just have to come up with a mathematically precise formulation of human values.  You know, the thing that the AI should maximize, that&amp;#8217;s gonna coincide with human welfare.&lt;/p&gt;



&lt;p&gt;In some sense, this is what Asimov was trying to do with his Three Laws of Robotics.  The trouble is, if you&amp;#8217;ve read any of his stories, they&amp;#8217;re all about the situations where those laws don&amp;#8217;t work well!  They were designed as much to give interesting story scenarios as actually to work.&lt;/p&gt;



&lt;p&gt;More generally, what happens when &amp;#8220;human values&amp;#8221; conflict with each other?  If humans can&amp;#8217;t even agree with each other about moral values, how on Earth can we formalize such things?&lt;/p&gt;



&lt;p&gt;I have these weekly calls with &lt;a href=&quot;https://en.wikipedia.org/wiki/Ilya_Sutskever&quot;&gt;Ilya Sutskever&lt;/a&gt;, who&amp;#8217;s a cofounder of OpenAI.  &lt;em&gt;Extremely&lt;/em&gt; interesting guy.  But when I tell him about the concrete projects that I&amp;#8217;m working on, or want to work on, he usually says, &amp;#8220;that&amp;#8217;s great Scott, you should keep working on that, but what I &lt;em&gt;really&lt;/em&gt; want to know is, what is the mathematical definition of goodness?  What&amp;#8217;s the complexity-theoretic formalization of an AI loving humanity?&amp;#8221;  And I&amp;#8217;m like, I&amp;#8217;ll keep thinking about that!  But of course it&amp;#8217;s hard to make progress on those enormities.&lt;/p&gt;



&lt;p&gt;(8) A different idea, which some people might consider more promising, is well, if we can&amp;#8217;t make explicit what all of our human values are, then why not just treat that as yet another machine learning problem?  Like, feed the AI all of the world&amp;#8217;s children&amp;#8217;s stories and literature and fables and even Saturday-morning cartoons, all of our examples of what we think is good and evil, then we tell it, go do your neural net thing and generalize from these examples as far as you can.&lt;/p&gt;



&lt;p&gt;One objection that many people raise to this is, how do we know that our current values are the right ones?  Like, it would&amp;#8217;ve been terrible to train the AI on consensus human values of the year 1700&amp;#8212;slavery is great and so forth&amp;#8212;the past is full of things that we now look back upon with horror.&lt;/p&gt;



&lt;p&gt;So, one idea that people have had&amp;#8212;this is actually Yudkowsky&amp;#8217;s term&amp;#8212;is &lt;a href=&quot;https://intelligence.org/files/CEV.pdf&quot;&gt;&amp;#8220;Coherent Extrapolated Volition.&amp;#8221;&lt;/a&gt;  This basically means that you&amp;#8217;d tell the AI: &amp;#8220;I&amp;#8217;ve given you all this training data about current human morality, all the human moral judgments as they currently stand.  Now simulate the humans being in a discussion seminar for 10,000 years, trying to refine all of their moral intuitions, and whatever you predict that that would end up with, those should be your values right now.&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;h2&gt;&lt;strong&gt;My Projects at OpenAI&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;So, there are some interesting ideas on the table.  The last thing that I wanted to tell you about, before opening it up to Q&amp;amp;A, is a little bit about what actual projects I&amp;#8217;ve been working on in the last five months.  I was excited to find a few things that&lt;/p&gt;



&lt;p&gt;(a) could actually be deployed in you know GPT or other current systems,&lt;/p&gt;



&lt;p&gt;(b) actually address some real safety worry, and where&lt;/p&gt;



&lt;p&gt;(c) theoretical computer science can actually say something about them.&lt;/p&gt;



&lt;p&gt;I had been worried that the intersection of (a), (b), and (c) would be the empty set!&lt;/p&gt;



&lt;p&gt;My main project so far has been a tool for statistically watermarking the outputs of a text model like GPT.  Basically, whenever GPT generates some long text, we want there to be an otherwise unnoticeable secret signal in its choices of words, which you can use to prove later that, yes, this came from GPT.  We want it to be much harder to take a GPT output and pass it off as if it came from a human.  This could be helpful for preventing academic plagiarism, obviously, but also, for example, mass generation of propaganda&amp;#8212;you know, spamming every blog with seemingly on-topic comments supporting Russia&amp;#8217;s invasion of Ukraine, without even a building full of trolls in Moscow.  Or impersonating someone&amp;#8217;s writing style in order to incriminate them.  These are all things one might want to make harder, right?&lt;/p&gt;



&lt;p&gt;More generally, when you try to think about the nefarious uses for GPT, &lt;em&gt;most&lt;/em&gt; of them&amp;#8212;at least that I was able to think of!&amp;#8212;require somehow concealing GPT&amp;#8217;s involvement.  In which case, watermarking would simultaneously attack most misuses.&lt;/p&gt;



&lt;p&gt;How does it work?  For GPT, every input and output is a string of &lt;em&gt;tokens&lt;/em&gt;, which could be words but also punctuation marks, parts of words, or more&amp;#8212;there are about 100,000 tokens in total.  At its core, GPT is constantly generating a probability distribution over the next token to generate, conditional on the string of previous tokens.  After the neural net generates the distribution, the OpenAI server then actually samples a token according to that distribution&amp;#8212;or some modified version of the distribution, depending on a parameter called &amp;#8220;temperature.&amp;#8221;  As long as the temperature is nonzero, though, there will usually be some &lt;em&gt;randomness&lt;/em&gt; in the choice of the next token: you could run over and over with the same prompt, and get a different completion (i.e., string of output tokens) each time.&lt;/p&gt;



&lt;p&gt;So then to watermark, instead of selecting the next token randomly, the idea will be to select it pseudorandomly, using a cryptographic pseudorandom function, whose key is known only to OpenAI.  That won&amp;#8217;t make any detectable difference to the end user, assuming the end user can&amp;#8217;t distinguish the pseudorandom numbers from truly random ones.  But now you can choose a pseudorandom function that secretly biases a certain score&amp;#8212;a sum over a certain function g evaluated at each n-gram (sequence of n consecutive tokens), for some small n&amp;#8212;which score you can also compute if you know the key for this pseudorandom function.&lt;/p&gt;



&lt;p&gt;To illustrate, in the special case that GPT had a bunch of possible tokens that it judged equally probable, you could simply choose whichever token maximized g.  The choice would &lt;em&gt;look&lt;/em&gt; uniformly random to someone who didn&amp;#8217;t know the key, but someone who &lt;em&gt;did&lt;/em&gt; know the key could later sum g over all n-grams and see that it was anomalously large.  The general case, where the token probabilities can all be different, is a little more technical, but the basic idea is similar.&lt;/p&gt;



&lt;p&gt;One thing I like about this approach is that, because it never actually goes inside the neural net and tries to change anything, but just places a sort of wrapper &lt;em&gt;over&lt;/em&gt; the neural net, it&amp;#8217;s actually possible to do some theoretical analysis!  In particular, you can prove a rigorous upper bound on how many tokens you&amp;#8217;d need to distinguish watermarked from non-watermarked text with such-and-such confidence, as a function of the average entropy in GPT&amp;#8217;s probability distribution over the next token.  Better yet, proving the bound involves doing some integrals whose answers involve the &lt;a href=&quot;https://en.wikipedia.org/wiki/Digamma_function&quot;&gt;digamma function&lt;/a&gt;, factors of π&lt;sup&gt;2&lt;/sup&gt;/6, and the &lt;a href=&quot;https://en.wikipedia.org/wiki/Euler%27s_constant&quot;&gt;Euler-Mascheroni constant&lt;/a&gt;.  I&amp;#8217;m excited to share details soon.&lt;/p&gt;



&lt;p&gt;Some might wonder: if OpenAI controls the server, then why go to all the trouble to watermark?  Why not just store all of GPT&amp;#8217;s outputs in a giant database, and then consult the database later if you want to know whether something came from GPT?  Well, the latter &lt;em&gt;could&lt;/em&gt; be done, and might even have to be done in high-stakes cases involving law enforcement or whatever.  But it would raise some serious privacy concerns: how do you reveal whether GPT did or didn&amp;#8217;t generate any given candidate text, without potentially revealing how other people have been using GPT?  The database approach also has difficulties in distinguishing text that GPT uniquely generated, from text that it generated simply because it has very high probability (e.g., a list of the first 100 prime numbers).&lt;/p&gt;



&lt;p&gt;Anyway, we actually have a working prototype of the watermarking scheme, built by OpenAI engineer &lt;a href=&quot;https://twitter.com/janhkirchner?lang=en&quot;&gt;Hendrik Kirchner&lt;/a&gt;.  It seems to work pretty well&amp;#8212;empirically, a few hundred tokens seem to be enough to get a reasonable signal that yes, this text came from GPT.  In principle, you could even take a long text and isolate which parts probably came from GPT and which parts probably didn&amp;#8217;t.&lt;/p&gt;



&lt;p&gt;Now, this can all be defeated with enough effort.  So for example, if you used another AI to paraphrase GPT&amp;#8217;s output&amp;#8212;well okay, we&amp;#8217;re not going to be able to detect that.  On the other hand, if you just insert or delete a few words here and there, or rearrange the order of some sentences, the watermarking signal will still be there.  Because it depends only on a sum over n-grams, it&amp;#8217;s robust against those sorts of interventions.&lt;/p&gt;



&lt;p&gt;The hope is that this can be rolled out with future GPT releases.  We&amp;#8217;d love to do something similar for DALL-E&amp;#8212;that is, watermarking images, not at the pixel level (where it&amp;#8217;s too easy to remove the watermark) but at the &amp;#8220;conceptual&amp;#8221; level, the level of the so-called &lt;a href=&quot;https://www.assemblyai.com/blog/how-dall-e-2-actually-works/&quot;&gt;CLIP representation&lt;/a&gt; that&amp;#8217;s prior to the image.  But we don&amp;#8217;t know if that&amp;#8217;s going to work yet.&lt;/p&gt;



&lt;p&gt;A more recent idea that I&amp;#8217;ve started thinking about was inspired by an &lt;a href=&quot;https://arxiv.org/abs/2204.06974&quot;&gt;amazing recent paper&lt;/a&gt; by four computer scientists, including my former MIT colleagues Shafi Goldwasser and Vinod Vaikuntanathan.  What they&amp;#8217;ve shown is how to plant a &lt;em&gt;cryptographically undetectable backdoor&lt;/em&gt; into a machine learning model&amp;#8212;things like depth-2 neural networks&amp;#8212;based on some known cryptographic hardness assumptions.  After you&amp;#8217;ve planted the backdoor, you get a model that&amp;#8217;s polynomial-time indistinguishable from how it would&amp;#8217;ve looked before, even to a user who can see all of the parameters.  &lt;em&gt;But&lt;/em&gt;, there&amp;#8217;s now a secret input, known only to the person who trained the network, where if you feed it that input, then it will output something insane, of the trainer&amp;#8217;s choice.&lt;/p&gt;



&lt;p&gt;So, it&amp;#8217;s now known that you can do this, at least in shallow networks&amp;#8212;it&amp;#8217;s an open problem whether the same can be done in deep networks (though it seems plausible).&lt;/p&gt;



&lt;p&gt;Anyway, this paper was from less than a year ago and some people treat it as kind of a lemon.  You know, the result seems like a bummer if you&amp;#8217;re trying to do interpretability research, because it means that in some sense it can be cryptographically impossible to look inside of a neural net and &amp;#8220;interpret&amp;#8221; everything it does, or even everything its designers wanted it to do.  The model can have these planted backdoors that you can&amp;#8217;t find without solving an exponentially hard problem.&lt;/p&gt;



&lt;p&gt;So, my proposal is just to turn that lemon into lemonade.  Why not use these cryptographic backdoors as a &lt;em&gt;positive tool&lt;/em&gt; for AI alignment?  We talked before about the difficulties with putting an off-switch into an AI&amp;#8212;namely, that the AI will often have strong incentives to disable the off-switch.  So why not make a &lt;em&gt;cryptographic&lt;/em&gt; off-switch?  In other words, when you train your superhuman AI, you&amp;#8217;ll purposefully put one of these cryptographic backdoors into it, which says: &lt;em&gt;if&lt;/em&gt; you get this bizarre input, which only the humans know about, then turn yourself off.  Or go into a special mode where the humans can control you.&lt;/p&gt;



&lt;p&gt;And now the key is this: even supposing that the AI is worried that this backdoor might be there, and even supposing that it can modify its own weights, it shouldn&amp;#8217;t know how to remove this thing without just completely recreating itself from scratch, which might get rid of a lot of hard-to-understand behaviors that the AI wants to &lt;em&gt;keep&lt;/em&gt;, in addition to the backdoor that it&amp;#8217;s trying to eliminate.&lt;/p&gt;



&lt;p&gt;I expect that this could be tried out right now&amp;#8212;not with AIs powerful enough to purposefully rewrite themselves, of course, but with GPT and other existing text models&amp;#8212;and I look forward to seeing a test implementation.  But it &lt;em&gt;also&lt;/em&gt;, I now think it opens up all sorts of new possibilities for science-fiction stories!&lt;/p&gt;



&lt;p&gt;Like, imagine the humans debating, what are they going to do with their secret key for controlling the AI?  Lock it in a safe?  Bury it underground?  Then you&amp;#8217;ve got to imagine the robots methodically searching for the key&amp;#8212;you know, torturing the humans to get them to reveal the hiding place, etc.  Or maybe there are actually seven different keys that all have to be found, like Voldemort with his horcruxes.  The screenplay practically writes itself!&lt;/p&gt;



&lt;p&gt;A third thing that I&amp;#8217;ve been thinking about is the theory of learning but in dangerous environments, where if you try to learn the wrong thing then it will kill you.  Can we generalize some of the basic results in machine learning to this scenario where you have to consider which queries are safe to make, and you have to try to learn more in order to expand your set of safe queries over time?&lt;/p&gt;



&lt;p&gt;Now there&amp;#8217;s one example of this sort of situation that&amp;#8217;s completely formal and that should be immediately familiar to almost everyone here and that&amp;#8217;s the game Minesweeper.&lt;/p&gt;


&lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-large&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://www.scottaaronson.com/minesweeper.jpg&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;So, you can think of the problem as &amp;#8220;Minesweeper learning.&amp;#8221;  Now, it&amp;#8217;s actually known that &lt;a href=&quot;https://web.mat.bham.ac.uk/R.W.Kaye/minesw/ASE2003.pdf&quot;&gt;Minesweeper is an NP-hard problem&lt;/a&gt; to play optimally, so we know that in learning in a dangerous environment you can get that kind of complexity.  As far as I know, we don&amp;#8217;t know anything about typicality or average-case hardness.  &lt;em&gt;Also&lt;/em&gt;, to my knowledge no one has proven any nontrivial rigorous bounds on the probability that you&amp;#8217;ll win Minesweeper if you play it optimally, with a given size board and a given number of randomly-placed mines.  Certainly the probability is strictly between 0 and 1; I think it would be extremely interesting to bound it.  I don&amp;#8217;t know if this directly feeds into the AI safety program, but it would at least tell you something about the theory of machine learning in cases where a wrong move can kill you.&lt;/p&gt;



&lt;p&gt;So, I hope that gives you at least some sense for what I&amp;#8217;ve been thinking about.  I wish I could end with some neat conclusion, but I don&amp;#8217;t really know the conclusion&amp;#8212;maybe if you ask me again in six more months I&amp;#8217;ll know!  For now, though, I just thought I&amp;#8217;d thank you for your attention and open things up to discussion.&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;h2&gt;&lt;strong&gt;Q&amp;amp;A&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Could you delay rolling out that statistical watermarking tool until May 2026?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Scott:&lt;/strong&gt; Why?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Oh, just until after I graduate [Laughter].  OK, my second question is how we can possibly implement these AI safety guidelines inside of systems like &lt;a href=&quot;https://en.wikipedia.org/wiki/Automated_machine_learning&quot;&gt;AutoML&lt;/a&gt;, or whatever their future equivalents are that are much more advanced.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Scott:&lt;/strong&gt; I feel like I should learn more about AutoML first before commenting on that specifically.  In general, though, it&amp;#8217;s certainly true that we&amp;#8217;re going to have AIs that will help with the design of other AIs, and indeed this is one of the main things that feeds into the worries about AI safety, which I should&amp;#8217;ve mentioned before explicitly.  Once you have an AI that can recursively self-improve, who knows where it&amp;#8217;s going to end up, right?  It&amp;#8217;s like shooting a rocket into space that you can then no longer steer once it&amp;#8217;s left the earth&amp;#8217;s atmosphere.  So at the very least, you&amp;#8217;d better try to get things right the first time!  You might have only one chance to align its values with what you want.&lt;/p&gt;



&lt;p&gt;Precisely for that reason, I tend to be very leery of that kind of thing.  I tend to be much more comfortable with ideas where humans would remain in the loop, where you don&amp;#8217;t just have this completely automated process of an AI designing a stronger AI which designs a still stronger one and so on, but where you&amp;#8217;re repeatedly consulting humans.  Crucially, in this process, we assume the humans can rely on any of the previous AIs to help them (as in the &lt;a href=&quot;https://arxiv.org/abs/1810.08575&quot;&gt;iterative amplification&lt;/a&gt; proposal).  But then it&amp;#8217;s ultimately humans making judgments about the next AI.&lt;/p&gt;



&lt;p&gt;Now, if this gets to the point where the humans can no longer even &lt;em&gt;judge&lt;/em&gt; a new AI, even with as much help as they want from earlier AIs, then you could argue: OK, maybe &lt;em&gt;now&lt;/em&gt; humans have finally been superseded and rendered irrelevant.  But unless and until we get to that point, I say that humans ought to remain in the loop!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Most of the protections that you talked about today come from, like, an altruistic human, or a company like OpenAI adding protections in.  Is there any way that you could think of that we could protect ourselves from an AI that&amp;#8217;s maliciously designed or accidentally maliciously designed?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Scott:&lt;/strong&gt; Excellent question!  Usually, when people talk about that question at all, they talk about using aligned AIs to help defend yourself against unaligned ones.  I mean, if your adversary has a robot army attacking you, it stands to reason that you&amp;#8217;ll probably want your own robot army, right?  And it&amp;#8217;s very unfortunate, maybe even terrifying, that one can already foresee those sorts of dynamics.&lt;/p&gt;



&lt;p&gt;Besides that, there&amp;#8217;s of course the idea of &lt;em&gt;monitoring, regulating, and slowing down the proliferation of powerful AI&lt;/em&gt;, which I didn&amp;#8217;t mention explicitly before, perhaps just because by its nature, it seems outside the scope of the technical solutions that a theoretical computer scientist like me might have any special expertise about.&lt;/p&gt;



&lt;p&gt;But there are certainly people who think that AI development ought to be more heavily regulated, or throttled, or even stopped entirely, in view of the dangers.  Ironically, the &amp;#8220;AI ethics&amp;#8221; camp and the &amp;#8220;orthodox AI alignment&amp;#8221; camp, despite their mutual contempt, seem more and more to want something like that &amp;#8230; an unexpected point of agreement!&lt;/p&gt;



&lt;p&gt;But how would you do it?  On the one hand, AI isn&amp;#8217;t like nuclear weapons, where you &lt;em&gt;know&lt;/em&gt; that anyone building them will need a certain amount of enriched uranium or plutonium, along with extremely specialized equipment, so you can try (successfully or not) to institute a global regime to track those materials.  You &lt;em&gt;can&amp;#8217;t&lt;/em&gt; do the same with software: assuming you&amp;#8217;re not going to confiscate and destroy all computers (which you&amp;#8217;re not), who the hell knows what code or data anyone has?&lt;/p&gt;



&lt;p&gt;On the other hand, at least with the current paradigm of AI, there &lt;em&gt;is&lt;/em&gt; an obvious choke point, and that&amp;#8217;s the &lt;a href=&quot;https://en.wikipedia.org/wiki/Graphics_processing_unit&quot;&gt;GPUs&lt;/a&gt; (Graphics Processing Units).  Today&amp;#8217;s state-of-the-art machine learning models already need huge server farms full of GPUs, and future generations are likely to need orders of magnitude more still.  And right now, the great majority of the world&amp;#8217;s GPUs are manufactured by &lt;a href=&quot;https://en.wikipedia.org/wiki/TSMC&quot;&gt;TSMC&lt;/a&gt; in Taiwan, albeit with crucial inputs from other countries.  I hardly need to explain the geopolitical ramifications!  A few months ago, as you might have seen, the Biden administrated decided to &lt;a href=&quot;https://www.nytimes.com/2022/08/31/technology/gpu-chips-china-russia.html&quot;&gt;restrict the export&lt;/a&gt; of high-end GPUs to China.  The restriction was driven, in large part, by worries about what the Chinese government could do with unlimited ability to train huge AI models.  Of course the future status of Taiwan figures into this conversation, as does China&amp;#8217;s ability (or inability) to develop a self-sufficient semiconductor industry.&lt;/p&gt;



&lt;p&gt;And then there&amp;#8217;s regulation.  I know that in the EU they&amp;#8217;re working on some &lt;a href=&quot;https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai&quot;&gt;regulatory framework&lt;/a&gt; for AI right now, but I don&amp;#8217;t understand the details.  You&amp;#8217;d have to ask someone who follows such things.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Thanks for coming out and seeing us; this is awesome.  Do you have thoughts on how we can incentivize organizations to build safer AI?  For example, if corporations are competing with each other, then couldn&amp;#8217;t focusing on AI safety make the AI less accurate or less powerful or cut into profits?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Scott:&lt;/strong&gt; Yeah, it&amp;#8217;s an excellent question.  You could worry that &lt;em&gt;all&lt;/em&gt; this stuff about trying to be safe and responsible when scaling AI &amp;#8230; as soon as it seriously hurts the bottom lines of Google and Facebook and Alibaba and the other major players, then a lot of it will go out the window.  People are very worried about that.&lt;/p&gt;



&lt;p&gt;On the other hand, we&amp;#8217;ve seen over the past 30 years that the big Internet companies &lt;em&gt;can&lt;/em&gt; agree on certain minimal standards, whether because of fear of getting sued, desire to be seen as a responsible player, or whatever else.  One simple example would be &lt;a href=&quot;https://www.cloudflare.com/learning/bots/what-is-robots.txt/&quot;&gt;robots.txt&lt;/a&gt;: if you want your website not to be indexed by search engines, you can specify that, and the major search engines will respect it.&lt;/p&gt;



&lt;p&gt;In a similar way, you could imagine something like watermarking&amp;#8212;&lt;em&gt;if&lt;/em&gt; we were able to demonstrate it and show that it works and that it&amp;#8217;s cheap and doesn&amp;#8217;t hurt the quality of the output and doesn&amp;#8217;t need much compute and so on&amp;#8212;that it would just become an industry standard, and anyone who wanted to be considered a responsible player would include it.&lt;/p&gt;



&lt;p&gt;To be sure, some of these measures really &lt;em&gt;do&lt;/em&gt; make sense only in a world where there are a few companies that are years ahead of everyone else in scaling up state-of-the-art models&amp;#8212;DeepMind, OpenAI, Google, Facebook, maybe a few others&amp;#8212;and they all agree to be responsible players.  If that equilibrium breaks down, and it becomes a free-for-all, then a lot of the safety measures do become harder, and might even be impossible, at least without government regulation.&lt;/p&gt;



&lt;p&gt;We&amp;#8217;re already starting to see that with image models.  As I mentioned earlier, DALL-E2 has all sorts of filters to try to prevent people from creating&amp;#8212;well, in practice it&amp;#8217;s often porn, and/or &lt;a href=&quot;https://en.wikipedia.org/wiki/Deepfake&quot;&gt;deepfakes&lt;/a&gt; involving real people.  In general, though, DALL-E2 will refuse to generate an image if its filters flag the prompt as (by OpenAI&amp;#8217;s lights) even a potential misuse of the technology.&lt;/p&gt;



&lt;p&gt;But as you might have seen, there&amp;#8217;s already an open-source image model called &lt;a href=&quot;https://stability.ai/blog/stable-diffusion-public-release&quot;&gt;Stable Diffusion&lt;/a&gt;, and people &lt;em&gt;are&lt;/em&gt; using it to do all sorts of things that DALL-E won&amp;#8217;t allow.  So it&amp;#8217;s a legitimate question: how can you prevent misuses, &lt;em&gt;unless&lt;/em&gt; the closed models remain well ahead of the open ones?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; You mentioned the importance of having humans in the loop who can judge AI systems.  So, as someone who could be in one of those pools of decision makers, what stakeholders do you think should be making the decisions?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Scott:&lt;/strong&gt; Oh gosh.  The ideal, as almost everyone agrees, is to have some kind of democratic governance mechanism with broad-based input.  But people have talked about this for years: how do you create the democratic mechanism?  Every activist who wants to bend AI in some preferred direction will &lt;em&gt;claim&lt;/em&gt; a democratic mandate; how should a tech company like OpenAI or DeepMind or Google decide which claims are correct?&lt;/p&gt;



&lt;p&gt;Maybe the one useful thing I can say is that, in my experience, which is admittedly very limited&amp;#8212;working at OpenAI for all of five months&amp;#8212;I&amp;#8217;ve found my colleagues there to be &lt;em&gt;extremely&lt;/em&gt; serious about safety, bordering on obsessive.  They talk about it constantly.  They actually have an &lt;a href=&quot;https://openai.com/about/&quot;&gt;unusual structure&lt;/a&gt;, where they&amp;#8217;re a for-profit company that&amp;#8217;s controlled by a nonprofit foundation, which is at least formally empowered to come in and hit the brakes.  OpenAI also has a &lt;a href=&quot;https://openai.com/charter/&quot;&gt;charter&lt;/a&gt; that contains some striking statements, especially the following:&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;We are concerned about late-stage AGI development becoming a competitive race without time for adequate safety precautions. Therefore, if a value-aligned, safety-conscious project comes close to building AGI before we do, we commit to stop competing with and start assisting this project.&lt;/p&gt;
&lt;/blockquote&gt;



&lt;p&gt;Of course, the fact that they&amp;#8217;ve put a great deal of thought into this doesn&amp;#8217;t mean that they&amp;#8217;re going to get it right!  But if you ask me: would I rather that it be OpenAI in the lead right now or the Chinese government?  Or, if it&amp;#8217;s going to be a company, then would I rather it be one with a charter like the above, or a charter of &amp;#8220;maximize clicks and ad revenue&amp;#8221;?  I suppose I do lean a certain way.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; This was a terrifying talk which was lovely, thank you!  But I was thinking: you listed eight different alignment approaches, like kill switches and so on.  You can imagine a future where there&amp;#8217;s a whole bunch of AIs that people spawn and then try to control in these eight ways.  But wouldn&amp;#8217;t this sort of naturally select for AIs that are good at getting past whatever checks we impose on them?  And then eventually you&amp;#8217;d get AIs that are sort of trained in order to fool our tests?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Scott:&lt;/strong&gt; Yes.  Your question reminds me of a huge irony.  Eliezer Yudkowsky, the prophet of AI alignment who I talked about earlier, has &lt;a href=&quot;https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities&quot;&gt;become completely doomerist&lt;/a&gt; within the last few years.  As a result, he and I have literally &lt;em&gt;switched positions&lt;/em&gt; on how optimistic to be about AI safety research!  Back, when he was gung-ho about it, I held back.  Today, Eliezer says that it barely matters anymore, since it&amp;#8217;s too late; we&amp;#8217;re all gonna be killed by AI with &gt;99% probability.  Now, he says, it&amp;#8217;s mostly just about dying with more &amp;#8220;dignity&amp;#8221; than otherwise.  Meanwhile, I&amp;#8217;m like, no, AI safety has actually just recently become fruitful and exciting to work on!  So, maybe I&amp;#8217;m just 20 years behind Eliezer, and will eventually catch up and become doomerist too.  Or maybe he, I, and everyone else will be dead before that happens.  I suppose the most optimistic spin is that no one ought to fear coming into AI safety today, as a newcomer, if the prophet of the movement himself says that the past 20 years of research on the subject has given him so little reason for hope.&lt;/p&gt;



&lt;p&gt;But if you ask, &lt;em&gt;why&lt;/em&gt; is Eliezer so doomerist?  Having read him since 2006, it strikes me that a huge part of it&amp;#8217;s that, no matter what AI safety proposal anyone comes up with, Eliezer has ready a &lt;em&gt;completely general counterargument&lt;/em&gt;.  Namely: &amp;#8220;yes, but the AI will be smarter than that.&amp;#8221;  In other words, no matter what you plan to do to make AI safer&amp;#8212;interpretability, backdoors, sandboxing, you name it&amp;#8212;the AI will have already foreseen it, and will have devised a countermeasure that your primate brain can&amp;#8217;t even conceive of because it&amp;#8217;s that much smarter than you.&lt;/p&gt;



&lt;p&gt;I confess that, after seeing enough examples of the &amp;#8220;fully general counterargument,&amp;#8221; at some point I&amp;#8217;m like, &amp;#8220;OK, what game are we even playing anymore?&amp;#8221;  If this is just a general refutation to any safety measure, then I suppose that, yes, &lt;em&gt;by hypothesis&lt;/em&gt;, we&amp;#8217;re screwed.  Yes, in a world where this counterargument is valid, we might as well give up and try to enjoy the time we have left.&lt;/p&gt;



&lt;p&gt;But you could also say: &lt;em&gt;for that very reason&lt;/em&gt;, it seems more useful to make the methodological assumption that we&amp;#8217;re &lt;em&gt;not&lt;/em&gt; in that world!  If we were, then what could we do, right?  So we might as well focus on the possible futures where AI emerges a bit more gradually, where we have time to see how it&amp;#8217;s going, learn from experience, improve our understanding, correct as we go&amp;#8212;in other words, the things that have &lt;em&gt;always&lt;/em&gt; been the prerequisites to scientific progress, and that have luckily always obtained, even if philosophically we never really had any right to expect them.  We might as well focus on the worlds where, for example, before we get an AI that successfully plots to kill all humans in a matter of seconds, we&amp;#8217;ll probably first get an AI that &lt;em&gt;tries&lt;/em&gt; to kill all humans but is really inept at it.  Now fortunately, I personally also regard the latter scenarios as the more plausible ones anyway.  But &lt;em&gt;even if you didn&amp;#8217;t&lt;/em&gt;&amp;#8212;again, methodologically, it seems to me that it&amp;#8217;d still make sense to focus on them.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Regarding your project on watermarking&amp;#8212;so in general, for discriminating between human and model outputs, what&amp;#8217;s the endgame?  Can watermarking win in the long run?  Will it just be an eternal arms race?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Scott:&lt;/strong&gt; Another great question.  One difficulty with watermarking is that it&amp;#8217;s hard even to formalize what the task is.  I mean, you could always take the output of an AI model and rephrase it using some &lt;em&gt;other&lt;/em&gt; AI model, for example, and catching all such things seems like an &lt;a href=&quot;https://en.wikipedia.org/wiki/AI-complete&quot;&gt;&amp;#8220;AI-complete problem.&amp;#8221;&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;On the other hand, I can think of writers&amp;#8212;Shakespeare, Wodehouse, David Foster Wallace&amp;#8212;who have such a distinctive style that, even if they &lt;em&gt;tried&lt;/em&gt; to pretend to be someone else, they plausibly couldn&amp;#8217;t.  Everyone would recognize that it was them.  So, you could imagine trying to build an AI in the same way.  That is, it would be constructed from the ground up so that all of its outputs contained indelible marks, whether cryptographic or stylistic, giving away their origin.  The AI couldn&amp;#8217;t easily hide and pretend to be a human or anything else it wasn&amp;#8217;t.  Whether this is possible strikes me as an &lt;em&gt;extremely&lt;/em&gt; interesting question at the interface between AI and cryptography!  It&amp;#8217;s especially challenging if you impose one or more of the following conditions:&lt;/p&gt;



&lt;ol&gt;
&lt;li&gt;the AI&amp;#8217;s code and parameters should be public (in which case, people might easily be able to modify it to remove the watermarking),&lt;/li&gt;



&lt;li&gt;the AI should have at least some ability to modify itself, and&lt;/li&gt;



&lt;li&gt;the means of &lt;em&gt;checking&lt;/em&gt; for the watermark should be public (in which case, again, the watermark might be easier to understand and remove).&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;I don&amp;#8217;t actually have a good intuition as to which side will ultimately win this contest, the AIs trying to conceal themselves or the watermarking schemes trying to reveal them, the Replicants or the &lt;a href=&quot;https://en.wikipedia.org/wiki/Blade_Runner#Voight-Kampff_machine&quot;&gt;Voight-Kampff machines&lt;/a&gt;.&lt;/p&gt;



&lt;p&gt;Certainly in the watermarking scheme that I&amp;#8217;m working on now, we crucially exploit the fact that OpenAI controls its own servers.  So, it can do the watermarking using a secret key, and it can check for the watermark using the same key.  In a world where anyone could build their own text model that was just as good as GPT &amp;#8230; what would you do there?&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-11-29 05:50:03 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>Extractors for Images of Varieties</title>
  <guid>http://arxiv.org/abs/2211.14497</guid>
  <link>http://arxiv.org/abs/2211.14497</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1&quot;&gt;Zeyu Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volk_B/0/1/0/all/0/1&quot;&gt;Ben Lee Volk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jalan_A/0/1/0/all/0/1&quot;&gt;Akhil Jalan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuckerman_D/0/1/0/all/0/1&quot;&gt;David Zuckerman&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We construct explicit deterministic extractors for polynomial images of
varieties, that is, distributions sampled by applying a low-degree polynomial
map $f : \mathbb{F}_q^r \to \mathbb{F}_q^n$ to an element sampled uniformly at
random from a $k$-dimensional variety $V \subseteq \mathbb{F}_q^r$. This class
of sources generalizes both polynomial sources, studied by Dvir, Gabizon and
Wigderson (FOCS 2007, Comput. Complex. 2009), and variety sources, studied by
Dvir (CCC 2009, Comput. Complex. 2012).
&lt;/p&gt;
&lt;p&gt;Assuming certain natural non-degeneracy conditions on the map $f$ and the
variety $V$, which in particular ensure that the source has enough min-entropy,
we extract almost all the min-entropy of the distribution. Unlike the
Dvir-Gabizon-Wigderson and Dvir results, our construction works over large
enough finite fields of arbitrary characteristic. One key part of our
construction is an improved deterministic rank extractor for varieties. As a
by-product, we obtain explicit Noether normalization lemmas for affine
varieties and affine algebras.
&lt;/p&gt;
&lt;p&gt;Additionally, we generalize a construction of affine extractors with
exponentially small error due to Bourgain, Dvir and Leeman (Comput. Complex.
2016) by extending it to all finite prime fields of quasipolynomial size.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-29 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Derandomization under Different Resource Constraints</title>
  <guid>http://arxiv.org/abs/2211.14640</guid>
  <link>http://arxiv.org/abs/2211.14640</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1&quot;&gt;Samuel Epstein&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We provide another proof to the EL Theorem. We show the tradeoff between
compressibility of codebooks and their communication capacity. A resource
bounded version of the EL Theorem is proven. This is used to prove three
instances of resource bounded derandomization. This paper is in support of the
general claim that if the existence of an object can be proven with the
probabilistic method, then bounds on its Kolmogorov complexity can be proven as
well.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-29 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Maximizing the Probability of Fixation in the Positional Voter Model</title>
  <guid>http://arxiv.org/abs/2211.14676</guid>
  <link>http://arxiv.org/abs/2211.14676</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Petsinis_P/0/1/0/all/0/1&quot;&gt;Petros Petsinis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Pavlogiannis_A/0/1/0/all/0/1&quot;&gt;Andreas Pavlogiannis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Karras_P/0/1/0/all/0/1&quot;&gt;Panagiotis Karras&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Voter model is a well-studied stochastic process that models the invasion
of a novel trait $A$ (e.g., a new opinion, social meme, genetic mutation,
magnetic spin) in a network of individuals (agents, people, genes, particles)
carrying an existing resident trait $B$. Individuals change traits by
occasionally sampling the trait of a neighbor, while an invasion bias
$\delta\geq 0$ expresses the stochastic preference to adopt the novel trait $A$
over the resident trait $B$. The strength of an invasion is measured by the
probability that eventually the whole population adopts trait $A$, i.e., the
fixation probability. In more realistic settings, however, the invasion bias is
not ubiquitous, but rather manifested only in parts of the network. For
instance, when modeling the spread of a social trait, the invasion bias
represents localized incentives. In this paper, we generalize the standard
biased Voter model to the positional Voter model, in which the invasion bias is
effectuated only on an arbitrary subset of the network nodes, called biased
nodes. We study the ensuing optimization problem, which is, given a budget $k$,
to choose $k$ biased nodes so as to maximize the fixation probability of a
randomly occurring invasion. We show that the problem is NP-hard both for
finite $\delta$ and when $\delta \rightarrow \infty$ (strong bias), while the
objective function is not submodular in either setting, indicating strong
computational hardness. On the other hand, we show that, when
$\delta\rightarrow 0$ (weak bias), we can obtain a tight approximation in
$O(n^{2\omega})$ time, where $\omega$ is the matrix-multiplication exponent. We
complement our theoretical results with an experimental evaluation of some
proposed heuristics.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-29 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Universal convex covering problems under translation and discrete rotations</title>
  <guid>http://arxiv.org/abs/2211.14807</guid>
  <link>http://arxiv.org/abs/2211.14807</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_M/0/1/0/all/0/1&quot;&gt;Mook Kwon Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1&quot;&gt;Sang Duk Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_H/0/1/0/all/0/1&quot;&gt;Hee-Kap Ahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tokuyama_T/0/1/0/all/0/1&quot;&gt;Takeshi Tokuyama&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the smallest-area universal covering of planar objects of
perimeter 2 (or equivalently closed curves of length 2) allowing translation
and discrete rotations. In particular, we show that the solution is an
equilateral triangle of height 1 when translation and discrete rotation of
$\pi$ are allowed. Our proof is purely geometric and elementary. We also give
convex coverings of closed curves of length 2 under translation and discrete
rotations of multiples of $\pi/2$ and $2\pi/3$. We show a minimality of the
covering for discrete rotation of multiples of $\pi/2$, which is an equilateral
triangle of height smaller than 1, and conjecture that the covering is the
smallest-area convex covering. Finally, we give the smallest-area convex
coverings of all unit segments under translation and discrete rotations
$2\pi/k$ for all integers $k\ge 3$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-29 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Hardness Results for Minimizing the Covariance of Randomly Signed Sum of Vectors</title>
  <guid>http://arxiv.org/abs/2211.14658</guid>
  <link>http://arxiv.org/abs/2211.14658</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Peng Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given vectors $\mathbb{v}_1, \ldots, \mathbb{v}_n \in \mathbb{R}^d$ with
Euclidean norm at most $1$ and $\mathbb{x}_0 \in [-1,1]^n$, our goal is to
sample a random signing $\mathbb{x} \in \{\pm 1\}^n$ with
$\mathbb{E}[\mathbb{x}] = \mathbb{x}_0$ such that the operator norm of the
covariance of the signed sum of the vectors $\sum_{i=1}^n \mathbb{x}(i)
\mathbb{v}_i$ is as small as possible. This problem arises from the algorithmic
discrepancy theory and its application in the design of randomized experiments.
It is known that one can sample a random signing with expectation
$\mathbb{x}_0$ and the covariance operator norm at most $1$.
&lt;/p&gt;
&lt;p&gt;In this paper, we prove two hardness results for this problem. First, we show
it is NP-hard to distinguish a list of vectors for which there exists a random
signing with expectation ${\bf 0}$ such that the operator norm is $0$ from
those for which any signing with expectation ${\bf 0}$ must have the operator
norm $\Omega(1)$. Second, we consider $\mathbb{x}_0 \in [-1,1]^n$ whose entries
are all around an arbitrarily fixed $p \in [-1,1]$. We show it is NP-hard to
distinguish a list of vectors for which there exists a random signing with
expectation $\mathbb{x}_0$ such that the operator norm is $0$ from those for
which any signing with expectation ${\bf 0}$ must have the operator norm
$\Omega((1-|p|)^2)$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-29 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Faster Algorithm for Structured John Ellipsoid Computation</title>
  <guid>http://arxiv.org/abs/2211.14407</guid>
  <link>http://arxiv.org/abs/2211.14407</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yuanyuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Computing John Ellipsoid is a fundamental problem in machine learning and
convex optimization, where the goal is to compute the ellipsoid with maximal
volume that lies in a given convex centrally symmetric polytope defined by a
matrix $A \in \mathbb{R}^{n \times d}$. In this work, we show two faster
algorithms for approximating the John Ellipsoid.
&lt;/p&gt;
&lt;p&gt;$\bullet$ For sparse matrix $A$, we can achieve nearly input sparsity time
$\mathrm{nnz}(A) + d^{\omega}$, where $\omega$ is exponent of matrix
multiplication. Currently, $\omega \approx 2.373$.
&lt;/p&gt;
&lt;p&gt;$\bullet$ For the matrix $A$ which has small treewidth $\tau$, we can achieve
$n \tau^2$ time.
&lt;/p&gt;
&lt;p&gt;Therefore, we significantly improves the state-of-the-art results on
approximating the John Ellipsoid for centrally symmetric polytope [Cohen,
Cousins, Lee, and Yang COLT 2019] which takes $nd^2$ time.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-29 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Equity Promotion in Public Transportation</title>
  <guid>http://arxiv.org/abs/2211.14531</guid>
  <link>http://arxiv.org/abs/2211.14531</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pramanik_A/0/1/0/all/0/1&quot;&gt;Anik Pramanik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Pan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yifan Xu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;There are many news articles reporting the obstacles confronting
poverty-stricken households in access to public transits. These barriers create
a great deal of inconveniences for these impoverished families and more
importantly, they contribute a lot of social inequalities. A typical approach
addressing the issue is to build more transport infrastructure to offer more
opportunities to access the public transits especially for those deprived
communities. Examples include adding more bus lines connecting needy residents
to railways systems and extending existing bus lines to areas with low
socioeconomic status. Recently, a new strategy is proposed, which is to harness
the ubiquitous ride-hailing services to connect disadvantaged households with
the nearest public transportations. Compared with the former
infrastructure-based solution, the ride-hailing-based strategy enjoys a few
exclusive benefits such as higher effectiveness and more flexibility.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose an optimization model to study how to integrate the
two approaches together for equity-promotion purposes. Specifically, we aim to
design a strategy of allocating a given limited budget to different candidate
programs such that the overall social equity is maximized, which is defined as
the minimum covering ratio among all pre-specified protected groups of
households (based on race, income, etc.). We have designed a linear-programming
(LP) based rounding algorithm, which proves to achieve an optimal approximation
ratio of 1-1/e. Additionally, we test our algorithm against a few baselines on
real data assembled by outsourcing multiple public datasets collected in the
city of Chicago. Experimental results confirm our theoretical predictions and
demonstrate the effectiveness of our LP-based strategy in promoting social
equity, especially when the budget is insufficient.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-29 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Identifying a 3-vertex strongly biconnected directed subgraph with minimum number of edges</title>
  <guid>http://arxiv.org/abs/2211.14572</guid>
  <link>http://arxiv.org/abs/2211.14572</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habib_A/0/1/0/all/0/1&quot;&gt;Azzam Habib&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A strongly connected graph is strongly biconnected if after ignoring the
direction of its edges we have an undirected graph with no articulation points.
A 3-vertex strongly biconnected graph is a strongly biconnected digraph that
has the property that deleting any two vertices in this graph leaves a strongly
binconnected subgraph. Jaberi [11] presented approximation algorithms for
minimum cardinality 2-vertex strongly biconnected directed subgraph problem. We
will focus in this paper on polynomial time algorithms which we have
implemented for producing spanning subgraphs that are 3-vertex strongly
biconnected.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-29 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Lower Bounds on Retroactive Data Structures</title>
  <guid>http://arxiv.org/abs/2211.14664</guid>
  <link>http://arxiv.org/abs/2211.14664</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chung_L/0/1/0/all/0/1&quot;&gt;Lily Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demaine_E/0/1/0/all/0/1&quot;&gt;Erik D. Demaine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendrickson_D/0/1/0/all/0/1&quot;&gt;Dylan Hendrickson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lynch_J/0/1/0/all/0/1&quot;&gt;Jayson Lynch&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove essentially optimal fine-grained lower bounds on the gap between a
data structure and a partially retroactive version of the same data structure.
Precisely, assuming any one of three standard conjectures, we describe a
problem that has a data structure where operations run in $O(T(n,m))$ time per
operation, but any partially retroactive version of that data structure
requires $T(n,m) \cdot m^{1-o(1)}$ worst-case time per operation, where $n$ is
the size of the data structure at any time and $m$ is the number of operations.
Any data structure with operations running in $O(T(n,m))$ time per operation
can be converted (via the &quot;rollback method&quot;) into a partially retroactive data
structure running in $O(T(n,m) \cdot m)$ time per operation, so our lower bound
is tight up to an $m^{o(1)}$ factor common in fine-grained complexity.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-29 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Would you be more productive if you didn&#39;t log on?  It worked for Christopher Havens!</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-7687955095057549080</guid>
  <link>http://blog.computationalcomplexity.org/2022/11/would-you-be-more-productive-if-you.html</link>
  <description>
    &lt;div&gt;There are times when NOT having computer access (is that possible anymore?) can make you MORE productive.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;1) I did a lot of my Muffin Work when I was in Mexico for a bar matzah and had no computer access, and no Television in English (though &lt;i&gt;Texas Walker Ranger&lt;/i&gt;, and &lt;i&gt;Kindergarden Cop,&lt;/i&gt; were actually pretty good in Spanish even though I don&#39;t now Spanish.)&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;2) I did work on NIM with Cash when I was stuck at an airport for 8 hours.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;3) I proofread (on paper!) most of my book with Erik D and Mohammad H when I was at a relatives house for four days&amp;nbsp; who had weak wifi and only got&amp;nbsp; ABC, NBC, CBS, PBS, some local channels, and COZI (not sure why they got COZI, though I am glad since I caught a good episode of&lt;i&gt; Columbo&lt;/i&gt;).&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;4) Thanksgiving at my Mom&#39;s apartment (she&#39;s 93 years young!), with no computer,&amp;nbsp; I relearned the proof of the Hales-Jewitt theorem. I seem to learn/forget/learn/forget that one a lot.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;There are times when being AWAY from technology is helpful. I sometimes go to the Math Library and try to NOT use my cell phone.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Having said that I do think that&lt;b&gt; overall&lt;/b&gt; having access to papers online is great and that overall academic productivity has increased.&amp;nbsp; But there are times when the computer can distract you and time AWAY from it is good.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Which brings us to the story of Christopher Havens. He works in Number Theory and logs on very rarely, perhaps never. He just works on math 10 hours a day. He has&amp;nbsp; a paper (with co-authors).&amp;nbsp; It take discipline to resist the urge to log on. How did he manage this?&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;He is in prison for murder.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=DPyWf4cI548&quot;&gt;Here&lt;/a&gt;&amp;nbsp;is a podcast with him as a guest.&amp;nbsp;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;https://44bars.com/christopher-havens-wikipedia-everything-to-know-about-his-mathematics-project/&quot;&gt;Here&lt;/a&gt;&amp;nbsp;is an article about him.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;https://arxiv.org/pdf/2002.12644.pdf&quot;&gt;Here&lt;/a&gt;&amp;nbsp;is a math article where he is a co-author.&amp;nbsp;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Here is the short version of all of this:&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;1) He is guilty of murder and in a max security prison in America.&amp;nbsp; It was a drug related shooting (why do people only talk about &lt;i&gt;drug deals gone bad&lt;/i&gt; when they should also talk about &lt;i&gt;drug deals gone good&lt;/i&gt;?) . When I first read &lt;i&gt;Prison Inmate Solves Math&lt;/i&gt; &lt;i&gt;Problem &lt;/i&gt;I thought that maybe a white collar criminal who majored in Math and was in a min security prison with access to the web (do white collar criminals have access to the web?)&amp;nbsp; But NO, Christopher Havens really did murder someone and is in max security.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;2) He really has turned his life around. He really is not the person he was, and when he gets out I cannot imagine he will go back to drugs and crime. I suspect he will work on the Math Prison Project which I mention later.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;3) His mother says that when he was in High School (which is as far as he got for education)&lt;/div&gt;&lt;div&gt;he was helping students in math who were&amp;nbsp; 2 grades above him, but he has no recollection of this.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;4) When he was the hole (solitary confinement) someone who did Prison Education gave him (and others, he was not picked out) an envelope of math problems to work on--- pre-algebra. Christopher did them well and liked it and began requesting more advanced math books and learned math by himself, working 10 hours a day. When he requested a book it was random which ones he would get. I don&#39;t know why some were blocked. I don&#39;t think he knows why some were blocked.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;5) Some mathematicians from Italy (Italy?) contacted him and they began corresponding and yada-yada-yada, he has a paper now.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;6) He has conceptualized the&amp;nbsp;&lt;a href=&quot;https://www.prisonmathproject.org/&quot;&gt;Math Prison Project&lt;/a&gt;&amp;nbsp;to help other prisoners do math, though I would suspect not on the level he is on.&amp;nbsp; Then again, maybe the reason that P vs NP is still open is that we all have to many distractions, and conference deadlines, that a prisoner would not have.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;7) Some articles say that he solved a ancient problem in math that Euclid couldn&#39;t solve. This is not true. He helped solve some problems about continued fractions.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;8) There is going to be a movie about him, see&amp;nbsp;&lt;a href=&quot;https://deadline.com/2022/02/neil-burger-dirk-wittenborn-johnny-lins-clandestine-laureate-biopic-christopher-havens-1234958309/&quot;&gt;here&lt;/a&gt;. I predict it will take an interesting story and make it less interesting and more fictional.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;What to make of all this?&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;1) KUDOS to him!&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;2) I don&#39;t know which side of the nature/nurture argument this goes to&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;a) He OBVIOUSLY had math talent naturally or else he couldn&#39;t have learned all of that math.&lt;/div&gt;&lt;div&gt;b) He shows that HARD WORK and TENACITY can overcome other issue.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;3) back to my original point- if you had the FREEDOM to work 10 hours a day JUST on math and had no other distractions, but also limited access to books and people,&amp;nbsp; would you be MORE productive? LESS productive? Also note- no faculty meetings, no teaching obligations, and no word processor to distract you.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 23:47:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>TAU Computer Science Theory-Fest 2022</title>
  <guid>http://cstheory-events.org/2022/11/28/tau-computer-science-theory-fest-2022/</guid>
  <link>https://cstheory-events.org/2022/11/28/tau-computer-science-theory-fest-2022/</link>
  <description>
    December 26-28, 2022 Northern Tel Aviv, TAU campus, ANU Museum (Tisch Hall) https://sites.google.com/view/tautheory-fest2022/home We at the Tel Aviv University School of Computer Science are pleased to announce our conference, TAU Theory Fest 2022. The purpose of the conference is for academics of the highest quality to present current research in the field of Theory of &amp;#8230; &lt;a href=&quot;https://cstheory-events.org/2022/11/28/tau-computer-science-theory-fest-2022/&quot; class=&quot;more-link&quot;&gt;Continue reading &lt;span class=&quot;screen-reader-text&quot;&gt;TAU Computer Science Theory-Fest&amp;#160;2022&lt;/span&gt;&lt;/a&gt;&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 14:43:00 UTC</pubDate>
  <author>CS Theory Events</author>
</item>

<item>
  <title>The World Dynamics Project</title>
  <guid>tag:blogger.com,1999:blog-27705661.post-181982905013238781</guid>
  <link>http://processalgebra.blogspot.com/2022/11/the-world-dynamics-project.html</link>
  <description>
    &lt;p&gt;Our colleagues &lt;a href=&quot;https://www.pilucrescenzi.it/&quot; target=&quot;_blank&quot;&gt;Pierluigi Crescenzi&lt;/a&gt;, &lt;a href=&quot;https://natema.github.io/ema-webpage/&quot; target=&quot;_blank&quot;&gt;Emanuele Natale &lt;/a&gt;and &lt;a href=&quot;https://paulobruno.github.io/&quot; target=&quot;_blank&quot;&gt;Paulo Bruno Serafim&lt;/a&gt; have been doing some work on what they call the &lt;a href=&quot;https://github.com/worlddynamics/WorldDynamics.jl&quot; target=&quot;_blank&quot;&gt;World Dynamics project&lt;/a&gt;, whose goal is to provide a modern framework for studying models of sustainable development, based on cutting-edge techniques from software engineering and machine learning.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The first outcome of their work is a &lt;a href=&quot;https://julialang.org/&quot; target=&quot;_blank&quot;&gt;Julia&lt;/a&gt; library that allows scientists to use and adapt different world models, from &lt;a href=&quot;https://en.wikipedia.org/wiki/World3&quot; target=&quot;_blank&quot;&gt;Meadows et al.&#39;s World3&lt;/a&gt; to recent proposals, in an easy way. &lt;/p&gt;&lt;p&gt;IMHO, this is a fascinating and timely research effort. I encourage readers of this blog to try the current version of the Julia library, which is still under development. It would be great if this library contributed to &quot;an open, interdisciplinary, and consistent comparative approach to scientific model development&quot; and I hope that global policy makers on environmental and economic issues will use similar tools in the nearest future.&lt;/p&gt;&lt;p&gt;Thanks to Emanuele, Paulo and Pierluigi for their work. I&#39;ll be following its future development with great interest.&lt;/p&gt;&lt;p&gt;If you speak Italian, I strongly recommend &lt;a href=&quot;https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5tZWdhcGhvbmUuZm0vc2lkZWNhcg/episode/NTcxZDY1NmMtYjgxMy00NjNkLWFmMDEtYmZjZDdlZjhkOTQ1?sa=X&amp;amp;ved=0CAUQkfYCahcKEwjg_KaO_tD7AhUAAAAAHQAAAAAQAQ&quot; target=&quot;_blank&quot;&gt;this podcast&lt;/a&gt;, in the &lt;a href=&quot;https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5tZWdhcGhvbmUuZm0vc2lkZWNhcg&quot; target=&quot;_blank&quot;&gt;GSSI-SISSA Sidecar series&lt;/a&gt;, in which Pierluigi discusses economic growth with &lt;a href=&quot;https://en.wikipedia.org/wiki/Michele_Boldrin&quot; target=&quot;_blank&quot;&gt;Michele Boldrin&lt;/a&gt;.&lt;br /&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Luca Aceto&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 13:26:00 UTC</pubDate>
  <author>Luca Aceto</author>
</item>

<item>
  <title>A Moment-Matching Approach to Testable Learning and a New Characterization of Rademacher Complexity</title>
  <guid>http://arxiv.org/abs/2211.13312</guid>
  <link>http://arxiv.org/abs/2211.13312</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gollakota_A/0/1/0/all/0/1&quot;&gt;Aravind Gollakota&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1&quot;&gt;Adam R. Klivans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1&quot;&gt;Pravesh K. Kothari&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A remarkable recent paper by Rubinfeld and Vasilyan (2022) initiated the
study of \emph{testable learning}, where the goal is to replace hard-to-verify
distributional assumptions (such as Gaussianity) with efficiently testable ones
and to require that the learner succeed whenever the unknown distribution
passes the corresponding test. In this model, they gave an efficient algorithm
for learning halfspaces under testable assumptions that are provably satisfied
by Gaussians.
&lt;/p&gt;
&lt;p&gt;In this paper we give a powerful new approach for developing algorithms for
testable learning using tools from moment matching and metric distances in
probability. We obtain efficient testable learners for any concept class that
admits low-degree \emph{sandwiching polynomials}, capturing most important
examples for which we have ordinary agnostic learners. We recover the results
of Rubinfeld and Vasilyan as a corollary of our techniques while achieving
improved, near-optimal sample complexity bounds for a broad range of concept
classes and distributions.
&lt;/p&gt;
&lt;p&gt;Surprisingly, we show that the information-theoretic sample complexity of
testable learning is tightly characterized by the Rademacher complexity of the
concept class, one of the most well-studied measures in statistical learning
theory. In particular, uniform convergence is necessary and sufficient for
testable learning. This leads to a fundamental separation from (ordinary)
distribution-specific agnostic learning, where uniform convergence is
sufficient but not necessary.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>On the Complexity of Counterfactual Reasoning</title>
  <guid>http://arxiv.org/abs/2211.13447</guid>
  <link>http://arxiv.org/abs/2211.13447</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yunqiu Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yizuo Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darwiche_A/0/1/0/all/0/1&quot;&gt;Adnan Darwiche&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the computational complexity of counterfactual reasoning in relation
to the complexity of associational and interventional reasoning on structural
causal models (SCMs). We show that counterfactual reasoning is no harder than
associational or interventional reasoning on fully specified SCMs in the
context of two computational frameworks. The first framework is based on the
notion of treewidth and includes the classical variable elimination and
jointree algorithms. The second framework is based on the more recent and
refined notion of causal treewidth which is directed towards models with
functional dependencies such as SCMs. Our results are constructive and based on
bounding the (causal) treewidth of twin networks -- used in standard
counterfactual reasoning that contemplates two worlds, real and imaginary -- to
the (causal) treewidth of the underlying SCM structure. In particular, we show
that the latter (causal) treewidth is no more than twice the former plus one.
Hence, if associational or interventional reasoning is tractable on a fully
specified SCM then counterfactual reasoning is tractable too. We extend our
results to general counterfactual reasoning that requires contemplating more
than two worlds and discuss applications of our results to counterfactual
reasoning with a partially specified SCM that is coupled with data. We finally
present empirical results that measure the gap between the complexities of
counterfactual reasoning and associational/interventional reasoning on random
SCMs.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Communication Complexity of Inner Product in Symmetric Normed Spaces</title>
  <guid>http://arxiv.org/abs/2211.13473</guid>
  <link>http://arxiv.org/abs/2211.13473</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andoni_A/0/1/0/all/0/1&quot;&gt;Alexandr Andoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1&quot;&gt;Jaros&amp;#x142;aw B&amp;#x142;asiok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filtser_A/0/1/0/all/0/1&quot;&gt;Arnold Filtser&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce and study the communication complexity of computing the inner
product of two vectors, where the input is restricted w.r.t. a norm $N$ on the
space $\mathbb{R}^n$. Here, Alice and Bob hold two vectors $v,u$ such that
$\|v\|_N\le 1$ and $\|u\|_{N^*}\le 1$, where $N^*$ is the dual norm. They want
to compute their inner product $\langle v,u \rangle$ up to an $\varepsilon$
additive term. The problem is denoted by $\mathrm{IP}_N$.
&lt;/p&gt;
&lt;p&gt;We systematically study $\mathrm{IP}_N$, showing the following results:
&lt;/p&gt;
&lt;p&gt;- For any symmetric norm $N$, given $\|v\|_N\le 1$ and $\|u\|_{N^*}\le 1$
there is a randomized protocol for $\mathrm{IP}_N$ using
$\tilde{\mathcal{O}}(\varepsilon^{-6} \log n)$ bits -- we will denote this by
$\mathcal{R}_{\varepsilon,1/3}(\mathrm{IP}_{N}) \leq
\tilde{\mathcal{O}}(\varepsilon^{-6} \log n)$.
&lt;/p&gt;
&lt;p&gt;- One way communication complexity
$\overrightarrow{\mathcal{R}}(\mathrm{IP}_{\ell_p})\leq\mathcal{O}(\varepsilon^{-\max(2,p)}\cdot
\log\frac n\varepsilon)$, and a nearly matching lower bound
$\overrightarrow{\mathcal{R}}(\mathrm{IP}_{\ell_p}) \geq
\Omega(\varepsilon^{-\max(2,p)})$ for $\varepsilon^{-\max(2,p)} \ll n$.
&lt;/p&gt;
&lt;p&gt;- One way communication complexity $\overrightarrow{\mathcal{R}}(N)$ for a
symmetric norm $N$ is governed by embeddings $\ell_\infty^k$ into $N$.
Specifically, while a small distortion embedding easily implies a lower bound
$\Omega(k)$, we show that, conversely, non-existence of such an embedding
implies protocol with communication $k^{\mathcal{O}(\log \log k)} \log^2 n$.
&lt;/p&gt;
&lt;p&gt;- For arbitrary origin symmetric convex polytope $P$, we show
$\mathcal{R}(\mathrm{IP}_{N}) \le\mathcal{O}(\varepsilon^{-2} \log
\mathrm{xc}(P))$, where $N$ is the unique norm for which $P$ is a unit ball,
and $\mathrm{xc}(P)$ is the extension complexity of $P$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Many bounded versions of undecidable problems are NP-hard</title>
  <guid>http://arxiv.org/abs/2211.13532</guid>
  <link>http://arxiv.org/abs/2211.13532</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Klingler_A/0/1/0/all/0/1&quot;&gt;Andreas Klingler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Eyden_M/0/1/0/all/0/1&quot;&gt;Mirte van der Eyden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Stengele_S/0/1/0/all/0/1&quot;&gt;Sebastian Stengele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Reinhart_T/0/1/0/all/0/1&quot;&gt;Tobias Reinhart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Cuevas_G/0/1/0/all/0/1&quot;&gt;Gemma De las Cuevas&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Several physically inspired problems have been proven undecidable; examples
are the spectral gap problem and the membership problem for quantum
correlations. Most of these results rely on reductions from a handful of
undecidable problems, such as the halting problem, the tiling problem, the Post
correspondence problem or the matrix mortality problem. All these problems have
a common property: they have an NP-hard bounded version. This work establishes
a relation between undecidable unbounded problems and their bounded NP-hard
versions. Specifically, we show that NP-hardness of a bounded version follows
easily from the reduction of the unbounded problems. This leads to new and
simpler proofs of the NP-hardness of bounded version of the Post correspondence
problem, the matrix mortality problem, the positivity of matrix product
operators, the reachability problem, the tiling problem, and the ground state
energy problem. This work sheds light on the intractability of problems in
theoretical physics and on the computational consequences of bounding a
parameter.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Parallel Repetition for the GHZ Game: Exponential Decay</title>
  <guid>http://arxiv.org/abs/2211.13741</guid>
  <link>http://arxiv.org/abs/2211.13741</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braverman_M/0/1/0/all/0/1&quot;&gt;Mark Braverman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khot_S/0/1/0/all/0/1&quot;&gt;Subhash Khot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1&quot;&gt;Dor Minzer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that the value of the $n$-fold repeated GHZ game is at most
$2^{-\Omega(n)}$, improving upon the polynomial bound established by Holmgren
and Raz. Our result is established via a reduction to approximate subgroup type
questions from additive combinatorics.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Quantum Adversarial Learning in Emulation of Monte-Carlo Methods for Max-cut Approximation: QAOA is not optimal</title>
  <guid>http://arxiv.org/abs/2211.13767</guid>
  <link>http://arxiv.org/abs/2211.13767</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Unsal_C/0/1/0/all/0/1&quot;&gt;Cem M. Unsal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Brady_L/0/1/0/all/0/1&quot;&gt;Lucas T. Brady&lt;/a&gt;&lt;/p&gt;&lt;p&gt;One of the leading candidates for near-term quantum advantage is the class of
Variational Quantum Algorithms, but these algorithms suffer from classical
difficulty in optimizing the variational parameters as the number of parameters
increases. Therefore, it is important to understand the expressibility and
power of various ans\&quot;atze to produce target states and distributions. To this
end, we apply notions of emulation to Variational Quantum Annealing and the
Quantum Approximate Optimization Algorithm (QAOA) to show that QAOA is
outperformed by variational annealing schedules with equivalent numbers of
parameters. Our Variational Quantum Annealing schedule is based on a novel
polynomial parameterization that can be optimized in a similar gradient-free
way as QAOA, using the same physical ingredients. In order to compare the
performance of ans\&quot;atze types, we have developed statistical notions of
Monte-Carlo methods. Monte-Carlo methods are computer programs that generate
random variables that approximate a target number that is computationally hard
to calculate exactly. While the most well-known Monte-Carlo method is
Monte-Carlo integration (e.g. Diffusion Monte-Carlo or path-integral quantum
Monte-Carlo), QAOA is itself a Monte-Carlo method that finds good solutions to
NP-complete problems such as Max-cut. We apply these statistical Monte-Carlo
notions to further elucidate the theoretical framework around these quantum
algorithms.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Approximating the chromatic polynomial is as hard as computing it exactly</title>
  <guid>http://arxiv.org/abs/2211.13790</guid>
  <link>http://arxiv.org/abs/2211.13790</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bencs_F/0/1/0/all/0/1&quot;&gt;Ferenc Bencs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huijben_J/0/1/0/all/0/1&quot;&gt;Jeroen Huijben&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regts_G/0/1/0/all/0/1&quot;&gt;Guus Regts&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that for any non-real algebraic number $q$ such that $|q-1|&amp;gt;1$ or
$\Re(q)&amp;gt;\frac{3}{2}$ it is \textsc{\#P}-hard to compute a multiplicative (resp.
additive) approximation to the absolute value (resp. argument) of the chromatic
polynomial evaluated at $q$ on planar graphs. This implies
\textsc{\#P}-hardness for all non-real algebraic $q$ on the family of all
graphs. We moreover prove several hardness results for $q$ such that $|q-1|\leq
1$.
&lt;/p&gt;
&lt;p&gt;Our hardness results are obtained by showing that a polynomial time algorithm
for approximately computing the chromatic polynomial of a planar graph at
non-real algebraic $q$ (satisfying some properties) leads to a polynomial time
algorithm for \emph{exactly} computing it, which is known to be hard by a
result of Vertigan. Many of our results extend in fact to the more general
partition function of the random cluster model, a well known reparametrization
of the Tutte polynomial.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Improved Elekes-Szab\&#39;o type estimates using proximity</title>
  <guid>http://arxiv.org/abs/2211.13294</guid>
  <link>http://arxiv.org/abs/2211.13294</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Solymosi_J/0/1/0/all/0/1&quot;&gt;Jozsef Solymosi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zahl_J/0/1/0/all/0/1&quot;&gt;Joshua Zahl&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove a new Elekes-Szab\&#39;o type estimate on the size of the intersection
of a Cartesian product $A\times B\times C$ with an algebraic surface $\{f=0\}$
over the reals. In particular, if $A,B,C$ are sets of $N$ real numbers and $f$
is a trivariate polynomial, then either $f$ has a special form that encodes
additive group structure (for example $f(x,y,x) = x + y - z$), or $A \times
B\times C \cap\{f=0\}$ has cardinality $O(N^{12/7})$. This is an improvement
over the previously bound $O(N^{11/6})$. We also prove an asymmetric version of
our main result, which yields an Elekes-Ronyai type expanding polynomial
estimate with exponent $3/2$. This has applications to questions in
combinatorial geometry related to the Erd\H{o}s distinct distances problem.
&lt;/p&gt;
&lt;p&gt;Like previous approaches to the problem, we rephrase the question as a $L^2$
estimate, which can be analyzed by counting additive quadruples. The latter
problem can be recast as an incidence problem involving points and curves in
the plane. The new idea in our proof is that we use the order structure of the
reals to restrict attention to a smaller collection of proximate additive
quadruples.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Reduction Algorithms for Persistence Diagrams of Networks: CoralTDA and PrunIT</title>
  <guid>http://arxiv.org/abs/2211.13708</guid>
  <link>http://arxiv.org/abs/2211.13708</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akcora_C/0/1/0/all/0/1&quot;&gt;Cuneyt Gurcan Akcora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kantarcioglu_M/0/1/0/all/0/1&quot;&gt;Murat Kantarcioglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gel_Y/0/1/0/all/0/1&quot;&gt;Yulia R. Gel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coskunuzer_B/0/1/0/all/0/1&quot;&gt;Baris Coskunuzer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Topological data analysis (TDA) delivers invaluable and complementary
information on the intrinsic properties of data inaccessible to conventional
methods. However, high computational costs remain the primary roadblock
hindering the successful application of TDA in real-world studies, particularly
with machine learning on large complex networks.
&lt;/p&gt;
&lt;p&gt;Indeed, most modern networks such as citation, blockchain, and online social
networks often have hundreds of thousands of vertices, making the application
of existing TDA methods infeasible. We develop two new, remarkably simple but
effective algorithms to compute the exact persistence diagrams of large graphs
to address this major TDA limitation. First, we prove that $(k+1)$-core of a
graph $\mathcal{G}$ suffices to compute its $k^{th}$ persistence diagram,
$PD_k(\mathcal{G})$. Second, we introduce a pruning algorithm for graphs to
compute their persistence diagrams by removing the dominated vertices. Our
experiments on large networks show that our novel approach can achieve
computational gains up to 95%.
&lt;/p&gt;
&lt;p&gt;The developed framework provides the first bridge between the graph theory
and TDA, with applications in machine learning of large complex networks. Our
implementation is available at
https://github.com/cakcora/PersistentHomologyWithCoralPrunit
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Space-efficient RLZ-to-LZ77 conversion</title>
  <guid>http://arxiv.org/abs/2211.13254</guid>
  <link>http://arxiv.org/abs/2211.13254</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1&quot;&gt;Travis Gagie&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Consider a text $T [1..n]$ prefixed by a reference sequence $R = T
[1..\ell]$. We show how, given $R$ and the $z&#39;$-phrase relative Lempel-Ziv
parse of $T [\ell + 1..n]$ with respect to $R$, we can build the LZ77 parse of
$T$ in $n\,\mathrm{polylog} (n)$ time and $O (\ell + z&#39;)$ total space.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Learning and Testing Latent-Tree Ising Models Efficiently</title>
  <guid>http://arxiv.org/abs/2211.13291</guid>
  <link>http://arxiv.org/abs/2211.13291</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1&quot;&gt;Davin Choo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dagan_Y/0/1/0/all/0/1&quot;&gt;Yuval Dagan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1&quot;&gt;Constantinos Daskalakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kandiros_A/0/1/0/all/0/1&quot;&gt;Anthimos Vardis Kandiros&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We provide time- and sample-efficient algorithms for learning and testing
latent-tree Ising models, i.e. Ising models that may only be observed at their
leaf nodes. On the learning side, we obtain efficient algorithms for learning a
tree-structured Ising model whose leaf node distribution is close in Total
Variation Distance, improving on the results of prior work. On the testing
side, we provide an efficient algorithm with fewer samples for testing whether
two latent-tree Ising models have leaf-node distributions that are close or far
in Total Variation distance. We obtain our algorithms by showing novel
localization results for the total variation distance between the leaf-node
distributions of tree-structured Ising models, in terms of their marginals on
pairs of leaves.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A fast and simple $O (z \log n)$-space index for finding approximately longest common substrings</title>
  <guid>http://arxiv.org/abs/2211.13434</guid>
  <link>http://arxiv.org/abs/2211.13434</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fagan_N/0/1/0/all/0/1&quot;&gt;Nick Fagan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Jorge Hermo Gonz&amp;#xe1;lez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1&quot;&gt;Travis Gagie&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We describe how, given a text $T [1..n]$ and a positive constant $\epsilon$,
we can build a simple $O (z \log n)$-space index, where $z$ is the number of
phrases in the LZ77 parse of $T$, such that later, given a pattern $P [1..m]$,
in $O (m \log \log z + \mathrm{polylog} (m + z))$ time and with high
probability we can find a substring of $P$ that occurs in $T$ and whose length
is at least a $(1 - \epsilon)$-fraction of the length of a longest common
substring of $P$ and $T$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Differentially Private Heatmaps</title>
  <guid>http://arxiv.org/abs/2211.13454</guid>
  <link>http://arxiv.org/abs/2211.13454</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1&quot;&gt;Badih Ghazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Junfeng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohlhoff_K/0/1/0/all/0/1&quot;&gt;Kai Kohlhoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Ravi Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1&quot;&gt;Pasin Manurangsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Navalpakkam_V/0/1/0/all/0/1&quot;&gt;Vidhya Navalpakkam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valliappan_N/0/1/0/all/0/1&quot;&gt;Nachiappan Valliappan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the task of producing heatmaps from users&#39; aggregated data while
protecting their privacy. We give a differentially private (DP) algorithm for
this task and demonstrate its advantages over previous algorithms on real-world
datasets.
&lt;/p&gt;
&lt;p&gt;Our core algorithmic primitive is a DP procedure that takes in a set of
distributions and produces an output that is close in Earth Mover&#39;s Distance to
the average of the inputs. We prove theoretical bounds on the error of our
algorithm under a certain sparsity assumption and that these are near-optimal.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Estimation of Similarity between DNA Sequences and Its Graphical Representation</title>
  <guid>http://arxiv.org/abs/2211.13462</guid>
  <link>http://arxiv.org/abs/2211.13462</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mondal_P/0/1/0/all/0/1&quot;&gt;Probir Mondal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Bioinformatics, which is now a well known field of study, originated in the
context of biological sequence analysis. Recently graphical representation
takes place for the research on DNA sequence. Research in biological sequence
is mainly based on the function and its structure. Bioinformatics finds wide
range of applications specifically in the domain of molecular biology which
focuses on the analysis of molecules viz. DNA, RNA, Protein etc. In this
review, we mainly deal with the similarity analysis between sequences and
graphical representation of DNA sequence.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Towards Better Bounds for Finding Quasi-Identifiers</title>
  <guid>http://arxiv.org/abs/2211.13882</guid>
  <link>http://arxiv.org/abs/2211.13882</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hildebrant_R/0/1/0/all/0/1&quot;&gt;Ryan Hildebrant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc-Tung Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ta_D/0/1/0/all/0/1&quot;&gt;Duy-Hoang Ta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vu_H/0/1/0/all/0/1&quot;&gt;Hoa T. Vu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We revisit the problem of finding small $\epsilon$-separation keys introduced
by Motwani and Xu (VLDB 07). In this problem, the input is $m$-dimensional
tuples $x_1,x_2,\ldots,x_n $. The goal is to find a small subset of coordinates
that separates at least $(1-\epsilon){n \choose 2}$ pairs of tuples. They
provided a fast algorithm that runs on $\Theta(m/\epsilon)$ tuples sampled
uniformly at random. We show that the sample size can be improved to
$\Theta(m/\sqrt{\epsilon})$. Our algorithm also enjoys a faster running time.
To obtain this result, we provide upper and lower bounds on the sample size to
solve the following decision problem. Given a subset of coordinates $A$, reject
if $A$ separates fewer than $(1-\epsilon){n \choose 2}$ pairs, and accept if
$A$ separates all pairs. The algorithm must be correct with probability at
least $1-\delta$ for all $A$. We show that for algorithms based on sampling:
&lt;/p&gt;
&lt;p&gt;- $\Theta(m/\sqrt{\epsilon})$ samples are sufficient and necessary so that
$\delta \leq e^{-m}$ and
&lt;/p&gt;
&lt;p&gt;- $\Omega(\sqrt{\frac{\log m}{\epsilon}})$ samples are necessary so that
$\delta$ is a constant.
&lt;/p&gt;
&lt;p&gt;Our analysis is based on a constrained version of the balls-into-bins
problem. We believe our analysis may be of independent interest. We also study
a related problem that asks for the following sketching algorithm: with given
parameters $\alpha,k$ and $\epsilon$, the algorithm takes a subset of
coordinates $A$ of size at most $k$ and returns an estimate of the number of
unseparated pairs in $A$ up to a $(1\pm\epsilon)$ factor if it is at least
$\alpha {n \choose 2}$. We show that even for constant $\alpha$ and success
probability, such a sketching algorithm must use $\Omega(mk \log
\epsilon^{-1})$ bits of space; on the other hand, uniform sampling yields a
sketch of size $\Theta(\frac{mk \log m}{\alpha \epsilon^2})$ for this purpose.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Synthesis Cost-Optimal Targeted Mutant Protein Libraries</title>
  <guid>http://arxiv.org/abs/2211.13898</guid>
  <link>http://arxiv.org/abs/2211.13898</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papamichail_D/0/1/0/all/0/1&quot;&gt;Dimitris Papamichail&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Febinger_M/0/1/0/all/0/1&quot;&gt;Madeline Febinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Almeda_S/0/1/0/all/0/1&quot;&gt;Shm Almeda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papamichail_G/0/1/0/all/0/1&quot;&gt;Georgios Papamichail&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Protein variant libraries produced by site-directed mutagenesis are a useful
tool utilized by protein engineers to explore variants with potentially
improved properties, such as activity and stability. These libraries are
commonly built by selecting residue positions and alternative beneficial
mutations for each position. All possible combinations are then constructed and
screened, by incorporating degenerate codons at mutation sites. These
degenerate codons often encode additional unwanted amino acids or even STOP
codons. Our study aims to take advantage of annealing based recombination of
oligonucleotides during synthesis and utilize multiple degenerate codons per
mutation site to produce targeted protein libraries devoid of unwanted
variants. Toward this goal we created an algorithm to calculate the minimum
number of degenerate codons necessary to specify any given amino acid set, and
a dynamic programming method that uses this algorithm to optimally partition a
DNA target sequence with degeneracies into overlapping oligonucleotides, such
that the total cost of synthesis of the target mutant protein library is
minimized. Computational experiments show that, for a modest increase in DNA
synthesis costs, beneficial variant yields in produced mutant libraries are
increased by orders of magnitude, an effect particularly pronounced in large
combinatorial libraries.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Combining Constructive and Perturbative Deep Learning Algorithms for the Capacitated Vehicle Routing Problem</title>
  <guid>http://arxiv.org/abs/2211.13922</guid>
  <link>http://arxiv.org/abs/2211.13922</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Torres_R/0/1/0/all/0/1&quot;&gt;Roberto Garc&amp;#xed;a-Torres&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macias_Infante_A/0/1/0/all/0/1&quot;&gt;Alitzel Adriana Macias-Infante&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conant_Pablos_S/0/1/0/all/0/1&quot;&gt;Santiago Enrique Conant-Pablos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortiz_Bayliss_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Carlos Ortiz-Bayliss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Terashima_Marin_H/0/1/0/all/0/1&quot;&gt;Hugo Terashima-Mar&amp;#xed;n&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Capacitated Vehicle Routing Problem is a well-known NP-hard problem that
poses the challenge of finding the optimal route of a vehicle delivering
products to multiple locations. Recently, new efforts have emerged to create
constructive and perturbative heuristics to tackle this problem using Deep
Learning. In this paper, we join these efforts to develop the Combined Deep
Constructor and Perturbator, which combines two powerful constructive and
perturbative Deep Learning-based heuristics, using attention mechanisms at
their core. Furthermore, we improve the Attention Model-Dynamic for the
Capacitated Vehicle Routing Problem by proposing a memory-efficient algorithm
that reduces its memory complexity by a factor of the number of nodes. Our
method shows promising results. It demonstrates a cost improvement in common
datasets when compared against other multiple Deep Learning methods. It also
obtains close results to the state-of-the art heuristics from the Operations
Research field. Additionally, the proposed memory efficient algorithm for the
Attention Model-Dynamic model enables its use in problem instances with more
than 100 nodes.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-28 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>TR22-170 |  The Complexity of the Shortest Vector Problem | 

	Huck Bennett</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/170</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/170</link>
  <description>
    Computational problems on point lattices play a central role in many areas of computer science including integer programming, coding theory, cryptanalysis, and especially the design of secure cryptosystems. In this survey, we present known results and open questions related to the complexity of the most important of these problems, the Shortest Vector Problem (SVP).
  </description>
  <pubDate>2022-11-27 05:46:17 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Postdoc at University of Toronto (apply by December 15, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/26/postdoc-at-university-of-toronto-apply-by-december-15-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/26/postdoc-at-university-of-toronto-apply-by-december-15-2022/</link>
  <description>
    &lt;p&gt;The theory group at the University of Toronto anticipates up to three postdoctoral positions beginning September 2023. We seek candidates from all areas of theoretical computer science including algorithms, complexity theory, cryptography, differential privacy, distributed computing, graph theory, quantum computing, and theoretical aspects of machine learning.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.cs.toronto.edu/theory/positions.html&quot;&gt;https://www.cs.toronto.edu/theory/positions.html&lt;/a&gt;&lt;br /&gt;
Email: sachdeva@cs.toronto.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-26 17:07:36 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>TR22-169 |  Extractors for Images of Varieties | 

	Zeyu Guo, 

	Ben Lee Volk, 

	Akhil Jalan, 

	David Zuckerman</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/169</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/169</link>
  <description>
    We construct explicit deterministic extractors for polynomial images of varieties, that is, distributions sampled by applying a low-degree polynomial map $f : \mathbb{F}_q^r \to \mathbb{F}_q^n$ to an element sampled uniformly at random from a $k$-dimensional variety $V \subseteq \mathbb{F}_q^r$. This class of sources generalizes both polynomial sources, studied by Dvir, Gabizon and Wigderson (FOCS 2007, Comput. Complex. 2009), and variety sources, studied by Dvir (CCC 2009, Comput. Complex. 2012).

  Assuming certain natural non-degeneracy conditions on the map $f$ and the variety $V$, which in particular ensure that the source has enough min-entropy, we extract almost all the min-entropy of the distribution. Unlike the Dvir-Gabizon-Wigderson and Dvir results, our construction works over large enough finite fields of arbitrary characteristic. One key part of our construction is an improved deterministic rank extractor for varieties. As a by-product, we obtain explicit Noether normalization lemmas for affine varieties and affine algebras.

  Additionally, we generalize a construction of affine extractors with exponentially small error due to Bourgain, Dvir and Leeman (Comput. Complex. 2016) by extending it to all finite prime fields of quasipolynomial size.
  </description>
  <pubDate>2022-11-26 12:06:05 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Postdoc at National University of Singapore (apply by February 15, 2023)</title>
  <guid>http://cstheory-jobs.org/2022/11/24/postdoc-at-national-university-of-singapore-apply-by-february-15-2023/</guid>
  <link>https://cstheory-jobs.org/2022/11/24/postdoc-at-national-university-of-singapore-apply-by-february-15-2023/</link>
  <description>
    &lt;p&gt;Postdoc positions hosted by Prashant Nalini Vasudevan. Looking for candidates with a strong background in theory interested in the foundations of cryptography, information-theoretic cryptography, or related areas of complexity theory and algorithms. See website for more details.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.comp.nus.edu.sg/~prashant/ads.html&quot;&gt;https://www.comp.nus.edu.sg/~prashant/ads.html&lt;/a&gt;&lt;br /&gt;
Email: prashant@comp.nus.edu.sg&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 11:49:05 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>TR22-168 |  A Proof of the Generalized Union-Closed Set Conjecture assuming the Union-Closed Set Conjecture | 

	Zubayir Kazi</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/168</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/168</link>
  <description>
    Abstract The Union Closed Set Conjecture states that if a set system X\subseteq\mathcal{P}([n]) is closed under pairwise unions, then there exists a\in[n] in at least half of the sets of X. We show that there is a very natural generalization of the union closed set conjecture which gives a lower bound for k-set subsets of [n]. This a stronger version of a Conjecture of (Nagel, 2022). We then prove the Conjecture conditional on the Union Closed Set Conjecture using invariants of Union-Closed sets. Additionally, we prove that there exists a k-set in .38^{k}|F| sets of a union closed set X for every n\geq k&amp;gt;0 using the recent improvements in (Gilmer, 2022) and (Alweiss et al, 2022). We explain why our result suggests a lack of sharpness of the original conjecture.
  </description>
  <pubDate>2022-11-24 10:14:14 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Two Round HotStuff</title>
  <guid>https://decentralizedthoughts.github.io/2022-11-24-two-round-HS/</guid>
  <link>https://decentralizedthoughts.github.io/2022-11-24-two-round-HS/</link>
  <description>
    In the first part of this post we describe a single-shot variation of Two Round HotStuff (see the HotStuff v1 paper) using Locked Broadcast that follows a similar path as our previous post on Paxos and Linear PBFT. In the second part, we describe a fully pipelined multi-shot State Machine...
  </description>
  <pubDate>2022-11-24 09:00:00 UTC</pubDate>
  <author>Decentralized Thoughts</author>
</item>

<item>
  <title>TCS+ talk: Wednesday, November 30 — Nicole Wein, DIMACS</title>
  <guid>http://tcsplus.wordpress.com/?p=649</guid>
  <link>https://tcsplus.wordpress.com/2022/11/23/tcs-talk-wednesday-november-30-nicole-wein-dimacs/</link>
  <description>
    &lt;p&gt;&lt;/p&gt;


&lt;p&gt;The next TCS+ talk will take place this coming Wednesday, November 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). &lt;a href=&quot;http://people.csail.mit.edu/nwein/&quot;&gt;&lt;strong&gt;Nicole Wein&lt;/strong&gt;&lt;/a&gt; from DIMACS will speak about &amp;#8220;&lt;em&gt;Online List Labeling: Breaking the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Clog%5E2+n&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Clog%5E2+n&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog%5E2+n&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;log^2 n&quot; class=&quot;latex&quot; /&gt; Barrier&lt;/em&gt;&amp;#8221; (abstract below).&lt;/p&gt;
&lt;p&gt;You can reserve a spot as an individual or a group to join us live by signing up on &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/next-tcs-talk&quot;&gt;the online form&lt;/a&gt;. Registration is &lt;em&gt;not&lt;/em&gt; required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/past-talks&quot;&gt;on our website&lt;/a&gt; afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/suggest-a-talk&quot;&gt;suggest&lt;/a&gt; a possible topic or speaker, please see &lt;a href=&quot;https://sites.google.com/view/tcsplus/&quot;&gt;the website&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;Abstract: The online list labeling problem is a basic primitive in data structures. The goal is to store a dynamically-changing set of n items in an array of m slots, while keeping the elements in sorted order. To do so, some items may need to be moved over time, and the goal is to minimize the number of items moved per insertion/deletion. When &lt;img src=&quot;https://s0.wp.com/latex.php?latex=m+%3D+Cn&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=m+%3D+Cn&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m+%3D+Cn&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;m = Cn&quot; class=&quot;latex&quot; /&gt; for some constant &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%3E1&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%3E1&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3E1&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C&amp;gt;1&quot; class=&quot;latex&quot; /&gt;, an upper bound of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%28%5Clog%5E2+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%28%5Clog%5E2+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28%5Clog%5E2+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(&amp;#92;log^2 n)&quot; class=&quot;latex&quot; /&gt; items moved per insertion/deletion has been known since 1981. There is a matching lower bound for deterministic algorithms, but for randomized algorithms, the best known lower bound is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;Omega(&amp;#92;log n)&quot; class=&quot;latex&quot; /&gt;, leaving a gap between upper and lower bounds. We improve the upper bound, providing a randomized data structure with expected &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%28%5Clog%5E%7B3%2F2%7D+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%28%5Clog%5E%7B3%2F2%7D+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28%5Clog%5E%7B3%2F2%7D+n%29&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(&amp;#92;log^{3/2} n)&quot; class=&quot;latex&quot; /&gt; items moved per insertion/deletion.&lt;/p&gt;
&lt;p&gt;Joint work with Michael Bender, Alexander Conway, Martin Farach-Colton, Hanna Komlos, and William Kuszmaul&lt;/p&gt;
&lt;/blockquote&gt;&lt;p class=&quot;authors&quot;&gt;By plustcs&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 04:20:07 UTC</pubDate>
  <author>TCS+ Seminar Series</author>
</item>

<item>
  <title>Shortest Odd Paths in Conservative Graphs: Connections and Complexity</title>
  <guid>http://arxiv.org/abs/2211.12862</guid>
  <link>http://arxiv.org/abs/2211.12862</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlotter_I/0/1/0/all/0/1&quot;&gt;Ildik&amp;#xf3; Schlotter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sebo_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe1;s Seb&amp;#x151;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present some reductions between optimization problems for undirected
conservative graphs, that is, edge-weighted graphs without negative cycles. We
settle the complexity of some of them, and exhibit some remaining challenges.
Our key result is that the shortest odd path problem between two given
vertices, and its variants, such as the shortest odd cycle problem through a
given vertex, turn out to be NP-hard, deciding a long-standing question by
Lov\&#39;asz (Open Problem 27 in Schrijver&#39;s book, 2003), in the negative. The
complexity of finding a shortest odd cycle for conservative weights or of
finding an odd $T$-join of minimum cardinality remains open. We finally relate
these problems to relevant, solved or hopeful variants.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The Stochastic Arrival Problem</title>
  <guid>http://arxiv.org/abs/2211.12982</guid>
  <link>http://arxiv.org/abs/2211.12982</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webster_T/0/1/0/all/0/1&quot;&gt;Thomas Webster&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study a new modification of the Arrival problem, which allows for nodes
that exhibit random as well as controlled behaviour, in addition to switching
nodes. We study the computational complexity of these extensions, building on
existing work on Reachability Switching Games. In particular, we show for
versions of the arrival problem involving just switching and random nodes it is
\PP{}-hard to decide if their value is greater than a half and we give a PSPACE
decision algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>On the Complexity of Finding a Diverse and Representative Committee using a Monotone, Separable Positional Multiwinner Voting Rule</title>
  <guid>http://arxiv.org/abs/2211.13217</guid>
  <link>http://arxiv.org/abs/2211.13217</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Relia_K/0/1/0/all/0/1&quot;&gt;Kunal Relia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Fairness in multiwinner elections, a growing line of research in
computational social choice, primarily concerns the use of constraints to
ensure fairness. Recent work proposed a model to find a diverse \emph{and}
representative committee and studied the model&#39;s computational aspects.
However, the work gave complexity results under major assumptions on how the
candidates and the voters are grouped. Here, we close this gap and classify the
complexity of finding a diverse and representative committee using a monotone,
separable positional multiwinner voting rule, conditioned \emph{only} on the
assumption that P $\neq$ NP.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Deterministic Approximation Algorithms for Volumes of Spectrahedra</title>
  <guid>http://arxiv.org/abs/2211.12541</guid>
  <link>http://arxiv.org/abs/2211.12541</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dogan_M/0/1/0/all/0/1&quot;&gt;Mahmut Levent Do&amp;#x11f;an&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leake_J/0/1/0/all/0/1&quot;&gt;Jonathan Leake&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravichandran_M/0/1/0/all/0/1&quot;&gt;Mohan Ravichandran&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give a method for computing asymptotic formulas and approximations for the
volumes of spectrahedra, based on the maximum-entropy principle from
statistical physics. The method gives an approximate volume formula based on a
single convex optimization problem of minimizing $-\log \det P$ over the
spectrahedron. Spectrahedra can be described as affine slices of the convex
cone of positive semi-definite (PSD) matrices, and the method yields efficient
deterministic approximation algorithms and asymptotic formulas whenever the
number of affine constraints is sufficiently dominated by the dimension of the
PSD cone.
&lt;/p&gt;
&lt;p&gt;Our approach is inspired by the work of Barvinok and Hartigan who used an
analogous framework for approximately computing volumes of polytopes.
Spectrahedra, however, possess a remarkable feature not shared by polytopes, a
new fact that we also prove: central sections of the set of density matrices
(the quantum version of the simplex) all have asymptotically the same volume.
This allows for very general approximation algorithms, which apply to large
classes of naturally occurring spectrahedra.
&lt;/p&gt;
&lt;p&gt;We give two main applications of this method. First, we apply this method to
what we call the &quot;multi-way Birkhoff spectrahedron&quot; and obtain an explicit
asymptotic formula for its volume. This spectrahedron is the set of quantum
states with maximal entanglement (i.e., the quantum states having univariant
quantum marginals equal to the identity matrix) and is the quantum analog of
the multi-way Birkhoff polytope. Second, we apply this method to explicitly
compute the asymptotic volume of central sections of the set of density
matrices.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Complexity Framework For Forbidden Subgraphs</title>
  <guid>http://arxiv.org/abs/2211.12887</guid>
  <link>http://arxiv.org/abs/2211.12887</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Johnson_M/0/1/0/all/0/1&quot;&gt;Matthew Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Martin_B/0/1/0/all/0/1&quot;&gt;Barnaby Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Oostveen_J/0/1/0/all/0/1&quot;&gt;Jelle J. Oostveen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pandey_S/0/1/0/all/0/1&quot;&gt;Sukanya Pandey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Paulusma_D/0/1/0/all/0/1&quot;&gt;Dani&amp;#xeb;l Paulusma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Smith_S/0/1/0/all/0/1&quot;&gt;Siani Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Leeuwen_E/0/1/0/all/0/1&quot;&gt;Erik Jan van Leeuwen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;For any finite set $\mathcal{H} = \{H_1,\ldots,H_p\}$ of graphs, a graph is
$\mathcal{H}$-subgraph-free if it does not contain any of $H_1,\ldots,H_p$ as a
subgraph. We propose a meta-theorem to classify if problems are &quot;efficiently
solvable&quot; or &quot;computationally hard&quot; on $\mathcal{H}$-subgraph-free graphs. The
conditions are that the problem should be efficiently solvable on graphs of
bounded treewidth, computationally hard on subcubic graphs, and computational
hardness is preserved under edge subdivision. We show that all problems
satisfying these conditions are efficiently solvable if $\mathcal{H}$ contains
a disjoint union of one or more paths and subdivided claws, and are
computationally hard otherwise. To illustrate the broad applicability of our
framework, we study covering or packing problems, network design problems and
width parameter problems. We apply the framework to obtain a dichotomy between
polynomial-time solvability and NP-completeness. For other problems we obtain a
dichotomy between almost-linear-time solvability and having no
subquadratic-time algorithm (conditioned on some hardness hypotheses). In this
way we strengthen results in the literature.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Quantum-Classical Tradeoffs in the Random Oracle Model</title>
  <guid>http://arxiv.org/abs/2211.12954</guid>
  <link>http://arxiv.org/abs/2211.12954</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hamoudi_Y/0/1/0/all/0/1&quot;&gt;Yassine Hamoudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qipeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sinha_M/0/1/0/all/0/1&quot;&gt;Makrand Sinha&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study tradeoffs between quantum and classical queries for hybrid
algorithms that have black-box access to a random oracle. Although there are
several established techniques for proving query lower bounds for both quantum
and classical algorithms, there is no such widely applicable technique for
hybrid algorithms and the optimal tradeoffs for many fundamental problems are
still unknown $\unicode{x2013}$ an optimal tradeoff for the search problem was
only shown recently by Rosmanis, although not in the random oracle model. For
another fundamental problem, collision finding, the optimal tradeoff was not
known.
&lt;/p&gt;
&lt;p&gt;In this work, we develop a framework for recording a query transcript for
quantum-classical algorithms that represents the knowledge gained by the
algorithm. The main feature of this framework is to allow us to record queries
in two incompatible bases $\unicode{x2013}$ classical queries in the standard
basis and quantum queries in the Fourier basis $\unicode{x2013}$ in a
consistent way. We call the framework the hybrid compressed oracle as it
naturally interpolates between the classical way of recording queries and the
compressed oracle framework of Zhandry for recording quantum queries. We
demonstrate its applicability by giving a simpler proof of the optimal
quantum-classical tradeoff for search and by showing an optimal tradeoff for
collision finding.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Scalable and Effective Conductance-based Graph Clustering</title>
  <guid>http://arxiv.org/abs/2211.12511</guid>
  <link>http://arxiv.org/abs/2211.12511</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Longlong Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Rong-Hua Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_T/0/1/0/all/0/1&quot;&gt;Tao Jia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Conductance-based graph clustering has been recognized as a fundamental
operator in numerous graph analysis applications. Despite the significant
success of conductance-based graph clustering, existing algorithms are either
hard to obtain satisfactory clustering qualities, or have high time and space
complexity to achieve provable clustering qualities. To overcome these
limitations, we devise a powerful \textit{peeling}-based graph clustering
framework \textit{PCon}. We show that many existing solutions can be reduced to
our framework. Namely, they first define a score function for each vertex, then
iteratively remove the vertex with the smallest score. Finally, they output the
result with the smallest conductance during the peeling process. Based on our
framework, we propose two novel algorithms \textit{PCon\_core} and
\emph{PCon\_de} with linear time and space complexity, which can efficiently
and effectively identify clusters from massive graphs with more than a few
billion edges. Surprisingly, we prove that \emph{PCon\_de} can identify
clusters with near-constant approximation ratio, resulting in an important
theoretical improvement over the well-known quadratic Cheeger bound. Empirical
results on real-life and synthetic datasets show that our algorithms can
achieve 5$\sim$42 times speedup with a high clustering accuracy, while using
1.4$\sim$7.8 times less memory than the baseline algorithms.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>SAH: Shifting-aware Asymmetric Hashing for Reverse $k$-Maximum Inner Product Search</title>
  <guid>http://arxiv.org/abs/2211.12751</guid>
  <link>http://arxiv.org/abs/2211.12751</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qiang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tung_A/0/1/0/all/0/1&quot;&gt;Anthony K. H. Tung&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper investigates a new yet challenging problem called Reverse
$k$-Maximum Inner Product Search (R$k$MIPS). Given a query (item) vector, a set
of item vectors, and a set of user vectors, the problem of R$k$MIPS aims to
find a set of user vectors whose inner products with the query vector are one
of the $k$ largest among the query and item vectors. We propose the first
subquadratic-time algorithm, i.e., Shifting-aware Asymmetric Hashing (SAH), to
tackle the R$k$MIPS problem. To speed up the Maximum Inner Product Search
(MIPS) on item vectors, we design a shifting-invariant asymmetric
transformation and develop a novel sublinear-time Shifting-Aware Asymmetric
Locality Sensitive Hashing (SA-ALSH) scheme. Furthermore, we devise a new
blocking strategy based on the Cone-Tree to effectively prune user vectors (in
a batch). We prove that SAH achieves a theoretical guarantee for solving the
RMIPS problem. Experimental results on five real-world datasets show that SAH
runs 4$\sim$8$\times$ faster than the state-of-the-art methods for R$k$MIPS
while achieving F1-scores of over 90\%. The code is available at
\url{https://github.com/HuangQiang/SAH}.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Worst-Case to Expander-Case Reductions</title>
  <guid>http://arxiv.org/abs/2211.12833</guid>
  <link>http://arxiv.org/abs/2211.12833</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abboud_A/0/1/0/all/0/1&quot;&gt;Amir Abboud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wallheimer_N/0/1/0/all/0/1&quot;&gt;Nathan Wallheimer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In recent years, the expander decomposition method was used to develop many
graph algorithms, resulting in major improvements to longstanding complexity
barriers. This powerful hammer has led the community to (1) believe that most
problems are as easy on worst-case graphs as they are on expanders, and (2)
suspect that expander decompositions are the key to breaking the remaining
longstanding barriers in fine-grained complexity.
&lt;/p&gt;
&lt;p&gt;We set out to investigate the extent to which these two things are true (and
for which problems). Towards this end, we put forth the concept of worst-case
to expander-case self-reductions. We design a collection of such reductions for
fundamental graph problems, verifying belief (1) for them. The list includes
$k$-Clique, $4$-Cycle, Maximum Cardinality Matching, Vertex-Cover, and Minimum
Dominating Set. Interestingly, for most (but not all) of these problems the
proof is via a simple gadget reduction, not via expander decompositions,
showing that this hammer is effectively useless against the problem and
contradicting (2).
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Branch-and-Bound with Barrier: Dominance and Suboptimality Detection for DD-Based Branch-and-Bound</title>
  <guid>http://arxiv.org/abs/2211.13118</guid>
  <link>http://arxiv.org/abs/2211.13118</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coppe_V/0/1/0/all/0/1&quot;&gt;Vianney Copp&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gillard_X/0/1/0/all/0/1&quot;&gt;Xavier Gillard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaus_P/0/1/0/all/0/1&quot;&gt;Pierre Schaus&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The branch-and-bound algorithm based on decision diagrams introduced by
Bergman et al. in 2016 is a framework for solving discrete optimization
problems with a dynamic programming formulation. It works by compiling a series
of bounded-width decision diagrams that can provide lower and upper bounds for
any given subproblem. Eventually, every part of the search space will be either
explored or pruned by the algorithm, thus proving optimality. This paper
presents new ingredients to speed up the search by exploiting the structure of
dynamic programming models. The key idea is to prevent the repeated exploration
of nodes corresponding to the same dynamic programming states by storing and
querying thresholds in a data structure called the Barrier. These thresholds
are based on dominance relations between partial solutions previously found.
They can be further strengthened by integrating the filtering techniques
introduced by Gillard et al. in 2021. Computational experiments show that the
pruning brought by the Barrier allows to significantly reduce the number of
nodes expanded by the algorithm. This results in more benchmark instances of
difficult optimization problems being solved in less time while using narrower
decision diagrams.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-24 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>2023 Summer Research Intern at Adobe Research at Adobe Research (apply by February 1, 2023)</title>
  <guid>http://cstheory-jobs.org/2022/11/23/2023-summer-research-intern-at-adobe-research-at-adobe-research-apply-by-february-1-2023/</guid>
  <link>https://cstheory-jobs.org/2022/11/23/2023-summer-research-intern-at-adobe-research-at-adobe-research-apply-by-february-1-2023/</link>
  <description>
    &lt;p&gt;Summer (TCS) Research Intern positions are available to work with Zhao Song at Adobe Research. The position is for 3-4 months in summer 2023, start date flexible. CV and a recommendation letter from Ph.D. advisor is required to be sent before ddl.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.adobe.com/careers/university/internships.html&quot;&gt;https://www.adobe.com/careers/university/internships.html&lt;/a&gt;&lt;br /&gt;
Email: zsong@adobe.com&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 23:16:50 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>TR22-167 |  Parallel Repetition for the GHZ Game: Exponential Decay | 

	Mark Braverman, 

	Subhash Khot, 

	Dor Minzer</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/167</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/167</link>
  <description>
    We show that the value of the $n$-fold repeated GHZ game is at most $2^{-\Omega(n)}$, improving upon the polynomial bound established by Holmgren and Raz. Our result is established via a reduction to approximate subgroup type questions from additive combinatorics.
  </description>
  <pubDate>2022-11-23 22:17:41 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>FACULTY (ANY RANK) at PENN STATE (apply by November 15, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/23/faculty-any-rank-at-penn-state-apply-by-november-15-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/23/faculty-any-rank-at-penn-state-apply-by-november-15-2022/</link>
  <description>
    &lt;p&gt;Applications are invited for tenure-track positions at all levels across all areas of theoretical computer science. Review of applications started on 11/15/2022 and will continue until the positions is filled.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/23484&quot;&gt;https://academicjobsonline.org/ajo/jobs/23484&lt;/a&gt;&lt;br /&gt;
Email: ablanca@cse.psu.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-23 15:58:56 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

</channel>
</rss>
