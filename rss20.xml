<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>QuICS Hartree Postdoctoral Fellowships at Joint Center for Quantum Information and Computer Science (QuICS) at QuICS/University of Maryland (apply by December 1, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/09/01/quics-hartree-postdoctoral-fellowships-at-joint-center-for-quantum-information-and-computer-science-quics-at-quics-university-of-maryland-apply-by-december-1-2022/</guid>
  <link>https://cstheory-jobs.org/2022/09/01/quics-hartree-postdoctoral-fellowships-at-joint-center-for-quantum-information-and-computer-science-quics-at-quics-university-of-maryland-apply-by-december-1-2022/</link>
  <description>
    &lt;p&gt;The Joint Center for Quantum Information and Computer Science (QuICS, &lt;a href=&quot;http://quics.umd.edu&quot;&gt;http://quics.umd.edu&lt;/a&gt;) is seeking exceptional candidates for the QuICS Hartree Postdoctoral Fellowships in Quantum Information and Computer Science. Applications should be submitted through AcademicJobsOnline at &lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/22534&quot;&gt;https://academicjobsonline.org/ajo/jobs/22534&lt;/a&gt;. Please indicate interest in “HPF.”&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/22534&quot;&gt;https://academicjobsonline.org/ajo/jobs/22534&lt;/a&gt;&lt;br /&gt;
Email: quics-coordinator@umiacs.umd.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-09-01 00:51:37 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Fine-Grained Distribution-Dependent Learning Curves</title>
  <guid>http://arxiv.org/abs/2208.14615</guid>
  <link>http://arxiv.org/abs/2208.14615</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bousquet_O/0/1/0/all/0/1&quot;&gt;Olivier Bousquet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1&quot;&gt;Steve Hanneke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1&quot;&gt;Shay Moran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafer_J/0/1/0/all/0/1&quot;&gt;Jonathan Shafer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1&quot;&gt;Ilya Tolstikhin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Learning curves plot the expected error of a learning algorithm as a function
of the number of labeled input samples. They are widely used by machine
learning practitioners as a measure of an algorithm&#39;s performance, but classic
PAC learning theory cannot explain their behavior. In this paper we introduce a
new combinatorial characterization called the VCL dimension that improves and
refines the recent results of Bousquet et al. (2021). Our characterization
sheds new light on the structure of learning curves by providing fine-grained
bounds, and showing that for classes with finite VCL, the rate of decay can be
decomposed into a linear component that depends only on the hypothesis class
and an exponential component that depends also on the target distribution. In
particular, the finer nuance of the VCL dimension implies lower bounds that are
quantitatively stronger than the bounds of Bousquet et al. (2021) and
qualitatively stronger than classic &#39;no free lunch&#39; lower bounds. The VCL
characterization solves an open problem studied by Antos and Lugosi (1998), who
asked in what cases such lower bounds exist. As a corollary, we recover their
lower bound for half-spaces in $\mathbb{R}^d$, and we do so in a principled way
that should be applicable to other cases as well. Finally, to provide another
viewpoint on our work and how it compares to traditional PAC learning bounds,
we also present an alternative formulation of our results in a language that is
closer to the PAC setting.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-01 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Complete and tractable machine-independent characterizations of second-order polytime</title>
  <guid>http://arxiv.org/abs/2208.14739</guid>
  <link>http://arxiv.org/abs/2208.14739</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hainry_E/0/1/0/all/0/1&quot;&gt;Emmanuel Hainry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapron_B/0/1/0/all/0/1&quot;&gt;Bruce M. Kapron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marion_J/0/1/0/all/0/1&quot;&gt;Jean-Yves Marion&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pechoux_R/0/1/0/all/0/1&quot;&gt;Romain P&amp;#xe9;choux&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The class of Basic Feasible Functionals BFF is the second-order counterpart
of the class of first-order functions computable in polynomial time. We present
several implicit characterizations of BFF based on a typed programming language
of terms. These terms may perform calls to imperative procedures, which are not
recursive. The type discipline has two layers: the terms follow a standard
simply-typed discipline and the procedures follow a standard tier-based type
discipline. BFF consists exactly of the second-order functionals that are
computed by typable and terminating programs. The completeness of this
characterization surprisingly still holds in the absence of lambda-abstraction.
Moreover, the termination requirement can be specified as a
completeness-preserving instance, which can be decided in time quadratic in the
size of the program. As typing is decidable in polynomial time, we obtain the
first tractable (i.e., decidable in polynomial time), sound, complete, and
implicit characterization of BFF, thus solving a problem opened for more than
20 years.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-01 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Reducing the Complexity of the Sensor-Target Coverage Problem Through Point and Set Classification</title>
  <guid>http://arxiv.org/abs/2208.14800</guid>
  <link>http://arxiv.org/abs/2208.14800</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thron_C/0/1/0/all/0/1&quot;&gt;Christophter Thron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreno_A/0/1/0/all/0/1&quot;&gt;Anthony Moreno&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The problem of covering random points in a plane with sets of a given shape
has several practical applications in communications and operations research.
One especially prominent application is the coverage of randomly-located points
of interest by randomly-located sensors in a wireless sensor network. In this
article we consider the situation of a large area containing randomly placed
points (representing points of interest), as well a number of randomly-placed
disks of equal radius in the same region (representing individual sensors&#39;
coverage areas). The problem of finding the smallest possible set of disks that
cover the given points is known to be NP-complete. We show that the
computational complexity may be reduced by classifying the disks into several
definite classes that can be characterized as necessary, excludable, or
indeterminate. The problem may then be reduced to considering only the
indeterminate sets and the points that they cover. In addition, indeterminate
sets and the points that they cover may be divided into disjoint ``islands&#39;&#39;
that can be solved separately. Hence the actual complexity is determined by the
number of points and sets in the largest island. We run a number of simulations
to show how the proportion of sets and points of various types depend on two
basic scale-invariant parameters related to point and set density. We show that
enormous reductions in complexity can be achieved even in situations where
point and set density is relatively high.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-01 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>On weighted graph separation problems and flow-augmentation</title>
  <guid>http://arxiv.org/abs/2208.14841</guid>
  <link>http://arxiv.org/abs/2208.14841</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1&quot;&gt;Eun Jung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1&quot;&gt;Marcin Pilipczuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1&quot;&gt;Roohani Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wahlstrom_M/0/1/0/all/0/1&quot;&gt;Magnus Wahlstr&amp;#xf6;m&lt;/a&gt;&lt;/p&gt;&lt;p&gt;One of the first application of the recently introduced technique of
\emph{flow-augmentation} [Kim et al., STOC 2022] is a fixed-parameter algorithm
for the weighted version of \textsc{Directed Feedback Vertex Set}, a landmark
problem in parameterized complexity. In this note we explore applicability of
flow-augmentation to other weighted graph separation problems parameterized by
the size of the cutset. We show the following. -- In weighted undirected graphs
\textsc{Multicut} is FPT, both in the edge- and vertex-deletion version. -- The
weighted version of \textsc{Group Feedback Vertex Set} is FPT, even with an
oracle access to group operations. -- The weighted version of \textsc{Directed
Subset Feedback Vertex Set} is FPT. Our study reveals \textsc{Directed
Symmetric Multicut} as the next important graph separation problem whose
parameterized complexity remains unknown, even in the unweighted setting.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-01 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Unbalancing Binary Trees</title>
  <guid>http://arxiv.org/abs/2208.14481</guid>
  <link>http://arxiv.org/abs/2208.14481</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ginsberg_M/0/1/0/all/0/1&quot;&gt;Matthew L. Ginsberg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Assuming Zipf&#39;s Law to be accurate, we show that existing techniques for
partially optimizing binary trees produce results that are approximately 10%
worse than true optimal. We present a new approximate optimization technique
that runs in O(n log n) time and produces trees approximately 1% worse than
optimal. The running time is comparable to that of the Garsia-Wachs algorithm
but the technique can be applied to the more useful case where the node being
searched for is expected to be contained in the tree as opposed to outside of
it.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-01 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Pattern matching under DTW distance</title>
  <guid>http://arxiv.org/abs/2208.14669</guid>
  <link>http://arxiv.org/abs/2208.14669</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gourdel_G/0/1/0/all/0/1&quot;&gt;Garance Gourdel&lt;/a&gt; (IRISA, DI-ENS), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Driemel_A/0/1/0/all/0/1&quot;&gt;Anne Driemel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peterlongo_P/0/1/0/all/0/1&quot;&gt;Pierre Peterlongo&lt;/a&gt; (IRISA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Starikovskaya_T/0/1/0/all/0/1&quot;&gt;Tatiana Starikovskaya&lt;/a&gt; (DI-ENS)&lt;/p&gt;&lt;p&gt;In this work, we consider the problem of pattern matching under the dynamic
time warping (DTW) distance motivated by potential applications in the analysis
of biological data produced by the third generation sequencing. To measure the
DTW distance between two strings, one must &quot;warp&quot; them, that is, double some
letters in the strings to obtain two equal-lengths strings, and then sum the
distances between the letters in the corresponding positions. When the
distances between letters are integers, we show that for a pattern P with m
runs and a text T with n runs: 1. There is an O(m + n)-time algorithm that
computes all locations where the DTW distance from P to T is at most 1; 2.
There is an O(kmn)-time algorithm that computes all locations where the DTW
distance from P to T is at most k. As a corollary of the second result, we also
derive an approximation algorithm for general metrics on the alphabet.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-01 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Combinatorial Algorithms for Subsequence Matching: A Survey</title>
  <guid>http://arxiv.org/abs/2208.14722</guid>
  <link>http://arxiv.org/abs/2208.14722</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kosche_M/0/1/0/all/0/1&quot;&gt;Maria Kosche&lt;/a&gt; (G&amp;#xf6;ttingen University, Germany), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koss_T/0/1/0/all/0/1&quot;&gt;Tore Ko&amp;#xdf;&lt;/a&gt; (G&amp;#xf6;ttingen University, Germany), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manea_F/0/1/0/all/0/1&quot;&gt;Florin Manea&lt;/a&gt; (G&amp;#xf6;ttingen University, Germany), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siemer_S/0/1/0/all/0/1&quot;&gt;Stefan Siemer&lt;/a&gt; (G&amp;#xf6;ttingen University, Germany)&lt;/p&gt;&lt;p&gt;In this paper we provide an overview of a series of recent results regarding
algorithms for searching for subsequences in words or for the analysis of the
sets of subsequences occurring in a word.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-01 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Computing all-vs-all MEMs in run-length encoded collections of HiFi reads</title>
  <guid>http://arxiv.org/abs/2208.14787</guid>
  <link>http://arxiv.org/abs/2208.14787</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaz_Dominguez_D/0/1/0/all/0/1&quot;&gt;Diego D&amp;#xed;az-Dom&amp;#xed;nguez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puglisi_S/0/1/0/all/0/1&quot;&gt;Simon J. Puglisi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salmela_L/0/1/0/all/0/1&quot;&gt;Leena Salmela&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We describe an algorithm to find maximal exact matches (MEMs) among HiFi
reads with homopolymer errors. The main novelty in our work is that we resort
to run-length compression to help deal with errors. Our method receives as
input a run-length-encoded string collection containing the HiFi reads along
with their reverse complements. Subsequently, it splits the encoding into two
arrays, one storing the sequence of symbols for equal-symbol runs and another
storing the run lengths. The purpose of the split is to get the BWT of the run
symbols and reorder their lengths accordingly. We show that this special BWT,
as it encodes the HiFi reads and their reverse complements, supports
bi-directional queries for the HiFi reads. Then, we propose a variation of the
MEM algorithm of Belazzougui et al. (2013) that exploits the run-length
encoding and the implicit bi-directional property of our BWT to compute
approximate MEMs. Concretely, if the algorithm finds that two substrings, $a_1
\ldots a_p$ and $b_1 \ldots b_p$, have a MEM, then it reports the MEM only if
their corresponding length sequences, $\ell^{a}_1 \ldots \ell^{a}_p$ and
$\ell^{b}_1 \ldots \ell^{b}_p$, do not differ beyond an input threshold. We use
a simple metric to calculate the similarity of the length sequences that we
call the {\em run-length excess}. Our technique facilitates the detection of
MEMs with homopolymer errors as it does not require dynamic programming to find
approximate matches where the only edits are the lengths of the equal-symbol
runs. Finally, we present a method that relies on a geometric data structure to
report the text occurrences of the MEMs detected by our algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-01 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A heuristic algorithm for the maximum happy vertices problem using tree decompositions</title>
  <guid>http://arxiv.org/abs/2208.14921</guid>
  <link>http://arxiv.org/abs/2208.14921</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carpentier_L/0/1/0/all/0/1&quot;&gt;Louis Carpentier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jooken_J/0/1/0/all/0/1&quot;&gt;Jorik Jooken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goedgebeur_J/0/1/0/all/0/1&quot;&gt;Jan Goedgebeur&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We propose a new heuristic algorithm for the Maximum Happy Vertices problem,
using tree decompositions. Traditionally, such algorithms construct an optimal
solution of the given problem instance through a dynamic programming approach.
We modify this procedure by integrating a parameter $W$ that dictates the
number of dynamic programming states to consider. We drop the exactness
guarantee in favour of a shorter running time. However, if $W$ is large enough
such that all valid states are considered, our heuristic algorithm proves
optimality of the constructed solution. Our algorithm more efficiently
constructs an optimal solution for the Maximum Happy Vertices problem than the
exact algorithm for graphs of bounded treewidth. Furthermore, our algorithm
constructs higher quality solutions than state-of-the-art heuristic algorithms
Greedy-MHV and Growth-MHV for instances of which at least 40% of the vertices
are initially coloured, at the cost of a larger running time.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-01 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>The NIST Process for Post-Quantum Cryptography</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-1874664086811883884</guid>
  <link>http://blog.computationalcomplexity.org/2022/08/the-nist-competition-for-post-quantum.html</link>
  <description>
    &lt;div&gt;&lt;i&gt;Guest post by &lt;a href=&quot;https://www.cs.umd.edu/~jkatz/&quot;&gt;Jonathan Katz&lt;/a&gt;&lt;/i&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;Over the past few months there have been several interesting developments in the &lt;a href=&quot;https://csrc.nist.gov/Projects/post-quantum-cryptography&quot;&gt;NIST post-quantum standardization process&lt;/a&gt;.&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;By way of background, since the advent of &lt;a href=&quot;https://en.wikipedia.org/wiki/Shor%27s_algorithm&quot;&gt;Shor&#39;s algorithm&lt;/a&gt; in 1994 we have known that a large-scale, general-purpose quantum computer would be able to break all currently deployed public-key cryptography in (quantum) polynomial time. While estimates vary as to when (or even whether!) quantum computers will become a realistic threat to existing public-key cryptosystems, it seems prudent to already begin developing/deploying newer &quot;post-quantum&quot; schemes that are plausibly secure against quantum computers.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;With the above in mind, NIST initiated an open process in 2017 for designing post-quantum cryptographic standards. Researchers from around the world submitted candidate algorithms for public-key encryption/key exchange and digital signatures. These were winnowed down over a series of rounds as cryptographers publicly debated the relative merits of different proposals, or showed  security weaknesses in some candidates.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;On July 5 of this year, NIST &lt;a href=&quot;https://nvlpubs.nist.gov/nistpubs/ir/2022/NIST.IR.8413.pdf&quot;&gt;announced&lt;/a&gt; that it had selected four of the submissions as finalists for standardization. Only one candidate for public-key encryption was chosen, along with three digital signature schemes. Three of the four selected algorithms rely on the hardness of lattice problems; the only non-lattice scheme is a hash-based signature scheme. (It is possible to build digital signatures using &quot;symmetric-key&quot; assumptions alone.) In addition, four other public-key encryption schemes not based on lattices were designated for further study and possible standardization at a later point in time.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Less than one month later, &lt;a href=&quot;https://eprint.iacr.org/2022/975&quot;&gt;Castryck and Decru announced&lt;/a&gt; a &lt;strong&gt;classical&lt;/strong&gt; attack on SIKE, one of the public-key encryption schemes chosen for further study. &lt;a href=&quot;https://sike.org/&quot;&gt;SIKE&lt;/a&gt; is based on a conjectured hard problem related to isogenies on supersingular elliptic curves.&amp;nbsp;The attack was not just theoretical; the researchers were able to implement the attack and run it in less than a day or less, depending on the security level being considered. Details of the attack are quite complex, but Galbraith &lt;a href=&quot;https://ellipticnews.wordpress.com/2022/07/31/breaking-supersingular-isogeny-diffie-hellman-sidh/&quot;&gt;gives a high-level overview&lt;/a&gt;. &lt;a href=&quot;https://ellipticnews.wordpress.com/2022/08/12/attacks-on-sidh-sike/&quot;&gt;Subsequent improvements&lt;/a&gt; to the attack followed.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;It is worth adding that the above follows an &lt;a href=&quot;https://eprint.iacr.org/2022/214&quot;&gt;entirely classical attack&lt;/a&gt; shown roughly six months earlier on Rainbow, another submission to the NIST standardization process that made it to the 3rd round. (Rainbow is a signature scheme that relies on an entirely different mathematical problem than SIKE.) For completeness, note that none of the four finalists are impacted by any of these attacks.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;A few reflections on the above:&lt;/div&gt;&lt;div&gt;&lt;ul style=&quot;text-align: left;&quot;&gt;&lt;li&gt;It is amazing that the factoring and RSA problems are still hard (for classical computers), more than 40 used after they were proposed for cryptography. The same goes for the discrete-logarithm problem (in certain groups).&lt;/li&gt;&lt;li&gt;It is not easy to find other hard mathematical problems! &lt;a href=&quot;https://en.wikipedia.org/wiki/McEliece_cryptosystem&quot;&gt;Code-based cryptography&lt;/a&gt; has been around about as long as factoring, but has been somewhat unpopular for reasons of efficiency. Lattice-based cryptosystems still seem to give the leading candidates.&lt;/li&gt;&lt;li&gt;We need more (non-cryptographers) studying cryptographic assumptions. The attacks on SIKE involved deep mathematics; attacks on lattice problems may involve algorithmic ideas that cryptographers haven&#39;t thought of.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 19:35:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>My Quantum Information Science II Lecture Notes: The wait is over!</title>
  <guid>https://scottaaronson.blog/?p=6685</guid>
  <link>https://scottaaronson.blog/?p=6685</link>
  <description>
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.scottaaronson.com/qisii.pdf&quot;&gt;Here they are [PDF]&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;They&amp;#8217;re 155 pages of awesome&amp;#8212;for a certain extremely specific definition of &amp;#8220;awesome&amp;#8221;&amp;#8212;which I&amp;#8217;m hereby offering to the world free of charge (for noncommercial use only, of course).  They cover material that I taught, for the first time, in my Introduction to Quantum Information Science II undergrad course at UT Austin in Spring 2022.&lt;/p&gt;



&lt;p&gt;The new notes pick up exactly where my older &lt;a href=&quot;https://www.scottaaronson.com/qclec.pdf&quot;&gt;QIS I lecture notes&lt;/a&gt; left off, and they presuppose familiarity with the QIS I material.  So, if you&amp;#8217;re just beginning your quantum information journey, then please start with my QIS I notes, which presuppose only linear algebra and a bit of classical algorithms (e.g., recurrence relations and big-O notation), and which self-containedly explain all the rules of QM, moving on to (e.g.) quantum circuits, density matrices, entanglement entropy, Wiesner&amp;#8217;s quantum money, QKD, quantum teleportation, the Bell inequality, interpretations of QM, the Shor 9-qubit code, and the algorithms of Deutsch-Jozsa, Bernstein-Vazirani, Simon, Shor, and Grover.  Master all that, and you&amp;#8217;ll be close to the quantum information research frontier of circa 1996.&lt;/p&gt;



&lt;p&gt;My new QIS II notes cover a bunch of topics, but the main theme is &amp;#8220;perspectives on quantum computing that go beyond the bare quantum circuit model, and that became increasingly central to the field from the late 1990s onwards.&amp;#8221;  Thus, it covers:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;Hamiltonians, ground states, the adiabatic algorithm, and the universality of adiabatic QC&lt;/li&gt;&lt;li&gt;The stabilizer formalism, the 1996 Gottesman-Knill Theorem on efficient classical simulation of stabilizer QC, my and Gottesman&amp;#8217;s 2004 elaborations, boosting up to universality via &amp;#8220;magic states,&amp;#8221; transversal codes, and the influential 2016 concept of &lt;em&gt;stabilizer rank&lt;/em&gt;&lt;/li&gt;&lt;li&gt;Bosons and fermions: the formalism of Fock space and of creation and annihilation operators, connection to the permanents and determinants of matrices, efficient classical simulation of free fermionic systems (Valiant&amp;#8217;s 2002 &amp;#8220;matchcircuits&amp;#8221;), the 2001 Knill-Laflamme-Milburn (KLM) theorem on universal optical QC, BosonSampling and its computational complexity, and the current experimental status of BosonSampling&lt;/li&gt;&lt;li&gt;Cluster states, Raussendorf and Briegel&amp;#8217;s 2000 measurement-based quantum computation (MBQC), and Gottesman and Chuang&amp;#8217;s 1999 &amp;#8220;gate teleportation&amp;#8221; trick&lt;/li&gt;&lt;li&gt;Matrix product states, and Vidal&amp;#8217;s 2003 efficient classical simulation of &amp;#8220;slightly entangled&amp;#8221; quantum computations&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Extra bonus topics include:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;The 2007 Broadbent-Fitzsimons-Kashefi (BFK) protocol for blind and authenticated QC; brief discussion of later developments including Reichardt-Unger-Vazirani 2012 and Mahadev 2018&lt;/li&gt;&lt;li&gt;Basic protocols for quantum state tomography&lt;/li&gt;&lt;li&gt;My 2007 work on PAC-learnability of quantum states&lt;/li&gt;&lt;li&gt;The &amp;#8220;dessert course&amp;#8221;: the black hole information problem, and the Harlow-Hayden argument on the computational hardness of decoding Hawking radiation&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Master all this, and hopefully you&amp;#8217;ll have the conceptual vocabulary to understand a large fraction of what people in quantum computing and information care about today, how they now think about building scalable QCs, and what they post to the quant-ph arXiv.&lt;/p&gt;



&lt;p&gt;Note that my QIS II course is complementary to my graduate course on quantum complexity theory, for which &lt;a href=&quot;https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-845-quantum-complexity-theory-fall-2010/lecture-notes/&quot;&gt;the lecture notes are here&lt;/a&gt;.  There&amp;#8217;s very little overlap between the two (and even less overlap between QIS II and &lt;em&gt;&lt;a href=&quot;https://www.amazon.ca/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565&quot;&gt;Quantum Computing Since Democritus&lt;/a&gt;&lt;/em&gt;).&lt;/p&gt;



&lt;p&gt;The biggest, most important topic related to the QIS II theme that I &lt;em&gt;didn&amp;#8217;t&lt;/em&gt; cover was &lt;a href=&quot;https://en.wikipedia.org/wiki/Topological_quantum_computer&quot;&gt;topological quantum computing&lt;/a&gt;.  I&amp;#8217;d wanted to, but it quickly became clear that topological QC begs for a whole course of its own, and that I had neither the time nor the expertise to do it justice.  In retrospect, I do wish I&amp;#8217;d at least covered the &lt;a href=&quot;https://en.wikipedia.org/wiki/Toric_code&quot;&gt;Kitaev surface code&lt;/a&gt;.&lt;/p&gt;



&lt;p&gt;Crucially, these lecture notes don&amp;#8217;t represent my effort alone.  I worked from draft scribe notes prepared by the QIS II students, who did a far better job than I had any right to expect (including creating the beautiful figures).  My wonderful course TA and PhD student Daniel Liang, along with students Ethan Tan, Samuel Ziegelbein, and Steven Han, then assembled everything, fixed numerous errors, and compiled the bibliography.  I’m grateful to all of them.  At the last minute, we had a LaTeX issue that none of us knew how to fix&amp;#8212;but, in response to a plea, &lt;em&gt;Shtetl-Optimized&lt;/em&gt; reader Pablo Cingolani generously volunteered to help, completed the work by the very next day (I&amp;#8217;d imagined it taking a month!), and earned a fruit basket from me in gratitude.&lt;/p&gt;



&lt;p&gt;Anyway, let me know of any mistakes you find!  We&amp;#8217;ll try to fix them.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 19:33:15 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>Linkage</title>
  <guid>https://11011110.github.io/blog/2022/08/31/linkage</guid>
  <link>https://11011110.github.io/blog/2022/08/31/linkage.html</link>
  <description>
    &lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;You’re probably familiar with machine-learning-based translation between natural languages, based on finding patterns in large datasets of known translations, for instance as used by Google translate. Now the Xena people are trying to use the same methods to &lt;a href=&quot;https://xenaproject.wordpress.com/2022/08/16/the-future-of-interactive-theorem-proving/&quot;&gt;convert LaTeX-formatted natural-language descriptions of mathematical propositions into the formal language used by the Lean theorem prover&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108834522515462270&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.shadertoy.com/view/wddBRX&quot;&gt;Pretty shadertoy flythrough of the Laves graph&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108841798903036223&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://matthewarcus.wordpress.com/2020/11/19/the-laves-graph/&quot;&gt;via&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.computationalcomplexity.org/2022/08/conference-modality.html&quot;&gt;The Computational Complexity blog takes on the question of the conference-based publishing culture in computer science&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108848289896382888&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; and whether in-person vs virtual vs hybrid conferences can really be said to be working, now that we have enough experience going back and forth between these modalities and the novelty of the virtual and hybrid formats has worn off.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gilkalai.wordpress.com/2022/08/19/alexander-a-gaifullin-many-27-vertex-triangulations-of-manifolds-like-the-octonionic-projective-plane-not-even-one-was-known-before/&quot;&gt;Many minimal triangulations of “manifolds like the octonionic projective plane”&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108854003041559158&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Blog post by Gil Kalai based on &lt;a href=&quot;https://arxiv.org/abs/2207.08507&quot;&gt;a new preprint by Alexander Gaifullin&lt;/a&gt;. Gaifullin conjectures that these all are the octonionic projective plane (not merely “like it”). Gil’s post connects this to several other extremal problems, mostly in polyhedral combinatorics but also including the existence of a girth-5 degree-57 &lt;a href=&quot;https://en.wikipedia.org/wiki/Moore_graph&quot;&gt;Moore graph&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://doi.org/10.1016/j.jvir.2022.07.008&quot;&gt;The &lt;em&gt;Journal of Vascular and Interventional Radiology&lt;/em&gt; retracts its crossword puzzle&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108856663784900462&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://retractionwatch.com/2022/08/20/weekend-reads-who-cares-about-publication-integrity-revealing-a-galileo-forgery-repeat-predatory-journal-authors/&quot;&gt;via&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/ivanoransky/status/1559174872714051584&quot;&gt;via2&lt;/a&gt;). No explanation why yet, but I suspect it’s not because of falsified experimental data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Today’s simple and somewhat obvious geometry observation &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108865083323085368&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; made while trying to fit old CD cover art into sleeves of a CD binder for more compact storage: if you’re trying to fit a flexible sheet into a flexible sleeve that is only just barely big enough to hold it, it doesn’t help to bend both into a convex curve; they will still be too tight. Instead, if you bend the sheet into a compound curve, while letting the sleeve fall into a convex shape surrounding it, you can make more room.&lt;/p&gt;

    &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;/blog/assets/2022/envelopment.svg&quot; alt=&quot;A convex curve, bent to fit a too-tight sleeve, remains too tight (top) while an S-shaped curve fits more easily (bottom)&quot; style=&quot;width:100%;max-width:540px&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Olligobber implements &lt;a href=&quot;https://en.wikipedia.org/wiki/Combinatory_logic&quot;&gt;combinatory logic&lt;/a&gt; in &lt;a href=&quot;https://gist.github.com/olligobber/e044c87a834b34bc74d8c8903b0b0d94&quot;&gt;\(\TeX\) macros&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@olligobber/106533354539487538&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.ams.org/journals/notices/202208/noti2522/noti2522.html&quot;&gt;The graph minor theorem meets algebra&lt;/a&gt;: in the &lt;em&gt;Notices&lt;/em&gt;, Eric Ramos explains a conjectured category-theoretic generalization of the fact that graph minors form a well-quasi-ordering. Via &lt;a href=&quot;https://mathstodon.xyz/@johncarlosbaez/108879289204270102&quot;&gt;a long multi-post thread by John Baez&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://hardness.mit.edu/&quot;&gt;New draft book on lower bounds in complexity theory&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108883442872860109&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;http://blog.computationalcomplexity.org/2022/08/computers-and-intractability-guide-to.html&quot;&gt;via&lt;/a&gt;), by Demaine, Gasarch, and Hajiaghayi, intended as a replacement for Garey and Johnson’s 1979 NP-completeness book.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://scilogs.spektrum.de/hlf/why-a4-the-mathematical-beauty-of-paper-size/&quot;&gt;Why A4? – the mathematical beauty of paper size&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108889131132278902&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; You probably already knew about the self-reproducing shape of \(1\times\sqrt2\) rectangles when folded in half, but the link is a nice explainer of why A4 paper has such odd-looking dimensions for those who didn’t know.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Talk slides for my papers at the just-concluded &lt;a href=&quot;https://www.torontomu.ca/canadian-conference-computational-geometry-2022/&quot;&gt;Canadian Conference on Computational Geometry&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;MLINK&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;):&lt;/span&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://www.ics.uci.edu/~eppstein/pubs/Epp-CCCG-22a.pdf&quot;&gt;Orthogonal dissection into few rectangles&lt;/a&gt; (see &lt;a href=&quot;/blog/2022/06/22/dehn-rank-revisited.html&quot;&gt;earlier post&lt;/a&gt;)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://www.ics.uci.edu/~eppstein/pubs/Epp-CCCG-22b.pdf&quot;&gt;Locked and unlocked smooth embeddings of surfaces&lt;/a&gt; (see &lt;a href=&quot;/blog/2022/06/28/motion-bend-lines.html&quot;&gt;earlier post&lt;/a&gt;)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;a href=&quot;https://www.ics.uci.edu/~eppstein/pubs/Epp-CCCG-22c.pdf&quot;&gt;Reflections in an octagonal mirror maze&lt;/a&gt; (see &lt;a href=&quot;/blog/2022/06/24/reflections-octagonal-mirror.html&quot;&gt;earlier post&lt;/a&gt;)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;An update on the “coffee near Ryerson” map from &lt;a href=&quot;/blog/2022/08/22/permuted-points-interest.html&quot;&gt;my recent post&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108900798389538030&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;):&lt;/span&gt;  I tried four cafés, only one of which was highlighted by a line on the map: Black Bear, Page One, Hailed, and Mast. I would have also tried Le Génie but it was closed mornings. The best coffee was at Hailed, but it’s tiny, with only outdoor seating. Second-best coffee, and the best space to hang out to drink the coffee, was Mast. The others did not disappoint but were not as good as Hailed and Mast.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://sigbed.org/2022/08/22/the-toxic-culture-of-rejection-in-computer-science/&quot;&gt;The toxic culture of rejection in computer science&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108910723093352198&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://news.ycombinator.com/item?id=32605494&quot;&gt;via&lt;/a&gt;), Edward Lee in the ACM SIGBED blog. I disagree with the post’s preference for incrementalism over novelty, but I agree that there’s big price for being too selective. Beyond frustrating everyone, I think it leads to dominance of trendiness and in-groups over significance, progress, originality, and depth. And though that may be good for those in the trendy in-groups, it’s not good for the field.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://electionlawblog.org/?p=131555&quot;&gt;Accusations of research misconduct against Princeton gerrymandering researcher Sam Wang, made by a Republican political operative, have been found to be “without merit” by the university&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108916373574688890&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://retractionwatch.com/2022/08/27/weekend-reads-the-problem-of-irreproducible-bioscience-research-how-to-stop-the-unknowing-citation-of-retracted-papers-data-scandal-leads-to-stock-drop/&quot;&gt;via&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.tokyoweekender.com/2022/07/origami-influencing-engineering-technology/&quot;&gt;How origami is engineering new technological opportunities&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108920072649801627&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Interview with mechanical engineer Sachiko Ishida of Meiji University on applications of folded structures in engineering, and where origami engineering is headed.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 17:28:00 UTC</pubDate>
  <author>David Eppstein</author>
</item>

<item>
  <title>Guest Post: TCS Women Travel Scholarships for FOCS’22</title>
  <guid>http://tcsplus.wordpress.com/?p=632</guid>
  <link>https://tcsplus.wordpress.com/2022/08/30/guest-post-tcs-women-travel-scholarships-for-focs22/</link>
  <description>
    &lt;p&gt;&lt;em&gt;Below is an announcement on behalf of &lt;a href=&quot;https://sigact.org/tcswomen/&quot;&gt;TCS Women&lt;/a&gt; regarding the upcoming FOCS&amp;#8217;22.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;TCS Women is offering travel scholarships to attend FOCS 2022 in Denver, Colorado, USA. TCS Women Travel Scholarships are intended for researchers at the beginning of their career. This scholarship is being made available for women and minorities, and anyone who identifies as such is welcome to apply; this scholarship is open to both US and international students. Preference will be given to students at the beginning of their studies. If we have sufficient funding, we will give awards to more senior students and possibly even postdocs.&lt;/p&gt;



&lt;p&gt;To apply, you will need to fill out the following form by&amp;nbsp;&lt;strong&gt;Sept 2nd, 2022&lt;/strong&gt;&amp;nbsp;(11:59 pm PDT) in which you provide basic information about yourself, an estimate of your expenses, and a brief statement:&lt;/p&gt;



&lt;p class=&quot;has-text-align-center&quot;&gt;&lt;a href=&quot;https://protect-au.mimecast.com/s/Y8mEC2xMQzikvQnLYhnDVRj?domain=forms.gle&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;Apply for a travel grant here.&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;In addition, you will need to have your advisor (or department head or other faculty mentor if you do not yet have an advisor) send a letter of support to &lt;a rel=&quot;noreferrer noopener&quot; href=&quot;mailto:tcswomen@gmail.com&quot; target=&quot;_blank&quot;&gt;tcswomen@gmail.com&lt;/a&gt; by Sept 2nd, 2022. Your advisor’s letter should also describe the availability of other travel funds.  Note for advisors: Specifics about alternative funding are very helpful.  Statements like “funding is tight” are not very helpful. This letter should be sent with the subject line &lt;em&gt;“support letter for [your name]”&lt;/em&gt;. This is very important. Your application is not complete without this letter.&lt;/p&gt;



&lt;p&gt;For more information, check out the website: &lt;a href=&quot;https://protect-au.mimecast.com/s/i-5BC3QNPBimwvLjkcqEmbE?domain=sigact.org/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;https://sigact.org/tcswomen/5th-tcs-women-meeting/travel-scholarship/&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By plustcs&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 01:08:20 UTC</pubDate>
  <author>TCS+ Seminar Series</author>
</item>

<item>
  <title>Generating Regular Hyperbolic Honeycombs</title>
  <guid>http://arxiv.org/abs/2208.13816</guid>
  <link>http://arxiv.org/abs/2208.13816</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celinska_Kopczynska_D/0/1/0/all/0/1&quot;&gt;Dorota Celi&amp;#x144;ska-Kopczy&amp;#x144;ska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kopczynski_E/0/1/0/all/0/1&quot;&gt;Eryk Kopczy&amp;#x144;ski&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Geodesic regular tree structures are essential to combat numerical precision
issues that arise while working with large-scale computational hyperbolic
geometry and have applications in algorithms based on distances in such
tessellations. We present a method of generating and applying such structures
to the tessellations of 3-dimensional hyperbolic space.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Minimum color spanning circle of imprecise points</title>
  <guid>http://arxiv.org/abs/2208.13865</guid>
  <link>http://arxiv.org/abs/2208.13865</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Acharyya_A/0/1/0/all/0/1&quot;&gt;Ankush Acharyya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jallu_R/0/1/0/all/0/1&quot;&gt;Ramesh K. Jallu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keikha_V/0/1/0/all/0/1&quot;&gt;Vahideh Keikha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loffler_M/0/1/0/all/0/1&quot;&gt;Maarten L&amp;#xf6;ffler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saumell_M/0/1/0/all/0/1&quot;&gt;Maria Saumell&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $\cal R$ be a set of $n$ colored imprecise points, where each point is
colored by one of $k$ colors. Each imprecise point is specified by a unit disk
in which the point lies. We study the problem of computing the smallest and the
largest possible minimum color spanning circle, among all possible choices of
points inside their corresponding disks. We present an $O(nk\log n)$ time
algorithm to compute a smallest minimum color spanning circle. Regarding the
largest minimum color spanning circle, we show that the problem is NP-Hard and
present a $\frac{1}{3}$-factor approximation algorithm. We improve the
approximation factor to $\frac{1}{2}$ for the case where no two disks of
distinct color intersect.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Approximation Algorithm for Minimum $p$ Union Under a Geometric Setting</title>
  <guid>http://arxiv.org/abs/2208.14264</guid>
  <link>http://arxiv.org/abs/2208.14264</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ran_Y/0/1/0/all/0/1&quot;&gt;Yingli Ran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhao Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a minimum $p$ union problem (Min$p$U), given a hypergraph $G=(V,E)$ and an
integer $p$, the goal is to find a set of $p$ hyperedges $E&#39;\subseteq E$ such
that the number of vertices covered by $E&#39;$ (that is $|\bigcup_{e\in E&#39;}e|$) is
minimized. It was known that Min$p$U is at least as hard as the densest
$k$-subgraph problem. A question is: how about the problem in some geometric
settings? In this paper, we consider the unit square Min$p$U problem
(Min$p$U-US) in which $V$ is a set of points on the plane, and each hyperedge
of $E$ consists of a set of points in a unit square. A
$(\frac{1}{1+\varepsilon},4)$-bicriteria approximation algorithm is presented,
that is, the algorithm finds at least $\frac{p}{1+\varepsilon}$ unit squares
covering at most $4opt$ points, where $opt$ is the optimal value for the
Min$p$U-US instance (the minimum number of points that can be covered by $p$
unit squares).
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Randomized Approximation Schemes for the Tutte Polynomial and Random Clustering in Subdense and Superdense Graphs</title>
  <guid>http://arxiv.org/abs/2208.13809</guid>
  <link>http://arxiv.org/abs/2208.13809</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauptmann_M/0/1/0/all/0/1&quot;&gt;Mathias Hauptmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiling_R/0/1/0/all/0/1&quot;&gt;Ronja Tiling&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Extending the work of Alon, Frieze abnd Welsh, we show that there are
randomized polynomial time approximation schemes for computing the Tutte
polynomial in subdense graphs with an minimal node degree of $\Omega\left (
\frac{n}{\sqrt{\log n}}\right )$ . The same holds for the partition function
$Z$ in the random cluster model with uniform edge probabilities and for the
associated distribution $\lambda (A),\: A \subseteq E$ whenever the underlying
graph $G=(V,E)$ is $c\cdot\frac{n}{\sqrt{\log (n)}}$-subdense. In the
superdense case with node degrees $n-o(n)$, we show that the Tutte polynomial
$T_G(x,y)$ is asymptotically equal to $Q=(x-1)(y-1)$. Moreover, we briefly
discuss the problem of approximating $Z$ in the case of $(\alpha, \beta
)$-power law graphs.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On Sparse Hitting Sets: from Fair Vertex Cover to Highway Dimension</title>
  <guid>http://arxiv.org/abs/2208.14132</guid>
  <link>http://arxiv.org/abs/2208.14132</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blum_J/0/1/0/all/0/1&quot;&gt;Johannes Blum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Disser_Y/0/1/0/all/0/1&quot;&gt;Yann Disser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldmann_A/0/1/0/all/0/1&quot;&gt;Andreas Feldmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Siddharth Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zych_Pawlewicz_A/0/1/0/all/0/1&quot;&gt;Anna Zych-Pawlewicz&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the Sparse Hitting Set (Sparse-HS) problem, where we are given a
set system $(V,\mathcal{F},\mathcal{B})$ with two families
$\mathcal{F},\mathcal{B}$ of subsets of $V$. The task is to find a hitting set
for $\mathcal{F}$ that minimizes the maximum number of elements in any of the
sets of $\mathcal{B}$. Our focus is on determining the complexity of some
special cases of Sparse-HS with respect to the sparseness $k$, which is the
optimum number of hitting set elements in any set of $\mathcal{B}$.
&lt;/p&gt;
&lt;p&gt;For the Sparse Vertex Cover (Sparse-VC) problem, $V$ is given by the vertex
set of a graph, and $\mathcal{F}$ is its edge set. We prove NP-hardness for
sparseness $k\geq 2$ and polynomial time solvability for $k=1$. We also provide
a polynomial-time $2$-approximation for any $k$. A special case of Sparse-VC is
Fair Vertex Cover (Fair-VC), where the family $\mathcal{B}$ is given by vertex
neighbourhoods. For this problem we prove NP-hardness for constant $k$ and
provide a polynomial-time $(2-\frac{1}{k})$-approximation. This is better than
any approximation possible for Sparse-VC or Vertex Cover (under UGC).
&lt;/p&gt;
&lt;p&gt;We then consider two problems derived from Sparse-HS related to the highway
dimension, a graph parameter modelling transportation networks. Most algorithms
for graphs of low highway dimension compute solutions to the $r$-Shortest Path
Cover ($r$-SPC) problem, where $r&amp;gt;0$, $\mathcal{F}$ contains all shortest paths
of length between $r$ and $2r$, and $\mathcal{B}$ contains all balls of radius
$2r$. There is an XP algorithm that computes solutions to $r$-SPC of sparseness
at most $h$ if the input graph has highway dimension $h$, but the existence if
an FPT algorithm was open. We prove that $r$-SPC and also the related
$r$-Highway Dimension ($r$-HD) problem are both W[1]-hard. Furthermore, we
prove that $r$-SPC admits a polynomial-time $O(\log n)$-approximation.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Unit-length Rectangular Drawings of Graphs</title>
  <guid>http://arxiv.org/abs/2208.14142</guid>
  <link>http://arxiv.org/abs/2208.14142</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alegria_C/0/1/0/all/0/1&quot;&gt;Carlos Alegria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozzo_G/0/1/0/all/0/1&quot;&gt;Giordano Da Lozzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Battista_G/0/1/0/all/0/1&quot;&gt;Giuseppe Di Battista&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frati_F/0/1/0/all/0/1&quot;&gt;Fabrizio Frati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosso_F/0/1/0/all/0/1&quot;&gt;Fabrizio Grosso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patrignani_M/0/1/0/all/0/1&quot;&gt;Maurizio Patrignani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A rectangular drawing of a planar graph $G$ is a planar drawing of $G$ in
which vertices are mapped to grid points, edges are mapped to horizontal and
vertical straight-line segments, and faces are drawn as rectangles. Sometimes
this latter constraint is relaxed for the outer face. In this paper, we study
rectangular drawings in which the edges have unit length. We show a complexity
dichotomy for the problem of deciding the existence of a unit-length
rectangular drawing, depending on whether the outer face must also be drawn as
a rectangle or not. Specifically, we prove that the problem is NP-complete for
biconnected graphs when the drawing of the outer face is not required to be a
rectangle, even if the sought drawing must respect a given planar embedding,
whereas it is polynomial-time solvable, both in the fixed and the variable
embedding settings, if the outer face is required to be drawn as a rectangle.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Minimum Coverage Instrumentation</title>
  <guid>http://arxiv.org/abs/2208.13907</guid>
  <link>http://arxiv.org/abs/2208.13907</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Li Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoag_E/0/1/0/all/0/1&quot;&gt;Ellis Hoag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kyungwoo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mestre_J/0/1/0/all/0/1&quot;&gt;Julian Mestre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pupyrev_S/0/1/0/all/0/1&quot;&gt;Sergey Pupyrev&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Modern compilers leverage block coverage profile data to carry out downstream
profile-guided optimizations to improve the runtime performance and the size of
a binary. Given a control-flow graph $G=(V, E)$ of a function in the binary,
where nodes in $V$ correspond to basic blocks (sequences of instructions that
are always executed sequentially) and edges in $E$ represent jumps in the
control flow, the goal is to know for each block $u \in V$ whether $u$ was
executed during a session. To this end, extra instrumentation code that records
when a block is executed needs to be added to the binary. This extra code
creates a time and space overhead, which one would like to minimize as much as
possible. Motivated by this application, we study the Minimum Coverage
Instrumentation problem, where the goal is to find a minimum size subset of
blocks to instrument such that the coverage of the remaining blocks in the
graph can be inferred from the coverage status of the instrumented subset. Our
main result is an algorithm to find an optimal instrumentation strategy and to
carry out the inference in $O(|E|)$ time. We also study variants of this basic
problem in which we are interested in learning the coverage of edges instead of
the nodes, or when we are only allowed to instrument edges instead of the
nodes.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Fitting Metrics and Ultrametrics with Minimum Disagreements</title>
  <guid>http://arxiv.org/abs/2208.13920</guid>
  <link>http://arxiv.org/abs/2208.13920</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1&quot;&gt;Vincent Cohen-Addad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1&quot;&gt;Chenglin Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1&quot;&gt;Euiwoong Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mesmay_A/0/1/0/all/0/1&quot;&gt;Arnaud de Mesmay&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given $x \in (\mathbb{R}_{\geq 0})^{\binom{[n]}{2}}$ recording pairwise
distances, the METRIC VIOLATION DISTANCE (MVD) problem asks to compute the
$\ell_0$ distance between $x$ and the metric cone; i.e., modify the minimum
number of entries of $x$ to make it a metric. Due to its large number of
applications in various data analysis and optimization tasks, this problem has
been actively studied recently.
&lt;/p&gt;
&lt;p&gt;We present an $O(\log n)$-approximation algorithm for MVD, exponentially
improving the previous best approximation ratio of $O(OPT^{1/3})$ of Fan et al.
[ SODA, 2018]. Furthermore, a major strength of our algorithm is its simplicity
and running time. We also study the related problem of ULTRAMETRIC VIOLATION
DISTANCE (UMVD), where the goal is to compute the $\ell_0$ distance to the cone
of ultrametrics, and achieve a constant factor approximation algorithm. The
UMVD can be regarded as an extension of the problem of fitting ultrametrics
studied by Ailon and Charikar [SIAM J. Computing, 2011] and by Cohen-Addad et
al. [FOCS, 2021] from $\ell_1$ norm to $\ell_0$ norm. We show that this problem
can be favorably interpreted as an instance of Correlation Clustering with an
additional hierarchical structure, which we solve using a new
$O(1)$-approximation algorithm for correlation clustering that has the
structural property that it outputs a refinement of the optimum clusters. An
algorithm satisfying such a property can be considered of independent interest.
We also provide an $O(\log n \log \log n)$ approximation algorithm for weighted
instances. Finally, we investigate the complementary version of these problems
where one aims at choosing a maximum number of entries of $x$ forming an
(ultra-)metric. In stark contrast with the minimization versions, we prove that
these maximization versions are hard to approximate within any constant factor
assuming the Unique Games Conjecture.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Achievable Rates and Algorithms for Group Testing with Runlength Constraints</title>
  <guid>http://arxiv.org/abs/2208.14066</guid>
  <link>http://arxiv.org/abs/2208.14066</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiore_S/0/1/0/all/0/1&quot;&gt;Stefano Della Fiore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalai_M/0/1/0/all/0/1&quot;&gt;Marco Dalai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaccaro_U/0/1/0/all/0/1&quot;&gt;Ugo Vaccaro&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we study bounds on the minimum length of
$(k,n,d)$-superimposed codes introduced by Agarwal et al. [1], in the context
of Non-Adaptive Group Testing algorithms with runlength constraints. A
$(k,n,d)$-superimposed code of length $t$ is a $t \times n$ binary matrix such
that any two 1&#39;s in each column are separated by a run of at least $d$ 0&#39;s, and
such that for any column $\mathbf{c}$ and any other $k-1$ columns, there exists
a row where $\mathbf{c}$ has $1$ and all the remaining $k-1$ columns have $0$.
Agarwal et al. proved the existence of such codes with
$t=\Theta(dk\log(n/k)+k^2\log(n/k))$. Here we investigate more in detail the
coefficients in front of these two main terms as well as the role of lower
order terms. We show that improvements can be obtained over the construction in
[1] by using different constructions and by an appropriate exploitation of the
Lov\&#39;asz Local Lemma in this context. Our findings also suggest $O(n^k)$
randomized Las Vegas algorithms for the construction of such codes. We also
extend our results to Two-Stage Group Testing algorithms with runlength
constraints.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Shape-Faithful Graph Drawings</title>
  <guid>http://arxiv.org/abs/2208.14095</guid>
  <link>http://arxiv.org/abs/2208.14095</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meidiana_A/0/1/0/all/0/1&quot;&gt;Amyra Meidiana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1&quot;&gt;Seok-Hee Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eades_P/0/1/0/all/0/1&quot;&gt;Peter Eades&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Shape-based metrics measure how faithfully a drawing D represents the
structure of a graph G, using the proximity graph S of D. While some limited
graph classes admit proximity drawings (i.e., optimally shape-faithful
drawings, where S = G), algorithms for shape-faithful drawings of general
graphs have not been investigated. In this paper, we present the first study
for shape-faithful drawings of general graphs. First, we conduct extensive
comparison experiments for popular graph layouts using the shape-based metrics,
and examine the properties of highly shape-faithful drawings. Then, we present
ShFR and ShSM, algorithms for shape-faithful drawings based on force-directed
and stress-based algorithms, by introducing new proximity forces/stress.
Experiments show that ShFR and ShSM obtain significant improvement over FR
(Fruchterman-Reingold) and SM (Stress Majorization), on average 12% and 35%
respectively, on shape-based metrics.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Small Point-Sets Supporting Graph Stories</title>
  <guid>http://arxiv.org/abs/2208.14126</guid>
  <link>http://arxiv.org/abs/2208.14126</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Battista_G/0/1/0/all/0/1&quot;&gt;Giuseppe Di Battista&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Didimo_W/0/1/0/all/0/1&quot;&gt;Walter Didimo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grilli_L/0/1/0/all/0/1&quot;&gt;Luca Grilli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosso_F/0/1/0/all/0/1&quot;&gt;Fabrizio Grosso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortali_G/0/1/0/all/0/1&quot;&gt;Giacomo Ortali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patrignani_M/0/1/0/all/0/1&quot;&gt;Maurizio Patrignani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tappini_A/0/1/0/all/0/1&quot;&gt;Alessandra Tappini&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a graph story the vertices enter a graph one at a time and each vertex
persists in the graph for a fixed amount of time $\omega$, called viewing
window. At any time, the user can see only the drawing of the graph induced by
the vertices in the viewing window and this determines a sequence of drawings.
For readability, we require that all the drawings of the sequence are planar.
For preserving the user&#39;s mental map we require that when a vertex or an edge
is drawn, it has the same drawing for its entire life. We study the problem of
drawing the entire sequence by mapping the vertices only to $\omega+k$ given
points, where $k$ is as small as possible. We show that: $(i)$ The problem does
not depend on the specific set of points but only on its size; $(ii)$ the
problem is NP-hard and is FPT when parameterized by $\omega+k$; $(iii)$ there
are families of graph stories that can be drawn with $k=0$ for any $\omega$,
while for $k=0$ and small values of $\omega$ there are families of graph
stories that can be drawn and others that cannot; $(iv)$ there are families of
graph stories that cannot be drawn for any fixed $k$ and families of graph
stories that require at least a certain $k$.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On the Fixed-Parameter Tractability of Capacitated Clustering</title>
  <guid>http://arxiv.org/abs/2208.14129</guid>
  <link>http://arxiv.org/abs/2208.14129</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1&quot;&gt;Vincent Cohen-Addad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jason Li&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the complexity of the classic capacitated k-median and k-means
problems parameterized by the number of centers, k. These problems are
notoriously difficult since the best known approximation bound for high
dimensional Euclidean space and general metric space is $\Theta(\log k)$ and it
remains a major open problem whether a constant factor exists. We show that
there exists a $(3+\epsilon)$-approximation algorithm for the capacitated
k-median and a $(9+\epsilon)$-approximation algorithm for the capacitated
k-means problem in general metric spaces whose running times are $f(\epsilon,k)
n^{O(1)}$. For Euclidean inputs of arbitrary dimension, we give a
$(1+\epsilon)$-approximation algorithm for both problems with a similar running
time. This is a significant improvement over the $(7+\epsilon)$-approximation
of Adamczyk et al. for k-median in general metric spaces and the
$(69+\epsilon)$-approximation of Xu et al. for Euclidean k-means.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Approximation Algorithms for Drone Delivery Packing Problem</title>
  <guid>http://arxiv.org/abs/2208.14304</guid>
  <link>http://arxiv.org/abs/2208.14304</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jana_S/0/1/0/all/0/1&quot;&gt;Saswata Jana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandal_P/0/1/0/all/0/1&quot;&gt;Partha Sarathi Mandal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Recent advancements in unmanned aerial vehicles, also known as drones, have
motivated logistics to use drones for multiple operations. Collaboration
between drones and trucks in a last-mile delivery system has numerous benefits
and reduces a number of challenges. In this paper, we introduce
\textit{drone-delivery packing problem} (DDP), where we have a set of
deliveries and respective customers with their prescribed locations, delivery
time intervals, associated cost for deliveries, and a set of drones with
identical battery budgets. The objective of the DDP is to find an assignment
for all deliveries to the drones by using the minimum number of drones subject
to the battery budget and compatibility of the assignment of each drone. We
prove that DDP is NP-Hard and formulate the integer linear programming (ILP)
formulation for it. We proposed two greedy approximation algorithms for DDP.
The first algorithm uses at most $2OPT + (\Delta + 1)$ drones. The second
algorithm uses at most $2OPT + \omega$ drones, where OPT is the optimum
solution for DDP, $\omega$ is the maximum clique size, and $\Delta$ is the
maximum degree of the interval graph $G$ constructed from the delivery time
intervals.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Sorting Genomes by Prefix Double-Cut-and-Joins</title>
  <guid>http://arxiv.org/abs/2208.14315</guid>
  <link>http://arxiv.org/abs/2208.14315</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fertin_G/0/1/0/all/0/1&quot;&gt;Guillaume Fertin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jean_G/0/1/0/all/0/1&quot;&gt;G&amp;#xe9;raldine Jean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Labarre_A/0/1/0/all/0/1&quot;&gt;Anthony Labarre&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we study the problem of sorting unichromosomal linear genomes
by prefix double-cut-and-joins (or DCJs) in both the signed and the unsigned
settings. Prefix DCJs cut the leftmost segment of a genome and any other
segment, and recombine the severed endpoints in one of two possible ways: one
of these options corresponds to a prefix reversal, which reverses the order of
elements between the two cuts (as well as their signs in the signed case).
Depending on whether we consider both options or reversals only, our main
results are:
&lt;/p&gt;
&lt;p&gt;(1) new structural lower bounds based on the breakpoint graph for sorting by
unsigned prefix reversals, unsigned prefix DCJs, or signed prefix DCJs;
&lt;/p&gt;
&lt;p&gt;(2) a polynomial-time algorithm for sorting by signed prefix DCJs, thus
answering an open question in [8];
&lt;/p&gt;
&lt;p&gt;(3) a 3/2-approximation for sorting by unsigned prefix DCJs, which is, to the
best of our knowledge, the first sorting by {\em prefix} rearrangements problem
that admits an approximation ratio strictly smaller than 2 (with the obvious
exception of the polynomial-time solvable problems); and finally,
&lt;/p&gt;
&lt;p&gt;(4) an FPT algorithm for sorting by unsigned prefix DCJs parameterised by the
number of breakpoints in the genome.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Improved Deterministic Algorithms for Non-monotone Submodular Maximization</title>
  <guid>http://arxiv.org/abs/2208.14388</guid>
  <link>http://arxiv.org/abs/2208.14388</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xiaoming Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jialin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhijie Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Submodular maximization is one of the central topics in combinatorial
optimization. It has found numerous applications in the real world. In the past
decades, a series of algorithms have been proposed for this problem. However,
most of the state-of-the-art algorithms are randomized. There remain
non-negligible gaps with respect to approximation ratios between deterministic
and randomized algorithms in submodular maximization. In this paper, we propose
deterministic algorithms with improved approximation ratios for non-monotone
submodular maximization. Specifically, for the matroid constraint, we provide a
deterministic $0.283-o(1)$ approximation algorithm, while the previous best
deterministic algorithm only achieves a $1/4$ approximation ratio. For the
knapsack constraint, we provide a deterministic $1/4$ approximation algorithm,
while the previous best deterministic algorithm only achieves a $1/6$
approximation ratio.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-31 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Busy Beaver Updates: Now Even Busier</title>
  <guid>https://scottaaronson.blog/?p=6673</guid>
  <link>https://scottaaronson.blog/?p=6673</link>
  <description>
    &lt;p&gt;Way back in the covid-filled summer of 2020, I &lt;a href=&quot;https://scottaaronson.blog/?p=4916&quot;&gt;wrote a survey article&lt;/a&gt; about the ridiculously-rapidly-growing &lt;a href=&quot;https://en.wikipedia.org/wiki/Busy_beaver&quot;&gt;Busy Beaver function&lt;/a&gt;.  My survey then expanded to nearly twice its original length, with the ideas, observations, and open problems of commenters on this blog.  Ever since, I&amp;#8217;ve felt a sort of duty to blog later developments in BusyBeaverology as well.  It&amp;#8217;s like, I&amp;#8217;ve built my dam, I&amp;#8217;ve built my lodge, I&amp;#8217;m here in the pond to stay!&lt;/p&gt;



&lt;p&gt;So without further ado:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;This May, Pavel Kropitz &lt;a href=&quot;https://groups.google.com/g/busy-beaver-discuss/c/-zjeW6y8ER4/m/ZBuLvbVOAgAJ&quot;&gt;found&lt;/a&gt; a machine demonstrating that $$ BB(6) \ge 10^{10^{10^{10^{10^{10^{10^{10^{10^{10^{10^{10^{10^{10^{10}}}}}}}}}}}}}} $$ (15 times)&amp;#8212;thereby blasting through his own 2010 record, that BB(6)≥10&lt;sup&gt;36,534&lt;/sup&gt;.  Or, for those tuning in from home: Kropitz constructed a 6-state, 2-symbol, 1-tape Turing machine that runs for at least the above number of steps, when started on an initially blank tape, &lt;em&gt;and then halt&lt;/em&gt;.  The machine was &lt;a href=&quot;https://groups.google.com/g/busy-beaver-discuss/c/-zjeW6y8ER4/m/Qv2qfJ5-AAAJ&quot;&gt;analyzed&lt;/a&gt; and &lt;a href=&quot;https://webusers.imj-prg.fr/~pascal.michel/bbc.html&quot;&gt;verified&lt;/a&gt; by Pascal Michel, the modern keeper of Busy Beaver lore.  In my 2020 survey, I&amp;#8217;d relayed an open problem posed by my then 7-year-old daughter Lily: namely, what&amp;#8217;s the first n such that BB(n) exceeds A(n), the n&lt;sup&gt;th&lt;/sup&gt; value of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Ackermann_function&quot;&gt;Ackermann function&lt;/a&gt;?  All that&amp;#8217;s been proven is that this n is at least 5 and at most 18.  Kropitz and Michel&amp;#8217;s discovery doesn&amp;#8217;t settle the question&amp;#8212;titanic though it is, the new lower bound on BB(6) is &lt;em&gt;still&lt;/em&gt; less than A(6) (!!)&amp;#8212;but in light of this result, I now strongly conjecture that the crossover happens at either n=6 or n=7.  Huge congratulations to Pavel and Pascal!&lt;/li&gt;&lt;/ul&gt;



&lt;ul&gt;&lt;li&gt;Tristan Stérin and Damien Woods wrote to tell me about a new collaborative initiative they&amp;#8217;ve launched called &lt;a href=&quot;https://bbchallenge.org/62366474&quot;&gt;BB Challenge&lt;/a&gt;.  With the participation of other leading figures in the neither-large-nor-sprawling Busy Beaver world, Tristan and Damien are aiming, not only to pin down the value of BB(5)&amp;#8212;proving or disproving the longstanding conjecture that BB(5)=47,176,870&amp;#8212;but to do so in a &lt;em&gt;formally verified way&lt;/em&gt;, with none of the old ambiguities about which Turing machines have or haven&amp;#8217;t been satisfactorily analyzed.  In my survey article, I&amp;#8217;d passed along a claim that, of all the 5-state machines, only 25 remained to be analyzed, to understand whether or not they run forever&amp;#8212;the &amp;#8220;default guess&amp;#8221; being that they all do, but that proving it for some of them might require fearsomely difficult number theory.  With their more formal and cautious approach, Tristan and Damien still count 1.5 million (!) holdout machines, but they hope to cut down that number extremely rapidly.  If you&amp;#8217;re feeling yourself successfully nerd-sniped, please join the quest and help them out!&lt;/li&gt;&lt;/ul&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 22:38:19 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>TR22-122 |  Efficient Linearization Implies the Multiphase Conjecture | 

	Young Kun Ko</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/122</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/122</link>
  <description>
    The main motivation for studying linear data structures and circuits is the intuition that non-linear advice cannot help in computing a linear operator. Jukna and Schnitger formalized this as a conjecture which states that all circuits computing a linear operator can be ``linearized,&amp;quot; with only a constant size blow-up. We show that if we assume strengthening of this intuition to data structures (to some field), then this implies Patrascu’s Multiphase Conjecture for such field. Furthermore, we show that this conjecture is an intermediate conjecture between NOF-Multiphase Conjecture and the Multiphase Conjecture, formalizing why Patrascu&amp;#39;s original approach to the Multiphase Conjecture is hard.
	
	Our main technical ingredient is proving unconditional space-time tradeoff for the following static data structure problem for any given field: Let $M \in \mathbb{F}^{m \times n}$ be fixed. Data structure preprocesses input $X \in \mathbb{F}^n$ using $s$-cells (dependant on $M$), each of which can store an arbitrary element in $\mathbb{F}$. When $i \in [m]$ is revealed, the data structure can output $M_i \cdot X$ using $t_q$ probes. We show that there exists $M \in \{ 0 , 1 \}^{m \times n}$ such that if the functions used by the data structure are all linear and $s \leq \tilde{o} ( m )$ then $t_q \geq \tilde{\Omega}(n)$.
	
	As a corollary, we show that Patrascu&amp;#39;s Multiphase Conjecture when restricted to dynamic linear data structure holds (with unlimited preprocessing) over any field. This exhibits an explicit dynamic data structure which requires polynomial update time $t_u \geq \tilde{\Omega}(n)$ or query time $t_q \geq \tilde{\Omega}(n)$. This also improves upon the breakthrough work of Larsen which showed a polynomial lower bound for dynamic data structure under the weaker group model.
  </description>
  <pubDate>2022-08-30 16:58:32 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Reducing Computational Complexity of Neural Networks in Optical Channel Equalization: From Concepts to Implementation</title>
  <guid>http://arxiv.org/abs/2208.12866</guid>
  <link>http://arxiv.org/abs/2208.12866</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Freire_P/0/1/0/all/0/1&quot;&gt;Pedro J. Freire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Napoli_A/0/1/0/all/0/1&quot;&gt;Antonio Napoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ron_D/0/1/0/all/0/1&quot;&gt;Diego Arguello Ron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Spinnler_B/0/1/0/all/0/1&quot;&gt;Bernhard Spinnler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Anderson_M/0/1/0/all/0/1&quot;&gt;Michael Anderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Schairer_W/0/1/0/all/0/1&quot;&gt;Wolfgang Schairer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bex_T/0/1/0/all/0/1&quot;&gt;Thomas Bex&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Costa_N/0/1/0/all/0/1&quot;&gt;Nelson Costa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Turitsyn_S/0/1/0/all/0/1&quot;&gt;Sergei K. Turitsyn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Prilepsky_J/0/1/0/all/0/1&quot;&gt;Jaroslaw E. Prilepsky&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, a new methodology is proposed that allows for the
low-complexity development of neural network (NN) based equalizers for the
mitigation of impairments in high-speed coherent optical transmission systems.
In this work, we provide a comprehensive description and comparison of various
deep model compression approaches that have been applied to feed-forward and
recurrent NN designs. Additionally, we evaluate the influence these strategies
have on the performance of each NN equalizer. Quantization, weight clustering,
pruning, and other cutting-edge strategies for model compression are taken into
consideration. In this work, we propose and evaluate a Bayesian
optimization-assisted compression, in which the hyperparameters of the
compression are chosen to simultaneously reduce complexity and improve
performance. In conclusion, the trade-off between the complexity of each
compression approach and its performance is evaluated by utilizing both
simulated and experimental data in order to complete the analysis. By utilizing
optimal compression approaches, we show that it is possible to design an
NN-based equalizer that is simpler to implement and has better performance than
the conventional digital back-propagation (DBP) equalizer with only one step
per span. This is accomplished by reducing the number of multipliers used in
the NN equalizer after applying the weighted clustering and pruning algorithms.
Furthermore, we demonstrate that an equalizer based on NN can also achieve
superior performance while still maintaining the same degree of complexity as
the full electronic chromatic dispersion compensation block. We conclude our
analysis by highlighting open questions and existing challenges, as well as
possible future research directions.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Randomised Composition and Small-Bias Minimax</title>
  <guid>http://arxiv.org/abs/2208.12896</guid>
  <link>http://arxiv.org/abs/2208.12896</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ben_David_S/0/1/0/all/0/1&quot;&gt;Shalev Ben-David&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blais_E/0/1/0/all/0/1&quot;&gt;Eric Blais&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goos_M/0/1/0/all/0/1&quot;&gt;Mika G&amp;#xf6;&amp;#xf6;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maystre_G/0/1/0/all/0/1&quot;&gt;Gilbert Maystre&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove two results about randomised query complexity $\mathrm{R}(f)$.
First, we introduce a &quot;linearised&quot; complexity measure $\mathrm{LR}$ and show
that it satisfies an inner-optimal composition theorem: $\mathrm{R}(f\circ g)
\geq \Omega(\mathrm{R}(f) \mathrm{LR}(g))$ for all partial $f$ and $g$, and
moreover, $\mathrm{LR}$ is the largest possible measure with this property. In
particular, $\mathrm{LR}$ can be polynomially larger than previous measures
that satisfy an inner composition theorem, such as the max-conflict complexity
of Gavinsky, Lee, Santha, and Sanyal (ICALP 2019).
&lt;/p&gt;
&lt;p&gt;Our second result addresses a question of Yao (FOCS 1977). He asked if
$\epsilon$-error expected query complexity $\bar{\mathrm{R}}_{\epsilon}(f)$
admits a distributional characterisation relative to some hard input
distribution. Vereshchagin (TCS 1998) answered this question affirmatively in
the bounded-error case. We show that an analogous theorem fails in the
small-bias case $\epsilon=1/2-o(1)$.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>An invitation to the promise constraint satisfaction problem</title>
  <guid>http://arxiv.org/abs/2208.13538</guid>
  <link>http://arxiv.org/abs/2208.13538</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krokhin_A/0/1/0/all/0/1&quot;&gt;Andrei Krokhin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oprsal_J/0/1/0/all/0/1&quot;&gt;Jakub Opr&amp;#x161;al&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The study of the complexity of the constraint satisfaction problem (CSP),
centred around the Feder-Vardi Dichotomy Conjecture, has been very prominent in
the last two decades. After a long concerted effort and many partial results,
the Dichotomy Conjecture has been proved in 2017 independently by Bulatov and
Zhuk. At about the same time, a vast generalisation of CSP, called promise CSP,
has started to gain prominence. In this survey, we explain the importance of
promise CSP and highlight many new very interesting features that the study of
promise CSP has brought to light. The complexity classification quest for the
promise CSP is wide open, and we argue that, despite the promise CSP being more
general, this quest is rather more accessible to a wide range of researchers
than the dichotomy-led study of the CSP has been.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Ortho-unit polygons can be guarded with at most $\lfloor \frac{n-4}{8} \rfloor$ guards</title>
  <guid>http://arxiv.org/abs/2208.12864</guid>
  <link>http://arxiv.org/abs/2208.12864</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1&quot;&gt;J.M. D&amp;#xed;az-B&amp;#xe1;&amp;#xf1;ez&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horn_P/0/1/0/all/0/1&quot;&gt;P. Horn&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopez_M/0/1/0/all/0/1&quot;&gt;M.A. Lopez&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marin_N/0/1/0/all/0/1&quot;&gt;N. Mar&amp;#xed;n&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramirez_Vigueras_A/0/1/0/all/0/1&quot;&gt;A. Ram&amp;#xed;rez-Vigueras&lt;/a&gt; (5), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sole_Pi_O/0/1/0/all/0/1&quot;&gt;O. Sol&amp;#xe9;-Pi&lt;/a&gt; (6), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stevens_A/0/1/0/all/0/1&quot;&gt;A. Stevens&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1&quot;&gt;J. Urrutia&lt;/a&gt; (5) ((1) Departamento de Matem&amp;#xe1;tica Aplicada II, Universidad de Sevilla, Spain. (2) Department of Mathematics, University of Denver, USA. (3) Department of Computer Science, University of Denver, USA. (4) Posgrado en Ciencia e Ingenier&amp;#xed;a de la Computaci&amp;#xf3;n, Universidad Nacional Aut&amp;#xf3;noma de M&amp;#xe9;xico, Mexico., (5) Instituto de Matem&amp;#xe1;ticas, Universidad Nacional Aut&amp;#xf3;noma de M&amp;#xe9;xico, Mexico. (6) Facultad de Ciencias, Universidad Nacional Aut&amp;#xf3;noma de M&amp;#xe9;xico, Mexico)&lt;/p&gt;&lt;p&gt;An orthogonal polygon is called an ortho-unit polygon if its vertices have
integer coordinates, and all of its edges have length one. In this paper we
prove that any ortho-unit polygon with $n \geq 12$ vertices can be guarded with
at most $\lfloor \frac{n-4}{8} \rfloor$ guards.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>An FPT Algorithm for Bipartite Vertex Splitting</title>
  <guid>http://arxiv.org/abs/2208.12898</guid>
  <link>http://arxiv.org/abs/2208.12898</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_R/0/1/0/all/0/1&quot;&gt;Reyan Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kobourov_S/0/1/0/all/0/1&quot;&gt;Stephen Kobourov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kryven_M/0/1/0/all/0/1&quot;&gt;Myroslav Kryven&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Bipartite graphs model the relationship between two disjoint sets of objects.
They have a wide range of applications and are often visualized as a 2-layered
drawing, where each set of objects is visualized as a set of vertices (points)
on one of the two parallel horizontal lines and the relationships are
represented by edges (simple curves) between the two lines connecting the
corresponding vertices. One of the common objectives in such drawings is to
minimize the number of crossings this, however, is computationally expensive
and may still result in drawings with so many crossings that they affect the
readability of the drawing. We consider a recent approach to remove crossings
in such visualizations by splitting vertices, where the goal is to find the
minimum number of vertices to be split to obtain a planar drawing. We show that
determining whether a planar drawing exists after splitting at most $k$
vertices is fixed parameter tractable in $k$.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Distinct Angles and Angle Chains in Three Dimensions</title>
  <guid>http://arxiv.org/abs/2208.13284</guid>
  <link>http://arxiv.org/abs/2208.13284</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ascoli_R/0/1/0/all/0/1&quot;&gt;Ruben Ascoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Betti_L/0/1/0/all/0/1&quot;&gt;Livia Betti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duke_J/0/1/0/all/0/1&quot;&gt;Jacob Lehmann Duke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xuyan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milgrim_W/0/1/0/all/0/1&quot;&gt;Wyatt Milgrim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_S/0/1/0/all/0/1&quot;&gt;Steven J. Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palsson_E/0/1/0/all/0/1&quot;&gt;Eyvindur A. Palsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Acosta_F/0/1/0/all/0/1&quot;&gt;Francisco Romero Acosta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iannuzzelli_S/0/1/0/all/0/1&quot;&gt;Santiago Velazquez Iannuzzelli&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In 1946, Erd\H{o}s posed the distinct distance problem, which seeks to find
the minimum number of distinct distances between pairs of points selected from
any configuration of $n$ points in the plane. The problem has since been
explored along with many variants, including ones that extend it into higher
dimensions. Less studied but no less intriguing is Erd\H{o}s&#39; distinct angle
problem, which seeks to find point configurations in the plane that minimize
the number of distinct angles. In their recent paper &quot;Distinct Angles in
General Position,&quot; Fleischmann, Konyagin, Miller, Palsson, Pesikoff, and Wolf
use a logarithmic spiral to establish an upper bound of $O(n^2)$ on the minimum
number of distinct angles in the plane in general position, which prohibits
three points on any line or four on any circle.
&lt;/p&gt;
&lt;p&gt;We consider the question of distinct angles in three dimensions and provide
bounds on the minimum number of distinct angles in general position in this
setting. We focus on pinned variants of the question, and we examine explicit
constructions of point configurations in $\mathbb{R}^3$ which use
self-similarity to minimize the number of distinct angles. Furthermore, we
study a variant of the distinct angles question regarding distinct angle chains
and provide bounds on the minimum number of distinct chains in $\mathbb{R}^2$
and $\mathbb{R}^3$.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Strictly-Convex Drawings of $3$-Connected Planar Graphs</title>
  <guid>http://arxiv.org/abs/2208.13388</guid>
  <link>http://arxiv.org/abs/2208.13388</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bekos_M/0/1/0/all/0/1&quot;&gt;Michael A. Bekos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gronemann_M/0/1/0/all/0/1&quot;&gt;Martin Gronemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montecchiani_F/0/1/0/all/0/1&quot;&gt;Fabrizio Montecchiani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Symvonis_A/0/1/0/all/0/1&quot;&gt;Antonios Symvonis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Strictly-convex straight-line drawings of $3$-connected planar graphs in
small area form a classical research topic in Graph Drawing. Currently, the
best-known area bound for such drawings is $O(n^2) \times O(n^2)$, as shown by
B\&#39;{a}r\&#39;{a}ny and Rote by means of a sophisticated technique based on
perturbing (non-strictly) convex drawings. Unfortunately, the hidden constants
in such area bound are in the $10^4$ order.
&lt;/p&gt;
&lt;p&gt;We present a new and easy-to-implement technique that yields strictly-convex
straight-line planar drawings of $3$-connected planar graphs on an integer grid
of size $2(n-1) \times (5n^3-4n^2)$.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Planar Confluent Orthogonal Drawings of 4-Modal Digraphs</title>
  <guid>http://arxiv.org/abs/2208.13446</guid>
  <link>http://arxiv.org/abs/2208.13446</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cornelsen_S/0/1/0/all/0/1&quot;&gt;Sabine Cornelsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diatzko_G/0/1/0/all/0/1&quot;&gt;Gregor Diatzko&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a planar confluent orthogonal drawing (PCOD) of a directed graph (digraph)
vertices are drawn as points in the plane and edges as orthogonal polylines
starting with a vertical segment and ending with a horizontal segment. Edges
may overlap in their first or last segment, but must not intersect otherwise.
PCODs can be seen as a directed variant of Kandinsky drawings or as planar
L-drawings of subdivisions of digraphs. The maximum number of subdivision
vertices in an edge is then the split complexity. A PCOD is upward if each edge
is drawn with monotonically increasing y-coordinates and quasi-upward if no
edge starts with decreasing y-coordinates. We study the split complexity of
PCODs and (quasi-)upward PCODs for various classes of graphs.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Recognizing DAGs with Page-Number 2 is NP-complete</title>
  <guid>http://arxiv.org/abs/2208.13615</guid>
  <link>http://arxiv.org/abs/2208.13615</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bekos_M/0/1/0/all/0/1&quot;&gt;Michael A. Bekos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozzo_G/0/1/0/all/0/1&quot;&gt;Giordano Da Lozzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frati_F/0/1/0/all/0/1&quot;&gt;Fabrizio Frati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gronemann_M/0/1/0/all/0/1&quot;&gt;Martin Gronemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mchedlidze_T/0/1/0/all/0/1&quot;&gt;Tamara Mchedlidze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raftopoulou_C/0/1/0/all/0/1&quot;&gt;Chrysanthi N. Raftopoulou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The page-number of a directed acyclic graph (a DAG, for short) is the minimum
$k$ for which the DAG has a topological order and a $k$-coloring of its edges
such that no two edges of the same color cross, i.e., have alternating
endpoints along the topological order. In 1999, Heath and Pemmaraju conjectured
that the recognition of DAGs with page-number $2$ is NP-complete and proved
that recognizing DAGs with page-number $6$ is NP-complete [SIAM J. Computing,
1999]. Binucci et al. recently strengthened this result by proving that
recognizing DAGs with page-number $k$ is NP-complete, for every $k\geq 3$ [SoCG
2019]. In this paper, we finally resolve Heath and Pemmaraju&#39;s conjecture in
the affirmative. In particular, our NP-completeness result holds even for
$st$-planar graphs and planar posets.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Efficiently Computing the Shapley Value of Connectivity Games in Low-Treewidth Graphs</title>
  <guid>http://arxiv.org/abs/2208.12868</guid>
  <link>http://arxiv.org/abs/2208.12868</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zanden_T/0/1/0/all/0/1&quot;&gt;Tom C. van der Zanden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bodlaender_H/0/1/0/all/0/1&quot;&gt;Hans L. Bodlaender&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamers_H/0/1/0/all/0/1&quot;&gt;Herbert J.M. Hamers&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Shapley value is the solution concept in cooperative game theory that is
most used in both theoretical as practical settings. Unfortunately, computing
the Shapley value is computationally intractable in general. This paper focuses
on computing the Shapley value of (weighted) connectivity games. For these
connectivity games, that are defined on an underlying (weighted) graph,
computing the Shapley value is #P-hard, and thus (likely) intractable even for
graphs with a moderate number of vertices. We present an algorithm that can
efficiently compute the Shapley value if the underlying graph has bounded
treewidth. Next, we apply our algorithm to several real-world (covert)
networks. We show that our algorithm can compute exact Shapley values for these
networks quickly, whereas in prior work these values could only be approximated
using a heuristic method. Finally, it is shown that our algorithm can also
compute the Shapley value time efficiently for several larger (artificial)
benchmark graphs from the PACE 2018 challenge.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Distributed Multilevel Memetic Algorithm for Signed Graph Clustering</title>
  <guid>http://arxiv.org/abs/2208.13618</guid>
  <link>http://arxiv.org/abs/2208.13618</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hausberger_F/0/1/0/all/0/1&quot;&gt;Felix Hausberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faraj_M/0/1/0/all/0/1&quot;&gt;Marcelo Fonseca Faraj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulz_C/0/1/0/all/0/1&quot;&gt;Christian Schulz&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In real-world applications, interactions between two entities can be usually
represented by signed graphs, i.e., graphs containing edges with positive
weight representing node attraction and edges with negative weight representing
node repulsion. A relevant problem for the analysis of a graph is to find a
graph clustering, i.e., a partition of its nodes into clusters such that nodes
contained in the same cluster are densely connected by positive edges and
sparsely connected by negative edges. In this work, we propose and engineer all
the details of a memetic algorithm based on a novel multilevel approach for the
problem. Experimental results show that our memetic strategy computes
significantly better solutions than the current state-of-the-art.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Finding Near-Optimal Weight Independent Sets at Scale</title>
  <guid>http://arxiv.org/abs/2208.13645</guid>
  <link>http://arxiv.org/abs/2208.13645</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grossmann_E/0/1/0/all/0/1&quot;&gt;Ernestine Gro&amp;#xdf;mann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lamm_S/0/1/0/all/0/1&quot;&gt;Sebastian Lamm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulz_C/0/1/0/all/0/1&quot;&gt;Christian Schulz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strash_D/0/1/0/all/0/1&quot;&gt;Darren Strash&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Computing maximum weight independent sets in graphs is an important NP-hard
optimization problem. The problem is particularly difficult to solve in large
graphs for which data reduction techniques do not work well. To be more
precise, state-of-the-art branch-and-reduce algorithms can solve many
large-scale graphs if reductions are applicable. However, if this is not the
case, their performance quickly degrades due to branching requiring exponential
time. In this paper, we develop an advanced memetic algorithm to tackle the
problem, which incorporates recent data reduction techniques to compute
near-optimal weighted independent sets in huge sparse networks. More precisely,
we use a memetic approach to recursively choose vertices that are likely to be
in a large-weight independent set. We include these vertices into the solution,
and then further reduce the graph. We show that identifying and removing
vertices likely to be in large-weight independent sets opens up the reduction
space and speeds up the computation of large-weight independent sets
remarkably. Our experimental evaluation indicates that we are able to
outperform state-of-the-art algorithms. For example, our algorithm computes the
best results among all competing algorithms for 33 out of 35 instances. Thus
can be seen as the dominating tool when large weight independent sets need to
be computed in~practice.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Minimizing Completion Times for Stochastic Jobs via Batched Free Times</title>
  <guid>http://arxiv.org/abs/2208.13696</guid>
  <link>http://arxiv.org/abs/2208.13696</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Anupam Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1&quot;&gt;Benjamin Moseley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1&quot;&gt;Rudy Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the classic problem of minimizing the expected total completion time
of jobs on $m$ identical machines in the setting where the sizes of the jobs
are stochastic. Specifically, the size of each job is a random variable whose
distribution is known to the algorithm, but whose realization is revealed only
after the job is scheduled. While minimizing the total completion time is easy
in the deterministic setting, the stochastic problem has long been notorious:
all known algorithms have approximation ratios that either depend on the
variances, or depend linearly on the number of machines.
&lt;/p&gt;
&lt;p&gt;We give an $\widetilde{O}(\sqrt{m})$-approximation for stochastic jobs which
have Bernoulli processing times. This is the first approximation for this
problem that is both independent of the variance in the job sizes, and is
sublinear in the number of machines $m$. Our algorithm is based on a novel
reduction from minimizing the total completion time to a natural makespan-like
objective, which we call the weighted free time. We hope this free time
objective will be useful in further improvements to this problem, as well as
other stochastic scheduling problems.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Graph Exploration with Embedding-Guided Layouts</title>
  <guid>http://arxiv.org/abs/2208.13699</guid>
  <link>http://arxiv.org/abs/2208.13699</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tai_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Tai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1&quot;&gt;Leixian Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_E/0/1/0/all/0/1&quot;&gt;Enya Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianmin Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Node-link diagrams are widely used to visualize graphs. Most graph layout
algorithms only consider graph topology or node attributes for aesthetic goals
(e.g., with fewer edge crossings and node occlusions), resulting in information
loss and waste. Existing hybrid approaches that bind the two perspectives
mostly build layouts on top of the attribute-based communities to better
satisfy exploration goals. However, they usually suffer from high human
dependency, input restriction, and loosely-coupled bindings of topology and
attributes, thus may have limited substantial improvements to the layout
quality. In this paper, we propose an embedding-based graph exploration
pipeline to enjoy the best of both graph topology and node attributes. First,
we leverage embedding algorithms for attributed graphs to encode the two
perspectives into latent space. Then, we present an embedding-driven graph
layout algorithm, GEGraph, which can achieve aesthetic layouts with better
community preservation to support an easy interpretation of the graph
structure. Next, graph explorations are extended based on the generated graph
layout and insights extracted from the embedding vectors. Illustrated with
examples, we build a layout-preserving aggregation method with Focus+Context
interaction and a related nodes searching approach with multiple proximity
strategies. Finally, we conduct quantitative and qualitative evaluations, a
user study, and two case studies to validate our approach.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Configuration Balancing for Stochastic Requests</title>
  <guid>http://arxiv.org/abs/2208.13702</guid>
  <link>http://arxiv.org/abs/2208.13702</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eberle_F/0/1/0/all/0/1&quot;&gt;Franziska Eberle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Anupam Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Megow_N/0/1/0/all/0/1&quot;&gt;Nicole Megow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1&quot;&gt;Benjamin Moseley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1&quot;&gt;Rudy Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The configuration balancing problem with stochastic requests generalizes many
well-studied resource allocation problems such as load balancing and virtual
circuit routing. In it, we have $m$ resources and $n$ requests. Each request
has multiple possible configurations, each of which increases the load of each
resource by some amount. The goal is to select one configuration for each
request to minimize the makespan: the load of the most-loaded resource. In our
work, we focus on a stochastic setting, where we only know the distribution for
how each configuration increases the resource loads, learning the realized
value only after a configuration is chosen.
&lt;/p&gt;
&lt;p&gt;We develop both offline and online algorithms for configuration balancing
with stochastic requests. When the requests are known offline, we give a
non-adaptive policy for configuration balancing with stochastic requests that
$O(\frac{\log m}{\log \log m})$-approximates the optimal adaptive policy. In
particular, this closes the adaptivity gap for this problem as there is an
asymptotically matching lower bound even for the very special case of load
balancing on identical machines. When requests arrive online in a list, we give
a non-adaptive policy that is $O(\log m)$ competitive. Again, this result is
asymptotically tight due to information-theoretic lower bounds for very special
cases (e.g., for load balancing on unrelated machines). Finally, we show how to
leverage adaptivity in the special case of load balancing on related machines
to obtain a constant-factor approximation offline and an $O(\log \log
m)$-approximation online. A crucial technical ingredient in all of our results
is a new structural characterization of the optimal adaptive policy that allows
us to limit the correlations between its decisions.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>That Financial Times QC skepticism piece</title>
  <guid>https://scottaaronson.blog/?p=6670</guid>
  <link>https://scottaaronson.blog/?p=6670</link>
  <description>
    &lt;p&gt;Several people have asked me to comment about a &lt;em&gt;Financial Times&lt;/em&gt; opinion piece entitled &lt;a href=&quot;https://www.ft.com/content/6d2e34ab-f9fd-4041-8a96-91802bab7765?accessToken=zwAAAYLqUflnkc9tLjSr-f1AQdOKlpGAK6t3ZQ.MEQCICfhbcBVMq-Z9bpXglona31mh7dWdi7b-TDRB9S6-mKrAiA4b25zNf-97bLQXsO1JLXGdhp7UkM8yfaK5TIBfHWCJQ&amp;amp;sharetype=gift&amp;amp;token=eb5313cd-6f61-4aff-b462-ad7f250c316a&quot;&gt;The Quantum Computing Bubble&lt;/a&gt; (subtitle: &amp;#8220;The industry has yet to demonstrate any real utility, despite the fanfare, billions of VC dollars and three Spacs&amp;#8221;) (&lt;a href=&quot;https://archive.ph/PBHhe&quot;&gt;archive link&lt;/a&gt;).  The piece is purely deflationary&amp;#8212;not a positive word in it&amp;#8212;though it never goes so far as to suggest that QC is blocked by any Gil-Kalai-like fundamental principle, nor does it even evince curiosity about that question.&lt;/p&gt;



&lt;p&gt;As it happens, the author, physicist Nikita Gourianov, had emailed me a few days ago with some nice words about my own skeptical efforts on &lt;em&gt;Shtetl-Optimized&lt;/em&gt;, and a request for comment on his article.  So, as a way to get back into blogging after a 2-week hiatus, I figured I&amp;#8217;d share my respoinse.&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator has-alpha-channel-opacity&quot;/&gt;



&lt;p&gt;Hi Nikita,&lt;/p&gt;



&lt;p&gt;Thanks for the kind words about my blog, and for your piece, which I just read.  There’s a great deal of truth in what you write, but I also take issue with a few points.  You say:&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;&lt;p&gt;A convincing strategy for overcoming these errors has not yet been demonstrated, making it unclear as to when — if ever — it will become possible to build a large-scale, fault-tolerant quantum computer.&lt;/p&gt;&lt;/blockquote&gt;



&lt;p&gt;In one sense this is tautologically true — the only fully convincing and clear demonstration that something is possible is to do it, as with the Wright brothers or the Trinity nuclear test.&amp;nbsp; In other sense, though, we’ve known the “strategy” since the 1990s.&amp;nbsp; It’s just that the fault-tolerance theorem called for gate fidelities 5-6 orders of magnitude better than anything achievable at the&amp;nbsp;time.&amp;nbsp; In the 25 years since, about 3 of those orders of magnitude have been achieved, so it doesn’t take any great imagination to foresee that the remainder could be as well.&amp;nbsp; A layperson reading your piece might not understand this.&lt;/p&gt;



&lt;p&gt;As for applications, my position has always been that if there were &lt;em&gt;zero&lt;/em&gt; applications, it would still be at least as scientifically important to try to build QCs as it was to build the LHC, LIGO, or the James Webb telescope.  If there &lt;em&gt;are&lt;/em&gt; real applications, such as simulating chemical dynamics, or certifiable randomness — and there very well might be — then those are icing on the cake.  This, of course, radically differs from the vision that now gets presented to investors and the press (hence all the railing on my blog!), but it also differs from what a reader of your piece would take away.&lt;/p&gt;



&lt;p&gt;Anyway, thanks again for sharing!&lt;/p&gt;



&lt;p&gt;Best,&lt;br&gt;Scott&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-08-29 15:03:49 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>The Parameterized Complexity Binary CSP for Graphs with a Small Vertex Cover and Related Results</title>
  <guid>http://arxiv.org/abs/2208.12543</guid>
  <link>http://arxiv.org/abs/2208.12543</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bodlaender_H/0/1/0/all/0/1&quot;&gt;Hans L. Bodlaender&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we show that \textsc{Binary CSP} with the size of a vertex
cover as parameter is complete for the class W[3]. This is one of the
firstexamples of a natural W[3]-complete problem that is not a variant
of\textsc{Satisfiability}. We obtain a number of related results with
variations of the proof techniques, that include: \textsc{Binary CSP} is
complete for W[$2d+1$] with as parameter the size of a vertex modulator to
graphs of treedepth $c$, or forests of depth $d$, for constant $c\geq 1$,
W[$t$]-hard for all $t\in \mathbb{N}$ with treewidth as parameter, and hard for
W[SAT] with feedback vertex set as parameter. As corollaries, we give some
hardness and membership problems for classes in the W-hierarchy for
\textsc{List Colouring} under different parameterizations.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-29 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The thickness of fan-planar graphs is at most three</title>
  <guid>http://arxiv.org/abs/2208.12324</guid>
  <link>http://arxiv.org/abs/2208.12324</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cheong_O/0/1/0/all/0/1&quot;&gt;Otfried Cheong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pfister_M/0/1/0/all/0/1&quot;&gt;Maximilian Pfister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Schlipf_L/0/1/0/all/0/1&quot;&gt;Lena Schlipf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove that in any strongly fan-planar drawing of a graph G the edges can
be colored with at most three colors, such that no two edges of the same color
cross. This implies that the thickness of strongly fan-planar graphs is at most
three. If G is bipartite, then two colors suffice to color the edges in this
way.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-29 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Polar, Spherical and Orthogonal Space Subdivisions for an Algorithm Acceleration: O(1) Point-in-Polygon/Polyhedron Test</title>
  <guid>http://arxiv.org/abs/2208.12488</guid>
  <link>http://arxiv.org/abs/2208.12488</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skala_V/0/1/0/all/0/1&quot;&gt;Vaclav Skala&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Acceleration of algorithms is becoming a crucial problem, if larger data sets
are to be processed. Evaluation of algorithms is mostly done by using
computational geometry approach and evaluation of computational complexity.
However in todays engineering problems this approach does not respect that
number of processed items is always limited and a significant role plays also
speed of read/write operations. One general method how to speed up an algorithm
is application of space subdivision technique and usually the orthogonal space
subdivision is used. In this paper non-orthogonal subdivisions are described.
The proposed approach can significantly improve memory consumption and run-time
complexity. The proposed modified space subdivision techniques are demonstrated
on two simple problems Point-in-Convex Polygon and Point-in-Convex Polyhedron
tests.
&lt;/p&gt;
  </description>
  <pubDate>2022-08-29 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

</channel>
</rss>
