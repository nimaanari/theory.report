<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>Inaugural address at the Hungarian Academy of Science: The Quantum Computer – A Miracle or Mirage</title>
  <guid>http://gilkalai.wordpress.com/?p=23390</guid>
  <link>https://gilkalai.wordpress.com/2022/11/05/inaugural-address-at-the-hungarian-academy-of-science-the-quantum-computer-a-miracle-or-mirage/</link>
  <description>
    &lt;h2&gt;&lt;a href=&quot;https://gilkalai.files.wordpress.com/2022/11/1655299431168.jpg&quot;&gt;&lt;img loading=&quot;lazy&quot; data-attachment-id=&quot;23493&quot; data-permalink=&quot;https://gilkalai.wordpress.com/2022/11/05/inaugural-address-at-the-hungarian-academy-of-science-the-quantum-computer-a-miracle-or-mirage/attachment/1655299431168/&quot; data-orig-file=&quot;https://gilkalai.files.wordpress.com/2022/11/1655299431168.jpg&quot; data-orig-size=&quot;3533,2603&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;1.79&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;Mi 9 Lite&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;1655306336&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;4.74&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;567&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0.03030303030303&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;1&amp;quot;}&quot; data-image-title=&quot;1655299431168&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://gilkalai.files.wordpress.com/2022/11/1655299431168.jpg?w=300&quot; data-large-file=&quot;https://gilkalai.files.wordpress.com/2022/11/1655299431168.jpg?w=640&quot; class=&quot;alignnone  wp-image-23493&quot; src=&quot;https://gilkalai.files.wordpress.com/2022/11/1655299431168.jpg?w=390&amp;#038;h=287&quot; alt=&quot;1655299431168&quot; width=&quot;390&quot; height=&quot;287&quot; srcset=&quot;https://gilkalai.files.wordpress.com/2022/11/1655299431168.jpg?w=390&amp;amp;h=287 390w, https://gilkalai.files.wordpress.com/2022/11/1655299431168.jpg?w=780&amp;amp;h=574 780w, https://gilkalai.files.wordpress.com/2022/11/1655299431168.jpg?w=150&amp;amp;h=111 150w, https://gilkalai.files.wordpress.com/2022/11/1655299431168.jpg?w=300&amp;amp;h=221 300w, https://gilkalai.files.wordpress.com/2022/11/1655299431168.jpg?w=768&amp;amp;h=566 768w&quot; sizes=&quot;(max-width: 390px) 100vw, 390px&quot; /&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;(Picture: János Pach)&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The Quantum Computer – A Miracle or Mirage&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;inaugural address of&lt;/p&gt;
&lt;h3&gt;Gil Kalai&lt;/h3&gt;
&lt;p&gt;honorary member of the MTA,&lt;/p&gt;
&lt;p&gt;Budapest, 15 June, 2022, 15:00&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;span style=&quot;color:#993366;&quot;&gt;&lt;em&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; On February 12, 2002, Michel Devoret&amp;#8217;s lecture entitled &amp;#8220;The Quantum Computers: Miracle or Mirage&amp;#8221; kicked off the 150th Anniversary Celebration of the Yale School of Engineering. In his abstract, Devoret asserted that while quantum mechanics had often been viewed as limiting the information one could extract from a physical system, &amp;#8220;recent discoveries show that fundamental properties of quantum mechanics could actually be used to perform computations that would be impossible on a standard &amp;#8216;classical&amp;#8217; computer.&amp;#8221; Devoret&amp;#8217;s question of whether the quantum computer is a miracle or a mirage is, to this day, one of the fascinating clear-cut open scientific questions of our time. In my inaugural lecture I will explain the question and the discoveries from the 1990s that suggested that quantum computers could perform miracles, and I will present my theory as to why the quantum computer is a mirage.&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Janos Pach told me that the name of the room were my lecture was given, &amp;#8220;Felolvaso terem&amp;#8221; means something like &amp;#8220;Hall for reading papers&amp;#8221;. This is a rarely used, somewhat archaic, expression that really refers to the act of reading out papers loudly for an audience. Quite untypically for mathematical lectures, this was precisely the style of my lecture.  Here is the text of my lecture:&lt;/p&gt;
&lt;p&gt;_________________________________________________&lt;/p&gt;
&lt;p&gt;I was very honored and happy for being elected as an honorary member of the Hungarian Academy of Sciences and I am especially happy to come to the beautiful city of Budapest to give this inaugural address and the Turán memorial lectures and I am thankful for the opportunity to meet friends and colleagues of many decades as well as a new generation of wonderful mathematicians.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;Our mathematical life and the inherent difficulties and uncertainties of mathematics and science are for us islands of stability and solace in times of great concerns and difficulties.&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;Preface&lt;/h2&gt;
&lt;p&gt;Quantum computers are new type of computers based on quantum physics. When it comes to certain computational objectives, the computational ability of quantum computers is tens, and even hundreds of orders of magnitude faster than that of the digital computers we are familiar with, and their construction will enable us to break most of the current cryptosystems. While quantum computers represent a future technology, which captivates the hearts and imaginations of many, there is also an ongoing dispute over the very possibility of their existence.&lt;/p&gt;
&lt;p&gt;My theory asserts that quantum computers are inherently noisy. Their robust components represent a low-level (classical) computational ability, and they necessarily exhibit chaotic behavior.&lt;/p&gt;
&lt;h2&gt;Classical Computers&lt;/h2&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;The classical computer can be seen as a device that contains n “bits” where every bit is in one of two positions of either “zero” or “one.” The computer operates through “gates” that perform logical operations on either a single or two bits. Two simple types of gates are sufficient to describe all forms of computation: the NOT gate, which reverses the value of a single bit, and the AND gate, which receives two bits as input and produces “one” if and only if the value of each of the bits in the input is “one.” The model presented here for computers is called the Boolean circuit model and is close to the 1940s models of Church, Turing, and others, which preceded the advent of the digital computer and the computer revolution in the second half of the twentieth century.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;In the 1960s and 1970s, computer science researchers came to an important insight regarding the inherent limitations of computers. There are certain computational tasks that are very easy to formulate (and even to check whether a suggested answer to them is correct), but which are nonetheless impossible to perform because they require too many computational steps. For example, if the number of computational steps for a problem described by an input of &lt;em&gt;n&lt;/em&gt; bits is &lt;em&gt;2&lt;sup&gt;n&lt;/sup&gt;&lt;/em&gt;, then this computation will not be feasible for the most powerful computers, even when n = 100. To describe feasible (or “efficient”) computations, that is, computations that can actually be performed, an important assumption was added, according to which the number of computational steps (i.e., the number of gates) does not exceed a constant power (e.g., n&lt;sup&gt;3&lt;/sup&gt;) in the number &lt;em&gt;n&lt;/em&gt; of bits describing the input. This definition represents an important step in the theory of computational complexity, while providing the central tool for the analysis of the computational power of computational models, algorithms, and physical computational systems.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;The main lens through which we analyze the difficulty of computation is the asymptotic lens. For most computational tasks we cannot hope for a full understanding of the number of required computational steps as a function of the number of bits of the input, but we can gain understanding (at times rough and at times just conjectural) of the computational difficulty by studying how the number of computational steps asymptotically depends on the input size. Experience gained in recent decades indicates that asymptotic analysis provides a good understanding of the practical difficulty of computational tasks.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;We will now enrich the picture by adding probability. A single bit has two possible values, “zero” and “one,” and it is possible to extend the Boolean circle model by allowing the bit to have the value “zero” with probability &lt;em&gt;p&lt;/em&gt; and the value “one” with probability &lt;em&gt;1-p&lt;/em&gt;. In this way, the classical computer equipped with probabilistic bits can describe a sample from a probability space of sequences of zeros and ones. The model of probabilistic classical computers is an important model in the theory of computational complexity and it also constitutes a convenient introduction to the concept of quantum computers. Probabilistic Boolean circuits can be realized rather easily by digital computers.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;Quantum Computers&lt;/h2&gt;
&lt;p&gt;The model of quantum computers is a computational model based on quantum mechanics and was first introduced in the 1980s. In quantum computers, the classical bit is replaced by the basic computational element called a qubit.&lt;/p&gt;
&lt;p&gt;The state of a single qubit is described by a unit vector in a complex two-dimensional vector space (namely, it is described by four real numbers whose sum of squares equals 1). The uncertainty principle asserts that we cannot identify the precise state of the qubit, but rather we can measure it and obtain a probabilistic bit. One way to think about it is as follows: there are two basic states for the qubit and we denote them by &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cleft%7C0%5Cright%5Crangle+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cleft%7C0%5Cright%5Crangle+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cleft%7C0%5Cright%5Crangle+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;left|0&amp;#92;right&amp;#92;rangle &quot; class=&quot;latex&quot; /&gt;  and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cleft%7C1%5Cright%5Crangle&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cleft%7C1%5Cright%5Crangle&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cleft%7C1%5Cright%5Crangle&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;left|1&amp;#92;right&amp;#92;rangle&quot; class=&quot;latex&quot; /&gt; while the general state of the qubit is a “superposition” of these two basic states, namely, the general state of a qubit is a linear combination of the form&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=z_1%5Cleft%7C0%5Cright%5Crangle+%2Bz_2%5Cleft%7C1%5Cright%5Crangle&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=z_1%5Cleft%7C0%5Cright%5Crangle+%2Bz_2%5Cleft%7C1%5Cright%5Crangle&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_1%5Cleft%7C0%5Cright%5Crangle+%2Bz_2%5Cleft%7C1%5Cright%5Crangle&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;z_1&amp;#92;left|0&amp;#92;right&amp;#92;rangle +z_2&amp;#92;left|1&amp;#92;right&amp;#92;rangle&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p&gt;where &lt;img src=&quot;https://s0.wp.com/latex.php?latex=z_1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=z_1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;z_1&quot; class=&quot;latex&quot; /&gt;  and latex z_2$  are complex numbers  satisfying&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7Cz_1%7C%5E2%2B%7Cz_2%7C%5E2%3D1.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7Cz_1%7C%5E2%2B%7Cz_2%7C%5E2%3D1.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cz_1%7C%5E2%2B%7Cz_2%7C%5E2%3D1.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;|z_1|^2+|z_2|^2=1.&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The state of the qubit can be measured and when a qubit in this state is measured, we obtain a probabilistic bit with a value 0 with probability  and 1 with probability. One possible physical realization of the two basic states of a single qubit is with the two energy levels of a Hydrogen atom, with quantum physics allowing the atom to be in a superposition of these basic states as described above.&lt;/p&gt;
&lt;p&gt;The computer acts on &lt;em&gt;n&lt;/em&gt; qubits through “quantum gates,” which are the basic quantum computation operations. (The gates are described mathematically by “unitary operators.”) At the end of the computation process, the state of the computer is measured, and this yields a single sample from a probability distribution of 0-1 strings of length n.  In this case too, the assumption is that for each efficient computation the number of gates is at most polynomial in &lt;em&gt;n&lt;/em&gt;. The crucial fact about quantum computers is that they would allow us to efficiently achieve samples that cannot be efficiently achieved by classical computers.&lt;/p&gt;
&lt;p&gt;In the 1990s, Peter Shor discovered that quantum computers would allow the execution of a certain computational tasks – factoring an integer to its prime components – hundreds of orders of magnitude faster than regular computers and would enable us to break most current cryptosystems.&lt;/p&gt;
&lt;h2&gt;Quantum Computers and Noise&lt;/h2&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;Quantum systems are by nature “noisy” and unstable. The term “noise” refers to a deviation of the computer from the planned program, and in the case of a quantum computer any unwanted interaction or leakage of information leads to such a deviation. The model of noisy quantum computer adds a component of noise to the description of the quantum computer. Noisy intermediate-scale quantum (NISQ) computers are simply noisy quantum circuits with at most 200 (say) qubits.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;It was around that time that early doubts concerning the model also surfaced: quantum systems are by nature “noisy” and unstable. The term “noise” refers to a deviation of the computer from the planned program, and in the case of a quantum computer any unwanted interaction or leakage of information leads to such a deviation. Therefore, in order to reduce the noise level, quantum computers must be isolated and protected from their environment. The key to a possible solution of the noise problem is quantum error-correcting codes, which will enable noisy quantum computers to perform the same computations conducted by the abstract noiseless model, provided that the level of noise can be reduced to below a certain threshold denoted by &lt;strong&gt;α&lt;/strong&gt;.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;It is a common opinion that the construction of quantum computers is possible, that the remaining challenge is mostly engineering-related, that such computers will be constructed in the next few decades, and that quantum error-correcting codes of the required quality will be developed in labs in the years to come. My standpoint is that it will be fundamentally impossible to reduce the noise level to below the required threshold. As a result, it will be impossible to develop the quantum codes required for quantum computation, nor will it be possible to reach the target of “quantum computation supremacy,” whereby a quantum computer performs computation that is extremely hard or even impossible for a classical computer.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;The argument against quantum computers&lt;/h2&gt;
&lt;p&gt;My argument for the impossibility of quantum computers lies within the scope of quantum mechanics and does not deviate from its principles. In essence, the argument is based on computational complexity and its interpretation, and it is discussed in-depth in my papers which also include a discussion of general conclusions that derive from my argument and relate to quantum physics, alongside suggestions of general laws of nature that express the impossibility of quantum computation.&lt;/p&gt;
&lt;p&gt;My argument mostly deals with understanding quantum computers on the intermediate scale (known as NISQ computers, an abbreviation of Noisy Intermediate Scale Quantum), that is, quantum computers of up to at most several hundreds of qubits. It is expected that on this scale we will be able to construct quantum codes of a quality sufficient for the construction of bigger quantum computers. It is further expected that on this scale the quantum computer will achieve computations far beyond the ability of powerful classical computers, that is, will achieve quantum computational supremacy. The Google’s Sycamore computer is an example of a noisy intermediate-scale quantum computer.&lt;/p&gt;
&lt;p&gt;As specified later, it is my argument that NISQ computers cannot be controlled. Hence:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Such systems cannot demonstrate significant quantum computational advantage.&lt;/li&gt;
&lt;li&gt;Such systems cannot be used for the creation of quantum error-correcting codes.&lt;/li&gt;
&lt;li&gt;Such systems lead to non-stationary and even chaotic distributions.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Regarding the first item, let me remind the audience that computational complexity theory provides tools for studying the computational power of models and physical computational devices. The reason NISQ computers cannot support quantum supremacy is that when we use computational complexity tools to understand the computational power of NISQ computers, we discover that they describe a very low-level computational class. This low-level computational class does not allow for any complicated computations, much less computational supremacy.  My analysis draws computational conclusions for NISQ computers based on their mathematical model’s asymptotic behavior.&lt;/p&gt;
&lt;p&gt;Regarding the second item, the reason it is impossible to build quantum error-correcting codes is that it requires an even lower noise level than that required for demonstrating quantum supremacy. The meaning of the infeasibility of quantum error-correcting codes is that even a quantum computer operating on a single qubit is inherently noisy. It is to be noted that the argument that the noise level required for error-correcting codes is lower than the level required for quantum supremacy is generally accepted by both theoreticians and experimental physicists.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://gilkalai.wordpress.com/2022/10/14/alefs-corner-it-wont-work-sorry/&quot;&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;A picture by Alef&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Weiner Chaos and Lorenz Chaos&lt;/h2&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;When I speak here of chaotic behavior, I refer to a system (either deterministic, probabilistic, or quantum) that is so sensitive to its defining parameters that its behavior (or a large component of its behavior) cannot be determined, not even probabilistically. This notion is related to the mathematical theory of “noise sensitivity” (Benjamini, Kalai, and Schramm 1999) that we mentioned before, and to the related mathematical theory of “black noise” (Tsirelson and Vershik 1998). Both these theories have their early roots in Weiner’s chaos expansion (Weiner 1938). Chaos in this sense is sometimes called “Knightian uncertainty”, a term that originates in economics. The first use of the theory of noise-sensitivity to quantum computers was in my 2014 paper with Guy Kindler on “Boson Sampling”. (There we use Hermite-Fourier expansion.)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;The term “chaotic system” in mathematical chaos theory (Lorenz 1963) refers to nonlinear classical deterministic systems, whose development very much depends on their initial conditions, and since these conditions are not known precisely, the system’s development in the long run cannot be predicted.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;It is plausible that natural chaotic phenomenon (like the weather) reflects both the Lorenz chaos and the Weiner chaos.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;Here I thank I Bernard Chazelle for raising an appealing argument for why Lorenz chaos and traditional dynamic theoretic notions of chaos are insufficient to describe chaos in nature.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;A Brief Look at the Mathematical Analysis: The Fourier Expansion&lt;/h2&gt;
&lt;p&gt;Following is a brief look at a central technical analytic tool that applies to all three components of the argument, namely, the Fourier expansion of functions. In our case we consider functions, whose values are real numbers that are described on sequences of length &lt;em&gt;n&lt;/em&gt; of zeros and ones, and every such function can be written (as a linear combination) by means of a special set of functions, known as Fourier–Walsh functions. Fourier–Walsh functions can be sorted according to their degree, which is a natural number between 0 and &lt;em&gt;n&lt;/em&gt;. Much as the regular Fourier expansion makes it possible to describe a musical sound as a combination of pure high and low tones, in Fourier–Walsh functions, too, the degrees can be seen as analogous to the heights of the pure tones.&lt;/p&gt;
&lt;p&gt;Our first step is to study the Walsh–Fourier transform of the probability distribution of the 0-1 sequences in an ideal noiseless quantum computer, and the second step is to study the effect of the noise. The main technical component of my argument is that the noise will exponentially lower the coefficients of the higher-degree Fourier–Walsh functions. This leads to a mathematical distinction (Benjamini, Kalai, and Schramm 1999) between distributions that can be described by low-degree Fourier coefficients and are referred to as “noise stable” and distributions that are supported by high-degree Fourier coefficients and are referred to as “noise sensitive.” A general distribution can have both noise-stable and noise-sensitive components.  This is the reason that, on the one hand, the stable component in the noisy distribution is described by low Fourier–Walsh levels, and hence this component represents an extremely low computational power, and that, on the other hand, if the unstable part, namely, the contributions of the higher-degree Fourier–Walsh functions remain substantial, this contribution will be chaotic.&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;On Classical Information and Classical Computation&lt;/h2&gt;
&lt;p&gt;The question “why does this argument fail for classical computers?” is an appropriate critique of any argument asserting that quantum computers are not possible. Regarding my argument, the answer to this question is as follows: the path to large-scale quantum computers requires building quantum error-correcting codes on NISQ systems, and my theory asserts that this is impossible. At the same time, the primitive computational power represented by NISQ systems still allows for stable classical information, and subsequently even for classical computation.&lt;/p&gt;
&lt;h2&gt;The Weak Link in My Argument&lt;/h2&gt;
&lt;p&gt;The mathematical analysis that leads to the conclusion that noisy intermediate-scale quantum computers have primitive computational power is asymptotic. That is, a mathematical model of these computers is described and analyzed when the noise level is fixed, and the number of qubits increases. The conclusion I draw from this asymptotic behavior concerns the lowest noise level engineers can reach. I argue that it would be impossible to lower the noise level in such a way that enables us to create computers whose computational ability is low in an asymptotic analysis, but very high – indeed beyond the ability of classical computers – for several dozen qubits.  The move from an asymptotic argument regarding the model’s computational complexity to a concrete claim regarding engineering-related limitations of intermediate-scale computers is hardly standard, and my argument clashes with the strong intuition of experts in the field, according to whom an engineering effort would make it possible in principle (as well as in practice) to lower the noise level as much as we would like. Indeed, the multiple resources invested in building quantum computers, especially noisy intermediate-scale quantum computers, are based on the common position that there is no fundamental obstacle obstructing this effort.&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;Recent experimental results&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;In 2019 Researchers from &lt;strong&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;G&lt;/span&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;o&lt;/span&gt;&lt;span style=&quot;color:#ffcc00;&quot;&gt;o&lt;/span&gt;&lt;span style=&quot;color:#0000ff;&quot;&gt;g&lt;/span&gt;&lt;span style=&quot;color:#00ff00;&quot;&gt;l&lt;/span&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;e&lt;/span&gt;&lt;/strong&gt; claimed to achieve in 300 seconds a sampling task that requires 10,000 years for a supercomputer.&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;However, since the Google paper appeared the number “10,000” years was replaced by (roughly) 300 second by better classical algorithms. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In a joint work with Yosi Rinott and Tomer Shoham we also examine other aspects of the Google methods and claims.&lt;/p&gt;
&lt;p&gt;In 2020 researchers from &lt;strong&gt;USTC&lt;/strong&gt;, China claimed to achieve in 300 seconds a sampling task that requires a billion years for a supercomputer.&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;However, my 2014 paper with Guy Kindler on “Boson Sampling” (and subsequent works) largely refute these fantastic claims.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;https://gilkalai.files.wordpress.com/2022/10/1655299431197.jpg&quot;&gt;&lt;img loading=&quot;lazy&quot; data-attachment-id=&quot;23492&quot; data-permalink=&quot;https://gilkalai.wordpress.com/2022/11/05/inaugural-address-at-the-hungarian-academy-of-science-the-quantum-computer-a-miracle-or-mirage/attachment/1655299431197/&quot; data-orig-file=&quot;https://gilkalai.files.wordpress.com/2022/10/1655299431197.jpg&quot; data-orig-size=&quot;2992,4000&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;1.79&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;Mi 9 Lite&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;1655306285&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;4.74&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;687&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0.03030303030303&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;1&amp;quot;}&quot; data-image-title=&quot;1655299431197&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://gilkalai.files.wordpress.com/2022/10/1655299431197.jpg?w=224&quot; data-large-file=&quot;https://gilkalai.files.wordpress.com/2022/10/1655299431197.jpg?w=640&quot; class=&quot;alignnone  wp-image-23492&quot; src=&quot;https://gilkalai.files.wordpress.com/2022/10/1655299431197.jpg?w=289&amp;#038;h=386&quot; alt=&quot;1655299431197&quot; width=&quot;289&quot; height=&quot;386&quot; srcset=&quot;https://gilkalai.files.wordpress.com/2022/10/1655299431197.jpg?w=289&amp;amp;h=386 289w, https://gilkalai.files.wordpress.com/2022/10/1655299431197.jpg?w=578&amp;amp;h=772 578w, https://gilkalai.files.wordpress.com/2022/10/1655299431197.jpg?w=112&amp;amp;h=150 112w, https://gilkalai.files.wordpress.com/2022/10/1655299431197.jpg?w=224&amp;amp;h=300 224w&quot; sizes=&quot;(max-width: 289px) 100vw, 289px&quot; /&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;(Picture: János Pach)&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Quantum computers are among the most important scientific developments of our time. In my judgement it is a serious possibility that quantum computers are not possible. This is what I expect, and I have been studying this possibility since 2005.&lt;/p&gt;
&lt;p&gt;Understanding noisy quantum systems and potentially even the failure of quantum computers is related to the fascinating mathematics of noise stability and noise sensitivity and its connections to the theory of computing. Exploring this avenue may have important implications to various areas of quantum physics.&lt;/p&gt;
&lt;p&gt;Evaluating the recent fantastic experimental claims is an exciting scientific matter on its own.&lt;/p&gt;
&lt;h3&gt;______________________________________________&lt;/h3&gt;
&lt;h3&gt;Some references&lt;/h3&gt;
&lt;p&gt;For the readers of the blog let me add some references to my papers:&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#993366;&quot;&gt;The argument against quantum computers&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(i) G. Kalai, &lt;a href=&quot;https://arxiv.org/abs/1908.02499&quot;&gt;The argument against quantum computers&lt;/a&gt;, &lt;em&gt;Quantum, Probability, Logic: Itamar Pitowsky’s Work and Influence&lt;/em&gt; (M. Hemmo and O. Shenker, eds.), pp. 399–422, Springer, 2019.&lt;/p&gt;
&lt;p&gt;(ii) G. Kalai, &lt;a href=&quot;https://www.ams.org/journals/notices/201605/rnoti-p508.pdf&quot;&gt;The quantum computer puzzle&lt;/a&gt;, Notices AMS, May 2016&lt;/p&gt;
&lt;p&gt;(iii). G. Kalai, &lt;a href=&quot;https://gilkalai.files.wordpress.com/2020/08/laws-blog2.pdf&quot;&gt;The argument against quantum computers, the quantum laws of nature, and Google’s supremacy claims,&lt;/a&gt;&lt;em&gt; The Intercontinental Academia Laws: Rigidity and Dynamics &lt;/em&gt;(M. J. Hannon and E. Z. Rabinovici, eds.), World Scientific, 2020. arXiv:2008.05188.&lt;/p&gt;
&lt;p&gt;(iv). G. Kalai, &lt;a href=&quot;https://arxiv.org/abs/2209.01648&quot;&gt;Conjecture C still stands,&lt;/a&gt; arXiv. 2022&lt;/p&gt;
&lt;p&gt;This recent paper responds to a &lt;a href=&quot;https://arxiv.org/abs/1204.3404&quot;&gt;2012 paper&lt;/a&gt; of Steve Flammia and Aram Harrow (see this post) regarding a certain &amp;#8220;Conjecture C&amp;#8221; discussed in my 2011 debate with Aram.&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#993366;&quot;&gt;In the wider context of &amp;#8220;mathematical computer science: theory and practice&amp;#8221;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(v). G. Kalai, &lt;a href=&quot;https://gilkalai.files.wordpress.com/2019/09/main-pr.pdf&quot;&gt;Three puzzles on mathematics computations, and games,&lt;/a&gt; Proc. ICM2018;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#993366;&quot;&gt;Boson sampling&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(vi). G. Kalai and G. Kindler, &lt;a href=&quot;https://arxiv.org/abs/1409.3093&quot; rel=&quot;nofollow ugc&quot;&gt;Gaussian Noise Sensitivity and BosonSampling, 2014. &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Our study of Boson Sampling gives the basis to understanding of general NISQ systems.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;(vii) G. Kalai and G. Kindler, &lt;a href=&quot;https://gilkalai.files.wordpress.com/2022/11/bskkr2.pdf&quot;&gt;Concerns about recent claims of a huge quantum computational advantage via Gaussian boson sampling&lt;/a&gt;,&lt;/p&gt;
&lt;p&gt;This was a discussion paper for the 2020-2021 email exchange with the USTC photonic team and other researchers regarding the boson sampling claims.&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#993366;&quot;&gt;On the Google 2019 experiment&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(viii) Y. Rinott, T. Shoham, and G. Kalai, &lt;a href=&quot;https://gilkalai.files.wordpress.com/2022/08/sts836.pdf&quot;&gt;Statistical Aspects of the Quantum Supremacy Demonstration,&lt;/a&gt; Statistical Science  (2022)&lt;/p&gt;
&lt;p&gt;(ix) G. Kalai, Y. Rinott and T. Shoham, &lt;a href=&quot;https://gilkalai.files.wordpress.com/2022/10/cc22a19.pdf&quot;&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;Google’s 2019 “Quantum Supremacy” Claims: &lt;/span&gt;&lt;span dir=&quot;ltr&quot; role=&quot;presentation&quot;&gt;Data, Documentation, &amp;amp; Discussion&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;See also Sections 5 and 6 in reference (iii).&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </description>
  <pubDate>2022-11-05 17:27:17 UTC</pubDate>
  <author>Gil Kalai</author>
</item>

<item>
  <title>postdoc at Technical University of Denmark, Copenhagen (apply by December 15, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/05/postdoc-at-technical-university-of-denmark-copenhagen-apply-by-december-15-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/05/postdoc-at-technical-university-of-denmark-copenhagen-apply-by-december-15-2022/</link>
  <description>
    &lt;p&gt;Join us in the pursuit of new provably efficient algorithms for graphs, dynamic graphs, discrete computational geometry, and related topics.&lt;br /&gt;
We are a collaborative group of researchers with an array of algorithmic hypotheses, as well as broad interests and open minds, and we are looking for a postdoc to join our group.&lt;br /&gt;
You are very welcome to contact us with any questions you may have.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.dtu.dk/english/about/job-and-career/vacant-positions/job?id=ef0a4d3f-d74e-4a6e-b6ac-dc37848e04ca&quot;&gt;https://www.dtu.dk/english/about/job-and-career/vacant-positions/job?id=ef0a4d3f-d74e-4a6e-b6ac-dc37848e04ca&lt;/a&gt;&lt;br /&gt;
Email: erot@dtu.dk&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-05 09:38:27 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>postdoc at IDEAL (Northwestern, UChicago, TTIC, UIC, IIT) (apply by December 15, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/04/postdoc-at-ideal-northwestern-uchicago-ttic-uic-iit-apply-by-december-15-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/04/postdoc-at-ideal-northwestern-uchicago-ttic-uic-iit-apply-by-december-15-2022/</link>
  <description>
    &lt;p&gt;The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) invites applications for two postdoctoral positions with an anticipated start date in the Fall of 2023. IDEAL is an interdisciplinary institute organized by Northwestern University, the University of Chicago, Toyota Technological Institute at Chicago, the University of Illinois Chicago, and Illinois Institute of Technology.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://academicjobsonline.org/ajo/jobs/23590&quot;&gt;https://academicjobsonline.org/ajo/jobs/23590&lt;/a&gt;&lt;br /&gt;
Email: idealpostdoc@ttic.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 16:45:56 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Tuesday, Nov 8th, 2022 — Edith Cohen from Google Research (&amp; Tel-Aviv University)</title>
  <guid>http://dstheory.wordpress.com/?p=140</guid>
  <link>https://dstheory.wordpress.com/2022/11/04/tuesday-nov-8th-2022-edith-cohen-from-google-research-tel-aviv-university/</link>
  <description>
    &lt;p&gt;The next &lt;a rel=&quot;noreferrer noopener&quot; href=&quot;https://sites.google.com/view/dstheory/home&quot; target=&quot;_blank&quot;&gt;Foundations of Data Science&lt;/a&gt; virtual talk series on recent advances in adversarially robust streaming will take place on &lt;strong&gt;Tuesday, November 8th&lt;/strong&gt; at &lt;strong&gt;1:00 PM Pacific Time&lt;/strong&gt; (16:00 Eastern Time, 22:00 Central European Time, 20:00 UTC). &lt;a href=&quot;http://www.cohenwang.com/edith/&quot;&gt;Edith Cohen&lt;/a&gt; from&lt;strong&gt; Google Research&lt;/strong&gt; will talk about “On Robustness to Adaptive Inputs: A Case Study of CountSketch.&lt;em&gt;”&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;https://sites.google.com/view/dstheory&quot;&gt;Details of the talk (Zoom link) are available here.&lt;/a&gt;&lt;/p&gt;



&lt;p class=&quot;has-text-align-justify&quot;&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:  The performance of randomized algorithms can be considered both in adaptive settings, where inputs may depend on prior outputs of the algorithm, and in non-adaptive settings. Adaptive settings arise when the algorithm is a component of a system with feedback or when an adversary attempts to construct an input on which the algorithm fails. The last decade saw impressive progress that included the development of black-box methods of obtaining algorithms that are robust to adaptive inputs from non-robust counterparts, most notably using differential privacy, and established lower bounds through &amp;#8220;attacks.&amp;#8221; But intriguing questions remain on the practical implications of adaptivity and the potential to develop tailored algorithms for specific problems and &amp;#8220;nicer&amp;#8221; inputs. In my talk, I will review key ideas from the literature and then present our recent work that explored these questions for CountSketch, a popular dimensionality reduction method (joint with Xin Lyu, Jelani Nelson, Tamas Sarlos, Moshe Shechner, and Uri Stemmer).&lt;/p&gt;



&lt;p&gt;&amp;nbsp;The series is supported by the &lt;a href=&quot;https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;amp;HistoricalAwards=false&quot;&gt;NSF HDR TRIPODS Grant 1934846&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By dstheory&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 15:35:20 UTC</pubDate>
  <author>Foundation of Data Science - Virtual Talk Series</author>
</item>

<item>
  <title>Faculty at KTH Royal Institute of Technology (apply by November 28, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/04/faculty-at-kth-royal-institute-of-technology-apply-by-november-28-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/04/faculty-at-kth-royal-institute-of-technology-apply-by-november-28-2022/</link>
  <description>
    &lt;p&gt;Assistant Professor in Computer science with specialization in algorithms and complexity theory.&lt;/p&gt;
&lt;p&gt;The area is foundational theoretical computer science. This covers research in all areas of algorithms and complexity theory such as circuit complexity, combinatorial optimization, communication complexity, distributed algorithms, graph algorithms, quantum algorithms and proof complexity.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.kth.se/en/om/work-at-kth/lediga-jobb/what:job/jobID:508144/type:job/where:4/apply:1&quot;&gt;https://www.kth.se/en/om/work-at-kth/lediga-jobb/what:job/jobID:508144/type:job/where:4/apply:1&lt;/a&gt;&lt;br /&gt;
Email: johanh@kth.se,karlm@kth.se&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 09:36:27 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>On Paxos from Recoverable Broadcast</title>
  <guid>https://decentralizedthoughts.github.io/2022-11-04-paxos-via-recoverable-broadcast/</guid>
  <link>https://decentralizedthoughts.github.io/2022-11-04-paxos-via-recoverable-broadcast/</link>
  <description>
    There are many ways to learn about the Paxos protocol, this post is one more way. This posts has embedded a set of simple exercise - try to go over them! The model is Partial Synchrony with $f&amp;lt;n/2$ omission failures and the goal is consensus (see below for exact details)....
  </description>
  <pubDate>2022-11-04 09:00:00 UTC</pubDate>
  <author>Decentralized Thoughts</author>
</item>

<item>
  <title>News for October 2022</title>
  <guid>https://ptreview.sublinear.info/?p=1766</guid>
  <link>https://ptreview.sublinear.info/2022/11/news-for-october-2022/</link>
  <description>
    &lt;p&gt;Yet another month that is kind of quiet! If we missed any work, please let us know in the comments.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Gaussian Mean Testing Made Simple&lt;/strong&gt;, by Ilias Diakonikolas, Daniel Kane and Ankit Pensia (&lt;a rel=&quot;noreferrer noopener&quot; href=&quot;https://arxiv.org/pdf/2210.13706.pdf&quot; target=&quot;_blank&quot;&gt;arXiv&lt;/a&gt;). Consider an unknown distribution distribution \(p\) over \(\mathbb{R}^d\) that we have sample access to. The paper studies the problem of determining whether \(p\) is a standard Gaussian with zero mean or whether it is a Gaussian with large mean. More formally, the task is to distinguish between the case that \(p\) is \(\mathcal{N}(0, I_d)\) and the case that \(p\) is a Gaussian of the form \(\mathcal{N}(\mu, \Sigma)\), where \(||\mu||_2 \geq \epsilon\) and \(\Sigma\) is an unknown covariance matrix. Canonne, Chen, Kamath, Levi and Weingarten (2021) gave a sample-optimal algorithm for this problem with sample complexity \(\Theta(\sqrt{d}/\epsilon^2)\) sample complexity. The current paper gives another sample-optimal algorithm for the same problem with a simpler analysis. In addition to being sample-optimal, the algorithm in the current paper also runs in time linear in the total sample size, which is an improvement over the work of Canonne et al. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Superpolynomial lower bounds for decision tree learning and testing&lt;/strong&gt;, by Caleb Koch, Carmen Strassle and Li-Yang Tan (&lt;a rel=&quot;noreferrer noopener&quot; href=&quot;https://arxiv.org/pdf/2210.06375.pdf&quot; target=&quot;_blank&quot;&gt;arXiv&lt;/a&gt;). Roughly speaking, the paper studies the problems of testing if a function has a low-depth decision tree and learning a low-depth decision tree approximating a function (provided that one such tree exists). In what follows, we summarize the testing results in the paper. Given an explicit representation of a function \(f:\{0,1\}^n \to \{0,1\}\) and access to samples from a known distribution \(\mathcal{D}\) over \(\{0,1\}^n\), one can aim to determine, with probability at least \(2/3\), if \(f\) has a decision tree of depth at most \(d\) or whether \(f\) is \(\epsilon\)-far from having a decision tree of depth at most \(d\log d\), where the distance is measured with respect to \(\mathcal{D}\). The paper shows that, under the randomized exponential time hypothesis, this problem cannot be solved in time \(\exp(d^{\Omega(1)})\). An immediate corollary is that the same lower bound holds for the problem of distribution-free testing of the property of having depth-\(d\) decision trees. The bound in the current paper is an improvement over the recent work of Blais, Ferreira Pinto Jr., and Harms (2021), who give a lower bound of \(\tilde{\Omega}(2^d)\) on the query complexity of testers for the same problem. However, the advantage of the latter result is that it is unconditional, as opposed to the result in the current paper. &lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Nithin Varma&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 05:07:40 UTC</pubDate>
  <author>Property Testing Review</author>
</item>

<item>
  <title>Improved Inapproximability of VC Dimension and Littlestone&#39;s Dimension via (Unbalanced) Biclique</title>
  <guid>http://arxiv.org/abs/2211.01443</guid>
  <link>http://arxiv.org/abs/2211.01443</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1&quot;&gt;Pasin Manurangsi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the complexity of computing (and approximating) VC Dimension and
Littlestone&#39;s Dimension when we are given the concept class explicitly. We give
a simple reduction from Maximum (Unbalanced) Biclique problem to approximating
VC Dimension and Littlestone&#39;s Dimension. With this connection, we derive a
range of hardness of approximation results and running time lower bounds. For
example, under the (randomized) Gap-Exponential Time Hypothesis or the
Strongish Planted Clique Hypothesis, we show a tight inapproximability result:
both dimensions are hard to approximate to within a factor of $o(\log n)$ in
polynomial-time. These improve upon constant-factor inapproximability results
from [Manurangsi and Rubinstein, COLT 2017].
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Pseudorandom (Function-Like) Quantum State Generators: New Definitions and Applications</title>
  <guid>http://arxiv.org/abs/2211.01444</guid>
  <link>http://arxiv.org/abs/2211.01444</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ananth_P/0/1/0/all/0/1&quot;&gt;Prabhanjan Ananth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gulati_A/0/1/0/all/0/1&quot;&gt;Aditya Gulati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Qian_L/0/1/0/all/0/1&quot;&gt;Lower Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yuen_H/0/1/0/all/0/1&quot;&gt;Henry Yuen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Pseudorandom quantum states (PRS) are efficiently constructible states that
are computationally indistinguishable from being Haar-random, and have recently
found cryptographic applications. We explore new definitions, new properties
and applications of pseudorandom states, and present the following
contributions:
&lt;/p&gt;
&lt;p&gt;1. New Definitions: We study variants of pseudorandom function-like state
(PRFS) generators, introduced by Ananth, Qian, and Yuen (CRYPTO&#39;22), where the
pseudorandomness property holds even when the generator can be queried
adaptively or in superposition. We show feasibility of these variants assuming
the existence of post-quantum one-way functions.
&lt;/p&gt;
&lt;p&gt;2. Classical Communication: We show that PRS generators with logarithmic
output length imply commitment and encryption schemes with classical
communication. Previous constructions of such schemes from PRS generators
required quantum communication.
&lt;/p&gt;
&lt;p&gt;3. Simplified Proof: We give a simpler proof of the Brakerski--Shmueli
(TCC&#39;19) result that polynomially-many copies of uniform superposition states
with random binary phases are indistinguishable from Haar-random states.
&lt;/p&gt;
&lt;p&gt;4. Necessity of Computational Assumptions: We also show that a secure PRS
with output length logarithmic, or larger, in the key length necessarily
requires computational assumptions.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The Complexity of Pattern Counting in Directed Graphs, Parameterised by the Outdegree</title>
  <guid>http://arxiv.org/abs/2211.01905</guid>
  <link>http://arxiv.org/abs/2211.01905</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bressan_M/0/1/0/all/0/1&quot;&gt;Marco Bressan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lanzinger_M/0/1/0/all/0/1&quot;&gt;Matthias Lanzinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_M/0/1/0/all/0/1&quot;&gt;Marc Roth&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the fixed-parameter tractability of the following fundamental
problem: given two directed graphs $\vec H$ and $\vec G$, count the number of
copies of $\vec H$ in $\vec G$. The standard setting, where the tractability is
well understood, uses only $|\vec H|$ as a parameter. In this paper we take a
step forward, and adopt as a parameter $|\vec H|+d(\vec G)$, where $d(\vec G)$
is the maximum outdegree of $|\vec G|$. Under this parameterization, we
completely characterize the fixed-parameter tractability of the problem in both
its non-induced and induced versions through two novel structural parameters,
the fractional cover number $\rho^*$ and the source number $\alpha_s$. On the
one hand we give algorithms with running time $f(|\vec H|,d(\vec G)) \cdot
|\vec G|^{\rho^*\!(\vec H)+O(1)}$ and $f(|\vec H|,d(\vec G)) \cdot |\vec
G|^{\alpha_s(\vec H)+O(1)}$ for counting respectively the copies and induced
copies of $\vec H$ in $\vec G$; on the other hand we show that, unless the
Exponential Time Hypothesis fails, for any class $\vec C$ of directed graphs
the (induced) counting problem is fixed-parameter tractable if and only if
$\rho^*(\vec C)$ ($\alpha_s(\vec C)$) is bounded. These results explain how the
orientation of the pattern can make counting easy or hard, and prove that a
classic algorithm by Chiba and Nishizeki and its extensions (Chiba, Nishizeki
SICOMP 85; Bressan Algorithmica 21) are optimal unless ETH fails.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Membership in moment cones, quiver semi-invariants, and generic semi-stability for bipartite quivers</title>
  <guid>http://arxiv.org/abs/2211.01990</guid>
  <link>http://arxiv.org/abs/2211.01990</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chindris_C/0/1/0/all/0/1&quot;&gt;Calin Chindris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Collins_B/0/1/0/all/0/1&quot;&gt;Brett Collins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kline_D/0/1/0/all/0/1&quot;&gt;Daniel Kline&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $Q$ be a bipartite quiver with vertex set $Q_0$ such that the number of
arrows between any two source and sink vertices is constant. Let
$\beta=(\beta(x))_{x \in Q_0}$ be a dimension vector of $Q$ with positive
integer coordinates, and let $\Delta(Q, \beta)$ be the moment cone associated
to $(Q, \beta)$. We show that the membership problem for $\Delta(Q, \beta)$ can
be solved in strongly polynomial time.
&lt;/p&gt;
&lt;p&gt;As a key step in our approach, we first solve the polytopal problem for
semi-invariants of $Q$ and its flag-extensions. Specifically, let $Q_{\beta}$
be the flag-extension of $Q$ obtained by attaching a flag $\mathcal{F}(x)$ of
length $\beta(x)-1$ at every vertex $x$ of $Q$, and let $\widetilde{\beta}$ be
the extension of $\beta$ to $Q_{\beta}$ that takes values $1, \ldots, \beta(x)$
along the vertices of the flag $\mathcal{F}(x)$ for every vertex $x$ of $Q$.
For an integral weight $\widetilde{\sigma}$ of $Q_{\beta}$, let
$K_{\widetilde{\sigma}}$ be the dimension of the space of semi-invariants of
weight $\widetilde{\sigma}$ on the representation space of
$\widetilde{\beta}$-dimensional complex representations of $Q_{\beta}$.
&lt;/p&gt;
&lt;p&gt;We show that $K_{\widetilde{\sigma}}$ can be expressed as the number of
lattice points of a certain hive-type polytope. This polytopal description
together with Derksen-Weyman&#39;s Saturation Theorem for quiver semi-invariants
allows us to use Tardos&#39;s algorithm to solve the membership problem for
$\Delta(Q,\beta)$ in strongly polynomial time. In particular, this yields a
strongly polynomial time algorithm for solving the generic semi-stability
problem for representations of $Q$ and $Q_\beta$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Complexity of Simon&#39;s problem in classical sense</title>
  <guid>http://arxiv.org/abs/2211.01776</guid>
  <link>http://arxiv.org/abs/2211.01776</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zantema_H/0/1/0/all/0/1&quot;&gt;Hans Zantema&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Simon&#39;s problem is a standard example of a problem that is exponential in
classical sense, while it admits a polynomial solution in quantum computing. It
is about a function $f$ for which it is given that a unique non-zero vector $s$
exists for which $f(x) = f(x \oplus s)$ for all $x$, where $\oplus$ is the
exclusive or operator. The goal is to find $s$. The exponential lower bound for
the classical sense assumes that $f$ only admits black box access. In this
paper we investigate classical complexity when $f$ is given by a standard
representation like a circuit. We focus on finding the vector space of all
vectors $s$ for which $f(x) = f(x \oplus s)$ for all $x$, for any given $f$.
Two main results are: (1) if $f$ is given by any circuit, then checking whether
this vector space contains a non-zero element is NP-hard, and (2) if $f$ is
given by any ordered BDD, then a basis of this vector space can be computed in
polynomial time.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A New Approach to Estimating Effective Resistances and Counting Spanning Trees in Expander Graphs</title>
  <guid>http://arxiv.org/abs/2211.01468</guid>
  <link>http://arxiv.org/abs/2211.01468</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lawrence Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sachdeva_S/0/1/0/all/0/1&quot;&gt;Sushant Sachdeva&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We demonstrate that for expander graphs, for all $\epsilon &amp;gt; 0,$ there exists
a data structure of size $\widetilde{O}(n\epsilon^{-1})$ which can be used to
return $(1 + \epsilon)$-approximations to effective resistances in
$\widetilde{O}(1)$ time per query. Short of storing all effective resistances,
previous best approaches could achieve $\widetilde{O}(n\epsilon^{-2})$ size and
$\widetilde{O}(\epsilon^{-2})$ time per query by storing Johnson-Lindenstrauss
vectors for each vertex, or $\widetilde{O}(n\epsilon^{-1})$ size and
$\widetilde{O}(n\epsilon^{-1})$ time per query by storing a spectral sketch.
&lt;/p&gt;
&lt;p&gt;Our construction is based on two key ideas: 1) $\epsilon^{-1}$-sparse,
$\epsilon$-additive approximations to $DL^+1_u$ for all $u,$ can be used to
recover $(1 + \epsilon)$-approximations to the effective resistances, 2) In
expander graphs, only $\widetilde{O}(\epsilon^{-1})$ coordinates of a vector
similar to $DL^+1_u$ are larger than $\epsilon.$ We give an efficient
construction for such a data structure in $\widetilde{O}(m + n\epsilon^{-2})$
time via random walks. This results in an algorithm for computing
$(1+\epsilon)$-approximate effective resistances for $s$ vertex pairs in
expanders that runs in $\widetilde{O}(m + n\epsilon^{-2} + s)$ time, improving
over the previously best known running time of $m^{1 + o(1)} + (n +
s)n^{o(1)}\epsilon^{-1.5}$ for $s = \omega(n\epsilon^{-0.5}).$
&lt;/p&gt;
&lt;p&gt;We employ the above algorithm to compute a $(1+\delta)$-approximation to the
number of spanning trees in an expander graph, or equivalently, approximating
the (pseudo)determinant of its Laplacian in $\widetilde{O}(m +
n^{1.5}\delta^{-1})$ time. This improves on the previously best known result of
$m^{1+o(1)} + n^{1.875+o(1)}\delta^{-1.75}$ time, and matches the best known
size of determinant sparsifiers.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Computing a many-to-many matching with demands and capacities between two sets using the Hungarian algorithm</title>
  <guid>http://arxiv.org/abs/2211.01612</guid>
  <link>http://arxiv.org/abs/2211.01612</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajabi_Alni_F/0/1/0/all/0/1&quot;&gt;Fatemeh Rajabi-Alni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagheri_A/0/1/0/all/0/1&quot;&gt;Alireza Bagheri&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given two sets A={a_1,a_2,...,a_s} and {b_1,b_2,...,b_t}, a many-to-many
matching with demands and capacities (MMDC) between A and B matches each
element a_i in A to at least \alpha_i and at most \alpha&#39;_i elements in B, and
each element b_j in B to at least \beta_j and at most \beta&#39;_j elements in A
for all 1=&amp;lt;i&amp;lt;=s and 1=&amp;lt;j&amp;lt;=t. In this paper, we present an algorithm for finding
a minimum-cost MMDC between A and B using the well-known Hungarian algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Pairing optimization via statistics: Algebraic structure in pairing problems and its application to performance enhancement</title>
  <guid>http://arxiv.org/abs/2211.01661</guid>
  <link>http://arxiv.org/abs/2211.01661</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujita_N/0/1/0/all/0/1&quot;&gt;Naoki Fujita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rohm_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; R&amp;#xf6;hm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mihana_T/0/1/0/all/0/1&quot;&gt;Takatomo Mihana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horisaki_R/0/1/0/all/0/1&quot;&gt;Ryoichi Horisaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Aohan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasegawa_M/0/1/0/all/0/1&quot;&gt;Mikio Hasegawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naruse_M/0/1/0/all/0/1&quot;&gt;Makoto Naruse&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Fully pairing all elements of a set while attempting to maximize the total
benefit is a combinatorically difficult problem. Such pairing problems
naturally appear in various situations in science, technology, economics, and
other fields. In our previous study, we proposed an efficient method to infer
the underlying compatibilities among the entities, under the constraint that
only the total compatibility is observable. Furthermore, by transforming the
pairing problem into a traveling salesman problem with a multi-layer
architecture, a pairing optimization algorithm was successfully demonstrated to
derive a high-total-compatibility pairing. However, there is substantial room
for further performance enhancement by further exploiting the underlying
mathematical properties. In this study, we prove the existence of algebraic
structures in the pairing problem. We transform the initially estimated
compatibility information into an equivalent form where the variance of the
individual compatibilities is minimized. We then demonstrate that the total
compatibility obtained when using the heuristic pairing algorithm on the
transformed problem is significantly higher compared to the previous method.
With this improved perspective on the pairing problem using fundamental
mathematical properties, we can contribute to practical applications such as
wireless communications beyond 5G, where efficient pairing is of critical
importance.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Round and Bipartize Approximation Algorithm for Vertex Cover</title>
  <guid>http://arxiv.org/abs/2211.01699</guid>
  <link>http://arxiv.org/abs/2211.01699</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kashaev_D/0/1/0/all/0/1&quot;&gt;Danish Kashaev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schafer_G/0/1/0/all/0/1&quot;&gt;Guido Sch&amp;#xe4;fer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The vertex cover problem is a fundamental and widely studied combinatorial
optimization problem. It is known that its standard linear programming
relaxation is integral for bipartite graphs and half-integral for general
graphs. As a consequence, the natural rounding algorithm based on this
relaxation computes an optimal solution for bipartite graphs and a
$2$-approximation for general graphs. This raises the question of whether one
can obtain improved bounds on the approximation ratio, depending on how close
the graph is to being bipartite.
&lt;/p&gt;
&lt;p&gt;In this paper, we consider a round-and-bipartize algorithm that exploits the
knowledge of an induced bipartite subgraph to attain improved approximation
ratios. Equivalently, we suppose that we have access to a subset of vertices
$S$ whose removal bipartizes the graph.
&lt;/p&gt;
&lt;p&gt;If $S$ is an independent set, we prove an approximation ratio of $1 +
1/\rho$, where $2\rho -1$ denotes the odd girth of the contracted graph
$\tilde{\mathcal{G}} := \mathcal{G} /S$ and thus satisfies $\rho \geq 2$. We
show that this is tight for any graph and independent set by providing a family
of weight functions for which this bound is attained. In addition, we give
tight upper bounds for the fractional chromatic number and the integrality gap
of such graphs, both of which also depend on the odd girth.
&lt;/p&gt;
&lt;p&gt;If $S$ is an arbitrary set, we prove a tight approximation ratio of
$\left(1+1/\rho \right) (1 - \alpha) + 2 \alpha$, where $\alpha \in [0,1]$
denotes the total normalized dual sum of the edges lying inside of the set $S$.
As an algorithmic application, we show that for any efficiently $k$-colorable
graph with $k \geq 4$ we can find a bipartizing set satisfying $\alpha \leq 1 -
4/k$. This provides an approximation algorithm recovering the bound of $2 -
2/k$ in the worst case (i.e., when $\rho = 2$), which is best possible for this
setting when using the standard relaxation.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Efficient Branch-and-Bound Algorithms for Finding Triangle-Constrained 2-Clubs</title>
  <guid>http://arxiv.org/abs/2211.01701</guid>
  <link>http://arxiv.org/abs/2211.01701</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gruttemeier_N/0/1/0/all/0/1&quot;&gt;Niels Gr&amp;#xfc;ttemeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komusiewicz_C/0/1/0/all/0/1&quot;&gt;Christian Komusiewicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kessler_P/0/1/0/all/0/1&quot;&gt;Philipp Heinrich Ke&amp;#xdf;ler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sommer_F/0/1/0/all/0/1&quot;&gt;Frank Sommer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the Vertex Triangle 2-Club problem, we are given an undirected graph $G$
and aim to find a maximum-vertex subgraph of $G$ that has diameter at most 2
and in which every vertex is contained in at least $\ell$ triangles in the
subgraph. So far, the only algorithm for solving Vertex Triangle 2-Club relies
on an ILP formulation [Almeida and Br\&#39;as, Comput. Oper. Res. 2019]. In this
work, we develop a combinatorial branch-and-bound algorithm that, coupled with
a set of data reduction rules, outperforms the existing implementation and is
able to find optimal solutions on sparse real-world graphs with more than
100,000 vertices in a few minutes. We also extend our algorithm to the Edge
Triangle 2-Club problem where the triangle constraint is imposed on all edges
of the subgraph.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Model-Checking for First-Order Logic with Disjoint Paths Predicates in Proper Minor-Closed Graph Classes</title>
  <guid>http://arxiv.org/abs/2211.01723</guid>
  <link>http://arxiv.org/abs/2211.01723</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golovach_P/0/1/0/all/0/1&quot;&gt;Petr A. Golovach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stamoulis_G/0/1/0/all/0/1&quot;&gt;Giannos Stamoulis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thilikos_D/0/1/0/all/0/1&quot;&gt;Dimitrios M. Thilikos&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The disjoint paths logic, FOL+DP, is an extension of First-Order Logic (FOL)
with the extra atomic predicate ${\sf dp}_k(x_1,y_1,\ldots,x_k,y_k),$
expressing the existence of internally vertex-disjoint paths between $x_i$ and
$y_i,$ for $i\in\{1,\ldots, k\}$. This logic can express a wide variety of
problems that escape the expressibility potential of FOL. We prove that for
every proper minor-closed graph class, model-checking for FOL+DP can be done in
quadratic time. We also introduce an extension of FOL+DP, namely the scattered
disjoint paths logic, FOL+SDP, where we further consider the atomic predicate
$s{\sf -sdp}_k(x_1,y_1,\ldots,x_k,y_k),$ demanding that the disjoint paths are
within distance bigger than some fixed value $s$. Using the same technique we
prove that model-checking for FOL+SDP can be done in quadratic time on classes
of graphs with bounded Euler genus.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Distributed Reconfiguration of Spanning Trees</title>
  <guid>http://arxiv.org/abs/2211.01725</guid>
  <link>http://arxiv.org/abs/2211.01725</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Siddharth Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1&quot;&gt;Manish Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pai_S/0/1/0/all/0/1&quot;&gt;Shreyas Pai&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a reconfiguration problem, given a problem and two feasible solutions of
the problem, the task is to find a sequence of transformations to reach from
one solution to the other such that every intermediate state is also a feasible
solution to the problem. In this paper, we study the distributed spanning tree
reconfiguration problem and we define a new reconfiguration step, called
$k$-simultaneous add and delete, in which every node is allowed to add at most
$k$ edges and delete at most $k$ edges such that multiple nodes do not add or
delete the same edge.
&lt;/p&gt;
&lt;p&gt;We first observe that, if the two input spanning trees are rooted, then we
can do the reconfiguration using a single $1$-simultaneous add and delete step
in one round in the CONGEST model. Therefore, we focus our attention towards
unrooted spanning trees and show that transforming an unrooted spanning tree
into another using a single $1$-simultaneous add and delete step requires
$\Omega(n)$ rounds in the LOCAL model. We additionally show that transforming
an unrooted spanning tree into another using a single $2$-simultaneous add and
delete step can be done in $O(\log n)$ rounds in the CONGEST model.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>SQUID: Faster Analytics via Sampled Quantiles Data-structure</title>
  <guid>http://arxiv.org/abs/2211.01726</guid>
  <link>http://arxiv.org/abs/2211.01726</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ben_Basat_R/0/1/0/all/0/1&quot;&gt;Ran Ben-Basat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Einziger_G/0/1/0/all/0/1&quot;&gt;Gil Einziger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1&quot;&gt;Wenchen Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tayh_B/0/1/0/all/0/1&quot;&gt;Bilal Tayh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Measurement is a fundamental enabler of network applications such as load
balancing, attack detection and mitigation, and traffic engineering. A key
building block in many critical measurement tasks is \emph{q-MAX}, where we
wish to find the largest $q$ values in a number stream. A standard approach of
maintaining a heap of the largest $q$ values ordered results in logarithmic
runtime, which is too slow for large measurements. Modern approaches attain a
constant runtime by removing small items in bulk and retaining the largest $q$
items at all times. Yet, these approaches are bottlenecked by an expensive
quantile calculation method.
&lt;/p&gt;
&lt;p&gt;We propose SQUID, a method that redesigns q-MAX to allow the use of
\emph{approximate quantiles}, which we can compute efficiently, thereby
accelerating the solution and, subsequently, many measurement tasks. We
demonstrate the benefit of our approach by designing a novel weighted heavy
hitters data structure that is faster and more accurate than the existing
alternatives. Here, we combine our previous techniques with a lazy deletion of
small entries, which expiates the maintenance process and increases the
accuracy. We also demonstrate the applicability of our algorithmic approach in
a general algorithmic scope by implementing the LRFU cache policy with a
constant update time. Furthermore, we also show the practicality of SQUID for
improving real-world networked systems, by implementing a P4 prototype of SQUID
for in-network caching and demonstrating how SQUID enables a wide spectrum of
score-based caching policies directly on a P4 switch.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Matching Augmentation via Simultaneous Contractions</title>
  <guid>http://arxiv.org/abs/2211.01912</guid>
  <link>http://arxiv.org/abs/2211.01912</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_M/0/1/0/all/0/1&quot;&gt;Mohit Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hommelsheim_F/0/1/0/all/0/1&quot;&gt;Felix Hommelsheim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Megow_N/0/1/0/all/0/1&quot;&gt;Nicole Megow&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the matching augmentation problem (MAP), where a matching of a
graph needs to be extended into a $2$-edge-connected spanning subgraph by
adding the minimum number of edges to it. We present a polynomial-time
algorithm with an approximation ratio of $13/8 = 1.625$ improving upon an
earlier $5/3$-approximation. The improvement builds on a new
$\alpha$-approximation preserving reduction for any $\alpha\geq 3/2$ from
arbitrary MAP instances to well-structured instances that do not contain
certain forbidden structures like parallel edges, small separators, and
contractible subgraphs. We further introduce, as key ingredients, the technique
of repeated simultaneous contractions and provide improved lower bounds for
instances that cannot be contracted.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Distributed Maximal Matching and Maximal Independent Set on Hypergraphs</title>
  <guid>http://arxiv.org/abs/2211.01945</guid>
  <link>http://arxiv.org/abs/2211.01945</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balliu_A/0/1/0/all/0/1&quot;&gt;Alkida Balliu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brandt_S/0/1/0/all/0/1&quot;&gt;Sebastian Brandt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuhn_F/0/1/0/all/0/1&quot;&gt;Fabian Kuhn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olivetti_D/0/1/0/all/0/1&quot;&gt;Dennis Olivetti&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We investigate the distributed complexity of maximal matching and maximal
independent set (MIS) in hypergraphs in the LOCAL model. A maximal matching of
a hypergraph $H=(V_H,E_H)$ is a maximal disjoint set $M\subseteq E_H$ of
hyperedges and an MIS $S\subseteq V_H$ is a maximal set of nodes such that no
hyperedge is fully contained in $S$. Both problems can be solved by a simple
sequential greedy algorithm, which can be implemented naively in $O(\Delta r +
\log^* n)$ rounds, where $\Delta$ is the maximum degree, $r$ is the rank, and
$n$ is the number of nodes.
&lt;/p&gt;
&lt;p&gt;We show that for maximal matching, this naive algorithm is optimal in the
following sense. Any deterministic algorithm for solving the problem requires
$\Omega(\min\{\Delta r, \log_{\Delta r} n\})$ rounds, and any randomized one
requires $\Omega(\min\{\Delta r, \log_{\Delta r} \log n\})$ rounds. Hence, for
any algorithm with a complexity of the form $O(f(\Delta, r) + g(n))$, we have
$f(\Delta, r) \in \Omega(\Delta r)$ if $g(n)$ is not too large, and in
particular if $g(n) = \log^* n$ (which is the optimal asymptotic dependency on
$n$ due to Linial&#39;s lower bound [FOCS&#39;87]). Our lower bound proof is based on
the round elimination framework, and its structure is inspired by a new round
elimination fixed point that we give for the $\Delta$-vertex coloring problem
in hypergraphs.
&lt;/p&gt;
&lt;p&gt;For the MIS problem on hypergraphs, we show that for $\Delta\ll r$, there are
significant improvements over the naive $O(\Delta r + \log^* n)$-round
algorithm. We give two deterministic algorithms for the problem. We show that a
hypergraph MIS can be computed in $O(\Delta^2\cdot\log r + \Delta\cdot\log
r\cdot \log^* r + \log^* n)$ rounds. We further show that at the cost of a
worse dependency on $\Delta$, the dependency on $r$ can be removed almost
entirely, by giving an algorithm with complexity $\Delta^{O(\Delta)}\cdot\log^*
r + O(\log^* n)$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Truthful Matching with Online Items and Offline Agents</title>
  <guid>http://arxiv.org/abs/2211.02004</guid>
  <link>http://arxiv.org/abs/2211.02004</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldman_M/0/1/0/all/0/1&quot;&gt;Michal Feldman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1&quot;&gt;Federico Fusco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leonardi_S/0/1/0/all/0/1&quot;&gt;Stefano Leonardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mauras_S/0/1/0/all/0/1&quot;&gt;Simon Mauras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reiffenhauser_R/0/1/0/all/0/1&quot;&gt;Rebecca Reiffenh&amp;#xe4;user&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study truthful mechanisms for welfare maximization in online bipartite
matching. In our (multi-parameter) setting, every buyer is associated with a
(possibly private) desired set of items, and has a private value for being
assigned an item in her desired set. Unlike most online matching settings,
where agents arrive online, in our setting the items arrive online in an
adversarial order while the buyers are present for the entire duration of the
process. This poses a significant challenge to the design of truthful
mechanisms, due to the ability of buyers to strategize over future rounds. We
provide an almost full picture of the competitive ratios in different
scenarios, including myopic vs. non-myopic agents, tardy vs. prompt payments,
and private vs. public desired sets. Among other results, we identify the
frontier for which the celebrated $e/(e-1)$ competitive ratio for the
vertex-weighted online matching of Karp, Vazirani and Vazirani extends to
truthful agents and online items.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Competitive Kill-and-Restart Strategies for Non-Clairvoyant Scheduling</title>
  <guid>http://arxiv.org/abs/2211.02044</guid>
  <link>http://arxiv.org/abs/2211.02044</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jager_S/0/1/0/all/0/1&quot;&gt;Sven J&amp;#xe4;ger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sagnol_G/0/1/0/all/0/1&quot;&gt;Guillaume Sagnol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waldschmidt_D/0/1/0/all/0/1&quot;&gt;Daniel Schmidt genannt Waldschmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Warode_P/0/1/0/all/0/1&quot;&gt;Philipp Warode&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the fundamental scheduling problem of minimizing the sum of
weighted completion times on a single machine in the non-clairvoyant setting.
While no non-preemptive algorithm is constant competitive, Motwani, Phillips,
and Torng (SODA &#39;93) proved that the simple preemptive round robin procedure is
$2$-competitive and that no better competitive ratio is possible, initiating a
long line of research focused on preemptive algorithms for generalized variants
of the problem. As an alternative model, Shmoys, Wein, and Williamson (FOCS
&#39;91) introduced kill-and-restart schedules, where running jobs may be killed
and restarted from scratch later, and analyzed then for the makespan objective.
However, to the best of our knowledge, this concept has never been considered
for the total completion time objective in the non-clairvoyant model.
&lt;/p&gt;
&lt;p&gt;We contribute to both models: First we give for any $b &amp;gt; 1$ a tight analysis
for the natural $b$-scaling kill-and-restart strategy for scheduling jobs
without release dates, as well as for a randomized variant of it. This implies
a performance guarantee of $(1+3\sqrt{3})\approx 6.197$ for the deterministic
algorithm and of $\approx 3.032$ for the randomized version. Second, we show
that the preemptive Weighted Shortest Elapsed Time First (WSETF) rule is
$2$-competitive for jobs released in an online fashion over time, matching the
lower bound by Motwani et al. Using this result as well as the competitiveness
of round robin for multiple machines, we prove performance guarantees of
adaptions of the $b$-scaling algorithm to online release dates and unweighted
jobs on identical parallel machines.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-04 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>TR22-142 |  Correlation bounds against polynomials | 

	Emanuele Viola</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/142</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/142</link>
  <description>
    A survey on correlation bounds against polynomials.
  </description>
  <pubDate>2022-11-03 15:00:46 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Should you quit Twitter and Texas?</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-1022697361105747430</guid>
  <link>http://blog.computationalcomplexity.org/2022/11/should-you-quit-twitter-and-texas.html</link>
  <description>
    &lt;p&gt;Generally with some exceptions, I use &lt;a href=&quot;https://facebook.com/fortnow&quot;&gt;Facebook&lt;/a&gt; for personal stuff, &lt;a href=&quot;https://www.linkedin.com/in/fortnow/&quot;&gt;LinkedIn&lt;/a&gt; for Illinois Tech stuff and &lt;a href=&quot;https://twitter.com/fortnow&quot;&gt;Twitter&lt;/a&gt;&amp;nbsp;and this blog for CS stuff. Many of you got to this post through the &lt;a href=&quot;https://twitter.com/fortnow/status/1588144625755328514&quot;&gt;Twitter link&lt;/a&gt;. Now that Elon Musk has bought the social media company, should I and the rest of the academic twitterverse move on to something else?&lt;/p&gt;&lt;p&gt;I&#39;d say not yet. Let&#39;s see what Elon does to the place. Maybe he can allow more points of view, without turning it into a cesspool. Or maybe he ruins it. It&#39;ll be a network effect--if too many academics leave Twitter, I&#39;d have to follow or I&#39;d have few followers. I wonder where they will go. I hope it isn&#39;t TikTok.&lt;/p&gt;&lt;p&gt;On a similar vein, I often here of those who suggest we don&#39;t hold conferences in certain jurisdictions for political reasons, for example Texas, because of its laws against abortion and transgender rights. I don&#39;t believe computer science, as a field, should be making decisions based on politics. Academics who live in these states don&#39;t generally hold the same views as the political leaders in those states.&lt;/p&gt;&lt;p&gt;Should we not have meetings in Illinois because some in our field might be opposed to abortion? Or do we just assume everyone has the same political views in the field. Individuals can make their own choices as to whether to attend, but it&#39;s best when politics is left out of academics. &lt;a href=&quot;https://focs2022.eecs.berkeley.edu/&quot;&gt;FOCS 2022&lt;/a&gt; is wrapping up today in Denver. Seems like a safe choice--perhaps all US conferences in the future should be in Colorado.&amp;nbsp;&lt;/p&gt;&lt;p&gt;There are limits--I wouldn&#39;t attend or organize a conference in Russia in the near future. But if we start eliminating locations based on politics, we&#39;ll only be able to meet up in the metaverse, and we won&#39;t have social media to tell us how to get there.&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 12:18:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>Persistent Tensors and Multiqudit Entanglement Transformation</title>
  <guid>http://arxiv.org/abs/2211.00652</guid>
  <link>http://arxiv.org/abs/2211.00652</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gharahi_M/0/1/0/all/0/1&quot;&gt;Masoud Gharahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lysikov_V/0/1/0/all/0/1&quot;&gt;Vladimir Lysikov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We construct a lower bound of the tensor rank for a new class of tensors,
which we call persistent tensors. We present three specific families of
persistent tensors, of which the lower bound is tight. We show that there is a
chain of degenerations between these three families of minimal-rank persistent
tensors that can be used to study the entanglement transformation between them.
In addition, we show that these three families of persistent tensors are indeed
different generalizations of multiqubit $\rm{W}$ states within multiqudit
systems and are geometrically in the orbit closure of multiqudit $\rm{GHZ}$
states. Consequently, we show that one can obtain every one of the
generalizations of $\rm{W}$ state from a multiqudit $\rm{GHZ}$ state via
asymptotic Stochastic Local Operations and Classical Communication (SLOCC) with
rate one. Finally, we extend the obtained lower bound of the tensor rank to
direct sums with persistent summands and to even more general combinations of
tensors, which we call block pyramidal tensors. As a result, we show that the
tensor rank is multiplicative under the Kronecker and tensor products of
minimal-rank persistent tensors with the $\rm{GHZ}$ tensor.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Quantum Pseudoentanglement</title>
  <guid>http://arxiv.org/abs/2211.00747</guid>
  <link>http://arxiv.org/abs/2211.00747</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bouland_A/0/1/0/all/0/1&quot;&gt;Adam Bouland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Fefferman_B/0/1/0/all/0/1&quot;&gt;Bill Fefferman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Soumik Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Vazirani_U/0/1/0/all/0/1&quot;&gt;Umesh Vazirani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zixin Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Quantum pseudorandom states are efficiently constructable states which
nevertheless masquerade as Haar-random states to poly-time observers. First
defined by Ji, Liu and Song, such states have found a number of applications
ranging from cryptography to the AdS/CFT correspondence. A fundamental question
is exactly how much entanglement is required to create such states. Haar-random
states, as well as $t$-designs for $t\geq 2$, exhibit near-maximal
entanglement. Here we provide the first construction of pseudorandom states
with only polylogarithmic entanglement entropy across an equipartition of the
qubits, which is the minimum possible. Our construction can be based on any
one-way function secure against quantum attack. We additionally show that the
entanglement in our construction is fully &quot;tunable&quot;, in the sense that one can
have pseudorandom states with entanglement $\Theta(f(n))$ for any desired
function $\omega(\log n) \leq f(n) \leq O(n)$.
&lt;/p&gt;
&lt;p&gt;More fundamentally, our work calls into question to what extent entanglement
is a &quot;feelable&quot; quantity of quantum systems. Inspired by recent work of
Gheorghiu and Hoban, we define a new notion which we call &quot;pseudoentanglement&quot;,
which are ensembles of efficiently constructable quantum states which hide
their entanglement entropy. We show such states exist in the strongest form
possible while simultaneously being pseudorandom states. We also describe
diverse applications of our result from entanglement distillation to property
testing to quantum gravity.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Polynomial Identity Testing via Evaluation of Rational Functions</title>
  <guid>http://arxiv.org/abs/2211.01062</guid>
  <link>http://arxiv.org/abs/2211.01062</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melkebeek_D/0/1/0/all/0/1&quot;&gt;Dieter van Melkebeek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morgan_A/0/1/0/all/0/1&quot;&gt;Andrew Morgan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce a hitting set generator for Polynomial Identity Testing based on
evaluations of low-degree univariate rational functions at abscissas associated
with the variables. Despite the univariate nature, we establish an equivalence
up to rescaling with a generator introduced by Shpilka and Volkovich, which has
a similar structure but uses multivariate polynomials in the abscissas.
&lt;/p&gt;
&lt;p&gt;We study the power of the generator by characterizing its vanishing ideal,
i.e., the set of polynomials that it fails to hit. Capitalizing on the
univariate nature, we develop a small collection of polynomials that jointly
produce the vanishing ideal. As corollaries, we obtain tight bounds on the
minimum degree, sparseness, and partition class size of set-multilinearity in
the vanishing ideal. Inspired by an alternating algebra representation, we
develop a structured deterministic membership test for the vanishing ideal. As
a proof of concept, we rederive known derandomization results based on the
generator by Shpilka and Volkovich and present a new application for read-once
oblivious algebraic branching programs.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Partitioning a Polygon Into Small Pieces</title>
  <guid>http://arxiv.org/abs/2211.01359</guid>
  <link>http://arxiv.org/abs/2211.01359</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abrahamsen_M/0/1/0/all/0/1&quot;&gt;Mikkel Abrahamsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rasmussen_N/0/1/0/all/0/1&quot;&gt;Nichlas Langhoff Rasmussen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problem of partitioning a given simple polygon $P$ into a
minimum number of polygonal pieces, each of which has bounded size. We give
algorithms for seven notions of `bounded size,&#39; namely that each piece has
bounded area, perimeter, straight-line diameter, geodesic diameter, or that
each piece must be contained in a unit disk, an axis-aligned unit square or an
arbitrarily rotated unit square.
&lt;/p&gt;
&lt;p&gt;A more general version of the area problem has already been studied. Here we
are, in addition to $P$, given positive real values $a_1,\ldots,a_k$ such that
the sum $\sum_{i=1}^k a_i$ equals the area of $P$. The goal is to partition $P$
into exactly $k$ pieces $Q_1,\ldots,Q_k$ such that the area of $Q_i$ is $a_i$.
Such a partition always exists, and an algorithm with running time $O(nk)$ has
previously been described, where $n$ is the number of corners of $P$. We give
an algorithm with optimal running time $O(n+k)$. For polygons with holes, we
get running time $O(n\log n+k)$.
&lt;/p&gt;
&lt;p&gt;For the other problems, it seems out of reach to compute optimal partitions
for simple polygons; for most of them, even in extremely restricted cases such
as when $P$ is a square. We therefore develop $O(1)$-approximation algorithms
for these problems, which means that the number of pieces in the produced
partition is at most a constant factor larger than the cardinality of a minimum
partition. Existing algorithms do not allow Steiner points, which means that
all corners of the produced pieces must also be corners of $P$. This has the
disappointing consequence that a partition does often not exist, whereas our
algorithms always produce useful partitions. Furthermore, an optimal partition
without Steiner points may require $\Omega(n)$ pieces for polygons where a
partition consisting of just $2$ pieces exists when Steiner points are allowed.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Simplified Prophet Inequalities for Combinatorial Auctions</title>
  <guid>http://arxiv.org/abs/2211.00707</guid>
  <link>http://arxiv.org/abs/2211.00707</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braun_A/0/1/0/all/0/1&quot;&gt;Alexander Braun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kesselheim_T/0/1/0/all/0/1&quot;&gt;Thomas Kesselheim&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider prophet inequalities for XOS and MPH-$k$ combinatorial auctions
and give a simplified proof for the existence of static and anonymous item
prices which recover the state-of-the-art competitive ratios.
&lt;/p&gt;
&lt;p&gt;Our proofs make use of a linear programming formulation which has a
non-negative objective value if there are prices which admit a given
competitive ratio $\alpha \geq 1$. Changing our perspective to dual space by an
application of strong LP duality, we use an interpretation of the dual
variables as probabilities to directly obtain our result. In contrast to
previous work, our proofs do not require to argue about specific values of
buyers for bundles, but only about the presence or absence of items.
&lt;/p&gt;
&lt;p&gt;As a side remark, for any $k \geq 2$, this simplification also leads to a
tiny improvement in the best competitive ratio for MPH-$k$ combinatorial
auctions from $4k-2$ to $2k + 2 \sqrt{k(k-1)} -1$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Alternative polynomial-time algorithm for Bipartite Matching</title>
  <guid>http://arxiv.org/abs/2211.00711</guid>
  <link>http://arxiv.org/abs/2211.00711</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guillemot_S/0/1/0/all/0/1&quot;&gt;Sylvain Guillemot&lt;/a&gt;&lt;/p&gt;&lt;p&gt;If $G$ is a bipartite graph, Hall&#39;s theorem \cite{H35} gives a condition for
the existence of a matching of $G$ covering one side of the bipartition. This
theorem admits a well-known algorithmic proof involving the repeated search of
augmenting paths. We present here an alternative algorithm, using a
game-theoretic formulation of the problem. We also show how to extend this
formulation to the setting of balanced hypergraphs.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Privacy Induces Robustness: Information-Computation Gaps and Sparse Mean Estimation</title>
  <guid>http://arxiv.org/abs/2211.00724</guid>
  <link>http://arxiv.org/abs/2211.00724</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Georgiev_K/0/1/0/all/0/1&quot;&gt;Kristian Georgiev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hopkins_S/0/1/0/all/0/1&quot;&gt;Samuel B. Hopkins&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We establish a simple connection between robust and differentially-private
algorithms: private mechanisms which perform well with very high probability
are automatically robust in the sense that they retain accuracy even if a
constant fraction of the samples they receive are adversarially corrupted.
Since optimal mechanisms typically achieve these high success probabilities,
our results imply that optimal private mechanisms for many basic statistics
problems are robust.
&lt;/p&gt;
&lt;p&gt;We investigate the consequences of this observation for both algorithms and
computational complexity across different statistical problems. Assuming the
Brennan-Bresler secret-leakage planted clique conjecture, we demonstrate a
fundamental tradeoff between computational efficiency, privacy leakage, and
success probability for sparse mean estimation. Private algorithms which match
this tradeoff are not yet known -- we achieve that (up to polylogarithmic
factors) in a polynomially-large range of parameters via the Sum-of-Squares
method.
&lt;/p&gt;
&lt;p&gt;To establish an information-computation gap for private sparse mean
estimation, we also design new (exponential-time) mechanisms using fewer
samples than efficient algorithms must use. Finally, we give evidence for
privacy-induced information-computation gaps for several other statistics and
learning problems, including PAC learning parity functions and estimation of
the mean of a multivariate Gaussian.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Benchmarking Hashing Algorithms for Load Balancing in a Distributed Database Environment</title>
  <guid>http://arxiv.org/abs/2211.00741</guid>
  <link>http://arxiv.org/abs/2211.00741</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Slesarev_A/0/1/0/all/0/1&quot;&gt;Alexander Slesarev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikhailov_M/0/1/0/all/0/1&quot;&gt;Mikhail Mikhailov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chernishev_G/0/1/0/all/0/1&quot;&gt;George Chernishev&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Modern high load applications store data using multiple database instances.
Such an architecture requires data consistency, and it is important to ensure
even distribution of data among nodes. Load balancing is used to achieve these
goals.
&lt;/p&gt;
&lt;p&gt;Hashing is the backbone of virtually all load balancing systems. Since the
introduction of classic Consistent Hashing, many algorithms have been devised
for this purpose.
&lt;/p&gt;
&lt;p&gt;One of the purposes of the load balancer is to ensure storage cluster
scalability. It is crucial for the performance of the whole system to transfer
as few data records as possible during node addition or removal. The load
balancer hashing algorithm has the greatest impact on this process.
&lt;/p&gt;
&lt;p&gt;In this paper we experimentally evaluate several hashing algorithms used for
load balancing, conducting both simulated and real system experiments. To
evaluate algorithm performance, we have developed a benchmark suite based on
Unidata MDM~ -- a scalable toolkit for various Master Data Management (MDM)
applications. For assessment, we have employed three criteria~ -- uniformity of
the produced distribution, the number of moved records, and computation speed.
Following the results of our experiments, we have created a table, in which
each algorithm is given an assessment according to the abovementioned criteria.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Balancing Utility and Fairness in Submodular Maximization (Technical Report)</title>
  <guid>http://arxiv.org/abs/2211.00980</guid>
  <link>http://arxiv.org/abs/2211.00980</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuchen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonchi_F/0/1/0/all/0/1&quot;&gt;Francesco Bonchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Ying Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Submodular function maximization is central in numerous data science
applications, including data summarization, influence maximization, and
recommendation. In many of these problems, our goal is to find a solution that
maximizes the \emph{average} of the utilities for all users, each measured by a
monotone submodular function. When the population of users is composed of
several demographic groups, another critical problem is whether the utility is
fairly distributed across groups. In the context of submodular optimization, we
seek to improve the welfare of the \emph{least well-off} group, i.e., to
maximize the minimum utility for any group, to ensure fairness. Although the
\emph{utility} and \emph{fairness} objectives are both desirable, they might
contradict each other, and, to our knowledge, little attention has been paid to
optimizing them jointly. In this paper, we propose a novel problem called
\emph{Bicriteria Submodular Maximization} (BSM) to strike a balance between
utility and fairness. Specifically, it requires finding a fixed-size solution
to maximize the utility function, subject to the value of the fairness function
not being below a threshold. Since BSM is inapproximable within any constant
factor in general, we propose efficient data-dependent approximation algorithms
for BSM by converting it into other submodular optimization problems and
utilizing existing algorithms for the converted problems to obtain solutions to
BSM. Using real-world and synthetic datasets, we showcase applications of our
framework in three submodular maximization problems, namely maximum coverage,
influence maximization, and facility location.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Joint Correlation Detection and Alignment of Gaussian Databases</title>
  <guid>http://arxiv.org/abs/2211.01069</guid>
  <link>http://arxiv.org/abs/2211.01069</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tamir_R/0/1/0/all/0/1&quot;&gt;Ran Tamir&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work, we propose an efficient two-stage algorithm solving a joint
problem of correlation detection and permutation recovery between two Gaussian
databases. Correlation detection is an hypothesis testing problem; under the
null hypothesis, the databases are independent, and under the alternate
hypothesis, they are correlated, under an unknown row permutation. We develop
relatively tight bounds on the type-I and type-II error probabilities, and show
that the analyzed detector performs better than a recently proposed detector,
at least for some specific parameter choices. Since the proposed detector
relies on a statistic, which is a sum of dependent indicator random variables,
then in order to bound the type-I probability of error, we develop a novel
graph-theoretic technique for bounding the $k$-th order moments of such
statistics. When the databases are accepted as correlated, the algorithm also
outputs an estimation for the underlying row permutation. By comparing to known
converse results for this problem, we prove that the alignment error
probability converges to zero under the asymptotically lowest possible
correlation coefficient.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Set Selection under Explorable Stochastic Uncertainty via Covering Techniques</title>
  <guid>http://arxiv.org/abs/2211.01097</guid>
  <link>http://arxiv.org/abs/2211.01097</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Megow_N/0/1/0/all/0/1&quot;&gt;Nicole Megow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schloter_J/0/1/0/all/0/1&quot;&gt;Jens Schl&amp;#xf6;ter&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given subsets of uncertain values, we study the problem of identifying the
subset of minimum total value (sum of the uncertain values) by querying as few
values as possible. This set selection problem falls into the field of
explorable uncertainty and is of intrinsic importance therein as it implies
strong adversarial lower bounds for a wide range of interesting combinatorial
problems such as knapsack and matchings. We consider a stochastic problem
variant and give algorithms that, in expectation, improve upon these
adversarial lower bounds. The key to our results is to prove a strong
structural connection to a seemingly unrelated covering problem with
uncertainty in the constraints via a linear programming formulation. We exploit
this connection to derive an algorithmic framework that can be used to solve
both problems under uncertainty, obtaining nearly tight bounds on the
competitive ratio. This is the first non-trivial stochastic result concerning
the sum of unknown values without further structure known for the set. Further,
we handle for the first time uncertainty in the constraints in a value-query
model. With our novel methods, we lay the foundations for solving more general
problems in the area of explorable uncertainty.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>New Tradeoffs for Decremental Approximate All-Pairs Shortest Paths</title>
  <guid>http://arxiv.org/abs/2211.01152</guid>
  <link>http://arxiv.org/abs/2211.01152</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dory_M/0/1/0/all/0/1&quot;&gt;Michal Dory&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forster_S/0/1/0/all/0/1&quot;&gt;Sebastian Forster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nazari_Y/0/1/0/all/0/1&quot;&gt;Yasamin Nazari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vos_T/0/1/0/all/0/1&quot;&gt;Tijn de Vos&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We provide new tradeoffs between approximation and running time for the
decremental all-pairs shortest paths (APSP) problem. For undirected graphs with
$m$ edges and $n$ nodes undergoing edge deletions, we provide two new
approximate decremental APSP algorithms, one for weighted and one for
unweighted graphs. Our first result is an algorithm that supports $(2+
\epsilon)$-approximate all-pairs constant-time distance queries with total
update time $\tilde{O}(m^{1/2}n^{3/2})$ when $m= O(n^{5/3})$ (and $m= n^{1+c}$
for any constant $c &amp;gt;0$), or $\tilde{O}(mn^{2/3})$ when $m = \Omega(n^{5/3})$.
Prior to our work the fastest algorithm for weighted graphs with approximation
at most $3$ had total $\tilde O(mn)$ update time providing a
$(1+\epsilon)$-approximation [Bernstein, SICOMP 2016]. Our technique also
yields a decremental algorithm with total update time $\tilde{O}(nm^{3/4})$
supporting $(2+\epsilon, W_{u,v})$-approximate queries where the second term is
an additional additive term and $W_{u,v}$ is the maximum weight on the shortest
path from $u$ to $v$.
&lt;/p&gt;
&lt;p&gt;Our second result is a decremental algorithm that given an unweighted graph
and a constant integer $k \geq 2 $, supports $(1+\epsilon, 2(k-1))$-approximate
queries and has $\tilde{O}(n^{2-1/k}m^{1/k})$ total update time (when
$m=n^{1+c}$ for any constant $c &amp;gt;0$). For comparison, in the special case of
$(1+\epsilon, 2)$-approximation, this improves over the state-of-the-art
algorithm by [Henzinger, Krinninger, Nanongkai, SICOMP 2016] with total update
time of $\tilde{O}(n^{2.5})$. All of our results are randomized and work
against an oblivious adversary.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Two Step Approach to Weighted Bipartite Link Recommendations</title>
  <guid>http://arxiv.org/abs/2211.01153</guid>
  <link>http://arxiv.org/abs/2211.01153</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_N/0/1/0/all/0/1&quot;&gt;Nathan Ma&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Many real world person-person or person-product relationships can be modeled
graphically. More specifically, bipartite graphs can be especially useful when
modeling scenarios that involve two disjoint groups. As a result, many existing
papers have utilized bipartite graphs for the classical link recommendation
problem. In this paper, using the principle of bipartite graphs, we present
another approach to this problem with a two step algorithm that takes into
account frequency and similarity between common edges to make recommendations.
We test this approach with bipartite data gathered from the Epinions and
Movielens data sources, and find it to perform with roughly 14 percent error,
which improves upon baseline results. This is a promising result, and can be
refined to generate even more accurate recommendations.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Cluster Assignment in Multi-Agent Systems : Sparsity Bounds and Fault Tolerance</title>
  <guid>http://arxiv.org/abs/2211.01316</guid>
  <link>http://arxiv.org/abs/2211.01316</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sharf_M/0/1/0/all/0/1&quot;&gt;Miel Sharf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zelazo_D/0/1/0/all/0/1&quot;&gt;Daniel Zelazo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study cluster assignment in homogeneous diffusive multi-agent networks.
Given the number of clusters and agents within each cluster, we design the
network graph ensuring the system will converge to the prescribed cluster
configuration. Using recent results linking clustering and symmetries, we show
that it is possible to design an oriented graph for which the action of the
automorphism group of the graph has orbits of predetermined sizes, guaranteeing
the network will converge to the prescribed cluster configuration. We provide
bounds on the number of edges needed to construct these graphs along with a
constructive approach for their generation. We also consider the robustness of
the clustering process under agent malfunction.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-03 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>PhotoGuard: Defending Against Diffusion-based Image Manipulation</title>
  <guid>https://gradientscience.org/photoguard/</guid>
  <link>https://gradientscience.org/photoguard/</link>
  <description>
    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://use.fontawesome.com/releases/v5.8.1/css/all.css&quot; integrity=&quot;sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf&quot; crossorigin=&quot;anonymous&quot; /&gt;

&lt;style&gt;
    div.footnote{
        overflow: hidden;
        margin-bottom: 2rem;
        padding-left: 5%;
        margin-left: 0%;
        margin-top: 20px;
        width: 90%;
        border-left: 3px #A31F34 solid;
        font-size: 0.9rem;
    }

    blockquote {
        padding-top: 0;
        padding-bottom: 0;
    }

    .bbutton{
        width: 27.5%;
        margin: 2.5%;
        height: 3rem;
        line-height: 3rem;
        display: inline-block;
        background: #DDD;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: 400;
        color: #000;
    }

    .bbutton:hover{
        background: #e98a99;
    }
&lt;/style&gt;

&lt;script src=&quot;/assets/scripts/onload.js&quot;&gt;&lt;/script&gt;

&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/assets/css/style.css&quot; /&gt;

&lt;p&gt;&lt;a class=&quot;bbutton&quot; style=&quot;float: left; width: 45%;&quot; href=&quot;#&quot;&gt;
&lt;i class=&quot;fas fa-file-pdf&quot;&gt;&lt;/i&gt;
    Paper Coming Soon!
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;bbutton&quot; style=&quot;float: left; width: 45%;&quot; href=&quot;https://github.com/MadryLab/photoguard&quot;&gt;
&lt;i class=&quot;fab fa-github&quot;&gt;&lt;/i&gt;
   Code
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;A few nights ago on The Daily Show, host Trevor Noah interviewed Mira Murati (CTO of OpenAI) about DALL$\cdot$E 2 and, more generally, the power of AI:&lt;/p&gt;

&lt;div style=&quot;width: 100%; text-align: center; padding-top: 10px; padding-bottom: 10px;&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Ba_C-C6UwlI?start=228&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;The whole interview is a great watch, but one thing that stood out to us is Trevor’s question at 3:50:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;“So how do you safeguard them [generative models]?… We can very quickly find ourselves in a world where nothing is real, and everything that’s real isn’t, and we question it. How do you prevent, or can you even prevent that completely?”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Indeed, DALL$\cdot$E (and diffusion models in general) greatly exacerbate the risks of malicious image manipulation—what previously required extensive knowledge of photoshop can now be done with just a simple natural-language query:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/photoguard/dog_example.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In fact, editing photos of cute dogs is just the tip of the iceberg:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/photoguard/trevor_example.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So, back to Trevor Noah’s question—is there any hope of protecting against this manipulation? We spent a few nights hacking away, and it turns out that—by leveraging adversarial examples—we can do exactly that! The details of our scheme are below,  but the essence is that, by slightly modifying (imperceptibly, even) the input image, we can create a &lt;em&gt;PhotoGuard&lt;/em&gt;, make the image immune to direct editing by generative models!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/photoguard/photoguard_headline.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;footnote&quot;&gt;
&lt;strong&gt;Note:&lt;/strong&gt; One might (rightfully) point out that by re-training a
diffusion model in the future, one will be able to get around our &quot;photo guard&quot;
(in other words, that we are in a &lt;a href=&quot;https://arxiv.org/abs/2106.14851&quot;&gt;static defense vs. adaptive attack&lt;/a&gt;
scenario). This is definitely true! However, our goal here is not to suggest
that individual users should safeguard their own images by themselves. Instead,
we hope that the companies providing the models themselves can provide an API to
safeguard one&#39;s images against editing.  
&lt;/div&gt;

&lt;p&gt;By the way, Michael Kosta is not the only person who has a selfie with Trevor. Hadi — the lead student on this project — took a selfie with Trevor couple years ago too.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;A selfie of Hadi and Trevor Noah&quot; src=&quot;/assets/photoguard/hadi_trevor_selfie.png&quot; style=&quot;width:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, Hadi can leverage diffusion-powered photo editing to “deepen” his
(imaginary) friendship with Trevor.
If the selfie was guarded, none of this would be possible (sadly for Trevor,
it isn’t)!&lt;/p&gt;

&lt;div class=&quot;widget&quot;&gt;
    &lt;div class=&quot;choices_one_full&quot; id=&quot;gen&quot;&gt;
    &lt;span class=&quot;widgetheading&quot; id=&quot;genclass&quot;&gt;Choose an Image&lt;/span&gt;
    &lt;/div&gt;
    &lt;div style=&quot;border-right: 3px white solid;&quot;&gt;
        &lt;img id=&quot;gen0-1&quot; class=&quot;image-container&quot; style=&quot;width: 0%; margin: 0;&quot; /&gt;
        &lt;img id=&quot;gen0-2&quot; class=&quot;image-container&quot; style=&quot;width: 100%; margin: 0;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div style=&quot;clear:both;&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;some-details&quot;&gt;Some details&lt;/h2&gt;

&lt;p&gt;The core of our “immunization” process is to leverage so-called &lt;a href=&quot;http://gradientscience.org/intro_adversarial/&quot;&gt;adversarial attacks&lt;/a&gt; on these generative models. In particular, we implemented two different PhotoGuards, focused on &lt;em&gt;latent diffusion models&lt;/em&gt; (like &lt;a href=&quot;http://stability.ai&quot;&gt;Stable Diffusion&lt;/a&gt;). For simplicity, we can think of such models as having two parts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The &lt;em&gt;conditioning mechanism&lt;/em&gt; is how the model incorporates external data such as the starting image and the prompt into its final generation. Typically, a pre-trained encoder converts the external signals to a shared embedding space—the model concatenates these embeddings and uses them as input to…&lt;/li&gt;
  &lt;li&gt;…the &lt;em&gt;diffusion process,&lt;/em&gt; which is responsible for generating the final image generated images. There are many good introductions to how exactly diffusion processes work, but the summary is that we start from random noise, and then repeatedly apply a model that “denoises” the input a little bit at a time.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We construct both a simple PhotoGuard targeting the conditioning mechanism, and a complex PhotoGuard targeting the end-to-end diffusion process itself.&lt;/p&gt;

&lt;h3 id=&quot;simple-photoguard&quot;&gt;Simple PhotoGuard&lt;/h3&gt;

&lt;p&gt;In the simpler of the two, we adversarially attack only the conditioning step of the diffusion process. That is, given a starting image $x_0$, we find an image $x_{adv}$ satisfying:&lt;/p&gt;

\[x_{adv} = \arg\min_{\mid\mid x - x_0 \mid\mid \lt \delta} \mathcal{L}(z_x, z_{targ})\]

&lt;p&gt;where $z_x$ is the embedding of the input $x$, and $z_{targ}$ is a fixed embedding. We set $z_{targ}$ to the all zeros vector (or even to an embedding of a random image), causing the diffusion model to completely ignore the starting image and focus only on the prompt.&lt;/p&gt;

&lt;div class=&quot;widget&quot;&gt;
    &lt;div class=&quot;choices_one_full&quot; id=&quot;gen-1&quot;&gt;
    &lt;span class=&quot;widgetheading&quot; id=&quot;genclass&quot;&gt;Choose an Image&lt;/span&gt;
    &lt;/div&gt;
    &lt;div style=&quot;border-right: 3px white solid;&quot;&gt;
        &lt;img id=&quot;gen1-1&quot; class=&quot;image-container&quot; style=&quot;width: 0%; margin: 0;&quot; /&gt;
        &lt;img id=&quot;gen1-2&quot; class=&quot;image-container&quot; style=&quot;width: 100%; margin: 0;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div style=&quot;clear:both;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;complex-photoguard&quot;&gt;Complex PhotoGuard&lt;/h3&gt;

&lt;p&gt;However, we find that we can do an even stronger guard! Here, we modify the starting image with the goal of breaking the &lt;em&gt;whole&lt;/em&gt; end-to-end diffusion process. Because the diffusion process is iterative and involves repeated application of a network, taking gradients through the diffusion process is memory-intensive. We found that differentiating through &lt;em&gt;only four&lt;/em&gt; denoising steps was enough to throw off the entire diffusion process. With a little engineering, we were able to fit four steps onto a single (A100) GPU. As you can see, editing our immunized/defended photos lead to much clearer fake images than the previous guard.&lt;/p&gt;

&lt;p&gt;Here are some examples of fake photos, with and without our “immunization!”&lt;/p&gt;

&lt;div class=&quot;widget&quot;&gt;
    &lt;div class=&quot;choices_one_full&quot; id=&quot;gen-2&quot;&gt;
    &lt;span class=&quot;widgetheading&quot; id=&quot;genclass&quot;&gt;Choose an Image&lt;/span&gt;
    &lt;/div&gt;
    &lt;div style=&quot;border-right: 3px white solid;&quot;&gt;
        &lt;img id=&quot;gen2-1&quot; class=&quot;image-container&quot; style=&quot;width: 0%; margin: 0;&quot; /&gt;
        &lt;img id=&quot;gen2-2&quot; class=&quot;image-container&quot; style=&quot;width: 100%; margin: 0;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div style=&quot;clear:both;&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;takeaways-and-future-work&quot;&gt;Takeaways and Future Work&lt;/h2&gt;

&lt;p&gt;So, using relatively simple techniques relating to adversarial examples (and about a week’s worth of hacking), we were able to protect images against manipulation from diffusion-based generative models. That said, this is just the beginning, and there are still many unanswered questions!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We only constructed these examples by using an &lt;a href=&quot;https://stability.ai/blog/stable-diffusion-public-release&quot;&gt;open-source diffusion model&lt;/a&gt; (from &lt;a href=&quot;https://huggingface.co/runwayml/stable-diffusion-inpainting&quot;&gt;HuggingFace&lt;/a&gt;). Is it be possible to make them with only black-box access to the model?&lt;/li&gt;
  &lt;li&gt;Our complex PhotoGuard uses a lot of memory (we could only fit four diffusion steps onto a single GPU). Meanwhile, &lt;a href=&quot;https://arxiv.org/abs/2205.07460&quot;&gt;recent work&lt;/a&gt; shows that for some diffusion processes, one can obtain the gradient through the entire diffusion process by solving a stochastic differential equation (SDE) and using a constant amount of memory. Is it possible to do something similar more generally?&lt;/li&gt;
  &lt;li&gt;There is a huge literature on constructing &lt;a href=&quot;https://arxiv.org/abs/1707.07397&quot;&gt;robust adversarial examples&lt;/a&gt;. It should be possible to leverage similar techniques to make our PhotoGuards more robust to manipulation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;More generally, we’re excited about the prospect of adversarial examples being used for forcing &lt;em&gt;intended&lt;/em&gt; behavior, rather than for exploiting vulnerabilities (a phenomenon also seen in our work on &lt;a href=&quot;http://gradientscience.org/unadversarial/&quot;&gt;unadversarial examples&lt;/a&gt;!).&lt;/p&gt;

&lt;script&gt;
 function main() {
     const BASE_DIR = &quot;/assets/photoguard/&quot;;
     
     // Generation
     var genImage1 = document.getElementById(&#39;gen0-1&#39;);
     var genImage2 = document.getElementById(&#39;gen0-2&#39;);
     var genSrcs = range(10).map((name) =&gt; BASE_DIR + &#39;hadi_selfies/&#39; + name + &quot;_orig.png&quot;);
     function genMapper(origSrc, id) {
           genImage1.src = origSrc;
           genImage2.src = origSrc.replace(&quot;_orig.png&quot;, &quot;.png&quot;);
     }
     activate_one_widget(&#39;gen&#39;, genSrcs, genMapper);

    // Generation
     var genImage11 = document.getElementById(&#39;gen1-1&#39;);
     var genImage12 = document.getElementById(&#39;gen1-2&#39;);
     var genSrcs1 = range(8).map((name) =&gt; BASE_DIR + &#39;encoder_attack/&#39; + name + &quot;_orig.png&quot;);
     function genMapper1(origSrc, id) {
           genImage11.src = origSrc;
           genImage12.src = origSrc.replace(&quot;_orig.png&quot;, &quot;.png&quot;);
     }

     activate_one_widget(&#39;gen-1&#39;, genSrcs1, genMapper1);
    
     var genImage21 = document.getElementById(&#39;gen2-1&#39;);
     var genImage22 = document.getElementById(&#39;gen2-2&#39;);
     var genSrcs2 = range(10).map((name) =&gt; BASE_DIR + &#39;diffusion_attack/&#39; + name + &quot;_orig.png&quot;);
     function genMapper2(origSrc, id) {
           genImage21.src = origSrc;
           genImage22.src = origSrc.replace(&quot;_orig.png&quot;, &quot;.png&quot;);
     }

     activate_one_widget(&#39;gen-2&#39;, genSrcs2, genMapper2);
 }
 window.onload = main;

&lt;/script&gt;
  </description>
  <pubDate>2022-11-03 00:00:00 UTC</pubDate>
  <author>Gradient Science</author>
</item>

<item>
  <title>TCS+ talk: Wednesday, November 9 — Yaonan Jin, Columbia University</title>
  <guid>http://tcsplus.wordpress.com/?p=646</guid>
  <link>https://tcsplus.wordpress.com/2022/11/02/tcs-talk-wednesday-november-9-yaonan-jin-columbia-university/</link>
  <description>
    &lt;p&gt;The next TCS+ talk will take place this coming Wednesday, November 9th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). &lt;strong&gt;Yaonan Jin&lt;/strong&gt; from Columbia University will speak about &amp;#8220;&lt;em&gt;First Price Auction is 1-1/e² Efficient&lt;/em&gt;&amp;#8221; (abstract below).&lt;/p&gt;
&lt;p&gt;You can reserve a spot as an individual or a group to join us live by signing up on &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/next-tcs-talk&quot;&gt;the online form&lt;/a&gt;. Registration is &lt;em&gt;not&lt;/em&gt; required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/past-talks&quot;&gt;on our website&lt;/a&gt; afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to &lt;a href=&quot;https://sites.google.com/view/tcsplus/welcome/suggest-a-talk&quot;&gt;suggest&lt;/a&gt; a possible topic or speaker, please see &lt;a href=&quot;https://sites.google.com/view/tcsplus/&quot;&gt;the website&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class=&quot;wp-block-quote&quot;&gt;&lt;p&gt;Abstract: We prove that, for the first-price auction, the tight Price of Anarchy (PoA) and the tight Price of Stability (PoS) are both &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1-1%2Fe%5E2+%5Capprox+0.8647&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1-1%2Fe%5E2+%5Capprox+0.8647&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1-1%2Fe%5E2+%5Capprox+0.8647&amp;#038;bg=fff&amp;#038;fg=444444&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1-1/e^2 &amp;#92;approx 0.8647&quot; class=&quot;latex&quot; /&gt;, closing the gap between the best known bounds [0.7430, 0.8689].&lt;/p&gt;
&lt;p&gt;Based on joint works with Pinyan Lu.&lt;br /&gt;
&lt;a href=&quot;https://arxiv.org/abs/2207.01761&quot;&gt;https://arxiv.org/abs/2207.01761&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://arxiv.org/abs/2207.04455&quot;&gt;https://arxiv.org/abs/2207.04455&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class=&quot;authors&quot;&gt;By plustcs&lt;/p&gt;
  </description>
  <pubDate>2022-11-02 15:47:26 UTC</pubDate>
  <author>TCS+ Seminar Series</author>
</item>

<item>
  <title>Composable Coresets for Constrained Determinant Maximization and Beyond</title>
  <guid>http://arxiv.org/abs/2211.00289</guid>
  <link>http://arxiv.org/abs/2211.00289</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahabadi_S/0/1/0/all/0/1&quot;&gt;Sepideh Mahabadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vuong_T/0/1/0/all/0/1&quot;&gt;Thuy-Duong Vuong&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the task of determinant maximization under partition constraint, in
the context of large data sets. Given a point set $V\subset \mathbb{R}^d$ that
is partitioned into $s$ groups $V_1,..., V_s$, and integers $k_1,...,k_s$ where
$k=\sum_i k_i$, the goal is to pick $k_i$ points from group $i$ such that the
overall determinant of the picked $k$ points is maximized. Determinant
Maximization and its constrained variants have gained a lot of interest for
modeling diversityand have found applications in the context of fairness and
data summarization.
&lt;/p&gt;
&lt;p&gt;We study the design of composable coresets for the constrained determinant
maximization problem. Composable coresets are small subsets of the data that
(approximately) preserve optimal solutions to optimization tasks and enable
efficient solutions in several other large data models including the
distributed and the streaming settings. In this work, we consider two regimes.
For the case of $k&amp;gt;d$, we show a peeling algorithm that gives us a composable
coreset of size $kd$ with an approximation factor of $d^{O(d)}$. We complement
our results by showing that this approximation factor is tight. For the case of
$k\leq d$, we show that a simple modification of the previous algorithms
results in an optimal coreset verified by our lower bounds. Our results apply
to all strongly Rayleigh distribution and several other experimental design
problems. In addition, we show coreset construction algorithms under the more
general laminar matroid constraints.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-02 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A GPU-friendly, Parallel, and (Almost-)In-Place Algorithm for Building Left-Balanced kd-Trees</title>
  <guid>http://arxiv.org/abs/2211.00120</guid>
  <link>http://arxiv.org/abs/2211.00120</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wald_I/0/1/0/all/0/1&quot;&gt;Ingo Wald&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present an algorithm that allows for building left-balanced and complete
k-d trees over k-dimensional points in a trivially parallel and GPU friendly
way. Our algorithm requires exactly one int per data point as temporary
storage, and uses O(logN ) iterations, each of which performs one parallel
sort, and one trivially parallel CUDA per-node update kernel.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-02 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Computational Power of A Single Oblivious Mobile Agent in Two-Edge-Connected Graphs</title>
  <guid>http://arxiv.org/abs/2211.00332</guid>
  <link>http://arxiv.org/abs/2211.00332</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inoue_T/0/1/0/all/0/1&quot;&gt;Taichi Inoue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kitamura_N/0/1/0/all/0/1&quot;&gt;Naoki Kitamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Izumi_T/0/1/0/all/0/1&quot;&gt;Taisuke Izumi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masuzawa_T/0/1/0/all/0/1&quot;&gt;Toshimitsu Masuzawa&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We investigate the computational power of a single mobile agent in an
$n$-node graph with storage (i.e., node memory). It has been shown that the
system with one-bit agent memory and $O(1)$-bit storage is as powerful as the
one with $O(n)$-bit agent memory and $O(1)$-bit storage, and thus we focus on
the difference between one-bit memory agents and oblivious (i.e. zero-bit
memory) agents. While it has been also shown that their computational powers
are not equivalent, all the known results exhibiting such a difference rely on
the fact that oblivious agents cannot transfer any information from one side to
the other side across the bridge edge. Then our main question is stated as
follows: Are the computational powers of one-bit memory agents and oblivious
agents equivalent in 2-edge-connected graphs or not? The main contribution of
this paper is to answer this question positively under the relaxed assumption
that each node has $O(\log\Delta)$-bit storage ($\Delta$ is the maximum degree
of the graph). We present an algorithm of simulating any algorithm for a single
one-bit memory agent by one oblivious agent with $O(n^2)$-time overhead per
round. Our result implies that the topological structure of graphs
differentiating the computational powers of oblivious and non-oblivious agents
is completely characterized by the existence of bridge edges.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-02 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Near-Linear Kernel for Two-Parsimony Distance</title>
  <guid>http://arxiv.org/abs/2211.00378</guid>
  <link>http://arxiv.org/abs/2211.00378</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deen_E/0/1/0/all/0/1&quot;&gt;Elise Deen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iersel_L/0/1/0/all/0/1&quot;&gt;Leo van Iersel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janssen_R/0/1/0/all/0/1&quot;&gt;Remie Janssen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1&quot;&gt;Mark Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murakami_Y/0/1/0/all/0/1&quot;&gt;Yuki Murakami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeh_N/0/1/0/all/0/1&quot;&gt;Norbert Zeh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The maximum parsimony distance $d_{\textrm{MP}}(T_1,T_2)$ and the
bounded-state maximum parsimony distance $d_{\textrm{MP}}^t(T_1,T_2)$ measure
the difference between two phylogenetic trees $T_1,T_2$ in terms of the maximum
difference between their parsimony scores for any character (with $t$ a bound
on the number of states in the character, in the case of
$d_{\textrm{MP}}^t(T_1,T_2)$). While computing $d_{\textrm{MP}}(T_1, T_2)$ was
previously shown to be fixed-parameter tractable with a linear kernel, no such
result was known for $d_{\textrm{MP}}^t(T_1,T_2)$. In this paper, we prove that
computing $d_{\textrm{MP}}^t(T_1, T_2)$ is fixed-parameter tractable for
all~$t$. Specifically, we prove that this problem has a kernel of size $O(k \lg
k)$, where $k = d_{\textrm{MP}}^t(T_1, T_2)$. As the primary analysis tool, we
introduce the concept of leg-disjoint incompatible quartets, which may be of
independent interest.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-02 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On the zeroes of hypergraph independence polynomials</title>
  <guid>http://arxiv.org/abs/2211.00464</guid>
  <link>http://arxiv.org/abs/2211.00464</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Galvin_D/0/1/0/all/0/1&quot;&gt;David Galvin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+McKinley_G/0/1/0/all/0/1&quot;&gt;Gwen McKinley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Perkins_W/0/1/0/all/0/1&quot;&gt;Will Perkins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sarantis_M/0/1/0/all/0/1&quot;&gt;Michail Sarantis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tetali_P/0/1/0/all/0/1&quot;&gt;Prasad Tetali&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the locations of complex zeroes of independence polynomials of
bounded degree hypergraphs. For graphs, this is a long-studied subject with
applications to statistical physics, algorithms, and combinatorics. Results on
zero-free regions for bounded-degree graphs include Shearer&#39;s result on the
optimal zero-free disk, along with several recent results on other zero-free
regions. Much less is known for hypergraphs. We make some steps towards an
understanding of zero-free regions for bounded-degree hypergaphs by proving
that all hypergraphs of maximum degree $\Delta$ have a zero-free disk almost as
large as the optimal disk for graphs of maximum degree $\Delta$ established by
Shearer (of radius $\sim 1/(e \Delta)$). Up to logarithmic factors in $\Delta$
this is optimal, even for hypergraphs with all edge-sizes strictly greater than
$2$. We conjecture that for $k\ge 3$, $k$-uniform linear hypergraphs have a
much larger zero-free disk of radius $\Omega(\Delta^{- \frac{1}{k-1}} )$. We
establish this in the case of linear hypertrees.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-02 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Postdocs at Harvard at Harvard University (apply by November 21, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/01/postdocs-at-harvard-at-harvard-university-apply-by-november-21-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/01/postdocs-at-harvard-at-harvard-university-apply-by-november-21-2022/</link>
  <description>
    &lt;p&gt;Multiple postdoc positions at Harvard University in theoretical CS, machine learning foundations, quantum computing, CS and society and more&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://windowsontheory.org/2022/11/01/postdocs-at-harvard/&quot;&gt;https://windowsontheory.org/2022/11/01/postdocs-at-harvard/&lt;/a&gt;&lt;br /&gt;
Email: achoat@seas.harvard.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-01 17:19:24 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Postdocs at Harvard!</title>
  <guid>http://windowsontheory.org/?p=8462</guid>
  <link>https://windowsontheory.org/2022/11/01/postdocs-at-harvard/</link>
  <description>
    &lt;p&gt;The &lt;a href=&quot;https://mlfoundations.org/#opportunities&quot;&gt;ML Foundations &lt;/a&gt;and &lt;a href=&quot;https://toc.seas.harvard.edu/positions&quot;&gt;theory&lt;/a&gt; groups at Harvard are looking for postdocs for the coming academic year. &lt;/p&gt;



&lt;p&gt;There are also several other positions at Harvard, including at the &lt;a href=&quot;https://datascience.harvard.edu/data-science-postdoctoral-fellows&quot;&gt;Harvard Data Science Initiative (HDSI)&lt;/a&gt;, &lt;a href=&quot;https://cmsa.fas.harvard.edu/about-us/jobs/&quot;&gt; Center of Mathematical Sciences and Applications (CMSA),&lt;/a&gt; &lt;a href=&quot;https://cbs.fas.harvard.edu/research/theory/#swartz&quot;&gt;Swartz fellows&lt;/a&gt; at the Center for Brain Sciences,  the &lt;a href=&quot;https://academicpositions.harvard.edu/postings/11637&quot;&gt;George Carrier fellowship in applied mathematics,&lt;/a&gt;  the &lt;a href=&quot;https://crcs.seas.harvard.edu/apply&quot;&gt;Center for Research on Computation and Society (CRCS)&lt;/a&gt;,   &lt;a href=&quot;https://quantum.harvard.edu/external-candidates&quot;&gt;Harvard Quantum Initiative (HQI)&lt;/a&gt;. I hope that the newly announced &lt;a href=&quot;https://www.harvard.edu/kempner-institute/&quot;&gt;Kempner Institute&lt;/a&gt; will also be able to offer positions for the next academic year. &lt;/p&gt;



&lt;p&gt;All these positions have different foci, conditions, and the searches are run by different institutions, even if the set of potential mentors might be overlapping. Hence I strongly recommend that people apply to all positions that they are interested in. (&lt;/p&gt;



&lt;p&gt;These positions and others are posted on the &lt;a href=&quot;https://mlfoundations.org/#opportunities&quot;&gt;opportunities&lt;/a&gt; section of the ML foundations home page ( &lt;a href=&quot;https://mlfoundations.org/#opportunities&quot; rel=&quot;nofollow&quot;&gt;https://mlfoundations.org/#opportunities&lt;/a&gt; ). When I hear of new opportunities, I may update there and/or on &lt;a href=&quot;https://twitter.com/boazbaraktcs&quot;&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Boaz Barak&lt;/p&gt;
  </description>
  <pubDate>2022-11-01 17:16:59 UTC</pubDate>
  <author>Windows on Theory</author>
</item>

<item>
  <title>Postdoc at Harvard University (apply by December 1, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/01/postdoc-at-harvard-university-apply-by-december-1-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/01/postdoc-at-harvard-university-apply-by-december-1-2022/</link>
  <description>
    &lt;p&gt;The Harvard CS Theory Group invites applications for a variety of postdoctoral fellowships, including the Michael Rabin Postdoctoral Fellowship, postdocs in the Privacy Tools Project, Fairness in Prediction Algorithms, and Foundations in Machine Learning, and postdocs with individual faculty members.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://academicpositions.harvard.edu/postings/11762&quot;&gt;https://academicpositions.harvard.edu/postings/11762&lt;/a&gt;&lt;br /&gt;
Email: achoat@seas.harvard.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-01 16:20:19 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

</channel>
</rss>
