<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>Shorties!</title>
  <guid>https://scottaaronson.blog/?p=6736</guid>
  <link>https://scottaaronson.blog/?p=6736</link>
  <description>
    &lt;p&gt;(1) Since I didn&amp;#8217;t blog about this before: huge congratulations to David Deutsch, Charles Bennett, Gilles Brassard, and my former MIT colleague Peter Shor, and separately to Dan Spielman, for their well-deserved &lt;a href=&quot;https://breakthroughprize.org/News/73&quot;&gt;Breakthrough Prizes&lt;/a&gt;! Their contributions are all so epochal, so universally known to all of us in quantum information and theoretical computer science, that there&amp;#8217;s little I can write to gild the lily, except to say how much I&amp;#8217;ve learned by interacting with all five of them personally. I did enjoy &lt;a href=&quot;https://mobile.twitter.com/plinytheelder_t/status/1573080349512732672&quot;&gt;this comment&lt;/a&gt; on the Breakthrough Prizes by someone on Twitter: “As long as that loudmouth Scott Aaronson keeps getting ignored, I&amp;#8217;ll be happy.”&lt;/p&gt;



&lt;p&gt;(2) My former UT colleague Ila Fiete brought to my attention an &lt;a href=&quot;https://ostp-letter.github.io/&quot;&gt;important scientists&amp;#8217; petition to the White House&lt;/a&gt;.  The context is that the Biden administration has announced &lt;a href=&quot;https://www.whitehouse.gov/ostp/news-updates/2022/08/25/ostp-issues-guidance-to-make-federally-funded-research-freely-available-without-delay/&quot;&gt;new rules&lt;/a&gt; requiring federally-funded research papers to be freely available to the public without delay.  This is &lt;em&gt;extremely&lt;/em&gt; welcome&amp;#8212;in fact, I&amp;#8217;ve &lt;a href=&quot;https://www.scottaaronson.com/writings/journal.html&quot;&gt;advocated&lt;/a&gt; such a step since I first became aware of the scourge of predatory journals around 2004.  But the looming danger is that publishers will just respond by leaning more heavily on the &amp;#8220;author pays&amp;#8221; model&amp;#8212;i.e., hitting up authors or their institutions for thousands of dollars in page fees&amp;#8212;and we&amp;#8217;ll go from only the credentialed few being able to read papers that aren&amp;#8217;t on preprint archives or the like, to only the credentialed few being able to publish them.  The petition urges the White House to build, or fund the research community to build, an infrastructure that will make scientific publishing truly open to everyone.  I&amp;#8217;ve signed it, and I hope you&amp;#8217;ll consider signing too.&lt;/p&gt;



&lt;p&gt;(3) Bill Gasarch asked me to announce that he, my former MIT colleague Erik Demaine, and Mohammad Hajiaghayi have written a brand-new book entitled &lt;em&gt;Computational Intractability: A Guide to Algorithmic Lower Bounds&lt;/em&gt;, and a &lt;a href=&quot;https://hardness.mit.edu/&quot;&gt;free draft is available online&lt;/a&gt;.  It looks excellent, like a &lt;a href=&quot;https://en.wikipedia.org/wiki/Computers_and_Intractability&quot;&gt;Garey &amp;amp; Johnson&lt;/a&gt; for the 21st century.  Bill and his coauthors are looking for feedback.  I was happy to help them by advertising this&amp;#8212;after all, it&amp;#8217;s not as if Bill&amp;#8217;s got his own complexity blog for such things!&lt;/p&gt;



&lt;p&gt;(4) Back when Google was still a novelty—maybe 2000 or so—I had my best friend, the now-famous computer security researcher Alex Halderman, over for Rosh Hashanah dinner with my family. Alex and I were talking about how Google evaded the limitations of all the previous decades’ worth of information retrieval systems. One of my relatives, however, misheard “Google” as &lt;a href=&quot;https://www.foodnetwork.com/recipes/dave-lieberman/noodle-kugel-recipe-1946564&quot;&gt;“kugel”&lt;/a&gt; (basically a dense block of noodles held together with egg), and so ended up passing the latter to Alex. “What is this?” Alex asked. Whereupon my uncle deadpanned, “it’s a noodle retrieval system.” Since then, every single Rosh Hashanah dinner, I think about querying the kugel to retrieve the noodles within, and how the desired search result is just the trivial “all of them.”&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 18:32:09 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>Linkage</title>
  <guid>https://11011110.github.io/blog/2022/09/30/linkage</guid>
  <link>https://11011110.github.io/blog/2022/09/30/linkage.html</link>
  <description>
    &lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://cohost.org/0xabad1dea/post/112175-the-exciting-new-wor&quot;&gt;The exciting new world of AI prompt injection&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109010772219100161&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://lobste.rs/s/v9skyo/exciting_new_world_ai_prompt_injection&quot;&gt;via&lt;/a&gt;). Promote your business by running a bot that uses other people’s social media post text to prompt a text-writing AI that generates customized responses to those posts. What could go wrong?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://community.wolfram.com/groups/-/m/t/2617634&quot;&gt;Ed Pegg constructs and visualizes Engel’s 38-sided space-filling polyhedron&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109018050225431095&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; the most possible for a Voronoi cell of an isohedral Voronoi tessellation, surrounded by 38 copies of itself.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mastodon.social/@curved_ruler/109015404349191976&quot;&gt;Cyclography&lt;/a&gt;, an old form of data visualization in which 3d points are visualized as 2d circles, with the third coordinate used as their radius. Sort of an inverse to the lifting transformation in computational geometry, which turns 2d circles into 3d points in order to use point-based algorithms on them.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://terrytao.wordpress.com/2022/09/19/a-counterexample-to-the-periodic-tiling-conjecture/&quot;&gt;Terry Tao on his new preprint with Rachel Greenfeld&lt;/a&gt;, “&lt;a href=&quot;https://arxiv.org/abs/2209.08451&quot;&gt;A counterexample to the periodic tiling conjecture&lt;/a&gt;” &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109029559029937263&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; The &lt;a href=&quot;https://en.wikipedia.org/wiki/Gyrobifastigium&quot;&gt;Schmitt-Conway-Danzer biprism&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Socolar%E2%80%93Taylor_tile&quot;&gt;Socolar–Taylor tile&lt;/a&gt; tile \(\mathbb{R}^3\) and \(\mathbb{R}^2\times{}\)finite only aperiodically. The &lt;a href=&quot;https://en.wikipedia.org/wiki/Einstein_problem&quot;&gt;einstein problem&lt;/a&gt; asks if \(\mathbb{R}^2\) has an aperiodic tile. This work looks at analogous questions for tiling by translation of \(\mathbb{Z}^2\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://doi.org/10.1090/noti2539&quot;&gt;Descriptive combinatorics and distributed algorithms&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109037227806099068&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Nice survey article by Anton Bernshteyn in &lt;em&gt;Notices of the AMS&lt;/em&gt; about implications and in some cases equivalences between topological statements about whether certain infinite sets are Borel or measurable, and whether certain corresponding finite computational problems have distributed algorithms with sub-logarithmic round complexity.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.libraryassociation.ie/irish-librarians-condemn-publisher-wileys-removal-of-hundreds-of-titles-from-ebook-collections/&quot;&gt;Irish librarians protest&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109037822255336737&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://news.ycombinator.com/item?id=32926378&quot;&gt;via&lt;/a&gt;) as Wiley suddenly removes over 1300 ebooks from the existing subscription packages of academic libraries, in order to convert them to a fee-per-student individual-textbook subscription model. &lt;a href=&quot;https://www.insidehighered.com/news/2022/09/28/publisher-blocks-access-ebooks-students-faculty-scramble&quot;&gt;Now also affecting US universities&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Do you need another demonstration that the physics of liquids is strange and counterintuitive &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109054291006791921&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;)?&lt;/span&gt; I learned from &lt;a href=&quot;https://www.youtube.com/watch?v=Vrl23FOgUck]&quot;&gt;this “What’s eating Dan?” video&lt;/a&gt; that, if you have the kind of peanut butter that needs mixing, but is too liquid (swimming in extra peanut oil), you can make it thicker by mixing in a little bit of water. The water droplets in the oil make an emulsion that is thicker than either the water or oil would be by themselves. I had occasion to try it recently and it worked! Science strikes again.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mathstodon.xyz/@ngons/109037311387589665&quot;&gt;Two swirly rhombus tilings of 4-subdivided 20-gons&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.quantamagazine.org/the-new-math-of-wrinkling-patterns-20220922/&quot;&gt;The new math of wrinkling&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109063241525281205&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; &lt;em&gt;Quanta&lt;/em&gt; on the research of Ian Tobasco on the way that crumpling thin surfaces (like paper) can sometimes lead to disordered folds and sometimes lead to regular patterns, like &lt;a href=&quot;https://en.wikipedia.org/wiki/Yoshimura_buckling&quot;&gt;Yoshimura buckling&lt;/a&gt;, depending in part on local curvature. Based on two papers by Tobasco, “&lt;a href=&quot;https://doi.org/10.1007/s00205-020-01566-8&quot;&gt;Curvature-driven wrinkling of thin elastic shells&lt;/a&gt;” (2021, &lt;a href=&quot;https://arxiv.org/abs/1906.02153&quot;&gt;arXiv:1906.02153&lt;/a&gt;) and “&lt;a href=&quot;https://doi.org/10.1038/s41567-022-01672-2&quot;&gt;Exact solutions for the wrinkle patterns of confined elastic shells&lt;/a&gt;” (2022, &lt;a href=&quot;https://arxiv.org/abs/2004.02839&quot;&gt;arXiv:2004.02839&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.wonkette.com/girls-who-code-books-banned&quot;&gt;&lt;em&gt;Girls Who Code&lt;/em&gt; appears on this year’s list of books banned by US schools&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109067124900840971&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; Apparently this happened not directly because the kind of people who ban books want women to be ignorant, but rather because these books appeared on a diversity resource list and the kind of people who ban books oppose diversity (meaning anything that would challenge the white cis male evangelical-Christian point of view) in all forms. Fortunately local protests got the ban rescinded. More &lt;a href=&quot;https://boingboing.net/2022/09/26/girls-who-code-book-series-banned-by-a-pennsylvania-school-district.html&quot;&gt;on BoingBoing&lt;/a&gt; and &lt;a href=&quot;https://www.theguardian.com/us-news/2022/sep/26/pennsylvania-book-ban-girls-who-code&quot;&gt;in &lt;em&gt;The Guardian&lt;/em&gt;&lt;/a&gt;. The statement in &lt;em&gt;The Guardian&lt;/em&gt; from a book-banning spokesperson “This book series has not been banned, and they remain available in our libraries” appears to actually mean that the ban blocked students from reading the books but failed to remove them permanently from the libraries, and that they became available because the ban was rescinded.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Mutilated_chessboard_problem&quot;&gt;Mutilated chessboard problem&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109074266481611822&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;):&lt;/span&gt; remove opposite corners from a chessboard and try to cover the rest with dominos. It’s just planar bipartite perfect matching, easy for algorithms. There’s a cute trick for human problem solving that I won’t spoil. And yet, a logical formulation has been a test case for automated reasoning for nearly 60 years, and is provably hard for some systems (especially resolution). How can it be so easy and so hard? New Wikipedia Good Article.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://jamesheathers.medium.com/publication-laundering-95c4888afd21&quot;&gt;Publication laundering&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109080279085285756&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://retractionwatch.com/2022/09/28/can-you-explain-what-these-1500-papers-are-doing-in-this-journal/&quot;&gt;via&lt;/a&gt;): James Heathers on how “proceedings journals” that accept whole special-issues without any internal oversight over relevance or quality ease the collaboration among academics desperate for publications, middlemen who sell authorship slots on mass-produced junk, and big publishers hungry for that publication-fee and subscription-fee cash as long as they can point the blame elsewhere.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mathstodon.xyz/@jsiehler/109082598903294416&quot;&gt;Foxagon: A hexagon with exactly one line of reflective symmetry and one reflex angle&lt;/a&gt;. Or maybe more specifically it’s what you get when you glue equilateral triangles onto two adjacent sides of a square. The more specific version tiles the plane; the tiling below hides a &lt;a href=&quot;https://en.wikipedia.org/wiki/Snub_square_tiling&quot;&gt;snub square tiling&lt;/a&gt; but other tilings are possible.&lt;/p&gt;

    &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;/blog/assets/2022/foxagons.svg&quot; alt=&quot;Tiling by foxagons&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://twitter.com/robinhouston/status/1556407331344244743&quot;&gt;The strange Wiki-history of Sethahedra and Chestahedra&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/109090046984135256&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://aperiodical.com/2022/09/carnival-of-maths-208/&quot;&gt;via&lt;/a&gt;, &lt;a href=&quot;https://alephjamesa.co.uk/posts.php?data=FoMSept22&quot;&gt;via2&lt;/a&gt;). The Chestahedron is a polyhedron whose faces are four equilateral triangles and three kites of the same area as the triangles. &lt;a href=&quot;http://frankchester.com/project/chestahedron/&quot;&gt;Frank Chester makes bronze sculptures of it&lt;/a&gt;. The Sethahedron is a nonexistent variation with golden-ratio dimensions. If made of paper it will fold along kite diagonals to form ten faces. The promoter of the Sethahedron has been edit-warring to keep their erroneous version in Wikipedia.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 18:28:00 UTC</pubDate>
  <author>David Eppstein</author>
</item>

<item>
  <title>Low-Stabilizer-Complexity Quantum States Are Not Pseudorandom</title>
  <guid>http://arxiv.org/abs/2209.14530</guid>
  <link>http://arxiv.org/abs/2209.14530</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Grewal_S/0/1/0/all/0/1&quot;&gt;Sabee Grewal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Iyer_V/0/1/0/all/0/1&quot;&gt;Vishnu Iyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kretschmer_W/0/1/0/all/0/1&quot;&gt;William Kretschmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liang_D/0/1/0/all/0/1&quot;&gt;Daniel Liang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show that quantum states with &quot;low stabilizer complexity&quot; can be
efficiently distinguished from Haar-random. Specifically, given an $n$-qubit
pure state $|\psi\rangle$, we give an efficient algorithm that distinguishes
whether $|\psi\rangle$ is (i) Haar-random or (ii) a state with stabilizer
fidelity at least $\frac{1}{k}$ (i.e., has fidelity at least $\frac{1}{k}$ with
some stabilizer state), promised that one of these is the case. With black-box
access to $|\psi\rangle$, our algorithm uses $O\!\left( k^{12}
\log(1/\delta)\right)$ copies of $|\psi\rangle$ and $O\!\left(n k^{12}
\log(1/\delta)\right)$ time to succeed with probability at least $1-\delta$,
and, with access to a state preparation unitary for $|\psi\rangle$ (and its
inverse), $O\!\left( k^{3} \log(1/\delta)\right)$ queries and $O\!\left(n k^{3}
\log(1/\delta)\right)$ time suffice.
&lt;/p&gt;
&lt;p&gt;As a corollary, we prove that $\omega(\log(n))$ $T$-gates are necessary for
any Clifford+$T$ circuit to prepare computationally pseudorandom quantum
states, a first-of-its-kind lower bound.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Quantum invariants for the graph isomorphism problem</title>
  <guid>http://arxiv.org/abs/2209.14914</guid>
  <link>http://arxiv.org/abs/2209.14914</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cruz_H/0/1/0/all/0/1&quot;&gt;Hern&amp;#xe1;n I. de la Cruz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pelayo_F/0/1/0/all/0/1&quot;&gt;Fernando L. Pelayo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pascual_V/0/1/0/all/0/1&quot;&gt;Vicente Pascual&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paulet_J/0/1/0/all/0/1&quot;&gt;Jose J. Paulet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cuartero_F/0/1/0/all/0/1&quot;&gt;Fernando Cuartero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Llana_L/0/1/0/all/0/1&quot;&gt;Luis Llana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mezzini_M/0/1/0/all/0/1&quot;&gt;Mauro Mezzini&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Graph Isomorphism is such an important problem in computer science, that it
has been widely studied over the last decades. It is well known that it belongs
to NP class, but is not NP-complete. It is thought to be of comparable
difficulty to integer factorisation. The best known proved algorithm to solve
this problem in general, was proposed by L\&#39;aszl\&#39;o Babai and Eugene Luks in
1983.
&lt;/p&gt;
&lt;p&gt;Recently, there has been some research in the topic by using quantum
computing, that also leads the present piece of research. In fact, we present a
quantum computing algorithm that defines an invariant over Graph Isomorphism
characterisation. This quantum algorithm is able to distinguish more
non-isomorphic graphs than most of the known invariants so far. The proof of
correctness and some hints illustrating the extent and reason of the
improvement are also included in this paper.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Batch Normalization Explained</title>
  <guid>http://arxiv.org/abs/2209.14778</guid>
  <link>http://arxiv.org/abs/2209.14778</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1&quot;&gt;Randall Balestriero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1&quot;&gt;Richard G. Baraniuk&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A critically important, ubiquitous, and yet poorly understood ingredient in
modern deep networks (DNs) is batch normalization (BN), which centers and
normalizes the feature maps. To date, only limited progress has been made
understanding why BN boosts DN learning and inference performance; work has
focused exclusively on showing that BN smooths a DN&#39;s loss landscape. In this
paper, we study BN theoretically from the perspective of function
approximation; we exploit the fact that most of today&#39;s state-of-the-art DNs
are continuous piecewise affine (CPA) splines that fit a predictor to the
training data via affine mappings defined over a partition of the input space
(the so-called &quot;linear regions&quot;). {\em We demonstrate that BN is an
unsupervised learning technique that -- independent of the DN&#39;s weights or
gradient-based learning -- adapts the geometry of a DN&#39;s spline partition to
match the data.} BN provides a &quot;smart initialization&quot; that boosts the
performance of DN learning, because it adapts even a DN initialized with random
weights to align its spline partition with the data. We also show that the
variation of BN statistics between mini-batches introduces a dropout-like
random perturbation to the partition boundaries and hence the decision boundary
for classification problems. This per mini-batch perturbation reduces
overfitting and improves generalization by increasing the margin between the
training samples and the decision boundary.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Minimum Link Fencing</title>
  <guid>http://arxiv.org/abs/2209.14804</guid>
  <link>http://arxiv.org/abs/2209.14804</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhore_S/0/1/0/all/0/1&quot;&gt;Sujoy Bhore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klute_F/0/1/0/all/0/1&quot;&gt;Fabian Klute&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loffler_M/0/1/0/all/0/1&quot;&gt;Maarten L&amp;#xf6;ffler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nollenburg_M/0/1/0/all/0/1&quot;&gt;Martin N&amp;#xf6;llenburg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Terziadis_S/0/1/0/all/0/1&quot;&gt;Soeren Terziadis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villedieu_A/0/1/0/all/0/1&quot;&gt;Ana&amp;#xef;s Villedieu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study a variant of the geometric multicut problem, where we are given a
set $\mathcal{P}$ of colored and pairwise interior-disjoint polygons in the
plane. The objective is to compute a set of simple closed polygon boundaries
(fences) that separate the polygons in such a way that any two polygons that
are enclosed by the same fence have the same color, and the total number of
links of all fences is minimized. We call this the minimum link fencing (MLF)
problem and consider the natural case of bounded minimum link fencing (BMLF),
where $\mathcal{P}$ contains a polygon $Q$ that is unbounded in all directions
and can be seen as an outer polygon. We show that BMLF is NP-hard in general
and that it is XP-time solvable when each fence contains at most two polygons
and the number of segments per fence is the parameter. Finally, we present an
$O(n \log n)$-time algorithm for the case that the convex hull of $\mathcal{P}
\setminus \{Q\}$ does not intersect $Q$.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Discrete Microlocal Morse Theory</title>
  <guid>http://arxiv.org/abs/2209.14993</guid>
  <link>http://arxiv.org/abs/2209.14993</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Brown_A/0/1/0/all/0/1&quot;&gt;Adam Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Draganov_O/0/1/0/all/0/1&quot;&gt;Ondrej Draganov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We establish several results combining discrete Morse theory and microlocal
sheaf theory in the setting of finite posets and simplicial complexes. Our
primary tool is a computationally tractable description of the bounded derived
category of sheaves on a poset with the Alexandrov topology. We prove that each
bounded complex of sheaves on a finite poset admits a unique (up to isomorphism
of complexes) minimal injective resolution, and we provide algorithms for
computing minimal injective resolutions, as well as several useful functors
between derived categories of sheaves. For the constant sheaf on a simplicial
complex, we give asymptotically tight bounds on the complexity of computing the
minimal injective resolution with this algorithm. Our main result is a novel
definition of the discrete microsupport of a bounded complex of sheaves on a
finite poset. We detail several foundational properties of the discrete
microsupport, as well as a microlocal generalization of the discrete
homological Morse theorem and Morse inequalities.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>The minimal canonical form of a tensor network</title>
  <guid>http://arxiv.org/abs/2209.14358</guid>
  <link>http://arxiv.org/abs/2209.14358</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Acuaviva_A/0/1/0/all/0/1&quot;&gt;Arturo Acuaviva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Makam_V/0/1/0/all/0/1&quot;&gt;Visu Makam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nieuwboer_H/0/1/0/all/0/1&quot;&gt;Harold Nieuwboer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Perez_Garcia_D/0/1/0/all/0/1&quot;&gt;David P&amp;#xe9;rez-Garc&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sittner_F/0/1/0/all/0/1&quot;&gt;Friedrich Sittner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Walter_M/0/1/0/all/0/1&quot;&gt;Michael Walter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Witteveen_F/0/1/0/all/0/1&quot;&gt;Freek Witteveen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Tensor networks have a gauge degree of freedom on the virtual degrees of
freedom that are contracted. A canonical form is a choice of fixing this degree
of freedom. For matrix product states, choosing a canonical form is a powerful
tool, both for theoretical and numerical purposes. On the other hand, for
tensor networks in dimension two or greater there is only limited understanding
of the gauge symmetry. Here we introduce a new canonical form, the minimal
canonical form, which applies to projected entangled pair states (PEPS) in any
dimension, and prove a corresponding fundamental theorem. Already for matrix
product states this gives a new canonical form, while in higher dimensions it
is the first rigorous definition of a canonical form valid for any choice of
tensor. We show that two tensors have the same minimal canonical forms if and
only if they are gauge equivalent up to taking limits; moreover, this is the
case if and only if they give the same quantum state for any geometry. In
particular, this implies that the latter problem is decidable - in contrast to
the well-known undecidability for PEPS on grids. We also provide rigorous
algorithms for computing minimal canonical forms. To achieve this we draw on
geometric invariant theory and recent progress in theoretical computer science
in non-commutative group optimization.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Repeated Prophet Inequality with Near-optimal Bounds</title>
  <guid>http://arxiv.org/abs/2209.14368</guid>
  <link>http://arxiv.org/abs/2209.14368</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chatterjee_K/0/1/0/all/0/1&quot;&gt;Krishnendu Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mohammadi_M/0/1/0/all/0/1&quot;&gt;Mona Mohammadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Saona_R/0/1/0/all/0/1&quot;&gt;Raimundo Saona&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In modern sample-driven Prophet Inequality, an adversary chooses a sequence
of $n$ items with values $v_1, v_2, \ldots, v_n$ to be presented to a decision
maker (DM). The process follows in two phases. In the first phase (sampling
phase), some items, possibly selected at random, are revealed to the DM, but
she can never accept them. In the second phase, the DM is presented with the
other items in a random order and online fashion. For each item, she must make
an irrevocable decision to either accept the item and stop the process or
reject the item forever and proceed to the next item. The goal of the DM is to
maximize the expected value as compared to a Prophet (or offline algorithm)
that has access to all information. In this setting, the sampling phase has no
cost and is not part of the optimization process. However, in many scenarios,
the samples are obtained as part of the decision-making process.
&lt;/p&gt;
&lt;p&gt;We model this aspect as a two-phase Prophet Inequality where an adversary
chooses a sequence of $2n$ items with values $v_1, v_2, \ldots, v_{2n}$ and the
items are randomly ordered. Finally, there are two phases of the Prophet
Inequality problem with the first $n$-items and the rest of the items,
respectively. We show that some basic algorithms achieve a ratio of at most
$0.450$. We present an algorithm that achieves a ratio of at least $0.495$.
Finally, we show that for every algorithm the ratio it can achieve is at most
$0.502$. Hence our algorithm is near-optimal.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Shortest Beer Path Queries in Interval Graphs</title>
  <guid>http://arxiv.org/abs/2209.14401</guid>
  <link>http://arxiv.org/abs/2209.14401</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1&quot;&gt;Rathish Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1&quot;&gt;Meng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kondratovsky_E/0/1/0/all/0/1&quot;&gt;Eitan Kondratovsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munro_J/0/1/0/all/0/1&quot;&gt;J. Ian Munro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naredla_A/0/1/0/all/0/1&quot;&gt;Anurag Murty Naredla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1&quot;&gt;Kaiyu Wu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Our interest is in paths between pairs of vertices that go through at least
one of a subset of the vertices known as beer vertices. Such a path is called a
beer path, and the beer distance between two vertices is the length of the
shortest beer path.
&lt;/p&gt;
&lt;p&gt;We show that we can represent unweighted interval graphs using $2n \log n +
O(n) + O(|B|\log n)$ bits where $|B|$ is the number of beer vertices. This data
structure answers beer distance queries in $O(\log^\varepsilon n)$ time for any
constant $\varepsilon &amp;gt; 0$ and shortest beer path queries in
$O(\log^\varepsilon n + d)$ time, where $d$ is the beer distance between the
two nodes. We also show that proper interval graphs may be represented using
$3n + o(n)$ bits to support beer distance queries in $O(f(n)\log n)$ time for
any $f(n) \in \omega(1)$ and shortest beer path queries in $O(d)$ time. All of
these results also have time-space trade-offs.
&lt;/p&gt;
&lt;p&gt;Lastly we show that the information theoretic lower bound for beer proper
interval graphs is very close to the space of our structure, namely
$\log(4+2\sqrt{3})n - o(n)$ (or about $ 2.9 n$) bits.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Efficient parameterized algorithms on graphs with heterogeneous structure: Combining tree-depth and modular-width</title>
  <guid>http://arxiv.org/abs/2209.14429</guid>
  <link>http://arxiv.org/abs/2209.14429</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kratsch_S/0/1/0/all/0/1&quot;&gt;Stefan Kratsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nelles_F/0/1/0/all/0/1&quot;&gt;Florian Nelles&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Many computational problems admit fast algorithms on special inputs, however,
the required properties might be quite restrictive. E.g., many graph problems
can be solved much faster on interval or cographs, or on graphs of small
modular-width or small tree-width, than on general graphs. One challenge is to
attain the greatest generality of such results, i.e., being applicable to less
restrictive input classes, without losing much in terms of running time.
&lt;/p&gt;
&lt;p&gt;Building on the use of algebraic expressions we present a clean and robust
way of combining such homogeneous structure into more complex heterogeneous
structure, and we show-case this for the combination of modular-width,
tree-depth, and a natural notion of modular tree-depth. We give a generic
framework for designing efficient parameterized algorithms on the created graph
classes, aimed at getting competitive running times that match the homogeneous
cases. To show the applicability we give efficient parameterized algorithms for
Negative Cycle Detection, Vertex-Weighted All-Pairs Shortest Paths, and
Triangle Counting.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On Quantum Speedups for Nonconvex Optimization via Quantum Tunneling Walks</title>
  <guid>http://arxiv.org/abs/2209.14501</guid>
  <link>http://arxiv.org/abs/2209.14501</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yizhou Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Su_W/0/1/0/all/0/1&quot;&gt;Weijie J. Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tongyang Li&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Classical algorithms are often not effective for solving nonconvex
optimization problems where local minima are separated by high barriers. In
this paper, we explore possible quantum speedups for nonconvex optimization by
leveraging the global effect of quantum tunneling. Specifically, we introduce a
quantum algorithm termed the quantum tunneling walk (QTW) and apply it to
nonconvex problems where local minima are approximately global minima. We show
that QTW achieves quantum speedup over classical stochastic gradient descents
(SGD) when the barriers between different local minima are high but thin and
the minima are flat. Based on this observation, we construct a specific
double-well landscape, where classical algorithms cannot efficiently hit one
target well knowing the other well but QTW can when given proper initial states
near the known well. Finally, we corroborate our findings with numerical
experiments.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Matroid Intersection under Restricted Oracles</title>
  <guid>http://arxiv.org/abs/2209.14516</guid>
  <link>http://arxiv.org/abs/2209.14516</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berczi_K/0/1/0/all/0/1&quot;&gt;Krist&amp;#xf3;f B&amp;#xe9;rczi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiraly_T/0/1/0/all/0/1&quot;&gt;Tam&amp;#xe1;s Kir&amp;#xe1;ly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamaguchi_Y/0/1/0/all/0/1&quot;&gt;Yutaro Yamaguchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yokoi_Y/0/1/0/all/0/1&quot;&gt;Yu Yokoi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Matroid intersection is one of the most powerful frameworks of matroid theory
that generalizes various problems in combinatorial optimization. Edmonds&#39;
fundamental theorem provides a min-max characterization for the unweighted
setting, while Frank&#39;s weight-splitting theorem provides one for the weighted
case. Several efficient algorithms were developed for these problems, all
relying on the usage of one of the conventional oracles for both matroids.
&lt;/p&gt;
&lt;p&gt;In the present paper, we consider the tractability of the matroid
intersection problem under restricted oracles. In particular, we focus on the
rank sum, common independence, and maximum rank oracles. We give a strongly
polynomial-time algorithm for weighted matroid intersection under the rank sum
oracle. In the common independence oracle model, we prove that the unweighted
matroid intersection problem is tractable when one of the matroids is a
partition matroid, and that even the weighted case is solvable when one of the
matroids is an elementary split matroid. Finally, we show that the common
independence and maximum rank oracles together are strong enough to realize the
steps of our algorithm under the rank sum oracle.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Tensor-Based Sketching Method for the Low-Rank Approximation of Data Streams</title>
  <guid>http://arxiv.org/abs/2209.14637</guid>
  <link>http://arxiv.org/abs/2209.14637</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Cuiyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1&quot;&gt;Chuanfu Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1&quot;&gt;Mingshuo Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chao Yang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Low-rank approximation in data streams is a fundamental and significant task
in computing science, machine learning and statistics. Multiple streaming
algorithms have emerged over years and most of them are inspired by randomized
algorithms, more specifically, sketching methods. However, many algorithms are
not able to leverage information of data streams and consequently suffer from
low accuracy. Existing data-driven methods improve accuracy but the training
cost is expensive in practice. In this paper, from a subspace perspective, we
propose a tensor-based sketching method for low-rank approximation of data
streams. The proposed algorithm fully exploits the structure of data streams
and obtains quasi-optimal sketching matrices by performing tensor decomposition
on training data. A series of experiments are carried out and show that the
proposed tensor-based method can be more accurate and much faster than the
previous work.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A dichotomy for succinct representations of homomorphisms</title>
  <guid>http://arxiv.org/abs/2209.14662</guid>
  <link>http://arxiv.org/abs/2209.14662</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berkholz_C/0/1/0/all/0/1&quot;&gt;Christoph Berkholz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinall_Smeeth_H/0/1/0/all/0/1&quot;&gt;Harry Vinall-Smeeth&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The task of computing homomorphisms between two finite relational structures
$\mathcal{A}$ and $\mathcal{B}$ is a well-studied question with numerous
applications. Since the set $\operatorname{Hom}(\mathcal{A},\mathcal{B})$ of
all homomorphisms may be very large having a method of representing it in a
succinct way, especially one which enables us to perform efficient enumeration
and counting, could be extremely useful.
&lt;/p&gt;
&lt;p&gt;One simple yet powerful way of doing so is to decompose
$\operatorname{Hom}(\mathcal{A},\mathcal{B})$ using union and Cartesian
product. Such data structures, called d-representations, have been introduced
by Olteanu and Zavodny in the context of database theory. Their results also
imply that if the treewidth of the left-hand side structure $\mathcal{A}$ is
bounded, then a d-representation of polynomial size can be found in polynomial
time. We show that for structures of bounded arity this is optimal: if the
treewidth is unbounded then there are instances where the size of any
d-representation is superpolynomial. Along the way we develop tools for proving
lower bounds on the size of d-representations, in particular we define a notion
of reduction suitable for this context and prove an almost tight lower bound on
the size of d-representations of all $k$-cliques in a graph.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Lattice Linear Algorithms</title>
  <guid>http://arxiv.org/abs/2209.14703</guid>
  <link>http://arxiv.org/abs/2209.14703</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Arya Tanmay Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1&quot;&gt;Sandeep S Kulkarni&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper focuses on analyzing and differentiating between lattice linear
problems and algorithms. It introduces a new class of algorithms called
\textit{(fully) lattice linear algorithms}. A property of these algorithms is
that they induce a partial order among all states and form \textit{multiple
lattices}. An initial state locks in one of these lattices. We present a
lattice linear self-stabilizing algorithm for minimal dominating set.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On Constructing Spanners from Random Gaussian Projections</title>
  <guid>http://arxiv.org/abs/2209.14775</guid>
  <link>http://arxiv.org/abs/2209.14775</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assadi_S/0/1/0/all/0/1&quot;&gt;Sepehr Assadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapralov_M/0/1/0/all/0/1&quot;&gt;Michael Kapralov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Huacheng Yu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Graph sketching is a powerful paradigm for analyzing graph structure via
linear measurements introduced by Ahn, Guha, and McGregor (SODA&#39;12) that has
since found numerous applications in streaming, distributed computing, and
massively parallel algorithms, among others. Graph sketching has proven to be
quite successful for various problems such as connectivity, minimum spanning
trees, edge or vertex connectivity, and cut or spectral sparsifiers. Yet, the
problem of approximating shortest path metric of a graph, and specifically
computing a spanner, is notably missing from the list of successes. This has
turned the status of this fundamental problem into one of the most longstanding
open questions in this area.
&lt;/p&gt;
&lt;p&gt;We present a partial explanation of this lack of success by proving a strong
lower bound for a large family of graph sketching algorithms that encompasses
prior work on spanners and many (but importantly not also all) related
cut-based problems mentioned above. Our lower bound matches the algorithmic
bounds of the recent result of Filtser, Kapralov, and Nouri (SODA&#39;21), up to
lower order terms, for constructing spanners via the same graph sketching
family. This establishes near-optimality of these bounds, at least restricted
to this family of graph sketching techniques, and makes progress on a
conjecture posed in this latter work.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On the Convergence of AdaGrad on $\R^{d}$: Beyond Convexity, Non-Asymptotic Rate and Acceleration</title>
  <guid>http://arxiv.org/abs/2209.14827</guid>
  <link>http://arxiv.org/abs/2209.14827</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zijian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Ta Duy Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ene_A/0/1/0/all/0/1&quot;&gt;Alina Ene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Huy L. Nguyen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Existing analysis of AdaGrad and other adaptive methods for smooth convex
optimization is typically for functions with bounded domain diameter. In
unconstrained problems, previous works guarantee an asymptotic convergence rate
without an explicit constant factor that holds true for the entire function
class. Furthermore, in the stochastic setting, only a modified version of
AdaGrad, different from the one commonly used in practice, in which the latest
gradient is not used to update the stepsize, has been analyzed. Our paper aims
at bridging these gaps and developing a deeper understanding of AdaGrad and its
variants in the standard setting of smooth convex functions as well as the more
general setting of quasar convex functions. First, we demonstrate new
techniques to explicitly bound the convergence rate of the vanilla AdaGrad for
unconstrained problems in both deterministic and stochastic settings. Second,
we propose a variant of AdaGrad for which we can show the convergence of the
last iterate, instead of the average iterate. Finally, we give new accelerated
adaptive algorithms and their convergence guarantee in the deterministic
setting with explicit dependency on the problem parameters, improving upon the
asymptotic rate shown in previous works.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>META-STORM: Generalized Fully-Adaptive Variance Reduced SGD for Unbounded Functions</title>
  <guid>http://arxiv.org/abs/2209.14853</guid>
  <link>http://arxiv.org/abs/2209.14853</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zijian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Ta Duy Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thien Hang Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ene_A/0/1/0/all/0/1&quot;&gt;Alina Ene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Huy L. Nguyen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the application of variance reduction (VR) techniques to general
non-convex stochastic optimization problems. In this setting, the recent work
STORM [Cutkosky-Orabona &#39;19] overcomes the drawback of having to compute
gradients of &quot;mega-batches&quot; that earlier VR methods rely on. There, STORM
utilizes recursive momentum to achieve the VR effect and is then later made
fully adaptive in STORM+ [Levy et al., &#39;21], where full-adaptivity removes the
requirement for obtaining certain problem-specific parameters such as the
smoothness of the objective and bounds on the variance and norm of the
stochastic gradients in order to set the step size. However, STORM+ crucially
relies on the assumption that the function values are bounded, excluding a
large class of useful functions. In this work, we propose META-STORM, a
generalized framework of STORM+ that removes this bounded function values
assumption while still attaining the optimal convergence rate for non-convex
optimization. META-STORM not only maintains full-adaptivity, removing the need
to obtain problem specific parameters, but also improves the convergence rate&#39;s
dependency on the problem parameters. Furthermore, META-STORM can utilize a
large range of parameter settings that subsumes previous methods allowing for
more flexibility in a wider range of settings. Finally, we demonstrate the
effectiveness of META-STORM through experiments across common deep learning
tasks. Our algorithm improves upon the previous work STORM+ and is competitive
with widely used algorithms after the addition of per-coordinate update and
exponential moving average heuristics.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Enumerating Regular Languages in Constant Delay</title>
  <guid>http://arxiv.org/abs/2209.14878</guid>
  <link>http://arxiv.org/abs/2209.14878</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amarilli_A/0/1/0/all/0/1&quot;&gt;Antoine Amarilli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monet_M/0/1/0/all/0/1&quot;&gt;Mika&amp;#xeb;l Monet&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the task, for a given language $L$, of enumerating the (generally
infinite) sequence of its words, without repetitions, while bounding the delay
between two consecutive words. To allow for constant delay bounds, we assume a
model where we produce each word by editing the preceding word with a small
edit script, rather than writing out the word from scratch. In particular, this
witnesses that the language is orderable, i.e., we can write its words as an
infinite sequence such that the Levenshtein edit distance between any two
consecutive words is bounded by a constant. For instance, $(a+b)^*$ is
orderable (with a variant of the Gray code), but $a^* + b^*$ is not.
&lt;/p&gt;
&lt;p&gt;We characterize which regular languages are enumerable in this sense, and
show that this can be decided in PTIME in an input deterministic finite
automaton (DFA) for the language. In fact, we show that, given a DFA $A$
recognizing a language $L$, we can compute in PTIME automata $A_1, \ldots, A_t$
such that $L$ is partitioned as $L(A_1) \sqcup \ldots \sqcup L(A_t)$ and every
$L(A_i)$ is orderable in this sense. Further, we show that this is optimal,
i.e., we cannot partition $L$ into less than $t$ orderable languages.
&lt;/p&gt;
&lt;p&gt;In the case where $L$ is orderable, we show that the ordering can be computed
as a constant-delay algorithm: specifically, the algorithm runs in a suitable
pointer machine model, and produces a sequence of constant-length edit scripts
to visit the words of $L$ without repetitions, with constant delay between each
script. In fact, we show that we can achieve this while only allowing the edit
operations push and pop at the beginning and end of the word, which implies
that the word can in fact be maintained in a double-ended queue.
&lt;/p&gt;
&lt;p&gt;We also show results on the complexity of a related problem, and study the
model where push-pop edits are only allowed at the end of the word.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-30 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Machine Learning and Complexity</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-140442697667456694</guid>
  <link>http://blog.computationalcomplexity.org/2022/09/machine-learning-and-complexity.html</link>
  <description>
    &lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjB-e4HIPenlJclDSenALB6otAw1Nga8deJ3zx3JoMuf41bWFlfy6u4fi-agHPIClWKvkOGcuQRyXbfXXI__l8YpgFjXBY17Y05mdXCMT6bZUbgoILvkQ7D2t4JRNvqFuG-LNaQMRC0HphwBVu3DoVnnHj1ojqbfCXov8yZaRNlj9hoGpqBAQ/s1024/DALL%C2%B7E%202022-09-17%2014.00.36%20-%20Schloss%20Dagstuhl%20in%20the%20style%20of%20monet.png&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1024&quot; data-original-width=&quot;1024&quot; height=&quot;400&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjB-e4HIPenlJclDSenALB6otAw1Nga8deJ3zx3JoMuf41bWFlfy6u4fi-agHPIClWKvkOGcuQRyXbfXXI__l8YpgFjXBY17Y05mdXCMT6bZUbgoILvkQ7D2t4JRNvqFuG-LNaQMRC0HphwBVu3DoVnnHj1ojqbfCXov8yZaRNlj9hoGpqBAQ/w400-h400/DALL%C2%B7E%202022-09-17%2014.00.36%20-%20Schloss%20Dagstuhl%20in%20the%20style%20of%20monet.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Schloss Dagstuhl by Monet by Dall-E&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;At Dagstuhl &lt;a href=&quot;https://blog.computationalcomplexity.org/2022/09/thirty-years-of-dagstuhl.html&quot;&gt;earlier this month&lt;/a&gt;, I hung out for a little bit&amp;nbsp;with the participants of the other seminar,&amp;nbsp;&lt;a href=&quot;https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=22372&quot;&gt;Knowledge Graphs and their Role in the Knowledge Engineering of the 21st Century&lt;/a&gt;. Knowledge graphs are what you would expect them to be, nodes are objects like &quot;Berlin&quot; and &quot;Germany&quot; with directed edges with labels like &quot;capital&quot;. Think of having knowledge graphs of hundreds of millions of nodes and how that could help answer queries about the world. These secondary workshops are shorter and focus on creating a new vision, in this case how to maximize the importance of knowledge graphs in an increasing ML-focused world.&lt;/p&gt;&lt;p&gt;Perhaps we need such a visioning seminar for complexity. While we often get lost in the mathematical questions and techniques in our field, computational complexity is designed to understand the difficulty of solving various problems. Machine learning and advances in optimization should be changing that conversation. If you imagine a world where P = NP (and I did exactly that in chapter 2 of &lt;a href=&quot;https://goldenticket.fortnow.com/&quot;&gt;my 2013 book&lt;/a&gt;) much of what you consider is &lt;a href=&quot;https://blog.computationalcomplexity.org/2020/12/optiland.html&quot;&gt;starting to happen anyway&lt;/a&gt;.&amp;nbsp;ML does fail to break cryptography but then again, isn&#39;t this the best of all possible worlds?&amp;nbsp;&lt;/p&gt;&lt;p&gt;Look at what Scott Aaronson &lt;a href=&quot;https://scottaaronson.blog/?p=122#:~:text=If%20P%3DNP%2C%20then%20the,strategy%20would%20be%20Warren%20Buffett.&quot;&gt;said back in 2006&lt;/a&gt;.&lt;/p&gt;&lt;blockquote&gt;If P=NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in “creative leaps,” no fundamental gap between solving a problem and recognizing the solution once it’s found. Everyone who could appreciate a symphony would be Mozart; everyone who could follow a step-by-step argument would be Gauss; everyone who could recognize a good investment strategy would be Warren Buffett.&amp;nbsp;&lt;/blockquote&gt;&lt;p&gt;If I can be a Monet, can Mozart be far behind? ML trading by some hedge funds are beating Warren Buffett but remember if everyone trades perfectly, no one beats the average. Gauss is going to be trickier but &lt;a href=&quot;https://www.quantamagazine.org/in-new-math-proofs-artificial-intelligence-plays-to-win-20220307/&quot;&gt;it&#39;s coming&lt;/a&gt;. There&#39;s a reason Scott is&amp;nbsp;&lt;a href=&quot;https://scottaaronson.blog/?p=6484&quot;&gt;spending a year at OpenAI&lt;/a&gt;&amp;nbsp;to understand &quot;what, if anything, can computational complexity contribute to a principled understanding of how to get an AI to do what we want and not do what we don’t want&quot;.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 14:35:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>A characterization of polynomial time computable functions from the integers to the reals using discrete ordinary differential equations</title>
  <guid>http://arxiv.org/abs/2209.13599</guid>
  <link>http://arxiv.org/abs/2209.13599</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blanc_M/0/1/0/all/0/1&quot;&gt;Manon Blanc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1&quot;&gt;Olivier Bournez&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a recent article, the class of functions from the integers to the integers
computable in polynomial time has been characterized using discrete ordinary
differential equations (ODE), also known as finite differences. Doing so, we
pointed out the fundamental role of linear (discrete) ODEs and classical ODE
tools such as changes of variables to capture computability and complexity
measures, or as a tool for programming. In this article, we extend the approach
to a characterization of functions from the integers to the reals computable in
polynomial time in the sense of computable analysis. In particular, we provide
a characterization of such functions in terms of the smallest class of
functions that contains some basic functions, and that is closed by
composition, linear length ODEs, and a natural effective limit schema.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>On the Descriptive Complexity of Groups without Abelian Normal Subgroups</title>
  <guid>http://arxiv.org/abs/2209.13725</guid>
  <link>http://arxiv.org/abs/2209.13725</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grochow_J/0/1/0/all/0/1&quot;&gt;Joshua A. Grochow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levet_M/0/1/0/all/0/1&quot;&gt;Michael Levet&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we explore the descriptive complexity theory of finite groups
by examining the power of the second Ehrenfeucht-Fra\&quot;iss\&#39;e bijective pebble
game in Hella&#39;s (Ann. Pure Appl. Log., 1989) heirarchy. This is a
Spoiler-Duplicator game in which Spoiler can place up to two pebbles each
round. While it trivially solves graph isomorphism, it may be nontrivial for
finite groups, and other ternary relational structures. We first provide a
novel generalization of Weisfeiler-Leman (WL) coloring, which we call 2-ary WL.
We then show that the 2-ary WL is equivalent to the second
Ehrenfeucht-Fra\&quot;iss\&#39;e bijective pebble game in Hella&#39;s heirarchy.
&lt;/p&gt;
&lt;p&gt;Our main result is that, in the pebble game characterization, only $O(1)$
pebbles and $O(1)$ rounds are sufficient to identify all groups without Abelian
normal subgroups (a class of groups for which isomorphism testing is known to
be in $\mathsf{P}$; Babai, Codenotti, &amp;amp; Qiao, ICALP 2012). In particular, we
show that within the first few rounds, Spoiler can force Duplicator to select
an isomorphism between two such groups at each subsequent round. By Hella&#39;s
results (\emph{ibid.}), this is equivalent to saying that these groups are
identified by formulas in first-order logic with generalized 2-ary quantifiers,
using only $O(1)$ variables and $O(1)$ quantifier depth.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Dynamic Embeddings of Dynamic Single-Source Upward Planar Graphs</title>
  <guid>http://arxiv.org/abs/2209.14094</guid>
  <link>http://arxiv.org/abs/2209.14094</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoog_I/0/1/0/all/0/1&quot;&gt;Ivor van der Hoog&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parada_I/0/1/0/all/0/1&quot;&gt;Irene Parada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1&quot;&gt;Eva Rotenberg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A directed graph $G$ is upward planar if it admits a planar embedding such
that each edge is $y$-monotone. Unlike planarity testing, upward planarity
testing is NP-hard except in restricted cases, such as when the graph has the
single-source property (i.e. each connected component only has one source).
&lt;/p&gt;
&lt;p&gt;In this paper, we present a dynamic algorithm for maintaining a combinatorial
embedding $\mathcal{E}(G)$ of a single-source upward planar graph subject to
edge deletions, edge contractions, edge insertions upwards across a face, and
single-source-preserving vertex splits through specified corners. We
furthermore support changes to the embedding $\mathcal{E}(G)$ on the form of
subgraph flips that mirror or slide the placement of a subgraph that is
connected to the rest of the graph via at most two vertices.
&lt;/p&gt;
&lt;p&gt;All update operations are supported as long as the graph remains upward
planar, and all queries are supported as long as the graph remains
single-source. Updates that violate upward planarity are identified as such and
rejected by our update algorithm. We dynamically maintain a linear-size data
structure on $G$ which supports incidence queries between a vertex and a face,
and upward-linkability of vertex pairs. If a pair of vertices are not
upwards-linkable, we facilitate one-flip-linkable queries that point to a
subgraph flip that makes them linkable, if any such flip exists.
&lt;/p&gt;
&lt;p&gt;We support all updates and queries in $O(\log^2 n)$ time.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Quantum Optimization Algorithm for Single Machine Total Weighted Tardiness Minimization</title>
  <guid>http://arxiv.org/abs/2209.13712</guid>
  <link>http://arxiv.org/abs/2209.13712</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Youhao Steve Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;Julian Cheng&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A single machine total weighted tardiness minimization (TWTM) problem in
operational planning is considered. The problem is formulated as an NP-hard
constrained combinatorial problem, which has no known deterministic polynomial
complexity solution using classical computing. Based on efficient Grover&#39;s
quantum search and Trugenberger&#39;s quantum optimization algorithms, a novel
efficient quantum optimization algorithm is proposed to solve the NP-hard
single machine TWTM problem, which makes the desired solution satisfying the
searching constraints and showing the minimal TWT value be measured with the
highest probability.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Near-Optimal Adaptive Policies for Serving Stochastically Departing Customers</title>
  <guid>http://arxiv.org/abs/2209.13878</guid>
  <link>http://arxiv.org/abs/2209.13878</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Segev_D/0/1/0/all/0/1&quot;&gt;Danny Segev&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider a multi-stage stochastic optimization problem originally
introduced by Cygan et al. (2013), studying how a single server should
prioritize stochastically departing customers. In this setting, our objective
is to determine an adaptive service policy that maximizes the expected total
reward collected along a discrete planning horizon, in the presence of
customers who are independently departing between one stage and the next with
known stationary probabilities. In spite of its deceiving structural
simplicity, we are unaware of non-trivial results regarding the rigorous design
of optimal or truly near-optimal policies at present time.
&lt;/p&gt;
&lt;p&gt;Our main contribution resides in proposing a quasi-polynomial-time
approximation scheme for adaptively serving impatient customers. Specifically,
letting $n$ be the number of underlying customers, our algorithm identifies in
$O( n^{ O_{ \epsilon }( \log^2 n ) } )$ time an adaptive service policy whose
expected reward is within factor $1 - \epsilon$ of the optimal adaptive reward.
Our method for deriving this approximation scheme synthesizes various
stochastic analyses in order to investigate how the adaptive optimum is
affected by alteration to several instance parameters, including the reward
values, the departure probabilities, and the collection of customers itself.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Worst-case Deterministic Fully-Dynamic Planar 2-vertex Connectivity</title>
  <guid>http://arxiv.org/abs/2209.14079</guid>
  <link>http://arxiv.org/abs/2209.14079</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holm_J/0/1/0/all/0/1&quot;&gt;Jacob Holm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoog_I/0/1/0/all/0/1&quot;&gt;Ivor van der Hoog&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1&quot;&gt;Eva Rotenberg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study dynamic planar graphs with $n$ vertices, subject to edge deletion,
edge contraction, edge insertion across a face, and the splitting of a vertex
in specified corners. We dynamically maintain a combinatorial embedding of such
a planar graph, subject to connectivity and $2$-vertex-connectivity
(biconnectivity) queries between pairs of vertices. Whenever a query pair is
connected and not biconnected, we find the first and last cutvertex separating
them.
&lt;/p&gt;
&lt;p&gt;Additionally, we allow local changes to the embedding by flipping the
embedding of a subgraph that is connected by at most two vertices to the rest
of the graph.
&lt;/p&gt;
&lt;p&gt;We support all queries and updates in deterministic, worst-case, $O(\log^2
n)$ time, using an $O(n)$-sized data structure.
&lt;/p&gt;
&lt;p&gt;Previously, the best bound for fully-dynamic planar biconnectivity (subject
to our set of operations) was an amortised $\tilde{O}(\log^3 n)$ for general
graphs, and algorithms with worst-case polylogarithmic update times were known
only in the partially dynamic (insertion-only or deletion-only) setting.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Adaptive Out-Orientations with Applications</title>
  <guid>http://arxiv.org/abs/2209.14087</guid>
  <link>http://arxiv.org/abs/2209.14087</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christiansen_A/0/1/0/all/0/1&quot;&gt;Aleksander B. G. Christiansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holm_J/0/1/0/all/0/1&quot;&gt;Jacob Holm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoog_I/0/1/0/all/0/1&quot;&gt;Ivor van der Hoog&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1&quot;&gt;Eva Rotenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwiegelshohn_C/0/1/0/all/0/1&quot;&gt;Chris Schwiegelshohn&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give simple algorithms for maintaining edge-orientations of a
fully-dynamic graph, such that the out-degree of each vertex is bounded. On one
hand, we show how to orient the edges such that the out-degree of each vertex
is proportional to the arboricity $\alpha$ of the graph, in a worst-case update
time of $O(\log^2 n \log \alpha)$. On the other hand, motivated by applications
in dynamic maximal matching, we obtain a different trade-off, namely the
improved worst case update time of $O(\log n \log \alpha)$ for the problem of
maintaining an edge-orientation with at most $O(\alpha + \log n)$ out-edges per
vertex. Since our algorithms have update times with worst-case guarantees, the
number of changes to the solution (i.e. the recourse) is naturally limited.
&lt;/p&gt;
&lt;p&gt;Our algorithms make choices based entirely on local information, which makes
them automatically adaptive to the current arboricity of the graph. In other
words, they are arboricity-oblivious, while they are arboricity-sensitive. This
both simplifies and improves upon previous work, by having fewer assumptions or
better asymptotic guarantees.
&lt;/p&gt;
&lt;p&gt;As a consequence, one obtains an algorithm with improved efficiency for
maintaining a $(1+\varepsilon)$ approximation of the maximum subgraph density,
and an algorithm for dynamic maximal matching whose worst-case update time is
guaranteed to be upper bounded by $O(\alpha + \log n\log \alpha)$, where
$\alpha$ is the arboricity at the time of the update.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Time and Energy Efficient Contention Resolution in Asynchronous Shared Channels</title>
  <guid>http://arxiv.org/abs/2209.14140</guid>
  <link>http://arxiv.org/abs/2209.14140</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marco_G/0/1/0/all/0/1&quot;&gt;Gianluca De Marco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kowalski_D/0/1/0/all/0/1&quot;&gt;Dariusz R. Kowalski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stachowiak_G/0/1/0/all/0/1&quot;&gt;Grzegorz Stachowiak&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A number of stations, independently activated over time, is able to
communicate by transmitting and listening to a shared channel in discrete time
slots, and a message is successfully delivered to all stations if and only if
its source station is the only transmitter at a time. Despite a vast amount of
work in the last decades, many fundamental questions remain open in the
realistic situation where stations do not start synchronously but are awaken in
arbitrary times. In this work we present a broad picture of results for the
fundamental problem of Contention resolution, in which each of the contending
stations needs to broadcast successfully its message.
&lt;/p&gt;
&lt;p&gt;We show that adaptive algorithms or algorithms with the knowledge of the
contention size $k$ achieve a linear $O(k)$ message latency even if the channel
feedback is restricted to simple acknowledgements in case of successful
transmissions and in the absence of synchronization. This asymptotically
optimal performance cannot be extended to other settings: we prove that there
is no non-adaptive algorithm without the knowledge of contention size $k$
admitting latency $o(k\log k/(\log\log k)^2)$. This means, in particular, that
coding (even random) with acknowledgements is not very efficient on a shared
channel without synchronization or an estimate of the contention size. We also
present a non-adaptive algorithm with no knowledge of contention size that
almost matches the lower bound on latency.
&lt;/p&gt;
&lt;p&gt;Finally, despite the absence of a collision detection mechanism, we show that
our algorithms are also efficient in terms of energy, understood as the total
number of transmissions performed by the stations during the execution.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Quantum Subroutine Composition</title>
  <guid>http://arxiv.org/abs/2209.14146</guid>
  <link>http://arxiv.org/abs/2209.14146</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jeffery_S/0/1/0/all/0/1&quot;&gt;Stacey Jeffery&lt;/a&gt;&lt;/p&gt;&lt;p&gt;An important tool in algorithm design is the ability to build algorithms from
other algorithms that run as subroutines. In the case of quantum algorithms, a
subroutine may be called on a superposition of different inputs, which
complicates things. For example, a classical algorithm that calls a subroutine
$Q$ times, where the average probability of querying the subroutine on input
$i$ is $p_i$, and the cost of the subroutine on input $i$ is $T_i$, incurs
expected cost $Q\sum_i p_i E[T_i]$ from all subroutine queries. While this
statement is obvious for classical algorithms, for quantum algorithms, it is
much less so, since naively, if we run a quantum subroutine on a superposition
of inputs, we need to wait for all branches of the superposition to terminate
before we can apply the next operation. We nonetheless show an analogous
quantum statement (*): If $q_i$ is the average query weight on $i$ over all
queries, the cost from all quantum subroutine queries is $Q\sum_i q_i E[T_i]$.
Here the query weight on $i$ for a particular query is the probability of
measuring $i$ in the input register if we were to measure right before the
query.
&lt;/p&gt;
&lt;p&gt;We prove this result using the technique of multidimensional quantum walks,
recently introduced in &lt;a href=&quot;/abs/2208.13492&quot;&gt;arXiv:2208.13492&lt;/a&gt;. We present a more general version of
their quantum walk edge composition result, which yields variable-time quantum
walks, generalizing variable-time quantum search, by, for example, replacing
the update cost with $\sqrt{\sum_{u,v}\pi_u P_{u,v} E[T_{u,v}^2]}$, where
$T_{u,v}$ is the cost to move from vertex $u$ to vertex $v$. The same technique
that allows us to compose quantum subroutines in quantum walks can also be used
to compose in any quantum algorithm, which is how we prove (*).
&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On Computing Exact Means of Time Series Using the Move-Split-Merge Metric</title>
  <guid>http://arxiv.org/abs/2209.14197</guid>
  <link>http://arxiv.org/abs/2209.14197</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holznigenkemper_J/0/1/0/all/0/1&quot;&gt;Jana Holznigenkemper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komusiewicz_C/0/1/0/all/0/1&quot;&gt;Christian Komusiewicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seeger_B/0/1/0/all/0/1&quot;&gt;Bernhard Seeger&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Computing an accurate mean of a set of time series is a critical task in
applications like nearest-neighbor classification and clustering of time
series. While there are many distance functions for time series, the most
popular distance function used for the computation of time series means is the
non-metric dynamic time warping (DTW) distance. A recent algorithm for the
exact computation of a DTW-Mean has a running time of
$\mathcal{O}(n^{2k+1}2^kk)$, where $k$ denotes the number of time series and
$n$ their maximum length. In this paper, we study the mean problem for the
move-split-merge (MSM) metric that not only offers high practical accuracy for
time series classification but also carries of the advantages of the metric
properties that enable further diverse applications. The main contribution of
this paper is an exact and efficient algorithm for the MSM-Mean problem of time
series. The running time of our algorithm is $\mathcal{O}(n^{k+3}2^k k^3 )$,
and thus better than the previous DTW-based algorithm. The results of an
experimental comparison confirm the running time superiority of our algorithm
in comparison to the DTW-Mean competitor. Moreover, we introduce a heuristic to
improve the running time significantly without sacrificing much accuracy.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-29 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>PhD and postdoc at IRIF (apply by November 1, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/09/28/phd-and-postdoc-at-irif-apply-by-november-1-2022/</guid>
  <link>https://cstheory-jobs.org/2022/09/28/phd-and-postdoc-at-irif-apply-by-november-1-2022/</link>
  <description>
    &lt;p&gt;The Algorithms &amp;amp; Complexity group at IRIF (CNRS, Université Paris-Cité) in Paris offers multiple PhD and postdoc positions on the theory of quantum computing. The group has expertise in quantum algorithms and quantum complexity theory, with permanent members S. Apers, I. Kerenidis, S. Laplante and F. Magniez.&lt;/p&gt;
&lt;p&gt;Soft deadline: November 1st, 2022.&lt;/p&gt;
&lt;p&gt;Website: irif.fr/en/equipes/algocomp/&lt;br /&gt;
Email: apers@irif.fr&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 10:12:03 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Strategyproofness-Exposing Mechanism Descriptions</title>
  <guid>http://arxiv.org/abs/2209.13148</guid>
  <link>http://arxiv.org/abs/2209.13148</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Gonczarowski_Y/0/1/0/all/0/1&quot;&gt;Yannai A. Gonczarowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Heffetz_O/0/1/0/all/0/1&quot;&gt;Ori Heffetz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Thomas_C/0/1/0/all/0/1&quot;&gt;Clayton Thomas&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A menu description defines a mechanism to player $i$ in two steps. Step (1)
uses the reports of other players to describe $i$&#39;s menu: the set of $i$&#39;s
potential outcomes. Step (2) uses $i$&#39;s report to select $i$&#39;s favorite outcome
from her menu. Can menu descriptions better expose strategyproofness, without
sacrificing simplicity? We propose a new, simple menu description of Deferred
Acceptance. We prove that -- in contrast with other common matching mechanisms
-- this menu description must differ substantially from the corresponding
traditional description. We demonstrate, with a lab experiment on two simple
mechanisms, the promise and challenges of menu descriptions.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Polynomial time computable functions over the reals characterized using discrete ordinary differential equations</title>
  <guid>http://arxiv.org/abs/2209.13404</guid>
  <link>http://arxiv.org/abs/2209.13404</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blanc_M/0/1/0/all/0/1&quot;&gt;Manon Blanc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1&quot;&gt;Olivier Bournez&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The class of functions from the integers to the integers computable in
polynomial time has been characterized recently using discrete ordinary
differential equations (ODE), also known as finite differences. In the
framework of ordinary differential equations, this is very natural to try to
extend the approach to classes of functions over the reals, and not only over
the integers. Recently, an extension of previous characterization was obtained
for functions from the integers to the reals, but the method used in the proof,
based on the existence of a continuous function from the integers to a suitable
discrete set of reals, cannot extend to functions from the reals to the reals,
as such a function cannot exist for clear topological reasons. In this article,
we prove that this is indeed possible to provide an elegant and simple
algebraic characterization of functions from the reals to the reals: we provide
a characterization of such functions as the smallest class of functions that
contains some basic functions, and that is closed by composition, linear length
ODEs, and a natural effective limit schema. This is obtained using an
alternative proof technique based on the construction of specific suitable
functions defined recursively, and a barycentric method. Furthermore, we also
extend previous characterizations in several directions: First, we prove that
there is no need of multiplication. We prove a normal form theorem, with a nice
side effect related to formal neural networks. Indeed, given some fixed error
and some polynomial time t(n), our settings produce effectively some neural
network that computes the function over its domain with the given precision,
for any t(n)-polynomial time computable function f .
&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Improved and Generalized Algorithms for Burning a Planar Point Set</title>
  <guid>http://arxiv.org/abs/2209.13024</guid>
  <link>http://arxiv.org/abs/2209.13024</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokhale_P/0/1/0/all/0/1&quot;&gt;Prashant Gokhale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keil_J/0/1/0/all/0/1&quot;&gt;J. Mark Keil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1&quot;&gt;Debajyoti Mondal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a set $P$ of points in the plane, a point burning process is a discrete
time process to burn all the points of $P$ where fires must be initiated at the
given points. Specifically, the point burning process starts with a single
burnt point from $P$, and at each subsequent step, burns all the points in the
plane that are within one unit distance from the currently burnt points, as
well as one other unburnt point of $P$ (if exists). The point burning number of
$P$ is the smallest number of steps required to burn all the points of $P$. If
we allow the fire to be initiated anywhere, then the burning process is called
an anywhere burning process, and the corresponding burning number is called
anywhere burning number. Computing the point and anywhere burning number is
known to be NP-hard. In this paper we show that both these problems admit PTAS
in one dimension. We then show that in two dimensions, point burning and
anywhere burning are $(1.96296+\varepsilon)$ and $(1.92188+\varepsilon)$
approximable, respectively, for every $\varepsilon&amp;gt;0$, which improves the
previously known $(2+\varepsilon)$ factor for these problems. We also observe
that a known result on set cover problem can be leveraged to obtain a
2-approximation for burning the maximum number of points in a given number of
steps. We show how the results generalize if we allow the points to have
different fire spreading rates. Finally, we prove that even if the burning
sources are given as input, finding a point burning sequence itself is NP-hard.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Optimal Placement of Base Stations in Border Surveillance using Limited Capacity Drones</title>
  <guid>http://arxiv.org/abs/2209.13311</guid>
  <link>http://arxiv.org/abs/2209.13311</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bereg_S/0/1/0/all/0/1&quot;&gt;S. Bereg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1&quot;&gt;J.M. D&amp;#xed;az-B&amp;#xe1;&amp;#xf1;ez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haghpanah_M/0/1/0/all/0/1&quot;&gt;M. Haghpanah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horn_P/0/1/0/all/0/1&quot;&gt;P. Horn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopez_M/0/1/0/all/0/1&quot;&gt;M.A. Lopez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marin_N/0/1/0/all/0/1&quot;&gt;N. Mar&amp;#xed;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramirez_Vigueras_A/0/1/0/all/0/1&quot;&gt;A. Ram&amp;#xed;rez-Vigueras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_F/0/1/0/all/0/1&quot;&gt;F. Rodr&amp;#xed;guez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sole_Pi_O/0/1/0/all/0/1&quot;&gt;O. Sol&amp;#xe9;-Pi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stevens_A/0/1/0/all/0/1&quot;&gt;A. Stevens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1&quot;&gt;J. Urrutia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Imagine an island modeled as a simple polygon $\P$ with $n$ vertices whose
coastline we wish to monitor. We consider the problem of building the minimum
number of refueling stations along the boundary of $\P$ in such a way that a
drone can follow a polygonal route enclosing the island without running out of
fuel. A drone can fly a maximum distance $d$ between consecutive stations and
is restricted to move either along the boundary of $\P$ or its exterior (i.e.,
over water). We present an algorithm that, given $\mathcal P$, finds the
locations for a set of refueling stations whose cardinality is at most the
optimal plus one. The time complexity of this algorithm is $O(n^2 + \frac{L}{d}
n)$, where $L$ is the length of $\mathcal P$. We also present an algorithm that
returns an additive $\epsilon$-approximation for the problem of minimizing the
fuel capacity required for the drones when we are allowed to place $k$ base
stations around the boundary of the island; this algorithm also finds the
locations of these refueling stations. Finally, we propose a practical
discretization heuristic which, under certain conditions, can be used to
certify optimality of the results.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Mathematics and Flamenco: An Unexpected Partnership</title>
  <guid>http://arxiv.org/abs/2209.13538</guid>
  <link>http://arxiv.org/abs/2209.13538</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9;-Miguel D&amp;#xed;az-B&amp;#xe1;&amp;#xf1;ez&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we present a series of mathematical problems which throw
interesting lights on flamenco music. More specifically, these are problems in
discrete and computational mathematics suggested by an analytical (not
compositional) examination of flamenco ``cante&#39;&#39; (singing). As a consequence,
since the problems are taken from a culturally specific context, the examples
can make more effective mathematics education.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>How to Sample From The Limiting Distribution of a Continuous-Time Quantum Walk</title>
  <guid>http://arxiv.org/abs/2209.13028</guid>
  <link>http://arxiv.org/abs/2209.13028</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Doliskani_J/0/1/0/all/0/1&quot;&gt;Javad Doliskani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce $\varepsilon$-projectors, using which we can sample from
limiting distributions of continuous-time quantum walks. The standard algorithm
for sampling from a distribution that is close to the limiting distribution of
a given quantum walk is to run the quantum walk for a time chosen uniformly at
random from a large interval, and measure the resulting quantum state. This
approach usually results in an exponential running time.
&lt;/p&gt;
&lt;p&gt;We show that, using $\varepsilon$-projectors, we can sample exactly from the
limiting distribution. In the black-box setting, where we only have query
access to the adjacency matrix of the graph, our sampling algorithm runs in
time proportional to $\Delta^{-1}$, where $\Delta$ is the minimum spacing
between the distinct eigenvalues of the graph. In the non-black-box setting, we
give examples of graphs for which our algorithm runs exponentially faster than
the standard sampling algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Quantum-Inspired Perfect Matching under Vertex-Color Constraints</title>
  <guid>http://arxiv.org/abs/2209.13063</guid>
  <link>http://arxiv.org/abs/2209.13063</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1&quot;&gt;Moshe Y. Vardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We propose and study the graph-theoretical problem PM-VC: perfect matching
under vertex-color constraints on graphs with bi-colored edges. PM-VC is of
special interest because of its motivation from quantum-state identification
and quantum-experiment design, as well as its rich expressiveness, i.e., PM-VC
subsumes many constrained matching problems naturally, such as exact perfect
matching. We give complexity and algorithmic results for PM-VC under two types
of vertex color constraints: 1) symmetric constraints (PM-VC-Sym) and 2)
decision-diagram constraints (PM-VC-DD).
&lt;/p&gt;
&lt;p&gt;We prove that PM-VC-Sym is in RNC via a symbolic determinant algorithm, which
can be derandomized on planar graphs. Moreover, PM-VC-Sym can be expressed in
extended MSO, which encourages our design of an efficient dynamic programming
algorithm for PM-VC-Sym on bounded-treewidth graphs. For PM-VC-DD, we reveal
its NP-hardness by a graph-gadget technique. Our novel results for PM-VC
provide insights to both constrained matching and scalable quantum experiment
design.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>An $O(3.82^k)$ Time FPT Algorithm for Convex Flip Distance</title>
  <guid>http://arxiv.org/abs/2209.13134</guid>
  <link>http://arxiv.org/abs/2209.13134</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haohong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1&quot;&gt;Ge Xia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let ${\cal P}$ be a convex polygon in the plane, and let ${\cal T}$ be a
triangulation of ${\cal P}$. An edge $e$ in ${\cal T}$ is called a diagonal if
it is shared by two triangles in ${\cal T}$. A {\em flip} of a diagonal $e$ is
the operation of removing $e$ and adding the opposite diagonal of the resulting
quadrilateral to obtain a new triangulation of ${\cal P}$ from ${\cal T}$. The
{\em flip distance} between two triangulations of ${\cal P}$ is the minimum
number of flips needed to transform one triangulation into the other. The {\sc
Convex Flip Distance} problem asks if the flip distance between two given
triangulations of ${\cal P}$ is at most $k$, for some given parameter $k$.
&lt;/p&gt;
&lt;p&gt;We present an FPT algorithm for the {\sc Convex Flip Distance} problem that
runs in time $O(3.82^{k})$ and uses polynomial space, where $k$ is the number
of flips. This algorithm significantly improves the previous best FPT
algorithms for the problem.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Partial and Simultaneous Transitive Orientations via Modular Decomposition</title>
  <guid>http://arxiv.org/abs/2209.13175</guid>
  <link>http://arxiv.org/abs/2209.13175</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munch_M/0/1/0/all/0/1&quot;&gt;Miriam M&amp;#xfc;nch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rutter_I/0/1/0/all/0/1&quot;&gt;Ignaz Rutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stumpf_P/0/1/0/all/0/1&quot;&gt;Peter Stumpf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A natural generalization of the recognition problem for a geometric graph
class is the problem of extending a representation of a subgraph to a
representation of the whole graph. A related problem is to find representations
for multiple input graphs that coincide on subgraphs shared by the input
graphs. A common restriction is the sunflower case where the shared graph is
the same for each pair of input graphs. These problems translate to the setting
of comparability graphs where the representations correspond to transitive
orientations of their edges. We use modular decompositions to improve the
runtime for the orientation extension problem and the sunflower orientation
problem to linear time. We apply these results to improve the runtime for the
partial representation problem and the sunflower case of the simultaneous
representation problem for permutation graphs to linear time. We also give the
first efficient algorithms for these problems on circular permutation graphs.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Algorithms for Large-scale Network Analysis and the NetworKit Toolkit</title>
  <guid>http://arxiv.org/abs/2209.13355</guid>
  <link>http://arxiv.org/abs/2209.13355</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angriman_E/0/1/0/all/0/1&quot;&gt;Eugenio Angriman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grinten_A/0/1/0/all/0/1&quot;&gt;Alexander van der Grinten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamann_M/0/1/0/all/0/1&quot;&gt;Michael Hamann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyerhenke_H/0/1/0/all/0/1&quot;&gt;Henning Meyerhenke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Penschuck_M/0/1/0/all/0/1&quot;&gt;Manuel Penschuck&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The abundance of massive network data in a plethora of applications makes
scalable analysis algorithms and software tools necessary to generate knowledge
from such data in reasonable time. Addressing scalability as well as other
requirements such as good usability and a rich feature set, the open-source
software NetworKit has established itself as a popular tool for large-scale
network analysis. This chapter provides a brief overview of the contributions
to NetworKit made by the DFG Priority Programme SPP 1736 Algorithms for Big
Data. Algorithmic contributions in the areas of centrality computations,
community detection, and sparsification are in the focus, but we also mention
several other aspects -- such as current software engineering principles of the
project and ways to visualize network data within a NetworKit-based workflow.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-28 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>The Blooming of the \(c^3\) LTC Flowers</title>
  <guid>https://blog.simons.berkeley.edu/?p=677</guid>
  <link>https://blog.simons.berkeley.edu/2022/09/the-blooming-of-the-c3-ltc-flowers/</link>
  <description>
    by Prahladh Harsha The last year (2021–22) has seen some amazing new constructions of locally testable codes with constant rate and constant fractional distance and testable with a constant number of queries, sometimes referred to as \(c^3\) LTCs [DELLM22, PK22]. &amp;#8230; &lt;a href=&quot;https://blog.simons.berkeley.edu/2022/09/the-blooming-of-the-c3-ltc-flowers/&quot;&gt;Continue reading &lt;span class=&quot;meta-nav&quot;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;&lt;p class=&quot;authors&quot;&gt;By Simons Institute Editor&lt;/p&gt;
  </description>
  <pubDate>2022-09-27 17:51:01 UTC</pubDate>
  <author>Simons Institute Blog</author>
</item>

<item>
  <title>Postdoc in Quantum Algorithms &amp; Complexity at University of Warwick (apply by October 18, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/09/27/postdoc-in-quantum-algorithms-complexity-at-university-of-warwick-apply-by-october-18-2022/</guid>
  <link>https://cstheory-jobs.org/2022/09/27/postdoc-in-quantum-algorithms-complexity-at-university-of-warwick-apply-by-october-18-2022/</link>
  <description>
    &lt;p&gt;We seek to appoint a postdoc for 24 months starting in March 2023 or as soon as possible thereafter. The aim is to study property testing algorithms for quantum channels as part of a collaboration between CS &amp;amp; Physics at Warwick, led by Animesh Datta and Tom Gur.&lt;/p&gt;
&lt;p&gt;For informal enquires, email your CV, explaining your suitability for the position.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://atsv7.wcn.co.uk/search_engine/jobs.cgi?owner=5062452&amp;amp;ownertype=fair&amp;amp;jcode=1888004&amp;amp;vt_template=1457&amp;amp;adminview=1&quot;&gt;https://atsv7.wcn.co.uk/search_engine/jobs.cgi?owner=5062452&amp;amp;ownertype=fair&amp;amp;jcode=1888004&amp;amp;vt_template=1457&amp;amp;adminview=1&lt;/a&gt;&lt;br /&gt;
Email: animesh.datta@warwick.ac.uk; tom.gur@warwick.ac.uk&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-09-27 15:22:22 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>TR22-137 |  On blocky ranks of matrices | 

	Daniel Avraham , 

	Amir Yehudayoff</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/137</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/137</link>
  <description>
    A matrix is blocky if it is a blowup of a permutation matrix. The blocky rank of a matrix M is the minimum number of blocky matrices that linearly span M. Hambardzumyan, Hatami and Hatami defined blocky rank and showed that it is connected to communication complexity and operator theory. We describe additional connections to circuit complexity and combinatorics, and we prove upper and lower bounds on blocky rank in various contexts.
  </description>
  <pubDate>2022-09-27 12:24:21 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Is the complexity of approximating Vertex Cover of degree 3 open? (ADDED LATER-NO)</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-1313340574525713217</guid>
  <link>http://blog.computationalcomplexity.org/2022/09/is-complexity-of-vertex-cover-of-degree.html</link>
  <description>
    &lt;p&gt;&amp;nbsp;RECALL:&lt;/p&gt;&lt;p&gt;A max-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that&lt;/p&gt;&lt;p&gt;&amp;nbsp;ALG(\epsilon) \ge (1-\epsilon)f(x).&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;A min-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that&lt;/p&gt;&lt;p&gt;&amp;nbsp;ALG(\epsilon) \le (1+\epsilon)f(x).&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;(Note that the poly can depend on epsilon so it may be something like n^{1/epsilon}.)&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;MAX3SAT is, given a formula with \le 3 literals per clause, find an assignment&lt;/p&gt;&lt;p&gt;that maximized the number of clauses satisfied.&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;VCB-a is Vertex cover where graphs have degree \le a&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;The following are known:&lt;/p&gt;&lt;p&gt;0) MAX3SAT is in APX.&lt;/p&gt;&lt;p&gt;1) The PCP paper,&amp;nbsp;&lt;a href=&quot;https://doi.org/10.1145/278298.278306&quot;&gt;here&lt;/a&gt;, showed that if MAX3SAT has a PTAS then P=NP.&lt;/p&gt;&lt;p&gt;2) Papadimitriou and Yannakakis (&lt;a href=&quot;https://doi.org/10.1016/0022-0000(91)90023-X&quot;&gt;here&lt;/a&gt;)&amp;nbsp; had showed much earlier that MAX3SAT \le VCB-4 with an approx preserving reduction.&lt;/p&gt;&lt;p&gt;3) From (1) and (2) we have that VCB-4 has a PTAS then P=NP. (VC is in APX by an easy 2-approx).&lt;/p&gt;&lt;p&gt;4) Clearly VCB-2 is in P.&lt;/p&gt;&lt;p&gt;The following seems to be open, though if you know otherwise pleae leave a comment:&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Is VCB-3 a) in P? b) NPC? (ADDED LATER- NPC- See comments.)&amp;nbsp;&lt;/p&gt;&lt;p&gt;Is the following true: if VCB-3 has a PTAS then P=NP. (ADDED LATER- NO PTAS-See Comments)&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;NOTE- all of the above is true for Ind Set-4 and Dom Set-4. So that leads to more open problems.&lt;/p&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </description>
  <pubDate>2022-09-27 02:02:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>A characterization of functions over the integers computable in polynomial time using discrete differential equations</title>
  <guid>http://arxiv.org/abs/2209.12168</guid>
  <link>http://arxiv.org/abs/2209.12168</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1&quot;&gt;Olivier Bournez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durand_A/0/1/0/all/0/1&quot;&gt;Arnaud Durand&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper studies the expressive and computational power of discrete
Ordinary Differential Equations (ODEs), a.k.a. (Ordinary) Difference Equations.
It presents a new framework using these equations as a central tool for
computation and algorithm design. We present the general theory of discrete
ODEs for computation theory, we illustrate this with various examples of
algorithms, and we provide several implicit characterizations of complexity and
computability classes.
&lt;/p&gt;
&lt;p&gt;The proposed framework presents an original point of view on complexity and
computation classes. It unifies several constructions that have been proposed
for characterizing these classes including classical approaches in implicit
complexity using restricted recursion schemes, as well as recent
characterizations of computability and complexity by classes of continuous
ordinary differential equations. It also helps understanding the relationships
between analog computations and classical discrete models of computation
theory.
&lt;/p&gt;
&lt;p&gt;At a more technical point of view, this paper points out the fundamental role
of linear (discrete) ODEs and classical ODE tools such as changes of variables
to capture computability and complexity measures, or as a tool for programming
many algorithms.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-27 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret</title>
  <guid>http://arxiv.org/abs/2209.11817</guid>
  <link>http://arxiv.org/abs/2209.11817</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1&quot;&gt;Matthew Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Huy L&amp;#xea; Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thy Nguyen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Recently a multi-agent variant of the classical multi-armed bandit was
proposed to tackle fairness issues in online learning. Inspired by a long line
of work in social choice and economics, the goal is to optimize the Nash social
welfare instead of the total utility. Unfortunately previous algorithms either
are not efficient or achieve sub-optimal regret in terms of the number of
rounds $T$. We propose a new efficient algorithm with lower regret than even
previous inefficient ones. For $N$ agents, $K$ arms, and $T$ rounds, our
approach has a regret bound of $\tilde{O}(\sqrt{NKT} + NK)$. This is an
improvement to the previous approach, which has regret bound of $\tilde{O}(
\min(NK, \sqrt{N} K^{3/2})\sqrt{T})$. We also complement our efficient
algorithm with an inefficient approach with $\tilde{O}(\sqrt{KT} + N^2K)$
regret. The experimental findings confirm the effectiveness of our efficient
algorithm compared to the previous approaches.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-27 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>The Online Knapsack Problem with Departures</title>
  <guid>http://arxiv.org/abs/2209.11934</guid>
  <link>http://arxiv.org/abs/2209.11934</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1&quot;&gt;Bo Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1&quot;&gt;Mohammad Hajiesmaili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1&quot;&gt;Adam Wierman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1&quot;&gt;John C.S. Lui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1&quot;&gt;Don Towsley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsang_D/0/1/0/all/0/1&quot;&gt;Danny H.K. Tsang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The online knapsack problem is a classic online resource allocation problem
in networking and operations research. Its basic version studies how to pack
online arriving items of different sizes and values into a capacity-limited
knapsack. In this paper, we study a general version that includes item
departures, while also considering multiple knapsacks and multi-dimensional
item sizes. We design a threshold-based online algorithm and prove that the
algorithm can achieve order-optimal competitive ratios. Beyond worst-case
performance guarantees, we also aim to achieve near-optimal average performance
under typical instances. Towards this goal, we propose a data-driven online
algorithm that learns within a policy-class that guarantees a worst-case
performance bound. In trace-driven experiments, we show that our data-driven
algorithm outperforms other benchmark algorithms in an application of online
knapsack to job scheduling for cloud computing.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-27 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Online Admission Control and Rebalancing in Payment Channel Networks</title>
  <guid>http://arxiv.org/abs/2209.11936</guid>
  <link>http://arxiv.org/abs/2209.11936</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastankhah_M/0/1/0/all/0/1&quot;&gt;Mahsa Bastankhah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_K/0/1/0/all/0/1&quot;&gt;Krishnendu Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maddah_Ali_M/0/1/0/all/0/1&quot;&gt;Mohammad Ali Maddah-Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1&quot;&gt;Stefan Schmid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svoboda_J/0/1/0/all/0/1&quot;&gt;Jakub Svoboda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeo_M/0/1/0/all/0/1&quot;&gt;Michelle Yeo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Payment channel networks (PCNs) are a promising technology to improve the
scalability of cryptocurrencies. PCNs, however, face the challenge that the
frequent usage of certain routes may deplete channels in one direction, and
hence prevent further transactions. In order to reap the full potential of
PCNs, recharging and rebalancing mechanisms are required to provision channels,
as well as an admission control logic to decide which transactions to reject in
case capacity is insufficient. This paper presents a formal model of this
optimisation problem. In particular, we consider an online algorithms
perspective, where transactions arrive over time in an unpredictable manner.
Our main contributions are competitive online algorithms which come with
provable guarantees over time. We empirically evaluate our algorithms on
randomly generated transactions to compare the average performance of our
algorithms to our theoretical bounds. We also show how this model and approach
differs from related problems in classic communication networks.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-27 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

</channel>
</rss>
