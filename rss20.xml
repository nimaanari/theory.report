<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>On Identity Testing and Noncommutative Rank Computation over the Free Skew Field</title>
  <guid>http://arxiv.org/abs/2209.04797</guid>
  <link>http://arxiv.org/abs/2209.04797</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arvind_V/0/1/0/all/0/1&quot;&gt;V. Arvind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1&quot;&gt;Abhranil Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosal_U/0/1/0/all/0/1&quot;&gt;Utsab Ghosal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhopadhyay_P/0/1/0/all/0/1&quot;&gt;Partha Mukhopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramya_C/0/1/0/all/0/1&quot;&gt;C. Ramya&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The identity testing of rational formulas (RIT) in the free skew field
efficiently reduces to computing the rank of a matrix whose entries are linear
polynomials in noncommuting variables\cite{HW15}. This rank computation problem
has deterministic polynomial-time white-box algorithms \cite{GGOW16, IQS18} and
a randomized polynomial-time algorithm in the black-box setting \cite{DM17}. In
this paper, we propose a new approach for efficient derandomization of
\emph{black-box} RIT. Additionally, we obtain results for matrix rank
computation over the free skew field, and construct efficient linear pencil
representations for a new class of rational expressions. More precisely, we
show the following results:
&lt;/p&gt;
&lt;p&gt;1. Under the hardness assumption that the ABP (algebraic branching program)
complexity of every polynomial identity for the $k\times k$ matrix algebra is
$2^{\Omega(k)}$ \cite{BW05}, we obtain a subexponential-time black-box
algorithm for RIT in almost general setting. This can be seen as the first
&quot;hardness implies derandomization&quot; type theorem for rational formulas.
&lt;/p&gt;
&lt;p&gt;2. We show that the noncommutative rank of any matrix over the free skew
field whose entries have small linear pencil representations can be computed in
deterministic polynomial time. Prior to this, an efficient rank computation was
only known for matrices with noncommutative formulas as entries\cite{GGOW20}.
As special cases of our algorithm, we obtain the first deterministic
polynomial-time algorithms for rank computation of matrices whose entries are
noncommutative ABPs or rational formulas.
&lt;/p&gt;
&lt;p&gt;3. Motivated by the definition given by Bergman\cite{Ber76}, we define a new
class that contains noncommutative ABPs and rational formulas. We obtain a
polynomial-size linear pencil representation for this class. As a by-product,
we obtain a white-box deterministic polynomial-time identity testing algorithm
for the class.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>PPP-Completeness and Extremal Combinatorics</title>
  <guid>http://arxiv.org/abs/2209.04827</guid>
  <link>http://arxiv.org/abs/2209.04827</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bourneuf_R/0/1/0/all/0/1&quot;&gt;Romain Bourneuf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Folwarczny_L/0/1/0/all/0/1&quot;&gt;Luk&amp;#xe1;&amp;#x161; Folwarczn&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubacek_P/0/1/0/all/0/1&quot;&gt;Pavel Hub&amp;#xe1;&amp;#x10d;ek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosen_A/0/1/0/all/0/1&quot;&gt;Alon Rosen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartzbach_N/0/1/0/all/0/1&quot;&gt;Nikolaj Ignatieff Schwartzbach&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Many classical theorems in combinatorics establish the emergence of
substructures within sufficiently large collections of objects. Well-known
examples are Ramsey&#39;s theorem on monochromatic subgraphs and the Erd\H{o}s-Rado
sunflower lemma. Implicit versions of the corresponding total search problems
are known to be PWPP-hard; here &quot;implici&quot; means that the collection is
represented by a poly-sized circuit inducing an exponentially large number of
objects.
&lt;/p&gt;
&lt;p&gt;We show that several other well-known theorems from extremal combinatorics -
including Erd\H{o}s-Ko-Rado, Sperner, and Cayley&#39;s formula - give rise to
complete problems for PWPP and PPP. This is in contrast to the Ramsey and
Erd\H{o}s-Rado problems, for which establishing inclusion in PWPP has remained
elusive. Besides significantly expanding the set of problems that are complete
for PWPP and PPP, our work identifies some key properties of combinatorial
proofs of existence that can give rise to completeness for these classes.
&lt;/p&gt;
&lt;p&gt;Our completeness results rely on efficient encodings for which finding
collisions allows extracting the desired substructure. These encodings are made
possible by the tightness of the bounds for the problems at hand (tighter than
what is known for Ramsey&#39;s theorem and the sunflower lemma). Previous
techniques for proving bounds in TFNP invariably made use of structured
algorithms. Such algorithms are not known to exist for the theorems considered
in this work, as their proofs &quot;from the book&quot; are non-constructive.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The Complexity and Expressive Power of Second-Order Extended Logic</title>
  <guid>http://arxiv.org/abs/2209.04837</guid>
  <link>http://arxiv.org/abs/2209.04837</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Shiguang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xishun Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the expressive powers of SO-HORN$^{*}$, SO-HORN$^{r}$ and
SO-HORN$^{*r}$ on all finite structures. We show that SO-HORN$^{r}$,
SO-HORN$^{*r}$, FO(LFP) coincide with each other and SO-HORN$^{*}$ is proper
sublogic of SO-HORN$^{r}$. To prove this result, we introduce the notions of
DATALOG$^{*}$ program, DATALOG$^{r}$ program and their stratified versions,
S-DATALOG$^{*}$ program and S-DATALOG$^{r}$ program. It is shown that, on all
structures, DATALOG$^{r}$ and S-DATALOG$^{r}$ are equivalent and DATALOG$^{*}$
is a proper sublogic of DATALOG$^{r}$. SO-HORN$^{*}$ and SO-HORN$^{r}$ can be
treated as the negations of DATALOG$^{*}$ and DATALOG$^{r}$, respectively. We
also show that SO-EHORN$^{r}$ logic which is an extended version of SO-HORN
captures co-NP on all finite structures.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>On The Computational Complexity of Self-Attention</title>
  <guid>http://arxiv.org/abs/2209.04881</guid>
  <link>http://arxiv.org/abs/2209.04881</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keles_F/0/1/0/all/0/1&quot;&gt;Feyza Duman Keles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijewardena_P/0/1/0/all/0/1&quot;&gt;Pruthuvi Mahesakya Wijewardena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1&quot;&gt;Chinmay Hegde&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Transformer architectures have led to remarkable progress in many
state-of-art applications. However, despite their successes, modern
transformers rely on the self-attention mechanism, whose time- and
space-complexity is quadratic in the length of the input. Several approaches
have been proposed to speed up self-attention mechanisms to achieve
sub-quadratic running time; however, the large majority of these works are not
accompanied by rigorous error guarantees. In this work, we establish lower
bounds on the computational complexity of self-attention in a number of
scenarios. We prove that the time complexity of self-attention is necessarily
quadratic in the input length, unless the Strong Exponential Time Hypothesis
(SETH) is false. This argument holds even if the attention computation is
performed only approximately, and for a variety of attention mechanisms. As a
complement to our lower bounds, we show that it is indeed possible to
approximate dot-product self-attention using finite Taylor series in
linear-time, at the cost of having an exponential dependence on the polynomial
order.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Nearly all $k$-SAT functions are unate</title>
  <guid>http://arxiv.org/abs/2209.04894</guid>
  <link>http://arxiv.org/abs/2209.04894</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Balogh_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf3;zsef Balogh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dong_D/0/1/0/all/0/1&quot;&gt;Dingding Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lidicky_B/0/1/0/all/0/1&quot;&gt;Bernard Lidick&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mani_N/0/1/0/all/0/1&quot;&gt;Nitya Mani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yufei Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove that $1-o(1)$ fraction of all $k$-SAT functions on $n$ Boolean
variables are unate (i.e., monotone after first negating some variables), for
any fixed positive integer $k$ and as $n \to \infty$. This resolves a
conjecture by Bollob\&#39;as, Brightwell, and Leader from 2003.
&lt;/p&gt;
&lt;p&gt;This paper is the second half of a two-part work solving the problem. The
first part, by Dong, Mani, and Zhao, reduces the conjecture to a Tur\&#39;an
problem on partially directed hypergraphs. In this paper we solve this Tur\&#39;an
problem.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Gradient-Free Methods for Deterministic and Stochastic Nonsmooth Nonconvex Optimization</title>
  <guid>http://arxiv.org/abs/2209.05045</guid>
  <link>http://arxiv.org/abs/2209.05045</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tianyi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zheng_Z/0/1/0/all/0/1&quot;&gt;Zeyu Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Nonsmooth nonconvex optimization problems broadly emerge in machine learning
and business decision making, whereas two core challenges impede the
development of efficient solution methods with finite-time convergence
guarantee: the lack of computationally tractable optimality criterion and the
lack of computationally powerful oracles. The contributions of this paper are
two-fold. First, we establish the relationship between the celebrated Goldstein
subdifferential~\citep{Goldstein-1977-Optimization} and uniform smoothing,
thereby providing the basis and intuition for the design of gradient-free
methods that guarantee the finite-time convergence to a set of Goldstein
stationary points. Second, we propose the gradient-free method (GFM) and
stochastic GFM for solving a class of nonsmooth nonconvex optimization problems
and prove that both of them can return a $(\delta,\epsilon)$-Goldstein
stationary point of a Lipschitz function $f$ at an expected convergence rate at
$O(d^{3/2}\delta^{-1}\epsilon^{-4})$ where $d$ is the problem dimension.
Two-phase versions of GFM and SGFM are also proposed and proven to achieve
improved large-deviation results. Finally, we demonstrate the effectiveness of
2-SGFM on training ReLU neural networks with the \textsc{Minst} dataset.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Localization with Few Distance Measurements</title>
  <guid>http://arxiv.org/abs/2209.04838</guid>
  <link>http://arxiv.org/abs/2209.04838</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halperin_D/0/1/0/all/0/1&quot;&gt;Dan Halperin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LaValle_S/0/1/0/all/0/1&quot;&gt;Steven M. LaValle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ugav_B/0/1/0/all/0/1&quot;&gt;Barak Ugav&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a polygon $W$, a depth sensor placed at point $p=(x,y)$ inside $W$ and
oriented in direction $\theta$ measures the distance $d=h(x,y,\theta)$ between
$p$ and the closest point on the boundary of $W$ along a ray emanating from $p$
in direction $\theta$. We study the following problem: Give a polygon $W$,
possibly with holes, with $n$ vertices, preprocess it such that given a query
real value $d\geq 0$, one can efficiently compute the preimage $h^{-1}(d)$,
namely determine all the possible poses (positions and orientations) of a depth
sensor placed in $W$ that would yield the reading $d$. We employ a
decomposition of $W\times S^1$, which is an extension of the celebrated
trapezoidal decomposition, and which we call rotational trapezoidal
decomposition and present an efficient data structure, which computes the
preimage in an output-sensitive fashion relative to this decomposition: if $k$
cells of the decomposition contribute to the final result, we will report them
in $O(k+1)$ time, after $O(n^2\log n)$ preprocessing time and using $O(n^2)$
storage space. We also analyze the shape of the projection of the preimage onto
the polygon $W$; this projection describes the portion of $W$ where the sensor
could have been placed. Furthermore, we obtain analogous results for the more
useful case (narrowing down the set of possible poses), where the sensor
performs two depth measurement from the same point $p$, one in direction
$\theta$ and the other in direction $\theta+\pi$. While localizations problems
in robotics are often carried out by exploring the full visibility polygon of a
sensor placed at a fixed point of the environment, the approach that we propose
here opens the door to sufficing with only few depth measurements, which is
advantageous as it allows for usage of inexpensive sensors and could also lead
to savings in storage and communication costs.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Structured $(\min,+)$-Convolution And Its Applications For The Shortest Vector, Closest Vector, and Separable Nonlinear Knapsack Problems</title>
  <guid>http://arxiv.org/abs/2209.04812</guid>
  <link>http://arxiv.org/abs/2209.04812</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gribanov_D/0/1/0/all/0/1&quot;&gt;D. V. Gribanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malyshev_D/0/1/0/all/0/1&quot;&gt;D. S. Malyshev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shumilov_I/0/1/0/all/0/1&quot;&gt;I. A. Shumilov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work we consider the problem of computing the $(\min, +)$-convolution
of two sequences $a$ and $b$ of lengths $n$ and $m$, respectively, where $n
\geq m$. We assume that $a$ is arbitrary, but $b_i = f(i)$, where $f(x) \colon
[0,m) \to \mathbb{R}$ is a function with one of the following properties:
&lt;/p&gt;
&lt;p&gt;1. the linear case, when $f(x) =\beta + \alpha \cdot x$;
&lt;/p&gt;
&lt;p&gt;2. the monotone case, when $f(i+1) \geq f(i)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;3. the convex case, when $f(i+1) - f(i) \geq f(i) - f(i-1)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;4. the concave case, when $f(i+1) - f(i) \leq f(i) - f(i-1)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;5. the piece-wise linear case, when $f(x)$ consist of $p$ linear pieces;
&lt;/p&gt;
&lt;p&gt;6. the polynomial case, when $f \in \mathbb{Z}^d[x]$, for some fixed $d$.
&lt;/p&gt;
&lt;p&gt;To the best of our knowledge, the cases 4-6 were not considered in literature
before. We develop true sub-quadratic algorithms for them.
&lt;/p&gt;
&lt;p&gt;We apply our results to the knapsack problem with a separable nonlinear
objective function, shortest lattice vector, and closest lattice vector
problems.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On finding short reconfiguration sequences between independent sets</title>
  <guid>http://arxiv.org/abs/2209.05145</guid>
  <link>http://arxiv.org/abs/2209.05145</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1&quot;&gt;Akanksha Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hait_S/0/1/0/all/0/1&quot;&gt;Soumita Hait&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mouawad_A/0/1/0/all/0/1&quot;&gt;Amer E. Mouawad&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Assume we are given a graph $G$, two independent sets $S$ and $T$ in $G$ of
size $k \geq 1$, and a positive integer $\ell \geq 1$. The goal is to decide
whether there exists a sequence $\langle I_0, I_1, ..., I_\ell \rangle$ of
independent sets such that for all $j \in \{0,\ldots,\ell-1\}$ the set $I_j$ is
an independent set of size $k$, $I_0 = S$, $I_\ell = T$, and $I_{j+1}$ is
obtained from $I_j$ by a predetermined reconfiguration rule. We consider two
reconfiguration rules. Intuitively, we view each independent set as a
collection of tokens placed on the vertices of the graph. Then, the Token
Sliding Optimization (TSO) problem asks whether there exists a sequence of at
most $\ell$ steps that transforms $S$ into $T$, where at each step we are
allowed to slide one token from a vertex to an unoccupied neighboring vertex.
In the Token Jumping Optimization (TJO) problem, at each step, we are allowed
to jump one token from a vertex to any other unoccupied vertex of the graph.
Both TSO and TJO are known to be fixed-parameter tractable when parameterized
by $\ell$ on nowhere dense classes of graphs. In this work, we show that both
problems are fixed-parameter tractable for parameter $k + \ell + d$ on
$d$-degenerate graphs as well as for parameter $|M| + \ell + \Delta$ on graphs
having a modulator $M$ whose deletion leaves a graph of maximum degree
$\Delta$. We complement these result by showing that for parameter $\ell$ alone
both problems become W[1]-hard already on $2$-degenerate graphs. Our positive
result makes use of the notion of independence covering families introduced by
Lokshtanov et al. Finally, we show that using such families one can obtain a
simpler and unified algorithm for the standard Token Jumping Reachability
problem parameterized by $k$ on both degenerate and nowhere dense classes of
graphs.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Experiments and a User Study for Hierarchical Drawings of Graphs</title>
  <guid>http://arxiv.org/abs/2209.04522</guid>
  <link>http://arxiv.org/abs/2209.04522</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lionakis_P/0/1/0/all/0/1&quot;&gt;Panagiotis Lionakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kritikakis_G/0/1/0/all/0/1&quot;&gt;Giorgos Kritikakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tollis_I/0/1/0/all/0/1&quot;&gt;Ioannis G. Tollis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present experimental results and a user study for hierarchical drawings of
graphs. A detailed hierarchical graph drawing technique that is based on the
Path Based Framework (PBF) is presented. Extensive edge bundling is applied to
draw all edges of the graph and the height of the drawing is minimized using
compaction. The drawings produced by this framework are compared to drawings
produced by the well known Sugiyama framework in terms of area, number of
bends, number of crossings, and execution time. The new algorithm runs very
fast and produces drawings that are readable and efficient. Since there are
advantages (and disadvantages) to both frameworks, we performed a user study
and the results show that the drawings produced by the new framework are well
received in terms of clarity, readability, and usability. Hence, the new
technique offers an interesting alternative to drawing hierarchical graphs, and
is especially useful in applications where user defined paths are important and
need to be highlighted.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Spectral hypergraph sparsification via chaining</title>
  <guid>http://arxiv.org/abs/2209.04539</guid>
  <link>http://arxiv.org/abs/2209.04539</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;James R. Lee&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a hypergraph on $n$ vertices where $D$ is the maximum size of a hyperedge,
there is a weighted hypergraph spectral $\varepsilon$-sparsifier with at most
$O(\varepsilon^{-2} \log(D) \cdot n \log n)$ hyperedges. This improves over the
bound of Kapralov, Krauthgamer, Tardos and Yoshida (2021) who achieve
$O(\varepsilon^{-4} n (\log n)^3)$, as well as the bound $O(\varepsilon^{-2}
D^3 n \log n)$ obtained by Bansal, Svensson, and Trevisan (2019). The same
sparsification result was obtained independently by Jambulapati, Liu, and
Sidford (2022).
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>PGAbB: A Block-Based Graph Processing Framework for Heterogeneous Platforms</title>
  <guid>http://arxiv.org/abs/2209.04541</guid>
  <link>http://arxiv.org/abs/2209.04541</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yasar_A/0/1/0/all/0/1&quot;&gt;Abdurrahman Yasar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajamanickam_S/0/1/0/all/0/1&quot;&gt;Sivasankaran Rajamanickam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berry_J/0/1/0/all/0/1&quot;&gt;Jonathan W. Berry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catalyurek_U/0/1/0/all/0/1&quot;&gt;Umit V. Catalyurek&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Designing flexible graph kernels that can run well on various platforms is a
crucial research problem due to the frequent usage of graphs for modeling data
and recent architectural advances and variety. In this work, we propose a novel
graph processing framework, PGAbB (Parallel Graph Algorithms by Blocks), for
modern shared-memory heterogeneous platforms. Our framework implements a
block-based programming model. This allows a user to express a graph algorithm
using kernels that operate on subgraphs. PGAbB support graph computations that
fit in host DRAM but not in GPU device memory, and provides simple but
effective scheduling techniques to schedule computations to all available
resources in a heterogeneous architecture. We have demonstrated that one can
easily implement a diverse set of graph algorithms in our framework by
developing five algorithms. Our experimental results show that PGAbB
implementations achieve better or competitive performance compared to
hand-optimized implementations. Based on our experiments on five graph
algorithms and forty-four graphs, in the median, PGAbB achieves 1.6, 1.6, 5.7,
3.4, 4.5, and 2.4 times better performance than GAPBS, Galois, Ligra, LAGraph
Galois-GPU, and Gunrock graph processing systems, respectively.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>The Bayan Algorithm: Detecting Communities in Networks Through Exact and Approximate Optimization of Modularity</title>
  <guid>http://arxiv.org/abs/2209.04562</guid>
  <link>http://arxiv.org/abs/2209.04562</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aref_S/0/1/0/all/0/1&quot;&gt;Samin Aref&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chheda_H/0/1/0/all/0/1&quot;&gt;Hriday Chheda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mostajabdaveh_M/0/1/0/all/0/1&quot;&gt;Mahdi Mostajabdaveh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Community detection is a classic problem in network science with extensive
applications in various fields. The most commonly used methods are the
algorithms designed to maximize a utility function, modularity, across
different ways that a network can be partitioned into communities. Despite
their name and design philosophy, current modularity maximization algorithms
generally fail to maximize modularity or guarantee any proximity to an optimal
solution. We propose the Bayan algorithm which, unlike the existing methods,
returns network partitions with a guarantee of either optimality or proximity
to an optimal solution. At the core of the Bayan algorithm is a branch-and-cut
scheme that solves a sparse integer programming formulation of the modularity
maximization problem to optimality or approximate it within a factor. We
analyze the performance of Bayan against 22 existing algorithms using synthetic
and real networks. Through extensive experiments, we demonstrate Bayan&#39;s
distinctive capabilities not only in maximizing modularity, but more
importantly in accurate retrieval of ground-truth communities. Bayan&#39;s
comparative level of performance remains stable over variations in the amount
of noise in the data (graph) generation process. The performance of Bayan as an
exact modularity maximization algorithm also reveals the theoretical capability
limits of maximum-modularity partitions in accurate retrieval of communities.
Overall our analysis points to Bayan as a suitable choice for a
methodologically grounded detection of communities through exact (approximate)
maximization of modularity in networks with up to $\sim10^3$ edges (and larger
networks). Prospective advances in graph optimization and integer programming
can push these limits further.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>An EPTAS for Budgeted Matroid Independent Set</title>
  <guid>http://arxiv.org/abs/2209.04654</guid>
  <link>http://arxiv.org/abs/2209.04654</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doron_Arad_I/0/1/0/all/0/1&quot;&gt;Ilan Doron-Arad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulik_A/0/1/0/all/0/1&quot;&gt;Ariel Kulik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shachnai_H/0/1/0/all/0/1&quot;&gt;Hadas Shachnai&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the budgeted matroid independent set problem. The input is a
ground set, where each element has a cost and a non-negative profit, along with
a matroid over the elements and a budget. The goal is to select a subset of
elements which maximizes the total profit subject to the matroid and budget
constraints. Several well known special cases, where we have, e.g., a uniform
matroid and a budget, or no matroid constraint (i.e., the classic knapsack
problem), admit a fully polynomial-time approximation scheme (FPTAS). In
contrast, already a slight generalization to the multi-budgeted matroid
independent set problem has a PTAS but does not admit an efficient
polynomial-time approximation scheme (EPTAS). This implies a PTAS for our
problem, which is the best known result prior to this work. Our main
contribution is an EPTAS for the budgeted matroid independent set problem. A
key idea of the scheme is to find a representative set for the instance, whose
cardinality depends solely on $1/\varepsilon$, where $\varepsilon &amp;gt; 0$ is the
accuracy parameter of the scheme. The representative set is identified via
matroid basis minimization, which can be solved by a simple greedy algorithm.
Our scheme enumerates over subsets of the representative set and extends each
subset using a linear program. The notion of representative sets may be useful
in solving other variants of the budgeted matroid independent set problem.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Growing a Random Maximal Independent Set Produces a 2-approximate Vertex Cover</title>
  <guid>http://arxiv.org/abs/2209.04673</guid>
  <link>http://arxiv.org/abs/2209.04673</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veldt_N/0/1/0/all/0/1&quot;&gt;Nate Veldt&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper presents a fast and simple new 2-approximation algorithm for
minimum weighted vertex cover. The unweighted version of this algorithm is
equivalent to a well-known greedy maximal independent set algorithm. We prove
that this independent set algorithm produces a 2-approximate vertex cover, and
we provide a principled new way to generalize it to node-weighted graphs. Our
analysis is inspired by connections to a clustering objective called
correlation clustering. To demonstrate the relationship between these problems,
we show how a simple Pivot algorithm for correlation clustering implicitly
approximates a special type of hypergraph vertex cover problem. Finally, we use
implicit implementations of this maximal independent set algorithm to develop
fast and simple 2-approximation algorithms for certain edge-deletion problems
that can be reduced to vertex cover in an approximation preserving way.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Hard Optimization Problems have Soft Edges</title>
  <guid>http://arxiv.org/abs/2209.04824</guid>
  <link>http://arxiv.org/abs/2209.04824</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Marino_R/0/1/0/all/0/1&quot;&gt;Raffaele Marino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Kirkpatrick_S/0/1/0/all/0/1&quot;&gt;Scott Kirkpatrick&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Finding a Maximum Clique is a classic property test from graph theory; find
any one of the largest complete subgraphs in an Erd{\&quot;o}s-R{\&#39;e}nyi $G(N,p)$
random graph. It is the simplest of many such problems in which algorithms
requiring only a small power of $N$ steps cannot reach solutions which
probabilistic arguments show must exist, exposing an inherently &quot;hard&quot; phase
within the solution space of the problem. Such &quot;hard&quot; phases are seen in many
NP-Complete problems, in the limit when $N \to \infty$. But optimization
problems arise and must be solved at finite N. We use this simplest case,
MaxClique, to explore the structure of the problem as a function of $N$ and
$K$, the clique size. It displays a complex phase boundary, a staircase of
steps at each of which $2 \log_2N$ and $K_{\text{max}}$, the maximum size of
clique that can be found, increase by $1$. Each of its boundaries have finite
width, and these widths allow local algorithms to find cliques beyond the
limits defined by the study of infinite systems. We explore the performance of
a number of extensions of traditional fast local algorithms, and find that much
of the &quot;hard&quot; space remains accessible at finite $N$.
&lt;/p&gt;
&lt;p&gt;The &quot;hidden clique&quot; problem embeds a clique somewhat larger than those which
occur naturally in a $G(N,p)$ random graph. Since such a clique is unique, we
find that local searches which stop early, once evidence for the hidden clique
is found, may outperform the best message passing or spectral algorithms.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Rethink Decision Tree Traversal</title>
  <guid>http://arxiv.org/abs/2209.04825</guid>
  <link>http://arxiv.org/abs/2209.04825</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jinxiong Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We will show how to evaluate binary decision tree traversal in the language
of matrix computation motivated by \textit{QuickScorer} in
\cite{lucchese2015quickscorer}. Our main contribution is a novel matrix
representation of the hierarchical structure of the decision tree. And we
propose some equivalent algorithms of binary decision tree traversal based on
rigorous theoretical analysis. The core idea is to find the relation between
the input and exit leaf node. Here we not only understand decisions without the
recursive traverse but also dive into the partitioning nature of tree-based
methods.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>An Improved Algorithm For Online Reranking</title>
  <guid>http://arxiv.org/abs/2209.04870</guid>
  <link>http://arxiv.org/abs/2209.04870</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bienkowski_M/0/1/0/all/0/1&quot;&gt;Marcin Bienkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mucha_M/0/1/0/all/0/1&quot;&gt;Marcin Mucha&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study a fundamental model of online preference aggregation, where an
algorithm maintains an ordered list of $n$ elements. An input is a stream of
preferred sets $R_1, R_2, \dots, R_t, \dots$. Upon seeing $R_t$ and without
knowledge of any future sets, an algorithm has to rerank elements (change the
list ordering), so that at least one element of $R_t$ is found near the list
front. The incurred cost is a sum of the list update costs (the number of swaps
of neighboring list elements) and access costs (position of the first element
of $R_t$ on the list). This scenario occurs naturally in applications such as
ordering items in an online shop using aggregated preferences of shop
customers. The theoretical underpinning of this problem is known as Min-Sum Set
Cover.
&lt;/p&gt;
&lt;p&gt;Unlike previous work (Fotakis et al., ICALP 2020, NIPS 2020) that mostly
studied the performance of an online algorithm ALG against the static optimal
solution (a single optimal list ordering), in this paper, we study an arguably
harder variant where the benchmark is the provably stronger optimal dynamic
solution OPT (that may also modify the list ordering). In terms of an online
shop, this means that the aggregated preferences of its user base evolve with
time. We construct a computationally efficient randomized algorithm whose
competitive ratio (ALG-to-OPT cost ratio) is $O(r^2)$ and prove the existence
of a deterministic $O(r^4)$-competitive algorithm. Here, $r$ is the maximum
cardinality of sets $R_t$. This is the first algorithm whose ratio does not
depend on $n$: the previously best algorithm for this problem was $O(r^{3/2}
\cdot \sqrt{n})$-competitive and $\Omega(r)$ is a lower bound on the
performance of any deterministic online algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Subquadratic Kronecker Regression with Applications to Tensor Decomposition</title>
  <guid>http://arxiv.org/abs/2209.04876</guid>
  <link>http://arxiv.org/abs/2209.04876</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fahrbach_M/0/1/0/all/0/1&quot;&gt;Matthew Fahrbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1&quot;&gt;Thomas Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghadiri_M/0/1/0/all/0/1&quot;&gt;Mehrdad Ghadiri&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Kronecker regression is a highly-structured least squares problem
$\min_{\mathbf{x}} \lVert \mathbf{K}\mathbf{x} - \mathbf{b} \rVert_{2}^2$,
where the design matrix $\mathbf{K} = \mathbf{A}^{(1)} \otimes \cdots \otimes
\mathbf{A}^{(N)}$ is a Kronecker product of factor matrices. This regression
problem arises in each step of the widely-used alternating least squares (ALS)
algorithm for computing the Tucker decomposition of a tensor. We present the
first subquadratic-time algorithm for solving Kronecker regression to a
$(1+\varepsilon)$-approximation that avoids the exponential term
$O(\varepsilon^{-N})$ in the running time. Our techniques combine leverage
score sampling and iterative methods. By extending our approach to block-design
matrices where one block is a Kronecker product, we also achieve
subquadratic-time algorithms for (1) Kronecker ridge regression and (2)
updating the factor matrix of a Tucker decomposition in ALS, which is not a
pure Kronecker regression problem, thereby improving the running time of all
steps of Tucker ALS. We demonstrate the speed and accuracy of this Kronecker
regression algorithm on synthetic data and real-world image tensors.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Cores of Games via Total Dual Integrality, with Applications to Perfect Graphs and Polymatroids</title>
  <guid>http://arxiv.org/abs/2209.04903</guid>
  <link>http://arxiv.org/abs/2209.04903</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vazirani_V/0/1/0/all/0/1&quot;&gt;Vijay V. Vazirani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;LP-duality theory has played a central role in the study of cores of games,
right from the early days of this notion to the present time. The classic paper
of Shapley and Shubik \cite{Shapley1971assignment} introduced the &quot;right&quot; way
of exploiting the power of this theory, namely picking problems whose
LP-relaxations support polyhedra having integral vertices. So far, the latter
fact was established by showing that the constraint matrix of the underlying
linear system is {\em totally unimodular}.
&lt;/p&gt;
&lt;p&gt;We attempt to take this methodology to its logical next step -- {\em using
total dual integrality} -- thereby addressing new classes of games which have
their origins in two major theories within combinatorial optimization, namely
perfect graphs and polymatroids. In the former, we address the stable set and
clique games and in the latter, we address the matroid independent set game.
For each of these games, we prove that the set of core imputations is precisely
the set of optimal solutions to the dual LPs.
&lt;/p&gt;
&lt;p&gt;Another novelty is the way the worth of the game is allocated among
sub-coalitions. Previous works follow the {\em bottom-up process} of allocating
to individual agents; the allocation to a sub-coalition is simply the sum of
the allocations to its agents. The {\em natural process for our games is
top-down}. The optimal dual allocates to &quot;objects&quot; in the grand coalition; a
sub-coalition inherits the allocation of each object with which it has
non-empty intersection.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Dynamic Subset Sum with Truly Sublinear Processing Time</title>
  <guid>http://arxiv.org/abs/2209.04936</guid>
  <link>http://arxiv.org/abs/2209.04936</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saleh_H/0/1/0/all/0/1&quot;&gt;Hamed Saleh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seddighin_S/0/1/0/all/0/1&quot;&gt;Saeed Seddighin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Subset sum is a very old and fundamental problem in theoretical computer
science. In this problem, $n$ items with weights $w_1, w_2, w_3, \ldots, w_n$
are given as input and the goal is to find out if there is a subset of them
whose weights sum up to a given value $t$. While the problem is NP-hard in
general, when the values are non-negative integer, subset sum can be solved in
pseudo-polynomial time $~\widetilde O(n+t)$.
&lt;/p&gt;
&lt;p&gt;In this work, we consider the dynamic variant of subset sum. In this setting,
an upper bound $\tmax$ is provided in advance to the algorithm and in each
operation, either a new item is added to the problem or for a given integer
value $t \leq \tmax$, the algorithm is required to output whether there is a
subset of items whose sum of weights is equal to $t$. Unfortunately, none of
the existing subset sum algorithms is able to process these operations in truly
sublinear time\footnote{Truly sublinear means $n^{1-\Omega(1)}$.} in terms of
$\tmax$.
&lt;/p&gt;
&lt;p&gt;Our main contribution is an algorithm whose amortized processing
time\footnote{Since the runtimes are amortized, we do not use separate terms
update time and query time for different operations and use processing time for
all types of operations.} for each operation is truly sublinear in $\tmax$ when
the number of operations is at least $\tmax^{2/3+\Omega(1)}$. We also show that
when both element addition and element removal are allowed, there is no
algorithm that can process each operation in time $\tmax^{1-\Omega(1)}$ on
average unless \textsf{SETH}\footnote{The \textit{strong exponential time
hypothesis} states that no algorithm can solve the satisfiability problem in
time $2^{n(1-\Omega(1))}$.} fails.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>QUBO formulations for NP-Hard spanning tree problems</title>
  <guid>http://arxiv.org/abs/2209.05024</guid>
  <link>http://arxiv.org/abs/2209.05024</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carvalho_I/0/1/0/all/0/1&quot;&gt;Ivan Carvalho&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce a novel Quadratic Unconstrained Binary Optimization (QUBO)
formulation method for spanning tree problems. Instead of encoding the presence
of edges in the tree individually, we opt to encode spanning trees as a
permutation problem. We apply our method to four NP-hard spanning tree
variants, namely the k-minimum spanning tree, degree-constrained minimum
spanning tree, minimum leaf spanning tree, and maximum leaf spanning tree. Our
main result is a formulation with $\mathcal{O}(|V|k)$ variables for the
k-minimum spanning tree problem, beating related strategies that need
$\mathcal{O}(|V|^{2})$ variables.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Thirty Years of Dagstuhl</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-4092582253443093216</guid>
  <link>http://blog.computationalcomplexity.org/2022/09/thirty-years-of-dagstuhl.html</link>
  <description>
    &lt;p&gt;&amp;nbsp;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiAVV6vqRxQ0GiKOwjxUJJsrSy10_N1Rnaq7CSWN1LgmRkcVyYHAp5sLgwslboCRbhHq3s6iMU9bSHGJlLBUthZUpI750kpeBrLOkMQcLtDBumFlxNfU-mSDwmO_8nRgw9onQW6AVeluj2ZL1-oGuWqCRxbIVJyT5OZAsdPSTc-BM8UqwioQ/s2668/PXL_20220912_120021005.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;2259&quot; data-original-width=&quot;2668&quot; height=&quot;339&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiAVV6vqRxQ0GiKOwjxUJJsrSy10_N1Rnaq7CSWN1LgmRkcVyYHAp5sLgwslboCRbhHq3s6iMU9bSHGJlLBUthZUpI750kpeBrLOkMQcLtDBumFlxNfU-mSDwmO_8nRgw9onQW6AVeluj2ZL1-oGuWqCRxbIVJyT5OZAsdPSTc-BM8UqwioQ/w400-h339/PXL_20220912_120021005.jpg&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Dagstuhl old-timers at the original castle&lt;br /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;I&#39;m back at Dagstuhl for the seminar on&amp;nbsp;&lt;a href=&quot;https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=22371&quot;&gt;Algebraic and Analytic Methods in Computational Complexity&lt;/a&gt;. My &lt;a href=&quot;https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=9206&quot;&gt;first seminar&lt;/a&gt; at Dagstuhl was back in 1992. I&#39;ve been coming for thirty years and have been here roughly thirty times. My &lt;a href=&quot;https://blog.computationalcomplexity.org/2019/03/back-at-dagstuhl.html&quot;&gt;last trip&lt;/a&gt; was pre-covid (virtual Dagstuhls don&#39;t count) and I really needed this chance to hang out and talk complexity with colleagues old and new.&lt;/p&gt;&lt;p&gt;Some changes since my last trip. The room doors have locks (there are rumors of an incident). You have to create your own keycard on a new machine logging into your Dagstuhl account. I had a long random password through a password manager and it was not so easy as process.&lt;/p&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLRrLcyKcZLTsqhWGocXuS13xG4yxOJNC9A0xL4mwzmXB8KXWwVTEsW4jF5lST7LAfHNbb_z4nwmOQarS1dwdoSwQYg7IX6NdpNqGkriuzDM4M1mP3rgiR99bV2XOAVr2iJvPsyGHBG6ECrwqYuR65Ok9uXvS_CvxogulpL0Eph-4xPLW9EA/s4080/PXL_20220912_122728903.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;3072&quot; data-original-width=&quot;4080&quot; height=&quot;241&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLRrLcyKcZLTsqhWGocXuS13xG4yxOJNC9A0xL4mwzmXB8KXWwVTEsW4jF5lST7LAfHNbb_z4nwmOQarS1dwdoSwQYg7IX6NdpNqGkriuzDM4M1mP3rgiR99bV2XOAVr2iJvPsyGHBG6ECrwqYuR65Ok9uXvS_CvxogulpL0Eph-4xPLW9EA/s320/PXL_20220912_122728903.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;p&gt;The main conference room has been updated with tech for hybrid meetings, and new led lights. Books were removed from the library to create a coffee breakout space.&lt;/p&gt;&lt;p&gt;No Bill this time so no &lt;a href=&quot;https://blog.computationalcomplexity.org/search?q=typecast&quot;&gt;typecasts&lt;/a&gt;. Still the best part of the week is talking and hearing about complexity. Today I learned about the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sperner%27s_lemma#Oriented_variants&quot;&gt;orientations of Sperner&#39;s lemma&lt;/a&gt;, that there is one more triangle oriented according to the direction of the corner vertices than those oriented the other way.&amp;nbsp;Christian Ikenmeyer used this fact to motivate a study of closure properties of #P-functions.&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2022-09-12 15:26:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>Quantum optimization with arbitrary connectivity using Rydberg atom arrays</title>
  <guid>http://arxiv.org/abs/2209.03965</guid>
  <link>http://arxiv.org/abs/2209.03965</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nguyen_M/0/1/0/all/0/1&quot;&gt;Minh-Thi Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jin-Guo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wurtz_J/0/1/0/all/0/1&quot;&gt;Jonathan Wurtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lukin_M/0/1/0/all/0/1&quot;&gt;Mikhail D. Lukin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sheng-Tao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pichler_H/0/1/0/all/0/1&quot;&gt;Hannes Pichler&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Programmable quantum systems based on Rydberg atom arrays have recently been
used for hardware-efficient tests of quantum optimization algorithms [Ebadi et
al., Science, 376, 1209 (2022)] with hundreds of qubits. In particular, the
maximum independent set problem on the so-called unit-disk graphs, was shown to
be efficiently encodable in such a quantum system. Here, we extend the classes
of problems that can be efficiently encoded in Rydberg arrays by constructing
explicit mappings from the original computation problems to maximum weighted
independent set problems on unit-disk graphs, with at most a quadratic overhead
in the number of qubits. We analyze several examples, including: maximum
weighted independent set on graphs with arbitrary connectivity, quadratic
unconstrained binary optimization problems with arbitrary or restricted
connectivity, and integer factorization. Numerical simulations on small system
sizes indicate that the adiabatic time scale for solving the mapped problems is
strongly correlated with that of the original problems. Our work provides a
blueprint for using Rydberg atom arrays to solve a wide range of combinatorial
optimization problems with arbitrary connectivity, beyond the restrictions
imposed by the hardware geometry.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Trajectory Range Visibility</title>
  <guid>http://arxiv.org/abs/2209.04013</guid>
  <link>http://arxiv.org/abs/2209.04013</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazemi_S/0/1/0/all/0/1&quot;&gt;Seyed Mohammad Hussein Kazemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaezi_A/0/1/0/all/0/1&quot;&gt;Arash Vaezi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghodsi_M/0/1/0/all/0/1&quot;&gt;Mohammad Ghodsi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problem of Trajectory Range Visibility, determining the
sub-trajectories on which two moving entities become mutually visible.
Specifically, we consider two moving entities with not necessarily equal
velocities and moving on a given piece-wise linear trajectory inside a simple
polygon. Deciding whether the entities can see one another with given constant
velocities, and assuming the trajectories only as line segments, was solved by
P. Eades et al. in 2020. However, we obtain stronger results and support
queries on constant velocities for non-constant complexity trajectories.
Namely, given a constant query velocity for a moving entity, we specify all
visible parts of the other entity&#39;s trajectory and all possible constant
velocities of the other entity to become visible. Regarding line-segment
trajectories, we obtain $\mathcal{O}(n \log n)$ time to specify all pairs of
mutually visible sub-trajectories s.t. $n$ is the number of vertices of the
polygon. Moreover, our results for a restricted case on non-constant complexity
trajectories yield $\mathcal{O}(n + m(\log m + \log n))$ time, in which $m$ is
the overall number of vertices of both trajectories. Regarding the unrestricted
case, we provide $\mathcal{O}(n \log n + m(\log m + \log n))$ running time. We
offer $\mathcal{O}(\log n)$ query time for line segment trajectories and
$\mathcal{O}(\log m + k)$ for the non-constant complexity ones s.t. $k$ is the
number of velocity ranges reported in the answer. Interestingly, our results
require only $\mathcal{O}(n + m)$ space for non-constant complexity
trajectories.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Separating bichromatic point sets in the plane by restricted orientation convex hulls</title>
  <guid>http://arxiv.org/abs/2209.04258</guid>
  <link>http://arxiv.org/abs/2209.04258</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alegria_C/0/1/0/all/0/1&quot;&gt;Carlos Alegr&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orden_D/0/1/0/all/0/1&quot;&gt;David Orden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seara_C/0/1/0/all/0/1&quot;&gt;Carlos Seara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1&quot;&gt;Jorge Urrutia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We explore the separability of point sets in the plane by a
restricted-orientation convex hull, which is an orientation-dependent, possibly
disconnected, and non-convex enclosing shape that generalizes the convex hull.
Let $R$ and $B$ be two disjoint sets of red and blue points in the plane, and
$\mathcal{O}$ be a set of $k \geq 2$ lines passing through the origin. We study
the problem of computing the set of orientations of the lines of $\mathcal{O}$
for which the $\mathcal{O}$-convex hull of $R$ contains no points of $B$.
&lt;/p&gt;
&lt;p&gt;For $k=2$ orthogonal lines we have the rectilinear convex hull. In optimal
$O(n \log n)$ time and $O(n)$ space, $n = \vert R \vert + \vert B \vert$, we
compute the set of rotation angles such that, after simultaneously rotating the
lines of $\mathcal{O}$ around the origin in the same direction, the rectilinear
convex hull of $R$ contains no points of $B$. We generalize this result to the
case where $\mathcal{O}$ is formed by $k \geq 2$ lines with arbitrary
orientations. In the counter-clockwise circular order of the lines of
$\mathcal{O}$, let $\alpha_i$ be the angle required to clockwise rotate the
$i$th line so it coincides with its successor. We solve the problem in this
case in $O(1/\Theta \cdot N \log N)$ time and $O(1/\Theta \cdot N)$ space,
where $\Theta = \min \{ \alpha_1,\ldots,\alpha_k \}$ and $N=\max\{k,\vert R
\vert + \vert B \vert \}$. We finally consider the case in which $\mathcal{O}$
is formed by $k=2$ lines, one of the lines is fixed, and the second line
rotates by an angle that goes from $0$ to $\pi$. We show that this last case
can also be solved in optimal $O(n\log n)$ time and $O(n)$ space, where $n =
\vert R \vert + \vert B \vert$.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Tensor Reconstruction Beyond Constant Rank</title>
  <guid>http://arxiv.org/abs/2209.04177</guid>
  <link>http://arxiv.org/abs/2209.04177</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peleg_S/0/1/0/all/0/1&quot;&gt;Shir Peleg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shpilka_A/0/1/0/all/0/1&quot;&gt;Amir Shpilka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volk_B/0/1/0/all/0/1&quot;&gt;Ben Lee Volk&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We give reconstruction algorithms for subclasses of depth-3 arithmetic
circuits. In particular, we obtain the first efficient algorithm for finding
tensor rank, and an optimal tensor decomposition as a sum of rank-one tensors,
when given black-box access to a tensor of super-constant rank. We obtain the
following results:
&lt;/p&gt;
&lt;p&gt;1. A deterministic algorithm that reconstructs polynomials computed by
$\Sigma^{[k]}\bigwedge^{[d]}\Sigma$ circuits in time $\mathsf{poly}(n,d,c)
\cdot \mathsf{poly}(k)^{k^{k^{10}}}$
&lt;/p&gt;
&lt;p&gt;2. A randomized algorithm that reconstructs polynomials computed by
multilinear $\Sigma^{k]}\prod^{[d]}\Sigma$ circuits in time
$\mathsf{poly}(n,d,c) \cdot k^{k^{k^{k^{O(k)}}}}$
&lt;/p&gt;
&lt;p&gt;3. A randomized algorithm that reconstructs polynomials computed by
set-multilinear $\Sigma^{k]}\prod^{[d]}\Sigma$ circuits in time
$\mathsf{poly}(n,d,c) \cdot k^{k^{k^{k^{O(k)}}}}$, where $c=\log q$ if
$\mathbb{F}=\mathbb{F}_q$ is a finite field, and $c$ equals the maximum bit
complexity of any coefficient of $f$ if $\mathbb{F}$ is infinite.
&lt;/p&gt;
&lt;p&gt;Prior to our work, polynomial time algorithms for the case when the rank,
$k$, is constant, were given by Bhargava, Saraf and Volkovich [BSV21].
&lt;/p&gt;
&lt;p&gt;Another contribution of this work is correcting an error from a paper of
Karnin and Shpilka [KS09] that affected Theorem 1.6 of [BSV21]. Consequently,
the results of [KS09, BSV21] continue to hold, with a slightly worse setting of
parameters. For fixing the error we study the relation between syntactic and
semantic ranks of $\Sigma\Pi\Sigma$ circuits.
&lt;/p&gt;
&lt;p&gt;We obtain our improvement by introducing a technique for learning rank
preserving coordinate-subspaces. [KS09] and [BSV21] tried all choices of
finding the &quot;correct&quot; coordinates, which led to having a fast growing function
of $k$ at the exponent of $n$. We find these spaces in time that is growing
fast with $k$, yet it is only a fixed polynomial in $n$.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Proceedings of the 30th International Symposium on Graph Drawing and Network Visualization (GD 2022)</title>
  <guid>http://arxiv.org/abs/2209.04402</guid>
  <link>http://arxiv.org/abs/2209.04402</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angelini_P/0/1/0/all/0/1&quot;&gt;Patrizio Angelini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanxleden_R/0/1/0/all/0/1&quot;&gt;Reinhard von Hanxleden&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This is the arXiv index for the electronic proceedings of GD 2022, which is
held at the Tokyo Institute of Technology, Tokyo, Japan, on September 13 - 16,
2022. It contains the peer-reviewed and revised accepted papers with an
optional appendix. Proceedings (without appendices) are also to be published by
Springer in the Lecture Notes in Computer Science series.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Algorithms with More Granular Differential Privacy Guarantees</title>
  <guid>http://arxiv.org/abs/2209.04053</guid>
  <link>http://arxiv.org/abs/2209.04053</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1&quot;&gt;Badih Ghazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Ravi Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1&quot;&gt;Pasin Manurangsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1&quot;&gt;Thomas Steinke&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Differential privacy is often applied with a privacy parameter that is larger
than the theory suggests is ideal; various informal justifications for
tolerating large privacy parameters have been proposed. In this work, we
consider partial differential privacy (DP), which allows quantifying the
privacy guarantee on a per-attribute basis. In this framework, we study several
basic data analysis and learning tasks, and design algorithms whose
per-attribute privacy parameter is smaller that the best possible privacy
parameter for the entire record of a person (i.e., all the attributes).
&lt;/p&gt;
  </description>
  <pubDate>2022-09-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Non-convex Quadratic Programming Using Coherent Optical Networks</title>
  <guid>http://arxiv.org/abs/2209.04415</guid>
  <link>http://arxiv.org/abs/2209.04415</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Khosravi_F/0/1/0/all/0/1&quot;&gt;Farhad Khosravi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yildiz_U/0/1/0/all/0/1&quot;&gt;Ugur Yildiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Scherer_A/0/1/0/all/0/1&quot;&gt;Artur Scherer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ronagh_P/0/1/0/all/0/1&quot;&gt;Pooya Ronagh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We investigate the possibility of solving continuous non-convex optimization
problems using a network of interacting quantum optical oscillators. We propose
a native encoding of continuous variables in analog signals associated with the
quadrature operators of a set of quantum optical modes. Optical coupling of the
modes and noise introduced by vacuum fluctuations from external reservoirs or
by weak measurements of the modes are used to optically simulate a diffusion
process on a set of continuous random variables. The process is run
sufficiently long for it to relax into the steady state of an energy potential
defined on a continuous domain. As a first demonstration, we numerically
benchmark solving box-constrained quadratic programming (BoxQP) problems using
these settings. We consider delay-line and measurement-feedback variants of the
experiment. Our benchmarking results demonstrate that in both cases the optical
network is capable of solving BoxQP problems over three orders of magnitude
faster than a state-of-the-art classical heuristic.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Comparing distances along lines</title>
  <guid>https://11011110.github.io/blog/2022/09/10/comparing-distances-lines</guid>
  <link>https://11011110.github.io/blog/2022/09/10/comparing-distances-lines.html</link>
  <description>
    &lt;p&gt;I’ve written here several times about &lt;a href=&quot;https://en.wikipedia.org/wiki/Gilbert_tessellation&quot;&gt;Gilbert tessellations&lt;/a&gt;, most recently in &lt;a href=&quot;/blog/2021/11/02/gilbert-tessellations-cellular.html&quot;&gt;last year’s post about cellular automata that naturally generate them&lt;/a&gt;. These are polygonal subdivisions of the plane, generated from the tracks of particles moving at the same speed, where the particles start as oppositely-moving pairs with random locations and directions, and continue moving until they crash into the track of another particle. Here’s Wikipedia’s illustration of these things, generated in 2012 by Claudio Rocchini:&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;&lt;a href=&quot;https://commons.wikimedia.org/wiki/File:Gilbert_tessellation.svg&quot;&gt;&lt;img src=&quot;/blog/assets/2018/Gilbert-tessellation.svg&quot; alt=&quot;A Gilbert tessellation, by Claudio Rocchini&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Suppose someone gives you a picture like this and tells you it’s a Gilbert tessellation, like I just did. How can you tell that it’s genuine? The starting positions of the particles are not marked on the picture, so what needs to be done is to infer their locations (or a system of points that could be their locations) and to check that particles, starting at those locations and moving along the lines, crash in the order that the picture shows. Wherever two segments intersect in the picture, one of them ends, and it must be the case that the starting position on the segment that ends is farther away than the starting position on the other segment. Otherwise, it would have been the other particle that crashed and the other segment that ended.&lt;/p&gt;

&lt;p&gt;One can set up a big system of inequalities where each variable describes the starting position of one of the particles, for instance by giving its distance from one end of its segment. Each inequality comes from an intersection of two segments and asks for the particle on one segment to be farther than the particle on the other segment. The distance between two positions \(x\) and \(y\) on the same segment, parameterized linearly, is &lt;span style=&quot;white-space:nowrap&quot;&gt;just \(\vert x-y\vert\).&lt;/span&gt; So when a particle on &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(j\)&lt;/span&gt; crashes into a track on &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(i\)&lt;/span&gt; we get an inequality like&lt;/p&gt;

\[\vert x_i-e_{ij}\vert\le \vert x_j-e_{ji}\vert,\]

&lt;p&gt;where \(x_i\) is the starting positions of the particle on &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(i\),&lt;/span&gt; \(e_i\) is the known position on &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(i\)&lt;/span&gt; of its intersection with &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(j\),&lt;/span&gt; \(\vert x_i-e_{ij}\vert\) is the distance from the starting position to the intersection, and the smaller distance for the particle on &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(i\)&lt;/span&gt; means that it gets to the intersection first, causing the other particle to crash into its track. We also have some inequalities specifying that each starting position lies between the endpoints of its line segment. This almost looks like a linear program (or rather a linear programming feasability problem, with only linear constraints but no objective function), but the absolute values make it nonlinear. We can get rid of them by two tricks:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Because the left absolute value occurs on the left hand side of a &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\le\) constraint,&lt;/span&gt; it is equivalent to replace it by two constraints, one for each choice of sign:&lt;/p&gt;

\[x_i-e_{ij}\le \vert x_j-e_{ji}\vert,\]

    &lt;p&gt;and&lt;/p&gt;

\[e_{ij}-x_i\le \vert x_j-e_{ji}\vert.\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Because &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(j\)&lt;/span&gt; ends at its intersection with &lt;span style=&quot;white-space:nowrap&quot;&gt;line \(i\),&lt;/span&gt; we know on which side of the intersection to find the starting &lt;span style=&quot;white-space:nowrap&quot;&gt;point \(x_j\),&lt;/span&gt; and therefore, we know the sign &lt;span style=&quot;white-space:nowrap&quot;&gt;of \(x_j-e_{ji}\).&lt;/span&gt; We can use this knowledge to replace \(\vert x_j-e_{ji}\vert\) by either \(x_j-e_{ji}\) or \(e_{ji}-x_j\) (whichever of these two expressions is guaranteed to be non-negative), eliminating the right absolute value.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once these replacements have been made, we have a linear program with two variables per inequality, which can be solved in (strongly) polynomial time.&lt;/p&gt;

&lt;p&gt;But all this made me wonder: can we always turn a system of inequaties between linear distances like this into a linear program? Suppose we have an arbitrary system of variables \(x_i\) and an arbitrary system of &lt;span style=&quot;white-space:nowrap&quot;&gt;inequalities \(\vert x_i-e_{ij}\vert\le \vert x_j-e_{ji}\vert\),&lt;/span&gt; not coming from Gilbert tessellation recognition. Can we determine whether such a system has a solution, efficiently? Can we maybe turn any system of inequalities like this into a linear program, and solve it that way?&lt;/p&gt;

&lt;p&gt;No! The problem is &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\mathsf{NP}\)-complete.&lt;/span&gt; The illustration below shows the key gadget, a system of six inequalities for two variables (each shown with a small blue double wedge in the plane pointing towards the points that obey the inequality). These inequalities have only the three red points shown as their solutions. You might want only one inequality per pair of variables, but in that case you can get the same effect by replacing each inequality by a pair of inequalities involving an additional dummy variable. The &lt;span style=&quot;white-space:nowrap&quot;&gt;\(\mathsf{NP}\)-completeness&lt;/span&gt; proof is a reduction from graph 3-coloring that translates each vertex into one of these gadgets, and represents the color of a vertex by the choice of which red point is used to solve these inequalities. I haven’t shown the edge gadgets, but it’s easy to find more inequalities to use for a pair of vertices, to force them to have different red points as their solutions. For instance, the &lt;span style=&quot;white-space:nowrap&quot;&gt;inequality \(\vert x_i\vert\ge\vert y_j-1\vert\)&lt;/span&gt; fails only for two vertices that both use the same red point \((0,0)\).&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;/blog/assets/2022/vertex-gadget.svg&quot; alt=&quot;Vertex gadget for reduction from 3-coloring to linear distance comparison, consisting of six inequalities abs(x) ≤ abs(y-4), abs(x+2) ≥ abs(y-2), abs(x-2) ≥ abs(y-2), abs(x+1) ≥ abs(y+1), abs(x-1) ≥ abs(y+1), and abs(x) ≤ abs(y+2), that force the two variables (x,y) to have one of the three combinations of values (3,1), (-3,1), or (0,0)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So somehow, the geometry of Gilbert tessellations is essential for the ability to convert their recognition problem into a linear program, and solve it efficiently.&lt;/p&gt;

&lt;p&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/108977122069764388&quot;&gt;Discuss on Mastodon&lt;/a&gt;)&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </description>
  <pubDate>2022-09-10 17:26:00 UTC</pubDate>
  <author>David Eppstein</author>
</item>

<item>
  <title>Provable Broadcast</title>
  <guid>https://decentralizedthoughts.github.io/2022-09-10-provable-broadcast/</guid>
  <link>https://decentralizedthoughts.github.io/2022-09-10-provable-broadcast/</link>
  <description>
    We explore a family of broadcast protocols in the authenticated setting in which a designated sender wants to create a delivery-certificate of its input value. After describing the base protocol we call Provable Broadcast ($PB$), we explore the surprising power of simply running $PB$ two times in a row, then...
  </description>
  <pubDate>2022-09-10 12:00:00 UTC</pubDate>
  <author>Decentralized Thoughts</author>
</item>

<item>
  <title>faculty at University of Oxford (apply by December 14, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/09/09/faculty-at-university-of-oxford-apply-by-december-14-2022/</guid>
  <link>https://cstheory-jobs.org/2022/09/09/faculty-at-university-of-oxford-apply-by-december-14-2022/</link>
  <description>
    &lt;p&gt;Oxford University’s Computer Science Department is hiring four new faculty. The positions are open to all areas of computer science and the closing date is 12 noon on 14 December 2022.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://www.cs.ox.ac.uk/aboutus/vacancies/vacancy-faculty-hiring.html&quot;&gt;https://www.cs.ox.ac.uk/aboutus/vacancies/vacancy-faculty-hiring.html&lt;/a&gt;&lt;br /&gt;
Email: hr@cs.ox.ac.uk&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-09-09 09:25:08 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>TR22-125 |  Tensor Reconstruction Beyond Constant Rank | 

	Shir Peleg, 

	Amir Shpilka, 

	Ben Lee Volk</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/125</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/125</link>
  <description>
    We give reconstruction algorithms for subclasses of depth-$3$ arithmetic circuits. In particular, we obtain the first efficient algorithm for finding tensor rank, and an optimal tensor decomposition as a sum of rank-one tensors, when given black-box access to a tensor of super-constant rank.  Specifically, we obtain the following results:

1. A deterministic algorithm that reconstructs polynomials computed by $\Sigma^{[k]}\bigwedge^{[d]}\Sigma$ circuits in time $\mathrm{poly}(n,d,c) \cdot \mathrm{poly}(k)^{k^{k^{10}}}$,
2. A randomized algorithm that reconstructs polynomials computed by multilinear $\Sigma^{[k]}\prod^{[d]}\Sigma$ circuits in time $\mathrm{poly}(n,d,c) \cdot k^{k^{k^{k^{O(k)}}}}$, 
3. A randomized algorithm that reconstructs polynomials computed by set-multilinear $\Sigma^{[k]}\prod^{[d]}\Sigma$ circuits in time $\mathrm{poly}(n,d,c) \cdot k^{k^{k^{k^{O(k)}}}}$,

where $c=\log q$ if $\mathbb{F}=\mathbb{F}_q$ is a finite field, and $c$ equals the maximum bit complexity of any coefficient of $f$ if $\mathbb{F}$ is infinite.
		
Prior to our work, polynomial time algorithms for the case when the rank, $k$, is constant, were given by Bhargava, Saraf and Volkovich ([BSV21]). 
		
Another contribution of this work is correcting an error from a paper of Karnin and Shpilka [KS09] (with some loss in parameters) that also affected Theorem 1.6 of [BSV21]. Consequently, the results of [KS09, BSV21] continue to hold, with a slightly worse setting of parameters. For fixing the error we systematically study the relation between syntactic  and semantic notions of rank of $\Sigma\Pi\Sigma$ circuits, and the corresponding partitions of such circuits. 
		
We obtain our improved running time by introducing a technique for learning rank preserving coordinate-subspaces. Both [KS09] and [BSV21] tried all choices of finding the &amp;quot;correct&amp;quot; coordinates, which, due to the size of the set, led to having a fast growing function of $k$ at the exponent of $n$. We manage to find these spaces in time that is still growing fast with $k$, yet it is only a fixed polynomial in $n$.
  </description>
  <pubDate>2022-09-09 09:12:30 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>TR22-124 |  On Interactive Proofs of Proximity with Proof-Oblivious Queries | 

	Oded Goldreich, 

	Guy Rothblum, 

	Tal Skverer</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/124</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/124</link>
  <description>
    Interactive proofs of proximity (IPPs) offer ultra-fast
approximate verification of assertions regarding their input,
where ultra-fast means that only a small portion of the input is read
and approximate verification is analogous to the notion of
approximate decision that underlies property testing.
Specifically, in an IPP, the prover can make the verifier
accept each input in the property, but cannot fool the verifier
into accepting an input that is far from the property
(except for with small probability).

The verifier in an IPP system engages in two very different types 
of activities: interacting with an untrusted prover, and querying its input. 
The definition allows for arbitrary coordination between these two activities, 
but keeping them separate is both conceptually interesting 
and necessary for important applications 
such as addressing temporal considerations 
(i.e., at what time is each of the services available)
and facilitating the construction of zero-knowledge schemes. 
In this work we embark on a systematic study of IPPs 
with proof-oblivious queries, where the queries should not be affected 
by the interaction with the prover. 
We assign the query and interaction activities to separate modules, 
and consider different limitations on their coordination.

The most strict limitation requires these activities to
be totally isolated from one another; they just feed
their views to a separate deciding module. 
We show that such systems can be efficiently emulated by standard testers.

Going to the other extreme, we only disallow information
to flow from the interacting module to the querying module,
but allow free information flow in the other direction.
We show that extremely efficient one-round (i.e., two-message) systems 
of such type can be used to verify properties that are extremely
hard to test (without the help of a prover).
That is, the complexity of verifying can be polylogarithmic in the complexity of testing.
This stands in contrast the MAPs (viewed as $1/2$-round systems)
in which proof-oblivious queries are as limited as our isolated model.

Our focus is on an intermediate model that allows
shared randomness among the querying and interacting modules 
but no information flow between them. 
In this case we show 
that 1-round systems are efficiently emulated by standard testers 
but $3/2$-round systems of extremely low complexity 
exist for properties that are extremely hard to test. 
One additional result about this model is that it can
efficiently emulate any IPP for any property of low-degree polynomials.
  </description>
  <pubDate>2022-09-09 08:31:15 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Counting Subgraphs in Somewhere Dense Graphs</title>
  <guid>http://arxiv.org/abs/2209.03402</guid>
  <link>http://arxiv.org/abs/2209.03402</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bressan_M/0/1/0/all/0/1&quot;&gt;Marco Bressan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_L/0/1/0/all/0/1&quot;&gt;Leslie Ann Goldberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meeks_K/0/1/0/all/0/1&quot;&gt;Kitty Meeks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_M/0/1/0/all/0/1&quot;&gt;Marc Roth&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problems of counting copies and induced copies of a small
pattern graph $H$ in a large host graph $G$. Recent work fully classified the
complexity of those problems according to structural restrictions on the
patterns $H$. In this work, we address the more challenging task of analysing
the complexity for restricted patterns and restricted hosts. Specifically we
ask which families of allowed patterns and hosts imply fixed-parameter
tractability, i.e., the existence of an algorithm running in time $f(H)\cdot
|G|^{O(1)}$ for some computable function $f$. Our main results present
exhaustive and explicit complexity classifications for families that satisfy
natural closure properties. Among others, we identify the problems of counting
small matchings and independent sets in subgraph-closed graph classes
$\mathcal{G}$ as our central objects of study and establish the following crisp
dichotomies as consequences of the Exponential Time Hypothesis: (1) Counting
$k$-matchings in a graph $G\in\mathcal{G}$ is fixed-parameter tractable if and
only if $\mathcal{G}$ is nowhere dense. (2) Counting $k$-independent sets in a
graph $G\in\mathcal{G}$ is fixed-parameter tractable if and only if
$\mathcal{G}$ is nowhere dense. Moreover, we obtain almost tight conditional
lower bounds if $\mathcal{G}$ is somewhere dense, i.e., not nowhere dense.
These base cases of our classifications subsume a wide variety of previous
results on the matching and independent set problem, such as counting
$k$-matchings in bipartite graphs (Curticapean, Marx; FOCS 14), in
$F$-colourable graphs (Roth, Wellnitz; SODA 20), and in degenerate graphs
(Bressan, Roth; FOCS 21), as well as counting $k$-independent sets in bipartite
graphs (Curticapean et al.; Algorithmica 19).
&lt;/p&gt;
  </description>
  <pubDate>2022-09-09 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Synthesizing efficient circuits for Hamiltonian simulation</title>
  <guid>http://arxiv.org/abs/2209.03478</guid>
  <link>http://arxiv.org/abs/2209.03478</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Mukhopadhyay_P/0/1/0/all/0/1&quot;&gt;Priyanka Mukhopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wiebe_N/0/1/0/all/0/1&quot;&gt;Nathan Wiebe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hong Tao Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We provide a new approach for compiling quantum simulation circuits that
appear in Trotter, qDRIFT and multi-product formulas to Clifford and
non-Clifford operations that can reduce the number of non-Clifford operations
by a factor of up to $4$. The central idea behind our approach is to collect
mutually commuting Hamiltonian terms into groups that satisfy one of several
symmetries identified in this work which allow an inexpensive simulation of the
entire group of terms. We further show that the cost can in some cases be
reduced by partially allocating Hamiltonian terms to several groups and provide
a polynomial time classical algorithm that can greedily allocate the terms to
appropriate groupings. We further specifically discuss these optimizations for
the case of fermionic dynamics and provide extensive numerical simulations for
qDRIFT of our grouping strategy to 6 and 4-qubit Heisenberg models, $LiH$,
$H_2$ and observe a factor of 1.8-3.2 reduction in the number of non-Clifford
gates. This suggests Trotter-based simulation of chemistry in second
quantization may be even more practical than previously believed.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-09 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Epic Fail: Emulators can tolerate polynomially many edge faults for free</title>
  <guid>http://arxiv.org/abs/2209.03675</guid>
  <link>http://arxiv.org/abs/2209.03675</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bodwin_G/0/1/0/all/0/1&quot;&gt;Greg Bodwin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dinitz_M/0/1/0/all/0/1&quot;&gt;Michael Dinitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nazari_Y/0/1/0/all/0/1&quot;&gt;Yasamin Nazari&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A $t$-emulator of a graph $G$ is a graph $H$ that approximates its pairwise
shortest path distances up to multiplicative $t$ error. We study fault tolerant
$t$-emulators, under the model recently introduced by Bodwin, Dinitz, and
Nazari [ITCS 2022] for vertex failures. In this paper we consider the version
for edge failures, and show that they exhibit surprisingly different behavior.
&lt;/p&gt;
&lt;p&gt;In particular, our main result is that, for $(2k-1)$-emulators with $k$ odd,
we can tolerate a polynomial number of edge faults for free. For example: for
any $n$-node input graph, we construct a $5$-emulator ($k=3$) on $O(n^{4/3})$
edges that is robust to $f = O(n^{2/9})$ edge faults. It is well known that
$\Omega(n^{4/3})$ edges are necessary even if the $5$-emulator does not need to
tolerate any faults. Thus we pay no extra cost in the size to gain this fault
tolerance. We leave open the precise range of free fault tolerance for odd $k$,
and whether a similar phenomenon can be proved for even $k$.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-09 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Packing $K_r$s in bounded degree graphs</title>
  <guid>http://arxiv.org/abs/2209.03684</guid>
  <link>http://arxiv.org/abs/2209.03684</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McKay_M/0/1/0/all/0/1&quot;&gt;Michael McKay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manlove_D/0/1/0/all/0/1&quot;&gt;David Manlove&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problem of finding a maximum-cardinality set of $r$-cliques in
an undirected graph of fixed maximum degree $\Delta$, subject to the cliques in
that set being either vertex-disjoint or edge-disjoint. It is known for $r=3$
that the vertex-disjoint (edge-disjoint) problem is solvable in linear time if
$\Delta=3$ ($\Delta=4$) but APX-hard if $\Delta \geq 4$ ($\Delta \geq 5$).
&lt;/p&gt;
&lt;p&gt;We generalise these results to an arbitrary but fixed $r \geq 3$, and provide
a complete complexity classification for both the vertex- and edge-disjoint
variants in graphs of maximum degree $\Delta$.
&lt;/p&gt;
&lt;p&gt;Specifically, we show that the vertex-disjoint problem is solvable in linear
time if $\Delta &amp;lt; 3r/2 - 1$, solvable in polynomial time if $\Delta &amp;lt; 5r/3 -
1$, and APX-hard if $\Delta \geq \lceil 5r/3 \rceil - 1$. We also show that if
$r\geq 6$ then the above implications also hold for the edge-disjoint problem.
If $r \leq 5$, then the edge-disjoint problem is solvable in linear time if
$\Delta &amp;lt; 3r/2 - 1$, solvable in polynomial time if $\Delta \leq 2r - 2$, and
APX-hard if $\Delta &amp;gt; 2r - 2$.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-09 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Routing permutations on spectral expanders via matchings</title>
  <guid>http://arxiv.org/abs/2209.03838</guid>
  <link>http://arxiv.org/abs/2209.03838</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nenadov_R/0/1/0/all/0/1&quot;&gt;Rajko Nenadov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the following matching-based routing problem. Initially, each
vertex $v$ of a connected graph $G$ is occupied by a pebble which has a unique
destination $\pi(v)$. In each round the pebbles across the edges of a selected
matching in $G$ are swapped, and the goal is to route each pebble to its
destination vertex in as few rounds as possible. We show that if $G$ is a
sufficiently strong $d$-regular spectral expander then any permutation $\pi$
can be achieved in $O(\log n)$ rounds. This is optimal for constant $d$ and
resolves a problem of Alon, Chung, and Graham [SIAM J. Discrete Math., 7
(1994), pp. 516--530].
&lt;/p&gt;
  </description>
  <pubDate>2022-09-09 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Opponent Indifference in Rating Systems: A Theoretical Case for Sonas</title>
  <guid>http://arxiv.org/abs/2209.03950</guid>
  <link>http://arxiv.org/abs/2209.03950</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bodwin_G/0/1/0/all/0/1&quot;&gt;Greg Bodwin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Forest Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In competitive games, it is common to assign each player a real number rating
signifying their skill level. A rating system is a procedure by which player
ratings are adjusted upwards each time they win, or downwards each time they
lose.
&lt;/p&gt;
&lt;p&gt;Many matchmaking systems give players some control over their opponent&#39;s
rating; for example, a player might be able to selectively initiate matches
against opponents whose ratings are publicly visible, or abort a match without
penalty before it begins but after glimpsing their opponent&#39;s rating. It is
natural to ask whether one can design a rating system that does not incentivize
a rating-maximizing player to act strategically, seeking matches against
opponents of one rating over another. We show the following:
&lt;/p&gt;
&lt;p&gt;- The full version of this &quot;opponent indifference&quot; property is unfortunately
too strong to be feasible. Although it is satisfied by some rating systems,
these systems lack certain desirable expressiveness properties, suggesting that
they are not suitable to capture most games of interest.
&lt;/p&gt;
&lt;p&gt;- However, there is a natural relaxation, roughly requiring indifference
between any two opponents who are ``reasonably evenly matched&#39;&#39; with the
choosing player. We prove that this relaxed variant of opponent indifference,
which we call $P$ opponent indifference, is viable. In fact, a certain strong
version of $P$ opponent indifference precisely characterizes the rating system
Sonas, which was originally proposed for its empirical predictive accuracy on
the outcomes of high-level chess matches.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-09 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Concentration bounds for quantum states and limitations on the QAOA from polynomial approximations</title>
  <guid>http://arxiv.org/abs/2209.02715</guid>
  <link>http://arxiv.org/abs/2209.02715</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Anshu_A/0/1/0/all/0/1&quot;&gt;Anurag Anshu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Metger_T/0/1/0/all/0/1&quot;&gt;Tony Metger&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove concentration bounds for the following classes of quantum states:
(i) output states of shallow quantum circuits, answering an open question from
[DPMRF22]; (ii) injective matrix product states; (iii) output states of dense
Hamiltonian evolution, i.e. states of the form $e^{\iota H^{(p)}} \cdots
e^{\iota H^{(1)}} |\psi_0\rangle$ for any $n$-qubit product state
$|\psi_0\rangle$, where each $H^{(i)}$ can be any local commuting Hamiltonian
satisfying a norm constraint, including dense Hamiltonians with interactions
between any qubits. Our proofs use polynomial approximations to show that these
states are close to local operators. This implies that the distribution of the
Hamming weight of a computational basis measurement (and of other related
observables) concentrates. An example of (iii) are the states produced by the
quantum approximate optimisation algorithm (QAOA). Using our concentration
results for these states, we show that for a random spin model, the QAOA can
only succeed with negligible probability even at super-constant level $p =
o(\log \log n)$. This gives the first limitations on the QAOA on dense
instances at super-constant level, improving upon the recent result [BGMZ22].
&lt;/p&gt;
  </description>
  <pubDate>2022-09-08 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Learning Distributions over Quantum Measurement Outcomes</title>
  <guid>http://arxiv.org/abs/2209.03007</guid>
  <link>http://arxiv.org/abs/2209.03007</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gong_W/0/1/0/all/0/1&quot;&gt;Weiyuan Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Aaronson_S/0/1/0/all/0/1&quot;&gt;Scott Aaronson&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Shadow tomography for quantum states provides a sample efficient approach for
predicting the properties of quantum systems when the properties are restricted
to expectation values of $2$-outcome POVMs. However, these shadow tomography
procedures yield poor bounds if there are more than 2 outcomes per measurement.
In this paper, we consider a general problem of learning properties from
unknown quantum states: given an unknown $d$-dimensional quantum state $\rho$
and $M$ unknown quantum measurements $\mathcal{M}_1,...,\mathcal{M}_M$ with
$K\geq 2$ outcomes, estimating the probability distribution for applying
$\mathcal{M}_i$ on $\rho$ to within total variation distance $\epsilon$.
Compared to the special case when $K=2$, we need to learn unknown distributions
instead of values. We develop an online shadow tomography procedure that solves
this problem with high success probability requiring $\tilde{O}(K\log^2M\log
d/\epsilon^4)$ copies of $\rho$. We further prove an information-theoretic
lower bound that at least $\Omega(\min\{d^2,K+\log M\}/\epsilon^2)$ copies of
$\rho$ are required to solve this problem with high success probability. Our
shadow tomography procedure requires sample complexity with only logarithmic
dependence on $M$ and $d$ and is sample-optimal for the dependence on $K$.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-08 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>A learning theory for quantum photonic processors and beyond</title>
  <guid>http://arxiv.org/abs/2209.03075</guid>
  <link>http://arxiv.org/abs/2209.03075</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rosati_M/0/1/0/all/0/1&quot;&gt;Matteo Rosati&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the tasks of learning quantum states, measurements and channels
generated by continuous-variable (CV) quantum circuits. This family of circuits
is suited to describe optical quantum technologies and in particular it
includes state-of-the-art photonic processors capable of showing quantum
advantage. We define classes of functions that map classical variables, encoded
into the CV circuit parameters, to outcome probabilities evaluated on those
circuits. We then establish efficient learnability guarantees for such classes,
by computing bounds on their pseudo-dimension or covering numbers, showing that
CV quantum circuits can be learned with a sample complexity that scales
polynomially with the circuit&#39;s size, i.e., the number of modes. Our results
establish that CV circuits can be trained efficiently using a number of
training samples that, unlike their finite-dimensional counterpart, does not
scale with the circuit depth.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-08 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>On Plane Subgraphs of Complete Topological Drawings</title>
  <guid>http://arxiv.org/abs/2209.03072</guid>
  <link>http://arxiv.org/abs/2209.03072</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_A/0/1/0/all/0/1&quot;&gt;Alfredo Garc&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilz_A/0/1/0/all/0/1&quot;&gt;Alexander Pilz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tejel_J/0/1/0/all/0/1&quot;&gt;Javier Tejel&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Topological drawings are representations of graphs in the plane, where
vertices are represented by points, and edges by simple curves connecting the
points. A drawing is simple if two edges intersect at most in a single point,
either at a common endpoint or at a proper crossing. In this paper we study
properties of maximal plane subgraphs of simple drawings $D_n$ of the complete
graph $K_n$ on $n$ vertices. Our main structural result is that maximal plane
subgraphs are 2-connected and what we call essentially 3-edge-connected.
Besides, any maximal plane subgraph contains at least $\lceil 3n/2 \rceil$
edges. We also address the problem of obtaining a plane subgraph of $D_n$ with
the maximum number of edges, proving that this problem is NP-complete. However,
given a plane spanning connected subgraph of $D_n$, a maximum plane
augmentation of this subgraph can be found in $O(n^3)$ time. As a side result,
we also show that the problem of finding a largest compatible plane
straight-line graph of two labeled point sets is NP-complete.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-08 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Manifold Free Riemannian Optimization</title>
  <guid>http://arxiv.org/abs/2209.03269</guid>
  <link>http://arxiv.org/abs/2209.03269</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shustin_B/0/1/0/all/0/1&quot;&gt;Boris Shustin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Avron_H/0/1/0/all/0/1&quot;&gt;Haim Avron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sober_B/0/1/0/all/0/1&quot;&gt;Barak Sober&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Riemannian optimization is a principled framework for solving optimization
problems where the desired optimum is constrained to a smooth manifold
$\mathcal{M}$. Algorithms designed in this framework usually require some
geometrical description of the manifold, which typically includes tangent
spaces, retractions, and gradients of the cost function. However, in many
cases, only a subset (or none at all) of these elements can be accessed due to
lack of information or intractability. In this paper, we propose a novel
approach that can perform approximate Riemannian optimization in such cases,
where the constraining manifold is a submanifold of $\R^{D}$. At the bare
minimum, our method requires only a noiseless sample set of the cost function
$(\x_{i}, y_{i})\in {\mathcal{M}} \times \mathbb{R}$ and the intrinsic
dimension of the manifold $\mathcal{M}$. Using the samples, and utilizing the
Manifold-MLS framework (Sober and Levin 2020), we construct approximations of
the missing components entertaining provable guarantees and analyze their
computational costs. In case some of the components are given analytically
(e.g., if the cost function and its gradient are given explicitly, or if the
tangent spaces can be computed), the algorithm can be easily adapted to use the
accurate expressions instead of the approximations. We analyze the global
convergence of Riemannian gradient-based methods using our approach, and we
demonstrate empirically the strength of this method, together with a
conjugate-gradients type method based upon similar principles.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-08 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>$1D$ to $nD$: A Meta Algorithm for Multivariate Global Optimization via Univariate Optimizers</title>
  <guid>http://arxiv.org/abs/2209.03246</guid>
  <link>http://arxiv.org/abs/2209.03246</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gokcesu_K/0/1/0/all/0/1&quot;&gt;Kaan Gokcesu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gokcesu_H/0/1/0/all/0/1&quot;&gt;Hakan Gokcesu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work, we propose a meta algorithm that can solve a multivariate
global optimization problem using univariate global optimizers. Although the
univariate global optimization does not receive much attention compared to the
multivariate case, which is more emphasized in academia and industry; we show
that it is still relevant and can be directly used to solve problems of
multivariate optimization. We also provide the corresponding regret bounds in
terms of the time horizon $T$ and the average regret of the univariate
optimizer, when it is robust against nonnegative noises with robust regret
guarantees.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-08 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Constructing Optimal Contraction Trees for Tensor Network Quantum Circuit Simulation</title>
  <guid>http://arxiv.org/abs/2209.02895</guid>
  <link>http://arxiv.org/abs/2209.02895</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ibrahim_C/0/1/0/all/0/1&quot;&gt;Cameron Ibrahim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lykov_D/0/1/0/all/0/1&quot;&gt;Danylo Lykov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zichang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Alexeev_Y/0/1/0/all/0/1&quot;&gt;Yuri Alexeev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Safro_I/0/1/0/all/0/1&quot;&gt;Ilya Safro&lt;/a&gt;&lt;/p&gt;&lt;p&gt;One of the key problems in tensor network based quantum circuit simulation is
the construction of a contraction tree which minimizes the cost of the
simulation, where the cost can be expressed in the number of operations as a
proxy for the simulation running time. This same problem arises in a variety of
application areas, such as combinatorial scientific computing, marginalization
in probabilistic graphical models, and solving constraint satisfaction
problems. In this paper, we reduce the computationally hard portion of this
problem to one of graph linear ordering, and demonstrate how existing
approaches in this area can be utilized to achieve results up to several orders
of magnitude better than existing state of the art methods for the same running
time. To do so, we introduce a novel polynomial time algorithm for constructing
an optimal contraction tree from a given order. Furthermore, we introduce a
fast and high quality linear ordering solver, and demonstrate its applicability
as a heuristic for providing orderings for contraction trees. Finally, we
compare our solver with competing methods for constructing contraction trees in
quantum circuit simulation on a collection of randomly generated Quantum
Approximate Optimization Algorithm Max Cut circuits and show that our method
achieves superior results on a majority of tested quantum circuits.
&lt;/p&gt;
&lt;p&gt;Reproducibility: Our source code and data are available at
https://github.com/cameton/HPEC2022_ContractionTrees.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-08 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>\~{O}ptimal Vertex Fault-Tolerant Spanners in \~{O}ptimal Time: Sequential, Distributed and Parallel</title>
  <guid>http://arxiv.org/abs/2209.02990</guid>
  <link>http://arxiv.org/abs/2209.02990</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parter_M/0/1/0/all/0/1&quot;&gt;Merav Parter&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We (nearly) settle the time complexity for computing vertex fault-tolerant
(VFT) spanners with optimal sparsity (up to polylogarithmic factors). VFT
spanners are sparse subgraphs that preserve distance information, up to a small
multiplicative stretch, in the presence of vertex failures. These structures
were introduced by [Chechik et al., STOC 2009] and have received a lot of
attention since then. We provide algorithms for computing nearly optimal
$f$-VFT spanners for any $n$-vertex $m$-edge graph, with near optimal running
time in several computational models:
&lt;/p&gt;
&lt;p&gt;- A randomized sequential algorithm with a runtime of $\widetilde{O}(m)$
(i.e., independent in the number of faults $f$). The state-of-the-art time
bound is $\widetilde{O}(f^{1-1/k}\cdot n^{2+1/k}+f^2 m)$ by [Bodwin, Dinitz and
Robelle, SODA 2021].
&lt;/p&gt;
&lt;p&gt;- A distributed congest algorithm of $\widetilde{O}(1)$ rounds. Improving
upon [Dinitz and Robelle, PODC 2020] that obtained FT spanners with
near-optimal sparsity in $\widetilde{O}(f^{2})$ rounds.
&lt;/p&gt;
&lt;p&gt;- A PRAM (CRCW) algorithm with $\widetilde{O}(m)$ work and $\widetilde{O}(1)$
depth. Prior bounds implied by [Dinitz and Krauthgamer, PODC 2011] obtained
sub-optimal FT spanners using $\widetilde{O}(f^3m)$ work and
$\widetilde{O}(f^3)$ depth.
&lt;/p&gt;
&lt;p&gt;An immediate corollary provides the first nearly-optimal PRAM algorithm for
computing nearly optimal $\lambda$-\emph{vertex} connectivity certificates
using polylogarithmic depth and near-linear work. This improves the
state-of-the-art parallel bounds of $\widetilde{O}(1)$ depth and $O(\lambda m)$
work, by [Karger and Motwani, STOC&#39;93].
&lt;/p&gt;
  </description>
  <pubDate>2022-09-08 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Local Search Algorithm for the Min-Sum Submodular Cover Problem</title>
  <guid>http://arxiv.org/abs/2209.03054</guid>
  <link>http://arxiv.org/abs/2209.03054</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hellerstein_L/0/1/0/all/0/1&quot;&gt;Lisa Hellerstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lidbetter_T/0/1/0/all/0/1&quot;&gt;Thomas Lidbetter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witter_R/0/1/0/all/0/1&quot;&gt;R. Teal Witter&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of solving the Min-Sum Submodular Cover problem using
local search. The Min-Sum Submodular Cover problem generalizes the NP-complete
Min-Sum Set Cover problem, replacing the input set cover instance with a
monotone submodular set function. A simple greedy algorithm achieves an
approximation factor of 4, which is tight unless P=NP [Streeter and Golovin,
NeurIPS, 2008]. We complement the greedy algorithm with analysis of a local
search algorithm. Building on work of Munagala et al. [ICDT, 2005], we show
that, using simple initialization, a straightforward local search algorithm
achieves a $(4+\epsilon)$-approximate solution in time
$O(n^3\log(n/\epsilon))$, provided that the monotone submodular set function is
also second-order supermodular. Second-order supermodularity has been shown to
hold for a number of submodular functions of practical interest, including
functions associated with set cover, matching, and facility location. We
present experiments on two special cases of Min-Sum Submodular Cover and find
that the local search algorithm can outperform the greedy algorithm on small
data sets.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-08 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

</channel>
</rss>
