<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>Faculty at Rutgers University (New Brunswick) (apply by January 3, 2023)</title>
  <guid>http://cstheory-jobs.org/2022/11/21/faculty-at-rutgers-university-new-brunswick-apply-by-january-3-2023/</guid>
  <link>https://cstheory-jobs.org/2022/11/21/faculty-at-rutgers-university-new-brunswick-apply-by-january-3-2023/</link>
  <description>
    &lt;p&gt;The Computer Science Department at Rutgers University, New Brunswick NJ, invites applications for multiple tenure-track/tenured. We invite applications from candidates specializing in any area of CS, and welcome applicants with interdisciplinary approaches. We are especially interested in Algorithms, Machine Learning and Data Science, High-performance Computing and Scalable Systems.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://jobs.rutgers.edu/postings/183703&quot;&gt;https://jobs.rutgers.edu/postings/183703&lt;/a&gt;&lt;br /&gt;
Email: hiring-committee@cs.rutgers.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-21 19:14:14 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>A Celebration of Juris</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-5196164101457278361</guid>
  <link>http://blog.computationalcomplexity.org/2022/11/a-celebration-of-juris.html</link>
  <description>
    &lt;p&gt;&lt;/p&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxWze7urg3GUKNZRP8vI4maCWwNHi1JQkVcFCRfLas3dZQbmvYZz4jLurkuCXLAiLOFmKXjg7QAFHh5iNwt2vCR4ONgOSIHSBRpw1cC0rQjCvm9bKSSREiDMmPRLK8N3xtg9la8HCM7yr1iOTwP9v4FWv1eYhwGAQoF6JrbXlEZvw8LR-kug/s4080/PXL_20221104_140728676.jpg&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;3072&quot; data-original-width=&quot;4080&quot; height=&quot;241&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxWze7urg3GUKNZRP8vI4maCWwNHi1JQkVcFCRfLas3dZQbmvYZz4jLurkuCXLAiLOFmKXjg7QAFHh5iNwt2vCR4ONgOSIHSBRpw1cC0rQjCvm9bKSSREiDMmPRLK8N3xtg9la8HCM7yr1iOTwP9v4FWv1eYhwGAQoF6JrbXlEZvw8LR-kug/s320/PXL_20221104_140728676.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;On November 4th I travelled to my undergraduate alma mater Cornell for a &lt;a href=&quot;https://cis.cornell.edu/bowers-cis-community-celebrates-life-juris-hartmanis&quot;&gt;Celebration of the Life and Career of Juris Hartmanis&lt;/a&gt;&amp;nbsp;who &lt;a href=&quot;https://blog.computationalcomplexity.org/2022/08/the-godfather-of-complexity.html&quot;&gt;passed away&lt;/a&gt; in July. The workshop attracted many Cornell faculty and students, many of Hartmanis&#39; former colleague and students, grad and undergrad, as well as his family. For the most part, the talks did not focus on technical content but rather memories of the great man.&amp;nbsp;&lt;p&gt;&lt;/p&gt;&lt;p&gt;I &lt;a href=&quot;https://www.youtube.com/watch?v=ACxU-90O-ag&amp;amp;t=2768s&quot;&gt;talked about&lt;/a&gt;&amp;nbsp;how Hartmanis founded the field of Computational Complexity and brought me into it. Herbert Lin &lt;a href=&quot;https://www.youtube.com/watch?v=QKW_GalI31o&amp;amp;t=2900s&quot;&gt;told the story&lt;/a&gt; behind &lt;a href=&quot;https://www.google.com/books/edition/Computing_the_Future/tYBQAAAAMAAJ&quot;&gt;Computing the Future&lt;/a&gt;, a 1992 agenda for the future of computer science led by Hartmanis and the challenge to the report by John McCarthy, one of the founders of AI. Should the agenda of computer science be solely in the hands of academic computer scientists, or should it take into account its role in the larger scientific and world-wide community? We still face these questions today.&lt;/p&gt;&lt;p&gt;Ryan Williams gave &lt;a href=&quot;https://www.youtube.com/watch?v=ACxU-90O-ag&amp;amp;t=10350s&quot;&gt;a powerful talk&lt;/a&gt;&amp;nbsp;about how Hartmanis personally intervened to ensure Ryan had a future in complexity. We are all better off for that.&lt;/p&gt;&lt;p&gt;After the workshop, Ryan and I walked around the campus and Collegetown reminiscing on how things have changed in the two decades since Ryan was an undergrad and the four decades (!) since I was. Most of the bars and restaurants have disappeared. The Arts quad is mostly the same, while the engineering building have been mostly rebuilt. There&#39;s a &lt;a href=&quot;https://www.engineering.cornell.edu/magazine/features/gates-hall-new-home-cis&quot;&gt;new computer science building&lt;/a&gt; with &lt;a href=&quot;https://ithacavoice.com/2022/05/cornell-plans-new-computer-science-building-on-hoy-field/&quot;&gt;another on the way&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;&lt;p&gt;I stayed in town to catch the Cornell football game the next day, as I once was on that field playing tuba for the marching band. They tore down the west stands to put up a parking lot and the east stands were sparsely filled watching Penn dominate the game.&lt;/p&gt;&lt;p&gt;Good bye Juris. You created a discipline, started one of the first CS departments, and plotted the future of both computational complexity and computer science as a whole. A master and commander indeed.&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2022-11-21 14:52:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>Computational Short Cuts in Infinite Domain Constraint Satisfaction</title>
  <guid>http://arxiv.org/abs/2211.10144</guid>
  <link>http://arxiv.org/abs/2211.10144</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jonsson_P/0/1/0/all/0/1&quot;&gt;Peter Jonsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lagerkvist_V/0/1/0/all/0/1&quot;&gt;Victor Lagerkvist&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ordyniak_S/0/1/0/all/0/1&quot;&gt;Sebastian Ordyniak&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A backdoor in a finite-domain CSP instance is a set of variables where each
possible instantiation moves the instance into a polynomial-time solvable
class. Backdoors have found many applications in artificial intelligence and
elsewhere, and the algorithmic problem of finding such backdoors has
consequently been intensively studied. Sioutis and Janhunen (Proc. 42nd German
Conference on AI (KI-2019)) have proposed a generalised backdoor concept
suitable for infinite-domain CSP instances over binary constraints. We
generalise their concept into a large class of CSPs that allow for higher-arity
constraints. We show that this kind of infinite-domain backdoors have many of
the positive computational properties that finite-domain backdoors have: the
associated computational problems are fixed-parameter tractable whenever the
underlying constraint language is finite. On the other hand, we show that
infinite languages make the problems considerably harder: the general backdoor
detection problem is W[2]-hard and fixed-parameter tractability is ruled out
under standard complexity-theoretic assumptions. We demonstrate that backdoors
may have suboptimal behaviour on binary constraints -- this is detrimental from
an AI perspective where binary constraints are predominant in, for instance,
spatiotemporal applications. In response to this, we introduce sidedoors as an
alternative to backdoors. The fundamental computational problems for sidedoors
remain fixed-parameter tractable for finite constraint language (possibly also
containing non-binary relations). Moreover, the sidedoor approach has appealing
computational properties that sometimes leads to faster algorithms than the
backdoor approach.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-21 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Crossing and intersecting families of geometric graphs on point sets</title>
  <guid>http://arxiv.org/abs/2211.09904</guid>
  <link>http://arxiv.org/abs/2211.09904</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Alvarez_Rebollar_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Luis &amp;#xc1;lvarez-Rebollar&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cravioto_Lagos_J/0/1/0/all/0/1&quot;&gt;Jorge Cravioto-Lagos&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Marin_N/0/1/0/all/0/1&quot;&gt;Nestaly Mar&amp;#xed;n&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sole_Pi_O/0/1/0/all/0/1&quot;&gt;Oriol Sol&amp;#xe9;-Pi&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Urrutia_J/0/1/0/all/0/1&quot;&gt;Jorge Urrutia&lt;/a&gt; (4) ((1) Posgrado en Ciencias Matem&amp;#xe1;ticas, UNAM and Departamento de Ciencias B&amp;#xe1;sicas, Instituto Tecnol&amp;#xf3;gico de Zit&amp;#xe1;cuaro, (2) Posgrado en Ciencia e Ingenier&amp;#xed;a de la Computaci&amp;#xf3;n, UNAM, (3) Facultad de Ciencias, UNAM, (4) Instituto de Matem&amp;#xe1;ticas, UNAM)&lt;/p&gt;&lt;p&gt;Let $S$ be a set of $n$ points in the plane in general position. Two line
segments connecting pairs of points of $S$ cross if they have an interior point
in common. Two vertex disjoint geometric graphs with vertices in $S$ cross if
there are two edges, one from each graph, which cross. A set of vertex disjoint
geometric graphs with vertices in $S$ is called mutually crossing if any two of
them cross.
&lt;/p&gt;
&lt;p&gt;We show that there exists a constant $c$ such that from any family of $n$
mutually crossing triangles, one can always obtain a family of at least $n^c$
mutually crossing $2$-paths (each of which is the result of deleting an edge
from one of the triangles) and then provide an example that implies that $c$
cannot be taken to be larger than $2/3$. For every $n$ we determine the maximum
number of crossings that a Hamiltonian cycle on a set of $n$ points might have.
Next, we construct a point set whose longest perfect matching contains no
crossings. We also consider edges consisting of a horizontal and a vertical
line segment joining pairs of points of $S$, which we call elbows, and prove
that in any point set $S$ there exists a family of $\lfloor n/4 \rfloor$ vertex
disjoint mutually crossing elbows. Additionally, we show a point set that
admits no more than $n/3$ mutually crossing elbows.
&lt;/p&gt;
&lt;p&gt;Finally we study intersecting families of graphs, which are not necessarily
vertex disjoint. A set of edge disjoint graphs with vertices in $S$ is called
an intersecting family if for any two graphs in the set we can choose an edge
in each of them such that they cross. We prove a conjecture by Lara and
Rubio-Montiel, namely, that any set $S$ of $n$ points in general position
admits a family of intersecting triangles with a quadratic number of elements.
&lt;/p&gt;
&lt;p&gt;Some other results are obtained throughout this work.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-21 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Optimal Algorithms for Linear Algebra in the Current Matrix Multiplication Time</title>
  <guid>http://arxiv.org/abs/2211.09964</guid>
  <link>http://arxiv.org/abs/2211.09964</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cherapanamjeri_Y/0/1/0/all/0/1&quot;&gt;Yeshwanth Cherapanamjeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1&quot;&gt;Sandeep Silwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1&quot;&gt;David P. Woodruff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Samson Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study fundamental problems in linear algebra, such as finding a maximal
linearly independent subset of rows or columns (a basis), solving linear
regression, or computing a subspace embedding. For these problems, we consider
input matrices $\mathbf{A}\in\mathbb{R}^{n\times d}$ with $n &amp;gt; d$. The input
can be read in $\text{nnz}(\mathbf{A})$ time, which denotes the number of
nonzero entries of $\mathbf{A}$. In this paper, we show that beyond the time
required to read the input matrix, these fundamental linear algebra problems
can be solved in $d^{\omega}$ time, i.e., where $\omega \approx 2.37$ is the
current matrix-multiplication exponent.
&lt;/p&gt;
&lt;p&gt;To do so, we introduce a constant-factor subspace embedding with the optimal
$m=\mathcal{O}(d)$ number of rows, and which can be applied in time
$\mathcal{O}\left(\frac{\text{nnz}(\mathbf{A})}{\alpha}\right) + d^{2 +
\alpha}\text{poly}(\log d)$ for any trade-off parameter $\alpha&amp;gt;0$, tightening
a recent result by Chepurko et. al. [SODA 2022] that achieves an
$\exp(\text{poly}(\log\log n))$ distortion with $m=d\cdot\text{poly}(\log\log
d)$ rows in
$\mathcal{O}\left(\frac{\text{nnz}(\mathbf{A})}{\alpha}+d^{2+\alpha+o(1)}\right)$
time. Our subspace embedding uses a recently shown property of stacked
Subsampled Randomized Hadamard Transforms (SRHT), which actually increase the
input dimension, to &quot;spread&quot; the mass of an input vector among a large number
of coordinates, followed by random sampling. To control the effects of random
sampling, we use fast semidefinite programming to reweight the rows. We then
use our constant-factor subspace embedding to give the first optimal runtime
algorithms for finding a maximal linearly independent subset of columns,
regression, and leverage score sampling. To do so, we also introduce a novel
subroutine that iteratively grows a set of independent rows, which may be of
independent interest.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-21 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Listing 4-Cycles</title>
  <guid>http://arxiv.org/abs/2211.10022</guid>
  <link>http://arxiv.org/abs/2211.10022</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abboud_A/0/1/0/all/0/1&quot;&gt;Amir Abboud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoury_S/0/1/0/all/0/1&quot;&gt;Seri Khoury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leibowitz_O/0/1/0/all/0/1&quot;&gt;Oree Leibowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Safier_R/0/1/0/all/0/1&quot;&gt;Ron Safier&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this note we present an algorithm that lists all $4$-cycles in a graph in
time $\tilde{O}(\min(n^2,m^{4/3})+t)$ where $t$ is their number. Notably, this
separates $4$-cycle listing from triangle-listing, since the latter has a
$(\min(n^3,m^{3/2})+t)^{1-o(1)}$ lower bound under the $3$-SUM Conjecture.
&lt;/p&gt;
&lt;p&gt;Our upper bound is conditionally tight because (1) $O(n^2,m^{4/3})$ is the
best known bound for detecting if the graph has any $4$-cycle, and (2) it
matches a recent $(\min(n^3,m^{3/2})+t)^{1-o(1)}$ $3$-SUM lower bound for
enumeration algorithms.
&lt;/p&gt;
&lt;p&gt;The latter lower bound was proved very recently by Abboud, Bringmann, and
Fischer [arXiv, 2022] and independently by Jin and Xu [arXiv, 2022].
&lt;/p&gt;
&lt;p&gt;In an independent work, Jin and Xu [arXiv, 2022] also present an algorithm
with the same time bound.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-21 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>The communication cost of security and privacy in federated frequency estimation</title>
  <guid>http://arxiv.org/abs/2211.10041</guid>
  <link>http://arxiv.org/abs/2211.10041</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei-Ning Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozgur_A/0/1/0/all/0/1&quot;&gt;Ayfer &amp;#xd6;zg&amp;#xfc;r&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1&quot;&gt;Graham Cormode&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bharadwaj_A/0/1/0/all/0/1&quot;&gt;Akash Bharadwaj&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the federated frequency estimation problem, where each user holds
a private item $X_i$ from a size-$d$ domain and a server aims to estimate the
empirical frequency (i.e., histogram) of $n$ items with $n \ll d$. Without any
security and privacy considerations, each user can communicate its item to the
server by using $\log d$ bits. A naive application of secure aggregation
protocols would, however, require $d\log n$ bits per user. Can we reduce the
communication needed for secure aggregation, and does security come with a
fundamental cost in communication?
&lt;/p&gt;
&lt;p&gt;In this paper, we develop an information-theoretic model for secure
aggregation that allows us to characterize the fundamental cost of security and
privacy in terms of communication. We show that with security (and without
privacy) $\Omega\left( n \log d \right)$ bits per user are necessary and
sufficient to allow the server to compute the frequency distribution. This is
significantly smaller than the $d\log n$ bits per user needed by the naive
scheme, but significantly higher than the $\log d$ bits per user needed without
security. To achieve differential privacy, we construct a linear scheme based
on a noisy sketch which locally perturbs the data and does not require a
trusted server (a.k.a. distributed differential privacy). We analyze this
scheme under $\ell_2$ and $\ell_\infty$ loss. By using our
information-theoretic framework, we show that the scheme achieves the optimal
accuracy-privacy trade-off with optimal communication cost, while matching the
performance in the centralized case where data is stored in the central server.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-21 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Identifying Correlation in Stream of Samples</title>
  <guid>http://arxiv.org/abs/2211.10137</guid>
  <link>http://arxiv.org/abs/2211.10137</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1&quot;&gt;Zhenhao Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hao Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Identifying independence between two random variables or correlated given
their samples has been a fundamental problem in Statistics. However, how to do
so in a space-efficient way if the number of states is large is not quite
well-studied.
&lt;/p&gt;
&lt;p&gt;We propose a new, simple counter matrix algorithm, which utilize hash
functions and a compressed counter matrix to give an unbiased estimate of the
$\ell_2$ independence metric. With $\mathcal{O}(\epsilon^{-4}\log\delta^{-1})$
(very loose bound) space, we can guarantee $1\pm\epsilon$ multiplicative error
with probability at least $1-\delta$. We also provide a comparison of our
algorithm with the state-of-the-art sketching of sketches algorithm and show
that our algorithm is effective, and actually faster and at least 2 times more
space-efficient.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-21 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Improved Approximations for Unrelated Machine Scheduling</title>
  <guid>http://arxiv.org/abs/2211.10398</guid>
  <link>http://arxiv.org/abs/2211.10398</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Im_S/0/1/0/all/0/1&quot;&gt;Sungjin Im&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shi Li&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We revisit two well-studied scheduling problems in the unrelated machines
setting where each job can have a different processing time on each machine.
For minimizing total weighted completion time we give a 1.45-approximation,
which improves upon the previous 1.488-approximation [Im and Shadloo SODA
2020]. The key technical ingredient in this improvement lies in a new rounding
scheme that gives strong negative correlation with less restrictions. For
minimizing $L_k$-norms of machine loads, inspired by [Kalaitzis et al. SODA
2017], we give better approximation algorithms. In particular we give a $\sqrt
{4/3}$-approximation for the $L_2$-norm which improves upon the former $\sqrt
2$-approximations due to [Azar-Epstein STOC 2005] and [Kumar et al. JACM 2009].
&lt;/p&gt;
  </description>
  <pubDate>2022-11-21 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Reform AI Alignment</title>
  <guid>https://scottaaronson.blog/?p=6821</guid>
  <link>https://scottaaronson.blog/?p=6821</link>
  <description>
    &lt;p&gt;Nearly halfway into my year at OpenAI, still reeling from the FTX collapse, I feel like it&amp;#8217;s finally time to start blogging my AI safety thoughts&amp;#8212;starting with a little appetizer course today, more substantial fare to come.&lt;/p&gt;



&lt;p&gt;Many people claim that AI alignment is little more a modern eschatological religion&amp;#8212;with prophets, an end-times prophecy, sacred scriptures, and even a god (albeit, one who doesn&amp;#8217;t exist quite yet).  The obvious response to that claim is that, while there&amp;#8217;s some truth to it, &amp;#8220;religions&amp;#8221; based around technology are a little different from the old kind, because technological progress &lt;em&gt;actually happens&lt;/em&gt; regardless of whether you believe in it.&lt;/p&gt;



&lt;p&gt;I mean, the Internet is sort of like the old concept of the collective unconscious, except that it actually exists and you&amp;#8217;re using it right now.  Airplanes and spacecraft are kind of like the ancient dream of Icarus&amp;#8212;except, again, for the actually existing part.  Today GPT-3 and DALL-E2 and LaMDA and AlphaTensor exist, as they didn&amp;#8217;t two years ago, and one has to try to project forward to what their vastly-larger successors will be doing a decade from now.  Though some of my colleagues are still in denial about it, I regard the fact that such systems will have transformative effects on civilization, comparable to or greater than those of the Internet itself, as &amp;#8220;already baked in&amp;#8221;&amp;#8212;as just the mainstream position, not even a question anymore.  That doesn&amp;#8217;t mean that future AIs are going to convert the earth into paperclips, or give us eternal life in a simulated utopia.  But their story &lt;em&gt;will&lt;/em&gt; be a central part of the story of this century.&lt;/p&gt;



&lt;p&gt;Which brings me to a second response.  If AI alignment is a religion, it’s now large and established enough to have a thriving &amp;#8220;Reform&amp;#8221; branch, in addition to the original &amp;#8220;Orthodox&amp;#8221; branch epitomized by Eliezer Yudkowsky and &lt;a href=&quot;https://intelligence.org/&quot;&gt;MIRI&lt;/a&gt;.  As far as I can tell, this Reform branch now counts among its members a large fraction of the AI safety researchers now working in academia and industry.  (I’ll leave the formation of a Conservative branch of AI alignment, which reacts against the Reform branch by moving &lt;em&gt;slightly&lt;/em&gt; back in the direction of the Orthodox branch, as a problem for the future — to say nothing of Reconstructionist or Marxist branches.)&lt;/p&gt;



&lt;p&gt;Here’s an incomplete but hopefully representative list of the differences in doctrine between Orthodox and Reform AI Risk:&lt;/p&gt;



&lt;p&gt;(1) Orthodox AI-riskers tend to believe that humanity will survive or be destroyed based on the actions of a few elite engineers over the next decade or two.  Everything else&amp;#8212;climate change, droughts, the future of US democracy, war over Ukraine and maybe Taiwan&amp;#8212;fades into insignificance except insofar as it affects those engineers.&lt;/p&gt;



&lt;p&gt;We Reform AI-riskers, by contrast, believe that AI might well pose civilizational risks in the coming century, but so does all the other stuff, and it&amp;#8217;s all tied together.  An invasion of Taiwan might change which world power gets access to TSMC GPUs.  Almost everything affects which entities pursue the AI scaling frontier and whether they&amp;#8217;re cooperating or competing to be first.&lt;/p&gt;



&lt;p&gt;(2) Orthodox AI-riskers believe that public outreach has limited value: most people can&amp;#8217;t understand this issue anyway, and will need to be saved from AI despite themselves.&lt;/p&gt;



&lt;p&gt;We Reform AI-riskers believe that trying to get a broad swath of the public on board with one&amp;#8217;s preferred AI policy is something close to a deontological imperative.&lt;/p&gt;



&lt;p&gt;(3) Orthodox AI-riskers worry almost entirely about an agentic, misaligned AI that deceives humans while it works to destroy them, along the way to maximizing its strange utility function.&lt;/p&gt;



&lt;p&gt;We Reform&amp;nbsp;AI-riskers entertain that possibility, but we worry at least as much about powerful AIs that are weaponized by bad humans, which we expect to pose existential risks much earlier in any case.&lt;/p&gt;



&lt;p&gt;(4) Orthodox AI-riskers have limited interest in AI safety research applicable to actually-existing systems (LaMDA, GPT-3, DALL-E2, etc.), seeing the dangers posed by those systems as basically trivial compared to the looming danger of a misaligned agentic AI.&lt;/p&gt;



&lt;p&gt;We Reform&amp;nbsp;AI-riskers see research on actually-existing systems as one of the only ways to get feedback from the world about which&amp;nbsp;AI&amp;nbsp;safety&amp;nbsp;ideas are or aren&amp;#8217;t promising.&lt;/p&gt;



&lt;p&gt;(5) Orthodox AI-riskers worry most about the &amp;#8220;FOOM&amp;#8221; scenario, where some AI might cross a threshold from innocuous-looking to plotting to kill all humans in the space of hours or days.&lt;/p&gt;



&lt;p&gt;We Reform&amp;nbsp;AI-riskers worry most about the &amp;#8220;slow-moving trainwreck&amp;#8221; scenario, where (just like with climate change) well-informed people can see the writing on the wall decades ahead, but just can&amp;#8217;t line up everyone&amp;#8217;s incentives to prevent it.&lt;/p&gt;



&lt;p&gt;(6) Orthodox AI-riskers talk a lot about a &amp;#8220;pivotal act&amp;#8221; to prevent a misaligned AI from ever being developed, which might involve (e.g.) using an aligned AI to impose a worldwide surveillance regime.&lt;/p&gt;



&lt;p&gt;We Reform&amp;nbsp;AI-riskers worry more about such an act causing the very calamity that it was intended to prevent.&lt;/p&gt;



&lt;p&gt;(7) Orthodox AI-riskers feel a strong need to repudiate the norms of mainstream science, seeing them as too slow-moving to react in time to the existential danger of AI.&lt;/p&gt;



&lt;p&gt;We Reform&amp;nbsp;AI-riskers feel a strong need to get mainstream science on board with the&amp;nbsp;AI&amp;nbsp;safety&amp;nbsp;program.&lt;/p&gt;



&lt;p&gt;(8) Orthodox AI-riskers are maximalists about the power of pure, unaided superintelligence to just figure out how to commandeer whatever physical resources it needs to take over the world (for example, by messaging some lab over the Internet, and tricking it into manufacturing nanobots that will do the superintelligence&amp;#8217;s bidding).&lt;/p&gt;



&lt;p&gt;We Reform AI-riskers believe that, here just like in high school, there are limits to the power of pure intelligence to achieve one&amp;#8217;s goals.  We&amp;#8217;d expect even an agentic, misaligned AI, if such existed, to need a stable power source, robust interfaces to the physical world, and probably allied humans before it posed much of an existential threat.&lt;/p&gt;



&lt;p&gt;What have I missed?&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-11-20 20:44:33 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>TR22-164 |  Learning versus Pseudorandom Generators in Constant Parallel Time | 

	Shuichi Hirahara, 

	Mikito Nanashima</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/164</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/164</link>
  <description>
    A polynomial-stretch pseudorandom generator (PPRG) in NC$^0$ (i.e., constant parallel time) is one of the most important cryptographic primitives, especially for constructing highly efficient cryptography and indistinguishability obfuscation. The celebrated work (Applebaum, Ishai, and Kushilevitz, SIAM Journal on Computing, 2006) on randomized encodings yields the characterization of sublinear-stretch pseudorandom generators in NC$^0$ by the existence of logspace-computable one-way functions, but characterizing PPRGs in NC$^0$ seems out of reach at present. Therefore, it is natural to ask which sort of hardness notion is essential for constructing PPRGs in NC$^0$. Particularly, to the best of our knowledge, all the previously known candidates for PPRGs in NC$^0$ follow only one framework based on Goldreich&amp;#39;s one-way function. 
		
In this paper, we present a new learning-theoretic characterization for PPRGs in NC$^0$ and related classes. Specifically, we consider the average-case hardness of learning for well-studied classes in parameterized settings, where the number of samples is restricted to fixed-parameter tractable (FPT), and show that the following are equivalent:
	(i) The existence of (a collection of) PPRGs in NC$^0$.
	(ii) The average-case hardness of learning sparse $\mathbb{F}_2$-polynomials on a sparse example distribution and an NC$^0$-samplable target distribution (i.e., a distribution on target functions).
	(iii) The average-case hardness of learning Fourier-sparse functions on a sparse example distribution and an NC$^0$-samplable target distribution.
	(iv) The average-case hardness of learning constant-depth parity decision trees on a sparse example distribution and an NC$^0$-samplable target distribution.
Furthermore, we characterize a (single) PPRG in $\oplus$-NC$^0$ by the average-case hardness of learning constant-degree $\mathbb{F}_2$-polynomials on a uniform example distribution with FPT samples. Based on our results, we propose new candidates for PPRGs in NC$^0$ and related classes under a hardness assumption on a natural learning problem. An important property of PPRGs in NC$^0$ constructed in our framework is that the output bits are computed by various predicates; thus, it seems to resist an attack that depends on a specific property of one fixed predicate.
	
Conceptually, the main contribution of this study is to formalize a theory of FPT dualization of concept classes, which yields a meta-theorem for the first result. For the second result on PPRGs in $\oplus$-NC$^0$, we use a different technique of pseudorandom $\mathbb{F}_2$-polynomials.
  </description>
  <pubDate>2022-11-20 11:26:40 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>TR22-163 |  Random Walks on Rotating Expanders | 

	Gil Cohen, 

	Gal Maor</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/163</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/163</link>
  <description>
    Random walks on expanders are a powerful tool which found applications in many areas of theoretical computer science, and beyond. However, they come with an inherent cost -- the spectral expansion of the corresponding power graph deteriorates at a rate that is exponential in the length of the walk. As an example, when $G$ is a $d$-regular Ramanujan graph, the power graph $G^t$ has spectral expansion $2^{\Omega(t)} \sqrt{D}$, where $D = d^t$ is the regularity of $G^t$, thus, $G^t$ is $2^{\Omega(t)}$ away from being Ramanujan. This exponential blowup manifests itself in many applications.

In this work we bypass this barrier by permuting the vertices of the given graph after each random step. We prove that there exists a sequence of permutations for which the spectral expansion deteriorates by only a linear factor in $t$. In the Ramanujan case this yields an expansion of $O(t \sqrt{D})$. We stress that the permutations are tailor-made to the graph at hand and require no randomness to generate.

Our proof, which holds for all sufficiently high girth graphs, makes heavy use of the powerful framework of finite free probability and interlacing families that was developed in a seminal sequence of works by Marcus, Spielman and Srivastava.
  </description>
  <pubDate>2022-11-20 09:05:18 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>On PBFT from Locked Broadcast</title>
  <guid>https://decentralizedthoughts.github.io/2022-11-20-pbft-via-locked-braodcast/</guid>
  <link>https://decentralizedthoughts.github.io/2022-11-20-pbft-via-locked-braodcast/</link>
  <description>
    We describe a variation of the authenticated version of PBFT using Locked Broadcast that follows a similar path as our previous post on Paxos using Recoverable Broadcast. I call this protocol linear PBFT and variants of it are used by SBFT and Tusk. A later post will show how to...
  </description>
  <pubDate>2022-11-20 09:00:00 UTC</pubDate>
  <author>Decentralized Thoughts</author>
</item>

<item>
  <title>TR22-162 |  Directed Isoperimetric Theorems for Boolean Functions on the Hypergrid and an $\widetilde{O}(n\sqrt{d})$ Monotonicity Tester | 

	Hadley Black, 

	Deeparnab Chakrabarty, 

	C. Seshadhri</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/162</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/162</link>
  <description>
    The problem of testing monotonicity for Boolean functions on the hypergrid, $f:[n]^d \to \{0,1\}$ is a classic topic in property testing. When $n=2$, the domain is the hypercube. For the hypercube case, a breakthrough result of Khot-Minzer-Safra (FOCS 2015) gave a non-adaptive, one-sided tester making $\widetilde{O}(\varepsilon^{-2}\sqrt{d})$ queries. Up to polylog $d$ and $\varepsilon$ factors, this bound matches the $\widetilde{\Omega}(\sqrt{d})$-query non-adaptive lower bound (Chen-De-Servedio-Tan (STOC 2015), Chen-Waingarten-Xie (STOC 2017)). For any $n &amp;gt; 2$, the optimal non-adaptive complexity was unknown. A previous result of the authors achieves a $\widetilde{O}(d^{5/6})$-query upper bound (SODA 2020), quite far from the $\sqrt{d}$ bound for the hypercube.

In this paper, we resolve the non-adaptive complexity of monotonicity testing for all constant $n$, up to $\text{poly}(\varepsilon^{-1}\log d)$ factors. Specifically, we give a non-adaptive, one-sided monotonicity tester making $\widetilde{O}(\varepsilon^{-2}n\sqrt{d})$ queries. From a technical standpoint, we prove new directed isoperimetric theorems over the hypergrid $[n]^d$. These results generalize the celebrated directed Talagrand inequalities that were only known for the hypercube.
  </description>
  <pubDate>2022-11-20 05:41:10 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>TR22-161 |  Towards Multi-Pass Streaming Lower Bounds for Optimal Approximation of Max-Cut | 

	Raghuvansh Saxena, 

	Lijie Chen, 

	Gillat Kol, 

	Dmitry Paramonov, 

	Zhao Song, 

	Huacheng Yu</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/161</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/161</link>
  <description>
    We consider the Max-Cut problem, asking how much space is needed by a streaming algorithm in order to estimate the value of the maximum cut in a graph. This problem has been extensively studied over the last decade, and we now have a near-optimal lower bound for one-pass streaming algorithms, showing that they require linear space to guarantee a better-than-$2$ approximation [KKS15, KK19]. The result relies on a lower bound for the cycle-finding problem, showing that it is hard for a one-pass streaming algorithm to find a cycle in a union of matchings.

The end-goal of our research is to prove a similar lower for multi-pass streaming algorithms that guarantee a better-than-$2$ approximation for Max-Cut, a highly challenging open problem. In this paper, we take a significant step in this direction, showing that even $o(\log n)$-pass streaming algorithms need $n^{\Omega(1)}$ space to solve the cycle-finding problem. Our proof is quite involved, dividing the cycles in the graph into &amp;quot;short&amp;quot; and &amp;quot;long&amp;quot; cycles, and using tailor-made lower bound techniques to handle each case.
  </description>
  <pubDate>2022-11-20 05:39:49 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>TR22-160 |  The Geometry of Rounding | 

	Jason Vander Woude, 

	Peter Dixon, 

	A.  Pavan, 

	Jamie Radcliffe, 

	N. V. Vinodchandran</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/160</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/160</link>
  <description>
    Rounding has proven to be a fundamental tool in theoretical computer science. By observing that rounding and partitioning of $\mathbb{R}^d$ are equivalent, we introduce the following natural partition problem which we call the secluded hypercube partition problem: Given $k\in\mathbb{N}$ (ideally small) and $\epsilon&amp;gt;0$ (ideally large), is there a partition of $\mathbb{R}^d$ with unit hypercubes such that for every point $\vec{p} \in \mathbb{R}^d$, its closed $\epsilon$-neighborhood (in the $\ell_{\infty}$  norm) intersects at most $k$ hypercubes?

We undertake a comprehensive study of this partition problem. We prove that for every $d\in\mathbb{N}$, there is an explicit (and efficiently computable) hypercube partition of $\mathbb{R}^d$ with $k = d+1$ and $\epsilon = \frac{1}{2d}$. We complement this construction by proving that the value of $k=d+1$ is the best possible (for any $\epsilon$) for a broad class of &amp;quot;reasonable&amp;quot; partitions including hypercube partitions. We also investigate the optimality of the parameter $\epsilon$ and prove that any partition in this broad class that has $k=d+1$, must have $\epsilon\leq\frac{1}{2\sqrt{d}}$. These bounds imply limitations of certain deterministic rounding schemes existing in the literature. Furthermore, this general bound is based on the currently known lower bounds for the dissection number of the cube, and improvements to this bound will yield improvements to our bounds.

While our work is motivated by the desire to understand rounding algorithms, one of our main conceptual contributions is the introduction of the secluded hypercube partition problem, which fits well with a long history of investigations by mathematicians on various hypercube partitions/tilings of Euclidean  space.
  </description>
  <pubDate>2022-11-20 05:38:52 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>From Single-Shot Consensus to State Machine Replication</title>
  <guid>https://decentralizedthoughts.github.io/2022-11-19-from-single-shot-to-smr/</guid>
  <link>https://decentralizedthoughts.github.io/2022-11-19-from-single-shot-to-smr/</link>
  <description>
    In this post we explore the path from Single-Shot Consensus, via Write-Once Registers, to Log Replication, and finally to State Machine Replication. We begin by defining all four problems assuming minority omission failures and partial synchrony. This post continues our previous post on Paxos from Recoverable Broadcast. (Single-Shot) Consensus In...
  </description>
  <pubDate>2022-11-19 09:00:00 UTC</pubDate>
  <author>Decentralized Thoughts</author>
</item>

<item>
  <title>TR22-159 |  Deep Neural Networks: The Missing Complexity Parameter | 

	Songhua He, 

	Periklis Papakonstantinou</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/159</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/159</link>
  <description>
    Deep neural networks are the dominant machine learning model. We show that this model is missing a crucial complexity parameter. Today, the standard neural network (NN) model is a circuit whose gates (neurons) are ReLU units. The complexity of a NN is quantified by the depth (number of layers) and the size (number of neurons = depth times width). This work shows that this alone is insufficient, resulting in NNs with unreasonable computing power. We show that the correct way to talk about the size complexity of a NN is beside the number of neurons to consider the precision (or magnitude) of the weights of the ReLU units. The main message of this work is that if the precision of the weights is not considered in the complexity of the NN then one can engineer weights to &amp;quot;buy&amp;quot; exponentially many neurons for free. In summary, we make three theoretical contributions, potentially affecting many theoretical works on NNs.

1. Every function $f:\{0,1\}^n\to\{0,1\}$ can be computed with $O(\sqrt{2^n})$ many neurons and constant fan-in per neuron; i.e.~exponential times less than Shannon&amp;#39;s classic lower bound for usual combinatorial circuits. 

2. We give a new definition of circuit size that takes into account the precision/magnitude of the weights. Under this new definition of size we asymptotically match Shannon&amp;#39;s bound for NNs.

3. We complement the above results showing that P-uniform NNs decide exactly P.
  </description>
  <pubDate>2022-11-18 19:13:20 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>TR22-158 |  Query Complexity of Inversion Minimization on Trees | 

	Ivan Hu, 

	Dieter van Melkebeek, 

	Andrew Morgan</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/158</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/158</link>
  <description>
    We consider the following computational problem: Given a rooted tree and a ranking of its leaves, what is the minimum number of inversions of the leaves that can be attained by ordering the tree? This variation of the well-known problem of counting inversions in arrays originated in mathematical psychology. It has the evaluation of the Mann-Whitney statistic for detecting differences between distributions as a special case. 

We study the complexity of the problem in the comparison-query model, the standard model for problems like sorting, selection, and heap construction. The complexity depends heavily on the shape of the tree: for trees of unit depth, the problem is trivial; for many other shapes, we establish lower bounds close to the strongest known in the model, namely the lower bound of $\log_2(n!)$ for sorting $n$ items. For trees with $n$ leaves we show, in increasing order of closeness to the sorting lower bound:
(a) $\log_2((\alpha(1-\alpha)n)!) - O(\log n)$ queries are needed whenever the tree has a subtree that contains a fraction $\alpha$ of the leaves. This implies a lower bound of $\log_2((\frac{k}{(k+1)^2}n)!) - O(\log n)$ for trees of degree $k$.
(b) $\log_2(n!) - O(\log n)$ queries are needed in case the tree is binary. 
(c) $\log_2(n!) - O(k \log k)$ queries are needed for certain classes of trees of degree $k$, including perfect trees with even $k$.

The lower bounds are obtained by developing two novel techniques for a generic problem $\Pi$ in the comparison-query model and applying them to inversion minimization on trees. Both techniques can be described in terms of the Cayley graph of the symmetric group with adjacent-rank transpositions as the generating set, or equivalently, in terms of the edge graph of the permutahedron, the polytope spanned by all permutations of the vector $(1,2,\dots,n)$. Consider the subgraph consisting of the edges between vertices with the same value under $\Pi$. We show that the size of any decision tree for $\Pi$ must be at least:
(i) the number of connected components of this subgraph, and
(ii) the factorial of the average degree of the complementary subgraph, divided by $n$.

Lower bounds on query complexity then follow by taking the base-2 logarithm. Technique (i) represents a discrete analog of a classical technique in algebraic complexity and allows us to establish (c) and a tight lower bound for counting cross inversions, as well as unify several of the known lower bounds in the comparison-query model. Technique (ii) represents an analog of sensitivity arguments in Boolean complexity and allows us to establish (a) and (b). 

Along the way to proving (b), we derive a tight upper bound on the maximum probability of the distribution of cross inversions, which is the distribution of the Mann-Whitney statistic in the case of the null hypothesis. Up to normalization the probabilities alternately appear in the literature as the coefficients of polynomials formed by the Gaussian binomial coefficients, also known as Gaussian polynomials.
  </description>
  <pubDate>2022-11-18 15:57:57 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>WINNERS of the Scott Aaronson Grant for Advanced Precollege STEM Education!</title>
  <guid>https://scottaaronson.blog/?p=6818</guid>
  <link>https://scottaaronson.blog/?p=6818</link>
  <description>
    &lt;p&gt;I&amp;#8217;m thrilled to be able to interrupt your regular depressing programming for 100% happy news.&lt;/p&gt;



&lt;p&gt;Some readers will remember that, back in September, I &lt;a href=&quot;https://scottaaronson.blog/?p=6678&quot;&gt;announced&lt;/a&gt; that an unnamed charitable foundation had asked my advice on how best to donate $250,000 for advanced precollege STEM education.  So, just like the &lt;a href=&quot;https://scottaaronson.blog/?p=6232&quot;&gt;previous time&lt;/a&gt; I got such a request, from Jaan Tallinn&amp;#8217;s &lt;a href=&quot;https://survivalandflourishing.fund/&quot;&gt;Survival and Flourishing Fund&lt;/a&gt;, I decided to do a call for proposals on &lt;em&gt;Shtetl-Optimized&lt;/em&gt; before passing along my recommendations.&lt;/p&gt;



&lt;p&gt;I can now reveal that the generous foundation, this time around, was the &lt;a href=&quot;https://www.packard.org/&quot;&gt;Packard Foundation&lt;/a&gt;.  Indeed, the idea and initial inquiries to me came directly from &lt;a href=&quot;https://www.packard.org/about-the-foundation/our-people/bio/david-orr/&quot;&gt;Dave Orr&lt;/a&gt;: the chair of the foundation, grandson of Hewlett-Packard cofounder &lt;a href=&quot;https://en.wikipedia.org/wiki/David_Packard&quot;&gt;David Packard&lt;/a&gt;, and (so I learned) longtime &lt;em&gt;Shtetl-Optimized&lt;/em&gt; reader.&lt;/p&gt;



&lt;p&gt;I can &lt;em&gt;also&lt;/em&gt; now reveal the results.  I was honored to get more than a dozen excellent applications.  After carefully considering all of them, I passed along four finalists to the Packard Foundation, which preferred to award the entire allotment to a single program if possible.  After more discussion and research, the Foundation then actually decided on &lt;em&gt;two&lt;/em&gt; winners:&lt;/p&gt;



&lt;ul&gt;
&lt;li&gt;$225,000 for general support to &lt;a href=&quot;https://promys.org/&quot;&gt;PROMYS&lt;/a&gt;: the long-running, world-renowned summer math camp for high-school students, which (among other things) is in the process of launching a new branch in India.  While I ended up at &lt;a href=&quot;https://www.mathcamp.org/&quot;&gt;Canada/USA Mathcamp&lt;/a&gt; (which I supported in my &lt;a href=&quot;https://scottaaronson.blog/?p=6256&quot;&gt;first grant round&lt;/a&gt;) rather than PROMYS, I knew all about and admired PROMYS even back when I was the right age to attend it.  I&amp;#8217;m thrilled to be able to play a small role in its expansion.&lt;/li&gt;
&lt;/ul&gt;



&lt;ul&gt;
&lt;li&gt;$30,000 for general support to &lt;a href=&quot;https://www.addiscoder.com/&quot;&gt;AddisCoder&lt;/a&gt;: the phenomenal program that introduces Ethiopian high-schoolers to programming and algorithms.  AddisCoder was founded by UC Berkeley theoretical computer science professor and longtime friend-of-the-blog &lt;a href=&quot;https://people.eecs.berkeley.edu/~minilek/&quot;&gt;Jelani Nelson&lt;/a&gt;, and &lt;em&gt;also&lt;/em&gt; received $30,000 in my &lt;a href=&quot;https://scottaaronson.blog/?p=6256&quot;&gt;first grant round&lt;/a&gt;.  Jelani and his co-organizers will be pressing ahead with AddisCoder despite political conflict in Ethiopia including a recently-concluded &lt;a href=&quot;https://en.wikipedia.org/wiki/Tigray_War&quot;&gt;civil war&lt;/a&gt;.  I&amp;#8217;m humbled if I can make even the tiniest difference.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Thanks so much to the Packard Foundation, and to Packard&amp;#8217;s talented program officers, directors, and associates&amp;#8212;especially Laura Sullivan, Jean Ries, and Prithi Trivedi&amp;#8212;for their hard work to make this happen.  Thanks so much also to everyone who applied.  While I wish we could&amp;#8217;ve funded everyone, I&amp;#8217;ve learned a lot about programs to which I&amp;#8217;d like to steer future support &lt;strong&gt;(other prospective benefactors: please email me!!)&lt;/strong&gt;, &lt;em&gt;and&lt;/em&gt; to which I&amp;#8217;d like to steer kids: my own, once they&amp;#8217;re old enough, and other kids of my acquaintance.&lt;/p&gt;



&lt;p&gt;I feel good that, in the tiny, underfunded world of accelerated STEM education, the $255,000 that Packard is donating will already make a difference.  But of course, $255,000 is only a thousandth of $255 million, which is a thousandth of $255 billion.  Perhaps I could earn the latter sort of sums, to donate to STEM education or any other cause, by (for example) starting my own cryptocurrency exchange.  I hope my readers will forgive me for not having chosen that route, expected-utility-maximization arguments be damned.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 08:01:17 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>Improved Monotonicity Testers via Hypercube Embeddings</title>
  <guid>http://arxiv.org/abs/2211.09229</guid>
  <link>http://arxiv.org/abs/2211.09229</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braverman_M/0/1/0/all/0/1&quot;&gt;Mark Braverman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khot_S/0/1/0/all/0/1&quot;&gt;Subhash Khot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kindler_G/0/1/0/all/0/1&quot;&gt;Guy Kindler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1&quot;&gt;Dor Minzer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show improved monotonicity testers for the Boolean hypercube under the
$p$-biased measure, as well as over the hypergrid $[m]^n$. Our results are:
&lt;/p&gt;
&lt;p&gt;1. For any $p\in (0,1)$, for the $p$-biased hypercube we show a non-adaptive
tester that makes $\tilde{O}(\sqrt{n}/\varepsilon^2)$ queries, accepts monotone
functions with probability $1$ and rejects functions that are $\varepsilon$-far
from monotone with probability at least $2/3$.
&lt;/p&gt;
&lt;p&gt;2. For all $m\in\mathbb{N}$, we show an
$\tilde{O}(\sqrt{n}m^3/\varepsilon^2)$ query monotonicity tester over $[m]^n$.
&lt;/p&gt;
&lt;p&gt;We also establish corresponding directed isoperimetric inequalities in these
domains. Previously, the best known tester due to Black, Chakrabarty and
Seshadhri had $\Omega(n^{5/6})$ query complexity. Our results are optimal up to
poly-logarithmic factors and the dependency on $m$.
&lt;/p&gt;
&lt;p&gt;Our proof uses a notion of monotone embeddings of measures into the Boolean
hypercube that can be used to reduce the problem of monotonicity testing over
an arbitrary product domains to the Boolean cube. The embedding maps a function
over a product domain of dimension $n$ into a function over a Boolean cube of a
larger dimension $n&#39;$, while preserving its distance from being monotone; an
embedding is considered efficient if $n&#39;$ is not much larger than $n$, and we
show how to construct efficient embeddings in the above mentioned settings.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Approaching the Soundness Barrier: A Near Optimal Analysis of the Cube versus Cube Test</title>
  <guid>http://arxiv.org/abs/2211.09341</guid>
  <link>http://arxiv.org/abs/2211.09341</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1&quot;&gt;Dor Minzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1&quot;&gt;Kai Zheng&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Cube versus Cube test is a variant of the well-known Plane versus Plane
test of Raz and Safra, in which to each $3$-dimensional affine subspace $C$ of
$\mathbb{F}_q^n$, a polynomial of degree at most $d$, $T(C)$, is assigned in a
somewhat locally consistent manner: taking two cubes $C_1, C_2$ that intersect
in a plane uniformly at random, the probability that $T(C_1)$ and $T(C_2)$
agree on $C_1\cap C_2$ is at least some $\epsilon$. An element of interest is
the soundness threshold of this test, i.e. the smallest value of $\epsilon$,
such that this amount of local consistency implies a global structure; namely,
that there is a global degree $d$ function $g$ such that $g|_{C} \equiv T(C)$
for at least $\Omega(\epsilon)$ fraction of the cubes.
&lt;/p&gt;
&lt;p&gt;We show that the cube versus cube low degree test has soundness ${\sf
poly}(d)/q$. This result achieves the optimal dependence on $q$ for soundness
in low degree testing and improves upon previous soundness results of ${\sf
poly}(d)/q^{1/2}$ due to Bhangale, Dinur and Navon.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Unique-Neighbor-Like Expansion and Group-Independent Cosystolic Expansion</title>
  <guid>http://arxiv.org/abs/2211.09482</guid>
  <link>http://arxiv.org/abs/2211.09482</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaufman_T/0/1/0/all/0/1&quot;&gt;Tali Kaufman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mass_D/0/1/0/all/0/1&quot;&gt;David Mass&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In recent years, high dimensional expanders have been found to have a variety
of applications in theoretical computer science, such as efficient CSPs
approximations, improved sampling and list-decoding algorithms, and more.
Within that, an important high dimensional expansion notion is \emph{cosystolic
expansion}, which has found applications in the construction of efficiently
decodable quantum codes and in proving lower bounds for CSPs.
&lt;/p&gt;
&lt;p&gt;Cosystolic expansion is considered with systems of equations over a group
where the variables and equations correspond to faces of the complex. Previous
works that studied cosystolic expansion were tailored to the specific group
$\mathbb{F}_2$. In particular, Kaufman, Kazhdan and Lubotzky (FOCS 2014), and
Evra and Kaufman (STOC 2016) in their breakthrough works, who solved a famous
open question of Gromov, have studied a notion which we term ``parity&#39;&#39;
expansion for small sets. They showed that small sets of $k$-faces have
proportionally many $(k+1)$-faces that contain \emph{an odd number} of
$k$-faces from the set. Parity expansion for small sets could be used to imply
cosystolic expansion only over $\mathbb{F}_2$.
&lt;/p&gt;
&lt;p&gt;In this work we introduce a stronger \emph{unique-neighbor-like} expansion
for small sets. We show that small sets of $k$-faces have proportionally many
$(k+1)$-faces that contain \emph{exactly one} $k$-face from the set. This
notion is fundamentally stronger than parity expansion and cannot be implied by
previous works.
&lt;/p&gt;
&lt;p&gt;We then show, utilizing the new unique-neighbor-like expansion notion
introduced in this work, that cosystolic expansion can be made
\emph{group-independent}, i.e., unique-neighbor-like expansion for small sets
implies cosystolic expansion \emph{over any group}.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Double Balanced Sets in High Dimensional Expanders</title>
  <guid>http://arxiv.org/abs/2211.09485</guid>
  <link>http://arxiv.org/abs/2211.09485</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaufman_T/0/1/0/all/0/1&quot;&gt;Tali Kaufman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mass_D/0/1/0/all/0/1&quot;&gt;David Mass&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Recent works have shown that expansion of pseudorandom sets is of great
importance. However, all current works on pseudorandom sets are limited only to
product (or approximate product) spaces, where Fourier Analysis methods could
be applied. In this work we ask the natural question whether pseudorandom sets
are relevant in domains where Fourier Analysis methods cannot be applied, e.g.,
one-sided local spectral expanders.
&lt;/p&gt;
&lt;p&gt;We take the first step in the path of answering this question. We put forward
a new definition for pseudorandom sets, which we call ``double balanced sets&#39;&#39;.
We demonstrate the strength of our new definition by showing that small double
balanced sets in one-sided local spectral expanders have very strong expansion
properties, such as unique-neighbor-like expansion. We further show that
cohomologies in cosystolic expanders are double balanced, and use the newly
derived strong expansion properties of double balanced sets in order to obtain
an exponential improvement over the current state of the art lower bound on
their minimal distance.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Cooperative 2D Reconfiguration using Spatio-Temporal Planning and Load Transferring</title>
  <guid>http://arxiv.org/abs/2211.09198</guid>
  <link>http://arxiv.org/abs/2211.09198</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_J/0/1/0/all/0/1&quot;&gt;Javier Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yannuzzi_M/0/1/0/all/0/1&quot;&gt;Michael Yannuzzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kramer_P/0/1/0/all/0/1&quot;&gt;Peter Kramer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rieck_C/0/1/0/all/0/1&quot;&gt;Christian Rieck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fekete_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe1;ndor P. Fekete&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Becker_A/0/1/0/all/0/1&quot;&gt;Aaron T. Becker&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present progress on the problem of reconfiguring a 2D arrangement of
building material by a cooperative set of robots. These robots are subjected to
the constraints of avoiding obstacles and maintaining connectivity of the
structure. We develop two reconfiguration methods, one based on spatio-temporal
planning, and one based on target swapping. Both methods achieve coordinated
motion of robots by avoiding deadlocks and maintaining all constraints. Both
methods also increase efficiency by reducing the amount of waiting times and
lowering combined travel costs. The resulting progress is validated by
simulations that also scale the number of robots.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Covering and packing with homothets of limited capacity</title>
  <guid>http://arxiv.org/abs/2211.09328</guid>
  <link>http://arxiv.org/abs/2211.09328</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pi_O/0/1/0/all/0/1&quot;&gt;Oriol Sol&amp;#xe9; Pi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This work revolves around the two following questions: Given a convex body
$C\subset\mathbb{R}^d$, a positive integer $k$ and a finite set
$S\subset\mathbb{R}^d$ (or a finite $\mu$ Borel measure in $\mathbb{R}^d$), how
many homothets of $C$ are required to cover $S$ if no homothet is allowed to
cover more than $k$ points of $S$ (or have measure more than $k$)? how many
homothets of $C$ can be packed if each of them must cover at least $k$ points
of $S$ (or have measure at least $k$)? We prove that, so long as $S$ is not too
degenerate, the answer to both questions is $\Theta_d(\frac{|S|}{k})$, where
the hidden constant is independent of $d$, this is clearly best possible up to
a multiplicative constant. Analogous results hold in the case of measures. Then
we introduce a generalization of the standard covering and packing densities of
a convex body $C$ to Borel measure spaces in $\mathbb{R}^d$ and, using the
aforementioned bounds, we show that they are bounded from above and below,
respectively, by functions of $d$. As an intermediate result, we give a simple
proof the existence of weak $\epsilon$-nets of size $O(\frac{1}{\epsilon})$ for
the range space induced by all homothets of $C$. Following some recent work in
discrete geometry, we investigate the case $d=k=2$ in greater detail. We also
provide polynomial time algorithms for constructing a packing/covering
exhibiting the $\Theta_d(\frac{|S|}{k})$ bound mentioned above in the case that
$C$ is an Euclidean ball. Finally, it is shown that if $C$ is a square then it
is NP-hard to decide whether $S$ can be covered by $\frac{|S|}{4}$ squares
containing $4$ points each.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Rounding via Low Dimensional Embeddings</title>
  <guid>http://arxiv.org/abs/2211.09729</guid>
  <link>http://arxiv.org/abs/2211.09729</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braverman_M/0/1/0/all/0/1&quot;&gt;Mark Braverman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1&quot;&gt;Dor Minzer&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A regular graph $G = (V,E)$ is an $(\varepsilon,\gamma)$ small-set expander
if for any set of vertices of fractional size at most $\varepsilon$, at least
$\gamma$ of the edges that are adjacent to it go outside. In this paper, we
give a unified approach to several known complexity-theoretic results on
small-set expanders. In particular, we show:
&lt;/p&gt;
&lt;p&gt;1. Max-Cut: we show that if a regular graph $G = (V,E)$ is an
$(\varepsilon,\gamma)$ small-set expander that contains a cut of fractional
size at least $1-\delta$, then one can find in $G$ a cut of fractional size at
least $1-O\left(\frac{\delta}{\varepsilon\gamma^6}\right)$ in polynomial time.
&lt;/p&gt;
&lt;p&gt;2. Improved spectral partitioning, Cheeger&#39;s inequality and the parallel
repetition theorem over small-set expanders. The general form of each one of
these results involves square-root loss that comes from certain rounding
procedure, and we show how this can be avoided over small set expanders.
&lt;/p&gt;
&lt;p&gt;Our main idea is to project a high dimensional vector solution into a
low-dimensional space while roughly maintaining $\ell_2^2$ distances, and then
perform a pre-processing step using low-dimensional geometry and the properties
of $\ell_2^2$ distances over it. This pre-processing leverages the small-set
expansion property of the graph to transform a vector valued solution to a
different vector valued solution with additional structural properties, which
give rise to more efficient integral-solution rounding schemes.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>(Re)packing Equal Disks into Rectangle</title>
  <guid>http://arxiv.org/abs/2211.09603</guid>
  <link>http://arxiv.org/abs/2211.09603</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1&quot;&gt;Fedor V. Fomin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golovach_P/0/1/0/all/0/1&quot;&gt;Petr A. Golovach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inamdar_T/0/1/0/all/0/1&quot;&gt;Tanmay Inamdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1&quot;&gt;Saket Saurabh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zehavi_M/0/1/0/all/0/1&quot;&gt;Meirav Zehavi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The problem of packing of equal disks (or circles) into a rectangle is a
fundamental geometric problem. (By a packing here we mean an arrangement of
disks in a rectangle without overlapping.) We consider the following
algorithmic generalization of the equal disk packing problem. In this problem,
for a given packing of equal disks into a rectangle, the question is whether by
changing positions of a small number of disks, we can allocate space for
packing more disks. More formally, in the repacking problem, for a given set of
$n$ equal disks packed into a rectangle and integers $k$ and $h$, we ask
whether it is possible by changing positions of at most $h$ disks to pack $n+k$
disks. Thus the problem of packing equal disks is the special case of our
problem with $n=h=0$.
&lt;/p&gt;
&lt;p&gt;While the computational complexity of packing equal disks into a rectangle
remains open, we prove that the repacking problem is NP-hard already for $h=0$.
Our main algorithmic contribution is an algorithm that solves the repacking
problem in time $(h+k)^{O(h+k)}\cdot |I|^{O(1)}$, where $I$ is the input size.
That is, the problem is fixed-parameter tractable parameterized by $k$ and $h$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On the complexity of implementing Trotter steps</title>
  <guid>http://arxiv.org/abs/2211.09133</guid>
  <link>http://arxiv.org/abs/2211.09133</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Low_G/0/1/0/all/0/1&quot;&gt;Guang Hao Low&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yuan Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Tong_Y/0/1/0/all/0/1&quot;&gt;Yu Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Tran_M/0/1/0/all/0/1&quot;&gt;Minh C. Tran&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Quantum dynamics can be simulated on a quantum computer by exponentiating
elementary terms from the Hamiltonian in a sequential manner. However, such an
implementation of Trotter steps has gate complexity depending on the total
Hamiltonian term number, comparing unfavorably to algorithms using more
advanced techniques. We develop methods to perform faster Trotter steps with
complexity sublinear in the number of terms. We achieve this for a class of
Hamiltonians whose interaction strength decays with distance according to power
law. Our methods include one based on a recursive block encoding and one based
on an average-cost simulation, overcoming the normalization-factor barrier of
these advanced quantum simulation techniques. We also realize faster Trotter
steps when certain blocks of Hamiltonian coefficients have low rank. Combining
with a tighter error analysis, we show that it suffices to use
$\left(\eta^{1/3}n^{1/3}+\frac{n^{2/3}}{\eta^{2/3}}\right)n^{1+o(1)}$ gates to
simulate uniform electron gas with $n$ spin orbitals and $\eta$ electrons in
second quantization in real space, asymptotically improving over the best
previous work. We obtain an analogous result when the external potential of
nuclei is introduced under the Born-Oppenheimer approximation. We prove a
circuit lower bound when the Hamiltonian coefficients take a continuum range of
values, showing that generic $n$-qubit $2$-local Hamiltonians with commuting
terms require at least $\Omega(n^2)$ gates to evolve with accuracy
$\epsilon=\Omega(1/poly(n))$ for time $t=\Omega(\epsilon)$. Our proof is based
on a gate-efficient reduction from the approximate synthesis of diagonal
unitaries within the Hamming weight-$2$ subspace, which may be of independent
interest. Our result thus suggests the use of Hamiltonian structural properties
as both necessary and sufficient to implement Trotter steps with lower gate
complexity.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On the Power of Learning-Augmented BSTs</title>
  <guid>http://arxiv.org/abs/2211.09251</guid>
  <link>http://arxiv.org/abs/2211.09251</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jingbang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Li Chen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present the first Learning-Augmented Binary Search Tree(BST) that attains
Static Optimality and Working-Set Bound given rough predictions. Following the
recent studies in algorithms with predictions and learned index structures,
Lin, Luo, and Woodruff (ICML 2022) introduced the concept of Learning-Augmented
BSTs, which aim to improve BSTs with learned advice. Unfortunately, their
construction gives only static optimality under strong assumptions on the
input.
&lt;/p&gt;
&lt;p&gt;In this paper, we present a simple BST maintenance scheme that benefits from
learned advice. With proper predictions, the scheme achieves Static Optimality
and Working-Set Bound, respectively, which are important performance measures
for BSTs. Moreover, the scheme is robust to prediction errors and makes no
assumption on the input.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Near-Optimal Distributed Computation of Small Vertex Cuts</title>
  <guid>http://arxiv.org/abs/2211.09415</guid>
  <link>http://arxiv.org/abs/2211.09415</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parter_M/0/1/0/all/0/1&quot;&gt;Merav Parter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petruschka_A/0/1/0/all/0/1&quot;&gt;Asaf Petruschka&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present near-optimal algorithms for detecting small vertex cuts in the
CONGEST model of distributed computing. Despite extensive research in this
area, our understanding of the vertex connectivity of a graph is still
incomplete, especially in the distributed setting. To this date, all
distributed algorithms for detecting cut vertices suffer from an inherent
dependency in the maximum degree of the graph, $\Delta$. Hence, in particular,
there is no truly sub-linear time algorithm for this problem, not even for
detecting a single cut vertex. We take a new algorithmic approach for vertex
connectivity which allows us to bypass the existing $\Delta$ barrier. As a
warm-up to our approach, we show a simple $\widetilde{O}(D)$-round randomized
algorithm for computing all cut vertices in a $D$-diameter $n$-vertex graph.
This improves upon the $O(D+\Delta/\log n)$-round algorithm of [Pritchard and
Thurimella, ICALP 2008]. Our key technical contribution is an
$\widetilde{O}(D)$-round randomized algorithm for computing all cut pairs in
the graph, improving upon the state-of-the-art $O(\Delta \cdot D)^4$-round
algorithm by [Parter, DISC &#39;19]. Note that even for the considerably simpler
setting of edge cuts, currently $\widetilde{O}(D)$-round algorithms are known
only for detecting pairs of cut edges. Our approach is based on employing the
well-known linear graph sketching technique [Ahn, Guha and McGregor, SODA 2012]
along with the heavy-light tree decomposition of [Sleator and Tarjan, STOC
1981]. Combining this with a careful characterization of the survivable
subgraphs, allows us to determine the connectivity of $G \setminus \{x,y\}$ for
every pair $x,y \in V$, using $\widetilde{O}(D)$-rounds. We believe that the
tools provided in this paper are useful for omitting the $\Delta$-dependency
even for larger cut values.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Incremental Approximate Maximum Flow in $m^{1/2+o(1)}$ update time</title>
  <guid>http://arxiv.org/abs/2211.09606</guid>
  <link>http://arxiv.org/abs/2211.09606</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goranci_G/0/1/0/all/0/1&quot;&gt;Gramoz Goranci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1&quot;&gt;Monika Henzinger&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We show an $(1+\epsilon)$-approximation algorithm for maintaining maximum
$s$-$t$ flow under $m$ edge insertions in $m^{1/2+o(1)} \epsilon^{-1/2}$
amortized update time for directed, unweighted graphs. This constitutes the
first sublinear dynamic maximum flow algorithm in general sparse graphs with
arbitrarily good approximation guarantee.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A (simple) classical algorithm for estimating Betti numbers</title>
  <guid>http://arxiv.org/abs/2211.09618</guid>
  <link>http://arxiv.org/abs/2211.09618</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Apers_S/0/1/0/all/0/1&quot;&gt;Simon Apers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1&quot;&gt;Sayantan Sen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szabo_D/0/1/0/all/0/1&quot;&gt;D&amp;#xe1;niel Szab&amp;#xf3;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We describe a simple algorithm for estimating the $k$-th normalized Betti
number of a simplicial complex over $n$ elements using the path integral Monte
Carlo method. For a general simplicial complex, the running time of our
algorithm is $n^{O(\frac{1}{\gamma}\log\frac{1}{\varepsilon})}$ with $\gamma$
measuring the spectral gap of the combinatorial Laplacian and $\varepsilon \in
(0,1)$ the additive precision. In the case of a clique complex, the running
time of our algorithm improves to
$(n/\lambda_{\max})^{O(\frac{1}{\gamma}\log\frac{1}{\varepsilon})}$ with
$\lambda_{\max} \geq k$ the maximum eigenvalue of the combinatorial Laplacian.
Our algorithm provides a classical benchmark for a line of quantum algorithms
for estimating Betti numbers, and it matches their running time on clique
complexes when the spectral gap is constant and $k \in \Omega(n)$ or
$\lambda_{\max} \in \Omega(n)$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Minimum Path Cover in Parameterized Linear Time</title>
  <guid>http://arxiv.org/abs/2211.09659</guid>
  <link>http://arxiv.org/abs/2211.09659</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caceres_M/0/1/0/all/0/1&quot;&gt;Manuel Caceres&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cairo_M/0/1/0/all/0/1&quot;&gt;Massimo Cairo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mumey_B/0/1/0/all/0/1&quot;&gt;Brendan Mumey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizzi_R/0/1/0/all/0/1&quot;&gt;Romeo Rizzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomescu_A/0/1/0/all/0/1&quot;&gt;Alexandru I. Tomescu&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A minimum path cover (MPC) of a directed acyclic graph (DAG) $G = (V,E)$ is a
minimum-size set of paths that together cover all the vertices of the DAG.
Computing an MPC is a basic polynomial problem, dating back to Dilworth&#39;s and
Fulkerson&#39;s results in the 1950s. Since the size $k$ of an MPC (also known as
the width) can be small in practical applications, research has also studied
algorithms whose running time is parameterized on $k$.
&lt;/p&gt;
&lt;p&gt;We obtain a new MPC parameterized algorithm for DAGs running in time
$O(k^2|V| + |E|)$. Our algorithm is the first solving the problem in
parameterized linear time. Additionally, we obtain an edge sparsification
algorithm preserving the width of a DAG but reducing $|E|$ to less than $2|V|$.
This algorithm runs in time $O(k^2|V|)$ and requires an MPC of a DAG as input,
thus its total running time is the same as the running time of our MPC
algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Features for the 0-1 knapsack problem based on inclusionwise maximal solutions</title>
  <guid>http://arxiv.org/abs/2211.09665</guid>
  <link>http://arxiv.org/abs/2211.09665</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jooken_J/0/1/0/all/0/1&quot;&gt;Jorik Jooken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leyman_P/0/1/0/all/0/1&quot;&gt;Pieter Leyman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Causmaecker_P/0/1/0/all/0/1&quot;&gt;Patrick De Causmaecker&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Decades of research on the 0-1 knapsack problem led to very efficient
algorithms that are able to quickly solve large problem instances to
optimality. This prompted researchers to also investigate whether relatively
small problem instances exist that are hard for existing solvers and
investigate which features characterize their hardness. Previously the authors
proposed a new class of hard 0-1 knapsack problem instances and demonstrated
that the properties of so-called inclusionwise maximal solutions (IMSs) can be
important hardness indicators for this class. In the current paper, we
formulate several new computationally challenging problems related to the IMSs
of arbitrary 0-1 knapsack problem instances. Based on generalizations of
previous work and new structural results about IMSs, we formulate polynomial
and pseudopolynomial time algorithms for solving these problems. From this we
derive a set of 14 computationally expensive features, which we calculate for
two large datasets on a supercomputer in approximately 540 CPU-hours. We show
that the proposed features contain important information related to the
empirical hardness of a problem instance that was missing in earlier features
from the literature by training machine learning models that can accurately
predict the empirical hardness of a wide variety of 0-1 knapsack problem
instances. Using the instance space analysis methodology, we also show that
hard 0-1 knapsack problem instances are clustered together around a relatively
dense region of the instance space and several features behave differently in
the easy and hard parts of the instance space.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Extensions of the $(p,q)$-Flexible-Graph-Connectivity model</title>
  <guid>http://arxiv.org/abs/2211.09747</guid>
  <link>http://arxiv.org/abs/2211.09747</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_I/0/1/0/all/0/1&quot;&gt;Ishan Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheriyan_J/0/1/0/all/0/1&quot;&gt;Joseph Cheriyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grout_L/0/1/0/all/0/1&quot;&gt;Logan Grout&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahimpur_S/0/1/0/all/0/1&quot;&gt;Sharat Ibrahimpur&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present approximation algorithms for network design problems in some
models related to the $(p,q)$-FGC model. Adjiashvili, Hommelsheim and
M\&quot;uhlenthaler introduced the model of Flexible Graph Connectivity that we
denote by FGC. Boyd, Cheriyan, Haddadan and Ibrahimpur introduced a
generalization of FGC. Let $p\geq 1$ and $q\geq 0$ be integers. In an instance
of the $(p,q)$-Flexible Graph Connectivity problem, denoted $(p,q)$-FGC, we
have an undirected connected graph $G = (V,E)$, a partition of $E$ into a set
of safe edges and a set of unsafe edges, and nonnegative costs
$c\in\mathbb{R}_{\geq0}^E$ on the edges. A subset $F \subseteq E$ of edges is
feasible for the $(p,q)$-FGC problem if for any set of unsafe edges, $F&#39;$, with
$|F&#39;|\leq q$, the subgraph $(V, F \setminus F&#39;)$ is $p$-edge connected. The
algorithmic goal is to find a feasible edge-set $F$ that minimizes $c(F) =
\sum_{e \in F} c_e$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Cheeger Inequalities for Directed Graphs and Hypergraphs Using Reweighted Eigenvalues</title>
  <guid>http://arxiv.org/abs/2211.09776</guid>
  <link>http://arxiv.org/abs/2211.09776</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lau_L/0/1/0/all/0/1&quot;&gt;Lap Chi Lau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tung_K/0/1/0/all/0/1&quot;&gt;Kam Chuen Tung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Robert Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We derive Cheeger inequalities for directed graphs and hypergraphs using the
reweighted eigenvalue approach that was recently developed for vertex expansion
in undirected graphs [OZ22,KLT22,JPV22]. The goal is to develop a new spectral
theory for directed graphs and an alternative spectral theory for hypergraphs.
&lt;/p&gt;
&lt;p&gt;The first main result is a Cheeger inequality relating the vertex expansion
$\vec{\psi}(G)$ of a directed graph $G$ to the vertex-capacitated maximum
reweighted second eigenvalue $\vec{\lambda}_2^{v*}$: \[ \vec{\lambda}_2^{v*}
\lesssim \vec{\psi}(G) \lesssim \sqrt{\vec{\lambda}_2^{v*} \cdot \log
(\Delta/\vec{\lambda}_2^{v*})}. \] This provides a combinatorial
characterization of the fastest mixing time of a directed graph by vertex
expansion, and builds a new connection between reweighted eigenvalued, vertex
expansion, and fastest mixing time for directed graphs.
&lt;/p&gt;
&lt;p&gt;The second main result is a stronger Cheeger inequality relating the edge
conductance $\vec{\phi}(G)$ of a directed graph $G$ to the edge-capacitated
maximum reweighted second eigenvalue $\vec{\lambda}_2^{e*}$: \[
\vec{\lambda}_2^{e*} \lesssim \vec{\phi}(G) \lesssim \sqrt{\vec{\lambda}_2^{e*}
\cdot \log (1/\vec{\lambda}_2^{e*})}. \] This provides a certificate for a
directed graph to be an expander and a spectral algorithm to find a sparse cut
in a directed graph, playing a similar role as Cheeger&#39;s inequality in
certifying graph expansion and in the spectral partitioning algorithm for
undirected graphs.
&lt;/p&gt;
&lt;p&gt;We also use this reweighted eigenvalue approach to derive the improved
Cheeger inequality for directed graphs, and furthermore to derive several
Cheeger inequalities for hypergraphs that match and improve the existing
results in [Lou15,CLTZ18]. These are supporting results that this provides a
unifying approach to lift the spectral theory for undirected graphs to more
general settings.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-18 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Amazing: Justin Gilmer gave a constant lower bound for the union-closed sets conjecture</title>
  <guid>http://gilkalai.wordpress.com/?p=23540</guid>
  <link>https://gilkalai.wordpress.com/2022/11/17/amazing-justin-gilmer-gave-a-constant-lower-bound-for-the-union-closed-sets-conjecture/</link>
  <description>
    &lt;p&gt;Frankl&amp;#8217;s conjecture (aka the union closed sets conjecture) asserts that if &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ccal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Ccal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ccal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;cal F&quot; class=&quot;latex&quot; /&gt; is a family of subsets of [n] (=: &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn+%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn+%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn+%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;{1,2,&amp;#92;dots,n &amp;#92;}&quot; class=&quot;latex&quot; /&gt;) which is closed under union then there is an element &lt;img src=&quot;https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;k&quot; class=&quot;latex&quot; /&gt; such that&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge+%5Cfrac+%7B1%7D%7B2%7D%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge+%5Cfrac+%7B1%7D%7B2%7D%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge+%5Cfrac+%7B1%7D%7B2%7D%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;|&amp;#92;{S &amp;#92;in {&amp;#92;cal F}: k &amp;#92;in S&amp;#92;}| &amp;#92;ge &amp;#92;frac {1}{2}|{&amp;#92;cal F}|.&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Justin Gilmer just proved an amazing weaker form of the conjecture asserting that there always exists an element &lt;img src=&quot;https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;k&quot; class=&quot;latex&quot; /&gt; such that&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge%C2%A0+0.01+%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge%C2%A0+0.01+%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7C%5C%7BS+%5Cin+%7B%5Ccal+F%7D%3A+k+%5Cin+S%5C%7D%7C+%5Cge%C2%A0+0.01+%7C%7B%5Ccal+F%7D%7C.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;|&amp;#92;{S &amp;#92;in {&amp;#92;cal F}: k &amp;#92;in S&amp;#92;}| &amp;#92;ge  0.01 |{&amp;#92;cal F}|.&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p&gt;This is am amazing progress! Congratulations, Justin.&lt;/p&gt;
&lt;p&gt;The breakthrough paper, just posted on the arXiv is:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2211.09055&quot;&gt;A constant lower bound for the union-closed sets conjecture&lt;/a&gt; by Justin Gilmer&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; We show that for any union-closed family  &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D+%5Csubseteq+2%5E%7B%5Bn%5D%7D%2C+%5Cmathcal%7BF%7D+%5Cneq+%5C%7B%5Cemptyset%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D+%5Csubseteq+2%5E%7B%5Bn%5D%7D%2C+%5Cmathcal%7BF%7D+%5Cneq+%5C%7B%5Cemptyset%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D+%5Csubseteq+2%5E%7B%5Bn%5D%7D%2C+%5Cmathcal%7BF%7D+%5Cneq+%5C%7B%5Cemptyset%5C%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;mathcal{F} &amp;#92;subseteq 2^{[n]}, &amp;#92;mathcal{F} &amp;#92;neq &amp;#92;{&amp;#92;emptyset&amp;#92;}&quot; class=&quot;latex&quot; /&gt; there exists an &lt;img src=&quot;https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;i &amp;#92;in [n]&quot; class=&quot;latex&quot; /&gt;  which is contained in a &lt;span id=&quot;MathJax-Element-3-Frame&quot; class=&quot;MathJax&quot;&gt;&lt;span id=&quot;MathJax-Span-29&quot; class=&quot;math&quot;&gt;&lt;span id=&quot;MathJax-Span-30&quot; class=&quot;mrow&quot;&gt;&lt;span id=&quot;MathJax-Span-31&quot; class=&quot;mn&quot;&gt;0.01&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; fraction of the sets in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cmathcal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cmathcal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal+F&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;mathcal F&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;This is the first known constant lower bound, and improves upon the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog_2%28%5Cmathcal%7BF%7D%7C%29%5E%7B-1%7D%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog_2%28%5Cmathcal%7BF%7D%7C%29%5E%7B-1%7D%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog_2%28%5Cmathcal%7BF%7D%7C%29%5E%7B-1%7D%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;Omega(&amp;#92;log_2(&amp;#92;mathcal{F}|)^{-1})&quot; class=&quot;latex&quot; /&gt; bounds of Knill and Wójick.&lt;/p&gt;
&lt;p&gt;Our result follows from an information theoretic strengthening of the conjecture. Specifically, we show that if &lt;img src=&quot;https://s0.wp.com/latex.php?latex=A%2CB&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=A%2CB&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%2CB&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;A,B&quot; class=&quot;latex&quot; /&gt; are independent samples from a distribution over subsets of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;[n]&quot; class=&quot;latex&quot; /&gt;  such that &lt;img src=&quot;https://s0.wp.com/latex.php?latex=Pr%5Bi+%5Cin+A%5D+%3C+0.01&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=Pr%5Bi+%5Cin+A%5D+%3C+0.01&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Pr%5Bi+%5Cin+A%5D+%3C+0.01&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;Pr[i &amp;#92;in A] &amp;lt; 0.01&quot; class=&quot;latex&quot; /&gt; for all &lt;span id=&quot;MathJax-Element-9-Frame&quot; class=&quot;MathJax&quot;&gt;&lt;span id=&quot;MathJax-Span-83&quot; class=&quot;math&quot;&gt;&lt;span id=&quot;MathJax-Span-84&quot; class=&quot;mrow&quot;&gt;&lt;span id=&quot;MathJax-Span-85&quot; class=&quot;mi&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=i&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=i&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;i&quot; class=&quot;latex&quot; /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=H%28A%29%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=H%28A%29%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28A%29%3E0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;H(A)&amp;gt;0&quot; class=&quot;latex&quot; /&gt;, then &lt;img src=&quot;https://s0.wp.com/latex.php?latex=H%28A+%5Ccup+B%29%3E+H%28A%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=H%28A+%5Ccup+B%29%3E+H%28A%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28A+%5Ccup+B%29%3E+H%28A%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;H(A &amp;#92;cup B)&amp;gt; H(A)&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;______&lt;/p&gt;
&lt;p&gt;Mike Saks who first told me about the breakthrough wrote &amp;#8220;the bound comes from a simple clever idea (using information theory) and 5 pages of gentle technical calculations.&amp;#8221; (I thank Mike, Ryan &lt;span class=&quot;gI&quot;&gt;&lt;span class=&quot;qu&quot; role=&quot;gridcell&quot;&gt;&lt;span class=&quot;gD&quot;&gt;Alweiss, and Nati Linial who wrote me about it.) &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We mentioned Frankl&amp;#8217;s conjecture several times including &lt;a href=&quot;https://gilkalai.wordpress.com/2008/04/29/hello-world/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://gilkalai.wordpress.com/2017/12/26/ilam-karpas-frankls-conjecture-for-large-families/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://gilkalai.wordpress.com/2018/03/09/frankls-conjecture-for-large-families-ilan-karpas-proof/&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;https://gilkalai.wordpress.com/2021/01/29/possible-future-polymath-projects-2009-2021/&quot;&gt;here&lt;/a&gt;. &lt;a href=&quot;https://gowers.wordpress.com/category/polymath11/&quot;&gt;Polymath11&lt;/a&gt; on Tim Gowers&amp;#8217;s blog was devoted to the conjecture. Below the fold: What it will take to prove the conjecture in its full strength and another beautiful conjecture by Peter Frankl.&lt;/p&gt;
&lt;p&gt;&lt;span id=&quot;more-23540&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;What is the limit of Gilmer&amp;#8217;s method and what it will take to prove the Frankl conjecture&lt;/h3&gt;
&lt;p&gt;Justin Gilmer&amp;#8217;s mentions that proving a tight bout for Lemma 1 in the paper will push the 0.01 bound to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cfrac%7B3-%5Csqrt+5%7D%7B2%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cfrac%7B3-%5Csqrt+5%7D%7B2%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac%7B3-%5Csqrt+5%7D%7B2%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;frac{3-&amp;#92;sqrt 5}{2}&quot; class=&quot;latex&quot; /&gt;=&lt;span id=&quot;cwos&quot; class=&quot;qv3Wpe&quot; dir=&quot;ltr&quot;&gt;0.381966&amp;#8230; . He also presents an appealing information-theoretic strengthening of the conjecture which may consist of a path toward a proof. &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Another beautiful conjecture by Peter Frankl&lt;/h3&gt;
&lt;p&gt;To face a possible risk that Frankl&amp;#8217;s &amp;#8220;union closed&amp;#8221; conjecture will be solved here is another beautiful conjecture by Peter Frankl.&lt;/p&gt;
&lt;p&gt;A family of sets is convex if whenever &lt;img src=&quot;https://s0.wp.com/latex.php?latex=A+%5Csubset+B+%5Csubset+C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=A+%5Csubset+B+%5Csubset+C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A+%5Csubset+B+%5Csubset+C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;A &amp;#92;subset B &amp;#92;subset C&quot; class=&quot;latex&quot; /&gt; and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=A%2CC+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=A%2CC+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%2CC+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;A,C &amp;#92;in {&amp;#92;cal F}&quot; class=&quot;latex&quot; /&gt; then also &lt;img src=&quot;https://s0.wp.com/latex.php?latex=B+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=B+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B+%5Cin+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;B &amp;#92;in {&amp;#92;cal F}&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;Conjecture (&lt;strong&gt;P. Frankl&lt;/strong&gt;):  Let &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;{&amp;#92;cal F}&quot; class=&quot;latex&quot; /&gt; be a convex family of subsets of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;[n]&quot; class=&quot;latex&quot; /&gt;. Then there exists an antichain &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ccal+G%7D+%5Csubset+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ccal+G%7D+%5Csubset+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Ccal+G%7D+%5Csubset+%7B%5Ccal+F%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;{&amp;#92;cal G} &amp;#92;subset {&amp;#92;cal F}&quot; class=&quot;latex&quot; /&gt; such that&lt;/p&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%7C%7B%5Ccal+G%7D%7C%2F%7C%7B%5Ccal+F%7D%7C+%5Cge+%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D%2F2%5En.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%7C%7B%5Ccal+G%7D%7C%2F%7C%7B%5Ccal+F%7D%7C+%5Cge+%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D%2F2%5En.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7C%7B%5Ccal+G%7D%7C%2F%7C%7B%5Ccal+F%7D%7C+%5Cge+%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D%2F2%5En.&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;|{&amp;#92;cal G}|/|{&amp;#92;cal F}| &amp;#92;ge {{n} &amp;#92;choose {[n/2]}}/2^n.&quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 20:47:56 UTC</pubDate>
  <author>Gil Kalai</author>
</item>

<item>
  <title>Fall Jobs Post 2022</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-1774067265916943204</guid>
  <link>http://blog.computationalcomplexity.org/2022/11/fall-jobs-post-2022.html</link>
  <description>
    &lt;p&gt;In the fall I try to make my predictions on the faculty job market for the spring. The outlook this year is hazy as we have two forces pushing in opposite directions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Most of the largest tech companies are having layoffs and hiring freezes amidst a recession, higher expenses and a drop in revenue from cloud and advertising. Meanwhile computing has never had a more exciting (or scary) year of advances, particularly in generative AI. I can&#39;t remember such a dichotomy in the past. In the downturn after the 2008 financial crisis computing wasn&#39;t particularly exciting as the cloud, smart phones and machine learning were then just nascent technologies.&lt;/p&gt;&lt;p&gt;We&#39;ll probably have more competition in the academic job market as many new PhDs may decide to look at academic positions because of limited opportunities in large tech companies. We might even see a reverse migration from industry to academia from those who now might see universities as a safe haven.&lt;/p&gt;&lt;p&gt;What about the students? Will they still come in droves driven by the excitement in computing or get scared off by the downturn in the tech industry. They shouldn&#39;t worry--the market should turn around by the time they graduate and even today there are plenty of tech jobs in smaller and midsize tech companies as well as companies that deal with data, which is pretty much every company.&lt;/p&gt;&lt;p&gt;But perception matters more than reality. If students do stay away that might reduce pressure to grow CS departments.&lt;/p&gt;&lt;p&gt;Onto my usual advice. Give yourself a good virtual face. Have a well-designed web page with access to all your job materials and papers. Maintain your Google Scholar page. Add yourself to the CRA&#39;s&amp;nbsp;&lt;a href=&quot;https://cra.org/cv-database/&quot;&gt;CV database&lt;/a&gt;. Find a way to stand out, perhaps a short video describing your research.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Best source for finding jobs are the ads from the&amp;nbsp;&lt;a href=&quot;https://cra.org/ads/&quot;&gt;CRA&lt;/a&gt;&amp;nbsp;and the&amp;nbsp;&lt;a href=&quot;https://jobs.acm.org/&quot;&gt;ACM&lt;/a&gt;. For theoretical computer science specific postdoc and faculty positions check out&amp;nbsp;&lt;a href=&quot;https://cstheory-jobs.org/&quot;&gt;TCS Jobs&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a href=&quot;http://dmatheorynet.blogspot.com/&quot;&gt;Theory Announcements&lt;/a&gt;. If you have jobs to announce, please post to the above and/or feel free to leave a comment on this post. Even if you don&#39;t see an ad for a specific school they may still be hiring, check out their website or email someone at the department. You&#39;ll never know if you don&#39;t ask.&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 14:44:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>Senior Faculty Position at Williams College (apply by December 1, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/17/senior-faculty-position-at-williams-college-apply-by-december-1-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/17/senior-faculty-position-at-williams-college-apply-by-december-1-2022/</link>
  <description>
    &lt;p&gt;The Department of Computer Science at Williams College invites applications for a tenured faculty position at the associate or full professor level beginning July 1, 2023. We welcome candidates from all areas of computer science who can contribute to the vibrancy of our academic community through their research, teaching, and service.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://apply.interfolio.com/111662&quot;&gt;https://apply.interfolio.com/111662&lt;/a&gt;&lt;br /&gt;
Email: cshiring@williams.edu&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 14:11:06 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Postdocs at Max Planck Institute for Informatics (apply by December 31, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/17/postdocs-at-max-planck-institute-for-informatics-apply-by-december-31-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/17/postdocs-at-max-planck-institute-for-informatics-apply-by-december-31-2022/</link>
  <description>
    &lt;p&gt;We are looking for applicants from all areas of algorithms and complexity, including related areas like mathematical optimization, distributed computing, and algorithms engineering. Postdoctoral fellowships are available at the algorithms and complexity department for two years through the Guest Program of our institute.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;http://www.mpi-inf.mpg.de/d1postdoc&quot;&gt;http://www.mpi-inf.mpg.de/d1postdoc&lt;/a&gt;&lt;br /&gt;
Email: d1office@mpi-inf.mpg.de&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 13:29:17 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Postdoc position in algorithms at University of Warwick (apply by December 6, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/11/17/postdoc-position-in-algorithms-at-university-of-warwick-apply-by-december-6-2022/</guid>
  <link>https://cstheory-jobs.org/2022/11/17/postdoc-position-in-algorithms-at-university-of-warwick-apply-by-december-6-2022/</link>
  <description>
    &lt;p&gt;In connection with a research grant of Dr. Ramanujan Sridharan and Prof. Graham Cormode at University of Warwick, UK, we are seeking excellent candidates for a postdoctoral fellow position in the area of design and analysis of parameterized and approximation algorithms.&lt;br /&gt;
The position is for 18 months and start date can be negotiated (preferably by March 2023).&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://tinyurl.com/ksz8rjfa&quot;&gt;https://tinyurl.com/ksz8rjfa&lt;/a&gt;&lt;br /&gt;
Email: r.maadapuzhi-sridharan@warwick.ac.uk&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 08:54:03 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Sneerers</title>
  <guid>https://scottaaronson.blog/?p=6813</guid>
  <link>https://scottaaronson.blog/?p=6813</link>
  <description>
    &lt;p&gt;In the past few weeks, I&amp;#8217;ve learned two ways to think about online sneerers that have been helping me tremendously, and that I wanted to share in case they&amp;#8217;re helpful to others:&lt;/p&gt;



&lt;p&gt;First, they&amp;#8217;re like a train in a movie that&amp;#8217;s barreling directly towards the camera. If you haven&amp;#8217;t yet internalized how the medium works, absolutely terrifying! Run from the theater! If you &lt;em&gt;have&lt;/em&gt; internalized it, though, you can sit and watch without even flinching.&lt;/p&gt;



&lt;p&gt;Second, the sneerers are like alligators&amp;#8212;and about as likely to be moved by your appeals to reason and empathy. But if, like me, you&amp;#8217;re lucky enough to have a loving family, friends, colleagues, and a nigh-uncancellable career, then it&amp;#8217;s as though you&amp;#8217;re standing on a bridge high above, looking down at the gators as they snap their jaws at you uselessly. There&amp;#8217;s &lt;em&gt;really&lt;/em&gt; no moral or intellectual obligation to go down to the swamp to wrestle them.  If they mean to attack you, let them at least come up to the bridge.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 01:48:08 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>Complexity Results for Implication Bases of Convex Geometries</title>
  <guid>http://arxiv.org/abs/2211.08524</guid>
  <link>http://arxiv.org/abs/2211.08524</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bichoupan_T/0/1/0/all/0/1&quot;&gt;Todd Bichoupan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A convex geometry is finite zero-closed closure system that satisfies the
anti-exchange property. Complexity results are given for two open problems
related to representations of convex geometries using implication bases. In
particular, the problem of optimizing an implication basis for a convex
geometry is shown to be NP-hard by establishing a reduction from the minimum
cardinality generator problem for general closure systems. Furthermore, even
the problem of deciding whether an implication basis defines a convex geometry
is shown to be co-NP-complete by a reduction from the Boolean tautology
problem.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The wrong direction of Jensen&#39;s inequality is algorithmically right</title>
  <guid>http://arxiv.org/abs/2211.08563</guid>
  <link>http://arxiv.org/abs/2211.08563</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zamir_O/0/1/0/all/0/1&quot;&gt;Or Zamir&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $\mathcal{A}$ be an algorithm with expected running time $e^X$,
conditioned on the value of some random variable $X$. We construct an algorithm
$\mathcal{A&#39;}$ with expected running time $O(e^{E[X]})$, that fully executes
$\mathcal{A}$. In particular, an algorithm whose running time is a random
variable $T$ can be converted to one with expected running time $O(e^{E[\ln
T]})$, which is never worse than $O(E[T])$. No information about the
distribution of $X$ is required for the construction of $\mathcal{A}&#39;$.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The Exact Bipartite Matching Polytope Has Exponential Extension Complexity</title>
  <guid>http://arxiv.org/abs/2211.09106</guid>
  <link>http://arxiv.org/abs/2211.09106</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1&quot;&gt;Xinrui Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svensson_O/0/1/0/all/0/1&quot;&gt;Ola Svensson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1&quot;&gt;Weiqiang Yuan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a graph with edges colored red or blue and an integer $k$, the exact
perfect matching problem asks if there exists a perfect matching with exactly
$k$ red edges. There exists a randomized polylogarithmic-time parallel
algorithm to solve this problem, dating back to the eighties, but no
deterministic polynomial-time algorithm is known, even for bipartite graphs. In
this paper we show that there is no sub-exponential sized linear program that
can describe the convex hull of exact matchings in bipartite graphs. In fact,
we prove something stronger, that there is no sub-exponential sized linear
program to describe the convex hull of perfect matchings with an odd number of
red edges.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Keeping it sparse: Computing Persistent Homology revised</title>
  <guid>http://arxiv.org/abs/2211.09075</guid>
  <link>http://arxiv.org/abs/2211.09075</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bauer_U/0/1/0/all/0/1&quot;&gt;Ulrich Bauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masood_T/0/1/0/all/0/1&quot;&gt;Talha Bin Masood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giunti_B/0/1/0/all/0/1&quot;&gt;Barbara Giunti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houry_G/0/1/0/all/0/1&quot;&gt;Guillaume Houry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kerber_M/0/1/0/all/0/1&quot;&gt;Michael Kerber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rathod_A/0/1/0/all/0/1&quot;&gt;Abhishek Rathod&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work, we study several variants of matrix reduction via Gaussian
elimination that try to keep the reduced matrix sparse. The motivation comes
from the growing field of topological data analysis where matrix reduction is
the major subroutine to compute barcodes. We propose two novel variants of the
standard algorithm, called swap and retrospective reductions, which improve
upon state-of-the-art techniques on several examples in practice. We also
present novel output-sensitive bounds for the retrospective variant which
better explain the discrepancy between the cubic worst-case complexity bound
and the almost linear practical behavior of matrix reduction. Finally, we
provide several constructions on which one of the variants performs strictly
better than the others.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 01:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Comparative Learning: A Sample Complexity Theory for Two Hypothesis Classes</title>
  <guid>http://arxiv.org/abs/2211.09101</guid>
  <link>http://arxiv.org/abs/2211.09101</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1&quot;&gt;Lunjia Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peale_C/0/1/0/all/0/1&quot;&gt;Charlotte Peale&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In many learning theory problems, a central role is played by a hypothesis
class: we might assume that the data is labeled according to a hypothesis in
the class (usually referred to as the realizable setting), or we might evaluate
the learned model by comparing it with the best hypothesis in the class (the
agnostic setting).
&lt;/p&gt;
&lt;p&gt;Taking a step beyond these classic setups that involve only a single
hypothesis class, we introduce comparative learning as a combination of the
realizable and agnostic settings in PAC learning: given two binary hypothesis
classes $S$ and $B$, we assume that the data is labeled according to a
hypothesis in the source class $S$ and require the learned model to achieve an
accuracy comparable to the best hypothesis in the benchmark class $B$. Even
when both $S$ and $B$ have infinite VC dimensions, comparative learning can
still have a small sample complexity. We show that the sample complexity of
comparative learning is characterized by the mutual VC dimension
$\mathsf{VC}(S,B)$ which we define to be the maximum size of a subset shattered
by both $S$ and $B$. We also show a similar result in the online setting, where
we give a regret characterization in terms of the mutual Littlestone dimension
$\mathsf{Ldim}(S,B)$. These results also hold for partial hypotheses.
&lt;/p&gt;
&lt;p&gt;We additionally show that the insights necessary to characterize the sample
complexity of comparative learning can be applied to characterize the sample
complexity of realizable multiaccuracy and multicalibration using the mutual
fat-shattering dimension, an analogue of the mutual VC dimension for
real-valued hypotheses. This not only solves an open problem proposed by Hu,
Peale, Reingold (2022), but also leads to independently interesting results
extending classic ones about regression, boosting, and covering number to our
two-hypothesis-class setting.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Bandit Algorithms for Prophet Inequality and Pandora&#39;s Box</title>
  <guid>http://arxiv.org/abs/2211.08586</guid>
  <link>http://arxiv.org/abs/2211.08586</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gatmiry_K/0/1/0/all/0/1&quot;&gt;Khashayar Gatmiry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kesselheim_T/0/1/0/all/0/1&quot;&gt;Thomas Kesselheim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1&quot;&gt;Sahil Singla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yifan Wang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The Prophet Inequality and Pandora&#39;s Box problems are fundamental stochastic
problem with applications in Mechanism Design, Online Algorithms, Stochastic
Optimization, Optimal Stopping, and Operations Research. A usual assumption in
these works is that the probability distributions of the $n$ underlying random
variables are given as input to the algorithm. Since in practice these
distributions need to be learned, we initiate the study of such stochastic
problems in the Multi-Armed Bandits model.
&lt;/p&gt;
&lt;p&gt;In the Multi-Armed Bandits model we interact with $n$ unknown distributions
over $T$ rounds: in round $t$ we play a policy $x^{(t)}$ and receive a partial
(bandit) feedback on the performance of $x^{(t)}$. The goal is to minimize the
regret, which is the difference over $T$ rounds in the total value of the
optimal algorithm that knows the distributions vs. the total value of our
algorithm that learns the distributions from the partial feedback. Our main
results give near-optimal $\tilde{O}(\mathsf{poly}(n)\sqrt{T})$ total regret
algorithms for both Prophet Inequality and Pandora&#39;s Box.
&lt;/p&gt;
&lt;p&gt;Our proofs proceed by maintaining confidence intervals on the unknown indices
of the optimal policy. The exploration-exploitation tradeoff prevents us from
directly refining these confidence intervals, so the main technique is to
design a regret upper bound that is learnable while playing low-regret Bandit
policies.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Dichotomy Theorem for Linear Time Homomorphism Orbit Counting in Bounded Degeneracy Graphs</title>
  <guid>http://arxiv.org/abs/2211.08605</guid>
  <link>http://arxiv.org/abs/2211.08605</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paul_Pena_D/0/1/0/all/0/1&quot;&gt;Daniel Paul-Pena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seshadhri_C/0/1/0/all/0/1&quot;&gt;C. Seshadhri&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Counting the number of homomorphisms of a pattern graph H in a large input
graph G is a fundamental problem in computer science. There are myriad
applications of this problem in databases, graph algorithms, and network
science. Often, we need more than just the total count. Especially in large
network analysis, we wish to compute, for each vertex v of G, the number of
H-homomorphisms that v participates in. This problem is referred to as
homomorphism orbit counting, as it relates to the orbits of vertices of H under
its automorphisms.
&lt;/p&gt;
&lt;p&gt;Given the need for fast algorithms for this problem, we study when
near-linear time algorithms are possible. A natural restriction is to assume
that the input graph G has bounded degeneracy, a commonly observed property in
modern massive networks. Can we characterize the patterns H for which
homomorphism orbit counting can be done in linear time?
&lt;/p&gt;
&lt;p&gt;We discover a dichotomy theorem that resolves this problem. For pattern H,
let l be the length of the longest induced path between any two vertices of the
same orbit (under the automorphisms of H). If l &amp;lt;= 5, then H-homomorphism orbit
counting can be done in linear time for bounded degeneracy graphs. If l &amp;gt; 5,
then (assuming fine-grained complexity conjectures) there is no near-linear
time algorithm for this problem. We build on existing work on dichotomy
theorems for counting the total H-homomorphism count. Somewhat surprisingly,
there exist (and we characterize) patterns H for which the total homomorphism
count can be computed in linear time, but the corresponding orbit counting
problem cannot be done in near-linear time.
&lt;/p&gt;
  </description>
  <pubDate>2022-11-17 01:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

</channel>
</rss>
