<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>PostDoc at Technion faculty of Computer Science (Israel) (apply by October 31, 2022)</title>
  <guid>http://cstheory-jobs.org/2022/09/15/postdoc-at-technion-faculty-of-computer-science-israel-apply-by-october-31-2022/</guid>
  <link>https://cstheory-jobs.org/2022/09/15/postdoc-at-technion-faculty-of-computer-science-israel-apply-by-october-31-2022/</link>
  <description>
    &lt;p&gt;Looking for a PostDoc interested in the area of sublinear algorithms and property testing, for up to four years. PhD applications will also be considered.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://eldar.cswp.cs.technion.ac.il/positions/&quot;&gt;https://eldar.cswp.cs.technion.ac.il/positions/&lt;/a&gt;&lt;br /&gt;
Email: eldar@cs.technion.ac.il&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2022-09-15 21:13:46 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Monarachy: A Problem with Definitions</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-6674583717006469349</guid>
  <link>http://blog.computationalcomplexity.org/2022/09/monarachy-problem-with-definitions.html</link>
  <description>
    &lt;p&gt;&amp;nbsp;As I am sure you know, Queen Elizabeth II passed away at the age of 96 recently.&amp;nbsp; I am not a royal-watcher, but I am a royal-watcher-watcher. That is, the question of why people care about the lives of these people intrigues me. A few notes&lt;/p&gt;&lt;p&gt;1) Was she a &lt;i&gt;good Queen?&lt;/i&gt; People tend to think so; however, since the job is somewhat ill-defined its hard to say.&amp;nbsp;&lt;/p&gt;&lt;p&gt;2) The Queen is supposed to be above politics (she does not vote- I was surprised to find out that legally she can, but she really can&#39;t). We know very few of Queen Elizabeth II&#39;s opinions on political events. But the notion of &lt;i&gt;political &lt;/i&gt;is not well defined. One would think that if she did an appeal for people to take the COVID vax that would not be political, but somehow it is (I do not know if she did such an appeal). King Charles III believes in global warming and that we need to do something about it. This again should not be political but is.&amp;nbsp;&lt;/p&gt;&lt;p&gt;3) She is the second longest reigning Monarch. First is King Louis XIV who first became king at the age of 4. I had a blog complaining about this&amp;nbsp;&lt;a href=&quot;https://blog.computationalcomplexity.org/2022/05/queen-elizabeth-is-3rd-longest-reigning.html&quot;&gt;here&lt;/a&gt;. However, there is a more interesting point I want to make. From the first to the last day of King Louis XIV reign not much had changed. Technology, politics, other things just didn&#39;t change much. By contrast the world changed A LOT between Queen Elizabeth II first and last day:&lt;/p&gt;&lt;p&gt;a) The British were an important power in 1952. Less so now.&lt;/p&gt;&lt;p&gt;b) When her father died she was in Kenya and it took 4 hours to get the news to her. Now that would be immediate.&amp;nbsp;&lt;/p&gt;&lt;p&gt;c) Divorce was considered bad in 1952 and is why King Edmond VIII could not be king (he wanted to marry a twice-divorced women whose ex-husbands were still alive). And now three of the Queen&#39;s children have been divorced.&lt;/p&gt;&lt;p&gt;d) Gay people.. enough said. There has even been a royal gay wedding, see&amp;nbsp;&lt;a href=&quot;https://www.dailymail.co.uk/news/article-5849971/Royal-familys-gay-wedding-story-Queens-cousin-Lord-Ivar-Mountbatten.html&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Black people (can&#39;t call them African-Americans), Women,... you fill it in.&amp;nbsp;&lt;/p&gt;&lt;p&gt;e) When Charles wanted to get married it seemed to be important that he marry a virgin. We cannot imagine this mentality anymore. When Prince William and Kate got married they were already living together and this was NOT an issue for ANYONE. I looked up what the Church of England thought of it and all I got was some very bland comments like &lt;i&gt;That&#39;s what young people do nowadays.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;3) Is the monarchy a good thing? As an American I feel I do not have a right to an opinion. If the citizens of the United Kingdom approve of the monarch (polls show they do) then who am I do tell them they are wrong? Even so, lets look at reasons for it&lt;/p&gt;&lt;p&gt;a) Tourism. It has been said that the Monarchy leads to MONEY from tourism. So it is worth the price? Nobody seems to know and it would be hard to tell. However, I don&#39;t think the citizens of the United Kingdom view&amp;nbsp; money as the reason for Monarchy. The American analog is giving Disneyland tax breaks to be in Florida which generates jobs. I doubt they think of the Monarchy in those mundane transactional terms.&amp;nbsp;&lt;/p&gt;&lt;p&gt;b) CS Lewis said&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Where men are forbidden to honour a king they honour millionaires, athletes, or film stars instead: even famous prostitutes and gangsters. For spiritual nature, like bodily nature, will be served; deny it food and it will gobble poison.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;This is&amp;nbsp; bit odd- they must all pretend to like the monarchy to make it work. A long time ago when Charles and Dianna were both having affairs, 80% of the citizens the United Kingdom thought that was okay so long as they are discrete so &lt;i&gt;the people&lt;/i&gt;&amp;nbsp;don&#39;t find out. But- those ARE the people.&lt;/p&gt;&lt;p&gt;Also odd- CS Lewis was a theologian and a&amp;nbsp; believing Christian; however, his comment above can apply to God as well as to Kings.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;br /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </description>
  <pubDate>2022-09-15 20:41:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>TR22-129 |  Binary Codes with Resilience Beyond 1/4 via Interaction | 

	Klim Efremenko, 

	Gillat Kol, 

	Raghuvansh Saxena, 

	Zhijun Zhang</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/129</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/129</link>
  <description>
    In the reliable transmission problem, a sender, Alice, wishes to transmit a bit-string x to a remote receiver, Bob, over a binary channel with adversarial noise. The solution to this problem is to encode x using an error correcting code. As it is long known that the distance of binary codes is at most 1/2, reliable transmission is possible only if the channel corrupts (flips) at most a 1/4-fraction of the communicated bits.
We revisit the reliable transmission problem in the two-way setting, where both Alice and Bob can send bits to each other. Our main result is the construction of two-way error correcting codes that are resilient to a constant fraction of corruptions strictly larger than 1/4. Moreover, our code has constant rate and requires Bob to only send one short message. We mention that our result resolves an open problem by Haeupler, Kamath, and Velingker [APPROX-RANDOM, 2015] and by Gupta, Kalai, and Zhang [STOC, 2022].
Curiously, our new two-way code requires a fresh perspective on classical error correcting codes: While classical codes have only one distance guarantee for all pairs of codewords (i.e., the minimum distance), we construct codes where the distance between a pair of codewords depends on the “compatibility” of the messages they encode. We also prove that such codes are necessary for our result.
  </description>
  <pubDate>2022-09-15 19:10:17 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Structure and Complexity of Graphical Designs for Weighted Graphs through Eigenpolytopes</title>
  <guid>http://arxiv.org/abs/2209.06349</guid>
  <link>http://arxiv.org/abs/2209.06349</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Babecki_C/0/1/0/all/0/1&quot;&gt;Catherine Babecki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shiroma_D/0/1/0/all/0/1&quot;&gt;David Shiroma&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We extend the theory of graphical designs, which are quadrature rules for
graphs, to positively weighted graphs. Through Gale duality for polytopes, we
show that there is a bijection between graphical designs and the faces of
eigenpolytopes associated to the graph. This bijection proves the existence of
graphical designs with positive quadrature weights, and upper bounds the size
of a graphical design. We further show that any combinatorial polytope appears
as the eigenpolytope of a positively weighted graph. Through this universality,
we establish two complexity results for graphical designs: it is strongly
NP-complete to determine if there is a graphical design smaller than the
mentioned upper bound, and it is #P-complete to count the number of minimal
graphical designs.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-15 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Red Blue Set Cover Problem on Axis-Parallel Hyperplanes and Other Objects</title>
  <guid>http://arxiv.org/abs/2209.06661</guid>
  <link>http://arxiv.org/abs/2209.06661</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abidha_V/0/1/0/all/0/1&quot;&gt;V P Abidha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashok_P/0/1/0/all/0/1&quot;&gt;Pradeesha Ashok&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a universe $\mathcal{U}=R \cup B$ of a finite set of red elements $R$,
and a finite set of blue elements $B$ and a family $\mathcal{F}$ of subsets of
$\mathcal{U}$, the \RBSC problem is to find a subset $\mathcal{F}&#39;$ of
$\mathcal{F}$ that covers all blue elements of $B$ and minimum number of red
elements from $R$.
&lt;/p&gt;
&lt;p&gt;We prove that the \RBSC problem is NP-hard even when $R$ and $B$ respectively
are sets of red and blue points in ${\rm I\!R}^2$ and the sets in $\mathcal{F}$
are defined by axis-parallel lines i.e, every set is a maximal set of points
with the same $x$ or $y$ coordinate.
&lt;/p&gt;
&lt;p&gt;We then study the parameterized complexity of a generalization of this
problem, where $\mathcal{U}$ is a set of points in ${\rm I\!R}^d$ and
$\mathcal{F}$ is a collection of set of axis-parallel hyperplanes in ${\rm
I\!R}^d$, under different parameterizations. For every parameter, we show that
the problem is fixed-parameter tractable and also show the existence of a
polynomial kernel.
&lt;/p&gt;
&lt;p&gt;We further consider the \RBSC problem for some special types of rectangles in
${\rm I\!R}^2$.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-15 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Scheduling Algorithms for Federated Learning with Minimal Energy Consumption</title>
  <guid>http://arxiv.org/abs/2209.06210</guid>
  <link>http://arxiv.org/abs/2209.06210</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilla_L/0/1/0/all/0/1&quot;&gt;La&amp;#xe9;rcio Lima Pilla&lt;/a&gt; (STORM)&lt;/p&gt;&lt;p&gt;Federated Learning (FL) has opened the opportunity for collaboratively
training machine learning models on heterogeneous mobile or Edge devices while
keeping local data private.With an increase in its adoption, a growing concern
is related to its economic and environmental cost (as is also the case for
other machine learning techniques).Unfortunately, little work has been done to
optimize its energy consumption or emissions of carbon dioxide or equivalents,
as energy minimization is usually left as a secondary objective.In this paper,
we investigate the problem of minimizing the energy consumption of FL training
on heterogeneous devices by controlling the workload distribution.We model this
as the Minimal Cost FL Schedule problem, a total cost minimization problem with
identical, independent, and atomic tasks that have to be assigned to
heterogeneous resources with arbitrary cost functions.We propose a
pseudo-polynomial optimal solution to the problem based on the previously
unexplored Multiple-Choice Minimum-Cost Maximal Knapsack Packing Problem.We
also provide four algorithms for scenarios where cost functions are
monotonically increasing and follow the same behavior.These solutions are
likewise applicable on the minimization of other kinds of costs, and in other
one-dimensional data partition problems.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-15 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Algorithmic (Semi-)Conjugacy via Koopman Operator Theory</title>
  <guid>http://arxiv.org/abs/2209.06374</guid>
  <link>http://arxiv.org/abs/2209.06374</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Redman_W/0/1/0/all/0/1&quot;&gt;William T. Redman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonoberova_M/0/1/0/all/0/1&quot;&gt;Maria Fonoberova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohr_R/0/1/0/all/0/1&quot;&gt;Ryan Mohr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kevrekidis_I/0/1/0/all/0/1&quot;&gt;Ioannis G. Kevrekidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mezic_I/0/1/0/all/0/1&quot;&gt;Igor Mezi&amp;#x107;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Iterative algorithms are of utmost importance in decision and control. With
an ever growing number of algorithms being developed, distributed, and
proprietarized, there is a similarly growing need for methods that can provide
classification and comparison. By viewing iterative algorithms as discrete-time
dynamical systems, we leverage Koopman operator theory to identify
(semi-)conjugacies between algorithms using their spectral properties. This
provides a general framework with which to classify and compare algorithms.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-15 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Performance Evaluation of Parallel Algorithms</title>
  <guid>http://arxiv.org/abs/2209.06450</guid>
  <link>http://arxiv.org/abs/2209.06450</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anireh_D/0/1/0/all/0/1&quot;&gt;Donald Ene Vincent Ike Anireh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Evaluating how well a whole system or set of subsystems performs is one of
the primary objectives of performance testing. We can tell via performance
assessment if the architecture implementation meets the design objectives.
Performance evaluations of several parallel algorithms are compared in this
study. Both theoretical and experimental methods are used in performance
assessment as a subdiscipline in computer science. The parallel method
outperforms its sequential counterpart in terms of throughput. The parallel
algorithm&#39;s performance (speedup) is examined, as shown in the result.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-15 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Parameterized algorithms for node connectivity augmentation problems</title>
  <guid>http://arxiv.org/abs/2209.06695</guid>
  <link>http://arxiv.org/abs/2209.06695</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nutov_Z/0/1/0/all/0/1&quot;&gt;Zeev Nutov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A graph $G$ is $k$-out-connected from its node $s$ if it contains $k$
internally disjoint $sv$-paths to every node $v$; $G$ is $k$-connected if it is
$k$-out-connected from every node. In connectivity augmentation problems the
goal is to augment a graph $G_0=(V,E_0)$ by a minimum costs edge set $J$ such
that $G_0 \cup J$ has higher connectivity than $G_0$. In the
$k$-Out-Connectivity Augmentation ($k$-OCA) problem, $G_0$ is
$(k-1)$-out-connected from $s$ and $G_0 \cup J$ should be $k$-out-connected
from $s$; in the $k$-Connectivity Augmentation ($k$-CA) problem $G_0$ is
$(k-1)$-connected and $G_0 \cup J$ should be $k$-connected. The parameterized
complexity status of these problems was open even for $k=3$ and unit costs. We
will show that $k$-OCA and $3$-CA can be solved in time $9^p \cdot n^{O(1)}$,
where $p$ is the size of an optimal solution. Our paper is the first that shows
fixed parameter tractability of a $k$-node-connectivity augmentation problem
with high values of $k$. We will also consider the $(2,k)$-Connectivity
Augmentation problem where $G_0$ is $(k-1)$-edge-connected and $G_0 \cup J$
should be both $k$-edge-connected and $2$-connected. We will show that this
problem can be solved in time $9^p \cdot n^{O(1)}$, and for unit costs
approximated within $1.892$.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-15 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Myth creation: The switching lemma</title>
  <guid>http://emanueleviola.wordpress.com/?p=1056</guid>
  <link>https://emanueleviola.wordpress.com/2022/09/14/myth-creation-the-switching-lemma/</link>
  <description>
    &lt;p&gt;&lt;!--?xml version=&quot;1.0&quot; encoding=&quot;iso-8859-1&quot; ?--&gt; &lt;!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd--&gt; &lt;!-- html,xhtml,-css,NoFonts --&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;The history of science is littered with anecdotes about misplaced credit. Because it does not matter if it was A or B who did it; it only matters if it was I or not I. In this spirit I am starting a series of posts about such misplaced credit, which I hesitated before calling more colorfully &amp;#8220;myth creation.&amp;#8221; Before starting, I want to make absolutely clear that I am in no way criticizing the works themselves or their authors. In fact, many are among my favorites. Moreover, at least in the examples I have in mind right now, the authors do place their work in the appropriate context with the use of citations etc. My only point is the credit that the work has received within and without our community (typically due to inertia and snowball effects rather than anything else).&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Of course, at some level this doesn’t matter. You can call Chebichev’s polynomials rainbow sprinkles and the math doesn’t change. And yet at some other level maybe it does matter a little, for science isn’t yet a purely robotic activity. With these posts I will advertise unpopular points of views that might be useful, for example to researchers who are junior or from different communities.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;
&lt;h3 class=&quot;sectionHead&quot;&gt;The switching lemma&lt;/h3&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;
&lt;div class=&quot;quote&quot;&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;em&gt;I must admit I had a good run &lt;/em&gt;&amp;#8212; Johan Hastad (privately to the blogger)&lt;/p&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Random restrictions have been used in complexity theory since at least the 60’s &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XSubbotovskaya61&quot;&gt;Sub61&lt;/a&gt;]&lt;/span&gt;. The first dramatic use in the context of AC0 is due to &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XFSS84&quot;&gt;FSS84&lt;/a&gt;, &lt;a href=&quot;#XAjt83&quot;&gt;Ajt83&lt;/a&gt;]&lt;/span&gt;. These works proved a &lt;em&gt;switching lemma&lt;/em&gt; the amazing fact that a DNF gets simplified by a random restriction to the point that it can be written as a CNF, so you can collapse layers and induct. (An exposition is given below.) Using it, they proved super-polynomial lower bounds for AC0. The proof in &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XFSS84&quot;&gt;FSS84&lt;/a&gt;]&lt;/span&gt; is very nice, and if I want to get a quick intuition of why switching is at all possible, I often go back to it. &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XAjt83&quot;&gt;Ajt83&lt;/a&gt;]&lt;/span&gt; is also a brilliant paper, and long, unavailable online for free, filled with a logical notation which makes some people twitch. The first symbol of the title says it all, and may be the most obscene ever chosen:&lt;/p&gt;
&lt;div style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5CSigma+_%7B1%7D%5E%7B1%7D.+%5Cend%7Baligned%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5CSigma+_%7B1%7D%5E%7B1%7D.+%5Cend%7Baligned%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5CSigma+_%7B1%7D%5E%7B1%7D.+%5Cend%7Baligned%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;begin{aligned} &amp;#92;Sigma _{1}^{1}. &amp;#92;end{aligned}&quot; class=&quot;latex&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Subsequently, &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XYao85&quot;&gt;Yao85&lt;/a&gt;]&lt;/span&gt; proved exponential lower bounds of the form &lt;img src=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%5E%7Bc%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%5E%7Bc%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%5E%7Bc%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;2^{n^{c}}&quot; class=&quot;latex&quot; /&gt;, with a refined analysis of the switching lemma. The bounds are tight, except for the constant &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c&quot; class=&quot;latex&quot; /&gt; which depends on the depth of the circuit. Finally, the star of this post &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;conf/stoc/Hastad86&quot;&gt;Has86&lt;/a&gt;, &lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt; obtained &lt;img src=&quot;https://s0.wp.com/latex.php?latex=c%3D1%2F%28depth-1%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=c%3D1%2F%28depth-1%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%3D1%2F%28depth-1%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;c=1/(depth-1)&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Yao’s paper doesn’t quite state that a DNF can be written exactly as a CNF, but it states that it can be approximated. Hastad’s work is the first to prove that a DNF can be written as a CNF, and in this sense his statement is cleaner than Yao’s. However, Yao’s paper states explicitly that a small circuit, after being hit by a restriction, can be set to constant by fixing few more bits.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;The modern formulation of the switching lemma says that a DNF can be written as a &lt;em&gt;shallow decision tree&lt;/em&gt; (and hence a small CNF). This formulation in terms of decision trees is actually not explicit in Hastad’s work. Beame, in his primer &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XBea94&quot;&gt;Bea94&lt;/a&gt;]&lt;/span&gt;, credits Cai with this idea and mentions several researchers noted Hastad’s proof works in this way.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Another switching lemma trivia is that the proof in Hastad’s thesis is actually due to Boppana; Hastad’s original argument &amp;#8212; of which apparently no written record exists &amp;#8212; was closer to Razborov’s later proof.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;So, let’s recap. Random restrictions are already in &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XSubbotovskaya61&quot;&gt;Sub61&lt;/a&gt;]&lt;/span&gt;. The idea of switching is already in &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XFSS84&quot;&gt;FSS84&lt;/a&gt;, &lt;a href=&quot;#XAjt83&quot;&gt;Ajt83&lt;/a&gt;]&lt;/span&gt;. You already had three analyses of these ideas, two giving superpolynomial lower bounds and one &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XYao85&quot;&gt;Yao85&lt;/a&gt;]&lt;/span&gt; giving exponential. The formulation in terms of decision trees isn’t in &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt;, and the proof that appears in &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt; is due to Boppana.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Still, I would guess &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt; is more well known than all the other works above combined. &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XYao85&quot;&gt;Yao85&lt;/a&gt;]&lt;/span&gt; did have a following at the time &amp;#8212; I think it appeared in the pop news. But hey &amp;#8212; have you ever heard of Yao’s switching lemma?&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;The current citation counts offer mixed support for my thesis:&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;FSS: 1351&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Y: 732&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;H &amp;#8211; paper &amp;#8220;Almost optimal&amp;#8230;:&amp;#8221; 867&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;H &amp;#8211; thesis: 582&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;But it is very hard to use citation information. The two H citations overlap, and papers are cited for various reasons. For example FSS got a ton of citations for the connection to oracles (which has nothing to do with switching lemmas).&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Instead it’s instructive to note the type of citations that you can find in the literature:&lt;/p&gt;
&lt;div class=&quot;quote&quot;&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;em&gt;Hastad’s switching lemma is a cornerstone of circuit complexity&lt;/em&gt; [No mention of FSS, A, Y]&lt;/p&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;
&lt;div class=&quot;quote&quot;&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;em&gt;Hastad‘s Switching Lemma is one of the gems of computational complexity&lt;/em&gt; [Notes below in passing it builds on FSS, A, Y]&lt;/p&gt;
&lt;/div&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;The wikipedia entry is also telling:&lt;/p&gt;
&lt;table class=&quot;quotation&quot; border=&quot;0&quot; cellspacing=&quot;15&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;div class=&quot;quotation&quot;&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;em&gt;In computational complexity theory, Hastad’s switching lemma is a key tool for proving lower bounds on the size of constant-depth Boolean circuits. Using the switching lemma, Johan Hastad (1987) showed that.&lt;/em&gt;.. [No mention of FSS,A,Y]&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I think that 99% of the contribution of this line of research is the &lt;em&gt;amazing idea&lt;/em&gt; that random restrictions simplify a DNF so that you can write it as a CNF and collapse. 90% of the rest is analyzing this to get superpolynomial lower bounds. And 90% of whatever is left is analyzing this to get exponential lower bounds.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Going back to something I mentioned at the beginning, I want to emphasize that Hastad during talks makes a point of reminding the audience that the idea of random restrictions is due to Sipser, and of Boppana’s contribution. And I also would like to thank him for his help with this post.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;OK &amp;#8212; so maybe this is so, but it must then be the case that &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt; is the final word on this stuff, like the ultimate tightest analysis that kills the problem. Actually, it is not tight in some regimes of interest, and several cool works of past and recent times address that. In the end, I can only think of one reason why &lt;span class=&quot;cite&quot;&gt;[&lt;a href=&quot;#XHas87&quot;&gt;Has87&lt;/a&gt;]&lt;/span&gt; entered the mythology in ways that other works did not, the reason that I carefully sidestepped while composing this post: å.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Perhaps one reason behind the aura of the switching lemma is that it’s hard to find examples. It would be nice to read: If you have this extreme DNF here’s what happens, on the other hand for this other extreme DNF here’s what happens, and in general this always works and here’s the switching lemma. &lt;em&gt;Examples are forever&lt;/em&gt; – Erdos. Instead the switching lemma is typically presented as &lt;em&gt;blam&lt;/em&gt;!: an example-free encoding argument which feels &lt;em&gt;deus ex machina&lt;/em&gt;, as in this &lt;a href=&quot;https://arxiv.org/abs/2202.05651&quot;&gt;crisp presentation by Thapen&lt;/a&gt;. For a little more discussion, I liked &lt;a href=&quot;https://www.cse.cuhk.edu.hk/~andrejb/csci5170/notes/19L02.pdf&quot;&gt;Bogdanov’s lecture notes&lt;/a&gt;. Next I give a slightly different exposition of the encoding argument.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;b&gt;The simplest case: Or of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; bits&lt;/b&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Here the circuit &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C&quot; class=&quot;latex&quot; /&gt; is simply the Or of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; bits &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;x_{1},x_{2},&amp;#92;ldots ,x_{n}&quot; class=&quot;latex&quot; /&gt;. This and the next case can be analyzed in more familiar ways, but the benefit of the encoding argument presented next is that it will extend to the general case more easily&amp;#8230; arguably. Anyway, it’s also just fun to learn a different argument.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;So, let’s take a random restriction &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt; with exactly &lt;img src=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;s&quot; class=&quot;latex&quot; /&gt; stars. Some of the bits may become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;, others &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;, and others yet may remain unfixed, i.e., assigned to stars. Those that become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt; you can ignore, while if some become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; then the whole circuit becomes &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;We will show that the number of restrictions for which the restricted circuit &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; requires decision trees of depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;ge d&quot; class=&quot;latex&quot; /&gt; is small. To accomplish this, we are going to encode/map such restrictions using/to a restriction&amp;#8230; with no stars (that is, just a 0/1 assignment to the variables). The gain is clear: just think of a restriction with zero stars versus a restriction with one star. The latter are more by a factor about the number &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt; of variables.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;A critical observation is that we only want to encode restrictions for which &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; requires large depth. So &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt; does not map any variable to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;, for else the Or is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; which has decision trees of depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;The way we are going to encode &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt; is this: &lt;em&gt;Simply replace the stars with ones&lt;/em&gt;. To go back, replace the ones with stars. We are using the ones in the encoding to “signal” where the stars are.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Hence, the number of bad restrictions is at most &lt;img src=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;2^{n}&quot; class=&quot;latex&quot; /&gt;, which is tiny compared to the number &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cbinom+%7Bn%7D%7Bs%7D2%5E%7Bn-s%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cbinom+%7Bn%7D%7Bs%7D2%5E%7Bn-s%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbinom+%7Bn%7D%7Bs%7D2%5E%7Bn-s%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;binom {n}{s}2^{n-s}&quot; class=&quot;latex&quot; /&gt; of restrictions with &lt;img src=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;s&quot; class=&quot;latex&quot; /&gt; stars.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;b&gt;The medium case: Or of functions on disjoint inputs&lt;/b&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;Instead of working with DNFs, I will consider a circuit &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C&quot; class=&quot;latex&quot; /&gt; which is the Or of arbitrary functions &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bi%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f_{i}&quot; class=&quot;latex&quot; /&gt; each on &lt;img src=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;w&quot; class=&quot;latex&quot; /&gt; bits. You can immediately get this formulation from the usual one for DNFs, but I still find it a little useful since otherwise you might think there is something special about DNFs. What &lt;em&gt;is &lt;/em&gt;special is that you take the Or of the functions, and we will exploit this again shortly.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;In this warm-up case, we start with functions on &lt;em&gt;disjoint&lt;/em&gt; inputs. So, again, let’s take a random restriction &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt; with exactly &lt;img src=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;s&quot; class=&quot;latex&quot; /&gt; stars. Some of the functions may become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;, others &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;, and others yet may remain unfixed. Those that become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt; you can ignore, while if some become &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; then the whole circuit becomes &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;As before, we will show that the number of restrictions for which the restricted circuit &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; requires decision trees of depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;ge d&quot; class=&quot;latex&quot; /&gt; is small. To accomplish this, we are going to encode/map such restrictions using/to a restriction with just &lt;img src=&quot;https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;s-d&quot; class=&quot;latex&quot; /&gt; stars, plus a little more information. As we saw already, the gain in reducing the number of stars is clear. In particular, standard calculations show that saving &lt;img src=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;d&quot; class=&quot;latex&quot; /&gt; stars reduces the number of restrictions by a factor &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%28s%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%28s%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28s%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(s/n)^{d}&quot; class=&quot;latex&quot; /&gt;. The auxiliary information will give us a factor of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=w%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=w%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;w^{d}&quot; class=&quot;latex&quot; /&gt;, leading to the familiar bound &lt;img src=&quot;https://s0.wp.com/latex.php?latex=O%28ws%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=O%28ws%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28ws%2Fn%29%5E%7Bd%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;O(ws/n)^{d}&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;As before, recall that we only want to encode restrictions for which &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; requires large depth. So no function in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;, for else the circuit is &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt; and has decision trees of depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;. Also, you have &lt;img src=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;d&quot; class=&quot;latex&quot; /&gt; stars among inputs to functions that are unfixed (i.e., not even fixed to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;0&quot; class=&quot;latex&quot; /&gt;), for else again you can compute the function reading less than &lt;img src=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;d&quot; class=&quot;latex&quot; /&gt; bits. Because the functions are unfixed, there is a setting for those &lt;img src=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;d&quot; class=&quot;latex&quot; /&gt; stars (and possibly a few more stars – that would only help the argument) that make the corresponding functions &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;. We are going to pick precisely that setting in our restriction &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+%27&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+%27&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+%27&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &amp;#039;&quot; class=&quot;latex&quot; /&gt; with &lt;img src=&quot;https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s-d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;s-d&quot; class=&quot;latex&quot; /&gt; stars. This allows us to “signal” which functions had inputs with the stars we are saving (namely, those that are the constant &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;). To completely recover &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt;, we simply add extra information to indicate where the stars were. The saving here is that we only have to say where the stars are among &lt;img src=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;w&quot; class=&quot;latex&quot; /&gt; symbols, not &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;n&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;&lt;b&gt;The general case: Or of functions on any subset of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;w&quot; class=&quot;latex&quot; /&gt; bits&lt;/b&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;First, the number of functions does not play a role, so you can think you have functions on any possible subset of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;w&quot; class=&quot;latex&quot; /&gt; bits, where some functions may be constant. The idea is the same, except we have to be slightly more careful because when we set values for the stars in one function we may also affect other functions. The idea is simply to fix one function at the time. Specifically, starting with &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt;, consider the first function &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f&quot; class=&quot;latex&quot; /&gt; that’s not made constant by &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt;. So the inputs to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f&quot; class=&quot;latex&quot; /&gt; have some stars. As before, let us replace the stars with constants that make the function &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f&quot; class=&quot;latex&quot; /&gt; equal to the constant 1, and append the extra information that allows us to recover where these stars were in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Crho+&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;rho &quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;We’d like to repeat the argument. Note however we only have guarantees about &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt;, not &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; with some stars replaced with constants that make &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f&quot; class=&quot;latex&quot; /&gt; equal to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;1&quot; class=&quot;latex&quot; /&gt;. We also can’t just jump to the 2nd function that’s not constant in &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt;, since the “signal” fixing for that might clash with the fixing for the first – this is where the overlap in inputs makes things slightly more involved. Instead, because &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; required decision tree depth at least &lt;img src=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;d&quot; class=&quot;latex&quot; /&gt;, we note there have to be some assignments to the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;m&quot; class=&quot;latex&quot; /&gt; stars in the input to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;f&quot; class=&quot;latex&quot; /&gt; so that the resulting, further restricted circuit still requires decision tree depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d-m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5Cge+d-m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+d-m&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;ge d-m&quot; class=&quot;latex&quot; /&gt; (else &lt;img src=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%7C_%7B%5Crho+%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;C|_{&amp;#92;rho }&quot; class=&quot;latex&quot; /&gt; has decision trees of depth &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%3Cd&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%3Cd&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%3Cd&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;lt;d&quot; class=&quot;latex&quot; /&gt;).  We append this assignment to the auxiliary information and we continue the argument using the further restricted circuit.&lt;/p&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;
&lt;h3 class=&quot;likesectionHead&quot;&gt;&lt;a id=&quot;x1-30001&quot;&gt;&lt;/a&gt;References&lt;/h3&gt;
&lt;p style=&quot;text-align:justify;&quot;&gt;
&lt;div class=&quot;thebibliography&quot;&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [Ajt83] &lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XAjt83&quot;&gt;&lt;/a&gt;Mikl�s Ajtai. &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; srcset=&quot;https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&amp;#038;zoom=4.5 4x&quot; alt=&quot;&amp;#92;Sigma &amp;#92;sp {1}&amp;#92;sb {1}&quot; class=&quot;latex&quot; /&gt;-formulae on finite structures. Annals of Pure and Applied Logic, 24(1):1–48, 1983.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [Bea94]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XBea94&quot;&gt;&lt;/a&gt;Paul Beame. A switching lemma primer. Technical Report UW-CSE-95-07-01, Department of Computer Science and Engineering, University of Washington, November 1994. Available from &lt;a href=&quot;http://www.cs.washington.edu/homes/beame/&quot; rel=&quot;nofollow&quot;&gt;http://www.cs.washington.edu/homes/beame/&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [FSS84]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XFSS84&quot;&gt;&lt;/a&gt;Merrick L. Furst, James B. Saxe, and Michael Sipser. Parity, circuits, and the polynomial-time hierarchy. Mathematical Systems Theory, 17(1):13–27, 1984.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [Has86]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XDBLP:conf/stoc/Hastad86&quot;&gt;&lt;/a&gt;Johan H�stad. Almost optimal lower bounds for small depth circuits. In Juris Hartmanis, editor, Proceedings of the 18th Annual ACM Symposium on Theory of Computing, May 28-30, 1986, Berkeley, California, USA, pages 6–20. ACM, 1986.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [H�s87]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XHas87&quot;&gt;&lt;/a&gt;Johan H�stad. Computational limitations of small-depth circuits. MIT Press, 1987.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [Sub61]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XSubbotovskaya61&quot;&gt;&lt;/a&gt;B. A. Subbotovskaya. Realizations of linear functions by formulas using +, *, -. Soviet Mathematics-Doklady, 2:110–112, 1961.&lt;/p&gt;
&lt;p class=&quot;bibitem&quot;&gt;&lt;span class=&quot;biblabel&quot;&gt; [Yao85]&lt;span class=&quot;bibsp&quot;&gt;   &lt;/span&gt;&lt;/span&gt;&lt;a id=&quot;XYao85&quot;&gt;&lt;/a&gt;Andrew Yao. Separating the polynomial-time hierarchy by oracles. In 26th IEEE Symp. on Foundations of Computer Science (FOCS), pages 1–10, 1985.&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;authors&quot;&gt;By Manu&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 17:11:22 UTC</pubDate>
  <author>Emanuele Viola</author>
</item>

<item>
  <title>I had a dream</title>
  <guid>https://scottaaronson.blog/?p=6718</guid>
  <link>https://scottaaronson.blog/?p=6718</link>
  <description>
    &lt;p&gt;As I slept fitfully, still recovering from COVID, I had one of the more interesting dreams of my life:&lt;/p&gt;



&lt;p&gt;I was desperately trying to finish some PowerPoint slides in time to give a talk. Uncharacteristically for me, one of the slides displayed actual code. This was a dream, so nothing was as clear as I&amp;#8217;d like, but the code did &lt;em&gt;something&lt;/em&gt; vaguely reminiscent of &lt;a href=&quot;https://scottaaronson.blog/?p=710&quot;&gt;Rosser’s Theorem&lt;/a&gt;—e.g., enumerating all proofs in ZFC until it finds the lexicographically first proof or disproof of a certain statement, then branching into cases depending on whether it&amp;#8217;s a proof or a disproof. In any case, it was simple enough to fit on one slide.&lt;/p&gt;



&lt;p&gt;Suddenly, though, my whole presentation was deleted. Everything was ruined!&lt;/p&gt;



&lt;p&gt;One of the developers of PowerPoint happened to be right there in the lecture hall (of course!), so I confronted him with my laptop and angrily demanded an explanation. He said that I must have triggered the section of Microsoft Office that tries to detect and prevent any discussion of logical paradoxes that are too dangerous for humankind—the ones that would cause people to realize that our entire universe is just an illusion, a sandbox being run inside an AI, a glitch-prone Matrix. He said it patronizingly, as if it should&amp;#8217;ve been obvious: &amp;#8220;you and I both know that the Paradoxes are not to be talked about, so why would you be so &lt;em&gt;stupid&lt;/em&gt; as to put one in your presentation?&amp;#8221;&lt;/p&gt;



&lt;p&gt;My reaction was to jab my finger in the guy’s face, shove him, scream, and curse him out. At that moment, I wasn’t concerned in the slightest about the universe being an illusion, or about glitches in the Matrix. I was concerned about my embarrassment when I’d be called in 10 minutes to give my talk and would have nothing to show.&lt;/p&gt;



&lt;p&gt;My last thought, before I woke with a start, was to wonder whether Greg Kuperberg was right and I should give my presentations in &lt;a href=&quot;https://en.wikipedia.org/wiki/Beamer_(LaTeX)&quot;&gt;Beamer&lt;/a&gt;, or some other open-source software, and then I wouldn’t have had this problem.&lt;/p&gt;



&lt;p&gt;A coda: I woke a bit after 7AM Central and started to write this down. But then&amp;#8212;this is now real life (!)&amp;#8212;I saw an email saying that a dozen people were waiting for me in a conference room in Europe for an important Zoom meeting. We&amp;#8217;d gotten the time zones wrong; I&amp;#8217;d thought that it wasn&amp;#8217;t until 8AM my time. If not for this dream causing me to wake up, I would&amp;#8217;ve missed the meeting entirely.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Scott&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 16:52:05 UTC</pubDate>
  <author>Scott Aaronson</author>
</item>

<item>
  <title>Quick reminders: masters, postdocs, faculty, etc.</title>
  <guid>http://windowsontheory.org/?p=8452</guid>
  <link>https://windowsontheory.org/2022/09/14/quick-reminders-masters-postdocs-faculty-etc/</link>
  <description>
    &lt;p&gt;As we&amp;#8217;re getting closer to the season when undergraduate students are considering graduate school, and graduate students are considering the next steps such as postdoc or faculty positions,  I wanted to remind people of two resources for such positions: the &lt;a href=&quot;https://cstheory-jobs.org/&quot;&gt;TCS jobs&lt;/a&gt; and &lt;a href=&quot;https://www.cs.princeton.edu/~smattw/masters/masters.html&quot;&gt;crowd-sourced masters&lt;/a&gt; pages. &lt;/p&gt;



&lt;p&gt;The process and market for both graduate studies and faculty positions (at least in the US) is fairly standard, with more or less a common timeline, and general ideas of where to look for positions (universities&amp;#8217; websites are always a good start, as are the websites of &lt;a href=&quot;https://jobs.acm.org/jobs/products/&quot;&gt;ACM&lt;/a&gt; and &lt;a href=&quot;https://cra.org/ads/&quot;&gt;CRA&lt;/a&gt;).  Even so, it&amp;#8217;s not always clear which areas a university is searching for at any given year, and also these resources are very US-centric, while many great places are located outside the US.&lt;/p&gt;



&lt;p&gt;The &lt;strong&gt;postdoc market&lt;/strong&gt; is much more &amp;#8220;ad hoc&amp;#8221;. Some places such as the &lt;a href=&quot;https://simons.berkeley.edu/programs/participate&quot;&gt;Simons institute&lt;/a&gt; and the &lt;a href=&quot;https://www.ias.edu/math/csdm/postdocs&quot;&gt;IAS&lt;/a&gt; search for postdocs yearly and have several positions. (Our own &lt;a href=&quot;https://www.harvard.edu/kempner-institute/&quot;&gt;Kempner Institute&lt;/a&gt; will also be having regular searches after it launches this year.)  But in many other cases, postdoc positions are with an individual researcher that might have availability only every few years, which makes it harder for candidates to find out about this.  For such positions, the &lt;a href=&quot;https://cstheory-jobs.org/&quot;&gt;&lt;strong&gt;Theoretical Computer Science jobs&lt;/strong&gt;&lt;/a&gt; page is a great way to both advertise any position you have to offer, as well as find out about opportunities.  Please post any postdoc or faculty positions relevant to TCS in your institution, as well as advertise it to your students as a place to look for jobs.&lt;/p&gt;



&lt;p&gt;Finding information about &lt;strong&gt;research-oriented Masters programs&lt;/strong&gt; is also sometimes challenging. In the US it&amp;#8217;s common for students to apply straight to a Ph.D from undergraduate, and Masters programs are often intended more for professional development. But, as I &lt;a href=&quot;https://windowsontheory.org/2018/02/20/research-masters/&quot;&gt;wrote in the past,&lt;/a&gt; &lt;em&gt;research-oriented&lt;/em&gt; Masters programs can actually be a great fit for many students. A Ph.D is a huge commitment on both the student and advisor side. If you have not had a chance to do research during your undergraduate studies,  it may be better to start with a Masters before taking such a commitment. Some research Masters programs do not charge any tuition, and several offer a stipend. To post and look for such opportunities, see the &lt;a href=&quot;https://www.cs.princeton.edu/~smattw/masters/masters.html&quot;&gt;&lt;strong&gt;crowdsourced TCS research masters website&lt;/strong&gt;&lt;/a&gt;, managed by Aviad Rubinstein and Matt Weinberg.&lt;/p&gt;



&lt;p&gt;If there are other great resources or opportunities, please post them in the comments!&lt;/p&gt;



&lt;p&gt;In particular, the resources above are geared for theoretical CS. If you have suggestions of analogous resources for other fields, please post them as well.&lt;/p&gt;



&lt;p&gt; &lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Boaz Barak&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 13:50:02 UTC</pubDate>
  <author>Windows on Theory</author>
</item>

<item>
  <title>On bounded depth proofs for Tseitin formulas on the grid; revisited</title>
  <guid>http://arxiv.org/abs/2209.05839</guid>
  <link>http://arxiv.org/abs/2209.05839</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+H%5Cr%7Ba%7Dstad_J/0/1/0/all/0/1&quot;&gt;Johan H&amp;#xe5;stad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risse_K/0/1/0/all/0/1&quot;&gt;Kilian Risse&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study Frege proofs using depth-$d$ Boolean formulas for the Tseitin
contradiction on $n \times n$ grids. We prove that if each line in the proof is
of size $M$ then the number of lines is exponential in $n/(\log M)^{O(d)}$.
This strengthens a recent result of Pitassi et al. [PRT22]. The key technical
step is a multi-switching lemma extending the switching lemma of H\r{a}stad
[H\r{a}s20] for a space of restrictions related to the Tseitin contradiction.
The strengthened lemma also allows us to improve the lower bound for standard
proof size of bounded depth Frege refutations from exponential in $\tilde
\Omega (n^{1/59d})$ to exponential in $\tilde \Omega (n^{1/(2d-1)})$.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>What is a combinatorial interpretation?</title>
  <guid>http://arxiv.org/abs/2209.06142</guid>
  <link>http://arxiv.org/abs/2209.06142</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pak_I/0/1/0/all/0/1&quot;&gt;Igor Pak&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this survey we discuss the notion of combinatorial interpretation in the
context of Algebraic Combinatorics and related areas. We approach the subject
from the Computational Complexity perspective. We review many examples, state a
workable definition, discuss many open problems, and present recent results on
the subject.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Topological Measures for Pattern quantification of Impact Centers in Piezo Vibration Striking Treatment (PVST)</title>
  <guid>http://arxiv.org/abs/2209.05531</guid>
  <link>http://arxiv.org/abs/2209.05531</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yesilli_M/0/1/0/all/0/1&quot;&gt;Melih C. Yesilli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chumley_M/0/1/0/all/0/1&quot;&gt;Max M. Chumley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jisheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khasawneh_F/0/1/0/all/0/1&quot;&gt;Firas A. Khasawneh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yang Guo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Surface texture influences wear and tribological properties of manufactured
parts, and it plays a critical role in end-user products. Therefore,
quantifying the order or structure of a manufactured surface provides important
information on the quality and life expectancy of the product. Although texture
can be intentionally introduced to enhance aesthetics or to satisfy a design
function, sometimes it is an inevitable byproduct of surface treatment
processes such as Piezo Vibration Striking Treatment (PVST). Measures of order
for surfaces have been characterized using statistical, spectral, and geometric
approaches. For nearly hexagonal lattices, topological tools have also been
used to measure the surface order. This paper utilizes tools from Topological
Data Analysis for quantifying the impact centers&#39; pattern in PVST. We compute
measures of order based on optical digital microscope images of surfaces
treated using PVST. These measures are applied to the grid obtained from
estimating the centers of tool impacts, and they quantify the grid&#39;s deviations
from the nominal one. Our results show that TDA provides a convenient framework
for the characterization of pattern type that bypasses some limitations of
existing tools such as difficult manual processing of the data and the need for
an expert user to analyze and interpret the surface images.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Rectilinear Convex Hull of Points in 3D</title>
  <guid>http://arxiv.org/abs/2209.06020</guid>
  <link>http://arxiv.org/abs/2209.06020</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Lantero_P/0/1/0/all/0/1&quot;&gt;Pablo P&amp;#xe9;rez-Lantero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seara_C/0/1/0/all/0/1&quot;&gt;Carlos Seara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1&quot;&gt;Jorge Urrutia&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $P$ be a set of $n$ points in $\mathbb{R}^3$ in general position, and let
$RCH(P)$ be the rectilinear convex hull of $P$. In this paper we obtain an
optimal $O(n\log n)$-time and $O(n)$-space algorithm to compute $RCH(P)$. We
also obtain an efficient $O(n\log^2 n)$-time and $O(n\log n)$-space algorithm
to compute and maintain the set of vertices of the rectilinear convex hull of
$P$ as we rotate $\mathbb R^3$ around the $z$-axis. Finally we study some
properties of the rectilinear convex hulls of point sets in $\mathbb{R}^3$.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Recovery from Non-Decomposable Distance Oracles</title>
  <guid>http://arxiv.org/abs/2209.05676</guid>
  <link>http://arxiv.org/abs/2209.05676</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zhuangfei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xinda Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1&quot;&gt;David P. Woodruff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shufan Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A line of work has looked at the problem of recovering an input from distance
queries. In this setting, there is an unknown sequence $s \in \{0,1\}^{\leq
n}$, and one chooses a set of queries $y \in \{0,1\}^{\mathcal{O}(n)}$ and
receives $d(s,y)$ for a distance function $d$. The goal is to make as few
queries as possible to recover $s$. Although this problem is well-studied for
decomposable distances, i.e., distances of the form $d(s,y) = \sum_{i=1}^n
f(s_i, y_i)$ for some function $f$, which includes the important cases of
Hamming distance, $\ell_p$-norms, and $M$-estimators, to the best of our
knowledge this problem has not been studied for non-decomposable distances, for
which there are important special cases such as edit distance, dynamic time
warping (DTW), Frechet distance, earth mover&#39;s distance, and so on. We initiate
the study and develop a general framework for such distances. Interestingly,
for some distances such as DTW or Frechet, exact recovery of the sequence $s$
is provably impossible, and so we show by allowing the characters in $y$ to be
drawn from a slightly larger alphabet this then becomes possible. In a number
of cases we obtain optimal or near-optimal query complexity. We also study the
role of adaptivity for a number of different distance functions. One motivation
for understanding non-adaptivity is that the query sequence can be fixed and
the distances of the input to the queries provide a non-linear embedding of the
input, which can be used in downstream applications involving, e.g., neural
networks for natural language processing.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Unsplittable Euclidean Capacitated Vehicle Routing: A $(2+\epsilon)$-Approximation Algorithm</title>
  <guid>http://arxiv.org/abs/2209.05520</guid>
  <link>http://arxiv.org/abs/2209.05520</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grandoni_F/0/1/0/all/0/1&quot;&gt;Fabrizio Grandoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathieu_C/0/1/0/all/0/1&quot;&gt;Claire Mathieu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hang Zhou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In the unsplittable capacitated vehicle routing problem, we are given a
metric space with a vertex called depot and a set of vertices called terminals.
Each terminal is associated with a positive demand between 0 and 1. The goal is
to find a minimum length collection of tours starting and ending at the depot
such that the demand of each terminal is covered by a single tour (i.e., the
demand cannot be split), and the total demand of the terminals in each tour
does not exceed the capacity of 1.
&lt;/p&gt;
&lt;p&gt;Our main result is a polynomial-time $(2+\epsilon)$-approximation algorithm
for this problem in the two-dimensional Euclidean plane, i.e., for the special
case where the terminals and the depot are associated with points in the
Euclidean plane and their distances are defined accordingly. This improves on
recent work by Blauth, Traub, and Vygen [IPCO&#39;21] and Friggstad, Mousavi,
Rahgoshay, and Salavatipour [IPCO&#39;22].
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Note on the Quickest Minimum Cost Transshipment Problem</title>
  <guid>http://arxiv.org/abs/2209.05558</guid>
  <link>http://arxiv.org/abs/2209.05558</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skutella_M/0/1/0/all/0/1&quot;&gt;Martin Skutella&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Klinz and Woeginger (1995) prove that the minimum cost quickest flow problem
is NP-hard. On the other hand, the quickest minimum cost flow problem can be
solved efficiently via a straightforward reduction to the quickest flow problem
without costs. More generally, we show how the quickest minimum cost
transshipment problem can be reduced to the efficiently solvable quickest
transshipment problem, thus adding another mosaic tile to the rich complexity
landscape of flows over time.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>An Improved Lower Bound for Matroid Intersection Prophet Inequalities</title>
  <guid>http://arxiv.org/abs/2209.05614</guid>
  <link>http://arxiv.org/abs/2209.05614</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxena_R/0/1/0/all/0/1&quot;&gt;Raghuvansh R. Saxena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velusamy_S/0/1/0/all/0/1&quot;&gt;Santhoshini Velusamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinberg_S/0/1/0/all/0/1&quot;&gt;S. Matthew Weinberg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider prophet inequalities subject to feasibility constraints that are
the intersection of $q$ matroids. The best-known algorithms achieve a
$\Theta(q)$-approximation, even when restricted to instances that are the
intersection of $q$ partition matroids, and with i.i.d.~Bernoulli random
variables. The previous best-known lower bound is $\Theta(\sqrt{q})$ due to a
simple construction of [Kleinberg-Weinberg STOC 2012] (which uses
i.i.d.~Bernoulli random variables, and writes the construction as the
intersection of partition matroids).
&lt;/p&gt;
&lt;p&gt;We establish an improved lower bound of $q^{1/2+\Omega(1/\log \log q)}$ by
writing the construction of [Kleinberg-Weinberg STOC 2012] as the intersection
of asymptotically fewer partition matroids. We accomplish this via an improved
upper bound on the product dimension of a graph with $p^p$ disjoint cliques of
size $p$, using recent techniques developed in [Alon-Alweiss European Journal
of Combinatorics 2020].
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Space Optimal Vertex Cover in Dynamic Streams</title>
  <guid>http://arxiv.org/abs/2209.05623</guid>
  <link>http://arxiv.org/abs/2209.05623</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naidu_K/0/1/0/all/0/1&quot;&gt;Kheeran K. Naidu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_V/0/1/0/all/0/1&quot;&gt;Vihan Shah&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We optimally resolve the space complexity for the problem of finding an
$\alpha$-approximate minimum vertex cover ($\alpha$MVC) in dynamic graph
streams. We give a randomised algorithm for $\alpha$MVC which uses
$O(n^2/\alpha^2)$ bits of space matching Dark and Konrad&#39;s lower bound [CCC
2020] up to constant factors. By computing a random greedy matching, we
identify `easy&#39; instances of the problem which can trivially be solved by
returning the entire vertex set. The remaining `hard&#39; instances, then have
sparse induced subgraphs which we exploit to get our space savings and solve
$\alpha$MVC.
&lt;/p&gt;
&lt;p&gt;Achieving this type of optimality result is crucial for providing a complete
understanding of a problem, and it has been gaining interest within the dynamic
graph streaming community. For connectivity, Nelson and Yu [SODA 2019] improved
the lower bound showing that $\Omega(n \log^3 n)$ bits of space is necessary
while Ahn, Guha, and McGregor [SODA 2012] have shown that $O(n \log^3 n)$ bits
is sufficient. For finding an $\alpha$-approximate maximum matching, the upper
bound was improved by Assadi and Shah [ITCS 2022] showing that
$O(n^2/\alpha^3)$ bits is sufficient while Dark and Konrad [CCC 2020] have
shown that $\Omega(n^2/\alpha^3)$ bits is necessary. The space complexity,
however, remains unresolved for many other dynamic graph streaming problems
where further improvements can still be made. \end{abstract}
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Fast Algorithms for Monotone Lower Subsets of Kronecker Least Squares Problems</title>
  <guid>http://arxiv.org/abs/2209.05662</guid>
  <link>http://arxiv.org/abs/2209.05662</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Malik_O/0/1/0/all/0/1&quot;&gt;Osman Asif Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yiming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cheng_N/0/1/0/all/0/1&quot;&gt;Nuojin Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Becker_S/0/1/0/all/0/1&quot;&gt;Stephen Becker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Doostan_A/0/1/0/all/0/1&quot;&gt;Alireza Doostan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Narayan_A/0/1/0/all/0/1&quot;&gt;Akil Narayan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Approximate solutions to large least squares problems can be computed
efficiently using leverage score-based row-sketches, but directly computing the
leverage scores, or sampling according to them with naive methods, still
requires an expensive manipulation and processing of the design matrix. In this
paper we develop efficient leverage score-based sampling methods for matrices
with certain Kronecker product-type structure; in particular we consider
matrices that are monotone lower column subsets of Kronecker product matrices.
Our discussion is general, encompassing least squares problems on infinite
domains, in which case matrices formally have infinitely many rows. We briefly
survey leverage score-based sampling guarantees from the numerical linear
algebra and approximation theory communities, and follow this with efficient
algorithms for sampling when the design matrix has Kronecker-type structure.
Our numerical examples confirm that sketches based on exact leverage score
sampling for our class of structured matrices achieve superior residual
compared to approximate leverage score sampling methods.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Hash Table Without Hash Functions, and How to Get the Most Out of Your Random Bits</title>
  <guid>http://arxiv.org/abs/2209.06038</guid>
  <link>http://arxiv.org/abs/2209.06038</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuszmaul_W/0/1/0/all/0/1&quot;&gt;William Kuszmaul&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper considers the basic question of how efficiently can a
constant-time hash table, storing $n$ $\Theta(\log n)$-bit key/value pairs,
make use of its random bits? That is, how many random bits does a hash table
need to offer constant-time operations with probability $1 - 1 / \poly(n)$?
And, if the number of random bits is unrestricted, then what is the
highest-probability guarantee that a hash table can offer?
&lt;/p&gt;
&lt;p&gt;Past work on these questions has been bottlenecked by limitations of the
known families of hash functions. The hash tables that achieve failure
probabilities $1 / \poly(n)$ use at least $\tilde{\Omega}(\log^2 n)$ random
bits, which is the number of random bits needed to create hash functions with
$\tilde{\Omega}(\log n)$-wise independence. And the only hash tables to achieve
failure probabilities less than $1 / 2^{\polylog n}$ require access to
fully-random hash functions -- if the same hash tables are implemented using
the known explicit families of hash functions, their failure probabilities
become $1 / \poly(n)$.
&lt;/p&gt;
&lt;p&gt;To get around these obstacles, we show how to construct a randomized data
structure that has the same guarantees as a hash table, but that \emph{avoids
the direct use of hash functions}. Building on this, we are then able to give
nearly optimal solutions to both problems described above: we construct a hash
table using $\tilde{O}(\log n)$ random bits that achieves failure-probability
$1 / \poly(n)$; and we construct a hash table using $O(n)$ random bits that
achieves failure probability $1 / n^{n^{1 - \epsilon}}$ for an arbitrary
positive constant $\epsilon$.
&lt;/p&gt;
&lt;p&gt;Finally, if the keys/values are $(1 + \Theta(1)) \log n$ bits each, then we
show that the above guarantees can even be achieved by \emph{succinct
dictionaries}, that is, by dictionaries that use space within a $1 + o(1)$
factor of the information-theoretic optimum.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>TR22-128 |  PPP-Completeness and Extremal Combinatorics | 

	Romain Bourneuf, 

	Lukáš Folwarczný, 

	Pavel Hubacek, 

	Alon Rosen, 

	Nikolaj Schwartzbach</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/128</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/128</link>
  <description>
    Many classical theorems in combinatorics establish the emergence of substructures within sufficiently large collections of objects. Well-known examples are Ramsey&amp;#39;s theorem on monochromatic subgraphs and the Erdos-Rado sunflower lemma. Implicit versions of the corresponding total search problems are known to be PWPP-hard; here &amp;quot;implicit&amp;quot; means that the collection is represented by a poly-sized circuit inducing an exponentially large number of objects.

We show that several other well-known  theorems from extremal combinatorics - including Erdos-Ko-Rado, Sperner, and Cayley&amp;#39;s formula - give rise to complete problems for PWPP and PPP. This is in contrast to the Ramsey and Erdos-Rado problems, for which establishing inclusion in PWPP has remained elusive. Besides significantly expanding the set of problems that are complete for PWPP and PPP, our work identifies some key properties of combinatorial proofs of existence that can give rise to completeness for these classes.

Our completeness results rely on efficient encodings for which finding collisions allows extracting the desired substructure. These encodings are made possible by the tightness of the bounds for the problems at hand (tighter than what is known for Ramsey&amp;#39;s theorem and the sunflower lemma). Previous techniques for proving bounds in TFNP invariably made use of structured algorithms. Such algorithms are not known to exist for the theorems considered in this work, as their proofs &amp;quot;from the book&amp;quot; are non-constructive.
  </description>
  <pubDate>2022-09-13 17:22:41 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>TR22-127 |  Kolmogorov Complexity Characterizes Statistical Zero Knowledge | 

	Eric Allender, 

	Shuichi Hirahara, 

	Harsha Tirumala</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/127</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/127</link>
  <description>
    We show that a decidable promise problem has a non-interactive statistical zero-knowledge proof system if and only if it is randomly reducible to a promise problem for Kolmogorov-random strings, with a superlogarithmic additive approximation term.  This extends recent work by Saks and Santhanam (CCC 2022).  We build on this to give new characterizations of Statistical Zero Knowledge (SZK), as well as the related classes NISZK_L and SZK_L.
  </description>
  <pubDate>2022-09-13 17:21:12 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>TR22-126 |  An Invitation to the Promise Constraint Satisfaction Problem | 

	Andrei Krokhin, 

	Jakub Opršal</title>
  <guid>https://eccc.weizmann.ac.il/report/2022/126</guid>
  <link>https://eccc.weizmann.ac.il/report/2022/126</link>
  <description>
    The study of the complexity of the constraint satisfaction problem (CSP), centred around the Feder-Vardi Dichotomy Conjecture, has been very prominent in the last two decades. After a long concerted effort and many partial results, the Dichotomy Conjecture has been proved in 2017 independently by Bulatov and Zhuk.

At about the same time, a vast generalisation of CSP, called promise CSP, has started to gain prominence. In this survey, we explain the importance of promise CSP and highlight many new very interesting features that the study of promise CSP has brought to light. The complexity classification quest for the promise CSP is wide open, and we argue that, despite the promise CSP being more general, this quest is rather more accessible to a wide range of researchers than the dichotomy-led study of the CSP has been.
  </description>
  <pubDate>2022-09-13 16:54:09 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>On Identity Testing and Noncommutative Rank Computation over the Free Skew Field</title>
  <guid>http://arxiv.org/abs/2209.04797</guid>
  <link>http://arxiv.org/abs/2209.04797</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arvind_V/0/1/0/all/0/1&quot;&gt;V. Arvind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1&quot;&gt;Abhranil Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosal_U/0/1/0/all/0/1&quot;&gt;Utsab Ghosal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhopadhyay_P/0/1/0/all/0/1&quot;&gt;Partha Mukhopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramya_C/0/1/0/all/0/1&quot;&gt;C. Ramya&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The identity testing of rational formulas (RIT) in the free skew field
efficiently reduces to computing the rank of a matrix whose entries are linear
polynomials in noncommuting variables\cite{HW15}. This rank computation problem
has deterministic polynomial-time white-box algorithms \cite{GGOW16, IQS18} and
a randomized polynomial-time algorithm in the black-box setting \cite{DM17}. In
this paper, we propose a new approach for efficient derandomization of
\emph{black-box} RIT. Additionally, we obtain results for matrix rank
computation over the free skew field, and construct efficient linear pencil
representations for a new class of rational expressions. More precisely, we
show the following results:
&lt;/p&gt;
&lt;p&gt;1. Under the hardness assumption that the ABP (algebraic branching program)
complexity of every polynomial identity for the $k\times k$ matrix algebra is
$2^{\Omega(k)}$ \cite{BW05}, we obtain a subexponential-time black-box
algorithm for RIT in almost general setting. This can be seen as the first
&quot;hardness implies derandomization&quot; type theorem for rational formulas.
&lt;/p&gt;
&lt;p&gt;2. We show that the noncommutative rank of any matrix over the free skew
field whose entries have small linear pencil representations can be computed in
deterministic polynomial time. Prior to this, an efficient rank computation was
only known for matrices with noncommutative formulas as entries\cite{GGOW20}.
As special cases of our algorithm, we obtain the first deterministic
polynomial-time algorithms for rank computation of matrices whose entries are
noncommutative ABPs or rational formulas.
&lt;/p&gt;
&lt;p&gt;3. Motivated by the definition given by Bergman\cite{Ber76}, we define a new
class that contains noncommutative ABPs and rational formulas. We obtain a
polynomial-size linear pencil representation for this class. As a by-product,
we obtain a white-box deterministic polynomial-time identity testing algorithm
for the class.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>PPP-Completeness and Extremal Combinatorics</title>
  <guid>http://arxiv.org/abs/2209.04827</guid>
  <link>http://arxiv.org/abs/2209.04827</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bourneuf_R/0/1/0/all/0/1&quot;&gt;Romain Bourneuf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Folwarczny_L/0/1/0/all/0/1&quot;&gt;Luk&amp;#xe1;&amp;#x161; Folwarczn&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubacek_P/0/1/0/all/0/1&quot;&gt;Pavel Hub&amp;#xe1;&amp;#x10d;ek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosen_A/0/1/0/all/0/1&quot;&gt;Alon Rosen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartzbach_N/0/1/0/all/0/1&quot;&gt;Nikolaj Ignatieff Schwartzbach&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Many classical theorems in combinatorics establish the emergence of
substructures within sufficiently large collections of objects. Well-known
examples are Ramsey&#39;s theorem on monochromatic subgraphs and the Erd\H{o}s-Rado
sunflower lemma. Implicit versions of the corresponding total search problems
are known to be PWPP-hard; here &quot;implici&quot; means that the collection is
represented by a poly-sized circuit inducing an exponentially large number of
objects.
&lt;/p&gt;
&lt;p&gt;We show that several other well-known theorems from extremal combinatorics -
including Erd\H{o}s-Ko-Rado, Sperner, and Cayley&#39;s formula - give rise to
complete problems for PWPP and PPP. This is in contrast to the Ramsey and
Erd\H{o}s-Rado problems, for which establishing inclusion in PWPP has remained
elusive. Besides significantly expanding the set of problems that are complete
for PWPP and PPP, our work identifies some key properties of combinatorial
proofs of existence that can give rise to completeness for these classes.
&lt;/p&gt;
&lt;p&gt;Our completeness results rely on efficient encodings for which finding
collisions allows extracting the desired substructure. These encodings are made
possible by the tightness of the bounds for the problems at hand (tighter than
what is known for Ramsey&#39;s theorem and the sunflower lemma). Previous
techniques for proving bounds in TFNP invariably made use of structured
algorithms. Such algorithms are not known to exist for the theorems considered
in this work, as their proofs &quot;from the book&quot; are non-constructive.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>The Complexity and Expressive Power of Second-Order Extended Logic</title>
  <guid>http://arxiv.org/abs/2209.04837</guid>
  <link>http://arxiv.org/abs/2209.04837</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Shiguang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xishun Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the expressive powers of SO-HORN$^{*}$, SO-HORN$^{r}$ and
SO-HORN$^{*r}$ on all finite structures. We show that SO-HORN$^{r}$,
SO-HORN$^{*r}$, FO(LFP) coincide with each other and SO-HORN$^{*}$ is proper
sublogic of SO-HORN$^{r}$. To prove this result, we introduce the notions of
DATALOG$^{*}$ program, DATALOG$^{r}$ program and their stratified versions,
S-DATALOG$^{*}$ program and S-DATALOG$^{r}$ program. It is shown that, on all
structures, DATALOG$^{r}$ and S-DATALOG$^{r}$ are equivalent and DATALOG$^{*}$
is a proper sublogic of DATALOG$^{r}$. SO-HORN$^{*}$ and SO-HORN$^{r}$ can be
treated as the negations of DATALOG$^{*}$ and DATALOG$^{r}$, respectively. We
also show that SO-EHORN$^{r}$ logic which is an extended version of SO-HORN
captures co-NP on all finite structures.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>On The Computational Complexity of Self-Attention</title>
  <guid>http://arxiv.org/abs/2209.04881</guid>
  <link>http://arxiv.org/abs/2209.04881</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keles_F/0/1/0/all/0/1&quot;&gt;Feyza Duman Keles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijewardena_P/0/1/0/all/0/1&quot;&gt;Pruthuvi Mahesakya Wijewardena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1&quot;&gt;Chinmay Hegde&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Transformer architectures have led to remarkable progress in many
state-of-art applications. However, despite their successes, modern
transformers rely on the self-attention mechanism, whose time- and
space-complexity is quadratic in the length of the input. Several approaches
have been proposed to speed up self-attention mechanisms to achieve
sub-quadratic running time; however, the large majority of these works are not
accompanied by rigorous error guarantees. In this work, we establish lower
bounds on the computational complexity of self-attention in a number of
scenarios. We prove that the time complexity of self-attention is necessarily
quadratic in the input length, unless the Strong Exponential Time Hypothesis
(SETH) is false. This argument holds even if the attention computation is
performed only approximately, and for a variety of attention mechanisms. As a
complement to our lower bounds, we show that it is indeed possible to
approximate dot-product self-attention using finite Taylor series in
linear-time, at the cost of having an exponential dependence on the polynomial
order.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Nearly all $k$-SAT functions are unate</title>
  <guid>http://arxiv.org/abs/2209.04894</guid>
  <link>http://arxiv.org/abs/2209.04894</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Balogh_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf3;zsef Balogh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dong_D/0/1/0/all/0/1&quot;&gt;Dingding Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lidicky_B/0/1/0/all/0/1&quot;&gt;Bernard Lidick&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mani_N/0/1/0/all/0/1&quot;&gt;Nitya Mani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yufei Zhao&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We prove that $1-o(1)$ fraction of all $k$-SAT functions on $n$ Boolean
variables are unate (i.e., monotone after first negating some variables), for
any fixed positive integer $k$ and as $n \to \infty$. This resolves a
conjecture by Bollob\&#39;as, Brightwell, and Leader from 2003.
&lt;/p&gt;
&lt;p&gt;This paper is the second half of a two-part work solving the problem. The
first part, by Dong, Mani, and Zhao, reduces the conjecture to a Tur\&#39;an
problem on partially directed hypergraphs. In this paper we solve this Tur\&#39;an
problem.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Gradient-Free Methods for Deterministic and Stochastic Nonsmooth Nonconvex Optimization</title>
  <guid>http://arxiv.org/abs/2209.05045</guid>
  <link>http://arxiv.org/abs/2209.05045</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tianyi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zheng_Z/0/1/0/all/0/1&quot;&gt;Zeyu Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Nonsmooth nonconvex optimization problems broadly emerge in machine learning
and business decision making, whereas two core challenges impede the
development of efficient solution methods with finite-time convergence
guarantee: the lack of computationally tractable optimality criterion and the
lack of computationally powerful oracles. The contributions of this paper are
two-fold. First, we establish the relationship between the celebrated Goldstein
subdifferential~\citep{Goldstein-1977-Optimization} and uniform smoothing,
thereby providing the basis and intuition for the design of gradient-free
methods that guarantee the finite-time convergence to a set of Goldstein
stationary points. Second, we propose the gradient-free method (GFM) and
stochastic GFM for solving a class of nonsmooth nonconvex optimization problems
and prove that both of them can return a $(\delta,\epsilon)$-Goldstein
stationary point of a Lipschitz function $f$ at an expected convergence rate at
$O(d^{3/2}\delta^{-1}\epsilon^{-4})$ where $d$ is the problem dimension.
Two-phase versions of GFM and SGFM are also proposed and proven to achieve
improved large-deviation results. Finally, we demonstrate the effectiveness of
2-SGFM on training ReLU neural networks with the \textsc{Minst} dataset.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Localization with Few Distance Measurements</title>
  <guid>http://arxiv.org/abs/2209.04838</guid>
  <link>http://arxiv.org/abs/2209.04838</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halperin_D/0/1/0/all/0/1&quot;&gt;Dan Halperin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LaValle_S/0/1/0/all/0/1&quot;&gt;Steven M. LaValle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ugav_B/0/1/0/all/0/1&quot;&gt;Barak Ugav&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Given a polygon $W$, a depth sensor placed at point $p=(x,y)$ inside $W$ and
oriented in direction $\theta$ measures the distance $d=h(x,y,\theta)$ between
$p$ and the closest point on the boundary of $W$ along a ray emanating from $p$
in direction $\theta$. We study the following problem: Give a polygon $W$,
possibly with holes, with $n$ vertices, preprocess it such that given a query
real value $d\geq 0$, one can efficiently compute the preimage $h^{-1}(d)$,
namely determine all the possible poses (positions and orientations) of a depth
sensor placed in $W$ that would yield the reading $d$. We employ a
decomposition of $W\times S^1$, which is an extension of the celebrated
trapezoidal decomposition, and which we call rotational trapezoidal
decomposition and present an efficient data structure, which computes the
preimage in an output-sensitive fashion relative to this decomposition: if $k$
cells of the decomposition contribute to the final result, we will report them
in $O(k+1)$ time, after $O(n^2\log n)$ preprocessing time and using $O(n^2)$
storage space. We also analyze the shape of the projection of the preimage onto
the polygon $W$; this projection describes the portion of $W$ where the sensor
could have been placed. Furthermore, we obtain analogous results for the more
useful case (narrowing down the set of possible poses), where the sensor
performs two depth measurement from the same point $p$, one in direction
$\theta$ and the other in direction $\theta+\pi$. While localizations problems
in robotics are often carried out by exploring the full visibility polygon of a
sensor placed at a fixed point of the environment, the approach that we propose
here opens the door to sufficing with only few depth measurements, which is
advantageous as it allows for usage of inexpensive sensors and could also lead
to savings in storage and communication costs.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>Structured $(\min,+)$-Convolution And Its Applications For The Shortest Vector, Closest Vector, and Separable Nonlinear Knapsack Problems</title>
  <guid>http://arxiv.org/abs/2209.04812</guid>
  <link>http://arxiv.org/abs/2209.04812</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gribanov_D/0/1/0/all/0/1&quot;&gt;D. V. Gribanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malyshev_D/0/1/0/all/0/1&quot;&gt;D. S. Malyshev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shumilov_I/0/1/0/all/0/1&quot;&gt;I. A. Shumilov&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work we consider the problem of computing the $(\min, +)$-convolution
of two sequences $a$ and $b$ of lengths $n$ and $m$, respectively, where $n
\geq m$. We assume that $a$ is arbitrary, but $b_i = f(i)$, where $f(x) \colon
[0,m) \to \mathbb{R}$ is a function with one of the following properties:
&lt;/p&gt;
&lt;p&gt;1. the linear case, when $f(x) =\beta + \alpha \cdot x$;
&lt;/p&gt;
&lt;p&gt;2. the monotone case, when $f(i+1) \geq f(i)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;3. the convex case, when $f(i+1) - f(i) \geq f(i) - f(i-1)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;4. the concave case, when $f(i+1) - f(i) \leq f(i) - f(i-1)$, for any $i$;
&lt;/p&gt;
&lt;p&gt;5. the piece-wise linear case, when $f(x)$ consist of $p$ linear pieces;
&lt;/p&gt;
&lt;p&gt;6. the polynomial case, when $f \in \mathbb{Z}^d[x]$, for some fixed $d$.
&lt;/p&gt;
&lt;p&gt;To the best of our knowledge, the cases 4-6 were not considered in literature
before. We develop true sub-quadratic algorithms for them.
&lt;/p&gt;
&lt;p&gt;We apply our results to the knapsack problem with a separable nonlinear
objective function, shortest lattice vector, and closest lattice vector
problems.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>On finding short reconfiguration sequences between independent sets</title>
  <guid>http://arxiv.org/abs/2209.05145</guid>
  <link>http://arxiv.org/abs/2209.05145</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1&quot;&gt;Akanksha Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hait_S/0/1/0/all/0/1&quot;&gt;Soumita Hait&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mouawad_A/0/1/0/all/0/1&quot;&gt;Amer E. Mouawad&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Assume we are given a graph $G$, two independent sets $S$ and $T$ in $G$ of
size $k \geq 1$, and a positive integer $\ell \geq 1$. The goal is to decide
whether there exists a sequence $\langle I_0, I_1, ..., I_\ell \rangle$ of
independent sets such that for all $j \in \{0,\ldots,\ell-1\}$ the set $I_j$ is
an independent set of size $k$, $I_0 = S$, $I_\ell = T$, and $I_{j+1}$ is
obtained from $I_j$ by a predetermined reconfiguration rule. We consider two
reconfiguration rules. Intuitively, we view each independent set as a
collection of tokens placed on the vertices of the graph. Then, the Token
Sliding Optimization (TSO) problem asks whether there exists a sequence of at
most $\ell$ steps that transforms $S$ into $T$, where at each step we are
allowed to slide one token from a vertex to an unoccupied neighboring vertex.
In the Token Jumping Optimization (TJO) problem, at each step, we are allowed
to jump one token from a vertex to any other unoccupied vertex of the graph.
Both TSO and TJO are known to be fixed-parameter tractable when parameterized
by $\ell$ on nowhere dense classes of graphs. In this work, we show that both
problems are fixed-parameter tractable for parameter $k + \ell + d$ on
$d$-degenerate graphs as well as for parameter $|M| + \ell + \Delta$ on graphs
having a modulator $M$ whose deletion leaves a graph of maximum degree
$\Delta$. We complement these result by showing that for parameter $\ell$ alone
both problems become W[1]-hard already on $2$-degenerate graphs. Our positive
result makes use of the notion of independence covering families introduced by
Lokshtanov et al. Finally, we show that using such families one can obtain a
simpler and unified algorithm for the standard Token Jumping Reachability
problem parameterized by $k$ on both degenerate and nowhere dense classes of
graphs.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Experiments and a User Study for Hierarchical Drawings of Graphs</title>
  <guid>http://arxiv.org/abs/2209.04522</guid>
  <link>http://arxiv.org/abs/2209.04522</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lionakis_P/0/1/0/all/0/1&quot;&gt;Panagiotis Lionakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kritikakis_G/0/1/0/all/0/1&quot;&gt;Giorgos Kritikakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tollis_I/0/1/0/all/0/1&quot;&gt;Ioannis G. Tollis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We present experimental results and a user study for hierarchical drawings of
graphs. A detailed hierarchical graph drawing technique that is based on the
Path Based Framework (PBF) is presented. Extensive edge bundling is applied to
draw all edges of the graph and the height of the drawing is minimized using
compaction. The drawings produced by this framework are compared to drawings
produced by the well known Sugiyama framework in terms of area, number of
bends, number of crossings, and execution time. The new algorithm runs very
fast and produces drawings that are readable and efficient. Since there are
advantages (and disadvantages) to both frameworks, we performed a user study
and the results show that the drawings produced by the new framework are well
received in terms of clarity, readability, and usability. Hence, the new
technique offers an interesting alternative to drawing hierarchical graphs, and
is especially useful in applications where user defined paths are important and
need to be highlighted.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Spectral hypergraph sparsification via chaining</title>
  <guid>http://arxiv.org/abs/2209.04539</guid>
  <link>http://arxiv.org/abs/2209.04539</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;James R. Lee&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a hypergraph on $n$ vertices where $D$ is the maximum size of a hyperedge,
there is a weighted hypergraph spectral $\varepsilon$-sparsifier with at most
$O(\varepsilon^{-2} \log(D) \cdot n \log n)$ hyperedges. This improves over the
bound of Kapralov, Krauthgamer, Tardos and Yoshida (2021) who achieve
$O(\varepsilon^{-4} n (\log n)^3)$, as well as the bound $O(\varepsilon^{-2}
D^3 n \log n)$ obtained by Bansal, Svensson, and Trevisan (2019). The same
sparsification result was obtained independently by Jambulapati, Liu, and
Sidford (2022).
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>PGAbB: A Block-Based Graph Processing Framework for Heterogeneous Platforms</title>
  <guid>http://arxiv.org/abs/2209.04541</guid>
  <link>http://arxiv.org/abs/2209.04541</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yasar_A/0/1/0/all/0/1&quot;&gt;Abdurrahman Yasar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajamanickam_S/0/1/0/all/0/1&quot;&gt;Sivasankaran Rajamanickam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berry_J/0/1/0/all/0/1&quot;&gt;Jonathan W. Berry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catalyurek_U/0/1/0/all/0/1&quot;&gt;Umit V. Catalyurek&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Designing flexible graph kernels that can run well on various platforms is a
crucial research problem due to the frequent usage of graphs for modeling data
and recent architectural advances and variety. In this work, we propose a novel
graph processing framework, PGAbB (Parallel Graph Algorithms by Blocks), for
modern shared-memory heterogeneous platforms. Our framework implements a
block-based programming model. This allows a user to express a graph algorithm
using kernels that operate on subgraphs. PGAbB support graph computations that
fit in host DRAM but not in GPU device memory, and provides simple but
effective scheduling techniques to schedule computations to all available
resources in a heterogeneous architecture. We have demonstrated that one can
easily implement a diverse set of graph algorithms in our framework by
developing five algorithms. Our experimental results show that PGAbB
implementations achieve better or competitive performance compared to
hand-optimized implementations. Based on our experiments on five graph
algorithms and forty-four graphs, in the median, PGAbB achieves 1.6, 1.6, 5.7,
3.4, 4.5, and 2.4 times better performance than GAPBS, Galois, Ligra, LAGraph
Galois-GPU, and Gunrock graph processing systems, respectively.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>The Bayan Algorithm: Detecting Communities in Networks Through Exact and Approximate Optimization of Modularity</title>
  <guid>http://arxiv.org/abs/2209.04562</guid>
  <link>http://arxiv.org/abs/2209.04562</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aref_S/0/1/0/all/0/1&quot;&gt;Samin Aref&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chheda_H/0/1/0/all/0/1&quot;&gt;Hriday Chheda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mostajabdaveh_M/0/1/0/all/0/1&quot;&gt;Mahdi Mostajabdaveh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Community detection is a classic problem in network science with extensive
applications in various fields. The most commonly used methods are the
algorithms designed to maximize a utility function, modularity, across
different ways that a network can be partitioned into communities. Despite
their name and design philosophy, current modularity maximization algorithms
generally fail to maximize modularity or guarantee any proximity to an optimal
solution. We propose the Bayan algorithm which, unlike the existing methods,
returns network partitions with a guarantee of either optimality or proximity
to an optimal solution. At the core of the Bayan algorithm is a branch-and-cut
scheme that solves a sparse integer programming formulation of the modularity
maximization problem to optimality or approximate it within a factor. We
analyze the performance of Bayan against 22 existing algorithms using synthetic
and real networks. Through extensive experiments, we demonstrate Bayan&#39;s
distinctive capabilities not only in maximizing modularity, but more
importantly in accurate retrieval of ground-truth communities. Bayan&#39;s
comparative level of performance remains stable over variations in the amount
of noise in the data (graph) generation process. The performance of Bayan as an
exact modularity maximization algorithm also reveals the theoretical capability
limits of maximum-modularity partitions in accurate retrieval of communities.
Overall our analysis points to Bayan as a suitable choice for a
methodologically grounded detection of communities through exact (approximate)
maximization of modularity in networks with up to $\sim10^3$ edges (and larger
networks). Prospective advances in graph optimization and integer programming
can push these limits further.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>An EPTAS for Budgeted Matroid Independent Set</title>
  <guid>http://arxiv.org/abs/2209.04654</guid>
  <link>http://arxiv.org/abs/2209.04654</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doron_Arad_I/0/1/0/all/0/1&quot;&gt;Ilan Doron-Arad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulik_A/0/1/0/all/0/1&quot;&gt;Ariel Kulik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shachnai_H/0/1/0/all/0/1&quot;&gt;Hadas Shachnai&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the budgeted matroid independent set problem. The input is a
ground set, where each element has a cost and a non-negative profit, along with
a matroid over the elements and a budget. The goal is to select a subset of
elements which maximizes the total profit subject to the matroid and budget
constraints. Several well known special cases, where we have, e.g., a uniform
matroid and a budget, or no matroid constraint (i.e., the classic knapsack
problem), admit a fully polynomial-time approximation scheme (FPTAS). In
contrast, already a slight generalization to the multi-budgeted matroid
independent set problem has a PTAS but does not admit an efficient
polynomial-time approximation scheme (EPTAS). This implies a PTAS for our
problem, which is the best known result prior to this work. Our main
contribution is an EPTAS for the budgeted matroid independent set problem. A
key idea of the scheme is to find a representative set for the instance, whose
cardinality depends solely on $1/\varepsilon$, where $\varepsilon &amp;gt; 0$ is the
accuracy parameter of the scheme. The representative set is identified via
matroid basis minimization, which can be solved by a simple greedy algorithm.
Our scheme enumerates over subsets of the representative set and extends each
subset using a linear program. The notion of representative sets may be useful
in solving other variants of the budgeted matroid independent set problem.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Growing a Random Maximal Independent Set Produces a 2-approximate Vertex Cover</title>
  <guid>http://arxiv.org/abs/2209.04673</guid>
  <link>http://arxiv.org/abs/2209.04673</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veldt_N/0/1/0/all/0/1&quot;&gt;Nate Veldt&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper presents a fast and simple new 2-approximation algorithm for
minimum weighted vertex cover. The unweighted version of this algorithm is
equivalent to a well-known greedy maximal independent set algorithm. We prove
that this independent set algorithm produces a 2-approximate vertex cover, and
we provide a principled new way to generalize it to node-weighted graphs. Our
analysis is inspired by connections to a clustering objective called
correlation clustering. To demonstrate the relationship between these problems,
we show how a simple Pivot algorithm for correlation clustering implicitly
approximates a special type of hypergraph vertex cover problem. Finally, we use
implicit implementations of this maximal independent set algorithm to develop
fast and simple 2-approximation algorithms for certain edge-deletion problems
that can be reduced to vertex cover in an approximation preserving way.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Hard Optimization Problems have Soft Edges</title>
  <guid>http://arxiv.org/abs/2209.04824</guid>
  <link>http://arxiv.org/abs/2209.04824</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Marino_R/0/1/0/all/0/1&quot;&gt;Raffaele Marino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Kirkpatrick_S/0/1/0/all/0/1&quot;&gt;Scott Kirkpatrick&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Finding a Maximum Clique is a classic property test from graph theory; find
any one of the largest complete subgraphs in an Erd{\&quot;o}s-R{\&#39;e}nyi $G(N,p)$
random graph. It is the simplest of many such problems in which algorithms
requiring only a small power of $N$ steps cannot reach solutions which
probabilistic arguments show must exist, exposing an inherently &quot;hard&quot; phase
within the solution space of the problem. Such &quot;hard&quot; phases are seen in many
NP-Complete problems, in the limit when $N \to \infty$. But optimization
problems arise and must be solved at finite N. We use this simplest case,
MaxClique, to explore the structure of the problem as a function of $N$ and
$K$, the clique size. It displays a complex phase boundary, a staircase of
steps at each of which $2 \log_2N$ and $K_{\text{max}}$, the maximum size of
clique that can be found, increase by $1$. Each of its boundaries have finite
width, and these widths allow local algorithms to find cliques beyond the
limits defined by the study of infinite systems. We explore the performance of
a number of extensions of traditional fast local algorithms, and find that much
of the &quot;hard&quot; space remains accessible at finite $N$.
&lt;/p&gt;
&lt;p&gt;The &quot;hidden clique&quot; problem embeds a clique somewhat larger than those which
occur naturally in a $G(N,p)$ random graph. Since such a clique is unique, we
find that local searches which stop early, once evidence for the hidden clique
is found, may outperform the best message passing or spectral algorithms.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Rethink Decision Tree Traversal</title>
  <guid>http://arxiv.org/abs/2209.04825</guid>
  <link>http://arxiv.org/abs/2209.04825</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jinxiong Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We will show how to evaluate binary decision tree traversal in the language
of matrix computation motivated by \textit{QuickScorer} in
\cite{lucchese2015quickscorer}. Our main contribution is a novel matrix
representation of the hierarchical structure of the decision tree. And we
propose some equivalent algorithms of binary decision tree traversal based on
rigorous theoretical analysis. The core idea is to find the relation between
the input and exit leaf node. Here we not only understand decisions without the
recursive traverse but also dive into the partitioning nature of tree-based
methods.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>An Improved Algorithm For Online Reranking</title>
  <guid>http://arxiv.org/abs/2209.04870</guid>
  <link>http://arxiv.org/abs/2209.04870</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bienkowski_M/0/1/0/all/0/1&quot;&gt;Marcin Bienkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mucha_M/0/1/0/all/0/1&quot;&gt;Marcin Mucha&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study a fundamental model of online preference aggregation, where an
algorithm maintains an ordered list of $n$ elements. An input is a stream of
preferred sets $R_1, R_2, \dots, R_t, \dots$. Upon seeing $R_t$ and without
knowledge of any future sets, an algorithm has to rerank elements (change the
list ordering), so that at least one element of $R_t$ is found near the list
front. The incurred cost is a sum of the list update costs (the number of swaps
of neighboring list elements) and access costs (position of the first element
of $R_t$ on the list). This scenario occurs naturally in applications such as
ordering items in an online shop using aggregated preferences of shop
customers. The theoretical underpinning of this problem is known as Min-Sum Set
Cover.
&lt;/p&gt;
&lt;p&gt;Unlike previous work (Fotakis et al., ICALP 2020, NIPS 2020) that mostly
studied the performance of an online algorithm ALG against the static optimal
solution (a single optimal list ordering), in this paper, we study an arguably
harder variant where the benchmark is the provably stronger optimal dynamic
solution OPT (that may also modify the list ordering). In terms of an online
shop, this means that the aggregated preferences of its user base evolve with
time. We construct a computationally efficient randomized algorithm whose
competitive ratio (ALG-to-OPT cost ratio) is $O(r^2)$ and prove the existence
of a deterministic $O(r^4)$-competitive algorithm. Here, $r$ is the maximum
cardinality of sets $R_t$. This is the first algorithm whose ratio does not
depend on $n$: the previously best algorithm for this problem was $O(r^{3/2}
\cdot \sqrt{n})$-competitive and $\Omega(r)$ is a lower bound on the
performance of any deterministic online algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Subquadratic Kronecker Regression with Applications to Tensor Decomposition</title>
  <guid>http://arxiv.org/abs/2209.04876</guid>
  <link>http://arxiv.org/abs/2209.04876</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fahrbach_M/0/1/0/all/0/1&quot;&gt;Matthew Fahrbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1&quot;&gt;Thomas Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghadiri_M/0/1/0/all/0/1&quot;&gt;Mehrdad Ghadiri&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Kronecker regression is a highly-structured least squares problem
$\min_{\mathbf{x}} \lVert \mathbf{K}\mathbf{x} - \mathbf{b} \rVert_{2}^2$,
where the design matrix $\mathbf{K} = \mathbf{A}^{(1)} \otimes \cdots \otimes
\mathbf{A}^{(N)}$ is a Kronecker product of factor matrices. This regression
problem arises in each step of the widely-used alternating least squares (ALS)
algorithm for computing the Tucker decomposition of a tensor. We present the
first subquadratic-time algorithm for solving Kronecker regression to a
$(1+\varepsilon)$-approximation that avoids the exponential term
$O(\varepsilon^{-N})$ in the running time. Our techniques combine leverage
score sampling and iterative methods. By extending our approach to block-design
matrices where one block is a Kronecker product, we also achieve
subquadratic-time algorithms for (1) Kronecker ridge regression and (2)
updating the factor matrix of a Tucker decomposition in ALS, which is not a
pure Kronecker regression problem, thereby improving the running time of all
steps of Tucker ALS. We demonstrate the speed and accuracy of this Kronecker
regression algorithm on synthetic data and real-world image tensors.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Cores of Games via Total Dual Integrality, with Applications to Perfect Graphs and Polymatroids</title>
  <guid>http://arxiv.org/abs/2209.04903</guid>
  <link>http://arxiv.org/abs/2209.04903</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vazirani_V/0/1/0/all/0/1&quot;&gt;Vijay V. Vazirani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;LP-duality theory has played a central role in the study of cores of games,
right from the early days of this notion to the present time. The classic paper
of Shapley and Shubik \cite{Shapley1971assignment} introduced the &quot;right&quot; way
of exploiting the power of this theory, namely picking problems whose
LP-relaxations support polyhedra having integral vertices. So far, the latter
fact was established by showing that the constraint matrix of the underlying
linear system is {\em totally unimodular}.
&lt;/p&gt;
&lt;p&gt;We attempt to take this methodology to its logical next step -- {\em using
total dual integrality} -- thereby addressing new classes of games which have
their origins in two major theories within combinatorial optimization, namely
perfect graphs and polymatroids. In the former, we address the stable set and
clique games and in the latter, we address the matroid independent set game.
For each of these games, we prove that the set of core imputations is precisely
the set of optimal solutions to the dual LPs.
&lt;/p&gt;
&lt;p&gt;Another novelty is the way the worth of the game is allocated among
sub-coalitions. Previous works follow the {\em bottom-up process} of allocating
to individual agents; the allocation to a sub-coalition is simply the sum of
the allocations to its agents. The {\em natural process for our games is
top-down}. The optimal dual allocates to &quot;objects&quot; in the grand coalition; a
sub-coalition inherits the allocation of each object with which it has
non-empty intersection.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Dynamic Subset Sum with Truly Sublinear Processing Time</title>
  <guid>http://arxiv.org/abs/2209.04936</guid>
  <link>http://arxiv.org/abs/2209.04936</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saleh_H/0/1/0/all/0/1&quot;&gt;Hamed Saleh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seddighin_S/0/1/0/all/0/1&quot;&gt;Saeed Seddighin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Subset sum is a very old and fundamental problem in theoretical computer
science. In this problem, $n$ items with weights $w_1, w_2, w_3, \ldots, w_n$
are given as input and the goal is to find out if there is a subset of them
whose weights sum up to a given value $t$. While the problem is NP-hard in
general, when the values are non-negative integer, subset sum can be solved in
pseudo-polynomial time $~\widetilde O(n+t)$.
&lt;/p&gt;
&lt;p&gt;In this work, we consider the dynamic variant of subset sum. In this setting,
an upper bound $\tmax$ is provided in advance to the algorithm and in each
operation, either a new item is added to the problem or for a given integer
value $t \leq \tmax$, the algorithm is required to output whether there is a
subset of items whose sum of weights is equal to $t$. Unfortunately, none of
the existing subset sum algorithms is able to process these operations in truly
sublinear time\footnote{Truly sublinear means $n^{1-\Omega(1)}$.} in terms of
$\tmax$.
&lt;/p&gt;
&lt;p&gt;Our main contribution is an algorithm whose amortized processing
time\footnote{Since the runtimes are amortized, we do not use separate terms
update time and query time for different operations and use processing time for
all types of operations.} for each operation is truly sublinear in $\tmax$ when
the number of operations is at least $\tmax^{2/3+\Omega(1)}$. We also show that
when both element addition and element removal are allowed, there is no
algorithm that can process each operation in time $\tmax^{1-\Omega(1)}$ on
average unless \textsf{SETH}\footnote{The \textit{strong exponential time
hypothesis} states that no algorithm can solve the satisfiability problem in
time $2^{n(1-\Omega(1))}$.} fails.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>QUBO formulations for NP-Hard spanning tree problems</title>
  <guid>http://arxiv.org/abs/2209.05024</guid>
  <link>http://arxiv.org/abs/2209.05024</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carvalho_I/0/1/0/all/0/1&quot;&gt;Ivan Carvalho&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We introduce a novel Quadratic Unconstrained Binary Optimization (QUBO)
formulation method for spanning tree problems. Instead of encoding the presence
of edges in the tree individually, we opt to encode spanning trees as a
permutation problem. We apply our method to four NP-hard spanning tree
variants, namely the k-minimum spanning tree, degree-constrained minimum
spanning tree, minimum leaf spanning tree, and maximum leaf spanning tree. Our
main result is a formulation with $\mathcal{O}(|V|k)$ variables for the
k-minimum spanning tree problem, beating related strategies that need
$\mathcal{O}(|V|^{2})$ variables.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-13 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Thirty Years of Dagstuhl</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-4092582253443093216</guid>
  <link>http://blog.computationalcomplexity.org/2022/09/thirty-years-of-dagstuhl.html</link>
  <description>
    &lt;p&gt;&amp;nbsp;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiAVV6vqRxQ0GiKOwjxUJJsrSy10_N1Rnaq7CSWN1LgmRkcVyYHAp5sLgwslboCRbhHq3s6iMU9bSHGJlLBUthZUpI750kpeBrLOkMQcLtDBumFlxNfU-mSDwmO_8nRgw9onQW6AVeluj2ZL1-oGuWqCRxbIVJyT5OZAsdPSTc-BM8UqwioQ/s2668/PXL_20220912_120021005.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;2259&quot; data-original-width=&quot;2668&quot; height=&quot;339&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiAVV6vqRxQ0GiKOwjxUJJsrSy10_N1Rnaq7CSWN1LgmRkcVyYHAp5sLgwslboCRbhHq3s6iMU9bSHGJlLBUthZUpI750kpeBrLOkMQcLtDBumFlxNfU-mSDwmO_8nRgw9onQW6AVeluj2ZL1-oGuWqCRxbIVJyT5OZAsdPSTc-BM8UqwioQ/w400-h339/PXL_20220912_120021005.jpg&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Dagstuhl old-timers at the original castle&lt;br /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;I&#39;m back at Dagstuhl for the seminar on&amp;nbsp;&lt;a href=&quot;https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=22371&quot;&gt;Algebraic and Analytic Methods in Computational Complexity&lt;/a&gt;. My &lt;a href=&quot;https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=9206&quot;&gt;first seminar&lt;/a&gt; at Dagstuhl was back in 1992. I&#39;ve been coming for thirty years and have been here roughly thirty times. My &lt;a href=&quot;https://blog.computationalcomplexity.org/2019/03/back-at-dagstuhl.html&quot;&gt;last trip&lt;/a&gt; was pre-covid (virtual Dagstuhls don&#39;t count) and I really needed this chance to hang out and talk complexity with colleagues old and new.&lt;/p&gt;&lt;p&gt;Some changes since my last trip. The room doors have locks (there are rumors of an incident). You have to create your own keycard on a new machine logging into your Dagstuhl account. I had a long random password through a password manager and it was not so easy as process.&lt;/p&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLRrLcyKcZLTsqhWGocXuS13xG4yxOJNC9A0xL4mwzmXB8KXWwVTEsW4jF5lST7LAfHNbb_z4nwmOQarS1dwdoSwQYg7IX6NdpNqGkriuzDM4M1mP3rgiR99bV2XOAVr2iJvPsyGHBG6ECrwqYuR65Ok9uXvS_CvxogulpL0Eph-4xPLW9EA/s4080/PXL_20220912_122728903.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;3072&quot; data-original-width=&quot;4080&quot; height=&quot;241&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLRrLcyKcZLTsqhWGocXuS13xG4yxOJNC9A0xL4mwzmXB8KXWwVTEsW4jF5lST7LAfHNbb_z4nwmOQarS1dwdoSwQYg7IX6NdpNqGkriuzDM4M1mP3rgiR99bV2XOAVr2iJvPsyGHBG6ECrwqYuR65Ok9uXvS_CvxogulpL0Eph-4xPLW9EA/s320/PXL_20220912_122728903.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;p&gt;The main conference room has been updated with tech for hybrid meetings, and new led lights. Books were removed from the library to create a coffee breakout space.&lt;/p&gt;&lt;p&gt;No Bill this time so no &lt;a href=&quot;https://blog.computationalcomplexity.org/search?q=typecast&quot;&gt;typecasts&lt;/a&gt;. Still the best part of the week is talking and hearing about complexity. Today I learned about the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sperner%27s_lemma#Oriented_variants&quot;&gt;orientations of Sperner&#39;s lemma&lt;/a&gt;, that there is one more triangle oriented according to the direction of the corner vertices than those oriented the other way.&amp;nbsp;Christian Ikenmeyer used this fact to motivate a study of closure properties of #P-functions.&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2022-09-12 15:26:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>Quantum optimization with arbitrary connectivity using Rydberg atom arrays</title>
  <guid>http://arxiv.org/abs/2209.03965</guid>
  <link>http://arxiv.org/abs/2209.03965</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nguyen_M/0/1/0/all/0/1&quot;&gt;Minh-Thi Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jin-Guo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wurtz_J/0/1/0/all/0/1&quot;&gt;Jonathan Wurtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lukin_M/0/1/0/all/0/1&quot;&gt;Mikhail D. Lukin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sheng-Tao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pichler_H/0/1/0/all/0/1&quot;&gt;Hannes Pichler&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Programmable quantum systems based on Rydberg atom arrays have recently been
used for hardware-efficient tests of quantum optimization algorithms [Ebadi et
al., Science, 376, 1209 (2022)] with hundreds of qubits. In particular, the
maximum independent set problem on the so-called unit-disk graphs, was shown to
be efficiently encodable in such a quantum system. Here, we extend the classes
of problems that can be efficiently encoded in Rydberg arrays by constructing
explicit mappings from the original computation problems to maximum weighted
independent set problems on unit-disk graphs, with at most a quadratic overhead
in the number of qubits. We analyze several examples, including: maximum
weighted independent set on graphs with arbitrary connectivity, quadratic
unconstrained binary optimization problems with arbitrary or restricted
connectivity, and integer factorization. Numerical simulations on small system
sizes indicate that the adiabatic time scale for solving the mapped problems is
strongly correlated with that of the original problems. Our work provides a
blueprint for using Rydberg atom arrays to solve a wide range of combinatorial
optimization problems with arbitrary connectivity, beyond the restrictions
imposed by the hardware geometry.
&lt;/p&gt;
  </description>
  <pubDate>2022-09-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

</channel>
</rss>
