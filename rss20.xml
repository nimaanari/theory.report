<?xml version="1.0"?>
<rss version="2.0">

<channel>
  <title>Theory of Computing Report</title>
  <link></link>
  <language>en</language>
  <description></description>


<item>
  <title>Finite state verifiers with both private and public coins</title>
  <guid>http://arxiv.org/abs/2306.09542</guid>
  <link>http://arxiv.org/abs/2306.09542</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gezer_M/0/1/0/all/0/1&quot;&gt;M. Utkan Gezer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Say_A/0/1/0/all/0/1&quot;&gt;A. C. Cem Say&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the effects of allowing a finite state verifier in an interactive
proof system to use a bounded number of private coins, in addition to &quot;public&quot;
coins whose outcomes are visible to the prover. Although swapping between
private and public-coin machines does not change the class of verifiable
languages when the verifiers are given reasonably large time and space bounds,
this distinction has well known effects for the capabilities of constant space
verifiers. We show that a constant private-coin &quot;budget&quot; (independent of the
length of the input) increases the power of public-coin interactive proofs with
finite state verifiers considerably, and provide a new characterization of the
complexity class $\rm P$ as the set of languages that are verifiable by such
machines with arbitrarily small error in expected polynomial time.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-19 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Minimizing an Uncrossed Collection of Drawings</title>
  <guid>http://arxiv.org/abs/2306.09550</guid>
  <link>http://arxiv.org/abs/2306.09550</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hlineny_P/0/1/0/all/0/1&quot;&gt;Petr Hlin&amp;#x11b;n&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masarik_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;&amp;#x161; Masa&amp;#x159;&amp;#xed;k&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we introduce the following new concept in graph drawing. Our
task is to find a small collection of drawings such that they all together
satisfy some property that is useful for graph visualization. We propose
investigating a property where each edge is not crossed in at least one drawing
in the collection. We call such collection uncrossed. Such property is
motivated by a quintessential problem of the crossing number, where one asks
for a plane drawing where the number of edge crossings is minimum. Indeed, if
we are allowed to visualize only one drawing, then the one which minimizes the
number of crossings is probably the neatest for the first orientation. However,
a collection of drawings where each highlights a different aspect of a graph
without any crossings could shed even more light on the graph&#39;s structure.
&lt;/p&gt;
&lt;p&gt;We propose two definitions. First, the uncrossed number, minimizes the number
of graph drawings in a collection, satisfying the uncrossed property. Second,
the uncrossed crossing number, minimizes the total number of crossings in the
collection that satisfy the uncrossed property. For both definitions, we
establish initial results. We prove that the uncrossed crossing number is
NP-hard, but there is an FPT algorithm parameterized by the solution size.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-19 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

<item>
  <title>An Efficient Algorithm for Power Dominating Set</title>
  <guid>http://arxiv.org/abs/2306.09870</guid>
  <link>http://arxiv.org/abs/2306.09870</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blasius_T/0/1/0/all/0/1&quot;&gt;Thomas Bl&amp;#xe4;sius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottlicher_M/0/1/0/all/0/1&quot;&gt;Max G&amp;#xf6;ttlicher&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The problem Power Dominating Set (PDS) is motivated by the placement of
phasor measurement units to monitor electrical networks. It asks for a minimum
set of vertices in a graph that observes all remaining vertices by exhaustively
applying two observation rules. Our contribution is twofold. First, we
determine the parameterized complexity of PDS by proving it is $W[P]$-complete
when parameterized with respect to the solution size. We note that it was only
known to be $W[2]$-hard before. Our second and main contribution is a new
algorithm for PDS that efficiently solves practical instances.
&lt;/p&gt;
&lt;p&gt;Our algorithm consists of two complementary parts. The first is a set of
reduction rules for PDS that can also be used in conjunction with previously
existing algorithms. The second is an algorithm for solving the remaining
kernel based on the implicit hitting set approach. Our evaluation on a set of
power grid instances from the literature shows that our solver outperforms
previous state-of-the-art solvers for PDS by more than one order of magnitude
on average. Furthermore, our algorithm can solve previously unsolved instances
of continental scale within a few minutes.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-19 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Private Federated Frequency Estimation: Adapting to the Hardness of the Instance</title>
  <guid>http://arxiv.org/abs/2306.09396</guid>
  <link>http://arxiv.org/abs/2306.09396</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jingfeng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wennan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kairouz_P/0/1/0/all/0/1&quot;&gt;Peter Kairouz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1&quot;&gt;Vladimir Braverman&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In federated frequency estimation (FFE), multiple clients work together to
estimate the frequencies of their collective data by communicating with a
server that respects the privacy constraints of Secure Summation (SecSum), a
cryptographic multi-party computation protocol that ensures that the server can
only access the sum of client-held vectors. For single-round FFE, it is known
that count sketching is nearly information-theoretically optimal for achieving
the fundamental accuracy-communication trade-offs [Chen et al., 2022]. However,
we show that under the more practical multi-round FEE setting, simple
adaptations of count sketching are strictly sub-optimal, and we propose a novel
hybrid sketching algorithm that is provably more accurate. We also address the
following fundamental question: how should a practitioner set the sketch size
in a way that adapts to the hardness of the underlying problem? We propose a
two-phase approach that allows for the use of a smaller sketch size for simpler
problems (e.g. near-sparse or light-tailed distributions). We conclude our work
by showing how differential privacy can be added to our algorithm and verifying
its superior performance through extensive experiments conducted on large-scale
datasets.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-19 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>A Smooth Binary Mechanism for Efficient Private Continual Observation</title>
  <guid>http://arxiv.org/abs/2306.09666</guid>
  <link>http://arxiv.org/abs/2306.09666</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andersson_J/0/1/0/all/0/1&quot;&gt;Joel Daniel Andersson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pagh_R/0/1/0/all/0/1&quot;&gt;Rasmus Pagh&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In privacy under continual observation we study how to release differentially
private estimates based on a dataset that evolves over time. The problem of
releasing private prefix sums of $x_1,x_2,x_3,\dots \in\{0,1\}$ (where the
value of each $x_i$ is to be private) is particularly well-studied, and a
generalized form is used in state-of-the-art methods for private stochastic
gradient descent (SGD). The seminal binary mechanism privately releases the
first $t$ prefix sums with noise of variance polylogarithmic in $t$. Recently,
Henzinger et al. and Denisov et al. showed that it is possible to improve on
the binary mechanism in two ways: The variance of the noise can be reduced by a
(large) constant factor, and also made more even across time steps. However,
their algorithms for generating the noise distribution are not as efficient as
one would like in terms of computation time and (in particular) space. We
address the efficiency problem by presenting a simple alternative to the binary
mechanism in which 1) generating the noise takes constant average time per
value, 2) the variance is reduced by a factor about 4 compared to the binary
mechanism, and 3) the noise distribution at each step is identical.
Empirically, a simple Python implementation of our approach outperforms the
running time of the approach of Henzinger et al., as well as an attempt to
improve their algorithm using high-performance algorithms for multiplication
with Toeplitz matrices.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-19 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>MementoHash: A Stateful, Minimal Memory, Best Performing Consistent Hash Algorithm</title>
  <guid>http://arxiv.org/abs/2306.09783</guid>
  <link>http://arxiv.org/abs/2306.09783</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coluzzi_M/0/1/0/all/0/1&quot;&gt;Massimo Coluzzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brocco_A/0/1/0/all/0/1&quot;&gt;Amos Brocco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antonucci_A/0/1/0/all/0/1&quot;&gt;Alessandro Antonucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leidi_T/0/1/0/all/0/1&quot;&gt;Tiziano Leidi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Consistent hashing is used in distributed systems and networking applications
to spread data evenly and efficiently across a cluster of nodes. In this paper,
we present MementoHash, a novel consistent hashing algorithm that eliminates
known limitations of state-of-the-art algorithms while keeping optimal
performance and minimal memory usage. We describe the algorithm in detail,
provide a pseudo-code implementation, and formally establish its solid
theoretical guarantees. To measure the efficacy of MementoHash, we compare its
performance, in terms of memory usage and lookup time, to that of
state-of-the-art algorithms, namely, AnchorHash, DxHash, and JumpHash. Unlike
JumpHash, MementoHash can handle random failures. Moreover, MementoHash does
not require fixing the overall capacity of the cluster (as AnchorHash and
DxHash do), allowing it to scale indefinitely. The number of removed nodes
affects the performance of all the considered algorithms. Therefore, we conduct
experiments considering three different scenarios: stable (no removed nodes),
one-shot removals (90% of the nodes removed at once), and incremental removals.
We report experimental results that averaged a varying number of nodes from ten
to one million. Results indicate that our algorithm shows optimal lookup
performance and minimal memory usage in its best-case scenario. It behaves
better than AnchorHash and DxHash in its average-case scenario and at least as
well as those two algorithms in its worst-case scenario. However, the
worst-case scenario for MementoHash occurs when more than 70% of the nodes
fail, which describes a unlikely scenario. Therefore, MementoHash shows the
best performance during the regular life cycle of a cluster.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-19 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Subset Selection Based On Multiple Rankings in the Presence of Bias: Effectiveness of Fairness Constraints for Multiwinner Voting Score Functions</title>
  <guid>http://arxiv.org/abs/2306.09835</guid>
  <link>http://arxiv.org/abs/2306.09835</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boehmer_N/0/1/0/all/0/1&quot;&gt;Niclas Boehmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celis_L/0/1/0/all/0/1&quot;&gt;L. Elisa Celis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lingxiao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehrotra_A/0/1/0/all/0/1&quot;&gt;Anay Mehrotra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1&quot;&gt;Nisheeth K. Vishnoi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of subset selection where one is given multiple
rankings of items and the goal is to select the highest ``quality&#39;&#39; subset.
Score functions from the multiwinner voting literature have been used to
aggregate rankings into quality scores for subsets. We study this setting of
subset selection problems when, in addition, rankings may contain systemic or
unconscious biases toward a group of items. For a general model of input
rankings and biases, we show that requiring the selected subset to satisfy
group fairness constraints can improve the quality of the selection with
respect to unbiased rankings. Importantly, we show that for fairness
constraints to be effective, different multiwinner score functions may require
a drastically different number of rankings: While for some functions, fairness
constraints need an exponential number of rankings to recover a
close-to-optimal solution, for others, this dependency is only polynomial. This
result relies on a novel notion of ``smoothness&#39;&#39; of submodular functions in
this setting that quantifies how well a function can ``correctly&#39;&#39; assess the
quality of items in the presence of bias. The results in this paper can be used
to guide the choice of multiwinner score functions for the subset selection
setting considered here; we additionally provide a tool to empirically enable
this.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-19 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Nearly-Optimal Hierarchical Clustering for Well-Clustered Graphs</title>
  <guid>http://arxiv.org/abs/2306.09950</guid>
  <link>http://arxiv.org/abs/2306.09950</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laenen_S/0/1/0/all/0/1&quot;&gt;Steinar Laenen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manghiuc_B/0/1/0/all/0/1&quot;&gt;Bogdan-Adrian Manghiuc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;He Sun&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This paper presents two efficient hierarchical clustering (HC) algorithms
with respect to Dasgupta&#39;s cost function. For any input graph $G$ with a clear
cluster-structure, our designed algorithms run in nearly-linear time in the
input size of $G$, and return an $O(1)$-approximate HC tree with respect to
Dasgupta&#39;s cost function. We compare the performance of our algorithm against
the previous state-of-the-art on synthetic and real-world datasets and show
that our designed algorithm produces comparable or better HC trees with much
lower running time.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-19 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Ted Kaczynski was at one time the worlds most famous living mathematician</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-1289689322553119435</guid>
  <link>https://blog.computationalcomplexity.org/2023/06/ted-kaczynski-was-at-one-time-worlds.html</link>
  <description>
    &lt;p&gt;(This post is inspired by the death of Ted Kaczynski who died on June 10, 2023.)&amp;nbsp;&lt;/p&gt;&lt;p&gt;From 1978 until 1995 23 mailbombs were sent to various people. 3 caused deaths, the rest caused injuries. The culprit was nicknamed &lt;i&gt;The Unabomber&lt;/i&gt; (I wonder if he liked that nickname.) For more on his story see&amp;nbsp;&lt;a href=&quot;https://en.wikipedia.org/wiki/Ted_Kaczynski&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The culprit was Ted Kaczynski. He had a BS in Math from Harvard in Mathematics in 1962, and a PhD in Math from The Univ of Michigan in 1967. He got a job in the Berkeley math dept but resigned in 1969. He soon thereafter moved to a shack in the woods (I wonder if his prison accommodations were better) and began sending out the mailbombs.&amp;nbsp;&lt;/p&gt;&lt;p&gt;When he was caught in 1995 he was (a) famous and (b) a mathematician. That last point is debatable in that I doubt he was doing math while living in his shack. But we will ignore that point for now. Would you call him a famous mathematician? If so then he was, in 1995, the most famous living mathematician.&amp;nbsp;&lt;/p&gt;&lt;p&gt;In&amp;nbsp; 1995 Andrew Wiles proved Fermat&#39;s Last theorem (this is not quite right- there was a bug and it was fixed with help from Richard Taylor) and he was, for a brief time, the world&#39;s most famous living mathematician, though perhaps Wiles and Kaczinski were tied. Wiles made People magazine&#39;s 25 most intriguing people of the year! (NOTE- I originally had, incorrectly that Wiles had proven it in 1986. A comment alerted me to the error which makes the story MORE interesting since Ted and Andrew were competing for Most Famous Living Mathemticians!)&lt;/p&gt;&lt;p&gt;Terry Tao won the Fields medal (2006) AND the MacArthur Genius award (2006) AND the breakthrough award (2015). The last one got him a spot on&amp;nbsp;&amp;nbsp;&lt;i&gt;The Colbert Report (2014)&lt;/i&gt; (See&amp;nbsp;&lt;a href=&quot;https://www.cc.com/video/6wtwlg/the-colbert-report-terence-tao&quot;&gt;here&lt;/a&gt;,) For those 15 minutes he might have been the most famous living mathematician. He did not have much competition for the honor.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;And then there is Grigori Perelman who solved the Ponicare Conjecture and declined the Fields Medal and the Millennium prize (Colbert commented on this, see&amp;nbsp;&lt;a href=&quot;https://www.cc.com/video/xr6owy/the-colbert-report-cheating-death-fields-medal&quot;&gt;here&lt;/a&gt;.) For a very brief time Perelman may have been the most famous living mathematician. He did not have much competition for the honor.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The most famous mathematicians of all time: Pythagoras of Samos, Euclid, Lewis Carroll.&amp;nbsp;&lt;/p&gt;&lt;p&gt;1) Pythagoras might not count since its not clear how much he had to do with his theorem.&lt;/p&gt;&lt;p&gt;2) Lewis Carroll is the most interesting case. He IS famous. He DID do Mathematics. He DID mathematics while he wrote the books that made him famous. So he is a &lt;i&gt;famous mathematician &lt;/i&gt;but he is not famous for his math. But that does not quite seem right.&amp;nbsp;&lt;/p&gt;&lt;p&gt;3) The Math version of AND and the English version of AND are different. Lewis Carroll is FAMOUS and Lewis Caroll is A MATHEMATICIAN but it doesn&#39;t seem quite right to call him a FAMOUS MATHEMATICIAN. Same for Ted K.&amp;nbsp; Andrew W was, for a short time, a legit FAMOUS MATHEMATICIAN.&amp;nbsp;&lt;/p&gt;&lt;p&gt;3) Stephen Hawkings has appeared on ST:TNG and his voice on The Simpsons, Futurama, The Big Bang Theory. He is famous for a combination of his disability, his expository work, and his Physics. Is he a &lt;i&gt;famous actor&lt;/i&gt;?&amp;nbsp;&lt;/p&gt;&lt;p&gt;4) Science expositors like Carl Sagan and Neil deGrasse Tyson are famous for being expositors of science, not quite for their science. How do Professor Proton and Bill Nye the Science Guy fit into this?&lt;/p&gt;&lt;p&gt;5) Looking at Ted K, Andrew W, Terry T, Grigori P one other point comes up: All of them were famous for a short time but it faded QUICKLY. So- fame is fleeting!&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </description>
  <pubDate>2023-06-18 13:37:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>News for May 2023</title>
  <guid>https://ptreview.sublinear.info/?p=1884</guid>
  <link>https://ptreview.sublinear.info/2023/06/news-for-may-2023/</link>
  <description>
    &lt;p&gt;Apologies, dear readers for the delay in getting out this month&amp;#8217;s post. This month we had three papers &amp;#8212; all on testing properties of graphs! One of the featured papers this month revisits the problem of testing the properties of directed graphs and comes back with a happy progress report. Alright, let&amp;#8217;s dig in.&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;A Distributed Conductance Tester Without Global Information Collection&lt;/strong&gt; by Tugkan Batu, Chhaya Trehan (&lt;a href=&quot;https://arxiv.org/abs/2305.14178&quot;&gt;arXiv&lt;/a&gt;) One of the classic questions in property testing considers the task of testing expansion. Here, you are interested in knowing whether the input graph has conductance at least \(\alpha\) or it is far from having conductance at most \(\alpha^2\). On a parallel track, we recall that thanks to the classic work of Parnas and Ron, we know there are connections between distributed algorithms and graph property testing. Meditating on these connections led to the emergence of distributed graph property testing as an active area of research. The featured paper considers the task of testing expansion in the distributed framework. The algorithms presented give a distributed implementation of multiple random walks from all vertices, and controls the congestion of the implementation. In particular, this leads to a \(O(\log n/\alpha^2)\) round expansion-tester. In a first attempt at such an implementation, you might note that you need to track how well short random walks mix when started from a bunch of randomly chosen vertices. This seems to require maintaining some global state/global aggregate information. One of the important features of their algorithm (as mentioned in the title) does away with the need to maintain such global states. As a closing remark, I note the algorithm presented in this paper does not require the graph to be bounded degree.&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Testing versus estimation of graph properties, revisited&lt;/strong&gt; by Lior Gishboliner, Nick Kushnir, Asaf Shapira (&lt;a href=&quot;https://arxiv.org/abs/2305.05487&quot;&gt;arXiv&lt;/a&gt;) This paper considers the task of additively estimating the distance to a property \(\mathcal{P}\) of a dense graph. Let me set up some context to view the results in the featured paper by summarizing what was known before. One of the early important results in this area is the original result of Fischer and Newman which shows that any testable graph property admits a \(\pm \varepsilon\) distance approximation algorithm, which follows from the regularity lemma. However, the query complexity of the resulting algorithm is a Wowzer-style bound. Later, Hoppen et al., building upon tools from the classic work of Conlon and Fox, demonstrated that this bound of \(twr(poly(1/\varepsilon))\) also holds for testable hereditary properties. Fiat and Ron introduced a decomposition machinery that allowed them to decompose a &amp;#8220;complex&amp;#8221; property into a collection of simpler properties. They used this decomposition to estimate distances to a vast collection of graph properties. They also asked if it was possible to find a transformation using which one can bypass the blowup in query complexity incurred by Fischer and Newman for some rich class of graph properties. The featured paper proves that for a hereditary graph property, you can in fact get algorithms where the query complexity for distance estimation only grows as \(\exp(1/\varepsilon)\). Additionally, for every testable graph property, you can get distance estimators for that property whose query complexity only grows doubly exponentially in \(1/\varepsilon\) (as opposed to the tower bound earlier).  &lt;/p&gt;



&lt;p&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;An Optimal Separation between Two Property Testing Models for Bounded Degree Directed Graphs&lt;/strong&gt; by Pan Peng, Yuyang Wang (&lt;a href=&quot;https://arxiv.org/abs/2305.13089&quot;&gt;arXiv&lt;/a&gt;) Unlike undirected graphs, directed graph properties have not received as much attention in the property testing community. In a classic work, Bender and Ron considered two natural models for studying property testing on directed graphs. The first model is one where you can only follow the &amp;#8220;out&amp;#8221; edges or the so-called &lt;em&gt;unidirectional model&lt;/em&gt;. In the other model, you are allowed to follow both the &amp;#8220;out&amp;#8221; edges and the &amp;#8220;in&amp;#8221; edges incident on the vertex which is also called the &lt;em&gt;bidirectional model&lt;/em&gt;. The featured paper considers directed graphs where the in-degree and the out-degrees are both bounded in both of the models mentioned above. The graph is presented to you in the adjacency list format (tailored for the model you consider). The paper shows that even for the fundamental task of subgraph-freeness, the directed world has some interesting behavior with respect to the two models above. Let me showcase one of the catchy results from the paper which illustrates this separation nicely. Take a connected directed graph \(H\) with \(k\) source components. The paper shows that for sufficiently small \(\varepsilon\), testing whether a directed graph \(G\) is \(H\)-free or \(\varepsilon\)-far from being \(H\)-free requires \(\Omega(n^{1-1/k})\) unidirectional queries. On the other hand, in the bidirectional model, this can be done with a mere \(O_{\varepsilon, d, k}(1)\) number of queries.&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By Akash&lt;/p&gt;
  </description>
  <pubDate>2023-06-18 07:14:46 UTC</pubDate>
  <author>Property Testing Review</author>
</item>

<item>
  <title>TR23-090 |  HDX Condensers | 

	Itay Cohen, 

	Roy Roth, 

	Amnon Ta-Shma</title>
  <guid>https://eccc.weizmann.ac.il/report/2023/090</guid>
  <link>https://eccc.weizmann.ac.il/report/2023/090</link>
  <description>
    More than twenty years ago, Capalbo, Reingold, Vadhan and Wigderson gave the first (and up to date only) explicit construction of a bipartite expander with almost full combinatorial expansion. The construction incorporates zig-zag ideas together with extractor technology, and is rather complicated. We give an alternative construction that builds upon recent constructions of hyper-regular, high-dimensional expanders. The new construction is, in our opinion, simple and elegant.
Beyond demonstrating a new, surprising, and intriguing, application of high-dimensional expanders, the construction employs totally new ideas which we hope may lead to progress on the still remaining open problems in the area.
  </description>
  <pubDate>2023-06-18 05:48:51 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Guest post: STOCial activities, Graduating Bits, and Junior/Senior Lunch at STOC 2023</title>
  <guid>http://tcsplus.wordpress.com/?p=693</guid>
  <link>https://tcsplus.wordpress.com/2023/06/17/guest-post-stocial-activities-graduating-bits-and-junior-senior-lunch-at-stoc-2023/</link>
  <description>
    &lt;p&gt;If you are attending &lt;a href=&quot;http://acm-stoc.org/stoc2023/&quot;&gt;STOC&amp;#8217;23&lt;/a&gt; as part of the TheoryFest next week, don&amp;#8217;t forget to have a look at the &lt;a href=&quot;https://sites.google.com/view/stocial2023/home&quot;&gt;STOCial Program&lt;/a&gt;! &lt;/p&gt;


&lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-large&quot;&gt;&lt;a href=&quot;https://tcsplus.files.wordpress.com/2023/06/it-is-fun-its-enjoyable.gif&quot;&gt;&lt;img data-attachment-id=&quot;699&quot; data-permalink=&quot;https://tcsplus.wordpress.com/2023/06/17/guest-post-stocial-activities-graduating-bits-and-junior-senior-lunch-at-stoc-2023/it-is-fun-its-enjoyable/&quot; data-orig-file=&quot;https://tcsplus.files.wordpress.com/2023/06/it-is-fun-its-enjoyable.gif&quot; data-orig-size=&quot;498,289&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;it-is-fun-its-enjoyable&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://tcsplus.files.wordpress.com/2023/06/it-is-fun-its-enjoyable.gif?w=300&quot; data-large-file=&quot;https://tcsplus.files.wordpress.com/2023/06/it-is-fun-its-enjoyable.gif?w=498&quot; src=&quot;https://tcsplus.files.wordpress.com/2023/06/it-is-fun-its-enjoyable.gif?w=498&quot; alt=&quot;GIF of a man with a beret saying &amp;quot;It is fun!&amp;quot;&quot; class=&quot;wp-image-699&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;&lt;/p&gt;



&lt;p&gt;In particular, and to get to the point of this announcement: if you are graduating or will be on the job market soon, consider participating to the &lt;em&gt;Graduating Bits Session&lt;/em&gt; on Wednesday: 1-2 slides, 2 minutes, entirely yours to present and pitch your research to the STOC attendees! To register, &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLScgDDosoozV6rJ7kemMolHQJGgt3vO7ihjfpKhaeVMc_7IDVw/viewform&quot;&gt;fill this form&lt;/a&gt; before Tuesday evening &lt;em&gt;(up to 25 slots, first-come-first-served)&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;Following the by-now-well-established tradition, there will also be a &amp;#8220;senior/junior lunch&amp;#8221; on Thursday, during the 12:30-2pm time slot: &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1nmPaZdjC0y0FbJgwXDAzaHSp6FjOtSoRM_SCjqbA9rE/edit&quot;&gt;put your name here&lt;/a&gt; as a &amp;#8220;senior&amp;#8221; (broadly construed) or a &amp;#8220;junior&amp;#8221; academic, for informal discussions, academic advice, and general questions over lunch. &lt;/p&gt;



&lt;p&gt;See you next week at the TheoryFest!&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Clément, on behalf of the STOCial Committee (Barna Saha, Clément Canonne, Elena Grigorescu, and Raghu Meka)&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By plustcs&lt;/p&gt;
  </description>
  <pubDate>2023-06-17 12:34:16 UTC</pubDate>
  <author>TCS+ Seminar Series</author>
</item>

<item>
  <title>Linkage</title>
  <guid>https://11011110.github.io/blog/2023/06/15/linkage</guid>
  <link>https://11011110.github.io/blog/2023/06/15/linkage.html</link>
  <description>
    &lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.thisiscolossal.com/2023/04/book-of-marble/&quot;&gt;&lt;em&gt;Marmor Soorten&lt;/em&gt;, or &lt;em&gt;The Book of Marble&lt;/em&gt;&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@colossal@mastodon.art/110349972015054620&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; an Enlightenment-era full-color catalog of types of marble, to be reprinted by Taschen.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.quantamagazine.org/how-math-has-changed-the-shape-of-gerrymandering-20230601/&quot;&gt;How Math Has Changed the Shape of Gerrymandering&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@JeanneClelland/110475855814528525&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; &lt;em&gt;Quanta&lt;/em&gt; on the ReCom method for generating random ensembles of redistricting plans with the probability of a plan proportional to its number of spanning forests, via Markov Chain Monte Carlo, and using them as a basis of comparison to test the fairness of real redistricting plans. Moon Duchin recently spoke on the same thing at SoCG.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.erdosproblems.com/&quot;&gt;Erdős problems&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@sioum/110469648800130541&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; collected and tracked by Thomas Bloom.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://meta.stackexchange.com/questions/389811/moderation-strike-stack-overflow-inc-cannot-consistently-ignore-mistreat-an&quot;&gt;Moderation Strike on Stack Overflow&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@highergeometer/110489672001944513&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;)&lt;/span&gt; triggered by a combination of corporate insistance on allowing AI content and lying to users about what they are requiring of their moderators. This affects both &lt;a href=&quot;https://mathoverflow.net/&quot;&gt;MathOverflow&lt;/a&gt; and the &lt;a href=&quot;https://cstheory.stackexchange.com/&quot;&gt;TCS Stack Exchange&lt;/a&gt;, although MathOverflow at least is merely operated by StackExchange, not actually owned by it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2002.09534&quot;&gt;Hyperbolic Minesweeper is in \(\mathsf{P}\)&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/110499653895105776&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; paper from FUN 2021 by Eryk Kopczyński. As the paper shows, finite subsets of hyperbolic tilings form graphs with only logarithmic treewidth. As a consequence, problems that can be solved by dynamic programming on these graphs, such as testing the safety of moves in hyperbolic minesweeper, take polynomial time.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.cambridge.org/files/9216/8487/6990/matching_book_pw.pdf&quot;&gt;&lt;em&gt;Online and Matching-Based Market Design&lt;/em&gt;&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@fortnow@fediscience.org/110498942774330068&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; new book edited by Federico Echenique, Nicole Immorlica, and Vijay Vazirani. The editors gave up any royalties to make it free online, but in a gratuitously annoying format where the online copy is password-locked with a publicly-announced password. The password is OMBMD_CUP. I put it into the filename of my downloaded copy so I wouldn’t lose one without the other.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2306.04007&quot;&gt;Sam Mattheus and Jacques Verstraete determine the asymptotics of the Ramsey numbers \(r(4,n)\) to within a polylog&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@anuragbishnoi/110508895802423231&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; See also &lt;a href=&quot;https://anuragbishnoi.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/&quot;&gt;Anurag Bishnoi’s blog post on the proof&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.techcityng.com/wikipedia-says-it-will-not-comply-with-uk-bill-on-age-checks/&quot;&gt;“Wikipedia has announced that it will not comply with the age verification requirements of the UK’s Online Safety Bill”&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/110518781331781604&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2023-06-05/In_the_media&quot;&gt;via&lt;/a&gt;). For more about the bill, see &lt;a href=&quot;https://en.wikipedia.org/wiki/Online_Safety_Bill&quot;&gt;Wikipedia’s article on it&lt;/a&gt; — the issues are whether Wikipedia’s articles on sexual topics could be classified as pornography, which would trigger mandatory age verification according to the bill, and incompatibility of both age restriction and reader identification with the goals and purposes of Wikipedia.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.insidehighered.com/news/faculty-issues/diversity-equity/2023/06/09/mathfest-florida-some-lgbtq-mathematicians-arent&quot;&gt;&lt;em&gt;Inside Higher Education&lt;/em&gt; on MAA’s insistence on holding MathFest in Florida this August&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/110524346620592147&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;,&lt;/span&gt; &lt;a href=&quot;https://web.archive.org/web/20230609042324/https://www.insidehighered.com/news/faculty-issues/diversity-equity/2023/06/09/mathfest-florida-some-lgbtq-mathematicians-arent&quot;&gt;archive&lt;/a&gt;), in-person only, over the objections of LGBTQ+ mathematicians targeted by recently passed state anti-gay laws that prohibit people from using gender-appropriate bathrooms, forbid the mention of homosexuality, sexism, or racism in schools, and have been used to shut down parades and concerts for including people being trans in public. See also &lt;a href=&quot;http://digitaleditions.walsworthprintgroup.com/publication/?i=793202&amp;amp;article_id=4588328&quot;&gt;“Mathfest in Tampa: A Discussion”, &lt;em&gt;MAA Focus&lt;/em&gt;&lt;/a&gt;. These sorts of events take years in advance to set up, and would incur a huge financial penalty to cancel at this late date, but the MAA already started having recriminations in 2021.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mathstodon.xyz/@tonwood/110524333213370377&quot;&gt;Anton Sherwood asks for monohedral tilings of the sphere with no symmetries&lt;/a&gt;. It’s possible, but whether it can be done with arbitrarily large numbers of tiles is unclear.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cantor%27s_isomorphism_theorem&quot;&gt;Newly promoted Wikipedia Good Article: Cantor’s isomorphism theorem&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@11011110/110533545897925388&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt; This is the one saying that when an infinite linear ordering looks like the ordering on the rational numbers, it is the same ordering. “Looks like” means:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;It has countably many elements&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;It has no minimum and no maximum&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;It has another element between any two of its elements&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;So the rationals, the dyadic rationals, the algebraic numbers, their intersections with the open unit interval, etc. all have the same ordering.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mathstodon.xyz/@logicalelegance@mastodon.online/110503412274553258&quot;&gt;Origami snail shells and companion octopodes&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.wired.com/story/dont-want-students-to-rely-on-chatgpt-have-them-use-it/&quot;&gt;According to &lt;em&gt;Wired&lt;/em&gt;, giving students assignments using ChatGPT can help them become more confident in their own abilities to do better than it&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@TammyKolda/110497708715756714&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;).&lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2301.10191&quot;&gt;New simple streaming algorithm for estimating the number of distinct elements in a stream&lt;/a&gt; &lt;span style=&quot;white-space:nowrap&quot;&gt;(&lt;a href=&quot;https://mathstodon.xyz/@fortnow@fediscience.org/110537617395576272&quot;&gt;\(\mathbb{M}\)&lt;/a&gt;),&lt;/span&gt; “Distinct Elements in Streams: An Algorithm for the (Text) Book”, by Sourav Chakraborty, N. V. Vinodchandran, and Kuldeep S. Meel, updated from their ESA 2022 paper. &lt;a href=&quot;https://en.wikipedia.org/wiki/HyperLogLog&quot;&gt;HyperLogLog&lt;/a&gt; can do the same thing but the new one is maybe more suitable for teaching, and doesn’t depend on hashing. See also writeups by &lt;a href=&quot;https://cs.stanford.edu/~knuth/papers/cvm-note.pdf&quot;&gt;Knuth&lt;/a&gt; and &lt;a href=&quot;https://justinjaffray.com/a-charming-algorithm-for-count-distinct/&quot;&gt;Justin Jaffray&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;authors&quot;&gt;By David Eppstein&lt;/p&gt;
  </description>
  <pubDate>2023-06-15 23:00:00 UTC</pubDate>
  <author>David Eppstein</author>
</item>

<item>
  <title>Randomized Acceptances</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-3898908089653621520</guid>
  <link>https://blog.computationalcomplexity.org/2023/06/randomized-acceptances.html</link>
  <description>
    &lt;p&gt;NeurIPS recently released their &lt;a href=&quot;https://arxiv.org/abs/2306.03262&quot;&gt;2021 consistency report&lt;/a&gt;, a sequel to the &lt;a href=&quot;https://inverseprobability.com/2014/12/16/the-nips-experiment&quot;&gt;2014 experiment&lt;/a&gt;. While the conference has grown dramatically, the results remain &quot;consistent&quot;, about 23% disagreement from two separated program committee groups. As &lt;a href=&quot;https://blog.computationalcomplexity.org/2014/12/the-nips-experiment.html&quot;&gt;before&lt;/a&gt; I don&#39;t find this too surprising--different committee members have different tastes.&lt;/p&gt;&lt;p&gt;Roughly conference submissions fall into three categories&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol style=&quot;text-align: left;&quot;&gt;&lt;li&gt;Clearly strong papers&lt;/li&gt;&lt;li&gt;Clear rejects&lt;/li&gt;&lt;li&gt;A bunch that could go either way.&lt;/li&gt;&lt;/ol&gt;A typical program committee quickly sorts out the first two groups and then painfully spends considerable time arguing over the others.&lt;p&gt;&lt;/p&gt;&lt;p&gt;What if instead we took a different approach. Accept all the strong papers and reject the weak ones. Choose the rest randomly, either with a uniform or weighted distribution based on the ranking. Maybe reduce the probability of those who submit multiple papers.&lt;/p&gt;&lt;p&gt;Choosing randomly reduces biases and can increase diversity, if there is diversity in submissions. Knowing there is randomness in the process allows those with rejected papers to blame the randomness and those whose papers gets in claim they were in the first group. Randomness encourages more submissions and is fair over time.&lt;/p&gt;&lt;p&gt;Note we&#39;re just acknowledging the randomness in the process instead of pretending there is a perfect linear order to the papers that only a lengthy program committee discussion can suss out.&lt;/p&gt;&lt;p&gt;We should do the same for grant proposals--all worthy proposals should get a chance to be funded.&lt;/p&gt;&lt;p&gt;I doubt any of this will ever happen. People would rather trust human decisions with all their inconsistencies over pure randomness.&amp;nbsp;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By Lance Fortnow&lt;/p&gt;
  </description>
  <pubDate>2023-06-15 21:04:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>TR23-089 |  New Explicit Constant-Degree Lossless Expanders | 

	Louis Golowich</title>
  <guid>https://eccc.weizmann.ac.il/report/2023/089</guid>
  <link>https://eccc.weizmann.ac.il/report/2023/089</link>
  <description>
    We present a new explicit construction of onesided bipartite lossless expanders of constant degree, with arbitrary constant ratio between the sizes of the two vertex sets. Our construction is simpler to state and analyze than the prior construction of Capalbo, Reingold, Vadhan, and Wigderson (2002).

  We construct our lossless expanders by imposing the structure of a constant-sized lossless expander &amp;quot;gadget&amp;quot; within the neighborhoods of a large bipartite spectral expander; similar constructions were previously used to obtain the weaker notion of unique-neighbor expansion. Our analysis simply consists of elementary counting arguments and an application of the expander mixing lemma.
  </description>
  <pubDate>2023-06-15 06:20:23 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>A Little Noise Makes Quantum Factoring Fail</title>
  <guid>https://rjlipton.wpcomstaging.com/?p=21761</guid>
  <link>https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/</link>
  <description>
    &lt;p&gt;
Jin-Yi Cai is one of the top theory experts in the world. Both Ken and I have had the pleasure to work with him and interact with him over the years. We have discussed some of his previous work &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2022/02/23/simons-awards-for-2022/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2017/11/20/a-magic-madison-visit/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/jcai/&quot; rel=&quot;attachment wp-att-21763&quot;&gt;&lt;img data-attachment-id=&quot;21763&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/jcai/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jcai.jpeg?fit=150%2C190&amp;amp;ssl=1&quot; data-orig-size=&quot;150,190&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;jcai&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jcai.jpeg?fit=150%2C190&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jcai.jpeg?fit=150%2C190&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/jcai.jpeg?resize=150%2C190&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;150&quot; height=&quot;190&quot; class=&quot;aligncenter size-full wp-image-21763&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
Today we will talk about his new work on quantum computing.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Quantum Factoring &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Peter Shor invented &lt;a href=&quot;https://en.wikipedia.org/wiki/Shor&amp;#37;27s_algorithm&quot;&gt;the&lt;/a&gt; quantum algorithm for finding the prime factors of an integer in 1994.&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/pshor/&quot; rel=&quot;attachment wp-att-21764&quot;&gt;&lt;img data-attachment-id=&quot;21764&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/pshor/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?fit=241%2C241&amp;amp;ssl=1&quot; data-orig-size=&quot;241,241&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;pshor&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?fit=241%2C241&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?fit=241%2C241&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?resize=150%2C150&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;150&quot; height=&quot;150&quot; class=&quot;aligncenter wp-image-21764&quot; srcset=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?w=241&amp;amp;ssl=1 241w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?resize=150%2C150&amp;amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/pshor.jpeg?resize=200%2C200&amp;amp;ssl=1 200w&quot; sizes=&quot;(max-width: 150px) 100vw, 150px&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
This is one of the great algorithms of all time. It shows at least in theory that quantum algorithms can be much more efficient than classical algorithms. The algorithm shows that the integer factorization problem can be efficiently solved on an idealized quantum computer and is consequently in the complexity class &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;mathsf{BQP}}&quot; class=&quot;latex&quot; /&gt;. This is almost exponentially faster than the most efficient known classical factoring algorithm.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Quantum Factoring Possible? &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;Is it practically feasible to use Shor&amp;#8217;s factoring method to break RSA? This leads to a major question: &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;
&lt;em&gt;Can cryptography survive quantum methods?&lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;
A &lt;a href=&quot;https://eprint.iacr.org/2017/351.pdf&quot;&gt;paper&lt;/a&gt; by Daniel Bernstein, Nadia Heninger, Paul Lou, and Luke Valenta titled &amp;#8220;Post-Quantum RSA&amp;#8221; is a key one. They consider further systems including elliptic curve cryptography (ECC) and say:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; The conventional wisdom among researchers in post-quantum cryptography is that quantum computers will kill RSA and ECC but will not kill hash-based cryptography, code-based cryptography, lattice-based cryptography, or multivariate- quadratic-equations cryptography.&lt;br /&gt;
&amp;#8230;&lt;br /&gt;
Shor&amp;#8217;s algorithm easily breaks RSA as used on the Internet today. The question is whether RSA parameters can be adjusted so that all known quantum attack algorithms are infeasible while encryption and decryption remain feasible. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
See also &lt;a href=&quot;https://math.mit.edu/~apost/courses/18.204-2016/18.204_Jeremy_Wohlwend_final_paper.pdf&quot;&gt;this&lt;/a&gt;. A 2019 &lt;a href=&quot;https://arxiv.org/abs/1905.09749&quot;&gt;paper&lt;/a&gt; by Craig Gidney and Martin Eker&amp;aring; argues that implementations of Shor on 2,048-bit integers &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N}&quot; class=&quot;latex&quot; /&gt; is within reach of current technology using noisy qubits&amp;#8212;needing only some millions of them. However, this presumes an error-free implementation of the Quantum Fourier Transform (QFT). They say:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Note furthermore that when we analyze the success probabilities of Shor’s algorithms, and the various derivatives, we assume the use of an ideal QFT even though the implemented QFT is technically an approximation. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;
[&lt;b&gt;Added 6/19:&lt;/b&gt; This quotation is taken somewhat out of context, because the paper&amp;#8217;s main concern is optimizing and dealing with the much greater noise and precision issues in the superposed modular exponentiation step.  See Craig Gidney&amp;#8217;s &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/#comment-120009&quot;&gt;comment&lt;/a&gt; below for more information on that and on how the QFT step is executed.]&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Quantum Factoring Impossible? &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;Now enter Jin-Yi. He has a new &lt;a href=&quot;https://pages.cs.wisc.edu/~jyc/Shor-Algorithm-with-Noise.pdf&quot;&gt;paper&lt;/a&gt; that says:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; We consider Shor&amp;#8217;s quantum factoring algorithm in the setting of noisy quantum gates. Under a generic model of random noise for rotation gates, we prove that the algorithm does not factor integers of the form &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bpq%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{pq}&quot; class=&quot;latex&quot; /&gt; when the noise exceeds a vanishingly small level in terms of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n}&quot; class=&quot;latex&quot; /&gt; (the number of bits of the integer to be factored), where &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{q}&quot; class=&quot;latex&quot; /&gt; are chosen from a set of primes of positive density. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Jin-Yi essentially is saying that quantum algorithms fail to break RSA in the presence of noisy gates. He argues that they will &lt;b&gt;not&lt;/b&gt; be able to work when quantum gates are not perfect. &lt;/p&gt;
&lt;p&gt;
&lt;i&gt;This seems to contradict the previous section.&lt;/i&gt; Can it be that quantum algorithms break RSA in theory, but are not practically realizable? See these &lt;a href=&quot;https://usa.kaspersky.com/blog/quantum-computers-and-rsa-2023/27605/&quot;&gt;three&lt;/a&gt; &lt;a href=&quot;https://www.lawfareblog.com/retrospective-post-quantum-policy-problem&quot;&gt;recent&lt;/a&gt; &lt;a href=&quot;https://www.forbes.com/sites/forbestechcouncil/2022/08/08/rsas-quantum-proof-successor-may-not-be-safe-for-long/?sh=55c0555475ff&quot;&gt;discussions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
To our knowledge, this is the first hard-and-fast negative result about Shor&amp;#8217;s algorithm. Let&amp;#8217;s take a closer look.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Angles on Shor&amp;#8217;s Algorithm &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Given &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN+%3D+pq%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N = pq}&quot; class=&quot;latex&quot; /&gt; to factor, Shor&amp;#8217;s algorithm starts by choosing &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{a}&quot; class=&quot;latex&quot; /&gt; relatively prime to &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N}&quot; class=&quot;latex&quot; /&gt;. The algorithm extends the domain of the function &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%3D+a%5Ex+%5Cpmod%7BN%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{f(x) = a^x &amp;#92;pmod{N}}&quot; class=&quot;latex&quot; /&gt; to all &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bx+%3C+M%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{x &amp;lt; M}&quot; class=&quot;latex&quot; /&gt; where &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM+%3D+2%5Em%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M = 2^m}&quot; class=&quot;latex&quot; /&gt;, &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bm+%3D+2n%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{m = 2n}&quot; class=&quot;latex&quot; /&gt;, and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{2^n}&quot; class=&quot;latex&quot; /&gt; is the next power of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B2%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{2}&quot; class=&quot;latex&quot; /&gt; after &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N}&quot; class=&quot;latex&quot; /&gt;, so that &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BM+%5Capprox+N%5E2%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{M &amp;#92;approx N^2}&quot; class=&quot;latex&quot; /&gt;. The quantum engine of Shor&amp;#8217;s algorithm has just two main components:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
A routine that computes the quantum state &lt;/p&gt;
&lt;p align=center&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CPhi+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7BM%7D%7D%5Csum_x+%7Cx%5Crangle%7Cf%28x%29%5Crangle.+&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;&amp;#92;displaystyle  &amp;#92;Phi = &amp;#92;frac{1}{&amp;#92;sqrt{M}}&amp;#92;sum_x |x&amp;#92;rangle|f(x)&amp;#92;rangle. &quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Put another way without the Dirac angle-bracket notation, &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;Phi}&quot; class=&quot;latex&quot; /&gt; is a state of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bm%2Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{m+n}&quot; class=&quot;latex&quot; /&gt; qubits that has equal nonzero amplitude only on those components &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bxy%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{xy}&quot; class=&quot;latex&quot; /&gt; where &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7By+%3D+f%28x%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{y = f(x)}&quot; class=&quot;latex&quot; /&gt;. &lt;/p&gt;
&lt;li&gt;
The QFT (or its inverse) on &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{m}&quot; class=&quot;latex&quot; /&gt; qubits.
&lt;/ol&gt;
&lt;p&gt;
Quantum gates of the form &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_k+%3D+%5Cbegin%7Bbmatrix%7D+1+%26+0+%5C%5C+0+%26+%5Comega_k+%5Cend%7Bbmatrix%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_k = &amp;#92;begin{bmatrix} 1 &amp;amp; 0 &amp;#92;&amp;#92; 0 &amp;amp; &amp;#92;omega_k &amp;#92;end{bmatrix}}&quot; class=&quot;latex&quot; /&gt; where &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Comega_k+%3D+%5Cexp%28%5Cfrac%7B2%5Cpi+i%7D%7B2%5Ek%7D%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;omega_k = &amp;#92;exp(&amp;#92;frac{2&amp;#92;pi i}{2^k})}&quot; class=&quot;latex&quot; /&gt;, when &lt;em&gt;controlled&lt;/em&gt; from another qubit, are used in the &amp;#8220;textbook&amp;#8221; way to compute the QFT. The diagram with &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bm%3D4%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{m=4}&quot; class=&quot;latex&quot; /&gt; suffices for the general pattern:&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;/p&gt;
&lt;table style=&quot;margin:auto;&quot;&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/qft4a/&quot; rel=&quot;attachment wp-att-21765&quot;&gt;&lt;img data-attachment-id=&quot;21765&quot; data-permalink=&quot;https://rjlipton.wpcomstaging.com/2023/06/14/a-little-noise-makes-quantum-factoring-fail/qft4a/&quot; data-orig-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/QFT4A.jpg?fit=666%2C178&amp;amp;ssl=1&quot; data-orig-size=&quot;666,178&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;KWRegan&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;1686570454&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;1&amp;quot;}&quot; data-image-title=&quot;QFT4A&quot; data-image-description=&quot;&quot; data-image-caption=&quot;&quot; data-medium-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/QFT4A.jpg?fit=300%2C80&amp;amp;ssl=1&quot; data-large-file=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/QFT4A.jpg?fit=600%2C160&amp;amp;ssl=1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/QFT4A.jpg?resize=555%2C150&amp;#038;ssl=1&quot; alt=&quot;&quot; width=&quot;555&quot; height=&quot;150&quot; class=&quot;aligncenter wp-image-21765&quot; data-recalc-dims=&quot;1&quot; /&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;caption alignright&quot;&gt;&lt;FONT size=&quot;-2&quot;&gt;&lt;a href=&quot;http://math.utoledo.edu/~codenth/Spring_15/4350/HW/fourier.pdf&quot;&gt;source&lt;/a&gt;&lt;/FONT&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;
For all but a few small values of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k}&quot; class=&quot;latex&quot; /&gt;, the rotation angle in &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_k}&quot; class=&quot;latex&quot; /&gt; is tinier than theoretical minimum units of space, let alone the smallest precision of angular or spatial resolution we have achieved in experiments such as LIGO. Call a circuit family using &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_k}&quot; class=&quot;latex&quot; /&gt; for unbounded &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k}&quot; class=&quot;latex&quot; /&gt; &amp;#8220;idealistic.&amp;#8221; &lt;/p&gt;
&lt;p&gt;
Donald Coppersmith &lt;a href=&quot;https://arxiv.org/abs/quant-ph/0201067&quot;&gt;showed&lt;/a&gt; that Shor&amp;#8217;s algorithm still works if &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_k}&quot; class=&quot;latex&quot; /&gt; is replaced by the identity operator for &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk+%3E+b%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k &amp;gt; b}&quot; class=&quot;latex&quot; /&gt;, where the threshold &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{b}&quot; class=&quot;latex&quot; /&gt; equals &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bc%5Clog_2+n%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{c&amp;#92;log_2 n}&quot; class=&quot;latex&quot; /&gt; for a constant &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{c}&quot; class=&quot;latex&quot; /&gt; slightly above &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B1%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{1}&quot; class=&quot;latex&quot; /&gt;. The resulting circuits are still &amp;#8220;idealistic&amp;#8221; but at least not exponentially so. Coppersmith&amp;#8217;s analysis is referenced in Shor&amp;#8217;s original &lt;a href=&quot;https://arxiv.org/abs/quant-ph/9508027&quot;&gt;paper&lt;/a&gt; but not expounded further there.&lt;/p&gt;
&lt;p&gt;
Jin-Yi shows that Shor&amp;#8217;s and Coppersmith&amp;#8217;s circuits cannot tolerate a natural kind of noise that operates close to Coppersmith&amp;#8217;s level of scaling. It stands concretely against any asymptotic claims of power via Shor&amp;#8217;s algorithm that involve idealistic circuits. At the end we will discuss its implications also for circuits that implement Shor&amp;#8217;s algorithm without using &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_k}&quot; class=&quot;latex&quot; /&gt; gates.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; The Noise &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
Call &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BC%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{C}&quot; class=&quot;latex&quot; /&gt; a &lt;em&gt;Shor circuit&lt;/em&gt; if it uses controlled &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_k}&quot; class=&quot;latex&quot; /&gt; gates to compute the QFT (or its inverse) and can be sampled by a classical procedure &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+A%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{{&amp;#92;cal A}}&quot; class=&quot;latex&quot; /&gt; to infer the period &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;rho}&quot; class=&quot;latex&quot; /&gt; of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%3D+a%5Ex+%5Cpmod%7BN%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{f(x) = a^x &amp;#92;pmod{N}}&quot; class=&quot;latex&quot; /&gt; in &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn%5E%7BO%281%29%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n^{O(1)}}&quot; class=&quot;latex&quot; /&gt; expected time. &lt;/p&gt;
&lt;p&gt;
Jin-Yi&amp;#8217;s noise operation has parameters &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;epsilon}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bb%27%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{b&amp;#039;}&quot; class=&quot;latex&quot; /&gt; and maps a Shor circuit &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BC%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{C}&quot; class=&quot;latex&quot; /&gt; to a distribution of circuits &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BC%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;tilde{C}}&quot; class=&quot;latex&quot; /&gt; defined as follows: For each controlled &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_k}&quot; class=&quot;latex&quot; /&gt; gate in &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BC%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{C}&quot; class=&quot;latex&quot; /&gt; with &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+b%27%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k &amp;#92;geq b&amp;#039;}&quot; class=&quot;latex&quot; /&gt; (alternatively, &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk+%3D+b%27%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k = b&amp;#039;}&quot; class=&quot;latex&quot; /&gt;), replace it by &lt;/p&gt;
&lt;p align=center&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctilde%7BR_k%7D+%3D+%5Cbegin%7Bbmatrix%7D+1+%26+0+%5C%5C+0+%26+%5Ctilde%7B%5Comega%7D+%5Cend%7Bbmatrix%7D%5Cquad%5Ctext%7Bwhere%7D%5Cquad+%5Ctilde%7B%5Comega%7D+%3D+%5Cexp%5Cleft%28%5Cfrac%7B2%5Cpi+i%281+%2B+r%5Cepsilon%29%7D%7B2%5Ek%7D%5Cright%29+&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;&amp;#92;displaystyle  &amp;#92;tilde{R_k} = &amp;#92;begin{bmatrix} 1 &amp;amp; 0 &amp;#92;&amp;#92; 0 &amp;amp; &amp;#92;tilde{&amp;#92;omega} &amp;#92;end{bmatrix}&amp;#92;quad&amp;#92;text{where}&amp;#92;quad &amp;#92;tilde{&amp;#92;omega} = &amp;#92;exp&amp;#92;left(&amp;#92;frac{2&amp;#92;pi i(1 + r&amp;#92;epsilon)}{2^k}&amp;#92;right) &quot; class=&quot;latex&quot; /&gt;&lt;/p&gt;
&lt;p&gt;with the same control qubit and with an independent draw of Gaussian noise &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Br+%5Csim+%7B%5Ccal+N%7D%280%2C1%29%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{r &amp;#92;sim {&amp;#92;cal N}(0,1)}&quot; class=&quot;latex&quot; /&gt;. The echo of Coppersmith&amp;#8217;s &amp;#8220;&lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{b}&quot; class=&quot;latex&quot; /&gt;&amp;#8221; is on purpose, because he establishes the following fact, which we first state loosely:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; Provided &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bb%27+%2B+%5Clog_2%281%2F%5Cepsilon%29+%5Csim+%5Cfrac%7B1%7D%7B3%7D%28%5Clog_2+n%29%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{b&amp;#039; + &amp;#92;log_2(1/&amp;#92;epsilon) &amp;#92;sim &amp;#92;frac{1}{3}(&amp;#92;log_2 n)}&quot; class=&quot;latex&quot; /&gt;, the circuits &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BC%7D%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;tilde{C}}&quot; class=&quot;latex&quot; /&gt; lose the Shor property, meaning that &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+A%7D%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{{&amp;#92;cal A}}&quot; class=&quot;latex&quot; /&gt; sampling &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BC%7D%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;tilde{C}}&quot; class=&quot;latex&quot; /&gt; cannot find &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;rho}&quot; class=&quot;latex&quot; /&gt;. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
This says that the noise range brushes against the Coppersmith upper bound for the precision needed to implement Shor&amp;#8217;s algorithm. Since &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k}&quot; class=&quot;latex&quot; /&gt; is exponentiated, one can say that noise on the order of the cube of the precision needed for Shor&amp;#8217;s algorithm is enough to destroy it. &lt;/p&gt;
&lt;p&gt;
The estimates in the paper allow replacing &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B3%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;frac{1}{3}}&quot; class=&quot;latex&quot; /&gt; by &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%2B%5Cdelta%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;frac{1}{2+&amp;#92;delta}}&quot; class=&quot;latex&quot; /&gt; with greater attention to additive constants, so lower noise approaching the square root of the Coppersmith precision suffices to destroy the Shor property. This may be improvable to almost linear. Exactly what does the noise attack? That&amp;#8217;s next.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Long Periods &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
The noise most strongly affects cases &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN+%3D+pq%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N = pq}&quot; class=&quot;latex&quot; /&gt; where &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp-1%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p-1}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bq-1%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{q-1}&quot; class=&quot;latex&quot; /&gt; have a large prime factor. The most extreme such case is &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bp+-+1%7D%7B2%7D+%3D+p%27%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;frac{p - 1}{2} = p&amp;#039;}&quot; class=&quot;latex&quot; /&gt; being prime. Then &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp%27%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p&amp;#039;}&quot; class=&quot;latex&quot; /&gt; is called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Safe_and_Sophie_Germain_primes&quot;&gt;Sophie Germain prime&lt;/a&gt;. Ironically, &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp+%3D+2p%27%2B1%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p = 2p&amp;#039;+1}&quot; class=&quot;latex&quot; /&gt; is called a &amp;#8220;safe prime&amp;#8221; but those are the most unsafe under Jin-Yi&amp;#8217;s noise.&lt;/p&gt;
&lt;p&gt;
It remains unknown whether infinitely many Sophie Germain primes exist, despite the quest &lt;a href=&quot;https://en.wikipedia.org/wiki/Proof_(play)&quot;&gt;winning&lt;/a&gt; a Tony Award and Pulitzer Prize. But a less-heralded property suffices. &amp;Eacute;tienne Fouvry &lt;a href=&quot;https://eudml.org/doc/143202&quot;&gt;proved&lt;/a&gt; in 1985 that the set of primes &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p}&quot; class=&quot;latex&quot; /&gt; for which &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp+-+1%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p - 1}&quot; class=&quot;latex&quot; /&gt; has a factor &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp%27+%3E+p%5E%7B2%2F3%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p&amp;#039; &amp;gt; p^{2/3}}&quot; class=&quot;latex&quot; /&gt; is not only infinite, but has positive density in the set of primes. It follows that cases &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN+%3D+pq%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N = pq}&quot; class=&quot;latex&quot; /&gt; where both &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{q}&quot; class=&quot;latex&quot; /&gt; have this &amp;#8220;Fouvry property&amp;#8221; have positive density among products of two primes. There can be only one prime factor &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp%27+%3E+p%5E%7B2%2F3%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p&amp;#039; &amp;gt; p^{2/3}}&quot; class=&quot;latex&quot; /&gt;, likewise &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bq%27+%3E+q%5E%7B2%2F3%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{q&amp;#039; &amp;gt; q^{2/3}}&quot; class=&quot;latex&quot; /&gt;. &lt;/p&gt;
&lt;p&gt;
The upshot for such &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{q}&quot; class=&quot;latex&quot; /&gt; is that most &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{a}&quot; class=&quot;latex&quot; /&gt; have exponentially long periods &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;rho}&quot; class=&quot;latex&quot; /&gt; modulo &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N}&quot; class=&quot;latex&quot; /&gt;. The geometric sums that concentrate amplitudes on multiples of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;rho}&quot; class=&quot;latex&quot; /&gt; in the ideal situation, when the circuit is sampled via quantum measurement, have norm-squared proportional to &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;rho}&quot; class=&quot;latex&quot; /&gt;. In the noisy situation, such length maximizes the perturbative effect of the noise so as to level out the amplitude. This destroys the ability to infer &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;rho}&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;
We cut a few corners in the statements of Jin-Yi&amp;#8217;s theorems, but they are reasonably close and the paper has full details. They hold also under the &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk+%3D+b%27%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k = b&amp;#039;}&quot; class=&quot;latex&quot; /&gt; variant and with-or-without removing controlled &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_k%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_k}&quot; class=&quot;latex&quot; /&gt; gates for &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bk+%3E+b%27%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{k &amp;gt; b&amp;#039;}&quot; class=&quot;latex&quot; /&gt;.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt;Theorem 1&lt;/b&gt; &lt;em&gt;&lt;a name=&quot;Fouvry&quot;&gt;&lt;/a&gt; Asymptotically as &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n &amp;#92;rightarrow &amp;#92;infty}&quot; class=&quot;latex&quot; /&gt;, if &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN+%3D+pq%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N = pq}&quot; class=&quot;latex&quot; /&gt; is an &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n}&quot; class=&quot;latex&quot; /&gt;-bit product of two Fouvry primes, and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bb%27+%2B+%5Clog%281%2F%5Cepsilon%29+%3C+%5Cfrac%7B1%7D%7B3%7D%5Clog_2+n+-+%5CTheta%281%29%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{b&amp;#039; + &amp;#92;log(1/&amp;#92;epsilon) &amp;lt; &amp;#92;frac{1}{3}&amp;#92;log_2 n - &amp;#92;Theta(1)}&quot; class=&quot;latex&quot; /&gt;, then the probability that &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+A%7D%28%5Ctilde%7BC%7D%29%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{{&amp;#92;cal A}(&amp;#92;tilde{C})}&quot; class=&quot;latex&quot; /&gt; infers &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;rho}&quot; class=&quot;latex&quot; /&gt; is exponentially small. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt;Theorem 2&lt;/b&gt; &lt;em&gt;&lt;a name=&quot;random&quot;&gt;&lt;/a&gt; Asymptotically as &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n &amp;#92;rightarrow &amp;#92;infty}&quot; class=&quot;latex&quot; /&gt;, for all but a vanishing fraction of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n}&quot; class=&quot;latex&quot; /&gt;-bit primes and with &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bb%27+%2B+%5Clog%281%2F%5Cepsilon%29+%3C+%5Cfrac%7B1%7D%7B3%7D%5Clog_2+n+-+%5CTheta%281%29%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{b&amp;#039; + &amp;#92;log(1/&amp;#92;epsilon) &amp;lt; &amp;#92;frac{1}{3}&amp;#92;log_2 n - &amp;#92;Theta(1)}&quot; class=&quot;latex&quot; /&gt;, the probability over &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{a}&quot; class=&quot;latex&quot; /&gt; and noisy &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BC%7D%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;tilde{C}}&quot; class=&quot;latex&quot; /&gt; that &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+A%7D%28%5Ctilde%7BC%7D%29%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{{&amp;#92;cal A}(&amp;#92;tilde{C})}&quot; class=&quot;latex&quot; /&gt; infers &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;rho}&quot; class=&quot;latex&quot; /&gt; is exponentially small. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Theorem &lt;a href=&quot;#random&quot;&gt;2&lt;/a&gt;, whose proof is in the paper&amp;#8217;s appendix, says that Shor&amp;#8217;s algorithm fails to survive the noise in all but a vanishing fraction of instances. It applies also under certain restrictions of the primes, such as &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{p}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{q}&quot; class=&quot;latex&quot; /&gt; both being congruent to 3 modulo 4. Theorem &lt;a href=&quot;#Fouvry&quot;&gt;1&lt;/a&gt; gives a substantial explicit set of cases &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BN+%3D+pq%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{N = pq}&quot; class=&quot;latex&quot; /&gt; on which the algorithm fails.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; How General Is This? &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
The theorems are carefully stated in terms of the period-inferencing component of Shor&amp;#8217;s algorithm. And they are asymptotic. They do not rule out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
possible quantum improvements on input sizes in the finite range of conceivable practical crypto; &lt;/p&gt;
&lt;li&gt;
quantum circuits &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BD%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{D}&quot; class=&quot;latex&quot; /&gt; that might factor by other means; nor &lt;/p&gt;
&lt;li&gt;
that error correction might restore the Shor property.
&lt;/ul&gt;
&lt;p&gt;
In particular, they do not define a general-purpose noise model that could apply to any quantum circuit &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BD%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{D}&quot; class=&quot;latex&quot; /&gt;. &lt;/p&gt;
&lt;p&gt;
Now we discuss two means to implement Shor&amp;#8217;s algorithm without using gates beyond &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BR_3%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{R_3}&quot; class=&quot;latex&quot; /&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
The Hadamard gate &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BH%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{H}&quot; class=&quot;latex&quot; /&gt;, the controlled-not gate CNOT, and the gate &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BT+%3D+R_3%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{T = R_3}&quot; class=&quot;latex&quot; /&gt; form a &lt;em&gt;complete set&lt;/em&gt; that (by the Solovay-Kitaev &lt;a href=&quot;https://en.wikipedia.org/wiki/Solovay-Kitaev_theorem&quot;&gt;theorem&lt;/a&gt;) can feasibly approximate the state produced by any feasible quantum circuit plus QFT. Then the minimum angle of any individual operation is &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F8%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;pi/8}&quot; class=&quot;latex&quot; /&gt;. &lt;/p&gt;
&lt;li&gt;
The Hadamard and &lt;a href=&quot;https://en.wikipedia.org/wiki/Toffoli_gate&quot;&gt;Toffoli&lt;/a&gt; gates form a universal set in the weaker sense of encoding real and imaginary parts of quantum amplitudes separately. This suffices to compute the factoring function via polynomial-size circuits using only real entries.
&lt;/ol&gt;
&lt;p&gt;
Idea 1 may only mask the issue, insofar as the resulting circuits must still approximate angles down to Coppersmith&amp;#8217;s unboundedly small magnitude &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B2%5E%7B-b%7D%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{2^{-b}}&quot; class=&quot;latex&quot; /&gt;. Both &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BH%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{H}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BT%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{T}&quot; class=&quot;latex&quot; /&gt; are rotations of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Bloch_sphere&quot;&gt;Bloch sphere&lt;/a&gt; of periods 2 and 8, respectively. As such, each may be exactly physically realizable, along with their controlled versions and CNOT in higher-dimensional Bloch spheres. &lt;/p&gt;
&lt;p&gt;
However, &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BH%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{H}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BT%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{T}&quot; class=&quot;latex&quot; /&gt; together generate an infinite subgroup of SU(2). The group has members that rotate through arbitrarily small angles. Jin-Yi says in his speculative concluding section:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;b&gt; &lt;/b&gt; &lt;em&gt; It is true that using a fixed finite set of rotations of reasonable angles such as &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F8%7D&amp;#038;bg=e8e8e8&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;pi/8}&quot; class=&quot;latex&quot; /&gt; along various axes &lt;b&gt;can&lt;/b&gt; compose to rotations of arbitrarily small angles. But my view is just that these compositional rules as specified by the group SU(2) must not be exact for physical reality. &lt;/em&gt;
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;p&gt;
Most in particular, let &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BA+%3D+HT%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{A = HT}&quot; class=&quot;latex&quot; /&gt;. If &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BA%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{A}&quot; class=&quot;latex&quot; /&gt; can be exactly realized, then any power &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BAA%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{AA}&quot; class=&quot;latex&quot; /&gt;, &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BAAA%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{AAA}&quot; class=&quot;latex&quot; /&gt;, &amp;#8230; should be. But the angle of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7BA%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{A}&quot; class=&quot;latex&quot; /&gt; is not a rational multiple of &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;pi}&quot; class=&quot;latex&quot; /&gt;, so the powers alone form an infinite state space and include arbitrarily tiny rotations. Please see Jin-Yi&amp;#8217;s &lt;a href=&quot;https://pages.cs.wisc.edu/~jyc/Shor-Algorithm-with-Noise.pdf&quot;&gt;paper&lt;/a&gt; for other context and justifications on these points, plus related &lt;a href=&quot;https://spectrum.ieee.org/the-case-against-quantum-computing&quot;&gt;contentions&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/ftp/arxiv/papers/1401/1401.3629.pdf&quot;&gt;by&lt;/a&gt; Mikhail Dyakonov.&lt;/p&gt;
&lt;p&gt;
The circuits in idea 2 cannot approximate any (feasible) quantum state metrically, but they can emulate Shor&amp;#8217;s algorithm using only &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B0%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{0}&quot; class=&quot;latex&quot; /&gt; and &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{&amp;#92;pi}&quot; class=&quot;latex&quot; /&gt; as &amp;#8220;angles.&amp;#8221; They may, however, still involve quantum states with filigrees beyond physically realizable precision. In the coda to our own textbook, we speculate this already for the deterministic &amp;#8220;functional superposition&amp;#8221; component of Shor&amp;#8217;s algorithm.&lt;/p&gt;
&lt;p&gt;
All this and more was discussed already twenty-plus years ago in the &amp;#8220;&lt;a href=&quot;http://www.scottaaronson.com/papers/mlinsiam.pdf&quot;&gt;Sure/Shor&lt;/a&gt; &lt;a href=&quot;https://www.scottaaronson.com/democritus/lec14.html&quot;&gt;separator&lt;/a&gt;&amp;#8221; &lt;a href=&quot;https://scottaaronson.blog/?p=124&quot;&gt;debate&lt;/a&gt;. The difference now is having Jin-Yi&amp;#8217;s new work as a linchpin for the skeptical side. Non-robustness to noise in the &amp;#8220;Coppersmith range&amp;#8221; may be a wider phenomenon than his current results show.&lt;/p&gt;
&lt;p&gt;
In his last paragraph, Jin-Yi argues that quantum computing makes a fundamental departure from Alan Turing&amp;#8217;s condition that primitive steps are finite and fixed independent of the data size &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n}&quot; class=&quot;latex&quot; /&gt;. He mentions the free use of SU(2) but his point may apply as well to the step of placing a Toffoli gate anywhere in an &lt;img decoding=&quot;async&quot; src=&quot;https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;#038;bg=ffffff&amp;#038;fg=000000&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;{n}&quot; class=&quot;latex&quot; /&gt;-qubit quantum circuit. This point is separate from issues of noise models, about which we have heard much from Gil Kalai including &lt;a href=&quot;https://rjlipton.wpcomstaging.com/2023/02/11/are-we-nuts/&quot;&gt;recently&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;H2&gt; Open Problems &lt;/H2&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
The issue is simple: Can quantum algorithms be made to work in the presence of gates that are making errors at Jin-Yi&amp;#8217;s scaling? The obvious interesting open question is: As in classical computation, can we build circuits that can handle errors? See &lt;a href=&quot;https://e3s-center.berkeley.edu/wp-content/uploads/2017/07/PEB2012_12_TSzkopek_Webfinal.pdf&quot;&gt;this&lt;/a&gt; and &lt;a href=&quot;https://cosmosmagazine.com/technology/error-free-quantum-computer/&quot;&gt;this&lt;/a&gt; on error-free computation. &lt;/p&gt;
&lt;p&gt;
This seems to be a wonderful question. Will the new results reshape debates on quantum computing and the polynomial Church-Turing thesis, or are they subsumed in &lt;a href=&quot;https://windowsontheory.org/2017/10/30/the-different-forms-of-quantum-computing-skepticism/&quot;&gt;matters&lt;/a&gt; &lt;a href=&quot;https://cacm.acm.org/magazines/2019/5/236426-quantum-hype-and-quantum-skepticism/fulltext?mobile=false&quot;&gt;already&lt;/a&gt; &lt;a href=&quot;https://unfashionable.blog/p/quantum&quot;&gt;recently&lt;/a&gt; &lt;a href=&quot;https://www.technologyreview.com/2022/03/28/1048355/quantum-computing-has-a-hype-problem/&quot;&gt;much&lt;/a&gt; &lt;a href=&quot;https://www.hpcwire.com/2023/05/02/microsoft-eth-take-aim-at-quantum-computings-hype-and-promise/&quot;&gt;discussed&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;&lt;P&gt;&lt;br /&gt;
[added update about Gidney-Eker&amp;aring; paper in third section]&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By RJLipton+KWRegan&lt;/p&gt;
  </description>
  <pubDate>2023-06-14 04:16:28 UTC</pubDate>
  <author>Richard Lipton</author>
</item>

<item>
  <title>Invertible Bloom Lookup Tables with Less Memory and Less Randomness</title>
  <guid>http://arxiv.org/abs/2306.07583</guid>
  <link>http://arxiv.org/abs/2306.07583</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fleischhacker_N/0/1/0/all/0/1&quot;&gt;Nils Fleischhacker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1&quot;&gt;Kasper Green Larsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obremski_M/0/1/0/all/0/1&quot;&gt;Maciej Obremski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simkin_M/0/1/0/all/0/1&quot;&gt;Mark Simkin&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this work we study Invertible Bloom Lookup Tables (IBLTs) with small
failure probabilities. IBLTs are highly versatile data structures that have
found applications in set reconciliation protocols, error-correcting codes, and
even the design of advanced cryptographic primitives. For storing $n$ elements
and ensuring correctness with probability at least $1 - \delta$, existing IBLT
constructions require $\Omega(n(\frac{\log(1/\delta)}{\log(n)}+1))$ space and
they crucially rely on fully random hash functions.
&lt;/p&gt;
&lt;p&gt;We present new constructions of IBLTs that are simultaneously more space
efficient and require less randomness. For storing $n$ elements with a failure
probability of at most $\delta$, our data structure only requires
$\mathcal{O}(n + \log(1/\delta)\log\log(1/\delta))$ space and
$\mathcal{O}(\log(\log(n)/\delta))$-wise independent hash functions.
&lt;/p&gt;
&lt;p&gt;As a key technical ingredient we show that hashing $n$ keys with any $k$-wise
independent hash function $h:U \to [Cn]$ for some sufficiently large constant
$C$ guarantees with probability $1 - 2^{-\Omega(k)}$ that at least $n/2$ keys
will have a unique hash value. Proving this is highly non-trivial as $k$
approaches $n$. We believe that the techniques used to prove this statement may
be of independent interest.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Differentially Private One Permutation Hashing and Bin-wise Consistent Weighted Sampling</title>
  <guid>http://arxiv.org/abs/2306.07674</guid>
  <link>http://arxiv.org/abs/2306.07674</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoyun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Ping Li&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Minwise hashing (MinHash) is a standard algorithm widely used in the
industry, for large-scale search and learning applications with the binary
(0/1) Jaccard similarity. One common use of MinHash is for processing massive
n-gram text representations so that practitioners do not have to materialize
the original data (which would be prohibitive). Another popular use of MinHash
is for building hash tables to enable sub-linear time approximate near neighbor
(ANN) search. MinHash has also been used as a tool for building large-scale
machine learning systems. The standard implementation of MinHash requires
applying $K$ random permutations. In comparison, the method of one permutation
hashing (OPH), is an efficient alternative of MinHash which splits the data
vectors into $K$ bins and generates hash values within each bin. OPH is
substantially more efficient and also more convenient to use.
&lt;/p&gt;
&lt;p&gt;In this paper, we combine the differential privacy (DP) with OPH (as well as
MinHash), to propose the DP-OPH framework with three variants: DP-OPH-fix,
DP-OPH-re and DP-OPH-rand, depending on which densification strategy is adopted
to deal with empty bins in OPH. A detailed roadmap to the algorithm design is
presented along with the privacy analysis. An analytical comparison of our
proposed DP-OPH methods with the DP minwise hashing (DP-MH) is provided to
justify the advantage of DP-OPH. Experiments on similarity search confirm the
merits of DP-OPH, and guide the choice of the proper variant in different
practical scenarios. Our technique is also extended to bin-wise consistent
weighted sampling (BCWS) to develop a new DP algorithm called DP-BCWS for
non-binary data. Experiments on classification tasks demonstrate that DP-BCWS
is able to achieve excellent utility at around $\epsilon = 5\sim 10$, where
$\epsilon$ is the standard parameter in the language of $(\epsilon,
\delta)$-DP.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Expanding the Scope of DAWN: A Novel Version for Weighted Shortest Path Problem</title>
  <guid>http://arxiv.org/abs/2306.07872</guid>
  <link>http://arxiv.org/abs/2306.07872</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yelai Feng&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The shortest path problem is a typical problem in graph theory with wide
potential applications. The state-of-the-art single-source shortest paths
algorithm on the weight graph is the $\Delta$-stepping algorithm, which can
efficiently process weighted graphs in parallel. DAWN is an algorithm that
addresses the shortest path problem on unweighted graphs, and we propose a
weighted version that can handle graphs with weights edges, while maintaining
the high scalability and parallelism features as DAWN. The novel version
requires $O(\mu m)$ and $O(\mu \cdot E_{wcc})$ times on the connected and
unconnected graphs for SSSP problems, respectively. $E_{wcc}$ denote the number
of edges included in the largest weakly connected component, and $\mu$ is a
constant denoting the average number of path transformations in the tasks. We
tested the weighted version on the real graphs from Stanford Network Analysis
Platform and SuiteSparse Matrix Collection, which outperformed the solution of
$\Delta$-stepping algorithm from Gunrock, achieving a speedup of
43.163$\times$.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Continual Release of Differentially Private Synthetic Data</title>
  <guid>http://arxiv.org/abs/2306.07884</guid>
  <link>http://arxiv.org/abs/2306.07884</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bun_M/0/1/0/all/0/1&quot;&gt;Mark Bun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaboardi_M/0/1/0/all/0/1&quot;&gt;Marco Gaboardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neunhoeffer_M/0/1/0/all/0/1&quot;&gt;Marcel Neunhoeffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wanrong Zhang&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Motivated by privacy concerns in long-term longitudinal studies in medical
and social science research, we study the problem of continually releasing
differentially private synthetic data. We introduce a model where, in every
time step, each individual reports a new data element, and the goal of the
synthesizer is to incrementally update a synthetic dataset to capture a rich
class of statistical properties. We give continual synthetic data generation
algorithms that preserve two basic types of queries: fixed time window queries
and cumulative time queries. We show nearly tight upper bounds on the error
rates of these algorithms and demonstrate their empirical performance on
realistically sized datasets from the U.S. Census Bureau&#39;s Survey of Income and
Program Participation.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Online Matching in Geometric Random Graphs</title>
  <guid>http://arxiv.org/abs/2306.07891</guid>
  <link>http://arxiv.org/abs/2306.07891</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sentenac_F/0/1/0/all/0/1&quot;&gt;Flore Sentenac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Noiry_N/0/1/0/all/0/1&quot;&gt;Nathan Noiry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lerasle_M/0/1/0/all/0/1&quot;&gt;Matthieu Lerasle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menard_L/0/1/0/all/0/1&quot;&gt;Laurent M&amp;#xe9;nard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1&quot;&gt;Vianney Perchet&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In online advertisement, ad campaigns are sequentially displayed to users.
Both users and campaigns have inherent features, and the former is eligible to
the latter if they are ``similar enough&#39;&#39;. We model these interactions as a
bipartite geometric random graph: the features of the $2N$ vertices ($N$ users
and $N$ campaigns) are drawn independently in a metric space and an edge is
present between a campaign and a user node if the distance between their
features is smaller than $c/N$, where $c&amp;gt;0$ is the parameter of the model. Our
contributions are two-fold. In the one-dimensional case, with uniform
distribution over the segment $[0,1]$, we derive the size of the optimal
offline matching in these bipartite random geometric graphs, and we build an
algorithm achieving it (as a benchmark), and analyze precisely its performance.
We then turn to the online setting where one side of the graph is known at the
beginning while the other part is revealed sequentially. We study the number of
matches of the online algorithm closest, which matches any incoming point to
its closest available neighbor. We show that its performances can be compared
to its fluid limit, completely described as the solution of an explicit PDE.
From the latter, we can compute the competitive ratio of closest.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Robustly Learning a Single Neuron via Sharpness</title>
  <guid>http://arxiv.org/abs/2306.07892</guid>
  <link>http://arxiv.org/abs/2306.07892</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Puqian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zarifis_N/0/1/0/all/0/1&quot;&gt;Nikos Zarifis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1&quot;&gt;Ilias Diakonikolas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diakonikolas_J/0/1/0/all/0/1&quot;&gt;Jelena Diakonikolas&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the problem of learning a single neuron with respect to the
$L_2^2$-loss in the presence of adversarial label noise. We give an efficient
algorithm that, for a broad family of activations including ReLUs, approximates
the optimal $L_2^2$-error within a constant factor. Our algorithm applies under
much milder distributional assumptions compared to prior work. The key
ingredient enabling our results is a novel connection to local error bounds
from optimization theory.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Reducing Exposure to Harmful Content via Graph Rewiring</title>
  <guid>http://arxiv.org/abs/2306.07930</guid>
  <link>http://arxiv.org/abs/2306.07930</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coupette_C/0/1/0/all/0/1&quot;&gt;Corinna Coupette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neumann_S/0/1/0/all/0/1&quot;&gt;Stefan Neumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gionis_A/0/1/0/all/0/1&quot;&gt;Aristides Gionis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Most media content consumed today is provided by digital platforms that
aggregate input from diverse sources, where access to information is mediated
by recommendation algorithms. One principal challenge in this context is
dealing with content that is considered harmful. Striking a balance between
competing stakeholder interests, rather than block harmful content altogether,
one approach is to minimize the exposure to such content that is induced
specifically by algorithmic recommendations. Hence, modeling media items and
recommendations as a directed graph, we study the problem of reducing the
exposure to harmful content via edge rewiring. We formalize this problem using
absorbing random walks, and prove that it is NP-hard and NP-hard to approximate
to within an additive error, while under realistic assumptions, the greedy
method yields a (1-1/e)-approximation. Thus, we introduce Gamine, a fast greedy
algorithm that can reduce the exposure to harmful content with or without
quality constraints on recommendations. By performing just 100 rewirings on
YouTube graphs with several hundred thousand edges, Gamine reduces the initial
exposure by 50%, while ensuring that its recommendations are at most 5% less
relevant than the original recommendations. Through extensive experiments on
synthetic data and real-world data from video recommendation and news feed
applications, we confirm the effectiveness, robustness, and efficiency of
Gamine in practice.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-14 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>PhD Student at Ruhr University of Bochum (apply by July 10, 2023)</title>
  <guid>http://cstheory-jobs.org/2023/06/12/phd-student-at-ruhr-university-of-bochum-apply-by-july-10-2023/</guid>
  <link>https://cstheory-jobs.org/2023/06/12/phd-student-at-ruhr-university-of-bochum-apply-by-july-10-2023/</link>
  <description>
    &lt;p&gt;We are inviting applications for a fully-funded PhD position at the Cluster of Excellence CASA. As the successful candidate, you will join the project &amp;#8220;Robust Certification of Quantum Devices&amp;#8221; and conduct fundamental research in the areas of:&lt;/p&gt;
&lt;p&gt;&amp;#8211; Nonlocal games and self-testing.&lt;br /&gt;
&amp;#8211; Quantum information and cryptography.&lt;br /&gt;
&amp;#8211; Group and representation theory.&lt;/p&gt;
&lt;p&gt;Language: English. Salary: E-13, 100%.&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://qi.ruhr-uni-bochum.de/hiring_casa&quot;&gt;https://qi.ruhr-uni-bochum.de/hiring_casa&lt;/a&gt;&lt;br /&gt;
Email: qi@rub.de&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 10:46:22 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Postdocs at Ruhr University Bochum (apply by July 10, 2023)</title>
  <guid>http://cstheory-jobs.org/2023/06/12/postdocs-at-ruhr-university-bochum-apply-by-july-10-2023/</guid>
  <link>https://cstheory-jobs.org/2023/06/12/postdocs-at-ruhr-university-bochum-apply-by-july-10-2023/</link>
  <description>
    &lt;p&gt;We are inviting applications for postdoc positions as part of the ERC project Symmetry and Optimization at the Frontiers of Computation (SYMOPTIC).&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://qi.rub.de/hiring_erc_pd&quot;&gt;https://qi.rub.de/hiring_erc_pd&lt;/a&gt;&lt;br /&gt;
Email: qi@rub.de&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 08:56:40 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>PhD at Ruhr University Bochum (apply by October 7, 2023)</title>
  <guid>http://cstheory-jobs.org/2023/06/12/phd-at-ruhr-university-bochum-apply-by-october-7-2023/</guid>
  <link>https://cstheory-jobs.org/2023/06/12/phd-at-ruhr-university-bochum-apply-by-october-7-2023/</link>
  <description>
    &lt;p&gt;We are inviting applications for fully-funded PhD positions as part of the ERC project Symmetry and Optimization at the Frontiers of Computation (SYMOPTIC).&lt;/p&gt;
&lt;p&gt;Website: &lt;a href=&quot;https://qi.rub.de/hiring_erc&quot;&gt;https://qi.rub.de/hiring_erc&lt;/a&gt;&lt;br /&gt;
Email: qi@rub.de&lt;/p&gt;
&lt;p class=&quot;authors&quot;&gt;By shacharlovett&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 08:52:55 UTC</pubDate>
  <author>CCI: jobs</author>
</item>

<item>
  <title>Complexity of Reachability Problems in Neural Networks</title>
  <guid>http://arxiv.org/abs/2306.05818</guid>
  <link>http://arxiv.org/abs/2306.05818</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wurm_A/0/1/0/all/0/1&quot;&gt;Adrian Wurm&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper we investigate formal verification problems for Neural Network
computations. Various reachability problems will be in the focus, such as:
Given symbolic specifications of allowed inputs and outputs in form of Linear
Programming instances, one question is whether valid inputs exist such that the
given network computes a valid output? Does this property hold for all valid
inputs? The former question&#39;s complexity has been investigated recently by
S\&quot;alzer and Lange for nets using the Rectified Linear Unit and the identity
function as their activation functions. We complement their achievements by
showing that the problem is NP-complete for piecewise linear functions with
rational coefficients that are not linear, NP-hard for almost all suitable
activation functions including non-linear ones that are continuous on an
interval, complete for the Existential Theory of the Reals $\exists \mathbb R$
for every non-linear polynomial and $\exists \mathbb R$-hard for the
exponential function and various sigmoidal functions. For the completeness
results, linking the verification tasks with the theory of Constraint
Satisfaction Problems turns out helpful.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>A dichotomy theorem for $\Gamma$-switchable $H$-colouring on $m$-edge coloured graphs</title>
  <guid>http://arxiv.org/abs/2306.05962</guid>
  <link>http://arxiv.org/abs/2306.05962</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Brewster_R/0/1/0/all/0/1&quot;&gt;Richard Brewster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kinder_A/0/1/0/all/0/1&quot;&gt;Arnott Kinder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+MacGillivray_G/0/1/0/all/0/1&quot;&gt;Gary MacGillivray&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $G$ be a graph in which each edge is assigned one of the colours $1, 2,
\ldots, m$, and let $\Gamma$ be a subgroup of $S_m$. The operation of switching
at a vertex $x$ of $G$ with respect to an element $\pi$ of $\Gamma$ permutes
the colours of the edges incident with $x$ according to $\pi$. We investigate
the complexity of whether there exists a sequence of switches that transforms a
given $m$-edge coloured graph $G$ so that it has a colour-preserving
homomorphism to a fixed $m$-edge coloured graph $H$ and give a dichotomy
theorem in the case that $\Gamma$ acts transitively.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Towards Universally Optimal Shortest Paths Algorithms in the Hybrid Model</title>
  <guid>http://arxiv.org/abs/2306.05977</guid>
  <link>http://arxiv.org/abs/2306.05977</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_P/0/1/0/all/0/1&quot;&gt;Philipp Schneider&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A drawback of the classic approach for complexity analysis of distributed
graph problems is that it mostly informs about the complexity of notorious
classes of ``worst case&#39;&#39; graphs. Algorithms that are used to prove a tight
(existential) bound are essentially optimized to perform well on such worst
case graphs. However, such graphs are often either unlikely or actively avoided
in practice, where benign graph instances usually admit much faster solutions.
&lt;/p&gt;
&lt;p&gt;To circumnavigate these drawbacks, the concept of universal complexity
analysis in the distributed setting was suggested by [Kutten and Peleg,
PODC&#39;95] and actively pursued by [Haeupler et al., STOC&#39;21]. Here, the aim is
to gauge the complexity of a distributed graph problem depending on the given
graph instance. The challenge is to identify and understand the graph property
that allows to accurately quantify the complexity of a distributed problem on a
given graph.
&lt;/p&gt;
&lt;p&gt;In the present work, we consider distributed shortest paths problems in the
HYBRID model of distributed computing, where nodes have simultaneous access to
two different modes of communication: one is restricted by locality and the
other is restricted by congestion. We identify the graph parameter of
neighborhood quality and show that it accurately describes a universal bound
for the complexity of certain class of shortest paths problems in the HYBRID
model.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Robust Topological Orderings for Directed Graphs</title>
  <guid>http://arxiv.org/abs/2306.05475</guid>
  <link>http://arxiv.org/abs/2306.05475</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1&quot;&gt;James Smith&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We modify the Pearce-Kelly algorithm that maintains a topological ordering
for a directed acyclic graph in order to allow cycles to be tolerated. Cycles
make topological orderings moot, of course, however tolerating them is useful
in practice. A user may mistakenly introduce a cyclic dependency in their
project,, for example, and then subsequently fix their mistake. In these cases
it is better to maintain the relevant data structures so that if and when the
directed graph becomes acyclic again, a topological ordering can be instantly
recovered. It turns out that adding this functionality costs us little, only
small modifications and some attention to detail are needed.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>An Improved Algorithm for Finding Maximum Outerplanar Subgraphs</title>
  <guid>http://arxiv.org/abs/2306.05588</guid>
  <link>http://arxiv.org/abs/2306.05588</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calinescu_G/0/1/0/all/0/1&quot;&gt;Gruia Calinescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaul_H/0/1/0/all/0/1&quot;&gt;Hemanshu Kaul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kudarzi_B/0/1/0/all/0/1&quot;&gt;Bahareh Kudarzi&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We study the NP-complete Maximum Outerplanar Subgraph problem. The previous
best known approximation ratio for this problem is 2/3. We propose a new
approximation algorithm which improves the ratio to 7/10.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Space-time Trade-offs for the LCP Array of Wheeler DFAs</title>
  <guid>http://arxiv.org/abs/2306.05684</guid>
  <link>http://arxiv.org/abs/2306.05684</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotumaccio_N/0/1/0/all/0/1&quot;&gt;Nicola Cotumaccio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1&quot;&gt;Travis Gagie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koppl_D/0/1/0/all/0/1&quot;&gt;Dominik K&amp;#xf6;ppl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1&quot;&gt;Nicola Prezza&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Recently, Conte et al. generalized the longest-common prefix (LCP) array from
strings to Wheeler DFAs, and they showed that it can be used to efficiently
determine matching statistics on a Wheeler DFA [DCC 2023]. However, storing the
LCP array requires $ O(n \log n) $ bits, $ n $ being the number of states,
while the compact representation of Wheeler DFAs often requires much less
space. In particular, the BOSS representation of a de Bruijn graph only
requires a linear number of bits, if the size of alphabet is constant.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a sampling technique that allows to access an entry
of the LCP array in logarithmic time by only storing a linear number of bits.
We use our technique to provide a space-time trade-off to compute matching
statistics on a Wheeler DFA. In addition, we show that by augmenting the BOSS
representation of a $ k $-th order de Bruijn graph with a linear number of bits
we can navigate the underlying variable-order de Bruijn graph in time
logarithmic in $ k $, thus improving a previous bound by Boucher et al. which
was linear in $ k $ [DCC 2015].
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework</title>
  <guid>http://arxiv.org/abs/2306.05734</guid>
  <link>http://arxiv.org/abs/2306.05734</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hua Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Sheng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huanyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1&quot;&gt;Weijie J. Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1&quot;&gt;Milan Shen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Hyperparameter optimization, also known as hyperparameter tuning, is a widely
recognized technique for improving model performance. Regrettably, when
training private ML models, many practitioners often overlook the privacy risks
associated with hyperparameter optimization, which could potentially expose
sensitive information about the underlying dataset. Currently, the sole
existing approach to allow privacy-preserving hyperparameter optimization is to
uniformly and randomly select hyperparameters for a number of runs,
subsequently reporting the best-performing hyperparameter. In contrast, in
non-private settings, practitioners commonly utilize &quot;adaptive&quot; hyperparameter
optimization methods such as Gaussian process-based optimization, which select
the next candidate based on information gathered from previous outputs. This
substantial contrast between private and non-private hyperparameter
optimization underscores a critical concern. In our paper, we introduce
DP-HyPO, a pioneering framework for &quot;adaptive&quot; private hyperparameter
optimization, aiming to bridge the gap between private and non-private
hyperparameter optimization. To accomplish this, we provide a comprehensive
differential privacy analysis of our framework. Furthermore, we empirically
demonstrate the effectiveness of DP-HyPO on a diverse set of real-world and
synthetic datasets.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Improved and Deterministic Online Service with Deadlines or Delay</title>
  <guid>http://arxiv.org/abs/2306.05744</guid>
  <link>http://arxiv.org/abs/2306.05744</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Touitou_N/0/1/0/all/0/1&quot;&gt;Noam Touitou&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider the problem of online service with delay on a general metric
space, first presented by Azar, Ganesh, Ge and Panigrahi (STOC 2017). The best
known randomized algorithm for this problem, by Azar and Touitou (FOCS 2019),
is $O(\log^2 n)$-competitive, where $n$ is the number of points in the metric
space. This is also the best known result for the special case of online
service with deadlines, which is of independent interest.
&lt;/p&gt;
&lt;p&gt;In this paper, we present $O(\log n)$-competitive deterministic algorithms
for online service with deadlines or delay, improving upon the results from
FOCS 2019. Furthermore, our algorithms are the first deterministic algorithms
for online service with deadlines or delay which apply to general metric spaces
and have sub-polynomial competitiveness.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Adaptivity Complexity for Causal Graph Discovery</title>
  <guid>http://arxiv.org/abs/2306.05781</guid>
  <link>http://arxiv.org/abs/2306.05781</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1&quot;&gt;Davin Choo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shiragur_K/0/1/0/all/0/1&quot;&gt;Kirankumar Shiragur&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Causal discovery from interventional data is an important problem, where the
task is to design an interventional strategy that learns the hidden ground
truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of
performed interventions. Most prior interventional strategies broadly fall into
two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a
single fixed set of interventions to be performed while adaptive strategies can
decide on which nodes to intervene on sequentially based on past interventions.
While adaptive algorithms may use exponentially fewer interventions than their
non-adaptive counterparts, there are practical concerns that constrain the
amount of adaptivity allowed. Motivated by this trade-off, we study the problem
of $r$-adaptivity, where the algorithm designer recovers the causal graph under
a total of $r$ sequential rounds whilst trying to minimize the total number of
interventions. For this problem, we provide a $r$-adaptive algorithm that
achieves $O(\min\{r,\log n\} \cdot n^{1/\min\{r,\log n\}})$ approximation with
respect to the verification number, a well-known lower bound for adaptive
algorithms. Furthermore, for every $r$, we show that our approximation is
tight. Our definition of $r$-adaptivity interpolates nicely between the
non-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our
approximation simplifies to $O(n)$ and $O(\log n)$ respectively, matching the
best-known approximation guarantees for both extremes. Our results also extend
naturally to the bounded size interventions.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Expectation-Complete Graph Representations with Homomorphisms</title>
  <guid>http://arxiv.org/abs/2306.05838</guid>
  <link>http://arxiv.org/abs/2306.05838</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welke_P/0/1/0/all/0/1&quot;&gt;Pascal Welke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiessen_M/0/1/0/all/0/1&quot;&gt;Maximilian Thiessen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jogl_F/0/1/0/all/0/1&quot;&gt;Fabian Jogl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gartner_T/0/1/0/all/0/1&quot;&gt;Thomas G&amp;#xe4;rtner&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We investigate novel random graph embeddings that can be computed in expected
polynomial time and that are able to distinguish all non-isomorphic graphs in
expectation. Previous graph embeddings have limited expressiveness and either
cannot distinguish all graphs or cannot be computed efficiently for every
graph. To be able to approximate arbitrary functions on graphs, we are
interested in efficient alternatives that become arbitrarily expressive with
increasing resources. Our approach is based on Lov\&#39;asz&#39; characterisation of
graph isomorphism through an infinite dimensional vector of homomorphism
counts. Our empirical evaluation shows competitive results on several benchmark
graph learning tasks.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Faster Discrete Convex Function Minimization with Predictions: The M-Convex Case</title>
  <guid>http://arxiv.org/abs/2306.05865</guid>
  <link>http://arxiv.org/abs/2306.05865</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oki_T/0/1/0/all/0/1&quot;&gt;Taihei Oki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sakaue_S/0/1/0/all/0/1&quot;&gt;Shinsaku Sakaue&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Recent years have seen a growing interest in accelerating optimization
algorithms with machine-learned predictions. Sakaue and Oki (NeurIPS 2022) have
developed a general framework that warm-starts the L-convex function
minimization method with predictions, revealing the idea&#39;s usefulness for
various discrete optimization problems. In this paper, we present a framework
for using predictions to accelerate M-convex function minimization, thus
complementing previous research and extending the range of discrete
optimization algorithms that can benefit from predictions. Our framework is
particularly effective for an important subclass called laminar convex
minimization, which appears in many operations research applications. Our
methods can improve time complexity bounds upon the best worst-case results by
using predictions and even have potential to go beyond a lower-bound result.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Differentially Private All-Pairs Shortest Distances for Low Tree-Width Graphs</title>
  <guid>http://arxiv.org/abs/2306.05916</guid>
  <link>http://arxiv.org/abs/2306.05916</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebrahimi_J/0/1/0/all/0/1&quot;&gt;Javad B. Ebrahimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammadi_A/0/1/0/all/0/1&quot;&gt;Alireza Tofighi Mohammadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kermani_F/0/1/0/all/0/1&quot;&gt;Fatemeh Kermani&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this paper, we present a polynomial time algorithm for the problem of
differentially private all pair shortest distances over the class of low
tree-width graphs. Our result generalizes the result of Sealfon 2016 for the
case of trees to a much larger family of graphs. Furthermore, if we restrict to
the class of low tree-width graphs, the additive error of our algorithm is
significantly smaller than that of the best known algorithm for this problem,
proposed by Chen et. al. 2023.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Optimal distance query reconstruction for graphs without long induced cycles</title>
  <guid>http://arxiv.org/abs/2306.05979</guid>
  <link>http://arxiv.org/abs/2306.05979</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastide_P/0/1/0/all/0/1&quot;&gt;Paul Bastide&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Groenland_C/0/1/0/all/0/1&quot;&gt;Carla Groenland&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let $G=(V,E)$ be an $n$-vertex connected graph of maximum degree $\Delta$.
Given access to $V$ and an oracle that given two vertices $u,v\in V$, returns
the shortest path distance between $u$ and $v$, how many queries are needed to
reconstruct $E$? We give a simple deterministic algorithm to reconstruct trees
using $\Delta n\log_\Delta n+(\Delta+2)n$ distance queries and show that even
randomised algorithms need to use at least $\frac1{100} \Delta n\log_\Delta n$
queries in expectation. The best previous lower bound was an
information-theoretic lower bound of $\Omega(n\log n/\log \log n)$. Our lower
bound also extends to related query models including distance queries for
phylogenetic trees, membership queries for learning partitions and path queries
in directed trees.
&lt;/p&gt;
&lt;p&gt;We extend our deterministic algorithm to reconstruct graphs without induced
cycles of length at least $k$ using $O_{\Delta,k}(n\log n)$ queries, which
includes various graph classes of interest such as chordal graphs, permutation
graphs and AT-free graphs. Since the previously best known randomised algorithm
for chordal graphs uses $O_{\Delta}(n\log^2 n)$ queries in expectation, we both
get rid off the randomness and get the optimal dependency in $n$ for chordal
graphs and various other graph classes.
&lt;/p&gt;
&lt;p&gt;Finally, we build on an algorithm of Kannan, Mathieu, and Zhou [ICALP, 2015]
to give a randomised algorithm for reconstructing graphs of treelength $k$
using $O_{\Delta,k}(n\log^2n)$ queries in expectation.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Fair Allocation with Binary Valuations for Mixed Divisible and Indivisible Goods</title>
  <guid>http://arxiv.org/abs/2306.05986</guid>
  <link>http://arxiv.org/abs/2306.05986</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawase_Y/0/1/0/all/0/1&quot;&gt;Yasushi Kawase&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nishimura_K/0/1/0/all/0/1&quot;&gt;Koichi Nishimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sumita_H/0/1/0/all/0/1&quot;&gt;Hanna Sumita&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The fair allocation of mixed goods, consisting of both divisible and
indivisible goods, among agents with heterogeneous preferences, has been a
prominent topic of study in economics and computer science. In this paper, we
investigate the nature of fair allocations when agents have binary valuations.
We define an allocation as fair if its utility vector minimizes a symmetric
strictly convex function, which includes conventional fairness criteria such as
maximum egalitarian social welfare and maximum Nash social welfare. While a
good structure is known for the continuous case (where only divisible goods
exist) or the discrete case (where only indivisible goods exist), deriving such
a structure in the hybrid case remains challenging. Our contributions are
twofold. First, we demonstrate that the hybrid case does not inherit some of
the nice properties of continuous or discrete cases, while it does inherit the
proximity theorem. Second, we analyze the computational complexity of finding a
fair allocation of mixed goods based on the proximity theorem. In particular,
we provide a polynomial-time algorithm for the case when all divisible goods
are identical and homogeneous, and demonstrate that the problem is NP-hard in
general. Our results also contribute to a deeper understanding of the hybrid
convex analysis.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Semi-online Scheduling with Lookahead</title>
  <guid>http://arxiv.org/abs/2306.06003</guid>
  <link>http://arxiv.org/abs/2306.06003</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dwibedy_D/0/1/0/all/0/1&quot;&gt;Debasis Dwibedy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohanty_R/0/1/0/all/0/1&quot;&gt;Rakesh Mohanty&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The knowledge of future partial information in the form of a lookahead to
design efficient online algorithms is a theoretically-efficient and realistic
approach to solving computational problems. Design and analysis of semi-online
algorithms with extra-piece-of-information (EPI) as a new input parameter has
gained the attention of the theoretical computer science community in the last
couple of decades. Though competitive analysis is a pessimistic worst-case
performance measure to analyze online algorithms, it has immense theoretical
value in developing the foundation and advancing the state-of-the-art
contributions in online and semi-online scheduling. In this paper, we study and
explore the impact of lookahead as an EPI in the context of online scheduling
in identical machine frameworks. We introduce a $k$-lookahead model and design
improved competitive semi-online algorithms. For a $2$-identical machine
setting, we prove a lower bound of $\frac{4}{3}$ and design an optimal
algorithm with a matching upper bound of $\frac{4}{3}$ on the competitive
ratio. For a $3$-identical machine setting, we show a lower bound of
$\frac{15}{11}$ and design a $\frac{16}{11}$-competitive improved semi-online
algorithm.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>Branching via Cutting Plane Selection: Improving Hybrid Branching</title>
  <guid>http://arxiv.org/abs/2306.06050</guid>
  <link>http://arxiv.org/abs/2306.06050</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Turner_M/0/1/0/all/0/1&quot;&gt;Mark Turner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Berthold_T/0/1/0/all/0/1&quot;&gt;Timo Berthold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Besancon_M/0/1/0/all/0/1&quot;&gt;Mathieu Besan&amp;#xe7;on&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Koch_T/0/1/0/all/0/1&quot;&gt;Thorsten Koch&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Cutting planes and branching are two of the most important algorithms for
solving mixed-integer linear programs. For both algorithms, disjunctions play
an important role, being used both as branching candidates and as the
foundation for some cutting planes. We relate branching decisions and cutting
planes to each other through the underlying disjunctions that they are based
on, with a focus on Gomory mixed-integer cuts and their corresponding split
disjunctions. We show that selecting branching decisions based on quality
measures of Gomory mixed-integer cuts leads to relatively small
branch-and-bound trees, and that the result improves when using cuts that more
accurately represent the branching decisions. Finally, we show how the history
of previously computed Gomory mixed-integer cuts can be used to improve the
performance of the state-of-the-art hybrid branching rule of SCIP. Our results
show a 4\% decrease in solve time, and an 8\% decrease in number of nodes over
affected instances of MIPLIB 2017.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-12 00:30:00 UTC</pubDate>
  <author>arXiv: Data Structures and Algorithms</author>
</item>

<item>
  <title>TR23-088 |  A High Dimensional Goldreich-Levin Theorem | 

	Silas Richelson, 

	Parker Newton, 

	Chase Wilson</title>
  <guid>https://eccc.weizmann.ac.il/report/2023/088</guid>
  <link>https://eccc.weizmann.ac.il/report/2023/088</link>
  <description>
    In this work we prove a high dimensional analogue of the beloved Goldreich-Levin theorem (STOC 1989).  We consider the following algorithmic problem: given oracle access to a function $f:\mathbb{Z}_q^m\rightarrow\mathbb{Z}_q^n$ such that ${\rm Prob}_{{\bf x}\sim\mathbb{Z}_q^m}\bigl[f({\bf x})={\bf Ax}\bigr]\geq\varepsilon$ for some ${\bf A}\in\mathbb{Z}_q^{n\times m}$ and $\varepsilon&amp;gt;0$, recover ${\bf A}$ (or a list of all such matrices).  We focus on the case $\varepsilon\leq1/q$ since when $\varepsilon\geq1/q+\delta$, the problem is solved by the original Goldreich-Levin theorem.  As stated, this problem cannot be efficiently solved, since when $\varepsilon\leq1/q$ the list of ${\bf A}$ with good agreement with $f$ might be exponentially large.  Our main theorem gives an algorithm which efficiently recovers a list of linear maps of size $\mathcal{O}\bigl(1/\varepsilon\bigr)$ which have good agreement with $f$, and such that every linear map which has good agreement with $f$, also has good agreement with some map in our list.  Our proof makes novel use of Fourier analysis.
  </description>
  <pubDate>2023-06-11 04:10:05 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>Posting a book online with a password- that you broadcast.</title>
  <guid>tag:blogger.com,1999:blog-3722233.post-1128876991296414088</guid>
  <link>https://blog.computationalcomplexity.org/2023/06/posting-book-online-with-password-that.html</link>
  <description>
    &lt;p&gt;&amp;nbsp;Recently Lance, at the request of&amp;nbsp; Vijay Vazirani, tweeted the following (I paraphrase)&lt;/p&gt;&lt;p&gt;---------------------------------------------------------------------------------------&lt;/p&gt;&lt;p&gt;Online and Matching-based Market Design book now available as free PDF&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.cambridge.org/files/9216/8487/6990/matching_book_pw.pdf&quot;&gt;cambridge.org/files/9216/848&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;The password is OMBMD_CUP&lt;/p&gt;&lt;p&gt;---------------------------------------------------------------------------------------------&lt;/p&gt;&lt;p&gt;This tweet raises two questions.&lt;/p&gt;&lt;p&gt;1) When a book is put online, does it cut into sales? I&#39;ve heard that people still like paper so the posting on line might be like an ad for the book. Also, for academic books, the authors WANT it to be out there and don&#39;t care so much about sales.&amp;nbsp; If Gasarch &amp;amp; Martin&#39;s &lt;i&gt;Bounded Queries in Recursion Theory &lt;/i&gt;was available for illegal download I would be delighted. And surprised.&amp;nbsp;&lt;/p&gt;&lt;p&gt;2) SO, they post it to make it more available and generate buzz. So why have a password? Was this a compromise:&amp;nbsp;&lt;/p&gt;&lt;p&gt;a) We want people to BUY the book so we&#39;ll post it with a password and limit access.&amp;nbsp;&lt;/p&gt;&lt;p&gt;b) We want people to SEE the book since as academics we don&#39;t care about sales, and it might generate buzz, so we don&#39;t want a password&lt;/p&gt;&lt;p&gt;c) COMPROMISE: Have a password but tell everyone what it is.&amp;nbsp;&lt;/p&gt;&lt;p&gt;If you can think of a more plausible scenario, leave a comment.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p class=&quot;authors&quot;&gt;By gasarch&lt;/p&gt;
  </description>
  <pubDate>2023-06-10 15:16:00 UTC</pubDate>
  <author>Computational Complexity</author>
</item>

<item>
  <title>TR23-087 |  How to Recover a Secret with $O(n)$ Additions | 

	Benny Applebaum, 

	Oded Nir, 

	Benny Pinkas</title>
  <guid>https://eccc.weizmann.ac.il/report/2023/087</guid>
  <link>https://eccc.weizmann.ac.il/report/2023/087</link>
  <description>
    Threshold cryptography is typically based on the idea of secret-sharing a private-key $s\in F$ ``in the exponent&amp;#39;&amp;#39; of some cryptographic group $G$, or more generally, encoding $s$ in some linearly homomorphic domain. In each invocation of the threshold system (e.g., for signing or decrypting) an ``encoding&amp;#39;&amp;#39; of the secret is being recovered and so the complexity, measured as the number of group multiplications over $G$, is equal to the number of $F$-additions that are needed to reconstruct the secret. Motivated by this scenario, we initiate the study of $n$-party secret-sharing schemes whose reconstruction algorithm makes a minimal number of \emph{additions}. The complexity of existing schemes either scales linearly with $n\log |F|$ (e.g., Shamir, CACM&amp;#39;79) or, at least, quadratically with $n$ independently of the size of the domain $F$ (e.g., Cramer-Xing, EUROCRYPT &amp;#39;20). This leaves open the existence of a secret sharing whose recovery algorithm can be computed by performing only $O(n)$ additions.

We resolve the question in the affirmative and present such a near-threshold secret sharing scheme that provides privacy against unauthorized sets of density at most $\tau_p$, and correctness for  authorized sets of density at least $\tau_c$, for any given arbitrarily close constants $\tau_p&amp;lt;\tau_c$. Reconstruction can be computed by making at most $O(n)$ additions and, in addition, (1) the share size is constant, (2) the sharing procedure also makes only $O(n)$ additions, and (3) the scheme is a blackbox secret-sharing scheme, i.e., the sharing and reconstruction algorithms work universally for all finite abelian groups $F$. Prior to our work, no such scheme was known even without features (1)--(3) and even for the ramp setting where $\tau_p$ and $\tau_c$ are far apart. As a by-product, we derive the first blackbox near-threshold secret-sharing scheme with linear-time sharing. We also present several concrete instantiations of our approach that seem practically efficient (e.g., for threshold discrete-log-based signatures).

Our constructions are combinatorial in nature. We combine graph-based erasure codes that support ``peeling-based&amp;#39;&amp;#39; decoding with a new randomness extraction method that is based on inner-product with a small-integer vector. We also introduce a general concatenation-like transform for secret-sharing schemes that allows us to arbitrarily shrink the privacy-correctness gap with a minor overhead. Our techniques enrich the secret-sharing toolbox and, in the context of blackbox secret sharing, provide a new alternative to existing number-theoretic approaches.
  </description>
  <pubDate>2023-06-09 13:12:55 UTC</pubDate>
  <author>ECCC Papers</author>
</item>

<item>
  <title>The asymptotics of r(4,t)</title>
  <guid>http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/</guid>
  <link>https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/</link>
  <description>
    &lt;div class=&quot;wpcom-reblog-snapshot&quot;&gt;&lt;div class=&quot;reblogger-note&quot;&gt;&lt;div class=&#39;reblogger-note-content&#39;&gt;&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://sammattheus.wordpress.com/&quot;&gt;&lt;img loading=&quot;lazy&quot; class=&quot;alignnone size-full wp-image-24567&quot; src=&quot;https://gilkalai.files.wordpress.com/2023/06/pal.png&quot; alt=&quot;pal&quot; width=&quot;955&quot; height=&quot;323&quot; srcset=&quot;https://gilkalai.files.wordpress.com/2023/06/pal.png 955w, https://gilkalai.files.wordpress.com/2023/06/pal.png?w=150&amp;amp;h=51 150w, https://gilkalai.files.wordpress.com/2023/06/pal.png?w=300&amp;amp;h=101 300w, https://gilkalai.files.wordpress.com/2023/06/pal.png?w=768&amp;amp;h=260 768w&quot; sizes=&quot;(max-width: 955px) 100vw, 955px&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;!-- wp:paragraph --&gt;&lt;/p&gt;
&lt;p&gt;Sam Mattheus wrote on his blog &amp;#8220;Points and Lines&amp;#8221; a summary with a general overview of the proof for his breakthrough with Jacques Verstraete about &lt;img src=&quot;https://s0.wp.com/latex.php?latex=r%284%2Ct%29&amp;#038;bg=ffffff&amp;#038;fg=333333&amp;#038;s=0&amp;#038;c=20201002&quot; alt=&quot;r(4,t)&quot; class=&quot;latex&quot; /&gt;. &lt;/p&gt;
&lt;p&gt;&lt;!-- /wp:paragraph --&gt;&lt;/p&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;reblog-post&quot;&gt;&lt;p class=&quot;reblog-from&quot;&gt;&lt;img alt=&#39;&#39; src=&#39;https://1.gravatar.com/avatar/46f67c6ee65d82a59f10b8438d0bdfb7676121b31aff9968cd1dfff4b11acaf7?s=32&amp;#038;d=identicon&amp;#038;r=PG&#39; class=&#39;avatar avatar-32&#39; height=&#39;32&#39; width=&#39;32&#39; /&gt;&lt;a href=&quot;https://sammattheus.wordpress.com/2023/06/07/the-asymptotics-of-r4t/&quot;&gt;Points And Lines&lt;/a&gt;&lt;/p&gt;&lt;div class=&quot;reblogged-content&quot;&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Jacques Verstraete and I posted a &lt;a href=&quot;https://arxiv.org/abs/2306.04007&quot;&gt;preprint&lt;/a&gt; on the arXiv today on the off-diagonal Ramsey number $latex r(4,t)$. In short, we show that $latex r(4,t) = Omega(t^3/log^4t)$, which is just a $latex log^2t$ factor shy from the upper bound $latex r(4,t) = O (t^3/log^2t)$ proved by Ajtai, Komlós and Szemerédi in 1980. Erdős [1] conjectured that up to logarithmic factors, $latex t^3$ is the order of growth:&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p class=&quot;has-text-align-center&quot;&gt;&lt;img class=&quot;wp-image-1130&quot; style=&quot;width: 600px&quot; src=&quot;https://gilkalai.files.wordpress.com/2023/06/erdos-prize-r4t.png&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;We thus confirm this conjecture. The previous best lower bound was due to Bohman and Keevash who studied the random $latex K_4$-free process and obtained $latex r(4,t) = widetilde{Omega}(t^{5/2})$, where the tilde hides logarithmic factors. It is not clear whether our methods can be pushed further to obtain asymptotically sharp bounds. In any case, that’s not what I want to speculate about, but rather sketch the proof of our result. It’s in my very biased opinion a nice combination of ideas that existed…&lt;/p&gt;
&lt;/div&gt;&lt;p class=&quot;reblog-source&quot;&gt;&lt;a href=&quot;https://sammattheus.wordpress.com/2023/06/07/the-asymptotics-of-r4t/&quot;&gt;View original post&lt;/a&gt; &lt;span class=&quot;more-words&quot;&gt;1,481 more words&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p class=&quot;authors&quot;&gt;By Gil Kalai&lt;/p&gt;
  </description>
  <pubDate>2023-06-09 06:17:30 UTC</pubDate>
  <author>Gil Kalai</author>
</item>

<item>
  <title>Free Fermion Distributions Are Hard to Learn</title>
  <guid>http://arxiv.org/abs/2306.04731</guid>
  <link>http://arxiv.org/abs/2306.04731</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nietner_A/0/1/0/all/0/1&quot;&gt;Alexander Nietner&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Free fermions are some of the best studied quantum systems. However, little
is known about the complexity of learning free-fermion distributions. In this
work we establish the hardness of this task in the particle number
non-preserving case. In particular, we give an information theoretical hardness
result for the general task of learning from expectation values and, in the
more general case when the algorithm is given access to samples, we give a
computational hardness result based on the LPN assumption for learning the
probability density function.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-09 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Classical Verification of Quantum Learning</title>
  <guid>http://arxiv.org/abs/2306.04843</guid>
  <link>http://arxiv.org/abs/2306.04843</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1&quot;&gt;Matthias C. Caro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hinsche_M/0/1/0/all/0/1&quot;&gt;Marcel Hinsche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ioannou_M/0/1/0/all/0/1&quot;&gt;Marios Ioannou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nietner_A/0/1/0/all/0/1&quot;&gt;Alexander Nietner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sweke_R/0/1/0/all/0/1&quot;&gt;Ryan Sweke&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Quantum data access and quantum processing can make certain classically
intractable learning tasks feasible. However, quantum capabilities will only be
available to a select few in the near future. Thus, reliable schemes that allow
classical clients to delegate learning to untrusted quantum servers are
required to facilitate widespread access to quantum learning advantages.
Building on a recently introduced framework of interactive proof systems for
classical machine learning, we develop a framework for classical verification
of quantum learning. We exhibit learning problems that a classical learner
cannot efficiently solve on their own, but that they can efficiently and
reliably solve when interacting with an untrusted quantum prover. Concretely,
we consider the problems of agnostic learning parities and Fourier-sparse
functions with respect to distributions with uniform input marginal. We propose
a new quantum data access model that we call &quot;mixture-of-superpositions&quot;
quantum examples, based on which we give efficient quantum learning algorithms
for these tasks. Moreover, we prove that agnostic quantum parity and
Fourier-sparse learning can be efficiently verified by a classical verifier
with only random example or statistical query access. Finally, we showcase two
general scenarios in learning and verification in which quantum
mixture-of-superpositions examples do not lead to sample complexity
improvements over classical data. Our results demonstrate that the potential
power of quantum data for learning tasks, while not unlimited, can be utilized
by classical agents through interaction with untrusted quantum entities.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-09 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Quantum computing algorithms for inverse problems on graphs and an NP-complete inverse problem</title>
  <guid>http://arxiv.org/abs/2306.05253</guid>
  <link>http://arxiv.org/abs/2306.05253</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ilmavirta_J/0/1/0/all/0/1&quot;&gt;Joonas Ilmavirta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lassas_M/0/1/0/all/0/1&quot;&gt;Matti Lassas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jinpeng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Oksanen_L/0/1/0/all/0/1&quot;&gt;Lauri Oksanen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ylinen_L/0/1/0/all/0/1&quot;&gt;Lauri Ylinen&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We consider an inverse problem for a finite graph $(X,E)$ where we are given
a subset of vertices $B\subset X$ and the distances $d_{(X,E)}(b_1,b_2)$ of all
vertices $b_1,b_2\in B$. The distance of points $x_1,x_2\in X$ is defined as
the minimal number of edges needed to connect two vertices, so all edges have
length 1. The inverse problem is a discrete version of the boundary rigidity
problem in Riemannian geometry or the inverse travel time problem in
geophysics. We will show that this problem has unique solution under certain
conditions and develop quantum computing methods to solve it. We prove the
following uniqueness result: when $(X,E)$ is a tree and $B$ is the set of
leaves of the tree, the graph $(X,E)$ can be uniquely determined in the class
of all graphs having a fixed number of vertices. We present a quantum computing
algorithm which produces a graph $(X,E)$, or one of those, which has a given
number of vertices and the required distances between vertices in $B$. To this
end we develop an algorithm that takes in a qubit representation of a graph and
combine it with Grover&#39;s search algorithm. The algorithm can be implemented
using only $O(|X|^2)$ qubits, the same order as the number of elements in the
adjacency matrix of $(X,E)$. It also has a quadratic improvement in
computational cost compared to standard classical algorithms. Finally, we
consider applications in theory of computation, and show that a slight
modification of the above inverse problem is NP-complete: all NP-problems can
be reduced to a discrete inverse problem we consider.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-09 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Complexity</author>
</item>

<item>
  <title>Scenic Routes with Weighted Points in 2D</title>
  <guid>http://arxiv.org/abs/2306.04858</guid>
  <link>http://arxiv.org/abs/2306.04858</link>
  <description>
    &lt;p class=&quot;arxiv-authors&quot;&gt;&lt;b&gt;Authors:&lt;/b&gt; &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shanmugaraj_V/0/1/0/all/0/1&quot;&gt;Vijayraj Shanmugaraj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_L/0/1/0/all/0/1&quot;&gt;Lini Thomas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karlapalem_K/0/1/0/all/0/1&quot;&gt;Kamalakar Karlapalem&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In a given 2D space, we can have points with different levels of importance.
One would prefer viewing those points from a closer/farther position per their
level of importance. A point in 2D from where the user can view two given
points per his/her preference of distance is termed a scenic point. We develop
the concept of scenic paths in a 2D space for two points that have weights
associated with them. Subsequently, we propose algorithms to generate scenic
routes a traveler can take, which cater to certain principles which define the
scenic routes. Following are the contributions of this paper: (1) mathematical
formulation of a scenic point, (2) introduction of scenic routes formed by such
scenic points in two-class point configurations in 2D spaces, and (3) design of
scenic route generation algorithms that fulfill certain defined requirements.
&lt;/p&gt;
  </description>
  <pubDate>2023-06-09 00:30:00 UTC</pubDate>
  <author>arXiv: Computational Geometry</author>
</item>

</channel>
</rss>
