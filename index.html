<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-05-13T14:30:21Z">Saturday, May 13 2023, 14:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, May 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/05/12/postdoc-at-cambridge-apply-by-july-1-2023/'>Postdoc at Cambridge (apply by July 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A postdoc position in Quantum Algorithms and Complexity at the University of Cambridge, under the supervision of Sergii Strelchuk and Tom Gur, is available. Website: www.maths.cam.ac.uk/person/ss870, www.dcs.warwick.ac.uk/~tomgur/ Email: ss870@cam.ac.uk, tom.gur@warwick.ac.uk
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A postdoc position in Quantum Algorithms and Complexity at the University of Cambridge, under the supervision of Sergii Strelchuk and Tom Gur, is available.</p>
<p>Website: <a href="https://www.maths.cam.ac.uk/person/ss870">https://www.maths.cam.ac.uk/person/ss870</a>, <a href="https://www.dcs.warwick.ac.uk/~tomgur/">https://www.dcs.warwick.ac.uk/~tomgur/</a><br />
Email: ss870@cam.ac.uk, tom.gur@warwick.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T10:03:39Z">Friday, May 12 2023, 10:03</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06821'>Constant-depth circuits vs. monotone circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bruno P. Cavalar, Igor C. Oliveira</p><p>We establish new separations between the power of monotone and general
(non-monotone) Boolean circuits:
</p>
<p>- For every $k \geq 1$, there is a monotone function in ${\sf AC^0}$ that
requires monotone circuits of depth $\Omega(\log^k n)$. This significantly
extends a classical result of Okol'nishnikova (1982) and Ajtai and Gurevich
(1987). In addition, our separation holds for a monotone graph property, which
was unknown even in the context of ${\sf AC^0}$ versus ${\sf mAC^0}$.
</p>
<p>- For every $k \geq 1$, there is a monotone function in ${\sf AC^0}[\oplus]$
that requires monotone circuits of size $\exp(\Omega(\log^k n))$. This makes
progress towards a question posed by Grigni and Sipser (1992).
</p>
<p>These results show that constant-depth circuits can be more efficient than
monotone circuits when computing monotone functions.
</p>
<p>In the opposite direction, we observe that non-trivial simulations are
possible in the absence of parity gates: every monotone function computed by an
${\sf AC^0}$ circuit of size $s$ and depth $d$ can be computed by a monotone
circuit of size $2^{n - n/O(\log s)^{d-1}}$. We show that the existence of
significantly faster monotone simulations would lead to breakthrough circuit
lower bounds. In particular, if every monotone function in ${\sf AC^0}$ admits
a polynomial size monotone circuit, then ${\sf NC^2}$ is not contained in ${\sf
NC^1}$ .
</p>
<p>Finally, we revisit our separation result against monotone circuit size and
investigate the limits of our approach, which is based on a monotone lower
bound for constraint satisfaction problems established by G\"o\"os et al.
(2019) via lifting techniques. Adapting results of Schaefer (1978) and Allender
et al. (2009), we obtain an unconditional classification of the monotone
circuit complexity of Boolean-valued CSPs via their polymorphisms. This result
and the consequences we derive from it might be of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cavalar_B/0/1/0/all/0/1">Bruno P. Cavalar</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_I/0/1/0/all/0/1">Igor C. Oliveira</a></p><p>We establish new separations between the power of monotone and general
(non-monotone) Boolean circuits:
</p>
<p>- For every $k \geq 1$, there is a monotone function in ${\sf AC^0}$ that
requires monotone circuits of depth $\Omega(\log^k n)$. This significantly
extends a classical result of Okol'nishnikova (1982) and Ajtai and Gurevich
(1987). In addition, our separation holds for a monotone graph property, which
was unknown even in the context of ${\sf AC^0}$ versus ${\sf mAC^0}$.
</p>
<p>- For every $k \geq 1$, there is a monotone function in ${\sf AC^0}[\oplus]$
that requires monotone circuits of size $\exp(\Omega(\log^k n))$. This makes
progress towards a question posed by Grigni and Sipser (1992).
</p>
<p>These results show that constant-depth circuits can be more efficient than
monotone circuits when computing monotone functions.
</p>
<p>In the opposite direction, we observe that non-trivial simulations are
possible in the absence of parity gates: every monotone function computed by an
${\sf AC^0}$ circuit of size $s$ and depth $d$ can be computed by a monotone
circuit of size $2^{n - n/O(\log s)^{d-1}}$. We show that the existence of
significantly faster monotone simulations would lead to breakthrough circuit
lower bounds. In particular, if every monotone function in ${\sf AC^0}$ admits
a polynomial size monotone circuit, then ${\sf NC^2}$ is not contained in ${\sf
NC^1}$ .
</p>
<p>Finally, we revisit our separation result against monotone circuit size and
investigate the limits of our approach, which is based on a monotone lower
bound for constraint satisfaction problems established by G\"o\"os et al.
(2019) via lifting techniques. Adapting results of Schaefer (1978) and Allender
et al. (2009), we obtain an unconditional classification of the monotone
circuit complexity of Boolean-valued CSPs via their polymorphisms. This result
and the consequences we derive from it might be of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06452'>A Near-Optimal Deterministic Distributed Synchronizer</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Ghaffari, Anton Trygub</p><p>We provide the first deterministic distributed synchronizer with near-optimal
time complexity and message complexity overheads. Concretely, given any
distributed algorithm $\mathcal{A}$ that has time complexity $T$ and message
complexity $M$ in the synchronous message-passing model (subject to some care
in defining the model), the synchronizer provides a distributed algorithm
$\mathcal{A}'$ that runs in the asynchronous message-passing model with time
complexity $T \cdot poly(\log n)$ and message complexity $(M+m)\cdot poly(\log
n)$. Here, $n$ and $m$ denote the number of nodes and edges in the network,
respectively. The synchronizer is deterministic in the sense that if algorithm
$\mathcal{A}$ is deterministic, then so is algorithm $\mathcal{A}'$.
Previously, only a randomized synchronizer with near-optimal overheads was
known by seminal results of Awerbuch, Patt-Shamir, Peleg, and Saks [STOC 1992]
and Awerbuch and Peleg [FOCS 1990]. We also point out and fix some inaccuracies
in these prior works.
</p>
<p>As concrete applications of our synchronizer, we resolve some longstanding
and fundamental open problems in distributed algorithms: we get the first
asynchronous deterministic distributed algorithms with near-optimal time and
message complexities for leader election, breadth-first search tree, and
minimum spanning tree computations: these all have message complexity
$\tilde{O}(m)$ message complexity. The former two have $\tilde{O}(D)$ time
complexity, where $D$ denotes the network diameter, and the latter has
$\tilde{O}(D+\sqrt{n})$ time complexity. All these bounds are optimal up to
logarithmic factors. Previously all such near-optimal algorithms were either
restricted to the synchronous setting or required randomization.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Trygub_A/0/1/0/all/0/1">Anton Trygub</a></p><p>We provide the first deterministic distributed synchronizer with near-optimal
time complexity and message complexity overheads. Concretely, given any
distributed algorithm $\mathcal{A}$ that has time complexity $T$ and message
complexity $M$ in the synchronous message-passing model (subject to some care
in defining the model), the synchronizer provides a distributed algorithm
$\mathcal{A}'$ that runs in the asynchronous message-passing model with time
complexity $T \cdot poly(\log n)$ and message complexity $(M+m)\cdot poly(\log
n)$. Here, $n$ and $m$ denote the number of nodes and edges in the network,
respectively. The synchronizer is deterministic in the sense that if algorithm
$\mathcal{A}$ is deterministic, then so is algorithm $\mathcal{A}'$.
Previously, only a randomized synchronizer with near-optimal overheads was
known by seminal results of Awerbuch, Patt-Shamir, Peleg, and Saks [STOC 1992]
and Awerbuch and Peleg [FOCS 1990]. We also point out and fix some inaccuracies
in these prior works.
</p>
<p>As concrete applications of our synchronizer, we resolve some longstanding
and fundamental open problems in distributed algorithms: we get the first
asynchronous deterministic distributed algorithms with near-optimal time and
message complexities for leader election, breadth-first search tree, and
minimum spanning tree computations: these all have message complexity
$\tilde{O}(m)$ message complexity. The former two have $\tilde{O}(D)$ time
complexity, where $D$ denotes the network diameter, and the latter has
$\tilde{O}(D+\sqrt{n})$ time complexity. All these bounds are optimal up to
logarithmic factors. Previously all such near-optimal algorithms were either
restricted to the synchronous setting or required randomization.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06541'>Spectral Clustering on Large Datasets: When Does it Work? Theory from Continuous Clustering and Density Cheeger-Buser</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Timothy Chu, Gary Miller, Noel Walkington</p><p>Spectral clustering is one of the most popular clustering algorithms that has
stood the test of time. It is simple to describe, can be implemented using
standard linear algebra, and often finds better clusters than traditional
clustering algorithms like $k$-means and $k$-centers. The foundational
algorithm for two-way spectral clustering, by Shi and Malik, creates a
geometric graph from data and finds a spectral cut of the graph.
</p>
<p>In modern machine learning, many data sets are modeled as a large number of
points drawn from a probability density function. Little is known about when
spectral clustering works in this setting -- and when it doesn't. Past
researchers justified spectral clustering by appealing to the graph Cheeger
inequality (which states that the spectral cut of a graph approximates the
``Normalized Cut''), but this justification is known to break down on large
data sets.
</p>
<p>We provide theoretically-informed intuition about spectral clustering on
large data sets drawn from probability densities, by proving when a continuous
form of spectral clustering considered by past researchers (the unweighted
spectral cut of a probability density) finds good clusters of the underlying
density itself. Our work suggests that Shi-Malik spectral clustering works well
on data drawn from mixtures of Laplace distributions, and works poorly on data
drawn from certain other densities, such as a density we call the `square-root
trough'.
</p>
<p>Our core theorem proves that weighted spectral cuts have low weighted
isoperimetry for all probability densities. Our key tool is a new Cheeger-Buser
inequality for all probability densities, including discontinuous ones.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1">Timothy Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_G/0/1/0/all/0/1">Gary Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Walkington_N/0/1/0/all/0/1">Noel Walkington</a></p><p>Spectral clustering is one of the most popular clustering algorithms that has
stood the test of time. It is simple to describe, can be implemented using
standard linear algebra, and often finds better clusters than traditional
clustering algorithms like $k$-means and $k$-centers. The foundational
algorithm for two-way spectral clustering, by Shi and Malik, creates a
geometric graph from data and finds a spectral cut of the graph.
</p>
<p>In modern machine learning, many data sets are modeled as a large number of
points drawn from a probability density function. Little is known about when
spectral clustering works in this setting -- and when it doesn't. Past
researchers justified spectral clustering by appealing to the graph Cheeger
inequality (which states that the spectral cut of a graph approximates the
``Normalized Cut''), but this justification is known to break down on large
data sets.
</p>
<p>We provide theoretically-informed intuition about spectral clustering on
large data sets drawn from probability densities, by proving when a continuous
form of spectral clustering considered by past researchers (the unweighted
spectral cut of a probability density) finds good clusters of the underlying
density itself. Our work suggests that Shi-Malik spectral clustering works well
on data drawn from mixtures of Laplace distributions, and works poorly on data
drawn from certain other densities, such as a density we call the `square-root
trough'.
</p>
<p>Our core theorem proves that weighted spectral cuts have low weighted
isoperimetry for all probability densities. Our key tool is a new Cheeger-Buser
inequality for all probability densities, including discontinuous ones.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06659'>Optimal Algorithms for Bounded Weighted Edit Distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alejandro Cassis, Tomasz Kociumaka, Philip Wellnitz</p><p>The edit distance of two strings is the minimum number of insertions,
deletions, and substitutions of characters needed to transform one string into
the other. The textbook dynamic-programming algorithm computes the edit
distance of two length-$n$ strings in $O(n^2)$ time, which is optimal up to
subpolynomial factors under SETH. An established way of circumventing this
hardness is to consider the bounded setting, where the running time is
parameterized by the edit distance $k$. A celebrated algorithm by Landau and
Vishkin (JCSS '88) achieves time $O(n + k^2)$, which is optimal as a function
of $n$ and $k$.
</p>
<p>Most practical applications rely on a more general weighted edit distance,
where each edit has a weight depending on its type and the involved characters
from the alphabet $\Sigma$. This is formalized through a weight function $w :
\Sigma\cup\{\varepsilon\}\times\Sigma\cup\{\varepsilon\}\to\mathbb{R}$
normalized so that $w(a,a)=0$ and $w(a,b)\geq 1$ for all $a,b \in
\Sigma\cup\{\varepsilon\}$ with $a \neq b$; the goal is to find an alignment of
the two strings minimizing the total weight of edits. The $O(n^2)$-time
algorithm supports this setting seamlessly, but only very recently, Das,
Gilbert, Hajiaghayi, Kociumaka, and Saha (STOC '23) gave the first non-trivial
algorithm for the bounded version, achieving time $O(n + k^5)$. While this
running time is linear for $k\le n^{1/5}$, it is still very far from the bound
$O(n+k^2)$ achievable in the unweighted setting.
</p>
<p>In this paper, we essentially close this gap by showing both an improved
$\tilde O(n+\sqrt{nk^3})$-time algorithm and, more surprisingly, a matching
lower bound: Conditioned on the All-Pairs Shortest Paths (APSP) hypothesis, our
running time is optimal for $\sqrt{n}\le k\le n$ (up to subpolynomial factors).
This is the first separation between the complexity of the weighted and
unweighted edit distance problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cassis_A/0/1/0/all/0/1">Alejandro Cassis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kociumaka_T/0/1/0/all/0/1">Tomasz Kociumaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Wellnitz_P/0/1/0/all/0/1">Philip Wellnitz</a></p><p>The edit distance of two strings is the minimum number of insertions,
deletions, and substitutions of characters needed to transform one string into
the other. The textbook dynamic-programming algorithm computes the edit
distance of two length-$n$ strings in $O(n^2)$ time, which is optimal up to
subpolynomial factors under SETH. An established way of circumventing this
hardness is to consider the bounded setting, where the running time is
parameterized by the edit distance $k$. A celebrated algorithm by Landau and
Vishkin (JCSS '88) achieves time $O(n + k^2)$, which is optimal as a function
of $n$ and $k$.
</p>
<p>Most practical applications rely on a more general weighted edit distance,
where each edit has a weight depending on its type and the involved characters
from the alphabet $\Sigma$. This is formalized through a weight function $w :
\Sigma\cup\{\varepsilon\}\times\Sigma\cup\{\varepsilon\}\to\mathbb{R}$
normalized so that $w(a,a)=0$ and $w(a,b)\geq 1$ for all $a,b \in
\Sigma\cup\{\varepsilon\}$ with $a \neq b$; the goal is to find an alignment of
the two strings minimizing the total weight of edits. The $O(n^2)$-time
algorithm supports this setting seamlessly, but only very recently, Das,
Gilbert, Hajiaghayi, Kociumaka, and Saha (STOC '23) gave the first non-trivial
algorithm for the bounded version, achieving time $O(n + k^5)$. While this
running time is linear for $k\le n^{1/5}$, it is still very far from the bound
$O(n+k^2)$ achievable in the unweighted setting.
</p>
<p>In this paper, we essentially close this gap by showing both an improved
$\tilde O(n+\sqrt{nk^3})$-time algorithm and, more surprisingly, a matching
lower bound: Conditioned on the All-Pairs Shortest Paths (APSP) hypothesis, our
running time is optimal for $\sqrt{n}\le k\le n$ (up to subpolynomial factors).
This is the first separation between the complexity of the weighted and
unweighted edit distance problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06696'>Characterizing the impact of last-level cache replacement policies on big-data workloads</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexandre Valentin Jamet, Lluc Alvarez, Marc Casas</p><p>In recent years, graph-processing has become an essential class of workloads
with applications in a rapidly growing number of fields. Graph-processing
typically uses large input sets, often in multi-gigabyte scale, and
data-dependent graph traversal methods exhibiting irregular memory access
patterns. Recent work demonstrates that, due to the highly irregular memory
access patterns of data-dependent graph traversals, state-of-the-art
graph-processing workloads spend up to 80 % of the total execution time waiting
for memory accesses to be served by the DRAM. The vast disparity between the
Last Level Cache (LLC) and main memory latencies is a problem that has been
addressed for years in computer architecture. One of the prevailing approaches
when it comes to mitigating this performance gap between modern CPUs and DRAM
is cache replacement policies. In this work, we characterize the challenges
drawn by graph-processing workloads and evaluate the most relevant cache
replacement policies.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jamet_A/0/1/0/all/0/1">Alexandre Valentin Jamet</a>, <a href="http://arxiv.org/find/cs/1/au:+Alvarez_L/0/1/0/all/0/1">Lluc Alvarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Casas_M/0/1/0/all/0/1">Marc Casas</a></p><p>In recent years, graph-processing has become an essential class of workloads
with applications in a rapidly growing number of fields. Graph-processing
typically uses large input sets, often in multi-gigabyte scale, and
data-dependent graph traversal methods exhibiting irregular memory access
patterns. Recent work demonstrates that, due to the highly irregular memory
access patterns of data-dependent graph traversals, state-of-the-art
graph-processing workloads spend up to 80 % of the total execution time waiting
for memory accesses to be served by the DRAM. The vast disparity between the
Last Level Cache (LLC) and main memory latencies is a problem that has been
addressed for years in computer architecture. One of the prevailing approaches
when it comes to mitigating this performance gap between modern CPUs and DRAM
is cache replacement policies. In this work, we characterize the challenges
drawn by graph-processing workloads and evaluate the most relevant cache
replacement policies.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06974'>Minimal dominating sets enumeration with FPT-delay parameterized by the degeneracy and maximum degree</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Valentin Bartier, Oscar Defrain, Fionn Mc Inerney</p><p>At STOC 2002, Eiter, Gottlob, and Makino presented a technique called ordered
generation that yields an $n^{O(d)}$-delay algorithm listing all minimal
transversals of an $n$-vertex hypergraph of degeneracy $d$, for an appropriate
definition of degeneracy. Recently at IWOCA 2019, Conte, Kant\'e, Marino, and
Uno asked whether, even for a more restrictive notion of degeneracy, this
XP-delay algorithm parameterized by $d$ could be made FPT-delay parameterized
by $d$ and the maximum degree $\Delta$, i.e., an algorithm with delay
$f(d,\Delta)\cdot n^{O(1)}$ for some computable function $f$. We answer this
question in the affirmative whenever the hypergraph corresponds to the closed
neighborhoods of a graph, i.e., we show that the intimately related problem of
enumerating minimal dominating sets in graphs admits an FPT-delay algorithm
parameterized by the degeneracy and the maximum degree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bartier_V/0/1/0/all/0/1">Valentin Bartier</a>, <a href="http://arxiv.org/find/cs/1/au:+Defrain_O/0/1/0/all/0/1">Oscar Defrain</a>, <a href="http://arxiv.org/find/cs/1/au:+Inerney_F/0/1/0/all/0/1">Fionn Mc Inerney</a></p><p>At STOC 2002, Eiter, Gottlob, and Makino presented a technique called ordered
generation that yields an $n^{O(d)}$-delay algorithm listing all minimal
transversals of an $n$-vertex hypergraph of degeneracy $d$, for an appropriate
definition of degeneracy. Recently at IWOCA 2019, Conte, Kant\'e, Marino, and
Uno asked whether, even for a more restrictive notion of degeneracy, this
XP-delay algorithm parameterized by $d$ could be made FPT-delay parameterized
by $d$ and the maximum degree $\Delta$, i.e., an algorithm with delay
$f(d,\Delta)\cdot n^{O(1)}$ for some computable function $f$. We answer this
question in the affirmative whenever the hypergraph corresponds to the closed
neighborhoods of a graph, i.e., we show that the intimately related problem of
enumerating minimal dominating sets in graphs admits an FPT-delay algorithm
parameterized by the degeneracy and the maximum degree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.07006'>Fair Price Discrimination</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Siddhartha Banerjee, Kamesh Munagala, Yiheng Shen, Kangning Wang</p><p>A seller is pricing identical copies of a good to a stream of unit-demand
buyers. Each buyer has a value on the good as his private information. The
seller only knows the empirical value distribution of the buyer population and
chooses the revenue-optimal price. We consider a widely studied third-degree
price discrimination model where an information intermediary with perfect
knowledge of the arriving buyer's value sends a signal to the seller, hence
changing the seller's posterior and inducing the seller to set a personalized
posted price. Prior work of Bergemann, Brooks, and Morris (American Economic
Review, 2015) has shown the existence of a signaling scheme that preserves
seller revenue, while always selling the item, hence maximizing consumer
surplus. In a departure from prior work, we ask whether the consumer surplus
generated is fairly distributed among buyers with different values. To this
end, we aim to maximize welfare functions that reward more balanced surplus
allocations.
</p>
<p>Our main result is the surprising existence of a novel signaling scheme that
simultaneously $8$-approximates all welfare functions that are non-negative,
monotonically increasing, symmetric, and concave, compared with any other
signaling scheme. Classical examples of such welfare functions include the
utilitarian social welfare, the Nash welfare, and the max-min welfare. Such a
guarantee cannot be given by any consumer-surplus-maximizing scheme -- which
are the ones typically studied in the literature. In addition, our scheme is
socially efficient, and has the fairness property that buyers with higher
values enjoy higher expected surplus, which is not always the case for existing
schemes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Siddhartha Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Munagala_K/0/1/0/all/0/1">Kamesh Munagala</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yiheng Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kangning Wang</a></p><p>A seller is pricing identical copies of a good to a stream of unit-demand
buyers. Each buyer has a value on the good as his private information. The
seller only knows the empirical value distribution of the buyer population and
chooses the revenue-optimal price. We consider a widely studied third-degree
price discrimination model where an information intermediary with perfect
knowledge of the arriving buyer's value sends a signal to the seller, hence
changing the seller's posterior and inducing the seller to set a personalized
posted price. Prior work of Bergemann, Brooks, and Morris (American Economic
Review, 2015) has shown the existence of a signaling scheme that preserves
seller revenue, while always selling the item, hence maximizing consumer
surplus. In a departure from prior work, we ask whether the consumer surplus
generated is fairly distributed among buyers with different values. To this
end, we aim to maximize welfare functions that reward more balanced surplus
allocations.
</p>
<p>Our main result is the surprising existence of a novel signaling scheme that
simultaneously $8$-approximates all welfare functions that are non-negative,
monotonically increasing, symmetric, and concave, compared with any other
signaling scheme. Classical examples of such welfare functions include the
utilitarian social welfare, the Nash welfare, and the max-min welfare. Such a
guarantee cannot be given by any consumer-surplus-maximizing scheme -- which
are the ones typically studied in the literature. In addition, our scheme is
socially efficient, and has the fairness property that buyers with higher
values enjoy higher expected surplus, which is not always the case for existing
schemes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-12T00:30:00Z">Friday, May 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, May 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/070'>TR23-070 |  Bounded Relativization | 

	Shuichi Hirahara, 

	Zhenjian Lu, 

	Hanlin Ren</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Relativization is one of the most fundamental concepts in complexity theory, which explains the difficulty of resolving major open problems. In this paper, we propose a weaker notion of relativization called *bounded relativization*. For a complexity class $C$, we say that a statement is *$C$-relativizing* if the statement holds relative to every oracle $O$ in $C$. It is easy to see that every result that relativizes also $C$-relativizes for every complexity class $C$. On the other hand, we observe that many non-relativizing results, such as $IP = PSPACE$, are in fact $PSPACE$-relativizing.

First, we use the idea of bounded relativization to obtain new lower bound results, including the following nearly maximum circuit lower bound: for every constant $\varepsilon &gt; 0$, $BPE^{MCSP}/2^{\varepsilon n} \not\subseteq SIZE[2^n/n]$. We prove this by $PSPACE$-relativizing the recent pseudodeterministic pseudorandom generator by Lu, Oliveira, and Santhanam (STOC 2021).

Next, we study the limitations of $PSPACE$-relativizing proof techniques, and show that a seemingly minor improvement over the known results using $PSPACE$-relativizing techniques would imply a breakthrough separation $NP \ne L$. For example:
$\bullet$ Impagliazzo and Wigderson (JCSS 2001) proved that if $EXP \ne BPP$, then $BPP$ admits infinitely-often subexponential-time heuristic derandomization. We show that their result is $PSPACE$-relativizing, and that improving it to worst-case derandomization using $PSPACE$-relativizing techniques implies $NP \ne L$.
$\bullet$ Oliveira and Santhanam (STOC 2017) recently proved that every dense subset in $P$ admits an infinitely-often subexponential-time pseudodeterministic construction, which we observe is $PSPACE$-relativizing. Improving this to almost-everywhere (pseudodeterministic) or (infinitely-often) deterministic constructions by $PSPACE$-relativizing techniques implies $NP \ne L$.
$\bullet$ Santhanam (SICOMP 2009) proved that $pr-MA$ does not have fixed polynomial-size circuits. This lower bound can be shown $PSPACE$-relativizing, and we show that improving it to an almost-everywhere lower bound using $PSPACE$-relativizing techniques implies $NP \ne L$.

In fact, we show that if we can use $PSPACE$-relativizing techniques to obtain the above-mentioned improvements, then $PSPACE \ne EXPH$. We obtain our barrier results by constructing suitable oracles computable in $EXPH$ relative to which these improvements are impossible.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Relativization is one of the most fundamental concepts in complexity theory, which explains the difficulty of resolving major open problems. In this paper, we propose a weaker notion of relativization called *bounded relativization*. For a complexity class $C$, we say that a statement is *$C$-relativizing* if the statement holds relative to every oracle $O$ in $C$. It is easy to see that every result that relativizes also $C$-relativizes for every complexity class $C$. On the other hand, we observe that many non-relativizing results, such as $IP = PSPACE$, are in fact $PSPACE$-relativizing.

First, we use the idea of bounded relativization to obtain new lower bound results, including the following nearly maximum circuit lower bound: for every constant $\varepsilon &gt; 0$, $BPE^{MCSP}/2^{\varepsilon n} \not\subseteq SIZE[2^n/n]$. We prove this by $PSPACE$-relativizing the recent pseudodeterministic pseudorandom generator by Lu, Oliveira, and Santhanam (STOC 2021).

Next, we study the limitations of $PSPACE$-relativizing proof techniques, and show that a seemingly minor improvement over the known results using $PSPACE$-relativizing techniques would imply a breakthrough separation $NP \ne L$. For example:
$\bullet$ Impagliazzo and Wigderson (JCSS 2001) proved that if $EXP \ne BPP$, then $BPP$ admits infinitely-often subexponential-time heuristic derandomization. We show that their result is $PSPACE$-relativizing, and that improving it to worst-case derandomization using $PSPACE$-relativizing techniques implies $NP \ne L$.
$\bullet$ Oliveira and Santhanam (STOC 2017) recently proved that every dense subset in $P$ admits an infinitely-often subexponential-time pseudodeterministic construction, which we observe is $PSPACE$-relativizing. Improving this to almost-everywhere (pseudodeterministic) or (infinitely-often) deterministic constructions by $PSPACE$-relativizing techniques implies $NP \ne L$.
$\bullet$ Santhanam (SICOMP 2009) proved that $pr-MA$ does not have fixed polynomial-size circuits. This lower bound can be shown $PSPACE$-relativizing, and we show that improving it to an almost-everywhere lower bound using $PSPACE$-relativizing techniques implies $NP \ne L$.

In fact, we show that if we can use $PSPACE$-relativizing techniques to obtain the above-mentioned improvements, then $PSPACE \ne EXPH$. We obtain our barrier results by constructing suitable oracles computable in $EXPH$ relative to which these improvements are impossible.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T19:05:26Z">Thursday, May 11 2023, 19:05</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/069'>TR23-069 |  Constant-depth circuits vs. monotone circuits | 

	Bruno Pasqualotto Cavalar, 

	Igor Carboni Oliveira</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We establish new separations between the power of monotone and general (non-monotone) Boolean circuits:

- For every $k \geq 1$, there is a monotone function in ${\rm AC^0}$ (constant-depth poly-size circuits) that requires monotone circuits of depth $\Omega(\log^k n)$. This significantly extends a classical result of Okol&#39;nishnikova (1982) and Ajtai and Gurevich (1987). In addition, our separation holds for a monotone graph property, which was unknown even in the context of ${\rm AC^0}$ versus ${\rm mAC^0}$.
- For every $k \geq 1$, there is a monotone function in ${\rm AC^0}[\oplus]$ (constant-depth poly-size circuits extended with parity gates) that requires monotone circuits of size $\exp(\Omega(\log^k n))$. This makes progress towards a question posed by Grigni and Sipser (1992).
  
These results show that constant-depth circuits can be more efficient than monotone circuits when computing monotone functions.

In the opposite direction, we observe that non-trivial simulations are possible in the absence of parity gates: every monotone function computed by an ${\rm AC^0}$ circuit of size $s$ and depth $d$ can be computed by a monotone circuit of size $2^{n - n/O(\log s)^{d-1}}$. We show that the existence of significantly faster monotone simulations would lead to breakthrough circuit lower bounds. In particular, if every monotone function in ${\rm AC^0}$ admits a polynomial size monotone circuit, then ${\rm NC^2}$ is not contained in ${\rm NC^1}$ .

Finally, we revisit our separation result against monotone circuit size and investigate the limits of our approach, which is based on a monotone lower bound for constraint satisfaction problems established by GÃ¶Ã¶s, Kamath, Robere and Sokolov (2019) via lifting techniques. Adapting results of Schaefer (1978) and Allender, Bauland, Immerman, Schnoor and Vollmer (2009), we obtain an unconditional classification of the monotone circuit complexity of Boolean-valued CSPs via their polymorphisms. This result and the consequences we derive from it might be of independent interest.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We establish new separations between the power of monotone and general (non-monotone) Boolean circuits:

- For every $k \geq 1$, there is a monotone function in ${\rm AC^0}$ (constant-depth poly-size circuits) that requires monotone circuits of depth $\Omega(\log^k n)$. This significantly extends a classical result of Okol&#39;nishnikova (1982) and Ajtai and Gurevich (1987). In addition, our separation holds for a monotone graph property, which was unknown even in the context of ${\rm AC^0}$ versus ${\rm mAC^0}$.
- For every $k \geq 1$, there is a monotone function in ${\rm AC^0}[\oplus]$ (constant-depth poly-size circuits extended with parity gates) that requires monotone circuits of size $\exp(\Omega(\log^k n))$. This makes progress towards a question posed by Grigni and Sipser (1992).
  
These results show that constant-depth circuits can be more efficient than monotone circuits when computing monotone functions.

In the opposite direction, we observe that non-trivial simulations are possible in the absence of parity gates: every monotone function computed by an ${\rm AC^0}$ circuit of size $s$ and depth $d$ can be computed by a monotone circuit of size $2^{n - n/O(\log s)^{d-1}}$. We show that the existence of significantly faster monotone simulations would lead to breakthrough circuit lower bounds. In particular, if every monotone function in ${\rm AC^0}$ admits a polynomial size monotone circuit, then ${\rm NC^2}$ is not contained in ${\rm NC^1}$ .

Finally, we revisit our separation result against monotone circuit size and investigate the limits of our approach, which is based on a monotone lower bound for constraint satisfaction problems established by GÃ¶Ã¶s, Kamath, Robere and Sokolov (2019) via lifting techniques. Adapting results of Schaefer (1978) and Allender, Bauland, Immerman, Schnoor and Vollmer (2009), we obtain an unconditional classification of the monotone circuit complexity of Boolean-valued CSPs via their polymorphisms. This result and the consequences we derive from it might be of independent interest.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T15:29:27Z">Thursday, May 11 2023, 15:29</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/068'>TR23-068 |  Colourful TFNP and Propositional Proofs | 

	Ben Davis, 

	Robert Robere</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Recent work has shown that many of the standard TFNP classes â such as PLS, PPADS, PPAD, SOPL, and EOPL â have corresponding proof systems in propositional proof complexity, in the sense that a total search problem is in the class if and only if the totality of the problem can be efficiently proved by the corresponding proof system. We build on this line of work by studying coloured variants of these TFNP classes: C-PLS, C-PPADS, C-PPAD, C-SOPL, and C-EOPL. While C-PLS has been studied in the literature before, the coloured variants of the other classes are introduced here for the first time. We give a family of results showing that these coloured TFNP classes are natural objects of study, and that the correspondence between TFNP and natural propositional proof systems is not an exceptional phenomenon isolated to weak TFNP classes. Namely, we show that:

- Each of the classes C-PLS, C-PPADS, and C-SOPL have corresponding proof systems characterizing them. Specifically, the proof systems for these classes are obtained by adding depth to the formulas in the corresponding proof system for the uncoloured class. For instance, while it was previously known that PLS is characterized by bounded-width Res- olution (i.e. depth 0.5 Frege), we prove that C-PLS is characterized by depth-1.5 Frege (Res(polylog(n))).

- The classes C-PPAD and C-EOPL coincide exactly with the uncoloured classes PPADS and SOPL, respectively. Thus, both of these classes also have corresponding proof systems: unary Sherali-Adams and Reversible Resolution, respectively.

- Finally, we prove a coloured intersection theorem for the coloured sink classes, showing C-PLS?C-PPADS = C-SOPL, generalizing the intersection theorem PLS?PPADS = SOPL. However, while it is known in the uncoloured world that PLS ? PPAD = EOPL = CLS, we prove that this equality fails in the coloured world in the black-box setting. More precisely, we show that there is an oracle O relative to which C-PLS ? C-PPAD $\neq$ C-EOPL.

To prove our results, we introduce an abstract multivalued proof system â the Blockwise Calculus â which may be of independent interest.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Recent work has shown that many of the standard TFNP classes â such as PLS, PPADS, PPAD, SOPL, and EOPL â have corresponding proof systems in propositional proof complexity, in the sense that a total search problem is in the class if and only if the totality of the problem can be efficiently proved by the corresponding proof system. We build on this line of work by studying coloured variants of these TFNP classes: C-PLS, C-PPADS, C-PPAD, C-SOPL, and C-EOPL. While C-PLS has been studied in the literature before, the coloured variants of the other classes are introduced here for the first time. We give a family of results showing that these coloured TFNP classes are natural objects of study, and that the correspondence between TFNP and natural propositional proof systems is not an exceptional phenomenon isolated to weak TFNP classes. Namely, we show that:

- Each of the classes C-PLS, C-PPADS, and C-SOPL have corresponding proof systems characterizing them. Specifically, the proof systems for these classes are obtained by adding depth to the formulas in the corresponding proof system for the uncoloured class. For instance, while it was previously known that PLS is characterized by bounded-width Res- olution (i.e. depth 0.5 Frege), we prove that C-PLS is characterized by depth-1.5 Frege (Res(polylog(n))).

- The classes C-PPAD and C-EOPL coincide exactly with the uncoloured classes PPADS and SOPL, respectively. Thus, both of these classes also have corresponding proof systems: unary Sherali-Adams and Reversible Resolution, respectively.

- Finally, we prove a coloured intersection theorem for the coloured sink classes, showing C-PLS?C-PPADS = C-SOPL, generalizing the intersection theorem PLS?PPADS = SOPL. However, while it is known in the uncoloured world that PLS ? PPAD = EOPL = CLS, we prove that this equality fails in the coloured world in the black-box setting. More precisely, we show that there is an oracle O relative to which C-PLS ? C-PPAD $\neq$ C-EOPL.

To prove our results, we introduce an abstract multivalued proof system â the Blockwise Calculus â which may be of independent interest.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T14:19:24Z">Thursday, May 11 2023, 14:19</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/05/winter-is-coming.html'>Winter is Coming</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>I fear we are heading to a computer science winter. Now why would I say that when CS enrollments are at record levels and AI is driving incredible excitement in the field? Back in 2016 I wrote</p><blockquote><p>We wonât see a decline in demand for computer science students until we automate ourselves out of a job.</p></blockquote><p>With advances in machine learning, especially generative AI, you can now use AI tools with little to no knowledge of computer science and mathematics. You can do quite a bit more with just a basic knowledge of Python programming and APIs. And tools like Github co-pilot make programming that much easier.</p><p>In 2005 during the last period computer science saw small enrollments, I suggested&nbsp;computing became a commodity and we lost the excitement in the field, leading to a decrease of interest and students. It didn't help that potential students had a (mostly mistaken) perception that all the computing jobs were being outsourced to India.</p><p>We may soon see a time when computing loses its excitement again if everyone can just interact in English (or any other language). Students might now have a perception that computing jobs will be outsourced to AI. The recent tech layoffs don't help. Even the ones interested in computing might focus more on the various low-cost certificate programs instead of a full CS degree.</p><p>What can we do? We need to reframe our degrees or create new ones to recognize the move to data-oriented computing. We need to embrace teaching responsible AI but without fighting the future.&nbsp;</p><p>CS is in a great place right now but we have to continually adjust to ensure our future relevance or we may no longer have it.</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I fear we are heading to a computer science winter. Now why would I say that when CS enrollments are at record levels and AI is driving incredible excitement in the field? Back in 2016 I <a href="https://blog.computationalcomplexity.org/2016/04/its-all-about-jobs.html">wrote</a></p><blockquote><p>We wonât see a decline in demand for computer science students until we automate ourselves out of a job.</p></blockquote><p>With advances in machine learning, especially generative AI, you can now use AI tools with little to no knowledge of computer science and mathematics. You can do quite a bit more with just a basic knowledge of Python programming and APIs. And tools like Github co-pilot make programming that much easier.</p><p>In 2005 during the last period computer science saw small enrollments, I <a href="https://blog.computationalcomplexity.org/2005/07/computer-science-in-high-school.html">suggested</a>&nbsp;computing became a commodity and we lost the excitement in the field, leading to a decrease of interest and students. It didn't help that potential students had a (<a href="https://cra.org/govaffairs/blog/2006/03/ny-times-editorial-outsourcing-isnt-as-bad-as-you-think/">mostly mistaken</a>) perception that all the computing jobs were being outsourced to India.</p><p>We may soon see a time when computing loses its excitement again if everyone can just interact in English (or any other language). Students might now have a perception that computing jobs will be outsourced to AI. The recent tech layoffs don't help. Even the ones interested in computing might focus more on the various low-cost certificate programs instead of a full CS degree.</p><p>What can we do? We need to reframe our degrees or create new ones to recognize the move to data-oriented computing. We need to embrace teaching responsible AI but without fighting the future.&nbsp;</p><p>CS is in a great place right now but we have to continually adjust to ensure our future relevance or we may no longer have it.</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T13:38:00Z">Thursday, May 11 2023, 13:38</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/05/11/mathematics-of-the-impossible-chapter-11-proofs/'>Mathematics of the impossible, Chapter 11, Proofs</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The notion of proof is pervasive. We have seen many proofs in this book until now. But the notion extends to others realms of knowledge, including empirical science, law, and more. Complexity theory has contributed a great deal to the notion of proof, with important applications in several areas such as cryptography. 11.1 Static proofs [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p style="text-align:justify">The notion of proof is pervasive. We have seen many proofs in this book until now. But the notion extends to others realms of knowledge, including empirical science, law, and more. Complexity theory has contributed a great deal to the notion of proof, with important applications in several areas such as cryptography.</p>
<h3 class="sectionHead"><span class="titlemark">11.1   </span> <a id="x1-11100011.1"></a>Static proofs</h3>
<p style="text-align:justify">As remarked in section&nbsp;<a href="#x1-590005.1.0.1">5.1.0.1<!--tex4ht:ref: subsec:How-to-think-of-NP --></a>, we can think of problems in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> as those admitting a solution that can be verified efficiently, namely in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. Let us repeat the definition of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> using the suggestive letter <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> for verifier.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-111001r1"></a> <b>Definition</b> 11.1.  </span> A function <img src="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:X&#92;subseteq &#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> iff there is <img src="https://s0.wp.com/latex.php?latex=V%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V&#92;in &#92;text {P}" class="latex" /> (called âverifierâ) and <img src="https://s0.wp.com/latex.php?latex=d%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#92;in &#92;mathbb {N}" class="latex" /> s.t.:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%7Cx%7C%5E%7Bd%7D%7D%3AV%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%7Cx%7C%5E%7Bd%7D%7D%3AV%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%7Cx%7C%5E%7Bd%7D%7D%3AV%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} f(x)=1&#92;Leftrightarrow &#92;exists y&#92;in &#92;{0,1&#92;} ^{|x|^{d}}:V(x,y)=1. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We are naturally interested in fast proof verification, and especially the complexity of <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" />. It turns out that proofs can be encoded in a format that allows for very efficient verification. This message is already in the following.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-111002r1"></a> <b>Theorem</b> 11.1.  </span>For any input length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> in Definition <a href="#x1-111001r1">11.1<!--tex4ht:ref: def:NP-as-proof-system --></a> can be taken to be a 3CNF of size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{d}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   That is, whereas when defining <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> as a proof system we considered arbitrary verifiers <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> in P, in fact the definition is unchanged if one selects a very restricted class of verifiers: small 3CNFs.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>This is just a restatement of Theorem <a href="#x1-57001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>. <b>QED</b></p>
</div>
<p style="text-align:justify">   This extreme reduction in the verifierâs complexity is possible because we are allowing proofs to be long, longer than the original verifierâs running time. If we donât allow for that, such a reduction is not known. Such âbounded proofsâ are very interesting to study, but we shall not do so now.</p>
<p style="text-align:justify">   Instead, we ask for more. The 3CNF in the above theorem still depends on the entire proof. We can ask for a verifier that only depends on few bits of the proof. Taking this to the extreme, we can ask whether <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> can only read a constant number of bits from <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. Without randomness, this is impossible.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-111003r1"></a> <b>Exercise</b> 11.1.  </span>Suppose <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> in Definition <a href="#x1-111001r1">11.1<!--tex4ht:ref: def:NP-as-proof-system --></a> only reads <img src="https://s0.wp.com/latex.php?latex=%5Cle+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le d" class="latex" /> bits of <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />, for a constant <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />. Show that the corresponding class would be the same as P.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Surprisingly, if we allow randomness this is possible. Moreover, the use of randomness is fairly limited â only logarithmically many bits â yielding the following central characterization.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-111004r2"></a> <b>Theorem</b> 11.2.  </span> A function <img src="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:X&#92;subseteq &#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> iff there is <img src="https://s0.wp.com/latex.php?latex=V%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V&#92;in &#92;text {P}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=d%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#92;in &#92;mathbb {N}" class="latex" /> s.t.:</p>
<p style="text-align:justify">   <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3D1%5CRightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%7Cx%7C%5E%7Bd%7D%7D%3A%5Cmathbb+%7BP%7D_%7Br%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bd%5Clog+%7Cx%7C%7D%7D%5BV%28x%2Cy%2Cr%29%3D1%5D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3D1%5CRightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%7Cx%7C%5E%7Bd%7D%7D%3A%5Cmathbb+%7BP%7D_%7Br%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bd%5Clog+%7Cx%7C%7D%7D%5BV%28x%2Cy%2Cr%29%3D1%5D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3D1%5CRightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%7Cx%7C%5E%7Bd%7D%7D%3A%5Cmathbb+%7BP%7D_%7Br%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bd%5Clog+%7Cx%7C%7D%7D%5BV%28x%2Cy%2Cr%29%3D1%5D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=1&#92;Rightarrow &#92;exists y&#92;in &#92;{0,1&#92;} ^{|x|^{d}}:&#92;mathbb {P}_{r&#92;in &#92;{0,1&#92;} ^{d&#92;log |x|}}[V(x,y,r)=1]=1" class="latex" />,</p>
<p style="text-align:justify">   <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3D0%5CRightarrow+%5Cforall+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%7Cx%7C%5E%7Bd%7D%7D%3A%5Cmathbb+%7BP%7D_%7Br%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bd%5Clog+%7Cx%7C%7D%7D%5BV%28x%2Cy%2Cr%29%3D1%5D%3C0.01&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3D0%5CRightarrow+%5Cforall+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%7Cx%7C%5E%7Bd%7D%7D%3A%5Cmathbb+%7BP%7D_%7Br%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bd%5Clog+%7Cx%7C%7D%7D%5BV%28x%2Cy%2Cr%29%3D1%5D%3C0.01&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3D0%5CRightarrow+%5Cforall+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7B%7Cx%7C%5E%7Bd%7D%7D%3A%5Cmathbb+%7BP%7D_%7Br%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bd%5Clog+%7Cx%7C%7D%7D%5BV%28x%2Cy%2Cr%29%3D1%5D%3C0.01&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=0&#92;Rightarrow &#92;forall y&#92;in &#92;{0,1&#92;} ^{|x|^{d}}:&#92;mathbb {P}_{r&#92;in &#92;{0,1&#92;} ^{d&#92;log |x|}}[V(x,y,r)=1]&lt;0.01" class="latex" />,</p>
<p style="text-align:justify">   and moreover <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> reads <img src="https://s0.wp.com/latex.php?latex=%5Cle+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le d" class="latex" /> bits of <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-111005r2"></a> <b>Exercise</b> 11.2.  </span>Prove the âonly ifâ in Theorem <a href="#x1-111004r2">11.2<!--tex4ht:ref: thm:NP-iff-PCP --></a> in the specific case <img src="https://s0.wp.com/latex.php?latex=f%3D0.01%5Ctext+%7B-Gap-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3D0.01%5Ctext+%7B-Gap-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3D0.01%5Ctext+%7B-Gap-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f=0.01&#92;text {-Gap-3Sat}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Given this exercise, the âonly ifâ direction for any problem in NP follows from the advanced result that any problem in NP can be map reduced to <img src="https://s0.wp.com/latex.php?latex=0.01&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0.01&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0.01&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0.01" class="latex" />-Gap-3Sat (which is essentially Theorem <a href="#x1-55002r7">4.7<!--tex4ht:ref: thm:-=00005BPCP=00005D --></a>, except we did not claim map reductions or a specific constant there).</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-111006r3"></a> <b>Exercise</b> 11.3.  </span>Prove the âifâ in Theorem <a href="#x1-111004r2">11.2<!--tex4ht:ref: thm:NP-iff-PCP --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">11.2   </span> <a id="x1-11200011.2"></a>Zero-knowledge</h3>
<p style="text-align:justify">In Theorem <a href="#x1-111004r2">11.2<!--tex4ht:ref: thm:NP-iff-PCP --></a> the verifier gains âconstant confidenceâ about the validity of the proof, just be inspecting a constant number of bits. Hence the verifier âlearnsâ at most a constant number of bits of the proof. This is remarkable, but we can further ask if we can modify the proof so that the verifier âlearns nothingâ about the proof. Such proofs are called zero knowledge and are extensively studied and applied.</p>
<p style="text-align:justify">   We sketch how this is done for Gap-3Color, which is also NP-complete. Rather than a single proof <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />, now the verifier will receive a random proof <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" />. This <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" /> is obtained from a 3 coloring <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> by randomly permuting colors (so for any <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> the corresponding <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" /> is uniform over 6 colorings). The verifier will pick a random edge and inspect the corresponding endpoints, and accept if they are different.</p>
<p style="text-align:justify">   The verifier learn nothing because all that they see is two random different color. One can formalize âlearning nothingâ by noting that the verifier can produce this distribution by themselves, without looking at the proof. (So why does the verifier gain anything from <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />? The fact that a proof <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> has been written down means that colors have been picked so that every two endpoints are uniform colors, something that the verifier is not easily able to reproduce.)</p>
<p style="text-align:justify">   This gives a zero-knowledge proof for verifiers that follow the protocol of just inspecting an edge. In a cryptographic setting one has to worry about verifiers which donât follow the protocol. Using cryptographic assumptions, one can force the verifiers to follow the protocol by considering an <em>interactive</em> proof: First a proof <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> is committed to but not revealed, then the verifier selects an edge to inspect, and only then the corresponding colors are revealed, and only those. This protocol lends itself to a physical implementation.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">11.3   </span> <a id="x1-11300011.3"></a>Interactive proofs</h3>
<p style="text-align:justify">We now consider interactive proofs. Here the verifier <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> engages in a protocol with a prover <img src="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="P" class="latex" />. Given an input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to both <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="P" class="latex" />, the verifier asks questions, the prover replies, the verifier asks more questions, and so on. The case of NP corresponds to the prover simply sending <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> to                                                                                                                                                                                     <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" />.</p>
<p style="text-align:justify">   It turns out that it suffices for the verifier to send uniformly random strings <img src="https://s0.wp.com/latex.php?latex=Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Q_{1},Q_{2},&#92;ldots " class="latex" /> bits to <img src="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="P" class="latex" />. This leads to a simple definition.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-113001r2"></a> <b>Definition</b> 11.2.  </span>A function <img src="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:X&#92;subseteq &#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> admits an efficient interactive proof, abbreviated IP, if there is <img src="https://s0.wp.com/latex.php?latex=V%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V&#92;in &#92;text {P}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=d%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#92;in &#92;mathbb {N}" class="latex" /> such that for every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" />, letting <img src="https://s0.wp.com/latex.php?latex=b%3A%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%3A%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%3A%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b:=n^{d}" class="latex" />:</p>
<p style="text-align:justify">
</div>
<ul class="itemize1">
<li class="itemize">If <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=1" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=%5Cexists+P%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+P%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+P%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists P:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} ^{b}" class="latex" /> such that
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+V%5Cleft+%28P%28Q_%7B1%7D%29%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%29%2C%5Cldots+%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%29%5Cright+%29%3D1+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+V%5Cleft+%28P%28Q_%7B1%7D%29%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%29%2C%5Cldots+%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%29%5Cright+%29%3D1+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+V%5Cleft+%28P%28Q_%7B1%7D%29%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%29%2C%5Cldots+%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%29%5Cright+%29%3D1+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} V&#92;left (P(Q_{1}),P(Q_{1},Q_{2}),&#92;ldots ,P(Q_{1},Q_{2},&#92;ldots ,Q_{b})&#92;right )=1 &#92;end{aligned}" class="latex" /></div>
<p>for every <img src="https://s0.wp.com/latex.php?latex=Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Q_{1},Q_{2},&#92;ldots ,Q_{b}&#92;in &#92;{0,1&#92;} ^{b}" class="latex" />.</li>
<li class="itemize">If <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=0" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=%5Cforall+P%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cforall+P%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cforall+P%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;forall P:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} ^{b}" class="latex" /> we have
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BQ_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D%7D%5Cleft+%5BV%5Cleft+%28P%28Q_%7B1%7D%29%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%29%2C%5Cldots+%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%29%5Cright+%29%3D1%5Cright+%5D%5Cle+1%2F3.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BQ_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D%7D%5Cleft+%5BV%5Cleft+%28P%28Q_%7B1%7D%29%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%29%2C%5Cldots+%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%29%5Cright+%29%3D1%5Cright+%5D%5Cle+1%2F3.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BQ_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bb%7D%7D%5Cleft+%5BV%5Cleft+%28P%28Q_%7B1%7D%29%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%29%2C%5Cldots+%2CP%28Q_%7B1%7D%2CQ_%7B2%7D%2C%5Cldots+%2CQ_%7Bb%7D%29%5Cright+%29%3D1%5Cright+%5D%5Cle+1%2F3.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{Q_{1},Q_{2},&#92;ldots ,Q_{b}&#92;in &#92;{0,1&#92;} ^{b}}&#92;left [V&#92;left (P(Q_{1}),P(Q_{1},Q_{2}),&#92;ldots ,P(Q_{1},Q_{2},&#92;ldots ,Q_{b})&#92;right )=1&#92;right ]&#92;le 1/3. &#92;end{aligned}" class="latex" /></div>
</li>
</ul>
<p style="text-align:justify">The following amazing result shows the power of interactive proofs, compared to non-interactive proofs. We can think of NP as âreading a bookâ and IP as âgoing to class and asking questions.â We donât yet know how to replace teachers with books.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-113002r3"></a> <b>Theorem</b> 11.3.  </span><span class="cite">[<a href="#XLundFoKaNi92">41</a>,&nbsp;<a href="#XShamir92">58</a>]</span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B+IP%7D%3D%5Ctext+%7BPSpace%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B+IP%7D%3D%5Ctext+%7BPSpace%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B+IP%7D%3D%5Ctext+%7BPSpace%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text { IP}=&#92;text {PSpace}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   In the rest of this section we present the main ideas in the proof of <a href="#x1-113002r3">11.3<!--tex4ht:ref: thm:IP=00003DPSpace --></a>, establishing a weaker result. In particular we show that IP contains problems not known to be in NP.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-113003r4"></a> <b>Theorem</b> 11.4.  </span>Given a field <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}" class="latex" />, an arithmetic circuit <img src="https://s0.wp.com/latex.php?latex=C%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bv%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bv%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bv%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(x_{1},x_{2},&#92;ldots ,x_{v})" class="latex" /> over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}" class="latex" /> computing a polynomial of degree <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />, and an element <img src="https://s0.wp.com/latex.php?latex=s%5Cin+%5Cmathbb+%7BF%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+%5Cmathbb+%7BF%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+%5Cmathbb+%7BF%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in &#92;mathbb {F}," class="latex" /> deciding if</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csum+_%7Bx_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bv%7D%5Cin+%5C%7B0%2C1%5C%7D+%7DC%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bv%7D%29%3Ds%7E%7E%7E%7E%2811.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csum+_%7Bx_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bv%7D%5Cin+%5C%7B0%2C1%5C%7D+%7DC%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bv%7D%29%3Ds%7E%7E%7E%7E%2811.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csum+_%7Bx_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bv%7D%5Cin+%5C%7B0%2C1%5C%7D+%7DC%28x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bv%7D%29%3Ds%7E%7E%7E%7E%2811.1%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;sum _{x_{1},x_{2},&#92;ldots ,x_{v}&#92;in &#92;{0,1&#92;} }C(x_{1},x_{2},&#92;ldots ,x_{v})=s~~~~(11.1) &#92;end{aligned}" class="latex" /></div>
<p>is in IP, whenever <img src="https://s0.wp.com/latex.php?latex=%281-d%2Fq%29%5E%7Bv%7D%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%281-d%2Fq%29%5E%7Bv%7D%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%281-d%2Fq%29%5E%7Bv%7D%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(1-d/q)^{v}&#92;ge 2/3" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>If <img src="https://s0.wp.com/latex.php?latex=v%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v=1" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> can decide this question by itself, by evaluating the circuit. For larger <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v" class="latex" /> we give a way to reduce <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v" class="latex" /> by <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />.</p>
<p style="text-align:justify">   As the first prover answer, <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> expects a polynomial <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> of degree <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> in the variable <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, which is meant to be</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+s%27%28x%29%3A%3D%5Csum+_%7Bx_%7B2%7D%2Cx_%7B3%7D%2C%5Cldots+%2Cx_%7Bn%7D%5Cin+%5C%7B0%2C1%5C%7D+%7DC%28x%2Cx_%7B2%7D%2Cx_%7B3%7D%5Cldots+%2Cx_%7Bn%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+s%27%28x%29%3A%3D%5Csum+_%7Bx_%7B2%7D%2Cx_%7B3%7D%2C%5Cldots+%2Cx_%7Bn%7D%5Cin+%5C%7B0%2C1%5C%7D+%7DC%28x%2Cx_%7B2%7D%2Cx_%7B3%7D%5Cldots+%2Cx_%7Bn%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+s%27%28x%29%3A%3D%5Csum+_%7Bx_%7B2%7D%2Cx_%7B3%7D%2C%5Cldots+%2Cx_%7Bn%7D%5Cin+%5C%7B0%2C1%5C%7D+%7DC%28x%2Cx_%7B2%7D%2Cx_%7B3%7D%5Cldots+%2Cx_%7Bn%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} s&#039;(x):=&#92;sum _{x_{2},x_{3},&#92;ldots ,x_{n}&#92;in &#92;{0,1&#92;} }C(x,x_{2},x_{3}&#92;ldots ,x_{n}). &#92;end{aligned}" class="latex" /></div>
<p><img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> checks if <img src="https://s0.wp.com/latex.php?latex=p%280%29%2Bp%281%29%3Ds&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%280%29%2Bp%281%29%3Ds&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%280%29%2Bp%281%29%3Ds&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(0)+p(1)=s" class="latex" />, and if not rejects. Otherwise, it recursively runs the protocol to verify that</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csum+_%7Bx_%7B2%7D%2Cx_%7B3%7D%2C%5Cldots+%2Cx_%7Bn%7D%5Cin+%5C%7B0%2C1%5C%7D+%7DC%28Q_%7B1%7D%2Cx_%7B2%7D%2Cx_%7B3%7D%2C%5Cldots+%2Cx_%7Bn%7D%29%3Dp%28Q_%7B1%7D%29.%7E%7E%7E%7E%2811.2%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csum+_%7Bx_%7B2%7D%2Cx_%7B3%7D%2C%5Cldots+%2Cx_%7Bn%7D%5Cin+%5C%7B0%2C1%5C%7D+%7DC%28Q_%7B1%7D%2Cx_%7B2%7D%2Cx_%7B3%7D%2C%5Cldots+%2Cx_%7Bn%7D%29%3Dp%28Q_%7B1%7D%29.%7E%7E%7E%7E%2811.2%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csum+_%7Bx_%7B2%7D%2Cx_%7B3%7D%2C%5Cldots+%2Cx_%7Bn%7D%5Cin+%5C%7B0%2C1%5C%7D+%7DC%28Q_%7B1%7D%2Cx_%7B2%7D%2Cx_%7B3%7D%2C%5Cldots+%2Cx_%7Bn%7D%29%3Dp%28Q_%7B1%7D%29.%7E%7E%7E%7E%2811.2%29+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;sum _{x_{2},x_{3},&#92;ldots ,x_{n}&#92;in &#92;{0,1&#92;} }C(Q_{1},x_{2},x_{3},&#92;ldots ,x_{n})=p(Q_{1}).~~~~(11.2) &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   This concludes the description of the protocol. We now verify its correctness.</p>
<p style="text-align:justify">   In case equation&nbsp;(??) is true, <img src="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="P" class="latex" /> can send polynomials that cause <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> to accept.</p>
<p style="text-align:justify">   In case equation&nbsp;(??) is false, <img src="https://s0.wp.com/latex.php?latex=s%27%280%29%2Bs%27%281%29%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%27%280%29%2Bs%27%281%29%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%27%280%29%2Bs%27%281%29%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#039;(0)+s&#039;(1)&#92;ne s" class="latex" />. Hence, unless <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> rejects right away because <img src="https://s0.wp.com/latex.php?latex=p%280%29%2Bp%281%29%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%280%29%2Bp%281%29%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%280%29%2Bp%281%29%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(0)+p(1)&#92;ne s" class="latex" />, we have <img src="https://s0.wp.com/latex.php?latex=p%5Cne+s%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%5Cne+s%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%5Cne+s%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p&#92;ne s&#039;" class="latex" />. The polynomials <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=s%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#039;" class="latex" /> have degree <img src="https://s0.wp.com/latex.php?latex=%5Cle+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le d" class="latex" />. Hence by Lemma <a href="#x1-33003r3">2.3<!--tex4ht:ref: lem:schwartz-zippel --></a></p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BQ_%7B1%7D%7D%5Bp%28Q_%7B1%7D%29%5Cne+s%27%28Q_%7B1%7D%29%5D%5Cge+1-d%2Fq.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BQ_%7B1%7D%7D%5Bp%28Q_%7B1%7D%29%5Cne+s%27%28Q_%7B1%7D%29%5D%5Cge+1-d%2Fq.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BQ_%7B1%7D%7D%5Bp%28Q_%7B1%7D%29%5Cne+s%27%28Q_%7B1%7D%29%5D%5Cge+1-d%2Fq.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{Q_{1}}[p(Q_{1})&#92;ne s&#039;(Q_{1})]&#92;ge 1-d/q. &#92;end{aligned}" class="latex" /></div>
<p>When this event occurs, equation&nbsp;(??) is again false, and we can repeat the argument. Overall, the probability that we maintain a false statement throughout the protocol is <img src="https://s0.wp.com/latex.php?latex=%5Cge+%281-d%2Fq%29%5E%7Bv%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+%281-d%2Fq%29%5E%7Bv%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+%281-d%2Fq%29%5E%7Bv%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge (1-d/q)^{v}" class="latex" />. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-113004r1"></a> <b>Corollary</b> 11.1.  </span>Given  a  3CNF  formula  <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" />  and  <img src="https://s0.wp.com/latex.php?latex=k%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k&#92;in &#92;mathbb {N}" class="latex" />,  deciding  if  <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" />  has  exactly  <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />  satisfying assignments is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BIP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BIP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BIP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {IP}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The proof uses a far-reaching technique: <em>arithmetization. </em>We construct an arithmetic circuit <img src="https://s0.wp.com/latex.php?latex=C_%7B%5Cphi+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7B%5Cphi+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7B%5Cphi+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{&#92;phi }" class="latex" /> over a field <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}" class="latex" /> which agrees with <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> on <em>boolean </em>inputs<em>, </em>but<em> </em>that can then be evaluated over other elements of the field.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-113005r4"></a> <b>Exercise</b> 11.4.  </span>Prove Corollary <a href="#x1-113004r1">11.1<!--tex4ht:ref: cor:=000023sat-IP --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The study of interactive proofs is rich. Many aspects are of interest, including:</p>
<ul class="itemize1">
<li class="itemize">The efficiency of the prover (does it have to be unbounded, randomized, etc.), and of       the verifier.</li>
<li class="itemize">The number of rounds.</li>
<li class="itemize">The tradeoff betwen the error and the other parameters.</li>
</ul>
<h3 class="likesectionHead"><a id="x1-11700012.2"></a>References</h3>
<p style="text-align:justify">
<div class="thebibliography">
<p class="bibitem"><span class="biblabel">   [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness      results for LCS and other sequence similarity measures.  In Venkatesan Guruswami,      editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS      2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59â78. IEEE Computer Society,      2015.</p>
<p class="bibitem"><span class="biblabel">   [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard  Adleman.   Two  theorems  on  random  polynomial  time.   In  19th IEEE      Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75â83. 1978.</p>
<p class="bibitem"><span class="biblabel">   [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjt83"></a>Miklï¿½s Ajtai.  <img src="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Sigma &#92;sp {1}&#92;sb {1}" class="latex" />-formulae on finite structures.  Annals of Pure and Applied Logic,      24(1):1â48, 1983.</p>
<p class="bibitem"><span class="biblabel">   [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjtai05"></a>Miklï¿½s Ajtai. A non-linear time lower bound for boolean branching programs. Theory      of Computing, 1(1):149â176, 2005.</p>
<p class="bibitem"><span class="biblabel">   [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAll89"></a>Eric  Allender.   A  note  on  the  power  of  threshold  circuits.   In  30th Symposium      on Foundations of Computer Science, pages 580â584, Research Triangle Park, North      Carolina, 30 Octoberâ1 November 1989. IEEE.</p>
<p class="bibitem"><span class="biblabel">   [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllender01"></a>Eric Allender. The division breakthroughs. Bulletin of the EATCS, 74:61â77, 2001.</p>
<p class="bibitem"><span class="biblabel">   [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllenderK10"></a>Eric  Allender  and  Michal  KouckÃ½.     Amplifying  lower  bounds  by  means  of      self-reducibility. J.&nbsp;of the ACM, 57(3), 2010.</p>
<p class="bibitem"><span class="biblabel">   [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAGHP92"></a>Noga Alon, Oded Goldreich, Johan Hï¿½stad, and Renï¿½ Peralta. Simple constructions      of  almost  <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-wise  independent  random  variables.   Random  Structures  &amp;  Algorithms,      3(3):289â304, 1992.</p>
<p class="bibitem"><span class="biblabel">   [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian      circuits and matchings. J. Comput. Syst. Sci., 18(2):155â193, 1979.</p>
<p class="bibitem"><span class="biblabel">  [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.      Proof  verification  and  the  hardness  of  approximation  problems.    J.&nbsp;of  the  ACM,      45(3):501â555, May 1998.</p>
<p class="bibitem"><span class="biblabel">  [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk.  Edit distance cannot be computed in strongly      subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087â1097, 2018.</p>
<p class="bibitem"><span class="biblabel">  [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBatcher68"></a>Kenneth&nbsp;E. Batcher.  Sorting networks and their applications.  In AFIPS Spring      Joint Computing Conference, volume&nbsp;32, pages 307â314, 1968.</p>
<p class="bibitem"><span class="biblabel">  [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBeameCH86"></a>Paul  Beame,  Stephen&nbsp;A.  Cook,  and  H.&nbsp;James  Hoover.   Log  depth  circuits  for      division and related problems. SIAM J. Comput., 15(4):994â1003, 1986.</p>
<p class="bibitem"><span class="biblabel">  [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBSSV03"></a>Paul Beame, Michael Saks, Xiaodong Sun, and Erik Vee.   Time-space trade-off      lower  bounds  for  randomized  computation  of  decision  problems.   J.&nbsp;of  the  ACM,      50(2):154â195, 2003.</p>
<p class="bibitem"><span class="biblabel">  [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBen-OrC92"></a>Michael Ben-Or and Richard Cleve. Computing algebraic formulas using a constant      number of registers. SIAM J.&nbsp;on Computing, 21(1):54â58, 1992.</p>
<p class="bibitem"><span class="biblabel">  [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/cc/BussW15"></a>Samuel&nbsp;R.  Buss  and  Ryan  Williams.   Limits  on  alternation  trading  proofs  for      time-space lower bounds. Comput. Complex., 24(3):533â600, 2015.</p>
<p class="bibitem"><span class="biblabel">  [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/stoc/ChenT19"></a>Lijie Chen and Roei Tell. Bootstrapping results for threshold circuits &#8220;just beyond&#8221;      known lower bounds.  In Moses Charikar and Edith Cohen, editors, Proceedings of the      51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix,      AZ, USA, June 23-26, 2019, pages 34â41. ACM, 2019.</p>
<p class="bibitem"><span class="biblabel">  [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCleve91"></a>Richard  Cleve.    Towards  optimal  simulations  of  formulas  by  bounded-width                                                                                                                                                                                          programs. Computational Complexity, 1:91â105, 1991.</p>
<p class="bibitem"><span class="biblabel">  [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCook73"></a>Stephen&nbsp;A. Cook. A hierarchy for nondeterministic time complexity. J.&nbsp;of Computer      and System Sciences, 7(4):343â353, 1973.</p>
<p class="bibitem"><span class="biblabel">  [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Csanky76"></a>L.&nbsp;Csanky.     Fast  parallel  matrix  inversion  algorithms.     SIAM  J.  Comput.,      5(4):618â623, 1976.</p>
<p class="bibitem"><span class="biblabel">  [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/Fortnow00"></a>Lance  Fortnow.   Time-space  tradeoffs  for  satisfiability.   J.  Comput.  Syst.  Sci.,      60(2):337â353, 2000.</p>
<p class="bibitem"><span class="biblabel">  [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jct/FraenkelL81"></a>Aviezri&nbsp;S. Fraenkel and David Lichtenstein. Computing a perfect strategy for n x n      chess requires time exponential in n. J. Comb. Theory, Ser. A, 31(2):199â214, 1981.</p>
<p class="bibitem"><span class="biblabel">  [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XFredmanS89"></a>Michael&nbsp;L. Fredman and Michael&nbsp;E. Saks.  The cell probe complexity of dynamic      data structures. In ACM Symp.&nbsp;on the Theory of Computing (STOC), pages 345â354,      1989.</p>
<p class="bibitem"><span class="biblabel">  [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational      geometry. Comput. Geom., 5:165â185, 1995.</p>
<p class="bibitem"><span class="biblabel">  [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the      Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel">  [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;Gï¿½del.   ï¿½ber  formal  unentscheidbare  sï¿½tze  der  Principia  Mathematica  und      verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel">  [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge      University Press, 2008.</p>
<p class="bibitem"><span class="biblabel">  [28]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGreenlawHR-Limits"></a>Raymond  Greenlaw,  H.&nbsp;James  Hoover,  and  Walter  Ruzzo.   Limits  to  Parallel      Computation: P-Completeness Theory. 02 2001.</p>
<p class="bibitem"><span class="biblabel">  [29]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of      Mathematics, 193(2):563 â 617, 2021.</p>
<p class="bibitem"><span class="biblabel">  [30]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie.  One-tape, off-line turing machine computations.  Information and      Control, 8(6):553â578, 1965.</p>
<p class="bibitem"><span class="biblabel">  [31]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred  Hennie  and  Richard  Stearns.    Two-tape  simulation  of  multitape  turing      machines. J.&nbsp;of the ACM, 13:533â546, October 1966.</p>
<p class="bibitem"><span class="biblabel">  [32]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jacm/HopcroftPV77"></a>John&nbsp;E. Hopcroft, Wolfgang&nbsp;J. Paul, and Leslie&nbsp;G. Valiant. On time versus space.      J. ACM, 24(2):332â337, 1977.</p>
<p class="bibitem"><span class="biblabel">  [33]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi.   The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 237â, 1999.</p>
<p class="bibitem"><span class="biblabel">  [34]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImpagliazzoPS97"></a>Russell Impagliazzo, Ramamohan Paturi, and Michael&nbsp;E. Saks. Size-depth tradeoffs      for threshold circuits. SIAM J. Comput., 26(3):693â707, 1997.</p>
<p class="bibitem"><span class="biblabel">  [35]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.  Which problems have      strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512â530, Dec      2001.</p>
<p class="bibitem"><span class="biblabel">  [36]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell  Impagliazzo  and  Avi  Wigderson.    <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" />  if  <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" />  requires  exponential  circuits:      Derandomizing the XOR lemma.  In 29th ACM Symp.&nbsp;on the Theory of Computing      (STOC), pages 220â229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel">  [37]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKarpLi82"></a>Richard&nbsp;M.  Karp  and  Richard&nbsp;J.  Lipton.    Turing  machines  that  take  advice.      LâEnseignement Mathï¿½matique. Revue Internationale. IIe Sï¿½rie, 28(3-4):191â209, 1982.</p>
<p class="bibitem"><span class="biblabel">  [38]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi.  On the structure of one-tape nondeterministic turing machine      time hierarchy. Theor. Comput. Sci., 40:175â193, 1985.</p>
<p class="bibitem"><span class="biblabel">  [39]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/LarsenWY20"></a>Kasper&nbsp;Green Larsen, Omri Weinstein, and Huacheng Yu. Crossing the logarithmic      barrier for dynamic boolean data structure lower bounds.  SIAM J. Comput., 49(5),      2020.</p>
<p class="bibitem"><span class="biblabel">  [40]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A.  Levin.    Universal  sequential  search  problems.    Problemy  Peredachi      Informatsii, 9(3):115â116, 1973.</p>
<p class="bibitem"><span class="biblabel">  [41]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLundFoKaNi92"></a>Carsten Lund, Lance Fortnow, Howard Karloff, and Noam Nisan. Algebraic methods      for interactive proof systems. J.&nbsp;of the ACM, 39(4):859â868, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [42]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120â140, 1958.</p>
<p class="bibitem"><span class="biblabel">  [43]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMaS87"></a>Wolfgang Maass and Amir Schorr. Speed-up of Turing machines with one work tape      and a two-way input tape. SIAM J.&nbsp;on Computing, 16(1):195â202, 1987.</p>
<p class="bibitem"><span class="biblabel">  [44]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBarrington89"></a>David&nbsp;A.  Mix  Barrington.   Bounded-width  polynomial-size  branching  programs      recognize  exactly  those  languages  in  NC<img src="https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^1" class="latex" />.    J.&nbsp;of  Computer  and  System  Sciences,      38(1):150â164, 1989.</p>
<p class="bibitem"><span class="biblabel">  [45]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNaN93"></a>Joseph Naor and Moni Naor.  Small-bias probability spaces: efficient constructions      and applications. SIAM J.&nbsp;on Computing, 22(4):838â856, 1993.</p>
<p class="bibitem"><span class="biblabel">  [46]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNechiporuk66"></a>E.&nbsp;I. Nechiporuk. A boolean function. Soviet Mathematics-Doklady, 169(4):765â766,      1966.</p>
<p class="bibitem"><span class="biblabel">  [47]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNep70"></a>Valery&nbsp;A. NepomnjaÅ¡ÄiÄ­. Rudimentary predicates and Turing calculations. Soviet      Mathematics-Doklady, 11(6):1462â1465, 1970.</p>
<p class="bibitem"><span class="biblabel">  [48]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaNEU-ram2sat-neu-author"></a>NEU. From RAM to SAT. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2012.</p>
<p class="bibitem"><span class="biblabel">                                                                                                                                                                                      [49]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation,      and complexity classes. J. Comput. Syst. Sci., 43(3):425â440, 1991.</p>
<p class="bibitem"><span class="biblabel">  [50]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPPST83"></a>Wolfgang&nbsp;J. Paul, Nicholas Pippenger, Endre Szemerï¿½di, and William&nbsp;T. Trotter.      On determinism versus non-determinism and related problems (preliminary version). In      IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 429â438, 1983.</p>
<p class="bibitem"><span class="biblabel">  [51]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures.      J.&nbsp;of the ACM, 26(2):361â381, 1979.</p>
<p class="bibitem"><span class="biblabel">  [52]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XRaz87"></a>Alexander Razborov. Lower bounds on the dimension of schemes of bounded depth      in a complete basis containing the logical addition function.  Akademiya Nauk SSSR.      Matematicheskie Zametki, 41(4):598â607, 1987.  English translation in Mathematical      Notes of the Academy of Sci. of the USSR, 41(4):333-338, 1987.</p>
<p class="bibitem"><span class="biblabel">  [53]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XReingold08"></a>Omer Reingold. Undirected connectivity in log-space. J.&nbsp;of the ACM, 55(4), 2008.</p>
<p class="bibitem"><span class="biblabel">  [54]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Robson84"></a>J.&nbsp;M.  Robson.    N  by  N  checkers  is  exptime  complete.    SIAM  J.  Comput.,      13(2):252â267, 1984.</p>
<p class="bibitem"><span class="biblabel">  [55]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/coco/Santhanam01"></a>Rahul Santhanam.   On separators, segregators and time versus space.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 286â294, 2001.</p>
<p class="bibitem"><span class="biblabel">  [56]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSAVITCH1970177"></a>Walter&nbsp;J. Savitch.  Relationships between nondeterministic and deterministic tape      complexities. Journal of Computer and System Sciences, 4(2):177â192, 1970.</p>
<p class="bibitem"><span class="biblabel">  [57]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold Schï¿½nhage. Storage modification machines. SIAM J. Comput., 9(3):490â508,      1980.</p>
<p class="bibitem"><span class="biblabel">  [58]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XShamir92"></a>Adi Shamir. IP = PSPACE. J.&nbsp;of the ACM, 39(4):869â877, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [59]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System                                                                                                                                                                                          Tech. J., 28:59â98, 1949.</p>
<p class="bibitem"><span class="biblabel">  [60]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields.      Mathematics of Computation, 54(189):435â447, 1990.</p>
<p class="bibitem"><span class="biblabel">  [61]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSiegel04"></a>Alan Siegel. On universal classes of extremely random constant-time hash functions.      SIAM J.&nbsp;on Computing, 33(3):505â543, 2004.</p>
<p class="bibitem"><span class="biblabel">  [62]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSip83b"></a>Michael Sipser. A complexity theoretic approach to randomness. In ACM Symp.&nbsp;on      the Theory of Computing (STOC), pages 330â335, 1983.</p>
<p class="bibitem"><span class="biblabel">  [63]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSmo87"></a>Roman Smolensky.  Algebraic methods in the theory of lower bounds for Boolean      circuit complexity.  In 19th ACM Symp.&nbsp;on the Theory of Computing (STOC), pages      77â82. ACM, 1987.</p>
<p class="bibitem"><span class="biblabel">  [64]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer.  Cosmological lower bound on the circuit      complexity of a small problem in logic. J. ACM, 49(6):753â784, 2002.</p>
<p class="bibitem"><span class="biblabel">  [65]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XToda91"></a>Seinosuke Toda.   PP is as hard as the polynomial-time hierarchy.   SIAM J.&nbsp;on      Computing, 20(5):865â877, 1991.</p>
<p class="bibitem"><span class="biblabel">  [66]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M.   Turing.      On   computable   numbers,   with   an   application   to   the      entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230â265, 1937.</p>
<p class="bibitem"><span class="biblabel">  [67]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XVal77"></a>Leslie&nbsp;G.  Valiant.   Graph-theoretic  arguments  in  low-level  complexity.   In  6th      Symposium on Mathematical Foundations of Computer Science, volume&nbsp;53 of Lecture      Notes in Computer Science, pages 162â176. Springer, 1977.</p>
<p class="bibitem"><span class="biblabel">  [68]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/ValiantV86"></a>Leslie&nbsp;G. Valiant and Vijay&nbsp;V. Vazirani. NP is as easy as detecting unique solutions.      Theor. Comput. Sci., 47(3):85â93, 1986.</p>
<p class="bibitem"><span class="biblabel">  [69]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMelkebeek06"></a>Dieter  van  Melkebeek.   A  survey  of  lower  bounds  for  satisfiability  and  related                                                                                                                                                                                          problems. Foundations and Trends in Theoretical Computer Science, 2(3):197â303, 2006.</p>
<p class="bibitem"><span class="biblabel">  [70]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/MelkebeekR05"></a>Dieter van Melkebeek and Ran Raz.  A time lower bound for satisfiability.  Theor.      Comput. Sci., 348(2-3):311â320, 2005.</p>
<p class="bibitem"><span class="biblabel">  [71]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/Vinodchandran05"></a>N.&nbsp;V. Vinodchandran.  A note on the circuit complexity of PP.  Theor. Comput.      Sci., 347(1-2):415â418, 2005.</p>
<p class="bibitem"><span class="biblabel">  [72]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaBPvsE"></a>Emanuele Viola.  On approximate majority and probabilistic time.  Computational      Complexity, 18(3):337â375, 2009.</p>
<p class="bibitem"><span class="biblabel">  [73]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-FTTCS09"></a>Emanuele Viola. On the power of small-depth computation. Foundations and Trends      in Theoretical Computer Science, 5(1):1â72, 2009.</p>
<p class="bibitem"><span class="biblabel">  [74]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola.  Reducing 3XOR to listing triangles, an exposition.  Available at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel">  [75]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-datastructurelb-implies-cclb"></a>Emanuele Viola.  Lower bounds for data structures with space close to maximum      imply  circuit  lower  bounds.    Theory  of  Computing,  15:1â9,  2019.    Available  at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>.</p>
<p class="bibitem"><span class="biblabel">  [76]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele  Viola.   Pseudorandom  bits  and  lower  bounds  for  randomized  turing      machines. Theory of Computing, 18(10):1â12, 2022.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T13:20:59Z">Thursday, May 11 2023, 13:20</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/05/11/tcs-talk-wednesday-may-17-justin-gilmer-google/'>TCS+ talk: Wednesday, May 17 â Justin Gilmer, Google</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, May 17th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Justin Gilmer from Google will speak about &#8220;A constant lower bound for Frankl&#8217;s union-closed sets conjecture.&#8221; (abstract below). You can reserve a spot as an individual or a [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, May 17th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Justin Gilmer</strong> from Google will speak about &#8220;<em>A constant lower bound for Frankl&#8217;s union-closed sets conjecture.</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: A finite set system is union-closed if for every pair of sets in the system their union is also in the system. Frankl in 1979 conjectured that for any such system there exists an element which is contained in Â½ of the sets in that system (the only exception being the family containing just the empty set). In this talk I will discuss how a simple observation regarding the contrapositive of Frankl&#8217;s conjecture eventually led to the discovery of an information theoretic approach on the problem and a proof of the first constant lower bound.</p></blockquote>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T10:53:10Z">Thursday, May 11 2023, 10:53</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/05/11/postdoc-at-aarhus-university-apply-by-january-6-2023/'>postdoc at Aarhus University (apply by January 6, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A post doc position in theoretical aspects of machine learning is available. The post doc is under the supervision of Professor Kasper Green Larsen, Aarhus University, Denmark. Candidates with expertise in theoretical computer science and/or machine learning are preferred. Website: clin.medarbejdere.au.dk/en/postgraduate-clinical-associate-professors/job-openings/job/post-doc-position-in-theoretical-aspects-of-machine-learning-at-computer-science-aarhus-university-1 Email: larsen@cs.au.dk
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A post doc position in theoretical aspects of machine learning is<br />
available. The post doc is under the supervision of Professor Kasper Green Larsen, Aarhus University, Denmark.</p>
<p>Candidates with expertise in theoretical computer science<br />
and/or machine learning are preferred.</p>
<p>Website: <a href="https://clin.medarbejdere.au.dk/en/postgraduate-clinical-associate-professors/job-openings/job/post-doc-position-in-theoretical-aspects-of-machine-learning-at-computer-science-aarhus-university-1">https://clin.medarbejdere.au.dk/en/postgraduate-clinical-associate-professors/job-openings/job/post-doc-position-in-theoretical-aspects-of-machine-learning-at-computer-science-aarhus-university-1</a><br />
Email: larsen@cs.au.dk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T09:10:21Z">Thursday, May 11 2023, 09:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/05/11/amnon-shashuas-lecture-at-reichman-university-a-deep-dive-into-llms-and-their-future-impact/'>Amnon Shashuaâs lecture at Reichman University: A Deep Dive into LLMs and their Future Impact.</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          LLM is the acronym for &#8220;large language model&#8221; like GPT-3, ChatGPT, GPT-4 etc. Amnon Shashua gave an enlightening clear lecture about the repeated recent breakthroughs for LLM&#8217;s and where we stand. Here is the You-Tube link for the lecture (in &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p></p>


<p>LLM is the acronym for &#8220;large language model&#8221; like GPT-3, ChatGPT, GPT-4 etc. Amnon Shashua gave an enlightening clear lecture about the repeated recent breakthroughs for LLM&#8217;s and where we stand. Here is the <a href="https://youtu.be/Qz3q6jcknHE">You-Tube link</a> for the lecture (in Hebrew) and I will try to add a link for the slides (which are in English). <strong>Update:</strong> <a title="LLMs-RUNI" href="https://gilkalai.files.wordpress.com/2023/05/llms-runi.pdf">Here are the slides.</a> One aspect of the story that I find mind boggling is that adding to the model the ability to program for the purpose of writing code, led also to improved language abilities! (As a matter of fact, everything about LLMs is mind boggling!)Â </p>
<p><iframe class="youtube-player" width="640" height="360" src="https://www.youtube.com/embed/Qz3q6jcknHE?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></p>
<p>Two weeks ago Amnon Shasua was awarded the <a href="https://en.wikipedia.org/wiki/Israel_Prize">Israel prize</a>, regarded as the state&#8217;s highest cultural honor. In his words on behalf of the recipients, Amnon emphasized the need to keepÂ  the independence and stature of the Israeli court systems. <span style="color: #0000ff"><strong>Congratulations, Amnon! </strong></span></p>
<p>Let me also mention that as part of a project (in its early stages) with Maya Bar-Hillel and Daphna Shahaf, last summer we performed several little experiments with various AI programs and below are some entertaining related Dalle-E2 pictures. Here is <a href="https://youtu.be/92T34rp6H6Q">another intersting video</a> where <a href="https://youtu.be/92T34rp6H6Q">Liron Lishinsky-Fisher</a> describes eight AI applications.Â </p>
<p><img loading="lazy" data-attachment-id="24245" data-permalink="https://gilkalai.wordpress.com/2023/05/11/amnon-shashuas-lecture-at-reichman-university-a-deep-dive-into-llms-and-their-future-impact/ai21-labs/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg" data-orig-size="2048,1365" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Roei Shor&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;\u00a9 2022 Roei Shor, all rights reserved.&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;AI21 labs&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="AI21 labs" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg?w=640" class="alignnone size-full wp-image-24245" src="https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg" alt="AI21 labs" width="2048" height="1365" srcset="https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg 2048w, https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg?w=150&amp;h=100 150w, https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg?w=300&amp;h=200 300w, https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg?w=768&amp;h=512 768w, https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg?w=1024&amp;h=683 1024w" sizes="(max-width: 2048px) 100vw, 2048px" /></p>
<p><a href="https://en.wikipedia.org/wiki/AI21_Labs">AI21</a> founders: Yoav Shoham, Ori Goshen, and Amnon Shashua. (Roei Shor Photography, <a href="https://www.timesofisrael.com/ai21-labs-co-founded-by-amnon-shashua-rolls-out-ai-feature-to-spice-up-writing/">source</a>)</p>
<p><img loading="lazy" data-attachment-id="24241" data-permalink="https://gilkalai.wordpress.com/2023/05/11/amnon-shashuas-lecture-at-reichman-university-a-deep-dive-into-llms-and-their-future-impact/fish2/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/fish2.jpg" data-orig-size="835,813" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fish2" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/fish2.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/fish2.jpg?w=640" class="alignnone size-full wp-image-24241" src="https://gilkalai.files.wordpress.com/2023/05/fish2.jpg" alt="fish2" width="835" height="813" srcset="https://gilkalai.files.wordpress.com/2023/05/fish2.jpg 835w, https://gilkalai.files.wordpress.com/2023/05/fish2.jpg?w=150&amp;h=146 150w, https://gilkalai.files.wordpress.com/2023/05/fish2.jpg?w=300&amp;h=292 300w, https://gilkalai.files.wordpress.com/2023/05/fish2.jpg?w=768&amp;h=748 768w" sizes="(max-width: 835px) 100vw, 835px" /></p>
<p><span style="color: #ff0000"><strong>Prompt: <span class="x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x xudqn12 x3x7a5m x6prxxf xvq8zen xo1l8bm xzsf02u x1yc453h" dir="auto">Steve is walking from the city hall toward the big fish and Andrew is walking from the big fish toward the city hall.</span></strong></span></p>
<p><img loading="lazy" data-attachment-id="24243" data-permalink="https://gilkalai.wordpress.com/2023/05/11/amnon-shashuas-lecture-at-reichman-university-a-deep-dive-into-llms-and-their-future-impact/dall%c2%b7e-2023-02-07-20-51-25-cecil-is-a-criminal-lawyer-show-a-picture-of-cecil-at-age-of-two/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/dallc2b7e-2023-02-07-20.51.25-cecil-is-a-criminal-lawyer.-show-a-picture-of-cecil-at-age-of-two.png" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="DALLÂ·E 2023-02-07 20.51.25 &#8211; Cecil is a criminal lawyer. Show a picture of Cecil at age of two." data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/dallc2b7e-2023-02-07-20.51.25-cecil-is-a-criminal-lawyer.-show-a-picture-of-cecil-at-age-of-two.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/dallc2b7e-2023-02-07-20.51.25-cecil-is-a-criminal-lawyer.-show-a-picture-of-cecil-at-age-of-two.png?w=640" class="alignnone size-full wp-image-24243" src="https://gilkalai.files.wordpress.com/2023/05/dallc2b7e-2023-02-07-20.51.25-cecil-is-a-criminal-lawyer.-show-a-picture-of-cecil-at-age-of-two.png" alt="DALLÂ·E 2023-02-07 20.51.25 - Cecil is a criminal lawyer. Show a picture of Cecil at age of two." width="1024" height="1024" srcset="https://gilkalai.files.wordpress.com/2023/05/dallc2b7e-2023-02-07-20.51.25-cecil-is-a-criminal-lawyer.-show-a-picture-of-cecil-at-age-of-two.png 1024w, https://gilkalai.files.wordpress.com/2023/05/dallc2b7e-2023-02-07-20.51.25-cecil-is-a-criminal-lawyer.-show-a-picture-of-cecil-at-age-of-two.png?w=150&amp;h=150 150w, https://gilkalai.files.wordpress.com/2023/05/dallc2b7e-2023-02-07-20.51.25-cecil-is-a-criminal-lawyer.-show-a-picture-of-cecil-at-age-of-two.png?w=300&amp;h=300 300w, https://gilkalai.files.wordpress.com/2023/05/dallc2b7e-2023-02-07-20.51.25-cecil-is-a-criminal-lawyer.-show-a-picture-of-cecil-at-age-of-two.png?w=768&amp;h=768 768w" sizes="(max-width: 1024px) 100vw, 1024px" /></p>
<p><strong><span style="color: #ff0000">A criminal lawyer at the age of two.</span></strong></p><p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T05:31:20Z">Thursday, May 11 2023, 05:31</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05676'>Scheme-Theoretic Approach to Computational Complexity. IV. A New Perspective on Hardness of Approximation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ali &#xc7;ivril</p><p>We provide a new approach for establishing hardness of approximation results,
based on the theory recently introduced by the author. It allows one to
directly show that approximating a problem beyond a certain threshold requires
super-polynomial time. To exhibit the framework, we revisit two famous problems
in this paper. The particular results we prove are:
</p>
<p>MAX-3-SAT$(1,\frac{7}{8}+\epsilon)$ requires exponential time for any
constant $\epsilon$ satisfying $\frac{1}{8} \geq \epsilon &gt; 0$. In particular,
the gap exponential time hypothesis (Gap-ETH) holds.
</p>
<p>MAX-3-LIN-2$(1-\epsilon, \frac{1}{2}+\epsilon)$ requires exponential time for
any constant $\epsilon$ satisfying $\frac{1}{4} \geq \epsilon &gt; 0$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Civril_A/0/1/0/all/0/1">Ali &#xc7;ivril</a></p><p>We provide a new approach for establishing hardness of approximation results,
based on the theory recently introduced by the author. It allows one to
directly show that approximating a problem beyond a certain threshold requires
super-polynomial time. To exhibit the framework, we revisit two famous problems
in this paper. The particular results we prove are:
</p>
<p>MAX-3-SAT$(1,\frac{7}{8}+\epsilon)$ requires exponential time for any
constant $\epsilon$ satisfying $\frac{1}{8} \geq \epsilon &gt; 0$. In particular,
the gap exponential time hypothesis (Gap-ETH) holds.
</p>
<p>MAX-3-LIN-2$(1-\epsilon, \frac{1}{2}+\epsilon)$ requires exponential time for
any constant $\epsilon$ satisfying $\frac{1}{4} \geq \epsilon &gt; 0$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05765'>On the average-case complexity of learning output distributions of quantum circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Nietner, Marios Ioannou, Ryan Sweke, Richard Kueng, Jens Eisert, Marcel Hinsche, Jonas Haferkamp</p><p>In this work, we show that learning the output distributions of brickwork
random quantum circuits is average-case hard in the statistical query model.
This learning model is widely used as an abstract computational model for most
generic learning algorithms. In particular, for brickwork random quantum
circuits on $n$ qubits of depth $d$, we show three main results:
</p>
<p>- At super logarithmic circuit depth $d=\omega(\log(n))$, any learning
algorithm requires super polynomially many queries to achieve a constant
probability of success over the randomly drawn instance.
</p>
<p>- There exists a $d=O(n)$, such that any learning algorithm requires
$\Omega(2^n)$ queries to achieve a $O(2^{-n})$ probability of success over the
randomly drawn instance.
</p>
<p>- At infinite circuit depth $d\to\infty$, any learning algorithm requires
$2^{2^{\Omega(n)}}$ many queries to achieve a $2^{-2^{\Omega(n)}}$ probability
of success over the randomly drawn instance.
</p>
<p>As an auxiliary result of independent interest, we show that the output
distribution of a brickwork random quantum circuit is constantly far from any
fixed distribution in total variation distance with probability $1-O(2^{-n})$,
which confirms a variant of a conjecture by Aaronson and Chen.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Nietner_A/0/1/0/all/0/1">Alexander Nietner</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ioannou_M/0/1/0/all/0/1">Marios Ioannou</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sweke_R/0/1/0/all/0/1">Ryan Sweke</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kueng_R/0/1/0/all/0/1">Richard Kueng</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Eisert_J/0/1/0/all/0/1">Jens Eisert</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hinsche_M/0/1/0/all/0/1">Marcel Hinsche</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Haferkamp_J/0/1/0/all/0/1">Jonas Haferkamp</a></p><p>In this work, we show that learning the output distributions of brickwork
random quantum circuits is average-case hard in the statistical query model.
This learning model is widely used as an abstract computational model for most
generic learning algorithms. In particular, for brickwork random quantum
circuits on $n$ qubits of depth $d$, we show three main results:
</p>
<p>- At super logarithmic circuit depth $d=\omega(\log(n))$, any learning
algorithm requires super polynomially many queries to achieve a constant
probability of success over the randomly drawn instance.
</p>
<p>- There exists a $d=O(n)$, such that any learning algorithm requires
$\Omega(2^n)$ queries to achieve a $O(2^{-n})$ probability of success over the
randomly drawn instance.
</p>
<p>- At infinite circuit depth $d\to\infty$, any learning algorithm requires
$2^{2^{\Omega(n)}}$ many queries to achieve a $2^{-2^{\Omega(n)}}$ probability
of success over the randomly drawn instance.
</p>
<p>As an auxiliary result of independent interest, we show that the output
distribution of a brickwork random quantum circuit is constantly far from any
fixed distribution in total variation distance with probability $1-O(2^{-n})$,
which confirms a variant of a conjecture by Aaronson and Chen.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05808'>On the Information Capacity of Nearest Neighbor Representations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kordag Mehmet Kilic, Jin Sima, Jehoshua Bruck</p><p>The $\textit{von Neumann Computer Architecture}$ has a distinction between
computation and memory. In contrast, the brain has an integrated architecture
where computation and memory are indistinguishable. Motivated by the
architecture of the brain, we propose a model of $\textit{associative
computation}$ where memory is defined by a set of vectors in $\mathbb{R}^n$
(that we call $\textit{anchors}$), computation is performed by convergence from
an input vector to a nearest neighbor anchor, and the output is a label
associated with an anchor. Specifically, in this paper, we study the
representation of Boolean functions in the associative computation model, where
the inputs are binary vectors and the corresponding outputs are the labels ($0$
or $1$) of the nearest neighbor anchors. The information capacity of a Boolean
function in this model is associated with two quantities: $\textit{(i)}$ the
number of anchors (called $\textit{Nearest Neighbor (NN) Complexity}$) and
$\textit{(ii)}$ the maximal number of bits representing entries of anchors
(called $\textit{Resolution}$). We study symmetric Boolean functions and
present constructions that have optimal NN complexity and resolution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kilic_K/0/1/0/all/0/1">Kordag Mehmet Kilic</a>, <a href="http://arxiv.org/find/cs/1/au:+Sima_J/0/1/0/all/0/1">Jin Sima</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruck_J/0/1/0/all/0/1">Jehoshua Bruck</a></p><p>The $\textit{von Neumann Computer Architecture}$ has a distinction between
computation and memory. In contrast, the brain has an integrated architecture
where computation and memory are indistinguishable. Motivated by the
architecture of the brain, we propose a model of $\textit{associative
computation}$ where memory is defined by a set of vectors in $\mathbb{R}^n$
(that we call $\textit{anchors}$), computation is performed by convergence from
an input vector to a nearest neighbor anchor, and the output is a label
associated with an anchor. Specifically, in this paper, we study the
representation of Boolean functions in the associative computation model, where
the inputs are binary vectors and the corresponding outputs are the labels ($0$
or $1$) of the nearest neighbor anchors. The information capacity of a Boolean
function in this model is associated with two quantities: $\textit{(i)}$ the
number of anchors (called $\textit{Nearest Neighbor (NN) Complexity}$) and
$\textit{(ii)}$ the maximal number of bits representing entries of anchors
(called $\textit{Resolution}$). We study symmetric Boolean functions and
present constructions that have optimal NN complexity and resolution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06064'>DNN Verification, Reachability, and the Exponential Function Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Omri Isac, Yoni Zohar, Clark Barrett, Guy Katz</p><p>Deep neural networks (DNNs) are increasingly being deployed to perform
safety-critical tasks. The opacity of DNNs, which prevents humans from
reasoning about them, presents new safety and security challenges. To address
these challenges, the verification community has begun developing techniques
for rigorously analyzing DNNs, with numerous verification algorithms proposed
in recent years. While a significant amount of work has gone into developing
these verification algorithms, little work has been devoted to rigorously
studying the computability and complexity of the underlying theoretical
problems. Here, we seek to contribute to the bridging of this gap. We focus on
two kinds of DNNs: those that employ piecewise-linear activation functions
(e.g., ReLU), and those that employ piecewise-smooth activation functions
(e.g., Sigmoids). We prove the two following theorems: 1) The decidability of
verifying DNNs with piecewise-smooth activation functions is equivalent to a
well-known, open problem formulated by Tarski; and 2) The DNN verification
problem for any quantifier-free linear arithmetic specification can be reduced
to the DNN reachability problem, whose approximation is NP-complete. These
results answer two fundamental questions about the computability and complexity
of DNN verification, and the ways it is affected by the network's activation
functions and error tolerance; and could help guide future efforts in
developing DNN verification tools.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Isac_O/0/1/0/all/0/1">Omri Isac</a>, <a href="http://arxiv.org/find/cs/1/au:+Zohar_Y/0/1/0/all/0/1">Yoni Zohar</a>, <a href="http://arxiv.org/find/cs/1/au:+Barrett_C/0/1/0/all/0/1">Clark Barrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1">Guy Katz</a></p><p>Deep neural networks (DNNs) are increasingly being deployed to perform
safety-critical tasks. The opacity of DNNs, which prevents humans from
reasoning about them, presents new safety and security challenges. To address
these challenges, the verification community has begun developing techniques
for rigorously analyzing DNNs, with numerous verification algorithms proposed
in recent years. While a significant amount of work has gone into developing
these verification algorithms, little work has been devoted to rigorously
studying the computability and complexity of the underlying theoretical
problems. Here, we seek to contribute to the bridging of this gap. We focus on
two kinds of DNNs: those that employ piecewise-linear activation functions
(e.g., ReLU), and those that employ piecewise-smooth activation functions
(e.g., Sigmoids). We prove the two following theorems: 1) The decidability of
verifying DNNs with piecewise-smooth activation functions is equivalent to a
well-known, open problem formulated by Tarski; and 2) The DNN verification
problem for any quantifier-free linear arithmetic specification can be reduced
to the DNN reachability problem, whose approximation is NP-complete. These
results answer two fundamental questions about the computability and complexity
of DNN verification, and the ways it is affected by the network's activation
functions and error tolerance; and could help guide future efforts in
developing DNN verification tools.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06093'>Deterministic and Strongly Nondeterministic Decision Trees for Decision Tables from Closed Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Azimkhon Ostonov, Mikhail Moshkov</p><p>In this paper, we consider classes of decision tables with 0-1-decisions
closed relative to removal of attributes (columns) and changing decisions
assigned to rows. For tables from an arbitrary closed class, we study the
dependence of the minimum complexity of deterministic decision trees on various
parameters of the tables: the minimum complexity of a test, the complexity of
the set of attributes attached to columns, and the minimum complexity of a
strongly nondeterministic decision tree. We also study the dependence of the
minimum complexity of strongly nondeterministic decision trees on the
complexity of the set of attributes attached to columns. Note that a strongly
nondeterministic decision tree can be interpreted as a set of true decision
rules that cover all rows labeled with the decision 1.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ostonov_A/0/1/0/all/0/1">Azimkhon Ostonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshkov_M/0/1/0/all/0/1">Mikhail Moshkov</a></p><p>In this paper, we consider classes of decision tables with 0-1-decisions
closed relative to removal of attributes (columns) and changing decisions
assigned to rows. For tables from an arbitrary closed class, we study the
dependence of the minimum complexity of deterministic decision trees on various
parameters of the tables: the minimum complexity of a test, the complexity of
the set of attributes attached to columns, and the minimum complexity of a
strongly nondeterministic decision tree. We also study the dependence of the
minimum complexity of strongly nondeterministic decision trees on the
complexity of the set of attributes attached to columns. Note that a strongly
nondeterministic decision tree can be interpreted as a set of true decision
rules that cover all rows labeled with the decision 1.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06146'>Shape Formation and Locomotion with Joint Movements in the Amoebot Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andreas Padalkin, Manish Kumar, Christian Scheideler</p><p>We are considering the geometric amoebot model where a set of $n$ amoebots is
placed on the triangular grid. An amoebot is able to send information to its
neighbors, and to move via expansions and contractions. Since amoebots and
information can only travel node by node, most problems have a natural lower
bound of $\Omega(D)$ where $D$ denotes the diameter of the structure. Inspired
by the nervous and muscular system, Feldmann et al. have proposed the
reconfigurable circuit extension and the joint movement extension of the
amoebot model with the goal of breaking this lower bound.
</p>
<p>In the joint movement extension, the way amoebots move is altered. Amoebots
become able to push and pull other amoebots. Feldmann et al. demonstrated the
power of joint movements by transforming a line of amoebots into a rhombus
within $O(\log n)$ rounds. However, they left the details of the extension
open. The goal of this paper is therefore to formalize and extend the joint
movement extension. In order to provide a proof of concept for the extension,
we consider two fundamental problems of modular robot systems: shape formation
and locomotion.
</p>
<p>We approach these problems by defining meta-modules of rhombical and
hexagonal shape, respectively. The meta-modules are capable of movement
primitives like sliding, rotating, and tunneling. This allows us to simulate
shape formation algorithms of various modular robot systems. Finally, we
construct three amoebot structures capable of locomotion by rolling, crawling,
and walking, respectively.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Padalkin_A/0/1/0/all/0/1">Andreas Padalkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1">Manish Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheideler_C/0/1/0/all/0/1">Christian Scheideler</a></p><p>We are considering the geometric amoebot model where a set of $n$ amoebots is
placed on the triangular grid. An amoebot is able to send information to its
neighbors, and to move via expansions and contractions. Since amoebots and
information can only travel node by node, most problems have a natural lower
bound of $\Omega(D)$ where $D$ denotes the diameter of the structure. Inspired
by the nervous and muscular system, Feldmann et al. have proposed the
reconfigurable circuit extension and the joint movement extension of the
amoebot model with the goal of breaking this lower bound.
</p>
<p>In the joint movement extension, the way amoebots move is altered. Amoebots
become able to push and pull other amoebots. Feldmann et al. demonstrated the
power of joint movements by transforming a line of amoebots into a rhombus
within $O(\log n)$ rounds. However, they left the details of the extension
open. The goal of this paper is therefore to formalize and extend the joint
movement extension. In order to provide a proof of concept for the extension,
we consider two fundamental problems of modular robot systems: shape formation
and locomotion.
</p>
<p>We approach these problems by defining meta-modules of rhombical and
hexagonal shape, respectively. The meta-modules are capable of movement
primitives like sliding, rotating, and tunneling. This allows us to simulate
shape formation algorithms of various modular robot systems. Finally, we
construct three amoebot structures capable of locomotion by rolling, crawling,
and walking, respectively.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06315'>NervePool: A Simplicial Pooling Layer</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sarah McGuire, Elizabeth Munch, Matthew Hirn</p><p>For deep learning problems on graph-structured data, pooling layers are
important for down sampling, reducing computational cost, and to minimize
overfitting. We define a pooling layer, NervePool, for data structured as
simplicial complexes, which are generalizations of graphs that include
higher-dimensional simplices beyond vertices and edges; this structure allows
for greater flexibility in modeling higher-order relationships. The proposed
simplicial coarsening scheme is built upon partitions of vertices, which allow
us to generate hierarchical representations of simplicial complexes, collapsing
information in a learned fashion. NervePool builds on the learned vertex
cluster assignments and extends to coarsening of higher dimensional simplices
in a deterministic fashion. While in practice, the pooling operations are
computed via a series of matrix operations, the topological motivation is a
set-theoretic construction based on unions of stars of simplices and the nerve
complex
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+McGuire_S/0/1/0/all/0/1">Sarah McGuire</a>, <a href="http://arxiv.org/find/cs/1/au:+Munch_E/0/1/0/all/0/1">Elizabeth Munch</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirn_M/0/1/0/all/0/1">Matthew Hirn</a></p><p>For deep learning problems on graph-structured data, pooling layers are
important for down sampling, reducing computational cost, and to minimize
overfitting. We define a pooling layer, NervePool, for data structured as
simplicial complexes, which are generalizations of graphs that include
higher-dimensional simplices beyond vertices and edges; this structure allows
for greater flexibility in modeling higher-order relationships. The proposed
simplicial coarsening scheme is built upon partitions of vertices, which allow
us to generate hierarchical representations of simplicial complexes, collapsing
information in a learned fashion. NervePool builds on the learned vertex
cluster assignments and extends to coarsening of higher dimensional simplices
in a deterministic fashion. While in practice, the pooling operations are
computed via a series of matrix operations, the topological motivation is a
set-theoretic construction based on unions of stars of simplices and the nerve
complex
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05671'>Parallel External Sorting of ASCII Records Using Learned Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ani Kristo, Tim Kraska</p><p>External sorting is at the core of many operations in large-scale database
systems, such as ordering and aggregation queries for large result sets,
building indexes, sort-merge joins, duplicate removal, sharding, and record
clustering. Unlike in-memory sorting, these algorithms need to work together
with the OS and the filesystem to efficiently utilize system resources and
minimize disk I/O.
</p>
<p>In this paper we describe ELSAR: a parallel external sorting algorithm that
uses an innovative paradigm based on a learned data distribution model. The
algorithm leverages the model to arrange the input records into mutually
exclusive, monotonic, and equi-depth partitions that, once sorted, can simply
be concatenated to form the output. This method completely eliminates the need
for multi-way file merging, which is typically used in external sorting.
</p>
<p>We present thorough benchmarks for uniform and skewed datasets in various
storage media, where we measure the sorting rates, size scalability, and energy
efficiency of ELSAR and other sorting algorithms. We observed that ELSAR has up
to 1.65x higher sorting rates than the next-best external sort (Nsort) on SSD
drives and 5.31x higher than the GNU coreutils' sort utility on Intel Optane
non-volatile memory. In addition, ELSAR supersedes the current winner of the
SortBenchmark for the most energy-efficient external string sorting algorithm
by an impressive margin of 41%.
</p>
<p>These results reinforce the premise that novel learning-enhanced algorithms
can provide remarkable performance benefits over traditional ones.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kristo_A/0/1/0/all/0/1">Ani Kristo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kraska_T/0/1/0/all/0/1">Tim Kraska</a></p><p>External sorting is at the core of many operations in large-scale database
systems, such as ordering and aggregation queries for large result sets,
building indexes, sort-merge joins, duplicate removal, sharding, and record
clustering. Unlike in-memory sorting, these algorithms need to work together
with the OS and the filesystem to efficiently utilize system resources and
minimize disk I/O.
</p>
<p>In this paper we describe ELSAR: a parallel external sorting algorithm that
uses an innovative paradigm based on a learned data distribution model. The
algorithm leverages the model to arrange the input records into mutually
exclusive, monotonic, and equi-depth partitions that, once sorted, can simply
be concatenated to form the output. This method completely eliminates the need
for multi-way file merging, which is typically used in external sorting.
</p>
<p>We present thorough benchmarks for uniform and skewed datasets in various
storage media, where we measure the sorting rates, size scalability, and energy
efficiency of ELSAR and other sorting algorithms. We observed that ELSAR has up
to 1.65x higher sorting rates than the next-best external sort (Nsort) on SSD
drives and 5.31x higher than the GNU coreutils' sort utility on Intel Optane
non-volatile memory. In addition, ELSAR supersedes the current winner of the
SortBenchmark for the most energy-efficient external string sorting algorithm
by an impressive margin of 41%.
</p>
<p>These results reinforce the premise that novel learning-enhanced algorithms
can provide remarkable performance benefits over traditional ones.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05763'>On the Number of $t$-Lee-Error-Correcting Codes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nadja Willenborg, Anna-Lena Horlemann, Violetta Weger</p><p>We consider $t$-Lee-error-correcting codes of length $n$ over the residue
ring $\mathbb{Z}_m := \mathbb{Z}/m\mathbb{Z}$ and determine upper and lower
bounds on the number of $t$-Lee-error-correcting codes. We use two different
methods, namely estimating isolated nodes on bipartite graphs and the graph
container method. The former gives density results for codes of fixed size and
the latter for any size. This confirms some recent density results for linear
Lee metric codes and provides new density results for nonlinear codes. To apply
a variant of the graph container algorithm we also investigate some geometrical
properties of the balls in the Lee metric.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Willenborg_N/0/1/0/all/0/1">Nadja Willenborg</a>, <a href="http://arxiv.org/find/cs/1/au:+Horlemann_A/0/1/0/all/0/1">Anna-Lena Horlemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Weger_V/0/1/0/all/0/1">Violetta Weger</a></p><p>We consider $t$-Lee-error-correcting codes of length $n$ over the residue
ring $\mathbb{Z}_m := \mathbb{Z}/m\mathbb{Z}$ and determine upper and lower
bounds on the number of $t$-Lee-error-correcting codes. We use two different
methods, namely estimating isolated nodes on bipartite graphs and the graph
container method. The former gives density results for codes of fixed size and
the latter for any size. This confirms some recent density results for linear
Lee metric codes and provides new density results for nonlinear codes. To apply
a variant of the graph container algorithm we also investigate some geometrical
properties of the balls in the Lee metric.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05826'>Universal Matrix Sparsifiers and Fast Deterministic Algorithms for Linear Algebra</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rajarshi Bhattacharjee, Gregory Dexter, Cameron Musco, Archan Ray, David P Woodruff</p><p>Given $\mathbf A \in \mathbb{R}^{n \times n}$ with entries bounded in
magnitude by $1$, it is well-known that if $S \subset [n] \times [n]$ is a
uniformly random subset of $\tilde{O} (n/\epsilon^2)$ entries, and if ${\mathbf
A}_S$ equals $\mathbf A$ on the entries in $S$ and is zero elsewhere, then
$\|\mathbf A - \frac{n^2}{s} \cdot {\mathbf A}_S\|_2 \le \epsilon n$ with high
probability, where $\|\cdot\|_2$ is the spectral norm. We show that for
positive semidefinite (PSD) matrices, no randomness is needed at all in this
statement. Namely, there exists a fixed subset $S$ of $\tilde{O}
(n/\epsilon^2)$ entries that acts as a universal sparsifier: the above error
bound holds simultaneously for every bounded entry PSD matrix $\mathbf A \in
\mathbb{R}^{n \times n}$. One can view this result as a significant extension
of a Ramanujan expander graph, which sparsifies any bounded entry PSD matrix,
not just the all ones matrix.
</p>
<p>We leverage the existence of such universal sparsifiers to give the first
deterministic algorithms for several central problems related to singular value
computation that run in faster than matrix multiplication time. We also prove
universal sparsification bounds for non-PSD matrices, showing that $\tilde{O}
(n/\epsilon^4)$ entries suffices to achieve error $\epsilon \cdot
\max(n,\|\mathbf A\|_1)$, where $\|\mathbf A\|_1$ is the trace norm. We prove
that this is optimal up to an $\tilde{O} (1/\epsilon^2)$ factor. Finally, we
give an improved deterministic spectral approximation algorithm for PSD
$\mathbf A$ with entries lying in $\{-1,0,1\}$, which we show is nearly
information-theoretically optimal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharjee_R/0/1/0/all/0/1">Rajarshi Bhattacharjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Dexter_G/0/1/0/all/0/1">Gregory Dexter</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>, <a href="http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1">Archan Ray</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P Woodruff</a></p><p>Given $\mathbf A \in \mathbb{R}^{n \times n}$ with entries bounded in
magnitude by $1$, it is well-known that if $S \subset [n] \times [n]$ is a
uniformly random subset of $\tilde{O} (n/\epsilon^2)$ entries, and if ${\mathbf
A}_S$ equals $\mathbf A$ on the entries in $S$ and is zero elsewhere, then
$\|\mathbf A - \frac{n^2}{s} \cdot {\mathbf A}_S\|_2 \le \epsilon n$ with high
probability, where $\|\cdot\|_2$ is the spectral norm. We show that for
positive semidefinite (PSD) matrices, no randomness is needed at all in this
statement. Namely, there exists a fixed subset $S$ of $\tilde{O}
(n/\epsilon^2)$ entries that acts as a universal sparsifier: the above error
bound holds simultaneously for every bounded entry PSD matrix $\mathbf A \in
\mathbb{R}^{n \times n}$. One can view this result as a significant extension
of a Ramanujan expander graph, which sparsifies any bounded entry PSD matrix,
not just the all ones matrix.
</p>
<p>We leverage the existence of such universal sparsifiers to give the first
deterministic algorithms for several central problems related to singular value
computation that run in faster than matrix multiplication time. We also prove
universal sparsification bounds for non-PSD matrices, showing that $\tilde{O}
(n/\epsilon^4)$ entries suffices to achieve error $\epsilon \cdot
\max(n,\|\mathbf A\|_1)$, where $\|\mathbf A\|_1$ is the trace norm. We prove
that this is optimal up to an $\tilde{O} (1/\epsilon^2)$ factor. Finally, we
give an improved deterministic spectral approximation algorithm for PSD
$\mathbf A$ with entries lying in $\{-1,0,1\}$, which we show is nearly
information-theoretically optimal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05829'>Constant Approximation for Network Revenue Management with Markovian-Correlated Customer Arrivals</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jiashuo Jiang</p><p>The Network Revenue Management (NRM) problem is a well-known challenge in
dynamic decision-making under uncertainty. In this problem, fixed resources
must be allocated to serve customers over a finite horizon, while customers
arrive according to a stochastic process. The typical NRM model assumes that
customer arrivals are independent over time. However, in this paper, we explore
a more general setting where customer arrivals over different periods can be
correlated. We propose a new model that assumes the existence of a system
state, which determines customer arrivals for the current period. This system
state evolves over time according to a time-inhomogeneous Markov chain. Our
model can be used to represent correlation in various settings and synthesizes
previous literature on correlation models.
</p>
<p>To solve the NRM problem under our correlated model, we derive a new linear
programming (LP) approximation of the optimal policy. Our approximation
provides a tighter upper bound on the total expected value collected by the
optimal policy than existing upper bounds. We use our LP to develop a new bid
price policy, which computes bid prices for each system state and time period
in a backward induction manner. The decision is then made by comparing the
reward of the customer against the associated bid prices. Our policy guarantees
to collect at least $1/(1+L)$ fraction of the total reward collected by the
optimal policy, where $L$ denotes the maximum number of resources required by a
customer.
</p>
<p>In summary, our work presents a new model for correlated customer arrivals in
the NRM problem and provides an LP approximation for solving the problem under
this model. We derive a new bid price policy and provides a theoretical
guarantee on the performance of the policy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiashuo Jiang</a></p><p>The Network Revenue Management (NRM) problem is a well-known challenge in
dynamic decision-making under uncertainty. In this problem, fixed resources
must be allocated to serve customers over a finite horizon, while customers
arrive according to a stochastic process. The typical NRM model assumes that
customer arrivals are independent over time. However, in this paper, we explore
a more general setting where customer arrivals over different periods can be
correlated. We propose a new model that assumes the existence of a system
state, which determines customer arrivals for the current period. This system
state evolves over time according to a time-inhomogeneous Markov chain. Our
model can be used to represent correlation in various settings and synthesizes
previous literature on correlation models.
</p>
<p>To solve the NRM problem under our correlated model, we derive a new linear
programming (LP) approximation of the optimal policy. Our approximation
provides a tighter upper bound on the total expected value collected by the
optimal policy than existing upper bounds. We use our LP to develop a new bid
price policy, which computes bid prices for each system state and time period
in a backward induction manner. The decision is then made by comparing the
reward of the customer against the associated bid prices. Our policy guarantees
to collect at least $1/(1+L)$ fraction of the total reward collected by the
optimal policy, where $L$ denotes the maximum number of resources required by a
customer.
</p>
<p>In summary, our work presents a new model for correlated customer arrivals in
the NRM problem and provides an LP approximation for solving the problem under
this model. We derive a new bid price policy and provides a theoretical
guarantee on the performance of the policy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05893'>Acceleration of FM-index Queries Through Prefix-free Parsing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aaron Hong, Marco Oliva, Dominik K&#xf6;ppl, Hideo Bannai, Christina Boucher, Travis Gagie</p><p>FM-indexes are a crucial data structure in DNA alignment, for example, but
searching with them usually takes at least one random access per character in
the query pattern. Ferragina and Fischer observed in 2007 that word-based
indexes often use fewer random accesses than character-based indexes, and thus
support faster searches. Since DNA lacks natural word-boundaries, however, it
is necessary to parse it somehow before applying word-based FM-indexing. Last
year, Deng et al.\ proposed parsing genomic data by induced suffix sorting, and
showed the resulting word-based FM-indexes support faster counting queries than
standard FM-indexes when patterns are a few thousand characters or longer. In
this paper we show that using prefix-free parsing -- which takes parameters
that let us tune the average length of the phrases -- instead of induced suffix
sorting, gives a significant speedup for patterns of only a few hundred
characters. We implement our method and demonstrate it is between 3 and 18
times faster than competing methods on queries to GRCh38. And was consistently
faster on queries made to 25,000, 50,000 and 100,000 SARS-CoV-2 genomes. Hence,
it is very clear that our method accelerates the performance of count over all
state-of-the-art methods with a minor increase in the memory. Our source code
is available at github.com/marco-oliva/afm .
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hong_A/0/1/0/all/0/1">Aaron Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliva_M/0/1/0/all/0/1">Marco Oliva</a>, <a href="http://arxiv.org/find/cs/1/au:+Koppl_D/0/1/0/all/0/1">Dominik K&#xf6;ppl</a>, <a href="http://arxiv.org/find/cs/1/au:+Bannai_H/0/1/0/all/0/1">Hideo Bannai</a>, <a href="http://arxiv.org/find/cs/1/au:+Boucher_C/0/1/0/all/0/1">Christina Boucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1">Travis Gagie</a></p><p>FM-indexes are a crucial data structure in DNA alignment, for example, but
searching with them usually takes at least one random access per character in
the query pattern. Ferragina and Fischer observed in 2007 that word-based
indexes often use fewer random accesses than character-based indexes, and thus
support faster searches. Since DNA lacks natural word-boundaries, however, it
is necessary to parse it somehow before applying word-based FM-indexing. Last
year, Deng et al.\ proposed parsing genomic data by induced suffix sorting, and
showed the resulting word-based FM-indexes support faster counting queries than
standard FM-indexes when patterns are a few thousand characters or longer. In
this paper we show that using prefix-free parsing -- which takes parameters
that let us tune the average length of the phrases -- instead of induced suffix
sorting, gives a significant speedup for patterns of only a few hundred
characters. We implement our method and demonstrate it is between 3 and 18
times faster than competing methods on queries to GRCh38. And was consistently
faster on queries made to 25,000, 50,000 and 100,000 SARS-CoV-2 genomes. Hence,
it is very clear that our method accelerates the performance of count over all
state-of-the-art methods with a minor increase in the memory. Our source code
is available at https://github.com/marco-oliva/afm .
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05953'>Novel Quantum Information Processing Methods and Investigation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhang Ze Yu</p><p>Quantum information processing and its subfield, quantum image processing,
are rapidly growing fields as a result of advancements in the practicality of
quantum mechanics. In this paper, we propose a quantum algorithm for processing
information, such as one-dimensional time series and two-dimensional images, in
the frequency domain. The information of interest is encoded into the magnitude
of probability amplitude or the coefficient of each basis state. The oracle for
filtering operates based on postselection results, and its explicit circuit
design is presented. This oracle is versatile enough to perform all basic
filtering, including high pass, low pass, band pass, band stop, and many other
processing techniques. Finally, we present two novel schemes for transposing
matrices in this paper. They use similar encoding rules but with deliberate
choices in terms of selecting basis states. These schemes could potentially be
useful for other quantum information processing tasks, such as edge detection.
The proposed techniques are implemented on the IBM Qiskit quantum simulator.
Some results are compared with traditional information processing results to
verify their correctness and are presented in this paper.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Yu_Z/0/1/0/all/0/1">Zhang Ze Yu</a></p><p>Quantum information processing and its subfield, quantum image processing,
are rapidly growing fields as a result of advancements in the practicality of
quantum mechanics. In this paper, we propose a quantum algorithm for processing
information, such as one-dimensional time series and two-dimensional images, in
the frequency domain. The information of interest is encoded into the magnitude
of probability amplitude or the coefficient of each basis state. The oracle for
filtering operates based on postselection results, and its explicit circuit
design is presented. This oracle is versatile enough to perform all basic
filtering, including high pass, low pass, band pass, band stop, and many other
processing techniques. Finally, we present two novel schemes for transposing
matrices in this paper. They use similar encoding rules but with deliberate
choices in terms of selecting basis states. These schemes could potentially be
useful for other quantum information processing tasks, such as edge detection.
The proposed techniques are implemented on the IBM Qiskit quantum simulator.
Some results are compared with traditional information processing results to
verify their correctness and are presented in this paper.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05972'>Coding for IBLTs with Listing Guarantees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniella Bar-Lev, Avi Mizrahi, Tuvi Etzion, Ori Rottenstreich, Eitan Yaakobi</p><p>The Invertible Bloom Lookup Table (IBLT) is a probabilistic data structure
for set representation, with applications in network and traffic monitoring. It
is known for its ability to list its elements, an operation that succeeds with
high probability for sufficiently large table. However, listing can fail even
for relatively small sets. This paper extends recent work on the worst-case
analysis of IBLT, which guarantees successful listing for all sets of a certain
size, by introducing more general IBLT schemes. These schemes allow for greater
freedom in the implementation of the insert, delete, and listing operations and
demonstrate that the IBLT memory can be reduced while still maintaining
successful listing guarantees. The paper also explores the time-memory
trade-off of these schemes, some of which are based on linear codes and
\(B_h\)-sequences over finite fields.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bar_Lev_D/0/1/0/all/0/1">Daniella Bar-Lev</a>, <a href="http://arxiv.org/find/cs/1/au:+Mizrahi_A/0/1/0/all/0/1">Avi Mizrahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Etzion_T/0/1/0/all/0/1">Tuvi Etzion</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottenstreich_O/0/1/0/all/0/1">Ori Rottenstreich</a>, <a href="http://arxiv.org/find/cs/1/au:+Yaakobi_E/0/1/0/all/0/1">Eitan Yaakobi</a></p><p>The Invertible Bloom Lookup Table (IBLT) is a probabilistic data structure
for set representation, with applications in network and traffic monitoring. It
is known for its ability to list its elements, an operation that succeeds with
high probability for sufficiently large table. However, listing can fail even
for relatively small sets. This paper extends recent work on the worst-case
analysis of IBLT, which guarantees successful listing for all sets of a certain
size, by introducing more general IBLT schemes. These schemes allow for greater
freedom in the implementation of the insert, delete, and listing operations and
demonstrate that the IBLT memory can be reduced while still maintaining
successful listing guarantees. The paper also explores the time-memory
trade-off of these schemes, some of which are based on linear codes and
\(B_h\)-sequences over finite fields.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05988'>Improving the performance of classical linear algebra iterative methods via hybrid parallelism</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pedro J. Martinez-Ferrer, Tufan Arslan, Vicen&#xe7; Beltran</p><p>We propose fork-join and task-based hybrid implementations of four classical
linear algebra iterative methods (Jacobi, Gauss-Seidel, conjugate gradient and
biconjugate gradient stabilised) as well as variations of them. Algorithms are
duly documented and the corresponding source code is made publicly available
for reproducibility. Both weak and strong scalability benchmarks are conducted
to statistically analyse their relative efficiencies.
</p>
<p>The weak scalability results assert the superiority of a task-based hybrid
parallelisation over MPI-only and fork-join hybrid implementations. Indeed, the
task-based model is able to achieve speedups of up to 25% larger than its
MPI-only counterpart depending on the numerical method and the computational
resources used. For strong scalability scenarios, hybrid methods based on tasks
remain more efficient with moderate computational resources where data locality
does not play an important role. Fork-join hybridisation often yields mixed
results and hence does not present a competitive advantage over a much simpler
MPI approach.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Martinez_Ferrer_P/0/1/0/all/0/1">Pedro J. Martinez-Ferrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Arslan_T/0/1/0/all/0/1">Tufan Arslan</a>, <a href="http://arxiv.org/find/cs/1/au:+Beltran_V/0/1/0/all/0/1">Vicen&#xe7; Beltran</a></p><p>We propose fork-join and task-based hybrid implementations of four classical
linear algebra iterative methods (Jacobi, Gauss-Seidel, conjugate gradient and
biconjugate gradient stabilised) as well as variations of them. Algorithms are
duly documented and the corresponding source code is made publicly available
for reproducibility. Both weak and strong scalability benchmarks are conducted
to statistically analyse their relative efficiencies.
</p>
<p>The weak scalability results assert the superiority of a task-based hybrid
parallelisation over MPI-only and fork-join hybrid implementations. Indeed, the
task-based model is able to achieve speedups of up to 25% larger than its
MPI-only counterpart depending on the numerical method and the computational
resources used. For strong scalability scenarios, hybrid methods based on tasks
remain more efficient with moderate computational resources where data locality
does not play an important role. Fork-join hybridisation often yields mixed
results and hence does not present a competitive advantage over a much simpler
MPI approach.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06067'>Pebble guided Treasure Hunt in Plane</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adri Bhattacharya, Barun Gorain, Partha Sarathi Mandal</p><p>We study the problem of treasure hunt in a Euclidean plane by a mobile agent
with the guidance of pebbles. The initial position of the agent and position of
the treasure are modeled as special points in the Euclidean plane. The treasure
is situated at a distance at most $D&gt;0$ from the initial position of the agent.
The agent has a perfect compass, but an adversary controls the speed of the
agent. Hence, the agent can not measure how much distance it traveled for a
given time. The agent can find the treasure only when it reaches the exact
position of the treasure. The cost of the treasure hunt is defined as the total
distance traveled by the agent before it finds the treasure. The agent has no
prior knowledge of the position of the treasure or the value of $D$. An Oracle,
which knows the treasure's position and the agent's initial location, places
some pebbles to guide the agent towards the treasure. Once decided to move
along some specified angular direction, the agent can decide to change its
direction only when it encounters a pebble or a special point.
</p>
<p>We ask the following central question in this paper:
</p>
<p>``For given $k \ge 0$, What is cheapest treasure hunt algorithm if at most
$k$ pebbles are placed by the Oracle?"
</p>
<p>We show that for $k=1$, there does not exist any treasure hunt algorithm that
finds the treasure with finite cost. We show the existence of an algorithm with
cost $O(D)$ for $k=2$. For $k&gt;8$ we have designed an algorithm that uses $k$
many pebbles to find the treasure with cost $O(k^{2}) + D(\sin\theta' +
\cos\theta')$, where $\theta'=\frac{\pi}{2^{k-8}}$. The second result shows the
existence of an algorithm with cost arbitrarily close to $D$ for sufficiently
large values of $D$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1">Adri Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorain_B/0/1/0/all/0/1">Barun Gorain</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandal_P/0/1/0/all/0/1">Partha Sarathi Mandal</a></p><p>We study the problem of treasure hunt in a Euclidean plane by a mobile agent
with the guidance of pebbles. The initial position of the agent and position of
the treasure are modeled as special points in the Euclidean plane. The treasure
is situated at a distance at most $D&gt;0$ from the initial position of the agent.
The agent has a perfect compass, but an adversary controls the speed of the
agent. Hence, the agent can not measure how much distance it traveled for a
given time. The agent can find the treasure only when it reaches the exact
position of the treasure. The cost of the treasure hunt is defined as the total
distance traveled by the agent before it finds the treasure. The agent has no
prior knowledge of the position of the treasure or the value of $D$. An Oracle,
which knows the treasure's position and the agent's initial location, places
some pebbles to guide the agent towards the treasure. Once decided to move
along some specified angular direction, the agent can decide to change its
direction only when it encounters a pebble or a special point.
</p>
<p>We ask the following central question in this paper:
</p>
<p>``For given $k \ge 0$, What is cheapest treasure hunt algorithm if at most
$k$ pebbles are placed by the Oracle?"
</p>
<p>We show that for $k=1$, there does not exist any treasure hunt algorithm that
finds the treasure with finite cost. We show the existence of an algorithm with
cost $O(D)$ for $k=2$. For $k&gt;8$ we have designed an algorithm that uses $k$
many pebbles to find the treasure with cost $O(k^{2}) + D(\sin\theta' +
\cos\theta')$, where $\theta'=\frac{\pi}{2^{k-8}}$. The second result shows the
existence of an algorithm with cost arbitrarily close to $D$ for sufficiently
large values of $D$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06120'>Average Awake Complexity of MIS and Matching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Ghaffari, Julian Portmann</p><p>Chatterjee, Gmyr, and Pandurangan [PODC 2020] recently introduced the notion
of awake complexity for distributed algorithms, which measures the number of
rounds in which a node is awake. In the other rounds, the node is sleeping and
performs no computation or communication. Measuring the number of awake rounds
can be of significance in many settings of distributed computing, e.g., in
sensor networks where energy consumption is of concern.
</p>
<p>In that paper, Chatterjee et al. provide an elegant randomized algorithm for
the Maximal Independent Set (MIS) problem that achieves an $O(1)$ node-averaged
awake complexity. That is, the average awake time among the nodes is $O(1)$
rounds. However, to achieve that, the algorithm sacrifices the more standard
round complexity measure from the well-known $O(\log n)$ bound of MIS, due to
Luby [STOC'85], to $O(\log^{3.41} n)$ rounds.
</p>
<p>Our first contribution is to present a simple randomized distributed MIS
algorithm that, with high probability, has $O(1)$ node-averaged awake
complexity and $O(\log n)$ worst-case round complexity. Our second, and more
technical contribution, is to show algorithms with the same $O(1)$
node-averaged awake complexity and $O(\log n)$ worst-case round complexity for
$(1+\varepsilon)$-approximation of maximum matching and
$(2+\varepsilon)$-approximation of minimum vertex cover, where $\varepsilon$
denotes an arbitrary small positive constant.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Portmann_J/0/1/0/all/0/1">Julian Portmann</a></p><p>Chatterjee, Gmyr, and Pandurangan [PODC 2020] recently introduced the notion
of awake complexity for distributed algorithms, which measures the number of
rounds in which a node is awake. In the other rounds, the node is sleeping and
performs no computation or communication. Measuring the number of awake rounds
can be of significance in many settings of distributed computing, e.g., in
sensor networks where energy consumption is of concern.
</p>
<p>In that paper, Chatterjee et al. provide an elegant randomized algorithm for
the Maximal Independent Set (MIS) problem that achieves an $O(1)$ node-averaged
awake complexity. That is, the average awake time among the nodes is $O(1)$
rounds. However, to achieve that, the algorithm sacrifices the more standard
round complexity measure from the well-known $O(\log n)$ bound of MIS, due to
Luby [STOC'85], to $O(\log^{3.41} n)$ rounds.
</p>
<p>Our first contribution is to present a simple randomized distributed MIS
algorithm that, with high probability, has $O(1)$ node-averaged awake
complexity and $O(\log n)$ worst-case round complexity. Our second, and more
technical contribution, is to show algorithms with the same $O(1)$
node-averaged awake complexity and $O(\log n)$ worst-case round complexity for
$(1+\varepsilon)$-approximation of maximum matching and
$(2+\varepsilon)$-approximation of minimum vertex cover, where $\varepsilon$
denotes an arbitrary small positive constant.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06198'>Optimal mixing of the down-up walk on independent sets of a given size</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vishesh Jain, Marcus Michelen, Huy Tuan Pham, Thuy-Duong Vuong</p><p>Let $G$ be a graph on $n$ vertices of maximum degree $\Delta$. We show that,
for any $\delta &gt; 0$, the down-up walk on independent sets of size $k \leq
(1-\delta)\alpha_c(\Delta)n$ mixes in time $O_{\Delta,\delta}(k\log{n})$,
thereby resolving a conjecture of Davies and Perkins in an optimal form. Here,
$\alpha_{c}(\Delta)n$ is the NP-hardness threshold for the problem of counting
independent sets of a given size in a graph on $n$ vertices of maximum degree
$\Delta$. Our mixing time has optimal dependence on $k,n$ for the entire range
of $k$; previously, even polynomial mixing was not known. In fact, for $k =
\Omega_{\Delta}(n)$ in this range, we establish a log-Sobolev inequality with
optimal constant $\Omega_{\Delta,\delta}(1/n)$.
</p>
<p>At the heart of our proof are three new ingredients, which may be of
independent interest. The first is a method for lifting
$\ell_\infty$-independence from a suitable distribution on the discrete cube --
in this case, the hard-core model -- to the slice by proving stability of an
Edgeworth expansion using a multivariate zero-free region for the base
distribution. The second is a generalization of the Lee-Yau induction to prove
log-Sobolev inequalities for distributions on the slice with considerably less
symmetry than the uniform distribution. The third is a sharp decomposition-type
result which provides a lossless comparison between the Dirichlet form of the
original Markov chain and that of the so-called projected chain in the presence
of a contractive coupling.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1">Vishesh Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Michelen_M/0/1/0/all/0/1">Marcus Michelen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Huy Tuan Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Vuong_T/0/1/0/all/0/1">Thuy-Duong Vuong</a></p><p>Let $G$ be a graph on $n$ vertices of maximum degree $\Delta$. We show that,
for any $\delta &gt; 0$, the down-up walk on independent sets of size $k \leq
(1-\delta)\alpha_c(\Delta)n$ mixes in time $O_{\Delta,\delta}(k\log{n})$,
thereby resolving a conjecture of Davies and Perkins in an optimal form. Here,
$\alpha_{c}(\Delta)n$ is the NP-hardness threshold for the problem of counting
independent sets of a given size in a graph on $n$ vertices of maximum degree
$\Delta$. Our mixing time has optimal dependence on $k,n$ for the entire range
of $k$; previously, even polynomial mixing was not known. In fact, for $k =
\Omega_{\Delta}(n)$ in this range, we establish a log-Sobolev inequality with
optimal constant $\Omega_{\Delta,\delta}(1/n)$.
</p>
<p>At the heart of our proof are three new ingredients, which may be of
independent interest. The first is a method for lifting
$\ell_\infty$-independence from a suitable distribution on the discrete cube --
in this case, the hard-core model -- to the slice by proving stability of an
Edgeworth expansion using a multivariate zero-free region for the base
distribution. The second is a generalization of the Lee-Yau induction to prove
log-Sobolev inequalities for distributions on the slice with considerably less
symmetry than the uniform distribution. The third is a sharp decomposition-type
result which provides a lossless comparison between the Dirichlet form of the
original Markov chain and that of the so-called projected chain in the presence
of a contractive coupling.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, May 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7299'>Robin Hanson and I discuss the AI future</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          That&#8217;s all. No real post this morning, just an hour-long podcast on YouTube featuring two decades-long veterans of the nerd blogosphere, Robin Hanson and yours truly, talking about AI, trying to articulate various possibilities outside the Yudkowskyan doom scenario. The podcast was Robin&#8217;s idea. Hope you enjoy, and looking forward to your comments! Update: Oh, [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>That&#8217;s all.  No real post this morning, just an <a href="https://www.youtube.com/watch?v=GANvcj019S0">hour-long podcast on YouTube</a> featuring two decades-long veterans of the nerd blogosphere, Robin Hanson and yours truly, talking about AI, trying to articulate various possibilities outside the Yudkowskyan doom scenario.  The podcast was Robin&#8217;s idea.  Hope you enjoy, and looking forward to your comments!</p>



<p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Update: </mark></strong>Oh, and <a href="https://share.transistor.fm/s/33bf25d3">another new podcast</a> is up, with me and Sebastian Hassinger of Amazon/AWS!  Audio only.  Mostly quantum computing but with a little AI thrown in.</p>



<p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Update:</mark></strong> <a href="https://thegradientpub.substack.com/p/scott-aaronson-against-ai-doomerism">Yet another new podcast</a>, with Daniel Bashir of The Gradient.  Daniel titled it &#8220;Against AI Doomerism,&#8221; but it covers a bunch of topics (and I&#8217;d say my views are a bit more complicated than &#8220;anti-doomerist&#8221;&#8230;).</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T13:59:59Z">Wednesday, May 10 2023, 13:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/05/10/phd-postdoc-at-hasso-plattner-institute-apply-by-may-31-2023/'>PhD, Postdoc at Hasso Plattner Institute (apply by May 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Algorithm Engineering group at the Hasso Plattner Institute (HPI) currently hosts about thirty researchers and invites applications for two new Ph.D. Students and/or Postdoctoral Researchers in Algorithms. Website: hpi.de/offers/2023/may-31.html Email: Timo.Koetzing@hpi.de
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Algorithm Engineering group at the Hasso Plattner Institute (HPI) currently hosts about thirty researchers and invites applications for two new Ph.D. Students and/or Postdoctoral Researchers in Algorithms.</p>
<p>Website: <a href="https://hpi.de/offers/2023/may-31.html">https://hpi.de/offers/2023/may-31.html</a><br />
Email: Timo.Koetzing@hpi.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T13:13:11Z">Wednesday, May 10 2023, 13:13</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.04983'>Low-Degree Testing Over Grids</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prashanth Amireddy, Srikanth Srinivasan, Madhu Sudan</p><p>We study the question of local testability of low (constant) degree functions
from a product domain $S_1 \times \dots \times {S}_n$ to a field $\mathbb{F}$,
where ${S_i} \subseteq \mathbb{F}$ can be arbitrary constant sized sets. We
show that this family is locally testable when the grid is "symmetric". That
is, if ${S_i} = {S}$ for all i, there is a probabilistic algorithm using
constantly many queries that distinguishes whether $f$ has a polynomial
representation of degree at most $d$ or is $\Omega(1)$-far from having this
property. In contrast, we show that there exist asymmetric grids with $|{S}_1|
=\dots= |{S}_n| = 3$ for which testing requires $\omega_n(1)$ queries, thereby
establishing that even in the context of polynomials, local testing depends on
the structure of the domain and not just the distance of the underlying code.
</p>
<p>The low-degree testing problem has been studied extensively over the years
and a wide variety of tools have been applied to propose and analyze tests. Our
work introduces yet another new connection in this rich field, by building
low-degree tests out of tests for "junta-degrees". A function $f : {S}_1 \times
\dots \times {S}_n \to {G}$, for an abelian group ${G}$ is said to be a
junta-degree-$d$ function if it is a sum of $d$-juntas. We derive our
low-degree test by giving a new local test for junta-degree-$d$ functions. For
the analysis of our tests, we deduce a small-set expansion theorem for
spherical noise over large grids, which may be of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Amireddy_P/0/1/0/all/0/1">Prashanth Amireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1">Srikanth Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudan_M/0/1/0/all/0/1">Madhu Sudan</a></p><p>We study the question of local testability of low (constant) degree functions
from a product domain $S_1 \times \dots \times {S}_n$ to a field $\mathbb{F}$,
where ${S_i} \subseteq \mathbb{F}$ can be arbitrary constant sized sets. We
show that this family is locally testable when the grid is "symmetric". That
is, if ${S_i} = {S}$ for all i, there is a probabilistic algorithm using
constantly many queries that distinguishes whether $f$ has a polynomial
representation of degree at most $d$ or is $\Omega(1)$-far from having this
property. In contrast, we show that there exist asymmetric grids with $|{S}_1|
=\dots= |{S}_n| = 3$ for which testing requires $\omega_n(1)$ queries, thereby
establishing that even in the context of polynomials, local testing depends on
the structure of the domain and not just the distance of the underlying code.
</p>
<p>The low-degree testing problem has been studied extensively over the years
and a wide variety of tools have been applied to propose and analyze tests. Our
work introduces yet another new connection in this rich field, by building
low-degree tests out of tests for "junta-degrees". A function $f : {S}_1 \times
\dots \times {S}_n \to {G}$, for an abelian group ${G}$ is said to be a
junta-degree-$d$ function if it is a sum of $d$-juntas. We derive our
low-degree test by giving a new local test for junta-degree-$d$ functions. For
the analysis of our tests, we deduce a small-set expansion theorem for
spherical noise over large grids, which may be of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05011'>In Honour of Ted Swart</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Stephen Gismondi</p><p>This is a tribute to my dear life-long friend, mentor and colleague Ted
Swart. It includes anecdotal stories and memories of our times together, and
also includes a new academic contribution in his honour, Teds polytope. Tweeks
made to the Birkhoff polytope Bn endow Teds polytope Tn({\epsilon}) with a
special tunable parameter {\epsilon} = {\epsilon}(n). Observe how Bn can be
viewed as the convex hull of both the TSP polytope, and the set of non-tour
permutation extrema, and, that its extended formulation is compact. Tours
(connected 2-factor permutation matrices when viewed as adjacency matrices) can
be distinguished from non-tours (disconnected 2-factor permutation matrices)
where {\epsilon} scales the magnitude of tweeks made to Bn. For {\epsilon} &gt; 0,
Tn({\epsilon}) is tuned so that the convex hull of extrema corresponding to
transformed tours is lifted from Bn, and separated (by a hyperplane) from the
convex hull of extrema corresponding to translated non-tours. This leads to
creation of the feasible region of an LP model that can decide existence of a
tour in a graph based on an extended formulation of the TSP polytope. That is,
by designing for polynomial-time distinguishable tour extrema embedded in a
subspace disjoint from non-tour extrema, NP-completeness strongholds come into
play, necessarily expressed in a non-compact extended formulation of
Tn({\epsilon}) i.e. a compact extended formulation of the TSP polytope cannot
exist. No matter, Ted would have loved these ideas, and Tn({\epsilon}) might
one day yet be useful in the study of the P versus NP conundrum. In summary,
Tn({\epsilon}) is a perturbed Bn i.e. the convex hull of both an
{\epsilon}-stretched TSP polytope, and the set of translated non-tour
permutation extrema i.e. a TSP-like polytope and separable non-tour extrema.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gismondi_S/0/1/0/all/0/1">Stephen Gismondi</a></p><p>This is a tribute to my dear life-long friend, mentor and colleague Ted
Swart. It includes anecdotal stories and memories of our times together, and
also includes a new academic contribution in his honour, Teds polytope. Tweeks
made to the Birkhoff polytope Bn endow Teds polytope Tn({\epsilon}) with a
special tunable parameter {\epsilon} = {\epsilon}(n). Observe how Bn can be
viewed as the convex hull of both the TSP polytope, and the set of non-tour
permutation extrema, and, that its extended formulation is compact. Tours
(connected 2-factor permutation matrices when viewed as adjacency matrices) can
be distinguished from non-tours (disconnected 2-factor permutation matrices)
where {\epsilon} scales the magnitude of tweeks made to Bn. For {\epsilon} &gt; 0,
Tn({\epsilon}) is tuned so that the convex hull of extrema corresponding to
transformed tours is lifted from Bn, and separated (by a hyperplane) from the
convex hull of extrema corresponding to translated non-tours. This leads to
creation of the feasible region of an LP model that can decide existence of a
tour in a graph based on an extended formulation of the TSP polytope. That is,
by designing for polynomial-time distinguishable tour extrema embedded in a
subspace disjoint from non-tour extrema, NP-completeness strongholds come into
play, necessarily expressed in a non-compact extended formulation of
Tn({\epsilon}) i.e. a compact extended formulation of the TSP polytope cannot
exist. No matter, Ted would have loved these ideas, and Tn({\epsilon}) might
one day yet be useful in the study of the P versus NP conundrum. In summary,
Tn({\epsilon}) is a perturbed Bn i.e. the convex hull of both an
{\epsilon}-stretched TSP polytope, and the set of translated non-tour
permutation extrema i.e. a TSP-like polytope and separable non-tour extrema.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05415'>Scheme-Theoretic Approach to Computational Complexity. III. SETH</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ali &#xc7;ivril</p><p>We show that there exist infinitely many $n \in \mathbb{Z}^+$ such that for
any constant $\epsilon &gt; 0$, any deterministic algorithm to solve
$k$-\textsf{SAT} for $k \geq 3$ must perform at least
$(2^{k-\frac{3}{2}-\epsilon})^{\frac{n}{k+1}}$ operations, where $n$ is the
number of variables in the $k$\textsf{-SAT} instance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Civril_A/0/1/0/all/0/1">Ali &#xc7;ivril</a></p><p>We show that there exist infinitely many $n \in \mathbb{Z}^+$ such that for
any constant $\epsilon &gt; 0$, any deterministic algorithm to solve
$k$-\textsf{SAT} for $k \geq 3$ must perform at least
$(2^{k-\frac{3}{2}-\epsilon})^{\frac{n}{k+1}}$ operations, where $n$ is the
number of variables in the $k$\textsf{-SAT} instance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05055'>CPMA: An Efficient Batch-Parallel Compressed Set Without Pointers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Brian Wheatman, Randal Burns, Ayd&#x131;n Bulu&#xe7;, Helen Xu</p><p>This paper introduces the batch-parallel Compressed Packed Memory Array
(CPMA), a compressed dynamic ordered batch-parallel set data structure based on
the Packed Memory Array (PMA). Traditionally, batch-parallel sets are built on
pointer-based data structures such as trees because pointer-based structures
enable fast parallel unions via pointer manipulation. When compared to
cache-optimized trees, PMAs were slower to update but faster to scan.
</p>
<p>The batch-parallel CPMA overcomes this tradeoff between updates and scans by
optimizing for cache-friendliness. On average, the CPMA is faster than
compressed PaC-trees, a state-of-the-art batch-parallel set library based on
cache-optimized trees, by 1.2x on range queries and 3x on batch updates.
</p>
<p>We further evaluate the CPMA compared to compressed PaC-trees on a real-world
application of dynamic graph processing. The CPMA is on average 1.2x faster on
a suite of graph algorithms and 2x faster on batch inserts for graphs when
compared with compressed PaC-trees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wheatman_B/0/1/0/all/0/1">Brian Wheatman</a>, <a href="http://arxiv.org/find/cs/1/au:+Burns_R/0/1/0/all/0/1">Randal Burns</a>, <a href="http://arxiv.org/find/cs/1/au:+Buluc_A/0/1/0/all/0/1">Ayd&#x131;n Bulu&#xe7;</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Helen Xu</a></p><p>This paper introduces the batch-parallel Compressed Packed Memory Array
(CPMA), a compressed dynamic ordered batch-parallel set data structure based on
the Packed Memory Array (PMA). Traditionally, batch-parallel sets are built on
pointer-based data structures such as trees because pointer-based structures
enable fast parallel unions via pointer manipulation. When compared to
cache-optimized trees, PMAs were slower to update but faster to scan.
</p>
<p>The batch-parallel CPMA overcomes this tradeoff between updates and scans by
optimizing for cache-friendliness. On average, the CPMA is faster than
compressed PaC-trees, a state-of-the-art batch-parallel set library based on
cache-optimized trees, by 1.2x on range queries and 3x on batch updates.
</p>
<p>We further evaluate the CPMA compared to compressed PaC-trees on a real-world
application of dynamic graph processing. The CPMA is on average 1.2x faster on
a suite of graph algorithms and 2x faster on batch inserts for graphs when
compared with compressed PaC-trees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05074'>Autumn: A Scalable Read Optimized LSM-tree based Key-Value Stores with Fast Point and Range Read Speed</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fuheng Zhao, Leron Reznikov, Divyakant Agrawal, Amr El Abbadi</p><p>The Log Structured Merge Trees (LSM-tree) based key-value stores are widely
used in many storage systems to support a variety of operations such as
updates, point reads, and range reads. Traditionally, LSM-tree's merge policy
organizes data into multiple levels of exponentially increasing capacity to
support high-speed writes. However, we contend that the traditional merge
policies are not optimized for reads. In this work, we present Autumn, a
scalable and read optimized LSM-tree based key-value stores with minimal point
and range read cost. The key idea in improving the read performance is to
dynamically adjust the capacity ratio between two adjacent levels as more data
are stored. As a result, smaller levels gradually increase their capacities and
merge more often. In particular, the point and range read cost improves from
the previous best known $O(logN)$ complexity to $O(\sqrt{logN})$ in Autumn by
applying the new novel Garnering merge policy. While Garnering merge policy
optimizes for both point reads and range reads, it maintains high performance
for updates. Moreover, to further improve the update costs, Autumn uses a small
amount of bounded space of DRAM to pin/keep the first level of LSM-tree. We
implemented Autumn on top of LevelDB and experimentally showcases the gain in
performance for real world workloads.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Fuheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Reznikov_L/0/1/0/all/0/1">Leron Reznikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_D/0/1/0/all/0/1">Divyakant Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbadi_A/0/1/0/all/0/1">Amr El Abbadi</a></p><p>The Log Structured Merge Trees (LSM-tree) based key-value stores are widely
used in many storage systems to support a variety of operations such as
updates, point reads, and range reads. Traditionally, LSM-tree's merge policy
organizes data into multiple levels of exponentially increasing capacity to
support high-speed writes. However, we contend that the traditional merge
policies are not optimized for reads. In this work, we present Autumn, a
scalable and read optimized LSM-tree based key-value stores with minimal point
and range read cost. The key idea in improving the read performance is to
dynamically adjust the capacity ratio between two adjacent levels as more data
are stored. As a result, smaller levels gradually increase their capacities and
merge more often. In particular, the point and range read cost improves from
the previous best known $O(logN)$ complexity to $O(\sqrt{logN})$ in Autumn by
applying the new novel Garnering merge policy. While Garnering merge policy
optimizes for both point reads and range reads, it maintains high performance
for updates. Moreover, to further improve the update costs, Autumn uses a small
amount of bounded space of DRAM to pin/keep the first level of LSM-tree. We
implemented Autumn on top of LevelDB and experimentally showcases the gain in
performance for real world workloads.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05121'>Memory-Efficient Solutions to Large-Graph MST Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arjun Bhalla</p><p>Minimum Spanning Trees are a well-studied subset of graph problems. While
classical algorithms have existed to solve these problems for decades, new
variations and application areas are constantly being discovered. When dealing
with large graph problems, however, memory constraints can often be limiting,
especially when using these classical methods in memory restricted
environments. In this work, we propose an augmentation of Prim's algorithm that
can be empirically shown to solve MST problems with a reduction in auxiliary
memory usage of over 90%, and a margin of error of less than 0.3%.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhalla_A/0/1/0/all/0/1">Arjun Bhalla</a></p><p>Minimum Spanning Trees are a well-studied subset of graph problems. While
classical algorithms have existed to solve these problems for decades, new
variations and application areas are constantly being discovered. When dealing
with large graph problems, however, memory constraints can often be limiting,
especially when using these classical methods in memory restricted
environments. In this work, we propose an augmentation of Prim's algorithm that
can be empirically shown to solve MST problems with a reduction in auxiliary
memory usage of over 90%, and a margin of error of less than 0.3%.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05129'>Sorting Finite Automata via Partition Refinement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ruben Becker, Manuel C&#xe1;ceres, Davide Cenzato, Sung-Hwan Kim, Bojana Kodric, Francisco Olivares, Nicola Prezza</p><p>Wheeler nondeterministic finite automata (WNFAs) were introduced as a
generalization of prefix sorting from strings to labeled graphs. WNFAs admit
optimal solutions to classic hard problems on labeled graphs and languages. The
problem of deciding whether a given NFA is Wheeler is known to be NP-complete.
Recently, however, Alanko et al. showed how to side-step this complexity by
switching to preorders: letting $Q$ be the set of states, $E$ the set of
transitions, $|Q|=n$, and $|E|=m$, they provided a $O(mn^2)$-time algorithm
computing a totally-ordered partition of the WNFA's states such that (1)
equivalent states recognize the same regular language, and (2) the order of
non-equivalent states is consistent with any Wheeler order, when one exists.
Then, the output is a preorder of the states as useful for pattern matching as
standard Wheeler orders. Further research generalized these concepts to
arbitrary NFAs by introducing co-lex partial preorders: any NFA admits a
partial preorder of its states reflecting the co-lex order of their accepted
strings; the smaller the width of such preorder is, the faster regular
expression matching queries can be performed. To date, the fastest algorithm
for computing the smallest-width partial preorder on NFAs runs in
$O(m^2+n^{5/2})$ time, while on DFAs the same can be done in $O(\min(n^2\log
n,mn))$ time. In this paper, we provide much more efficient solutions to the
problem above. Our results are achieved by extending a classic algorithm for
the relational coarsest partition refinement problem to work with ordered
partitions. Specifically, we provide a $O(m\log n)$-time algorithm computing a
co-lex total preorder when the input is a WNFA, and an algorithm with the same
time complexity computing the smallest-width co-lex partial order of any DFA.
Also, we present implementations of our algorithms and show that they are very
efficient in practice.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Becker_R/0/1/0/all/0/1">Ruben Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Caceres_M/0/1/0/all/0/1">Manuel C&#xe1;ceres</a>, <a href="http://arxiv.org/find/cs/1/au:+Cenzato_D/0/1/0/all/0/1">Davide Cenzato</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sung-Hwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kodric_B/0/1/0/all/0/1">Bojana Kodric</a>, <a href="http://arxiv.org/find/cs/1/au:+Olivares_F/0/1/0/all/0/1">Francisco Olivares</a>, <a href="http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1">Nicola Prezza</a></p><p>Wheeler nondeterministic finite automata (WNFAs) were introduced as a
generalization of prefix sorting from strings to labeled graphs. WNFAs admit
optimal solutions to classic hard problems on labeled graphs and languages. The
problem of deciding whether a given NFA is Wheeler is known to be NP-complete.
Recently, however, Alanko et al. showed how to side-step this complexity by
switching to preorders: letting $Q$ be the set of states, $E$ the set of
transitions, $|Q|=n$, and $|E|=m$, they provided a $O(mn^2)$-time algorithm
computing a totally-ordered partition of the WNFA's states such that (1)
equivalent states recognize the same regular language, and (2) the order of
non-equivalent states is consistent with any Wheeler order, when one exists.
Then, the output is a preorder of the states as useful for pattern matching as
standard Wheeler orders. Further research generalized these concepts to
arbitrary NFAs by introducing co-lex partial preorders: any NFA admits a
partial preorder of its states reflecting the co-lex order of their accepted
strings; the smaller the width of such preorder is, the faster regular
expression matching queries can be performed. To date, the fastest algorithm
for computing the smallest-width partial preorder on NFAs runs in
$O(m^2+n^{5/2})$ time, while on DFAs the same can be done in $O(\min(n^2\log
n,mn))$ time. In this paper, we provide much more efficient solutions to the
problem above. Our results are achieved by extending a classic algorithm for
the relational coarsest partition refinement problem to work with ordered
partitions. Specifically, we provide a $O(m\log n)$-time algorithm computing a
co-lex total preorder when the input is a WNFA, and an algorithm with the same
time complexity computing the smallest-width co-lex partial order of any DFA.
Also, we present implementations of our algorithms and show that they are very
efficient in practice.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05353'>Constant-Competitiveness for Random Assignment Matroid Secretary Without Knowing the Matroid</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Richard Santiago, Ivan Sergeev, Rico Zenklusen</p><p>The Matroid Secretary Conjecture is a notorious open problem in online
optimization. It claims the existence of an $O(1)$-competitive algorithm for
the Matroid Secretary Problem (MSP). Here, the elements of a weighted matroid
appear one-by-one, revealing their weight at appearance, and the task is to
select elements online with the goal to get an independent set of largest
possible weight. $O(1)$-competitive MSP algorithms have so far only been
obtained for restricted matroid classes and for MSP variations, including
Random-Assignment MSP (RA-MSP), where an adversary fixes a number of weights
equal to the ground set size of the matroid, which then get assigned randomly
to the elements of the ground set. Unfortunately, these approaches heavily rely
on knowing the full matroid upfront. This is an arguably undesirable
requirement, and there are good reasons to believe that an approach towards
resolving the MSP Conjecture should not rely on it. Thus, both Soto [SIAM
Journal on Computing 2013] and Oveis Gharan &amp; Vondrak [Algorithmica 2013]
raised as an open question whether RA-MSP admits an $O(1)$-competitive
algorithm even without knowing the matroid upfront.
</p>
<p>In this work, we answer this question affirmatively. Our result makes RA-MSP
the first well-known MSP variant with an $O(1)$-competitive algorithm that does
not need to know the underlying matroid upfront and without any restriction on
the underlying matroid. Our approach is based on first approximately learning
the rank-density curve of the matroid, which we then exploit algorithmically.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Santiago_R/0/1/0/all/0/1">Richard Santiago</a>, <a href="http://arxiv.org/find/cs/1/au:+Sergeev_I/0/1/0/all/0/1">Ivan Sergeev</a>, <a href="http://arxiv.org/find/cs/1/au:+Zenklusen_R/0/1/0/all/0/1">Rico Zenklusen</a></p><p>The Matroid Secretary Conjecture is a notorious open problem in online
optimization. It claims the existence of an $O(1)$-competitive algorithm for
the Matroid Secretary Problem (MSP). Here, the elements of a weighted matroid
appear one-by-one, revealing their weight at appearance, and the task is to
select elements online with the goal to get an independent set of largest
possible weight. $O(1)$-competitive MSP algorithms have so far only been
obtained for restricted matroid classes and for MSP variations, including
Random-Assignment MSP (RA-MSP), where an adversary fixes a number of weights
equal to the ground set size of the matroid, which then get assigned randomly
to the elements of the ground set. Unfortunately, these approaches heavily rely
on knowing the full matroid upfront. This is an arguably undesirable
requirement, and there are good reasons to believe that an approach towards
resolving the MSP Conjecture should not rely on it. Thus, both Soto [SIAM
Journal on Computing 2013] and Oveis Gharan &amp; Vondrak [Algorithmica 2013]
raised as an open question whether RA-MSP admits an $O(1)$-competitive
algorithm even without knowing the matroid upfront.
</p>
<p>In this work, we answer this question affirmatively. Our result makes RA-MSP
the first well-known MSP variant with an $O(1)$-competitive algorithm that does
not need to know the underlying matroid upfront and without any restriction on
the underlying matroid. Our approach is based on first approximately learning
the rank-density curve of the matroid, which we then exploit algorithmically.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05398'>An Improved Approximation Algorithm for the Minimum 2-Vertex-Connected Spanning Subgraph Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ali &#xc7;ivril</p><p>We provide an algorithm for the minimum 2-vertex-connected spanning subgraph
problem with approximation ratio $\frac{4}{3}$, improving upon the previous
best factor $\frac{10}{7}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Civril_A/0/1/0/all/0/1">Ali &#xc7;ivril</a></p><p>We provide an algorithm for the minimum 2-vertex-connected spanning subgraph
problem with approximation ratio $\frac{4}{3}$, improving upon the previous
best factor $\frac{10}{7}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05411'>4/3-Approximation of Graphic TSP</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ali &#xc7;ivril</p><p>We describe a $\frac{4}{3}$-approximation algorithm for the traveling
salesman problem in which the distances between points are induced by
graph-theoretical distances in an unweighted graph. The algorithm is based on
finding a minimum cost perfect matching on the odd degree vertices of a
carefully computed 2-edge-connected spanning subgraph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Civril_A/0/1/0/all/0/1">Ali &#xc7;ivril</a></p><p>We describe a $\frac{4}{3}$-approximation algorithm for the traveling
salesman problem in which the distances between points are induced by
graph-theoretical distances in an unweighted graph. The algorithm is based on
finding a minimum cost perfect matching on the odd degree vertices of a
carefully computed 2-edge-connected spanning subgraph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05417'>Fast Many-to-Many Routing for Ridesharing with Multiple Pickup and Dropoff Locations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Moritz Laupichler, Peter Sanders</p><p>We introduce KaRRi, an improved algorithm for scheduling a fleet of shared
vehicles as it is used by services like UberXShare and Lyft Shared. We speed up
the basic online algorithm that looks for all possible insertions of a new
customer into a set of existing routes, we generalize the objective function,
and efficiently support a large number of possible pick-up and drop-off
locations. This lays an algorithmic foundation for ridesharing systems with
higher vehicle occupancy -- enabling greatly reduced cost and ecological impact
at comparable service quality. We find that our algorithm computes assignments
between vehicles and riders several times faster than a previous
state-of-the-art approach. Further, we observe that allowing meeting points for
vehicles and riders can reduce the operating cost of vehicle fleets by up to
$15\%$ while also reducing passenger wait and trip times.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Laupichler_M/0/1/0/all/0/1">Moritz Laupichler</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanders_P/0/1/0/all/0/1">Peter Sanders</a></p><p>We introduce KaRRi, an improved algorithm for scheduling a fleet of shared
vehicles as it is used by services like UberXShare and Lyft Shared. We speed up
the basic online algorithm that looks for all possible insertions of a new
customer into a set of existing routes, we generalize the objective function,
and efficiently support a large number of possible pick-up and drop-off
locations. This lays an algorithmic foundation for ridesharing systems with
higher vehicle occupancy -- enabling greatly reduced cost and ecological impact
at comparable service quality. We find that our algorithm computes assignments
between vehicles and riders several times faster than a previous
state-of-the-art approach. Further, we observe that allowing meeting points for
vehicles and riders can reduce the operating cost of vehicle fleets by up to
$15\%$ while also reducing passenger wait and trip times.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05487'>Testing versus estimation of graph properties, revisited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lior Gishboliner, Nick Kushnir, Asaf Shapira</p><p>A distance estimator for a graph property $\mathcal{P}$ is an algorithm that
given $G$ and $\alpha, \varepsilon &gt;0$ distinguishes between the case that $G$
is $(\alpha-\varepsilon)$-close to $\mathcal{P}$ and the case that $G$ is
$\alpha$-far from $\mathcal{P}$ (in edit distance). We say that $\mathcal{P}$
is estimable if it has a distance estimator whose query complexity depends only
on $\varepsilon$.
</p>
<p>Every estimable property is also testable, since testing corresponds to
estimating with $\alpha=\varepsilon$. A central result in the area of property
testing, the Fischer--Newman theorem, gives an inverse statement: every
testable property is in fact estimable. The proof of Fischer and Newman was
highly ineffective, since it incurred a tower-type loss when transforming a
testing algorithm for $\mathcal{P}$ into a distance estimator. This raised the
natural problem, studied recently by Fiat--Ron and by
Hoppen--Kohayakawa--Lang--Lefmann--Stagni, whether one can find a
transformation with a polynomial loss. We obtain the following results.
</p>
<p>1. If $\mathcal{P}$ is hereditary, then one can turn a tester for
$\mathcal{P}$ into a distance estimator with an exponential loss. This is an
exponential improvement over the result of Hoppen et. al., who obtained a
transformation with a double exponential loss.
</p>
<p>2. For every $\mathcal{P}$, one can turn a testing algorithm for
$\mathcal{P}$ into a distance estimator with a double exponential loss. This
improves over the transformation of Fischer--Newman that incurred a tower-type
loss. Our main conceptual contribution in this work is that we manage to turn
the approach of Fischer--Newman, which was inherently ineffective, into an
efficient one. On the technical level, our main contribution is in establishing
certain properties of Frieze--Kannan Weak Regular partitions that are of
independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gishboliner_L/0/1/0/all/0/1">Lior Gishboliner</a>, <a href="http://arxiv.org/find/math/1/au:+Kushnir_N/0/1/0/all/0/1">Nick Kushnir</a>, <a href="http://arxiv.org/find/math/1/au:+Shapira_A/0/1/0/all/0/1">Asaf Shapira</a></p><p>A distance estimator for a graph property $\mathcal{P}$ is an algorithm that
given $G$ and $\alpha, \varepsilon &gt;0$ distinguishes between the case that $G$
is $(\alpha-\varepsilon)$-close to $\mathcal{P}$ and the case that $G$ is
$\alpha$-far from $\mathcal{P}$ (in edit distance). We say that $\mathcal{P}$
is estimable if it has a distance estimator whose query complexity depends only
on $\varepsilon$.
</p>
<p>Every estimable property is also testable, since testing corresponds to
estimating with $\alpha=\varepsilon$. A central result in the area of property
testing, the Fischer--Newman theorem, gives an inverse statement: every
testable property is in fact estimable. The proof of Fischer and Newman was
highly ineffective, since it incurred a tower-type loss when transforming a
testing algorithm for $\mathcal{P}$ into a distance estimator. This raised the
natural problem, studied recently by Fiat--Ron and by
Hoppen--Kohayakawa--Lang--Lefmann--Stagni, whether one can find a
transformation with a polynomial loss. We obtain the following results.
</p>
<p>1. If $\mathcal{P}$ is hereditary, then one can turn a tester for
$\mathcal{P}$ into a distance estimator with an exponential loss. This is an
exponential improvement over the result of Hoppen et. al., who obtained a
transformation with a double exponential loss.
</p>
<p>2. For every $\mathcal{P}$, one can turn a testing algorithm for
$\mathcal{P}$ into a distance estimator with a double exponential loss. This
improves over the transformation of Fischer--Newman that incurred a tower-type
loss. Our main conceptual contribution in this work is that we manage to turn
the approach of Fischer--Newman, which was inherently ineffective, into an
efficient one. On the technical level, our main contribution is in establishing
certain properties of Frieze--Kannan Weak Regular partitions that are of
independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05565'>Greedy Heuristics and Linear Relaxations for the Random Hitting Set Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gabriel Arpino, Daniil Dmitriev, Nicolo Grometto</p><p>Consider the Hitting Set problem where, for a given universe $\mathcal{X} =
\left\{ 1, ... , n \right\}$ and a collection of subsets $\mathcal{S}_1, ... ,
\mathcal{S}_m$, one seeks to identify the smallest subset of $\mathcal{X}$
which has nonempty intersection with every element in the collection. We study
a probabilistic formulation of this problem, where the underlying subsets are
formed by including each element of the universe with probability $p$,
independently of one another. For large enough values of $n$, we rigorously
analyse the average case performance of Lov\'asz's celebrated greedy algorithm
(Lov\'asz, 1975) with respect to the chosen input distribution. In addition, we
study integrality gaps between linear programming and integer programming
solutions of the problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Arpino_G/0/1/0/all/0/1">Gabriel Arpino</a>, <a href="http://arxiv.org/find/math/1/au:+Dmitriev_D/0/1/0/all/0/1">Daniil Dmitriev</a>, <a href="http://arxiv.org/find/math/1/au:+Grometto_N/0/1/0/all/0/1">Nicolo Grometto</a></p><p>Consider the Hitting Set problem where, for a given universe $\mathcal{X} =
\left\{ 1, ... , n \right\}$ and a collection of subsets $\mathcal{S}_1, ... ,
\mathcal{S}_m$, one seeks to identify the smallest subset of $\mathcal{X}$
which has nonempty intersection with every element in the collection. We study
a probabilistic formulation of this problem, where the underlying subsets are
formed by including each element of the universe with probability $p$,
independently of one another. For large enough values of $n$, we rigorously
analyse the average case performance of Lov\'asz's celebrated greedy algorithm
(Lov\'asz, 1975) with respect to the chosen input distribution. In addition, we
study integrality gaps between linear programming and integer programming
solutions of the problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, May 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03946'>An Improved PTAS for Covering Targets with Mobile Sensors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nonthaphat Wongwattanakij, Nattawut Phetmak, Chaiporn Jaikaeo, Jittat Fakcharoenphol</p><p>This paper considers a movement minimization problem for mobile sensors.
Given a set of $n$ point targets, the $k$-Sink Minimum Movement Target Coverage
Problem is to schedule mobile sensors, initially located at $k$ base stations,
to cover all targets minimizing the total moving distance of the sensors. We
present a polynomial-time approximation scheme for finding a $(1+\epsilon)$
approximate solution running in time $n^{O(1/\epsilon)}$ for this problem when
$k$, the number of base stations, is constant. Our algorithm improves the
running time exponentially from the previous work that runs in time
$n^{O(1/\epsilon^2)}$, without any target distribution assumption. To devise a
faster algorithm, we prove a stronger bound on the number of sensors in any
unit area in the optimal solution and employ a more refined dynamic programming
algorithm whose complexity depends only on the width of the problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wongwattanakij_N/0/1/0/all/0/1">Nonthaphat Wongwattanakij</a>, <a href="http://arxiv.org/find/cs/1/au:+Phetmak_N/0/1/0/all/0/1">Nattawut Phetmak</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaikaeo_C/0/1/0/all/0/1">Chaiporn Jaikaeo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakcharoenphol_J/0/1/0/all/0/1">Jittat Fakcharoenphol</a></p><p>This paper considers a movement minimization problem for mobile sensors.
Given a set of $n$ point targets, the $k$-Sink Minimum Movement Target Coverage
Problem is to schedule mobile sensors, initially located at $k$ base stations,
to cover all targets minimizing the total moving distance of the sensors. We
present a polynomial-time approximation scheme for finding a $(1+\epsilon)$
approximate solution running in time $n^{O(1/\epsilon)}$ for this problem when
$k$, the number of base stations, is constant. Our algorithm improves the
running time exponentially from the previous work that runs in time
$n^{O(1/\epsilon^2)}$, without any target distribution assumption. To devise a
faster algorithm, we prove a stronger bound on the number of sensors in any
unit area in the optimal solution and employ a more refined dynamic programming
algorithm whose complexity depends only on the width of the problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-09T00:30:00Z">Tuesday, May 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
