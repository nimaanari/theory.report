<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-02-02T01:59:16Z">Thursday, February 02 2023, 01:59</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, February 02
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00273'>Hardness of braided quantum circuit optimization in the surface code</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kunihiro Wasa, Shin Nishio, Koki Suetsugu, Michael Hanks, Ashley Stephens, Yu Yokoi, Kae Nemoto</p><p>Large-scale quantum information processing requires the use of quantum error
correcting codes to mitigate the effects of noise in quantum devices.
Topological error-correcting codes, such as surface codes, are promising
candidates as they can be implemented using only local interactions in a
two-dimensional array of physical qubits. Procedures such as defect braiding
and lattice surgery can then be used to realize a fault-tolerant universal set
of gates on the logical space of such topological codes. However, error
correction also introduces a significant overhead in computation time, the
number of physical qubits, and the number of physical gates. While optimizing
fault-tolerant circuits to minimize this overhead is critical, the
computational complexity of such optimization problems remains unknown. This
ambiguity leaves room for doubt surrounding the most effective methods for
compiling fault-tolerant circuits for a large-scale quantum computer. In this
paper, we show that the optimization of a special subset of braided quantum
circuits is NP-hard by a polynomial-time reduction of the optimization problem
into a specific problem called Planar Rectilinear 3SAT.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Wasa_K/0/1/0/all/0/1">Kunihiro Wasa</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nishio_S/0/1/0/all/0/1">Shin Nishio</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Suetsugu_K/0/1/0/all/0/1">Koki Suetsugu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hanks_M/0/1/0/all/0/1">Michael Hanks</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Stephens_A/0/1/0/all/0/1">Ashley Stephens</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yokoi_Y/0/1/0/all/0/1">Yu Yokoi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nemoto_K/0/1/0/all/0/1">Kae Nemoto</a></p><p>Large-scale quantum information processing requires the use of quantum error
correcting codes to mitigate the effects of noise in quantum devices.
Topological error-correcting codes, such as surface codes, are promising
candidates as they can be implemented using only local interactions in a
two-dimensional array of physical qubits. Procedures such as defect braiding
and lattice surgery can then be used to realize a fault-tolerant universal set
of gates on the logical space of such topological codes. However, error
correction also introduces a significant overhead in computation time, the
number of physical qubits, and the number of physical gates. While optimizing
fault-tolerant circuits to minimize this overhead is critical, the
computational complexity of such optimization problems remains unknown. This
ambiguity leaves room for doubt surrounding the most effective methods for
compiling fault-tolerant circuits for a large-scale quantum computer. In this
paper, we show that the optimization of a special subset of braided quantum
circuits is NP-hard by a polynomial-time reduction of the optimization problem
into a specific problem called Planar Rectilinear 3SAT.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00541'>Parameterized Complexity of Weighted Team Definability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Juha Kontinen, Yasir Mahmood, Arne Meier, Heribert Vollmer</p><p>In this article, we study the complexity of weighted team definability for
logics with team semantics. This problem is a natural analogue of one of the
most studied problems in parameterized complexity, the notion of weighted
Fagin-definability, which is formulated in terms of satisfaction of first-order
formulas with free relation variables. We focus on the parameterized complexity
of weighted team definability for a fixed formula phi of central team-based
logics. Given a first-order structure A and the parameter value k as input, the
question is to determine whether A,T models phi for some team T of size k. We
show several results on the complexity of this problem for dependence,
independence, and inclusion logic formulas. Moreover, we also relate the
complexity of weighted team definability to the complexity classes in the
well-known W-hierarchy as well as paraNP.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kontinen_J/0/1/0/all/0/1">Juha Kontinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_Y/0/1/0/all/0/1">Yasir Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Meier_A/0/1/0/all/0/1">Arne Meier</a>, <a href="http://arxiv.org/find/cs/1/au:+Vollmer_H/0/1/0/all/0/1">Heribert Vollmer</a></p><p>In this article, we study the complexity of weighted team definability for
logics with team semantics. This problem is a natural analogue of one of the
most studied problems in parameterized complexity, the notion of weighted
Fagin-definability, which is formulated in terms of satisfaction of first-order
formulas with free relation variables. We focus on the parameterized complexity
of weighted team definability for a fixed formula phi of central team-based
logics. Given a first-order structure A and the parameter value k as input, the
question is to determine whether A,T models phi for some team T of size k. We
show several results on the complexity of this problem for dependence,
independence, and inclusion logic formulas. Moreover, we also relate the
complexity of weighted team definability to the complexity classes in the
well-known W-hierarchy as well as paraNP.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00573'>An automated, geometry-based method for the analysis of hippocampal thickness</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kersten Diers, Hannah Baumeister, Frank Jessen, Emrah D&#xfc;zel, David Berron, Martin Reuter</p><p>The hippocampus is one of the most studied neuroanatomical structures due to
its involvement in attention, learning, and memory as well as its atrophy in
ageing, neurological, and psychiatric diseases. Hippocampal shape changes,
however, are complex and cannot be fully characterized by a single summary
metric such as hippocampal volume as determined from MR images. In this work,
we propose an automated, geometry-based approach for the unfolding, point-wise
correspondence, and local analysis of hippocampal shape features such as
thickness and curvature. Starting from an automated segmentation of hippocampal
subfields, we create a 3D tetrahedral mesh model as well as a 3D intrinsic
coordinate system of the hippocampal body. From this coordinate system, we
derive local curvature and thickness estimates as well as a 2D sheet for
hippocampal unfolding. We evaluate the performance of our algorithm with a
series of experiments to quantify neurodegenerative changes in Mild Cognitive
Impairment and Alzheimer's disease dementia. We find that hippocampal thickness
estimates detect known differences between clinical groups and can determine
the location of these effects on the hippocampal sheet. Further, thickness
estimates improve classification of clinical groups and cognitively unimpaired
controls when added as an additional predictor. Comparable results are obtained
with different datasets and segmentation algorithms. Taken together, we
replicate canonical findings on hippocampal volume/shape changes in dementia,
extend them by gaining insight into their spatial localization on the
hippocampal sheet, and provide additional, complementary information beyond
traditional measures. We provide a new set of sensitive processing and analysis
tools for the analysis of hippocampal geometry that allows comparisons across
studies without relying on image registration or requiring manual intervention.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Diers_K/0/1/0/all/0/1">Kersten Diers</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumeister_H/0/1/0/all/0/1">Hannah Baumeister</a>, <a href="http://arxiv.org/find/cs/1/au:+Jessen_F/0/1/0/all/0/1">Frank Jessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Duzel_E/0/1/0/all/0/1">Emrah D&#xfc;zel</a>, <a href="http://arxiv.org/find/cs/1/au:+Berron_D/0/1/0/all/0/1">David Berron</a>, <a href="http://arxiv.org/find/cs/1/au:+Reuter_M/0/1/0/all/0/1">Martin Reuter</a></p><p>The hippocampus is one of the most studied neuroanatomical structures due to
its involvement in attention, learning, and memory as well as its atrophy in
ageing, neurological, and psychiatric diseases. Hippocampal shape changes,
however, are complex and cannot be fully characterized by a single summary
metric such as hippocampal volume as determined from MR images. In this work,
we propose an automated, geometry-based approach for the unfolding, point-wise
correspondence, and local analysis of hippocampal shape features such as
thickness and curvature. Starting from an automated segmentation of hippocampal
subfields, we create a 3D tetrahedral mesh model as well as a 3D intrinsic
coordinate system of the hippocampal body. From this coordinate system, we
derive local curvature and thickness estimates as well as a 2D sheet for
hippocampal unfolding. We evaluate the performance of our algorithm with a
series of experiments to quantify neurodegenerative changes in Mild Cognitive
Impairment and Alzheimer's disease dementia. We find that hippocampal thickness
estimates detect known differences between clinical groups and can determine
the location of these effects on the hippocampal sheet. Further, thickness
estimates improve classification of clinical groups and cognitively unimpaired
controls when added as an additional predictor. Comparable results are obtained
with different datasets and segmentation algorithms. Taken together, we
replicate canonical findings on hippocampal volume/shape changes in dementia,
extend them by gaining insight into their spatial localization on the
hippocampal sheet, and provide additional, complementary information beyond
traditional measures. We provide a new set of sensitive processing and analysis
tools for the analysis of hippocampal geometry that allows comparisons across
studies without relying on image registration or requiring manual intervention.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00360'>Faster maximal clique enumeration in large real-world link streams</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexis Baudin, Cl&#xe9;mence Magnien, Lionel Tabourier</p><p>Link streams offer a good model for representing interactions over time. They
consist of links $(b,e,u,v)$, where $u$ and $v$ are vertices interacting during
the whole time interval $[b,e]$. In this paper, we deal with the problem of
enumerating maximal cliques in link streams. A clique is a pair
$(C,[t_0,t_1])$, where $C$ is a set of vertices that all interact pairwise
during the full interval $[t_0,t_1]$. It is maximal when neither its set of
vertices nor its time interval can be increased. Some of the main works solving
this problem are based on the famous Bron-Kerbosch algorithm for enumerating
maximal cliques in graphs. We take this idea as a starting point to propose a
new algorithm which matches the cliques of the instantaneous graphs formed by
links existing at a given time $t$ to the maximal cliques of the link stream.
We prove its validity and compute its complexity, which is better than the
state-of-the art ones in many cases of interest. We also study the
output-sensitive complexity, which is close to the output size, thereby showing
that our algorithm is efficient. To confirm this, we perform experiments on
link streams used in the state of the art, and on massive link streams, up to
100 million links. In all cases our algorithm is faster, mostly by a factor of
at least 10 and up to a factor of $10^4$. Moreover, it scales to massive link
streams for which the existing algorithms are not able to provide the solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Baudin_A/0/1/0/all/0/1">Alexis Baudin</a>, <a href="http://arxiv.org/find/cs/1/au:+Magnien_C/0/1/0/all/0/1">Cl&#xe9;mence Magnien</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabourier_L/0/1/0/all/0/1">Lionel Tabourier</a></p><p>Link streams offer a good model for representing interactions over time. They
consist of links $(b,e,u,v)$, where $u$ and $v$ are vertices interacting during
the whole time interval $[b,e]$. In this paper, we deal with the problem of
enumerating maximal cliques in link streams. A clique is a pair
$(C,[t_0,t_1])$, where $C$ is a set of vertices that all interact pairwise
during the full interval $[t_0,t_1]$. It is maximal when neither its set of
vertices nor its time interval can be increased. Some of the main works solving
this problem are based on the famous Bron-Kerbosch algorithm for enumerating
maximal cliques in graphs. We take this idea as a starting point to propose a
new algorithm which matches the cliques of the instantaneous graphs formed by
links existing at a given time $t$ to the maximal cliques of the link stream.
We prove its validity and compute its complexity, which is better than the
state-of-the art ones in many cases of interest. We also study the
output-sensitive complexity, which is close to the output size, thereby showing
that our algorithm is efficient. To confirm this, we perform experiments on
link streams used in the state of the art, and on massive link streams, up to
100 million links. In all cases our algorithm is faster, mostly by a factor of
at least 10 and up to a factor of $10^4$. Moreover, it scales to massive link
streams for which the existing algorithms are not able to provide the solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00025'>On the Within-Group Discrimination of Screening Classifiers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nastaran Okati, Stratis Tsirtsis, Manuel Gomez Rodriguez</p><p>Screening classifiers are increasingly used to identify qualified candidates
in a variety of selection processes. In this context, it has been recently
shown that, if a classifier is calibrated, one can identify the smallest set of
candidates which contains, in expectation, a desired number of qualified
candidates using a threshold decision rule. This lends support to focusing on
calibration as the only requirement for screening classifiers. In this paper,
we argue that screening policies that use calibrated classifiers may suffer
from an understudied type of within-group discrimination -- they may
discriminate against qualified members within demographic groups of interest.
Further, we argue that this type of discrimination can be avoided if
classifiers satisfy within-group monotonicity, a natural monotonicity property
within each of the groups. Then, we introduce an efficient post-processing
algorithm based on dynamic programming to minimally modify a given calibrated
classifier so that its probability estimates satisfy within-group monotonicity.
We validate our algorithm using US Census survey data and show that
within-group monotonicity can be often achieved at a small cost in terms of
prediction granularity and shortlist size.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Okati_N/0/1/0/all/0/1">Nastaran Okati</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsirtsis_S/0/1/0/all/0/1">Stratis Tsirtsis</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_M/0/1/0/all/0/1">Manuel Gomez Rodriguez</a></p><p>Screening classifiers are increasingly used to identify qualified candidates
in a variety of selection processes. In this context, it has been recently
shown that, if a classifier is calibrated, one can identify the smallest set of
candidates which contains, in expectation, a desired number of qualified
candidates using a threshold decision rule. This lends support to focusing on
calibration as the only requirement for screening classifiers. In this paper,
we argue that screening policies that use calibrated classifiers may suffer
from an understudied type of within-group discrimination -- they may
discriminate against qualified members within demographic groups of interest.
Further, we argue that this type of discrimination can be avoided if
classifiers satisfy within-group monotonicity, a natural monotonicity property
within each of the groups. Then, we introduce an efficient post-processing
algorithm based on dynamic programming to minimally modify a given calibrated
classifier so that its probability estimates satisfy within-group monotonicity.
We validate our algorithm using US Census survey data and show that
within-group monotonicity can be often achieved at a small cost in terms of
prediction granularity and shortlist size.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00037'>Differentially-Private Hierarchical Clustering with Provable Approximation Guarantees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jacob Imola, Alessandro Epasto, Mohammad Mahdian, Vincent Cohen-Addad, Vahab Mirrokni</p><p>Hierarchical Clustering is a popular unsupervised machine learning method
with decades of history and numerous applications. We initiate the study of
differentially private approximation algorithms for hierarchical clustering
under the rigorous framework introduced by (Dasgupta, 2016). We show strong
lower bounds for the problem: that any $\epsilon$-DP algorithm must exhibit
$O(|V|^2/ \epsilon)$-additive error for an input dataset $V$. Then, we exhibit
a polynomial-time approximation algorithm with $O(|V|^{2.5}/
\epsilon)$-additive error, and an exponential-time algorithm that meets the
lower bound. To overcome the lower bound, we focus on the stochastic block
model, a popular model of graphs, and, with a separation assumption on the
blocks, propose a private $1+o(1)$ approximation algorithm which also recovers
the blocks exactly. Finally, we perform an empirical study of our algorithms
and validate their performance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Imola_J/0/1/0/all/0/1">Jacob Imola</a>, <a href="http://arxiv.org/find/cs/1/au:+Epasto_A/0/1/0/all/0/1">Alessandro Epasto</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahdian_M/0/1/0/all/0/1">Mohammad Mahdian</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1">Vincent Cohen-Addad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a></p><p>Hierarchical Clustering is a popular unsupervised machine learning method
with decades of history and numerous applications. We initiate the study of
differentially private approximation algorithms for hierarchical clustering
under the rigorous framework introduced by (Dasgupta, 2016). We show strong
lower bounds for the problem: that any $\epsilon$-DP algorithm must exhibit
$O(|V|^2/ \epsilon)$-additive error for an input dataset $V$. Then, we exhibit
a polynomial-time approximation algorithm with $O(|V|^{2.5}/
\epsilon)$-additive error, and an exponential-time algorithm that meets the
lower bound. To overcome the lower bound, we focus on the stochastic block
model, a popular model of graphs, and, with a separation assumption on the
blocks, propose a private $1+o(1)$ approximation algorithm which also recovers
the blocks exactly. Finally, we perform an empirical study of our algorithms
and validate their performance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00052'>Exploring Wedges of an Oriented Grid by an Automaton with Pebbles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Subhash Bhagat, Andrzej Pelc</p><p>A mobile agent, modeled as a deterministic finite automaton, navigates in the
infinite anonymous oriented grid $\mathbb{Z} \times \mathbb{Z}$. It has to
explore a given infinite subgraph of the grid by visiting all of its nodes. We
focus on the simplest subgraphs, called {\em wedges}, spanned by all nodes of
the grid located between two half-lines in the plane, with a common origin.
Many wedges turn out to be impossible to explore by an automaton that cannot
mark nodes of the grid. Hence, we study the following question: Given a wedge
$W$, what is the smallest number $p$ of (movable) pebbles for which there
exists an automaton that can explore $W$ using $p$ pebbles? Our main
contribution is a complete solution of this problem. For each wedge $W$ we
determine this minimum number $p$, show an automaton that explores it using $p$
pebbles and show that fewer pebbles are not enough. We show that this smallest
number of pebbles can vary from 0 to 3, depending on the angle between
half-lines limiting the wedge and depending on whether the automaton can cross
these half-lines or not.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhagat_S/0/1/0/all/0/1">Subhash Bhagat</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelc_A/0/1/0/all/0/1">Andrzej Pelc</a></p><p>A mobile agent, modeled as a deterministic finite automaton, navigates in the
infinite anonymous oriented grid $\mathbb{Z} \times \mathbb{Z}$. It has to
explore a given infinite subgraph of the grid by visiting all of its nodes. We
focus on the simplest subgraphs, called {\em wedges}, spanned by all nodes of
the grid located between two half-lines in the plane, with a common origin.
Many wedges turn out to be impossible to explore by an automaton that cannot
mark nodes of the grid. Hence, we study the following question: Given a wedge
$W$, what is the smallest number $p$ of (movable) pebbles for which there
exists an automaton that can explore $W$ using $p$ pebbles? Our main
contribution is a complete solution of this problem. For each wedge $W$ we
determine this minimum number $p$, show an automaton that explores it using $p$
pebbles and show that fewer pebbles are not enough. We show that this smallest
number of pebbles can vary from 0 to 3, depending on the angle between
half-lines limiting the wedge and depending on whether the automaton can cross
these half-lines or not.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00112'>Adding an Edge in a $P_4$-sparse Graph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anna Mpanti, Stavros D. Nikolopoulos, Leonidas Palios</p><p>The minimum completion (fill-in) problem is defined as follows: Given a graph
family $\mathcal{F}$ (more generally, a property $\Pi$) and a graph $G$, the
completion problem asks for the minimum number of non-edges needed to be added
to $G$ so that the resulting graph belongs to the graph family $\mathcal{F}$
(or has property $\Pi$). This problem is NP-complete for many subclasses of
perfect graphs and polynomial solutions are available only for minimal
completion sets. We study the minimum completion problem of a $P_4$-sparse
graph $G$ with an added edge. For any optimal solution of the problem, we prove
that there is an optimal solution whose form is of one of a small number of
possibilities. This along with the solution of the problem when the added edge
connects two non-adjacent vertices of a spider or connects two vertices in
different connected components of the graph enables us to present a
polynomial-time algorithm for the problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mpanti_A/0/1/0/all/0/1">Anna Mpanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolopoulos_S/0/1/0/all/0/1">Stavros D. Nikolopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Palios_L/0/1/0/all/0/1">Leonidas Palios</a></p><p>The minimum completion (fill-in) problem is defined as follows: Given a graph
family $\mathcal{F}$ (more generally, a property $\Pi$) and a graph $G$, the
completion problem asks for the minimum number of non-edges needed to be added
to $G$ so that the resulting graph belongs to the graph family $\mathcal{F}$
(or has property $\Pi$). This problem is NP-complete for many subclasses of
perfect graphs and polynomial solutions are available only for minimal
completion sets. We study the minimum completion problem of a $P_4$-sparse
graph $G$ with an added edge. For any optimal solution of the problem, we prove
that there is an optimal solution whose form is of one of a small number of
possibilities. This along with the solution of the problem when the added edge
connects two non-adjacent vertices of a spider or connects two vertices in
different connected components of the graph enables us to present a
polynomial-time algorithm for the problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00133'>Sublinear Approximation Schemes for Scheduling Precedence Graphs of Bounded Depth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bin Fu, Yumei Huo, Hairong Zhao</p><p>We study the classical scheduling problem on parallel machines %with
precedence constraints where the precedence graph has the bounded depth $h$.
Our goal is to minimize the maximum completion time. We focus on developing
approximation algorithms that use only sublinear space or sublinear time. We
develop the first one-pass streaming approximation schemes using sublinear
space when all jobs' processing times differ no more than a constant factor $c$
and the number of machines $m$ is at most $\tfrac {2n \epsilon}{3 h c }$. This
is so far the best approximation we can have in terms of $m$, since no
polynomial time approximation better than $\tfrac{4}{3}$ exists when $m =
\tfrac{n}{3}$ unless P=NP. %the problem cannot be approximated within a factor
of $\tfrac{4}{3}$ when $m = \tfrac{n}{3}$ even if all jobs have equal
processing time. The algorithms are then extended to the more general problem
where the largest $\alpha n$ jobs have no more than $c$ factor difference. %
for some constant $0 &lt; \alpha \le 1$. We also develop the first sublinear time
algorithms for both problems. For the more general problem, when $ m \le \tfrac
{ \alpha n \epsilon}{20 c^2 \cdot h } $, our algorithm is a randomized
$(1+\epsilon)$-approximation scheme that runs in sublinear time. This work not
only provides an algorithmic solution to the studied problem under big data %
and cloud computing environment, but also gives a methodological framework for
designing sublinear approximation algorithms for other scheduling problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fu_B/0/1/0/all/0/1">Bin Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1">Yumei Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hairong Zhao</a></p><p>We study the classical scheduling problem on parallel machines %with
precedence constraints where the precedence graph has the bounded depth $h$.
Our goal is to minimize the maximum completion time. We focus on developing
approximation algorithms that use only sublinear space or sublinear time. We
develop the first one-pass streaming approximation schemes using sublinear
space when all jobs' processing times differ no more than a constant factor $c$
and the number of machines $m$ is at most $\tfrac {2n \epsilon}{3 h c }$. This
is so far the best approximation we can have in terms of $m$, since no
polynomial time approximation better than $\tfrac{4}{3}$ exists when $m =
\tfrac{n}{3}$ unless P=NP. %the problem cannot be approximated within a factor
of $\tfrac{4}{3}$ when $m = \tfrac{n}{3}$ even if all jobs have equal
processing time. The algorithms are then extended to the more general problem
where the largest $\alpha n$ jobs have no more than $c$ factor difference. %
for some constant $0 &lt; \alpha \le 1$. We also develop the first sublinear time
algorithms for both problems. For the more general problem, when $ m \le \tfrac
{ \alpha n \epsilon}{20 c^2 \cdot h } $, our algorithm is a randomized
$(1+\epsilon)$-approximation scheme that runs in sublinear time. This work not
only provides an algorithmic solution to the studied problem under big data %
and cloud computing environment, but also gives a methodological framework for
designing sublinear approximation algorithms for other scheduling problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00135'>Durable Algorithms for Writable LL/SC and CAS with Dynamic Joining</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prasad Jayanti, Siddhartha Jayanti, Sucharita Jayanti</p><p>We present durable implementations for two well known universal primitives --
CAS (compare-and-swap), and its ABA-free counter-part LLSC (load-linked,
store-conditional). All our implementations are: writable, meaning they support
a Write() operation; have constant time complexity per operation; allow for
dynamic joining, meaning newly created processes (a.k.a. threads) of arbitrary
names can join a protocol and access our implementations; and have adaptive
space complexities, meaning the space use scales in the number of processes $n$
that actually use the objects, as opposed to previous protocols which are
designed for a maximum number of processes $N$. Our durable Writable-CAS
implementation, DuraCAS, requires $O(m + n)$ space to support $m$ objects that
get accessed by $n$ processes, improving on the state-of-the-art $O(m + N^2)$.
By definition, LLSC objects must store "contexts" in addition to object values.
Our Writable-LLSC implementation, DuraLL, requires $O(m + n + C)$ space, where
$C$ is the number of "contexts" stored across all the objects. While LLSC has
an advantage over CAS due to being ABA-free, the object definition seems to
require additional space usage. To address this trade-off, we define an
External Context (EC) variant of LLSC. Our EC Writable-LLSC implementation is
ABA-free and has a space complexity of just $O(m + n)$.
</p>
<p>To our knowledge, we are the first to present durable CAS algorithms that
allow for dynamic joining, and our algorithms are the first to exhibit adaptive
space complexities. To our knowledge, we are the first to implement any type of
durable LLSC objects.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jayanti_P/0/1/0/all/0/1">Prasad Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayanti_S/0/1/0/all/0/1">Siddhartha Jayanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayanti_S/0/1/0/all/0/1">Sucharita Jayanti</a></p><p>We present durable implementations for two well known universal primitives --
CAS (compare-and-swap), and its ABA-free counter-part LLSC (load-linked,
store-conditional). All our implementations are: writable, meaning they support
a Write() operation; have constant time complexity per operation; allow for
dynamic joining, meaning newly created processes (a.k.a. threads) of arbitrary
names can join a protocol and access our implementations; and have adaptive
space complexities, meaning the space use scales in the number of processes $n$
that actually use the objects, as opposed to previous protocols which are
designed for a maximum number of processes $N$. Our durable Writable-CAS
implementation, DuraCAS, requires $O(m + n)$ space to support $m$ objects that
get accessed by $n$ processes, improving on the state-of-the-art $O(m + N^2)$.
By definition, LLSC objects must store "contexts" in addition to object values.
Our Writable-LLSC implementation, DuraLL, requires $O(m + n + C)$ space, where
$C$ is the number of "contexts" stored across all the objects. While LLSC has
an advantage over CAS due to being ABA-free, the object definition seems to
require additional space usage. To address this trade-off, we define an
External Context (EC) variant of LLSC. Our EC Writable-LLSC implementation is
ABA-free and has a space complexity of just $O(m + n)$.
</p>
<p>To our knowledge, we are the first to present durable CAS algorithms that
allow for dynamic joining, and our algorithms are the first to exhibit adaptive
space complexities. To our knowledge, we are the first to implement any type of
durable LLSC objects.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00213'>Approximating Red-Blue Set Cover</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eden Chlamt&#xe1;&#x10d;, Yury Makarychev, Ali Vakilian</p><p>We provide a new approximation algorithm for the Red-Blue Set Cover problem
and give a new hardness result. Our approximation algorithm achieves $\tilde
O(m^{1/3})$-approximation improving on the $\tilde O(m^{1/2})$-approximation
due to Elkin and Peleg (where $m$ is the number of sets). Additionally, we
provide a nearly approximation preserving reduction from Min $k$-Union to
Red-Blue Set Cover that gives an $\tilde\Omega(m^{1/4 - \varepsilon})$ hardness
under the Dense-vs-Random conjecture.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chlamtac_E/0/1/0/all/0/1">Eden Chlamt&#xe1;&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_Y/0/1/0/all/0/1">Yury Makarychev</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakilian_A/0/1/0/all/0/1">Ali Vakilian</a></p><p>We provide a new approximation algorithm for the Red-Blue Set Cover problem
and give a new hardness result. Our approximation algorithm achieves $\tilde
O(m^{1/3})$-approximation improving on the $\tilde O(m^{1/2})$-approximation
due to Elkin and Peleg (where $m$ is the number of sets). Additionally, we
provide a nearly approximation preserving reduction from Min $k$-Union to
Red-Blue Set Cover that gives an $\tilde\Omega(m^{1/4 - \varepsilon})$ hardness
under the Dense-vs-Random conjecture.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00248'>A Nearly-Optimal Bound for Fast Regression with $\ell_\infty$ Guarantee</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhao Song, Mingquan Ye, Junze Yin, Lichen Zhang</p><p>Given a matrix $A\in \mathbb{R}^{n\times d}$ and a vector $b\in
\mathbb{R}^n$, we consider the regression problem with $\ell_\infty$
guarantees: finding a vector $x'\in \mathbb{R}^d$ such that $ \|x'-x^*\|_\infty
\leq \frac{\epsilon}{\sqrt{d}}\cdot \|Ax^*-b\|_2\cdot \|A^\dagger\|$ where
$x^*=\arg\min_{x\in \mathbb{R}^d}\|Ax-b\|_2$. One popular approach for solving
such $\ell_2$ regression problem is via sketching: picking a structured random
matrix $S\in \mathbb{R}^{m\times n}$ with $m\ll n$ and $SA$ can be quickly
computed, solve the ``sketched'' regression problem $\arg\min_{x\in
\mathbb{R}^d} \|SAx-Sb\|_2$. In this paper, we show that in order to obtain
such $\ell_\infty$ guarantee for $\ell_2$ regression, one has to use sketching
matrices that are dense. To the best of our knowledge, this is the first user
case in which dense sketching matrices are necessary. On the algorithmic side,
we prove that there exists a distribution of dense sketching matrices with
$m=\epsilon^{-2}d\log^3(n/\delta)$ such that solving the sketched regression
problem gives the $\ell_\infty$ guarantee, with probability at least
$1-\delta$. Moreover, the matrix $SA$ can be computed in time $O(nd\log n)$.
Our row count is nearly-optimal up to logarithmic factors, and significantly
improves the result in [Price, Song and Woodruff, ICALP'17], in which a
super-linear in $d$ rows, $m=\Omega(\epsilon^{-2}d^{1+\gamma})$ for
$\gamma=\Theta(\sqrt{\frac{\log\log n}{\log d}})$ is required. We also develop
a novel analytical framework for $\ell_\infty$ guarantee regression that
utilizes the Oblivious Coordinate-wise Embedding (OCE) property introduced in
[Song and Yu, ICML'21]. Our analysis is arguably much simpler and more general
than [Price, Song and Woodruff, ICALP'17], and it extends to dense sketches for
tensor product of vectors.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Mingquan Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Junze Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lichen Zhang</a></p><p>Given a matrix $A\in \mathbb{R}^{n\times d}$ and a vector $b\in
\mathbb{R}^n$, we consider the regression problem with $\ell_\infty$
guarantees: finding a vector $x'\in \mathbb{R}^d$ such that $ \|x'-x^*\|_\infty
\leq \frac{\epsilon}{\sqrt{d}}\cdot \|Ax^*-b\|_2\cdot \|A^\dagger\|$ where
$x^*=\arg\min_{x\in \mathbb{R}^d}\|Ax-b\|_2$. One popular approach for solving
such $\ell_2$ regression problem is via sketching: picking a structured random
matrix $S\in \mathbb{R}^{m\times n}$ with $m\ll n$ and $SA$ can be quickly
computed, solve the ``sketched'' regression problem $\arg\min_{x\in
\mathbb{R}^d} \|SAx-Sb\|_2$. In this paper, we show that in order to obtain
such $\ell_\infty$ guarantee for $\ell_2$ regression, one has to use sketching
matrices that are dense. To the best of our knowledge, this is the first user
case in which dense sketching matrices are necessary. On the algorithmic side,
we prove that there exists a distribution of dense sketching matrices with
$m=\epsilon^{-2}d\log^3(n/\delta)$ such that solving the sketched regression
problem gives the $\ell_\infty$ guarantee, with probability at least
$1-\delta$. Moreover, the matrix $SA$ can be computed in time $O(nd\log n)$.
Our row count is nearly-optimal up to logarithmic factors, and significantly
improves the result in [Price, Song and Woodruff, ICALP'17], in which a
super-linear in $d$ rows, $m=\Omega(\epsilon^{-2}d^{1+\gamma})$ for
$\gamma=\Theta(\sqrt{\frac{\log\log n}{\log d}})$ is required. We also develop
a novel analytical framework for $\ell_\infty$ guarantee regression that
utilizes the Oblivious Coordinate-wise Embedding (OCE) property introduced in
[Song and Yu, ICML'21]. Our analysis is arguably much simpler and more general
than [Price, Song and Woodruff, ICALP'17], and it extends to dense sketches for
tensor product of vectors.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00352'>Flip-width: Cops and Robber on dense graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Symon Toru&#x144;czyk</p><p>We define new graph parameters that generalize tree-width, degeneracy, and
generalized coloring numbers for sparse graphs, and clique-width and twin-width
for dense graphs. Those parameters are defined using variants of the Cops and
Robber game, in which the robber has speed bounded by a fixed constant
$r\in\mathbb N\cup\{\infty\}$, and the cops perform flips (or perturbations) of
the considered graph. We propose a new notion of tameness of a graph class,
called bounded flip-width, which is a dense counterpart of classes of bounded
expansion of Ne\v{s}et\v{r}il and Ossona de Mendez, and includes classes of
bounded twin-width of Bonnet, Kim, Thomass\'e and Watrigant. We prove that
boundedness of flip-width is preserved by first-order interpretations, or
transductions, generalizing previous results concerning classes of bounded
expansion and bounded twin-width. We provide an algorithm approximating the
flip-width of a given graph, which runs in slicewise polynomial time (XP) in
the size of the graph. We also propose a more general notion of tameness,
called almost bounded flip-width, which is a dense counterpart of nowhere dense
classes, and includes all structurally nowhere dense classes. We conjecture,
and provide evidence, that classes with almost bounded flip-width coincide with
monadically dependent classes, introduced by Shelah in model theory.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Torunczyk_S/0/1/0/all/0/1">Symon Toru&#x144;czyk</a></p><p>We define new graph parameters that generalize tree-width, degeneracy, and
generalized coloring numbers for sparse graphs, and clique-width and twin-width
for dense graphs. Those parameters are defined using variants of the Cops and
Robber game, in which the robber has speed bounded by a fixed constant
$r\in\mathbb N\cup\{\infty\}$, and the cops perform flips (or perturbations) of
the considered graph. We propose a new notion of tameness of a graph class,
called bounded flip-width, which is a dense counterpart of classes of bounded
expansion of Ne\v{s}et\v{r}il and Ossona de Mendez, and includes classes of
bounded twin-width of Bonnet, Kim, Thomass\'e and Watrigant. We prove that
boundedness of flip-width is preserved by first-order interpretations, or
transductions, generalizing previous results concerning classes of bounded
expansion and bounded twin-width. We provide an algorithm approximating the
flip-width of a given graph, which runs in slicewise polynomial time (XP) in
the size of the graph. We also propose a more general notion of tameness,
called almost bounded flip-width, which is a dense counterpart of nowhere dense
classes, and includes all structurally nowhere dense classes. We conjecture,
and provide evidence, that classes with almost bounded flip-width coincide with
monadically dependent classes, introduced by Shelah in model theory.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00458'>Improved Exact and Heuristic Algorithms for Maximum Weight Clique</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Roman Erhardt, Kathrin Hanauer, Nils Kriege, Christian Schulz, Darren Strash</p><p>We propose improved exact and heuristic algorithms for solving the maximum
weight clique problem, a well-known problem in graph theory with many
applications. Our algorithms interleave successful techniques from related work
with novel data reduction rules that use local graph structure to identify and
remove vertices and edges while retaining the optimal solution. We evaluate our
algorithms on a range of synthetic and real-world graphs, and find that they
outperform the current state of the art on most inputs. Our data reductions
always produce smaller reduced graphs than existing data reductions alone. As a
result, our exact algorithm, MWCRedu, finds solutions orders of magnitude
faster on naturally weighted, medium-sized map labeling graphs and random
hyperbolic graphs. Our heuristic algorithm, MWCPeel, outperforms its
competitors on these instances, but is slightly less effective on extremely
dense or large instances.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Erhardt_R/0/1/0/all/0/1">Roman Erhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanauer_K/0/1/0/all/0/1">Kathrin Hanauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kriege_N/0/1/0/all/0/1">Nils Kriege</a>, <a href="http://arxiv.org/find/cs/1/au:+Schulz_C/0/1/0/all/0/1">Christian Schulz</a>, <a href="http://arxiv.org/find/cs/1/au:+Strash_D/0/1/0/all/0/1">Darren Strash</a></p><p>We propose improved exact and heuristic algorithms for solving the maximum
weight clique problem, a well-known problem in graph theory with many
applications. Our algorithms interleave successful techniques from related work
with novel data reduction rules that use local graph structure to identify and
remove vertices and edges while retaining the optimal solution. We evaluate our
algorithms on a range of synthetic and real-world graphs, and find that they
outperform the current state of the art on most inputs. Our data reductions
always produce smaller reduced graphs than existing data reductions alone. As a
result, our exact algorithm, MWCRedu, finds solutions orders of magnitude
faster on naturally weighted, medium-sized map labeling graphs and random
hyperbolic graphs. Our heuristic algorithm, MWCPeel, outperforms its
competitors on these instances, but is slightly less effective on extremely
dense or large instances.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00608'>The Investment Management Game: Extending the Scope of the Notion of Core</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vijay V. Vazirani</p><p>The core is a dominant solution concept in economics and game theory. In this
context, the following question arises, ``How versatile is this solution
concept?'' We note that within game theory, this notion has been used for
profit -- equivalently, cost or utility -- sharing only. In this paper, we show
a completely different use for it: in an {\em investment management game},
under which an agent needs to allocate her money among investment firms in such
a way that {\em in each of exponentially many future scenarios}, sufficient
money is available in the ``right'' firms so she can buy an ``optimal
investment'' for that scenario.
</p>
<p>We study a restriction of this game to {\em perfect graphs} and characterize
its core. Our characterization is analogous to Shapley and Shubik's
characterization of the core of the assignment game. The difference is the
following: whereas their characterization follows from {\em total
unimodularity}, ours follows from {\em total dual integrality}. The latter is
another novelty of our work.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/econ/1/au:+Vazirani_V/0/1/0/all/0/1">Vijay V. Vazirani</a></p><p>The core is a dominant solution concept in economics and game theory. In this
context, the following question arises, ``How versatile is this solution
concept?'' We note that within game theory, this notion has been used for
profit -- equivalently, cost or utility -- sharing only. In this paper, we show
a completely different use for it: in an {\em investment management game},
under which an agent needs to allocate her money among investment firms in such
a way that {\em in each of exponentially many future scenarios}, sufficient
money is available in the ``right'' firms so she can buy an ``optimal
investment'' for that scenario.
</p>
<p>We study a restriction of this game to {\em perfect graphs} and characterize
its core. Our characterization is analogous to Shapley and Shubik's
characterization of the core of the assignment game. The difference is the
following: whereas their characterization follows from {\em total
unimodularity}, ours follows from {\em total dual integrality}. The latter is
another novelty of our work.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00630'>Parameterized Algorithms for Colored Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Leon Kellerhals, Tomohiro Koana, Pascal Kunz, Rolf Niedermeier</p><p>In the Colored Clustering problem, one is asked to cluster edge-colored
(hyper-)graphs whose colors represent interaction types. More specifically, the
goal is to select as many edges as possible without choosing two edges that
share an endpoint and are colored differently. Equivalently, the goal can also
be described as assigning colors to the vertices in a way that fits the
edge-coloring as well as possible. As this problem is NP-hard, we build on
previous work by studying its parameterized complexity. We give a $2^{\mathcal
O(k)} \cdot n^{\mathcal O(1)}$-time algorithm where $k$ is the number of edges
to be selected and $n$ the number of vertices. We also prove the existence of a
problem kernel of size $\mathcal O(k^{5/2} )$, resolving an open problem posed
in the literature. We consider parameters that are smaller than $k$, the number
of edges to be selected, and $r$, the number of edges that can be deleted. Such
smaller parameters are obtained by considering the difference between $k$ or
$r$ and some lower bound on these values. We give both algorithms and lower
bounds for Colored Clustering with such parameterizations. Finally, we settle
the parameterized complexity of Colored Clustering with respect to structural
graph parameters by showing that it is $W[1]$-hard with respect to both vertex
cover number and tree-cut width, but fixed-parameter tractable with respect to
slim tree-cut width.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kellerhals_L/0/1/0/all/0/1">Leon Kellerhals</a>, <a href="http://arxiv.org/find/cs/1/au:+Koana_T/0/1/0/all/0/1">Tomohiro Koana</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunz_P/0/1/0/all/0/1">Pascal Kunz</a>, <a href="http://arxiv.org/find/cs/1/au:+Niedermeier_R/0/1/0/all/0/1">Rolf Niedermeier</a></p><p>In the Colored Clustering problem, one is asked to cluster edge-colored
(hyper-)graphs whose colors represent interaction types. More specifically, the
goal is to select as many edges as possible without choosing two edges that
share an endpoint and are colored differently. Equivalently, the goal can also
be described as assigning colors to the vertices in a way that fits the
edge-coloring as well as possible. As this problem is NP-hard, we build on
previous work by studying its parameterized complexity. We give a $2^{\mathcal
O(k)} \cdot n^{\mathcal O(1)}$-time algorithm where $k$ is the number of edges
to be selected and $n$ the number of vertices. We also prove the existence of a
problem kernel of size $\mathcal O(k^{5/2} )$, resolving an open problem posed
in the literature. We consider parameters that are smaller than $k$, the number
of edges to be selected, and $r$, the number of edges that can be deleted. Such
smaller parameters are obtained by considering the difference between $k$ or
$r$ and some lower bound on these values. We give both algorithms and lower
bounds for Colored Clustering with such parameterizations. Finally, we settle
the parameterized complexity of Colored Clustering with respect to structural
graph parameters by showing that it is $W[1]$-hard with respect to both vertex
cover number and tree-cut width, but fixed-parameter tractable with respect to
slim tree-cut width.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.00657'>Adding a Tail in Classes of Perfect Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anna Mpanti, Stavros D. Nikolopoulos, Leonidas Palios</p><p>Consider a graph $G$ which belongs to a graph class ${\cal C}$. We are
interested in connecting a node $w \not\in V(G)$ to $G$ by a single edge $u w$
where $u \in V(G)$; we call such an edge a \emph{tail}. As the graph resulting
from $G$ after the addition of the tail, denoted $G+uw$, need not belong to the
class ${\cal C}$, we want to compute a minimum ${\cal C}$-completion of $G+w$,
i.e., the minimum number of non-edges (excluding the tail $u w$) to be added to
$G+uw$ so that the resulting graph belongs to ${\cal C}$. In this paper, we
study this problem for the classes of split, quasi-threshold, threshold, and
$P_4$-sparse graphs and we present linear-time algorithms by exploiting the
structure of split graphs and the tree representation of quasi-threshold,
threshold, and $P_4$-sparse graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mpanti_A/0/1/0/all/0/1">Anna Mpanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolopoulos_S/0/1/0/all/0/1">Stavros D. Nikolopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Palios_L/0/1/0/all/0/1">Leonidas Palios</a></p><p>Consider a graph $G$ which belongs to a graph class ${\cal C}$. We are
interested in connecting a node $w \not\in V(G)$ to $G$ by a single edge $u w$
where $u \in V(G)$; we call such an edge a \emph{tail}. As the graph resulting
from $G$ after the addition of the tail, denoted $G+uw$, need not belong to the
class ${\cal C}$, we want to compute a minimum ${\cal C}$-completion of $G+w$,
i.e., the minimum number of non-edges (excluding the tail $u w$) to be added to
$G+uw$ so that the resulting graph belongs to ${\cal C}$. In this paper, we
study this problem for the classes of split, quasi-threshold, threshold, and
$P_4$-sparse graphs and we present linear-time algorithms by exploiting the
structure of split graphs and the tree representation of quasi-threshold,
threshold, and $P_4$-sparse graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-02T01:30:00Z">Thursday, February 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, February 01
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13224'>Near-perfect Reachability of Variational Quantum Search with Depth-1 Ansatz</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Junpeng Zhan</p><p>Grover's search algorithm is renowned for its dramatic speedup in solving
many important scientific problems. The recently proposed Variational Quantum
Search (VQS) algorithm has shown an exponential advantage over Grover's
algorithm for up to 26 qubits. However, its advantage for larger numbers of
qubits has not yet been proven. Here we show that the exponentially deep
circuit required by Grover's algorithm can be replaced by a multi-controlled
NOT gate together with either a single layer of Ry gates or two layers of
circuits consisting of Hadamard and NOT gates, which is valid for any number of
qubits greater than five. We prove that the VQS, with a single layer of Ry
gates as its Ansatz, has near-perfect reachability in finding the good element
of an arbitrarily large unstructured data set, and its reachability
exponentially improves with the number of qubits, where the reachability is
defined to quantify the ability of a given Ansatz to generate an optimal
quantum state. Numerical studies further validate the excellent reachability of
the VQS. Proving the near-perfect reachability of the VQS, with a depth-1
Ansatz, for any number of qubits completes an essential step in proving its
exponential advantage over Grover's algorithm for any number of qubits, and the
latter proving is significant as it means that the VQS can efficiently solve
NP-complete problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Zhan_J/0/1/0/all/0/1">Junpeng Zhan</a></p><p>Grover's search algorithm is renowned for its dramatic speedup in solving
many important scientific problems. The recently proposed Variational Quantum
Search (VQS) algorithm has shown an exponential advantage over Grover's
algorithm for up to 26 qubits. However, its advantage for larger numbers of
qubits has not yet been proven. Here we show that the exponentially deep
circuit required by Grover's algorithm can be replaced by a multi-controlled
NOT gate together with either a single layer of Ry gates or two layers of
circuits consisting of Hadamard and NOT gates, which is valid for any number of
qubits greater than five. We prove that the VQS, with a single layer of Ry
gates as its Ansatz, has near-perfect reachability in finding the good element
of an arbitrarily large unstructured data set, and its reachability
exponentially improves with the number of qubits, where the reachability is
defined to quantify the ability of a given Ansatz to generate an optimal
quantum state. Numerical studies further validate the excellent reachability of
the VQS. Proving the near-perfect reachability of the VQS, with a depth-1
Ansatz, for any number of qubits completes an essential step in proving its
exponential advantage over Grover's algorithm for any number of qubits, and the
latter proving is significant as it means that the VQS can efficiently solve
NP-complete problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13329'>A Finer Analysis of Multi-Structural Games and Beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marco Carmosino, Ronald Fagin, Neil Immerman, Phokion Kolaitis, Jonathan Lenchner, Rik Sengupta</p><p>Multi-structural (MS) games are combinatorial games that capture the number
of quantifiers of first-order sentences. On the face of their definition, MS
games differ from Ehrenfeucht-Fraisse (EF) games in two ways: first, MS games
are played on two sets of structures, while EF games are played on a pair of
structures; second, in MS games, Duplicator can make any number of copies of
structures. In the first part of this paper, we perform a finer analysis of MS
games and develop a closer comparison of MS games with EF games. In particular,
we point out that the use of sets of structures is of the essence and that when
MS games are played on pairs of structures, they capture Boolean combinations
of first-order sentences with a fixed number of quantifiers. After this, we
focus on another important difference between MS games and EF games, namely,
the necessity for Spoiler to play on top of a previous move in order to win
some MS games. Via an analysis of the types realized during MS games, we
delineate the expressive power of the variant of MS games in which Spoiler
never plays on top of a previous move. In the second part we focus on
simultaneously capturing number of quantifiers and number of variables in
first-order logic. We show that natural variants of the MS game do not achieve
this. We then introduce a new game, the quantifier-variable tree game, and show
that it simultaneously captures the number of quantifiers and number of
variables.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Carmosino_M/0/1/0/all/0/1">Marco Carmosino</a>, <a href="http://arxiv.org/find/cs/1/au:+Fagin_R/0/1/0/all/0/1">Ronald Fagin</a>, <a href="http://arxiv.org/find/cs/1/au:+Immerman_N/0/1/0/all/0/1">Neil Immerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolaitis_P/0/1/0/all/0/1">Phokion Kolaitis</a>, <a href="http://arxiv.org/find/cs/1/au:+Lenchner_J/0/1/0/all/0/1">Jonathan Lenchner</a>, <a href="http://arxiv.org/find/cs/1/au:+Sengupta_R/0/1/0/all/0/1">Rik Sengupta</a></p><p>Multi-structural (MS) games are combinatorial games that capture the number
of quantifiers of first-order sentences. On the face of their definition, MS
games differ from Ehrenfeucht-Fraisse (EF) games in two ways: first, MS games
are played on two sets of structures, while EF games are played on a pair of
structures; second, in MS games, Duplicator can make any number of copies of
structures. In the first part of this paper, we perform a finer analysis of MS
games and develop a closer comparison of MS games with EF games. In particular,
we point out that the use of sets of structures is of the essence and that when
MS games are played on pairs of structures, they capture Boolean combinations
of first-order sentences with a fixed number of quantifiers. After this, we
focus on another important difference between MS games and EF games, namely,
the necessity for Spoiler to play on top of a previous move in order to win
some MS games. Via an analysis of the types realized during MS games, we
delineate the expressive power of the variant of MS games in which Spoiler
never plays on top of a previous move. In the second part we focus on
simultaneously capturing number of quantifiers and number of variables in
first-order logic. We show that natural variants of the MS game do not achieve
this. We then introduce a new game, the quantifier-variable tree game, and show
that it simultaneously captures the number of quantifiers and number of
variables.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13603'>Limits of structures and Total NP Search Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ond&#x159;ej Je&#x17e;il</p><p>For a class of finite graphs, we define a limit object relative to some
computationally restricted class of functions. The properties of the limit
object then reflect how a computationally restricted viewer "sees" a generic
instance from the class. The construction uses Kraj\'i\v{c}ek's forcing with
random variables [7]. We prove sufficient conditions for universal and
existential sentences to be valid in the limit, provide several examples, and
prove that such a limit object can then be expanded to a model of weak
arithmetic. We then take the limit of all finite pointed paths to obtain a
model of arithmetic where the problem OntoWeakPigeon is total but Leaf (the
complete problem for $\textbf{PPA}$) is not. This can be viewed as a logical
separation of the oracle classes of total NP search problems, which in our
setting implies standard nonreducibility of Leaf to OntoWeakPigeon.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Jezil_O/0/1/0/all/0/1">Ond&#x159;ej Je&#x17e;il</a></p><p>For a class of finite graphs, we define a limit object relative to some
computationally restricted class of functions. The properties of the limit
object then reflect how a computationally restricted viewer "sees" a generic
instance from the class. The construction uses Kraj\'i\v{c}ek's forcing with
random variables [7]. We prove sufficient conditions for universal and
existential sentences to be valid in the limit, provide several examples, and
prove that such a limit object can then be expanded to a model of weak
arithmetic. We then take the limit of all finite pointed paths to obtain a
model of arithmetic where the problem OntoWeakPigeon is total but Leaf (the
complete problem for $\textbf{PPA}$) is not. This can be viewed as a logical
separation of the oracle classes of total NP search problems, which in our
setting implies standard nonreducibility of Leaf to OntoWeakPigeon.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13656'>A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Raphael Sulzer, Loic Landrieu, Renaud Marlet, Bruno Vallet</p><p>We survey and benchmark traditional and novel learning-based algorithms that
address the problem of surface reconstruction from point clouds. Surface
reconstruction from point clouds is particularly challenging when applied to
real-world acquisitions, due to noise, outliers, non-uniform sampling and
missing data. Traditionally, different handcrafted priors of the input points
or the output surface have been proposed to make the problem more tractable.
However, hyperparameter tuning for adjusting priors to different acquisition
defects can be a tedious task. To this end, the deep learning community has
recently addressed the surface reconstruction problem. In contrast to
traditional approaches, deep surface reconstruction methods can learn priors
directly from a training set of point clouds and corresponding true surfaces.
In our survey, we detail how different handcrafted and learned priors affect
the robustness of methods to defect-laden input and their capability to
generate geometric and topologically accurate reconstructions. In our
benchmark, we evaluate the reconstructions of several traditional and
learning-based methods on the same grounds. We show that learning-based methods
can generalize to unseen shape categories, but their training and test sets
must share the same point cloud characteristics. We also provide the code and
data to compete in our benchmark and to further stimulate the development of
learning-based surface reconstruction
github.com/raphaelsulzer/dsr-benchmark.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sulzer_R/0/1/0/all/0/1">Raphael Sulzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Landrieu_L/0/1/0/all/0/1">Loic Landrieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Marlet_R/0/1/0/all/0/1">Renaud Marlet</a>, <a href="http://arxiv.org/find/cs/1/au:+Vallet_B/0/1/0/all/0/1">Bruno Vallet</a></p><p>We survey and benchmark traditional and novel learning-based algorithms that
address the problem of surface reconstruction from point clouds. Surface
reconstruction from point clouds is particularly challenging when applied to
real-world acquisitions, due to noise, outliers, non-uniform sampling and
missing data. Traditionally, different handcrafted priors of the input points
or the output surface have been proposed to make the problem more tractable.
However, hyperparameter tuning for adjusting priors to different acquisition
defects can be a tedious task. To this end, the deep learning community has
recently addressed the surface reconstruction problem. In contrast to
traditional approaches, deep surface reconstruction methods can learn priors
directly from a training set of point clouds and corresponding true surfaces.
In our survey, we detail how different handcrafted and learned priors affect
the robustness of methods to defect-laden input and their capability to
generate geometric and topologically accurate reconstructions. In our
benchmark, we evaluate the reconstructions of several traditional and
learning-based methods on the same grounds. We show that learning-based methods
can generalize to unseen shape categories, but their training and test sets
must share the same point cloud characteristics. We also provide the code and
data to compete in our benchmark and to further stimulate the development of
learning-based surface reconstruction
https://github.com/raphaelsulzer/dsr-benchmark.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13541'>Singular Value Approximation and Reducing Directed to Undirected Graph Sparsification</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: AmirMahdi Ahmadinejad, John Peebles, Edward Pyne, Aaron Sidford, Salil Vadhan</p><p>In this paper, we introduce a new, spectral notion of approximation between
directed graphs, which we call Singular Value (SV) approximation.
SV-approximation is stronger than previous notions of spectral approximation
considered in the literature, including spectral approximation of Laplacians
for undirected graphs (Spielman Teng STOC 2004), standard approximation for
directed graphs (Cohen et. al. STOC 2007), and unit-circle approximation for
directed graphs (Ahmadinejad et. al. FOCS 2020). Moreover, SV approximation
enjoys several useful properties not known to be possessed by previous notions
of approximation, such as being preserved under products of random-walk
matrices and with matrices of bounded norm.
</p>
<p>Notably, we show that there is a simple black-box reduction from
SV-sparsifying Eulerian directed graphs to SV-sparsifying undirected graphs.
With this reduction in hand, we provide a nearly linear-time algorithm for
SV-sparsifying undirected and hence also Eulerian directed graphs. This also
yields the first nearly linear-time algorithm for unit-circle-sparsifying
Eulerian directed graphs. In addition, we give a nearly linear-time algorithm
for SV-sparsifying (and UC-sparsifying) random-walk polynomials of Eulerian
directed graphs with second normalized singular value bounded away from $1$ by
$1/\text{poly}(n)$.
</p>
<p>Finally, we show that a simple repeated-squaring and sparsification algorithm
for solving Laplacian systems, introduced by (Peng Spielman STOC 2014) for
undirected graphs, also works for Eulerian digraphs whose random-walk matrix is
normal (i.e. unitarily diagonalizable), if we use SV-sparsification at each
step. Prior Laplacian solvers for Eulerian digraphs are significantly more
complicated.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ahmadinejad_A/0/1/0/all/0/1">AmirMahdi Ahmadinejad</a>, <a href="http://arxiv.org/find/cs/1/au:+Peebles_J/0/1/0/all/0/1">John Peebles</a>, <a href="http://arxiv.org/find/cs/1/au:+Pyne_E/0/1/0/all/0/1">Edward Pyne</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidford_A/0/1/0/all/0/1">Aaron Sidford</a>, <a href="http://arxiv.org/find/cs/1/au:+Vadhan_S/0/1/0/all/0/1">Salil Vadhan</a></p><p>In this paper, we introduce a new, spectral notion of approximation between
directed graphs, which we call Singular Value (SV) approximation.
SV-approximation is stronger than previous notions of spectral approximation
considered in the literature, including spectral approximation of Laplacians
for undirected graphs (Spielman Teng STOC 2004), standard approximation for
directed graphs (Cohen et. al. STOC 2007), and unit-circle approximation for
directed graphs (Ahmadinejad et. al. FOCS 2020). Moreover, SV approximation
enjoys several useful properties not known to be possessed by previous notions
of approximation, such as being preserved under products of random-walk
matrices and with matrices of bounded norm.
</p>
<p>Notably, we show that there is a simple black-box reduction from
SV-sparsifying Eulerian directed graphs to SV-sparsifying undirected graphs.
With this reduction in hand, we provide a nearly linear-time algorithm for
SV-sparsifying undirected and hence also Eulerian directed graphs. This also
yields the first nearly linear-time algorithm for unit-circle-sparsifying
Eulerian directed graphs. In addition, we give a nearly linear-time algorithm
for SV-sparsifying (and UC-sparsifying) random-walk polynomials of Eulerian
directed graphs with second normalized singular value bounded away from $1$ by
$1/\text{poly}(n)$.
</p>
<p>Finally, we show that a simple repeated-squaring and sparsification algorithm
for solving Laplacian systems, introduced by (Peng Spielman STOC 2014) for
undirected graphs, also works for Eulerian digraphs whose random-walk matrix is
normal (i.e. unitarily diagonalizable), if we use SV-sparsification at each
step. Prior Laplacian solvers for Eulerian digraphs are significantly more
complicated.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13245'>A Safety Framework for Flow Decomposition Problems via Integer Linear Programming</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fernando H. C. Dias, Manuel Caceres, Lucia Williams, Brendan Mumey, Alexandru I. Tomescu</p><p>Many important problems in Bioinformatics (e.g., assembly or multi-assembly)
admit multiple solutions, while the final objective is to report only one. A
common approach to deal with this uncertainty is finding safe partial solutions
(e.g., contigs) which are common to all solutions. Previous research on safety
has focused on polynomially-time solvable problems, whereas many successful and
natural models are NP-hard to solve, leaving a lack of "safety tools" for such
problems. We propose the first method for computing all safe solutions for an
NP-hard problem, minimum flow decomposition. We obtain our results by
developing a "safety test" for paths based on a general Integer Linear
Programming (ILP) formulation. Moreover, we provide implementations with
practical optimizations aimed to reduce the total ILP time, the most efficient
of these being based on a recursive group-testing procedure.
</p>
<p>Results: Experimental results on the transcriptome datasets of Shao and
Kingsford (TCBB, 2017) show that all safe paths for minimum flow decompositions
correctly recover up to 90% of the full RNA transcripts, which is at least 25%
more than previously known safe paths, such as (Caceres et al. TCBB, 2021),
(Zheng et al., RECOMB 2021), (Khan et al., RECOMB 2022, ESA 2022). Moreover,
despite the NP-hardness of the problem, we can report all safe paths for 99.8%
of the over 27,000 non-trivial graphs of this dataset in only 1.5 hours. Our
results suggest that, on perfect data, there is less ambiguity than thought in
the notoriously hard RNA assembly problem.
</p>
<p>Availability: github.com/algbio/mfd-safety
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dias_F/0/1/0/all/0/1">Fernando H. C. Dias</a>, <a href="http://arxiv.org/find/cs/1/au:+Caceres_M/0/1/0/all/0/1">Manuel Caceres</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_L/0/1/0/all/0/1">Lucia Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Mumey_B/0/1/0/all/0/1">Brendan Mumey</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomescu_A/0/1/0/all/0/1">Alexandru I. Tomescu</a></p><p>Many important problems in Bioinformatics (e.g., assembly or multi-assembly)
admit multiple solutions, while the final objective is to report only one. A
common approach to deal with this uncertainty is finding safe partial solutions
(e.g., contigs) which are common to all solutions. Previous research on safety
has focused on polynomially-time solvable problems, whereas many successful and
natural models are NP-hard to solve, leaving a lack of "safety tools" for such
problems. We propose the first method for computing all safe solutions for an
NP-hard problem, minimum flow decomposition. We obtain our results by
developing a "safety test" for paths based on a general Integer Linear
Programming (ILP) formulation. Moreover, we provide implementations with
practical optimizations aimed to reduce the total ILP time, the most efficient
of these being based on a recursive group-testing procedure.
</p>
<p>Results: Experimental results on the transcriptome datasets of Shao and
Kingsford (TCBB, 2017) show that all safe paths for minimum flow decompositions
correctly recover up to 90% of the full RNA transcripts, which is at least 25%
more than previously known safe paths, such as (Caceres et al. TCBB, 2021),
(Zheng et al., RECOMB 2021), (Khan et al., RECOMB 2022, ESA 2022). Moreover,
despite the NP-hardness of the problem, we can report all safe paths for 99.8%
of the over 27,000 non-trivial graphs of this dataset in only 1.5 hours. Our
results suggest that, on perfect data, there is less ambiguity than thought in
the notoriously hard RNA assembly problem.
</p>
<p>Availability: https://github.com/algbio/mfd-safety
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13307'>Breadth-First Depth-Next: Optimal Collaborative Exploration of Trees with Low Diameter</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Romain Cosson, Laurent Massouli&#xe9;, Laurent Viennot</p><p>We consider the problem of collaborative tree exploration posed by
Fraigniaud, Gasieniec, Kowalski, and Pelc where a team of $k$ agents is tasked
to collectively go through all the edges of an unknown tree as fast as
possible. Denoting by $n$ the total number of nodes and by $D$ the tree depth,
the $\mathcal{O}(n/\log(k)+D)$ algorithm of Fraigniaud et al. achieves the
best-known competitive ratio with respect to the cost of offline exploration
which is $\Theta(\max{\{2n/k,2D\}})$. Brass, Cabrera-Mora, Gasparri, and Xiao
consider an alternative performance criterion, namely the additive overhead
with respect to $2n/k$, and obtain a $2n/k+\mathcal{O}((D+k)^k)$ runtime
guarantee. In this paper, we introduce `Breadth-First Depth-Next' (BFDN), a
novel and simple algorithm that performs collaborative tree exploration in time
$2n/k+\mathcal{O}(D^2\log(k))$, thus outperforming Brass et al. for all values
of $(n,D)$ and being order-optimal for all trees with depth $D=o_k(\sqrt{n})$.
Moreover, a recent result from Disser et al. implies that no exploration
algorithm can achieve a $2n/k+\mathcal{O}(D^{2-\epsilon})$ runtime guarantee.
The dependency in $D^2$ of our bound is in this sense optimal. The proof of our
result crucially relies on the analysis of an associated two-player game. We
extend the guarantees of BFDN to: scenarios with limited memory and
communication, adversarial setups where robots can be blocked, and exploration
of classes of non-tree graphs. Finally, we provide a recursive version of BFDN
with a runtime of $\mathcal{O}_\ell(n/k^{1/\ell}+\log(k) D^{1+1/\ell})$ for
parameter $\ell\ge 1$, thereby improving performance for trees with large
depth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cosson_R/0/1/0/all/0/1">Romain Cosson</a>, <a href="http://arxiv.org/find/cs/1/au:+Massoulie_L/0/1/0/all/0/1">Laurent Massouli&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Viennot_L/0/1/0/all/0/1">Laurent Viennot</a></p><p>We consider the problem of collaborative tree exploration posed by
Fraigniaud, Gasieniec, Kowalski, and Pelc where a team of $k$ agents is tasked
to collectively go through all the edges of an unknown tree as fast as
possible. Denoting by $n$ the total number of nodes and by $D$ the tree depth,
the $\mathcal{O}(n/\log(k)+D)$ algorithm of Fraigniaud et al. achieves the
best-known competitive ratio with respect to the cost of offline exploration
which is $\Theta(\max{\{2n/k,2D\}})$. Brass, Cabrera-Mora, Gasparri, and Xiao
consider an alternative performance criterion, namely the additive overhead
with respect to $2n/k$, and obtain a $2n/k+\mathcal{O}((D+k)^k)$ runtime
guarantee. In this paper, we introduce `Breadth-First Depth-Next' (BFDN), a
novel and simple algorithm that performs collaborative tree exploration in time
$2n/k+\mathcal{O}(D^2\log(k))$, thus outperforming Brass et al. for all values
of $(n,D)$ and being order-optimal for all trees with depth $D=o_k(\sqrt{n})$.
Moreover, a recent result from Disser et al. implies that no exploration
algorithm can achieve a $2n/k+\mathcal{O}(D^{2-\epsilon})$ runtime guarantee.
The dependency in $D^2$ of our bound is in this sense optimal. The proof of our
result crucially relies on the analysis of an associated two-player game. We
extend the guarantees of BFDN to: scenarios with limited memory and
communication, adversarial setups where robots can be blocked, and exploration
of classes of non-tree graphs. Finally, we provide a recursive version of BFDN
with a runtime of $\mathcal{O}_\ell(n/k^{1/\ell}+\log(k) D^{1+1/\ell})$ for
parameter $\ell\ge 1$, thereby improving performance for trees with large
depth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13317'>The Iteration Number of the Weisfeiler-Leman Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Martin Grohe, Moritz Lichter, Daniel Neuen</p><p>We prove new upper and lower bounds on the number of iterations the
$k$-dimensional Weisfeiler-Leman algorithm ($k$-WL) requires until
stabilization. For $k \geq 3$, we show that $k$-WL stabilizes after at most
$O(kn^{k-1}\log n)$ iterations (where $n$ denotes the number of vertices of the
input structures), obtaining the first improvement over the trivial upper bound
of $n^{k}-1$ and extending a previous upper bound of $O(n \log n)$ for $k=2$
[Lichter et al., LICS 2019].
</p>
<p>We complement our upper bounds by constructing $k$-ary relational structures
on which $k$-WL requires at least $n^{\Omega(k)}$ iterations to stabilize. This
improves over a previous lower bound of $n^{\Omega(k / \log k)}$ [Berkholz,
Nordstr\"{o}m, LICS 2016].
</p>
<p>We also investigate tradeoffs between the dimension and the iteration number
of WL, and show that $d$-WL, where $d = \lceil\frac{3(k+1)}{2}\rceil$, can
simulate the $k$-WL algorithm using only $O(k^2 \cdot n^{\lfloor k/2\rfloor +
1} \log n)$ many iterations, but still requires at least $n^{\Omega(k)}$
iterations for any $d$ (that is sufficiently smaller than $n$).
</p>
<p>The number of iterations required by $k$-WL to distinguish two structures
corresponds to the quantifier rank of a sentence distinguishing them in the $(k
+ 1)$-variable fragment $C_{k+1}$ of first-order logic with counting
quantifiers. Hence, our results also imply new upper and lower bounds on the
quantifier rank required in the logic $C_{k+1}$, as well as tradeoffs between
variable number and quantifier rank.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1">Martin Grohe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lichter_M/0/1/0/all/0/1">Moritz Lichter</a>, <a href="http://arxiv.org/find/cs/1/au:+Neuen_D/0/1/0/all/0/1">Daniel Neuen</a></p><p>We prove new upper and lower bounds on the number of iterations the
$k$-dimensional Weisfeiler-Leman algorithm ($k$-WL) requires until
stabilization. For $k \geq 3$, we show that $k$-WL stabilizes after at most
$O(kn^{k-1}\log n)$ iterations (where $n$ denotes the number of vertices of the
input structures), obtaining the first improvement over the trivial upper bound
of $n^{k}-1$ and extending a previous upper bound of $O(n \log n)$ for $k=2$
[Lichter et al., LICS 2019].
</p>
<p>We complement our upper bounds by constructing $k$-ary relational structures
on which $k$-WL requires at least $n^{\Omega(k)}$ iterations to stabilize. This
improves over a previous lower bound of $n^{\Omega(k / \log k)}$ [Berkholz,
Nordstr\"{o}m, LICS 2016].
</p>
<p>We also investigate tradeoffs between the dimension and the iteration number
of WL, and show that $d$-WL, where $d = \lceil\frac{3(k+1)}{2}\rceil$, can
simulate the $k$-WL algorithm using only $O(k^2 \cdot n^{\lfloor k/2\rfloor +
1} \log n)$ many iterations, but still requires at least $n^{\Omega(k)}$
iterations for any $d$ (that is sufficiently smaller than $n$).
</p>
<p>The number of iterations required by $k$-WL to distinguish two structures
corresponds to the quantifier rank of a sentence distinguishing them in the $(k
+ 1)$-variable fragment $C_{k+1}$ of first-order logic with counting
quantifiers. Hence, our results also imply new upper and lower bounds on the
quantifier rank required in the logic $C_{k+1}$, as well as tradeoffs between
variable number and quantifier rank.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13326'>A Framework for Adapting Offline Algorithms to Solve Combinatorial Multi-Armed Bandit Problems with Bandit Feedback</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guanyu Nie, Yididiya Y Nadew, Yanhui Zhu, Vaneet Aggarwal, Christopher John Quinn</p><p>We investigate the problem of stochastic, combinatorial multi-armed bandits
where the learner only has access to bandit feedback and the reward function
can be non-linear. We provide a general framework for adapting discrete offline
approximation algorithms into sublinear $\alpha$-regret methods that only
require bandit feedback, achieving
$\mathcal{O}\left(T^\frac{2}{3}\log(T)^\frac{1}{3}\right)$ expected cumulative
$\alpha$-regret dependence on the horizon $T$. The framework only requires the
offline algorithms to be robust to small errors in function evaluation. The
adaptation procedure does not even require explicit knowledge of the offline
approximation algorithm -- the offline algorithm can be used as black box
subroutine.
</p>
<p>To demonstrate the utility of the proposed framework, the proposed framework
is applied to multiple problems in submodular maximization, adapting
approximation algorithms for cardinality and for knapsack constraints. The new
CMAB algorithms for knapsack constraints outperform a full-bandit method
developed for the adversarial setting in experiments with real-world data.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nie_G/0/1/0/all/0/1">Guanyu Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadew_Y/0/1/0/all/0/1">Yididiya Y Nadew</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanhui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1">Vaneet Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Quinn_C/0/1/0/all/0/1">Christopher John Quinn</a></p><p>We investigate the problem of stochastic, combinatorial multi-armed bandits
where the learner only has access to bandit feedback and the reward function
can be non-linear. We provide a general framework for adapting discrete offline
approximation algorithms into sublinear $\alpha$-regret methods that only
require bandit feedback, achieving
$\mathcal{O}\left(T^\frac{2}{3}\log(T)^\frac{1}{3}\right)$ expected cumulative
$\alpha$-regret dependence on the horizon $T$. The framework only requires the
offline algorithms to be robust to small errors in function evaluation. The
adaptation procedure does not even require explicit knowledge of the offline
approximation algorithm -- the offline algorithm can be used as black box
subroutine.
</p>
<p>To demonstrate the utility of the proposed framework, the proposed framework
is applied to multiple problems in submodular maximization, adapting
approximation algorithms for cardinality and for knapsack constraints. The new
CMAB algorithms for knapsack constraints outperform a full-bandit method
developed for the adversarial setting in experiments with real-world data.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13334'>A Bias-Variance-Privacy Trilemma for Statistical Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gautam Kamath, Argyris Mouzakis, Matthew Regehr, Vikrant Singhal, Thomas Steinke, Jonathan Ullman</p><p>The canonical algorithm for differentially private mean estimation is to
first clip the samples to a bounded range and then add noise to their empirical
mean. Clipping controls the sensitivity and, hence, the variance of the noise
that we add for privacy. But clipping also introduces statistical bias. We
prove that this tradeoff is inherent: no algorithm can simultaneously have low
bias, low variance, and low privacy loss for arbitrary distributions.
</p>
<p>On the positive side, we show that unbiased mean estimation is possible under
approximate differential privacy if we assume that the distribution is
symmetric. Furthermore, we show that, even if we assume that the data is
sampled from a Gaussian, unbiased mean estimation is impossible under pure or
concentrated differential privacy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Kamath_G/0/1/0/all/0/1">Gautam Kamath</a>, <a href="http://arxiv.org/find/math/1/au:+Mouzakis_A/0/1/0/all/0/1">Argyris Mouzakis</a>, <a href="http://arxiv.org/find/math/1/au:+Regehr_M/0/1/0/all/0/1">Matthew Regehr</a>, <a href="http://arxiv.org/find/math/1/au:+Singhal_V/0/1/0/all/0/1">Vikrant Singhal</a>, <a href="http://arxiv.org/find/math/1/au:+Steinke_T/0/1/0/all/0/1">Thomas Steinke</a>, <a href="http://arxiv.org/find/math/1/au:+Ullman_J/0/1/0/all/0/1">Jonathan Ullman</a></p><p>The canonical algorithm for differentially private mean estimation is to
first clip the samples to a bounded range and then add noise to their empirical
mean. Clipping controls the sensitivity and, hence, the variance of the noise
that we add for privacy. But clipping also introduces statistical bias. We
prove that this tradeoff is inherent: no algorithm can simultaneously have low
bias, low variance, and low privacy loss for arbitrary distributions.
</p>
<p>On the positive side, we show that unbiased mean estimation is possible under
approximate differential privacy if we assume that the distribution is
symmetric. Furthermore, we show that, even if we assume that the data is
sampled from a Gaussian, unbiased mean estimation is impossible under pure or
concentrated differential privacy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13534'>Weitzman's Rule for Pandora's Box with Correlations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Evangelia Gergatsouli, Christos Tzamos</p><p>Pandora's Box is a central problem in decision making under uncertainty that
can model various real life scenarios. In this problem we are given $n$ boxes,
each with a fixed opening cost, and an unknown value drawn from a known
distribution, only revealed if we pay the opening cost. Our goal is to find a
strategy for opening boxes to minimize the sum of the value selected and the
opening cost paid.
</p>
<p>In this work we revisit Pandora's Box when the value distributions are
correlated, first studied in Chawla et al. (arXiv:1911.01632). We show that the
optimal algorithm for the independent case, given by Weitzman's rule, directly
works for the correlated case. In fact, our algorithm results in significantly
improved approximation guarantees compared to the previous work, while also
being substantially simpler. We finally show how to implement the rule given
only sample access to the correlated distribution of values. Specifically, we
find that a number of samples that is polynomial in the number of boxes is
sufficient for the algorithm to work.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gergatsouli_E/0/1/0/all/0/1">Evangelia Gergatsouli</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1">Christos Tzamos</a></p><p>Pandora's Box is a central problem in decision making under uncertainty that
can model various real life scenarios. In this problem we are given $n$ boxes,
each with a fixed opening cost, and an unknown value drawn from a known
distribution, only revealed if we pay the opening cost. Our goal is to find a
strategy for opening boxes to minimize the sum of the value selected and the
opening cost paid.
</p>
<p>In this work we revisit Pandora's Box when the value distributions are
correlated, first studied in Chawla et al. (<a href="/abs/1911.01632">arXiv:1911.01632</a>). We show that the
optimal algorithm for the independent case, given by Weitzman's rule, directly
works for the correlated case. In fact, our algorithm results in significantly
improved approximation guarantees compared to the previous work, while also
being substantially simpler. We finally show how to implement the rule given
only sample access to the correlated distribution of values. Specifically, we
find that a number of samples that is polynomial in the number of boxes is
sufficient for the algorithm to work.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13723'>p-median location interdiction on trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lena Lei&#xdf;, Till Heller, Luca E. Sch&#xe4;fer, Manuel Streicher, Stefan Ruzika</p><p>In p-median location interdiction the aim is to find a subset of edges in a
graph, such that the objective value of the p-median problem in the same graph
without the selected edges is as large as possible.
</p>
<p>We prove that this problem is NP-hard even on acyclic graphs. Restricting the
problem to trees with unit lengths on the edges, unit interdiction costs, and a
single edge interdiction, we provide an algorithm which solves the problem in
polynomial time. Furthermore, we investigate path graphs with unit and
arbitrary lengths. For the former case, we present an algorithm, where multiple
edges can get interdicted. Furthermore, for the latter case, we present a
method to compute an optimal solution for one interdiction step which can also
be extended to multiple interdicted edges.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Leiss_L/0/1/0/all/0/1">Lena Lei&#xdf;</a>, <a href="http://arxiv.org/find/cs/1/au:+Heller_T/0/1/0/all/0/1">Till Heller</a>, <a href="http://arxiv.org/find/cs/1/au:+Schafer_L/0/1/0/all/0/1">Luca E. Sch&#xe4;fer</a>, <a href="http://arxiv.org/find/cs/1/au:+Streicher_M/0/1/0/all/0/1">Manuel Streicher</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruzika_S/0/1/0/all/0/1">Stefan Ruzika</a></p><p>In p-median location interdiction the aim is to find a subset of edges in a
graph, such that the objective value of the p-median problem in the same graph
without the selected edges is as large as possible.
</p>
<p>We prove that this problem is NP-hard even on acyclic graphs. Restricting the
problem to trees with unit lengths on the edges, unit interdiction costs, and a
single edge interdiction, we provide an algorithm which solves the problem in
polynomial time. Furthermore, we investigate path graphs with unit and
arbitrary lengths. For the former case, we present an algorithm, where multiple
edges can get interdicted. Furthermore, for the latter case, we present a
method to compute an optimal solution for one interdiction step which can also
be extended to multiple interdicted edges.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13735'>Flipper games for monadically stable graph classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jakub Gajarsk&#xfd;, Nikolas M&#xe4;hlmann, Rose McCarty, Pierre Ohlmann, Micha&#x142; Pilipczuk, Wojciech Przybyszewski, Sebastian Siebertz, Marek Soko&#x142;owski, Szymon Toru&#x144;czyk</p><p>A class of graphs $\mathscr{C}$ is monadically stable if for any unary
expansion $\widehat{\mathscr{C}}$ of $\mathscr{C}$, one cannot interpret, in
first-order logic, arbitrarily long linear orders in graphs from
$\widehat{\mathscr{C}}$. It is known that nowhere dense graph classes are
monadically stable; these encompass most of the studied concepts of sparsity in
graphs, including graph classes that exclude a fixed topological minor. On the
other hand, monadic stability is a property expressed in purely model-theoretic
terms and hence it is also suited for capturing structure in dense graphs.
</p>
<p>For several years, it has been suspected that one can create a structure
theory for monadically stable graph classes that mirrors the theory of nowhere
dense graph classes in the dense setting. In this work we provide a step in
this direction by giving a characterization of monadic stability through the
Flipper game: a game on a graph played by Flipper, who in each round can
complement the edge relation between any pair of vertex subsets, and Connector,
who in each round localizes the game to a ball of bounded radius. This is an
analog of the Splitter game, which characterizes nowhere dense classes of
graphs (Grohe, Kreutzer, and Siebertz, J.ACM'17).
</p>
<p>We give two different proofs of our main result. The first proof uses tools
from model theory, and it exposes an additional property of monadically stable
graph classes that is close in spirit to definability of types. Also, as a
byproduct, we give an alternative proof of the recent result of Braunfeld and
Laskowski (arXiv 2209.05120) that monadic stability for graph classes coincides
with existential monadic stability. The second proof relies on the recently
introduced notion of flip-wideness (Dreier, M\"ahlmann, Siebertz, and
Toru\'nczyk, arXiv 2206.13765) and provides an efficient algorithm to compute
Flipper's moves in a winning strategy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gajarsky_J/0/1/0/all/0/1">Jakub Gajarsk&#xfd;</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahlmann_N/0/1/0/all/0/1">Nikolas M&#xe4;hlmann</a>, <a href="http://arxiv.org/find/cs/1/au:+McCarty_R/0/1/0/all/0/1">Rose McCarty</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohlmann_P/0/1/0/all/0/1">Pierre Ohlmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Micha&#x142; Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Przybyszewski_W/0/1/0/all/0/1">Wojciech Przybyszewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Siebertz_S/0/1/0/all/0/1">Sebastian Siebertz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolowski_M/0/1/0/all/0/1">Marek Soko&#x142;owski</a>, <a href="http://arxiv.org/find/cs/1/au:+Torunczyk_S/0/1/0/all/0/1">Szymon Toru&#x144;czyk</a></p><p>A class of graphs $\mathscr{C}$ is monadically stable if for any unary
expansion $\widehat{\mathscr{C}}$ of $\mathscr{C}$, one cannot interpret, in
first-order logic, arbitrarily long linear orders in graphs from
$\widehat{\mathscr{C}}$. It is known that nowhere dense graph classes are
monadically stable; these encompass most of the studied concepts of sparsity in
graphs, including graph classes that exclude a fixed topological minor. On the
other hand, monadic stability is a property expressed in purely model-theoretic
terms and hence it is also suited for capturing structure in dense graphs.
</p>
<p>For several years, it has been suspected that one can create a structure
theory for monadically stable graph classes that mirrors the theory of nowhere
dense graph classes in the dense setting. In this work we provide a step in
this direction by giving a characterization of monadic stability through the
Flipper game: a game on a graph played by Flipper, who in each round can
complement the edge relation between any pair of vertex subsets, and Connector,
who in each round localizes the game to a ball of bounded radius. This is an
analog of the Splitter game, which characterizes nowhere dense classes of
graphs (Grohe, Kreutzer, and Siebertz, J.ACM'17).
</p>
<p>We give two different proofs of our main result. The first proof uses tools
from model theory, and it exposes an additional property of monadically stable
graph classes that is close in spirit to definability of types. Also, as a
byproduct, we give an alternative proof of the recent result of Braunfeld and
Laskowski (arXiv <a href="/abs/2209.05120">2209.05120</a>) that monadic stability for graph classes coincides
with existential monadic stability. The second proof relies on the recently
introduced notion of flip-wideness (Dreier, M\"ahlmann, Siebertz, and
Toru\'nczyk, arXiv <a href="/abs/2206.13765">2206.13765</a>) and provides an efficient algorithm to compute
Flipper's moves in a winning strategy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13767'>Multicalibration as Boosting for Regression</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ira Globus-Harris, Declan Harrison, Michael Kearns, Aaron Roth, Jessica Sorrell</p><p>We study the connection between multicalibration and boosting for squared
error regression. First we prove a useful characterization of multicalibration
in terms of a ``swap regret'' like condition on squared error. Using this
characterization, we give an exceedingly simple algorithm that can be analyzed
both as a boosting algorithm for regression and as a multicalibration algorithm
for a class H that makes use only of a standard squared error regression oracle
for H. We give a weak learning assumption on H that ensures convergence to
Bayes optimality without the need to make any realizability assumptions --
giving us an agnostic boosting algorithm for regression. We then show that our
weak learning assumption on H is both necessary and sufficient for
multicalibration with respect to H to imply Bayes optimality. We also show that
if H satisfies our weak learning condition relative to another class C then
multicalibration with respect to H implies multicalibration with respect to C.
Finally we investigate the empirical performance of our algorithm
experimentally using an open source implementation that we make available. Our
code repository can be found at
github.com/Declancharrison/Level-Set-Boosting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Globus_Harris_I/0/1/0/all/0/1">Ira Globus-Harris</a>, <a href="http://arxiv.org/find/cs/1/au:+Harrison_D/0/1/0/all/0/1">Declan Harrison</a>, <a href="http://arxiv.org/find/cs/1/au:+Kearns_M/0/1/0/all/0/1">Michael Kearns</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1">Aaron Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorrell_J/0/1/0/all/0/1">Jessica Sorrell</a></p><p>We study the connection between multicalibration and boosting for squared
error regression. First we prove a useful characterization of multicalibration
in terms of a ``swap regret'' like condition on squared error. Using this
characterization, we give an exceedingly simple algorithm that can be analyzed
both as a boosting algorithm for regression and as a multicalibration algorithm
for a class H that makes use only of a standard squared error regression oracle
for H. We give a weak learning assumption on H that ensures convergence to
Bayes optimality without the need to make any realizability assumptions --
giving us an agnostic boosting algorithm for regression. We then show that our
weak learning assumption on H is both necessary and sufficient for
multicalibration with respect to H to imply Bayes optimality. We also show that
if H satisfies our weak learning condition relative to another class C then
multicalibration with respect to H implies multicalibration with respect to C.
Finally we investigate the empirical performance of our algorithm
experimentally using an open source implementation that we make available. Our
code repository can be found at
https://github.com/Declancharrison/Level-Set-Boosting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13832'>Bounds for c-Ideal Hashing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fabian Frei, David Wehner</p><p>In this paper, we analyze hashing from a worst-case perspective. To this end,
we study a new property of hash families that is strongly related to d-perfect
hashing, namely c-ideality. On the one hand, this notion generalizes the
definition of perfect hashing, which has been studied extensively; on the other
hand, it provides a direct link to the notion of c-approximativity. We focus on
the usually neglected case where the average load \alpha is at least 1 and
prove upper and lower parametrized bounds on the minimal size of c-ideal hash
families.
</p>
<p>As an aside, we show how c-ideality helps to analyze the advice complexity of
hashing. The concept of advice, introduced a decade ago, lets us measure the
information content of an online problem. We prove hashing's advice complexity
to be linear in the hash table size.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Frei_F/0/1/0/all/0/1">Fabian Frei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wehner_D/0/1/0/all/0/1">David Wehner</a></p><p>In this paper, we analyze hashing from a worst-case perspective. To this end,
we study a new property of hash families that is strongly related to d-perfect
hashing, namely c-ideality. On the one hand, this notion generalizes the
definition of perfect hashing, which has been studied extensively; on the other
hand, it provides a direct link to the notion of c-approximativity. We focus on
the usually neglected case where the average load \alpha is at least 1 and
prove upper and lower parametrized bounds on the minimal size of c-ideal hash
families.
</p>
<p>As an aside, we show how c-ideality helps to analyze the advice complexity of
hashing. The concept of advice, introduced a decade ago, lets us measure the
information content of an online problem. We prove hashing's advice complexity
to be linear in the hash table size.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13850'>Gaussian Noise is Nearly Instance Optimal for Private Unbiased Mean Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aleksandar Nikolov, Haohua Tang</p><p>We investigate unbiased high-dimensional mean estimators in differential
privacy. We consider differentially private mechanisms whose expected output
equals the mean of the input dataset, for every dataset drawn from a fixed
convex domain $K$ in $\mathbb{R}^d$. In the setting of concentrated
differential privacy, we show that, for every input such an unbiased mean
estimator introduces approximately at least as much error as a mechanism that
adds Gaussian noise with a carefully chosen covariance. This is true when the
error is measured with respect to $\ell_p$ error for any $p \ge 2$. We extend
this result to local differential privacy, and to approximate differential
privacy, but for the latter the error lower bound holds either for a dataset or
for a neighboring dataset. We also extend our results to mechanisms that take
i.i.d.~samples from a distribution over $K$ and are unbiased with respect to
the mean of the distribution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Nikolov_A/0/1/0/all/0/1">Aleksandar Nikolov</a>, <a href="http://arxiv.org/find/math/1/au:+Tang_H/0/1/0/all/0/1">Haohua Tang</a></p><p>We investigate unbiased high-dimensional mean estimators in differential
privacy. We consider differentially private mechanisms whose expected output
equals the mean of the input dataset, for every dataset drawn from a fixed
convex domain $K$ in $\mathbb{R}^d$. In the setting of concentrated
differential privacy, we show that, for every input such an unbiased mean
estimator introduces approximately at least as much error as a mechanism that
adds Gaussian noise with a carefully chosen covariance. This is true when the
error is measured with respect to $\ell_p$ error for any $p \ge 2$. We extend
this result to local differential privacy, and to approximate differential
privacy, but for the latter the error lower bound holds either for a dataset or
for a neighboring dataset. We also extend our results to mechanisms that take
i.i.d.~samples from a distribution over $K$ and are unbiased with respect to
the mean of the distribution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.13860'>Zero-Memory Graph Exploration with Unknown Inports</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hans-Joachim B&#xf6;ckenhauer, Fabian Frei, Walter Unger, David Wehner</p><p>We study a very restrictive graph exploration problem. In our model, an agent
without persistent memory is placed on a vertex of a graph and only sees the
adjacent vertices. The goal is to visit every vertex of the graph, return to
the start vertex, and terminate. The agent does not know through which edge it
entered a vertex. The agent may color the current vertex and can see the colors
of the neighboring vertices in an arbitrary order. The agent may not recolor a
vertex. We investigate the number of colors necessary and sufficient to explore
all graphs. We prove that n-1 colors are necessary and sufficient for
exploration in general, 3 colors are necessary and sufficient if only trees are
to be explored, and min(2k-3,n-1) colors are necessary and min(2k-1,n-1) colors
are sufficient on graphs of size n and circumference $k$, where the
circumference is the length of a longest cycle. This only holds if an algorithm
has to explore all graphs and not merely certain graph classes. We give an
example for a graph class where each graph can be explored with 4 colors,
although the graphs have maximal circumference. Moreover, we prove that
recoloring vertices is very powerful by designing an algorithm with recoloring
that uses only 7 colors and explores all graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bockenhauer_H/0/1/0/all/0/1">Hans-Joachim B&#xf6;ckenhauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Frei_F/0/1/0/all/0/1">Fabian Frei</a>, <a href="http://arxiv.org/find/cs/1/au:+Unger_W/0/1/0/all/0/1">Walter Unger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wehner_D/0/1/0/all/0/1">David Wehner</a></p><p>We study a very restrictive graph exploration problem. In our model, an agent
without persistent memory is placed on a vertex of a graph and only sees the
adjacent vertices. The goal is to visit every vertex of the graph, return to
the start vertex, and terminate. The agent does not know through which edge it
entered a vertex. The agent may color the current vertex and can see the colors
of the neighboring vertices in an arbitrary order. The agent may not recolor a
vertex. We investigate the number of colors necessary and sufficient to explore
all graphs. We prove that n-1 colors are necessary and sufficient for
exploration in general, 3 colors are necessary and sufficient if only trees are
to be explored, and min(2k-3,n-1) colors are necessary and min(2k-1,n-1) colors
are sufficient on graphs of size n and circumference $k$, where the
circumference is the length of a longest cycle. This only holds if an algorithm
has to explore all graphs and not merely certain graph classes. We give an
example for a graph class where each graph can be explored with 4 colors,
although the graphs have maximal circumference. Moreover, we prove that
recoloring vertices is very powerful by designing an algorithm with recoloring
that uses only 7 colors and explores all graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-01T01:30:00Z">Wednesday, February 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, January 31
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/01/31/linkage-glass-viruses.html'>Linkage with glass viruses and a Cheeto sphere</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          FOCS 2023 introduces a new âconjectures trackâ (\(\mathbb{M}\)), seeking papers like the one by Khot that introduced the Unique Games Conjecture.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://windowsontheory.org/2023/01/16/new-in-focs-2023-a-conjectures-track/">FOCS 2023 introduces a new âconjectures trackâ</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109701298874363291">\(\mathbb{M}\)</a>),</span> seeking papers like the one by Khot that introduced the Unique Games Conjecture.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2212.14200">Intersecting ellipses induced by a max-sum matching</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109708982979012608">\(\mathbb{M}\)</a>).</span> Any matching on \(2n\) plane points is shorter than any star with them as leaves, by the triangle inequality. But sometimes not much shorter: there is a matching and star center from which all matched edges have angles \(\ge 2\pi/3\), so the length ratio is \(\le 2/\sqrt3\). This preprint by Barabanshchikova &amp; Polyanskii proves more: the max length matching itself has a star that approximates each edge individually with the same ratio.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/finally-a-fast-algorithm-for-shortest-paths-on-negative-graphs-20230118/">Three computer scientists have discovered a fast algorithm for finding  shortest paths between points on graphs with negative weights</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@QuantaMagazine@mstdn.social/109711314801457276">\(\mathbb{M}\)</a>),</span> <em>Quanta</em> summary of a recent breakthrough on a long-standing optimization problem. The original paper by Aaron Bernstein, Danupon Nanongkai, and Christian Wulff-Nilsen is in FOCS 2022 and online at <a href="https://arxiv.org/abs/2203.03456">arXiv:2203.03456</a>.</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2023/01/17/as-the-us-public-domain-expands-20-year-pause-for-the-canadian-public-domain-begins/">The release of works into the public domain in Canada goes into a 20-year hiatus</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109719958934723525">\(\mathbb{M}\)</a>)</span> after its North American partners forced Canada into using Life+70 instead of Life+50 protection terms.</p>
  </li>
  <li>
    <p><a href="https://icml.cc/Conferences/2023/CallForPapers">ICML banned ChatGPT for writing submissions</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@fortnow@fediscience.org/109677987334540502">\(\mathbb{M}\)</a>)</span> and then <a href="https://icml.cc/Conferences/2023/llm-policy">walked it back</a>.</p>
  </li>
  <li>
    <p><a href="https://www.thebulwark.com/the-economic-secret-hidden-in-a-tiny-discontinued-pasta/">The difficulty of of making machines to make machines to make the things you want</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@Leahwrenn@mastodon.social/109701058818221148">\(\mathbb{M}\)</a>);</span> in this case, tiny star-shaped pasta.</p>
  </li>
  <li>
    <p><a href="https://cp4space.hatsya.com/2023/01/18/tensor-rank-paper/">Bounds on the tensor rank of the determinant over various fields</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109737432277072901">\(\mathbb{M}\)</a>).</span> Iâm intrigued by the connection between tensor ranks, tilings of space by orthogonal polyhedra, and flip graphs of ordered partitions of subsets alluded to in this blog post on <a href="https://arxiv.org/abs/2301.06586">a new preprint</a>.</p>
  </li>
  <li>
    <p><a href="https://futurism.com/cnet-ai-plagiarism">âCNETâs AI-written articles arenât just riddled with errors. They also appear to be substantially plagiarizedâ</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109745677430217499">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=34502939">via</a>). âThe botâs misbehavior ranges from verbatim copying to moderate edits to significant rephrasings, all without properly crediting the original. In at least some of its articles, it appears that virtually every sentence maps directly onto something previously published elsewhere.â</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/the-computer-scientist-who-finds-life-lessons-in-board-games-20230125/"><em>Quanta</em> interview with Shang-Hua Teng</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@QuantaMagazine@mstdn.social/109751056152008812">\(\mathbb{M}\)</a>).</span> âTeng discusses his upbringing in China and the math that good board games have in common.â</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@kameryn/109756698881498419">Nice explainer on the continuum hypothesis</a> and how the idea that its independence makes the problem intractable âmisses the actual nuance of the mathematical terrainâ: for any ânaturalâ-enough set, the dichotomy between the cardinalities of \(\mathbb{N}\) and \(\mathbb{R}\) is valid and provable.</p>
  </li>
  <li>
    <p>I have no mathematical point to share here <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109765566564556642">\(\mathbb{M}\)</a>),</span> just a recoloring of an old image I made of the <a href="https://en.wikipedia.org/wiki/Folkman_graph">Folkman graph</a> that I thought came out interesting-looking. It is something like one of Escherâs impossible figures: Locally it looks like it could be made from overlapping translucent sheets of blue material, cut out in this pattern, but globally it doesnât all fit together.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/Folkman-shaded.svg" alt="A figure with five-fold symmetry, made from arcs of circles, shaded in light and dark blue. There are 20 points where the arcs cross a central circle; if these points are are taken as the vertices of a graph, and the arcs between them taken as edges of a graph, the result is the Folkman graph, the smallest graph that is symmetric on its edges but not on its vertices." style="width:100%;max-width:600px" /></p>
  </li>
  <li>
    <p>Youâve probably heard about the glass flowers at Harvard, but have you seen <a href="https://www.lukejerram.com/glass/">Luke Jerramâs glass viruses and bacteria</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109771266602473224">\(\mathbb{M}\)</a>,</span> <a href="https://www.thisiscolossal.com/2023/01/luke-jerram-glass-microbes/">via</a>)?</p>
  </li>
  <li>
    <p><a href="https://www.si.edu/spotlight/geometric-models-jullien-models-for-descriptive-geometry">Jullien Models for Descriptive Geometry</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@divbyzero/109751804697166396">\(\mathbb{M}\)</a>).</span> Fold-out paper-and-thread models of 3d geometric constructions, from the mid-1870s, in the collection of the <em>Smithsonian</em>.</p>
  </li>
  <li>
    <p><a href="https://www.latimes.com/california/story/2023-01-27/uc-scrambling-to-pay-big-wage-gains-for-academic-workers-grad-student-cuts-loom">âTo afford historic labor contract, UC considers cutting TAs, graduate student admissionsâ</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109779527458911961">\(\mathbb{M}\)</a>).</span> Apparently the administration is treating this as a zero-sum game: theyâve agreed to pay teaching assistants significantly more per person, but they wonât give us any larger budget for them, apparently intending that there be fewer slots to make it all balance.</p>
  </li>
  <li>
    <p><a href="https://www.itsnicethat.com/articles/sam-keller-art-020322">Sam Kellerâs <em>Cheetosphere</em></a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@daw15@universeodon.com/109767629934965993">\(\mathbb{M}\)</a>),</span> an artwork constructed much like a geodesic dome, but out of Cheetos.</p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-31T23:04:00Z">Tuesday, January 31 2023, 23:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/01/why-does-pi-come-up-so-often-i-dont.html'>Why does pi come up so often? I don't know either but ...</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;Here is how history DID unfold:</p><p>1) People noticed that the ratio of the circumference to the diameter of ANY circle is always the same, it's a number between 3 and 4, roughly 3.14 or as my Dad would say, exactly 22/7 (see&nbsp;this blog post). On the web (see&nbsp;here) is a claim that Euler first used the symbol pi since it is the first letter of a Greek word for Circumference. I've seen other sites that claim someone less famous and its the first letter of a Greek work for Perimeter.&nbsp;</p><p>But in any case pi was known (though not called that) a LONG time ago.</p><p>2) MUCH LATER people noticed</p><p>1/1^2 + 1/2^2 + 1/3^2 + ... = pi^2/6 (Euler showed this in 1735, see&nbsp;here. That site says that it was Basel's problem to determine the sum. Yeah for Basel--- his name lives on even after his problem was solved! This did not happen for Baudet and Vazsonyi. If you don't know what they conjectured--- well, that proves my point. ADDED LATER: commenter Robert pointed out that Basel is NOT a person's name but a cities name. I am delighted to know that!)&nbsp;</p><p>1 - 1/3 + 1/5 - 1/7 + 1/9 ... = pi/4 (Leibniz showed this in 1676, see here. A good Quora site on that sum is&nbsp;here.)</p><p>(There are other series where pi comes up as well.)&nbsp;</p><p><br></p><p>3) People wonder Why did pi, which has to do with CIRCLES, end up in INFINITE SERIES?</p><p><br></p><p>What if history unfolded the other way:&nbsp;</p><p>1) People noticed</p><p>1/1^2 + 1/2^2 + 1/3^2 + ... =a^2/6 (Euler did that in 1735, see&nbsp;here.)&nbsp;</p><p>1 - 1/3 + 1/5 - 1/7 + 1/9 ... = b/4 (Leibniz showed this, see&nbsp;here.&nbsp;A good Quora site on that sum is&nbsp;here.)</p><p>and they noticce that a=b and is between 3 and 4, closer to 3. They decide to call it pi for no good reason.&nbsp;</p><p>(There are other series where pi comes up as well.)&nbsp;</p><p>2) MUCH LATER people noticed that this same funny constant pi was the ratio of circumference to diameter in any circle.&nbsp;</p><p>3) People wonder Why did pi, which has to do with INFINITE SERIES, end up in CIRCLES?</p><p>The following comic captures the dichotomy:&nbsp;here</p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;Here is how history DID unfold:</p><p>1) People noticed that the ratio of the circumference to the diameter of ANY circle is always the same, it's a number between 3 and 4, roughly 3.14 or as my Dad would say, exactly 22/7 (see&nbsp;<a href="https://blog.computationalcomplexity.org/2019/06/a-proof-that-227-pi-0-and-more.html">this blog post</a>). On the web (see&nbsp;<a href="https://www.piday.org/pi-symbol/">here</a>) is a claim that Euler first used the symbol pi since it is the first letter of a Greek word for <i>Circumference</i>. I've seen other sites that claim someone less famous and its the first letter of a Greek work for <i>Perimeter</i>.&nbsp;</p><p>But in any case pi was known (though not called that) a LONG time ago.</p><p>2) MUCH LATER people noticed</p><p>1/1^2 + 1/2^2 + 1/3^2 + ... = pi^2/6 (Euler showed this in 1735, see&nbsp;<a href="https://en.wikipedia.org/wiki/Basel_problem">here</a>. That site says that it was Basel's problem to determine the sum. Yeah for Basel--- his name lives on even after his problem was solved! This did not happen for Baudet and Vazsonyi. If you don't know what they conjectured--- well, that proves my point. ADDED LATER: commenter Robert pointed out that Basel is NOT a person's name but a cities name. I am delighted to know that!)&nbsp;</p><p>1 - 1/3 + 1/5 - 1/7 + 1/9 ... = pi/4 (Leibniz showed this in 1676, see <a href="https://en.wikipedia.org/wiki/Leibniz_formula_for_%CF%80">here</a>. A good Quora site on that sum is&nbsp;<a href="https://www.quora.com/What-is-the-sigma-notation-of-1-1-3-1-5-1-7-1-15">here</a>.)</p><p>(There are other series where pi comes up as well.)&nbsp;</p><p><br /></p><p>3) People wonder <i>Why did pi, which has to do with CIRCLES, end up in INFINITE SERIES?</i></p><p><br /></p><p>What if history unfolded the other way:&nbsp;</p><p>1) People noticed</p><p>1/1^2 + 1/2^2 + 1/3^2 + ... =a^2/6 (Euler did that in 1735, see&nbsp;<a href="https://en.wikipedia.org/wiki/Basel_problem">here</a>.)&nbsp;</p><p>1 - 1/3 + 1/5 - 1/7 + 1/9 ... = b/4 (Leibniz showed this, see&nbsp;<a href="https://en.wikipedia.org/wiki/Leibniz_formula_for_%CF%80">here</a>.&nbsp;A good Quora site on that sum is&nbsp;<a href="https://www.quora.com/What-is-the-sigma-notation-of-1-1-3-1-5-1-7-1-15">here</a>.)</p><p>and they noticce that a=b and is between 3 and 4, closer to 3. They decide to call it pi for no good reason.&nbsp;</p><p>(There are other series where pi comes up as well.)&nbsp;</p><p>2) MUCH LATER people noticed that this same funny constant pi was the ratio of circumference to diameter in any circle.&nbsp;</p><p>3) People wonder <i>Why did pi, which has to do with INFINITE SERIES, end up in CIRCLES?</i></p><p>The following comic captures the dichotomy:&nbsp;<a href="https://www.smbc-comics.com/comic/pi-2">here</a></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-31T21:53:00Z">Tuesday, January 31 2023, 21:53</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://thmatters.wordpress.com/2023/01/31/tcs-job-market-profiles-2/'>TCS Job Market profiles</a></h3>
        <p class='tr-article-feed'>from <a href='https://thmatters.wordpress.com'>Theory Matters</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Are you or your institution looking to hire a theoretician? Check out these job market profiles of TCS candidates. Feel free to share widely within your network. This information can also be found under the &#8220;TCS Job Market&#8221; tab in the menu above. Candidates on the TCS job market: fill out this form to get [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Are you or your institution looking to hire a theoretician? Check out <a rel="noreferrer noopener" href="https://sites.google.com/view/tcsjobmarket/home" target="_blank">these job market profiles</a> of TCS candidates. Feel free to share widely within your network. This information can also be found under the &#8220;<a rel="noreferrer noopener" href="https://thmatters.wordpress.com/tcs-job-market-resources/" target="_blank">TCS</a><a href="https://thmatters.wordpress.com/tcs-job-market-resources/" target="_blank" rel="noreferrer noopener"> </a><a rel="noreferrer noopener" href="https://thmatters.wordpress.com/tcs-job-market-resources/" target="_blank">Job Market</a>&#8221; tab in the menu above.</p>



<p>Candidates on the TCS job market: fill out <a rel="noreferrer noopener" href="https://docs.google.com/forms/d/1jeN3hjzwdRCmI3-7yzuHmyelcZjCtKDn19X2dj4POro/viewform?edit_requested=true" target="_blank">this form</a> to get your profile added to the list. We will review responses and add them to the list every 2-3 weeks.</p>



<p></p>
<p class="authors">By shuchic</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-31T14:26:14Z">Tuesday, January 31 2023, 14:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-events.org/2023/01/31/summer-school-on-high-dimensional-expanders/'>Summer School on High-dimensional Expanders</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-events.org'>CS Theory Events</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          May 22-26, 2023 Ghent, Belgium algebra.ugent.be/hdx/ This summer school on high-dimensional expanders is the first event organized in the framework of the EOS-project &#8220;High-dimensional expanders and KacâMoodyâSteinberg groups&#8221;. It consists of 7 short series of lectures by experts in the field and is meant to be accessible to a wide audience of both young and &#8230; Continue reading Summer School on High-dimensional Expanders<p>By shacharlovett</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          May 22-26, 2023 Ghent, Belgium https://algebra.ugent.be/hdx/ This summer school on high-dimensional expanders is the first event organized in the framework of the EOS-project &#8220;High-dimensional expanders and KacâMoodyâSteinberg groups&#8221;. It consists of 7 short series of lectures by experts in the field and is meant to be accessible to a wide audience of both young and &#8230; <a href="https://cstheory-events.org/2023/01/31/summer-school-on-high-dimensional-expanders/" class="more-link">Continue reading <span class="screen-reader-text">Summer School on High-dimensional Expanders</span></a><p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-31T11:24:02Z">Tuesday, January 31 2023, 11:24</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/01/31/research-associate-postdoc-at-the-university-of-edinburgh-at-university-of-edinburgh-apply-by-february-28-2023/'>RESEARCH ASSOCIATE (POSTDOC) AT THE UNIVERSITY OF EDINBURGH at University of Edinburgh (apply by February 28, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Applications are invited for research associate positions in Algorithms and Complexity, funded by the European Research Council (ERC) starting grant âNew Approaches to Counting and Samplingâ (NACS), led by Dr. Heng Guo in the School of Informatics, University of Edinburgh. Website: elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/6411 Email: hguo at inf.ed.ac.uk
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Applications are invited for research associate positions in Algorithms and Complexity, funded by the European Research Council (ERC) starting grant âNew Approaches to Counting and Samplingâ (NACS), led by Dr. Heng Guo in the School of Informatics, University of Edinburgh.</p>
<p>Website: <a href="https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/6411">https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/6411</a><br />
Email: hguo at inf.ed.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-31T11:05:14Z">Tuesday, January 31 2023, 11:05</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.12028'>An Arithmetic Theory to Characterize Poly-Time Random Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Melissa Antonelli, Ugo Dal Lago, Davide Davoli, Isabel Oitavem, Paolo Pistone</p><p>We introduce a new bounded theory RS^1_2 and show that the functions which
are Sigma^b_1-representable in it are precisely random functions which can be
computed in polynomial time. Concretely, we pass through a class of oracle
functions over string, called POR, together with the theory of arithmetic
RS^1_2. Then, we show that functions computed by poly-time PTMs are
arithmetically characterized by a class of probabilistic bounded formulas.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Antonelli_M/0/1/0/all/0/1">Melissa Antonelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Lago_U/0/1/0/all/0/1">Ugo Dal Lago</a>, <a href="http://arxiv.org/find/cs/1/au:+Davoli_D/0/1/0/all/0/1">Davide Davoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Oitavem_I/0/1/0/all/0/1">Isabel Oitavem</a>, <a href="http://arxiv.org/find/cs/1/au:+Pistone_P/0/1/0/all/0/1">Paolo Pistone</a></p><p>We introduce a new bounded theory RS^1_2 and show that the functions which
are Sigma^b_1-representable in it are precisely random functions which can be
computed in polynomial time. Concretely, we pass through a class of oracle
functions over string, called POR, together with the theory of arithmetic
RS^1_2. Then, we show that functions computed by poly-time PTMs are
arithmetically characterized by a class of probabilistic bounded formulas.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-31T01:30:00Z">Tuesday, January 31 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.12122'>Rethinking NPN Classification from Face and Point Characteristics of Boolean Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jiaxi Zhang, Shenggen Zheng, Liwei Ni, Huawei Li, Guojie Luo</p><p>NPN classification is an essential problem in the design and verification of
digital circuits. Most existing works explored variable symmetries and cofactor
signatures to develop their classification methods. However, cofactor
signatures only consider the face characteristics of Boolean functions. In this
paper, we propose a new NPN classifier using both face and point
characteristics of Boolean functions, including cofactor, influence, and
sensitivity. The new method brings a new perspective to the classification of
Boolean functions. The classifier only needs to compute some signatures, and
the equality of corresponding signatures is a prerequisite for NPN equivalence.
Therefore, these signatures can be directly used for NPN classification, thus
avoiding the exhaustive transformation enumeration. The experiments show that
the proposed NPN classifier gains better NPN classification accuracy with
comparable speed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaxi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shenggen Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_L/0/1/0/all/0/1">Liwei Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Huawei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1">Guojie Luo</a></p><p>NPN classification is an essential problem in the design and verification of
digital circuits. Most existing works explored variable symmetries and cofactor
signatures to develop their classification methods. However, cofactor
signatures only consider the face characteristics of Boolean functions. In this
paper, we propose a new NPN classifier using both face and point
characteristics of Boolean functions, including cofactor, influence, and
sensitivity. The new method brings a new perspective to the classification of
Boolean functions. The classifier only needs to compute some signatures, and
the equality of corresponding signatures is a prerequisite for NPN equivalence.
Therefore, these signatures can be directly used for NPN classification, thus
avoiding the exhaustive transformation enumeration. The experiments show that
the proposed NPN classifier gains better NPN classification accuracy with
comparable speed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-31T01:30:00Z">Tuesday, January 31 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.12212'>Efficient Enumeration of Markov Equivalent DAGs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marcel Wien&#xf6;bst, Malte Luttermann, Max Bannach, Maciej Li&#x15b;kiewicz</p><p>Enumerating the directed acyclic graphs (DAGs) of a Markov equivalence class
(MEC) is an important primitive in causal analysis. The central resource from
the perspective of computational complexity is the delay, that is, the time an
algorithm that lists all members of the class requires between two consecutive
outputs. Commonly used algorithms for this task utilize the rules proposed by
Meek (1995) or the transformational characterization by Chickering (1995), both
resulting in superlinear delay. In this paper, we present the first linear-time
delay algorithm. On the theoretical side, we show that our algorithm can be
generalized to enumerate DAGs represented by models that incorporate background
knowledge, such as MPDAGs; on the practical side, we provide an efficient
implementation and evaluate it in a series of experiments. Complementary to the
linear-time delay algorithm, we also provide intriguing insights into Markov
equivalence itself: All members of an MEC can be enumerated such that two
successive DAGs have structural Hamming distance at most three.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wienobst_M/0/1/0/all/0/1">Marcel Wien&#xf6;bst</a>, <a href="http://arxiv.org/find/cs/1/au:+Luttermann_M/0/1/0/all/0/1">Malte Luttermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Bannach_M/0/1/0/all/0/1">Max Bannach</a>, <a href="http://arxiv.org/find/cs/1/au:+Liskiewicz_M/0/1/0/all/0/1">Maciej Li&#x15b;kiewicz</a></p><p>Enumerating the directed acyclic graphs (DAGs) of a Markov equivalence class
(MEC) is an important primitive in causal analysis. The central resource from
the perspective of computational complexity is the delay, that is, the time an
algorithm that lists all members of the class requires between two consecutive
outputs. Commonly used algorithms for this task utilize the rules proposed by
Meek (1995) or the transformational characterization by Chickering (1995), both
resulting in superlinear delay. In this paper, we present the first linear-time
delay algorithm. On the theoretical side, we show that our algorithm can be
generalized to enumerate DAGs represented by models that incorporate background
knowledge, such as MPDAGs; on the practical side, we provide an efficient
implementation and evaluate it in a series of experiments. Complementary to the
linear-time delay algorithm, we also provide intriguing insights into Markov
equivalence itself: All members of an MEC can be enumerated such that two
successive DAGs have structural Hamming distance at most three.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-31T01:30:00Z">Tuesday, January 31 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.12274'>Cut-matching Games for Generalized Hypergraph Ratio Cuts</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nate Veldt</p><p>Hypergraph clustering is a basic algorithmic primitive for analyzing complex
datasets and systems characterized by multiway interactions, such as group
email conversations, groups of co-purchased retail products, and co-authorship
data. This paper presents a practical $O(\log n)$-approximation algorithm for a
broad class of hypergraph ratio cut clustering objectives. This includes
objectives involving generalized hypergraph cut functions, which allow a user
to penalize cut hyperedges differently depending on the number of nodes in each
cluster. Our method is a generalization of the cut-matching framework for graph
ratio cuts, and relies only on solving maximum s-t flow problems in a special
reduced graph. It is significantly faster than existing hypergraph ratio cut
algorithms, while also solving a more general problem. In numerical experiments
on various types of hypergraphs, we show that it quickly finds ratio cut
solutions within a small factor of optimality.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Veldt_N/0/1/0/all/0/1">Nate Veldt</a></p><p>Hypergraph clustering is a basic algorithmic primitive for analyzing complex
datasets and systems characterized by multiway interactions, such as group
email conversations, groups of co-purchased retail products, and co-authorship
data. This paper presents a practical $O(\log n)$-approximation algorithm for a
broad class of hypergraph ratio cut clustering objectives. This includes
objectives involving generalized hypergraph cut functions, which allow a user
to penalize cut hyperedges differently depending on the number of nodes in each
cluster. Our method is a generalization of the cut-matching framework for graph
ratio cuts, and relies only on solving maximum s-t flow problems in a special
reduced graph. It is significantly faster than existing hypergraph ratio cut
algorithms, while also solving a more general problem. In numerical experiments
on various types of hypergraphs, we show that it quickly finds ratio cut
solutions within a small factor of optimality.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-31T01:30:00Z">Tuesday, January 31 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, January 30
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://thmatters.wordpress.com/2023/01/30/rotator-position-at-nsf/'>Rotator position at NSF</a></h3>
        <p class='tr-article-feed'>from <a href='https://thmatters.wordpress.com'>Theory Matters</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I posted earlier about a permanent program director position at NSF in CCF/AF. There is also an opening for a rotator position. This is a great opportunity for anyone seeking a short (2-3 year) sabbatical from their academic position, and a wonderful and highly impactful way of serving the community. Please consider applying! You can [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I posted earlier about a permanent program director position at NSF in CCF/AF. There is also an opening for a rotator position. This is a great opportunity for anyone seeking a short (2-3 year) sabbatical from their academic position, and a wonderful and highly impactful way of serving the community. Please consider applying!</p>



<p>You can find more information at <a href="https://beta.nsf.gov/careers/openings/cise/ccf/ccf-2022-79939" rel="nofollow">https://beta.nsf.gov/careers/openings/cise/ccf/ccf-2022-79939</a> for the rotator position. If you have any questions about the position, please feel free to reach out to <a href="mailto:shuchi@cs.utexas.edu">me</a> or to one of the current AF PDs. </p>
<p class="authors">By shuchic</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-30T15:11:53Z">Monday, January 30 2023, 15:11</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/01/30/assistant-professor-in-logic-semantics-at-vrije-universiteit-amsterdam-apply-by-march-14-2023/'>Assistant professor in logic / semantics at Vrije Universiteit Amsterdam (apply by March 14, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Department of Computer Science at the Vrije Universiteit Amsterdam offers an open position as assistant professor in Theoretical Computer Science, in the area of logic or semantics, broadly construed. Website: workingat.vu.nl/ad/assistant-professor-tcs-tenure-track-career-track/b860v9 Email: Wan Fokkink
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Department of Computer Science at the Vrije Universiteit Amsterdam offers an open position as assistant professor in Theoretical Computer Science, in the area of logic or semantics, broadly construed.</p>
<p>Website: <a href="https://workingat.vu.nl/ad/assistant-professor-tcs-tenure-track-career-track/b860v9">https://workingat.vu.nl/ad/assistant-professor-tcs-tenure-track-career-track/b860v9</a><br />
Email: Wan Fokkink</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-30T09:54:41Z">Monday, January 30 2023, 09:54</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.11615'>Decompositions into two linear forests of bounded lengths</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rutger Campbell, Florian H&#xf6;rsch, Benjamin Moore</p><p>For some $k \in \mathbb{Z}_{\geq 0}\cup \infty$, we call a linear forest
$k$-bounded if each of its components has at most $k$ edges. We will say a
$(k,\ell)$-bounded linear forest decomposition of a graph $G$ is a partition of
$E(G)$ into the edge sets of two linear forests $F_k,F_\ell$ where $F_k$ is
$k$-bounded and $F_\ell$ is $\ell$-bounded. We show that the problem of
deciding whether a given graph has such a decomposition is NP-complete if both
$k$ and $\ell$ are at least $2$, NP-complete if $k\geq 9$ and $\ell =1$, and is
in P for $(k,\ell)=(2,1)$. Before this, the only known NP-complete cases were
the $(2,2)$ and $(3,3)$ cases. Our hardness result answers a question of
Bermond et al. from 1984. We also show that planar graphs of girth at least
nine decompose into a linear forest and a matching, which in particular is
stronger than $3$-edge-colouring such graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Campbell_R/0/1/0/all/0/1">Rutger Campbell</a>, <a href="http://arxiv.org/find/math/1/au:+Horsch_F/0/1/0/all/0/1">Florian H&#xf6;rsch</a>, <a href="http://arxiv.org/find/math/1/au:+Moore_B/0/1/0/all/0/1">Benjamin Moore</a></p><p>For some $k \in \mathbb{Z}_{\geq 0}\cup \infty$, we call a linear forest
$k$-bounded if each of its components has at most $k$ edges. We will say a
$(k,\ell)$-bounded linear forest decomposition of a graph $G$ is a partition of
$E(G)$ into the edge sets of two linear forests $F_k,F_\ell$ where $F_k$ is
$k$-bounded and $F_\ell$ is $\ell$-bounded. We show that the problem of
deciding whether a given graph has such a decomposition is NP-complete if both
$k$ and $\ell$ are at least $2$, NP-complete if $k\geq 9$ and $\ell =1$, and is
in P for $(k,\ell)=(2,1)$. Before this, the only known NP-complete cases were
the $(2,2)$ and $(3,3)$ cases. Our hardness result answers a question of
Bermond et al. from 1984. We also show that planar graphs of girth at least
nine decompose into a linear forest and a matching, which in particular is
stronger than $3$-edge-colouring such graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-30T01:30:00Z">Monday, January 30 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.11632'>Turing Machines Equipped with CTC in Physical Universes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sara Babaee Khanehsar, Farzad Didehvar</p><p>We study the paradoxical aspects of closed time-like curves and their impact
on the theory of computation. After introducing the $\text{TM}_\text{CTC}$, a
classical Turing machine benefiting CTCs for backward time travel, Aaronson et
al. proved that $\text{P} = \text{PSPACE}$ and the $\Delta_2$ sets, such as the
halting problem, are computable within this computational model. Our critical
view is the physical consistency of this model, which leads to proposing the
strong axiom, explaining that every particle rounding on a CTC will be
destroyed before returning to its starting time, and the weak axiom, describing
the same notion, particularly for Turing machines. We claim that in a universe
containing CTCs, the two axioms must be true; otherwise, there will be an
infinite number of any particle rounding on a CTC in the universe.
</p>
<p>An immediate result of the weak axiom is the incapability of Turing machines
to convey information for a full round on a CTC, leading to the proposed
$\text{TM}_\text{CTC}$ programs for the aforementioned corollaries failing to
function. We suggest our solution for this problem as the data transferring
hypothesis, which applies another $\text{TM}_\text{CTC}$ as a means for storing
data. A prerequisite for it is the existence of the concept of Turing machines
throughout time, which makes it appear infeasible in our universe. Then, we
discuss possible physical conditions that can be held for a universe containing
CTCs and conclude that if returning to an approximately equivalent universe by
a CTC was conceivable, the above corollaries would be valid.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Khanehsar_S/0/1/0/all/0/1">Sara Babaee Khanehsar</a>, <a href="http://arxiv.org/find/cs/1/au:+Didehvar_F/0/1/0/all/0/1">Farzad Didehvar</a></p><p>We study the paradoxical aspects of closed time-like curves and their impact
on the theory of computation. After introducing the $\text{TM}_\text{CTC}$, a
classical Turing machine benefiting CTCs for backward time travel, Aaronson et
al. proved that $\text{P} = \text{PSPACE}$ and the $\Delta_2$ sets, such as the
halting problem, are computable within this computational model. Our critical
view is the physical consistency of this model, which leads to proposing the
strong axiom, explaining that every particle rounding on a CTC will be
destroyed before returning to its starting time, and the weak axiom, describing
the same notion, particularly for Turing machines. We claim that in a universe
containing CTCs, the two axioms must be true; otherwise, there will be an
infinite number of any particle rounding on a CTC in the universe.
</p>
<p>An immediate result of the weak axiom is the incapability of Turing machines
to convey information for a full round on a CTC, leading to the proposed
$\text{TM}_\text{CTC}$ programs for the aforementioned corollaries failing to
function. We suggest our solution for this problem as the data transferring
hypothesis, which applies another $\text{TM}_\text{CTC}$ as a means for storing
data. A prerequisite for it is the existence of the concept of Turing machines
throughout time, which makes it appear infeasible in our universe. Then, we
discuss possible physical conditions that can be held for a universe containing
CTCs and conclude that if returning to an approximately equivalent universe by
a CTC was conceivable, the above corollaries would be valid.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-30T01:30:00Z">Monday, January 30 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.11820'>Hydrodynamic and conservative models of hypercomputation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Robert Cardona</p><p>Dynamical systems and physical models defined on idealized continuous phase
spaces are known to exhibit non-computable phenomena, examples include the wave
equation, recurrent neural networks, or Julia sets in holomorphic dynamics.
Inspired by the works of Moore and Siegelmann, in this article we introduce new
dynamical models of hypercomputation. First, we show that ideal fluids, modeled
by the Euler equations, can simulate poly-time Turing machines with polynomial
advice on compact three-dimensional domains. The complexity class that is shown
to be computable by stationary ideal fluids is precisely the one considered by
Siegelmann in her study of analog recurrent neural networks: the class
$P/poly$. Then, we introduce a class of symbolic systems that can be embedded
in conservative homeomorphisms of the disk. These systems are shown to be
capable of simulating Turing machines with advice in real-time, contrary to
previously known models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math-ph/1/au:+Cardona_R/0/1/0/all/0/1">Robert Cardona</a></p><p>Dynamical systems and physical models defined on idealized continuous phase
spaces are known to exhibit non-computable phenomena, examples include the wave
equation, recurrent neural networks, or Julia sets in holomorphic dynamics.
Inspired by the works of Moore and Siegelmann, in this article we introduce new
dynamical models of hypercomputation. First, we show that ideal fluids, modeled
by the Euler equations, can simulate poly-time Turing machines with polynomial
advice on compact three-dimensional domains. The complexity class that is shown
to be computable by stationary ideal fluids is precisely the one considered by
Siegelmann in her study of analog recurrent neural networks: the class
$P/poly$. Then, we introduce a class of symbolic systems that can be embedded
in conservative homeomorphisms of the disk. These systems are shown to be
capable of simulating Turing machines with advice in real-time, contrary to
previously known models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-30T01:30:00Z">Monday, January 30 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.11849'>Complexity of equilibria in binary public goods games on undirected graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Max Klimm, Maximilian J. Stahlberg</p><p>We study the complexity of computing equilibria in binary public goods games
on undirected graphs. In such a game, players correspond to vertices in a graph
and face a binary choice of performing an action, or not. Each player's
decision depends only on the number of neighbors in the graph who perform the
action and is encoded by a per-player binary pattern. We show that games with
decreasing patterns (where players only want to act up to a threshold number of
adjacent players doing so) always have a pure Nash equilibrium and that one is
reached from any starting profile by following a polynomially bounded sequence
of best responses. For non-monotonic patterns of the form $10^k10^*$ (where
players want to act alone or alongside $k + 1$ neighbors), we show that it is
$\mathsf{NP}$-hard to decide whether a pure Nash equilibrium exists. We further
investigate a generalization of the model that permits ties of varying
strength: an edge with integral weight $w$ behaves as $w$ parallel edges.
While, in this model, a pure Nash equilibrium still exists for decreasing
patters, we show that the task of computing one is $\mathsf{PLS}$-complete.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Klimm_M/0/1/0/all/0/1">Max Klimm</a>, <a href="http://arxiv.org/find/cs/1/au:+Stahlberg_M/0/1/0/all/0/1">Maximilian J. Stahlberg</a></p><p>We study the complexity of computing equilibria in binary public goods games
on undirected graphs. In such a game, players correspond to vertices in a graph
and face a binary choice of performing an action, or not. Each player's
decision depends only on the number of neighbors in the graph who perform the
action and is encoded by a per-player binary pattern. We show that games with
decreasing patterns (where players only want to act up to a threshold number of
adjacent players doing so) always have a pure Nash equilibrium and that one is
reached from any starting profile by following a polynomially bounded sequence
of best responses. For non-monotonic patterns of the form $10^k10^*$ (where
players want to act alone or alongside $k + 1$ neighbors), we show that it is
$\mathsf{NP}$-hard to decide whether a pure Nash equilibrium exists. We further
investigate a generalization of the model that permits ties of varying
strength: an edge with integral weight $w$ behaves as $w$ parallel edges.
While, in this model, a pure Nash equilibrium still exists for decreasing
patters, we show that the task of computing one is $\mathsf{PLS}$-complete.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-30T01:30:00Z">Monday, January 30 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2301.11756'>A comment on the structure of graded modules over graded principal ideal domains in the context of persistent homology</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Clara Loeh</p><p>The literature in persistent homology often refers to a "structure theorem
for finitely generated graded modules over a graded principal ideal domain". We
clarify the nature of this structure theorem in this context.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Loeh_C/0/1/0/all/0/1">Clara Loeh</a></p><p>The literature in persistent homology often refers to a "structure theorem
for finitely generated graded modules over a graded principal ideal domain". We
clarify the nature of this structure theorem in this context.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-01-30T01:30:00Z">Monday, January 30 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
