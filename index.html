<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2022-10-25T14:53:05Z">Tuesday, October 25 2022, 14:53</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, October 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2022/10/25/remarkable-limitations-of-linear-cross-entropy-as-a-measure-for-quantum-advantage-by-xun-gao-marcin-kalinowski-chi-ning-chou-mikhail-d-lukin-boaz-barak-and-soonwon-choi/'>Remarkable: “Limitations of Linear Cross-Entropy as a Measure for Quantum Advantage,” by Xun Gao, Marcin Kalinowski, Chi-Ning Chou, Mikhail D. Lukin, Boaz Barak, and Soonwon Choi</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this post I would like to report about an important paper (posted Dec. 2021) by Xun Gao, Marcin Kalinowski, Chi-Ning Chou, Mikhail D. Lukin, Boaz Barak, and Soonwon Choi. (I am thankful to Xun Gao and&#160; Boaz Barak for &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In this post I would like to report about an important paper (posted Dec. 2021) by Xun Gao, Marcin Kalinowski, Chi-Ning Chou, Mikhail D. Lukin, Boaz Barak, and Soonwon Choi. (I am thankful to Xun Gao and&nbsp; Boaz Barak for helpful discussions).</p>
<h3><a href="https://arxiv.org/abs/2112.01657">Limitations of Linear Cross-Entropy as a Measure for Quantum Advantage</a></h3>
<p>Here is the abstract:</p>
<blockquote><p><em> <span id="2112.01657v1-abstract-full" class="abstract-full has-text-grey-dark mathjax"> Demonstrating quantum advantage requires experimental implementation of a computational task that is hard to achieve using state-of-the-art classical systems. One approach is to perform sampling from a probability distribution associated with a class of highly entangled many-body wavefunctions. It has been suggested that this approach can be certified with the Linear Cross-Entropy Benchmark (XEB). We critically examine this notion. First, in a &#8220;benign&#8221; setting where an honest implementation of noisy quantum circuits is assumed, we characterize the conditions under which the XEB approximates the fidelity. Second, in an &#8220;adversarial&#8221; setting where all possible classical algorithms are considered for comparison, we show that achieving relatively high XEB values does not imply faithful simulation of quantum dynamics. We present an efficient classical algorithm that, with 1 GPU within 2s, yields high XEB values, namely 2-12% of those obtained in experiments. By identifying and exploiting several vulnerabilities of the XEB, we achieve high XEB values without full simulation of quantum circuits. Remarkably, our algorithm features better scaling with the system size than noisy quantum devices for commonly studied random circuit ensembles. To quantitatively explain the success of our algorithm and the limitations of the XEB, we use a theoretical framework in which the average XEB and fidelity are mapped to statistical models. We illustrate the relation between the XEB and the fidelity for quantum circuits in various architectures, with different gate choices, and in the presence of noise. Our results show that XEB&#8217;s utility as a proxy for fidelity hinges on several conditions, which must be checked in the benign setting but cannot be assumed in the adversarial setting. Thus, the XEB alone has limited utility as a benchmark for quantum advantage. We discuss ways to overcome these limitations.</span></em></p></blockquote>
<h2>I. Three parameters for noisy quantum circuits:</h2>
<ol>
<li><strong>F</strong> &#8211; The fidelity. If <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi" class="latex" /> is the ideal state and <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;psi" class="latex" /> is the noisy state, then the fidelity <strong>F</strong> is defined by <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%5Cleft+%7C+%5Cphi+%5Cright+%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%5Cleft+%7C+%5Cphi+%5Cright+%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%5Cleft+%7C+%5Cphi+%5Cright+%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;langle &#92;psi &#92;left | &#92;phi &#92;right | &#92;psi &#92;rangle" class="latex" />,</li>
<li><strong>XEB</strong> &#8211; the linear cross entropy estimator for the fidelity</li>
<li><strong>P(No err)</strong> &#8211; The probability of no errors (denoted in the paper by <img src="https://s0.wp.com/latex.php?latex=p_%7Bno%7Eerr%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_%7Bno%7Eerr%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_%7Bno%7Eerr%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_{no~err}" class="latex" />).</li>
</ol>
<h2>II. Some issues:</h2>
<p>a) The fidelity <strong>F</strong> cannot be read from the distribution of the samples produced by the quantum computer. Suppose we are given an unlimited number of samples (or a large number of samples for which the empirical distribution is a good approximation to the noisy distribution), what is the best way to estimate the fidelity?</p>
<p>b) If we have a polynomial number of samples in (1/F). What are the best ways to estimate the fidelity?</p>
<p>c) What in general are the relations between <strong>F</strong>, <strong>XEB</strong>, and <strong>P(No err)?</strong></p>
<h2>III. A basic observation:</h2>
<p>A basic observation of the paper is that when you apply depolarizing noise to the gates, the resulting distribution has a positive correlation to the ideal distribution. (Hence this leads to positive XEB value.)&nbsp; The basic idea (as I see it) is simple: let&#8217;s consider 1-gate which is a certain unitary operator U.<br />
The space of such operators is spanned by I, X, Y, and Z. Let us assume that applying to U unitary noise, say, Y, will lead to a new quantum circuit which gives uncorrelated samples and fidelity estimator 0. However, applying (I+X+Y+Z), which replace the qubit with a maximal entropy state is a very basic form of noise (depolarizing noise on the qubit on which the gate acts) and this form of noise is expected to slash the fidelity estimator by four and not send it to zero. (For 2-gates the story is similar but this time there are 16 basic possibilities for unitary noise so we can expect that a depolarizing noise will slash the linear cross entropy estimator by 1/16 (and not to zero).)</p>
<h2>IV. Additional observations</h2>
<p>The paper by Gao et al. describes various additional reasons for which the effect of gate errors will lead to positive correlations with the ideal distribution, and in general will lead to strict inequalities</p>
<p style="text-align:center;"><strong>(1) &nbsp; XEB &nbsp; &gt;&nbsp; P(No err) </strong></p>
<p>and</p>
<p style="text-align:center;"><strong>(2) &nbsp;</strong> <strong>XEB &gt; F &gt; P(No err) </strong></p>
<p>First, it turns out that even a single unitary gate error can contribute to the increase of <strong>XEB&nbsp; </strong>(and also to increase<strong> F)</strong>, and, moreover, the effect of two (or more) gate errors can also lead to an increased <strong>XEB (</strong>and also an increased <strong>F</strong>.)</p>
<p>In expectation we can actually expect.</p>
<p style="text-align:center;"><strong>(3) &nbsp;&nbsp; XEB &gt; F &gt; P(No err) </strong></p>
<p>This is demonstrated by Figure 1 of the paper.</p>
<h2><img loading="lazy" data-attachment-id="23473" data-permalink="https://gilkalai.wordpress.com/2022/10/25/remarkable-limitations-of-linear-cross-entropy-as-a-measure-for-quantum-advantage-by-xun-gao-marcin-kalinowski-chi-ning-chou-mikhail-d-lukin-boaz-barak-and-soonwon-choi/xungao/" data-orig-file="https://gilkalai.files.wordpress.com/2022/10/xungao.png" data-orig-size="337,578" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="XunGao" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=175" data-large-file="https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=337" class="alignnone  wp-image-23473" src="https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=310&#038;h=532" alt="XunGao" width="310" height="532" srcset="https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=310&amp;h=532 310w, https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=87&amp;h=150 87w, https://gilkalai.files.wordpress.com/2022/10/xungao.png?w=175&amp;h=300 175w, https://gilkalai.files.wordpress.com/2022/10/xungao.png 337w" sizes="(max-width: 310px) 100vw, 310px"></h2>
<h2>V. The idea behind the spoofing algorithm</h2>
<p>The way Gao, Kalinowski, Chou, Lukin, Barak, and Choi used this observation is by applying such depolarization noise on a set of 2-gates that would split the circuit into two parts. This will lead to a sort of &#8220;patched&#8221; circuit for which one can make the computation separately on every patch, which gives much quicker classical algorithms.</p>
<h2>VI The asymptotic behavior</h2>
<p>One interesting aspect of the paper is that (as far as I could understand) when the number of qubits grows the &#8220;quantum advantage&#8221; , namely the advantage of the quantum algorithms over the classical algorithms, diminishes. As Gao et al. write</p>
<blockquote><p><span style="color:#0000ff;"><em>&#8220;Remarkably, the <strong>XEB </strong></em><em>value of our algorithm generally improves for larger </em><em>quantum circuits, whereas that of noisy quantum </em><em>devices quickly deteriorates. Such scaling continues to hold when the number of qubits is increased </em><em>while the depth of the circuit and the error-per-gate </em><em>are fixed&#8230;&#8221;</em></span></p></blockquote>
<p>Remark: This conclusion assumes that you need enough samples to verify the fidelity. Philosophically one can claim that the quantum advantage may apply for producing *one* sample; After all, your argument is based anyway on extrapolation, and for supremacy experiments you cannot verify even the individual amplitudes. (I made this claim in a discussion with Daniel Lidar regarding the very nice paper by <span dir="ltr" role="presentation">Zlokapa, Boixo, and Lidar, <a href="https://arxiv.org/abs/2005.02464">Boundaries of quantum supremacy </a></span><span dir="ltr" role="presentation">via random circuit sampling,</span> but I couldn&#8217;t persuade Daniel.)</p>
<h2>VII Relevance to the statistical analysis and the concerns regarding the Google 2019 experiment</h2>
<p>The paper is relevant to two important aspects of my <a href="https://gilkalai.files.wordpress.com/2022/08/sts836.pdf">statistical science paper</a> with Yosi Rinott and Tomer Shoham and to our work which puts the Google 2019 experiment under scrutiny.</p>
<ol>
<li>The fact that <strong>XEB</strong> is systematically larger than <strong>P(No err)</strong> may support the concern that the precise agreement of the <strong>XEB</strong> estimator with the <strong>P(No err)</strong> computation (Formula (77)) is &#8220;too good to be true,&#8221; namely, it fits too well with the researcher&#8217;s expectations rather than with physical reality.</li>
<li>The basic observation (III) implies that the exponential decay for the Fourier coefficients with the degrees, that we attributed only to readout errors is also caused by gate errors. Subsequently, the Fourier description of the data that we regarded as providing confirmation to the Google claim (see, Figure 2 in <a href="https://arxiv.org/abs/2210.12753">our recent paper</a>) actually appears to show that the empirical data does not fit the theory.</li>
</ol>
<p>Apropos Fourier methods and Xun Gao: The first I heard of Xun Gao&#8217;s work was in connection with his excellent early work with Duan <a href="https://arxiv.org/abs/1810.03176">Efficient classical simulation of noisy quantum computation</a> that used Fourier methods to study quantum circuits.</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T04:59:48Z">Tuesday, October 25 2022, 04:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://theorydish.blog/2022/10/24/9th-toca-sv-11-18/'>9th TOCA-SV – 11/18</a></h3>
        <p class='tr-article-feed'>from <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The 9th TOCA-SV day is Coming on Friday 11/18/22, in the Google campus in Mountain View. It is free but you need to register here, where you can also see an up-to-date list of talks and abstracts. Schedule (tentative): 0930-1000: Breakfast 1000-1015: Welcome 1015-1100: Gagan Aggarwal (Google) 1100-1145: Li-Yang Tan (Stanford) 1145-1245: Short talks I 1245-1400: Lunch (provided) and campus tour 1400-1445: Sandy Irani (Simons/UC Berkeley) 1445-1530: Kunal Talwar (Apple) 1530-1600: Coffee Break 1600-1730: Short talks II
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The 9th TOCA-SV day is Coming on Friday 11/18/22, in the Google campus in Mountain View. It is free but you need to register <a href="https://sites.google.com/view/9th-toca-sv-nov-18-2022/">here</a>, where you can also see an up-to-date list of talks and abstracts.</p>
<div class="CjVfdc">Schedule (tentative):</div>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>0930-1000: Breakfast</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1000-1015: Welcome</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1015-1100: Gagan Aggarwal (Google)</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1100-1145: Li-Yang Tan (Stanford)</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1145-1245: Short talks I</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1245-1400: Lunch</strong><strong> (provided) </strong><strong>and campus tour</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1400-1445: Sandy Irani (Simons/UC Berkeley)</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1445-1530: Kunal Talwar (Apple)</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1530-1600: Coffee Break</strong></p>
<p class="CDt4Ke zfr3Q" dir="ltr"><strong>1600-1730: Short talks II</strong></p>
<p class="authors">By Omer Reingold</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T04:34:04Z">Tuesday, October 25 2022, 04:34</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12289'>Complexity and Ramsey Largeness of Sets of Oracles Separating Complexity Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alex Creiner, Stephen Jackson</p><p>We prove two sets of results concerning computational complexity classes. The
first concerns a variation of the random oracle hypothesis posed by Bennett and
Gill after they showed that relative to a randomly chosen oracle, P not equal
NP with probability 1. This hypothesis was quickly disproven in several ways,
most famously in 1992 with the result that IP equals PSPACE, in spite of the
classes being shown unequal with probability 1. Here we propose a variation of
what it means to be ``large'' using the Ellentuck topology. In this new
context, we demonstrate that the set of oracles separating NP and co-NP is not
small, and obtain similar results for the separation of PSPACE from PH along
with the separation of NP from BQP. We demonstrate that this version of the
hypothesis turns it into a sufficient condition for unrelativized
relationships, at least in the three cases considered here. Second, we example
the descriptive complexity of the classes of oracles providing the separations
for these various classes, and determine their exact placement in the Borel
hierarchy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Creiner_A/0/1/0/all/0/1">Alex Creiner</a>, <a href="http://arxiv.org/find/math/1/au:+Jackson_S/0/1/0/all/0/1">Stephen Jackson</a></p><p>We prove two sets of results concerning computational complexity classes. The
first concerns a variation of the random oracle hypothesis posed by Bennett and
Gill after they showed that relative to a randomly chosen oracle, P not equal
NP with probability 1. This hypothesis was quickly disproven in several ways,
most famously in 1992 with the result that IP equals PSPACE, in spite of the
classes being shown unequal with probability 1. Here we propose a variation of
what it means to be ``large'' using the Ellentuck topology. In this new
context, we demonstrate that the set of oracles separating NP and co-NP is not
small, and obtain similar results for the separation of PSPACE from PH along
with the separation of NP from BQP. We demonstrate that this version of the
hypothesis turns it into a sufficient condition for unrelativized
relationships, at least in the three cases considered here. Second, we example
the descriptive complexity of the classes of oracles providing the separations
for these various classes, and determine their exact placement in the Borel
hierarchy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T00:30:00Z">Tuesday, October 25 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12438'>Algorithms with Prediction Portfolios</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, Sergei Vassilvitskii</p><p>The research area of algorithms with predictions has seen recent success
showing how to incorporate machine learning into algorithm design to improve
performance when the predictions are correct, while retaining worst-case
guarantees when they are not. Most previous work has assumed that the algorithm
has access to a single predictor. However, in practice, there are many machine
learning methods available, often with incomparable generalization guarantees,
making it hard to pick a best method a priori. In this work we consider
scenarios where multiple predictors are available to the algorithm and the
question is how to best utilize them.
</p>
<p>Ideally, we would like the algorithm's performance to depend on the quality
of the best predictor. However, utilizing more predictions comes with a cost,
since we now have to identify which prediction is the best. We study the use of
multiple predictors for a number of fundamental problems, including matching,
load balancing, and non-clairvoyant scheduling, which have been well-studied in
the single predictor setting. For each of these problems we introduce new
algorithms that take advantage of multiple predictors, and prove bounds on the
resulting performance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dinitz_M/0/1/0/all/0/1">Michael Dinitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Im_S/0/1/0/all/0/1">Sungjin Im</a>, <a href="http://arxiv.org/find/cs/1/au:+Lavastida_T/0/1/0/all/0/1">Thomas Lavastida</a>, <a href="http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1">Benjamin Moseley</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilvitskii_S/0/1/0/all/0/1">Sergei Vassilvitskii</a></p><p>The research area of algorithms with predictions has seen recent success
showing how to incorporate machine learning into algorithm design to improve
performance when the predictions are correct, while retaining worst-case
guarantees when they are not. Most previous work has assumed that the algorithm
has access to a single predictor. However, in practice, there are many machine
learning methods available, often with incomparable generalization guarantees,
making it hard to pick a best method a priori. In this work we consider
scenarios where multiple predictors are available to the algorithm and the
question is how to best utilize them.
</p>
<p>Ideally, we would like the algorithm's performance to depend on the quality
of the best predictor. However, utilizing more predictions comes with a cost,
since we now have to identify which prediction is the best. We study the use of
multiple predictors for a number of fundamental problems, including matching,
load balancing, and non-clairvoyant scheduling, which have been well-studied in
the single predictor setting. For each of these problems we introduce new
algorithms that take advantage of multiple predictors, and prove bounds on the
resulting performance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T00:30:00Z">Tuesday, October 25 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12468'>Discrepancy Minimization in Input-Sparsity Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yichuan Deng, Zhao Song, Omri Weinstein</p><p>A recent work of Larsen [Lar23] gave a faster combinatorial alternative to
Bansal's SDP algorithm for finding a coloring $x\in\{-1,1\}^n$ that
approximately minimizes the discrepancy $\mathrm{disc}(A,x) : = \| A x
\|_{\infty}$ of a general real-valued $m\times n$ matrix $A$. Larsen's
algorithm runs in $\widetilde{O}(mn^2)$ time compared to Bansal's
$\widetilde{O}(mn^{4.5})$-time algorithm, at the price of a slightly weaker
logarithmic approximation ratio in terms of the hereditary discrepancy of $A$
[Ban10].
</p>
<p>In this work we present a combinatorial $\widetilde{O}(\mathrm{nnz}(A) +
n^3)$ time algorithm with the same approximation guarantee as Larsen, which is
optimal for tall matrices $m=\mathrm{poly}(n)$. Using a more intricate analysis
and fast matrix-multiplication, we achieve $\widetilde{O}(\mathrm{nnz}(A) +
n^{2.53})$ time, which breaks cubic runtime for square matrices, and bypasses
the barrier of linear-programming approaches [ES14] for which input-sparsity
time is currently out of reach.
</p>
<p>Our algorithm relies on two main ideas: (i) A new sketching technique for
finding a projection matrix with short $\ell_2$-basis using implicit
leverage-score sampling; (ii) A data structure for faster implementation of the
iterative Edge-Walk partial-coloring algorithm of Lovett-Meka, using an
alternative analysis that enables ``lazy" batch-updates with low-rank
corrections. Our result nearly closes the computational gap between real-valued
and binary matrices (set-systems), for which input-sparsity time coloring was
very recently obtained [JSS23].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yichuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinstein_O/0/1/0/all/0/1">Omri Weinstein</a></p><p>A recent work of Larsen [Lar23] gave a faster combinatorial alternative to
Bansal's SDP algorithm for finding a coloring $x\in\{-1,1\}^n$ that
approximately minimizes the discrepancy $\mathrm{disc}(A,x) : = \| A x
\|_{\infty}$ of a general real-valued $m\times n$ matrix $A$. Larsen's
algorithm runs in $\widetilde{O}(mn^2)$ time compared to Bansal's
$\widetilde{O}(mn^{4.5})$-time algorithm, at the price of a slightly weaker
logarithmic approximation ratio in terms of the hereditary discrepancy of $A$
[Ban10].
</p>
<p>In this work we present a combinatorial $\widetilde{O}(\mathrm{nnz}(A) +
n^3)$ time algorithm with the same approximation guarantee as Larsen, which is
optimal for tall matrices $m=\mathrm{poly}(n)$. Using a more intricate analysis
and fast matrix-multiplication, we achieve $\widetilde{O}(\mathrm{nnz}(A) +
n^{2.53})$ time, which breaks cubic runtime for square matrices, and bypasses
the barrier of linear-programming approaches [ES14] for which input-sparsity
time is currently out of reach.
</p>
<p>Our algorithm relies on two main ideas: (i) A new sketching technique for
finding a projection matrix with short $\ell_2$-basis using implicit
leverage-score sampling; (ii) A data structure for faster implementation of the
iterative Edge-Walk partial-coloring algorithm of Lovett-Meka, using an
alternative analysis that enables ``lazy" batch-updates with low-rank
corrections. Our result nearly closes the computational gap between real-valued
and binary matrices (set-systems), for which input-sparsity time coloring was
very recently obtained [JSS23].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T00:30:00Z">Tuesday, October 25 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12495'>Quartic Samples Suffice for Fourier Interpolation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhao Song, Baocheng Sun, Omri Weinstein, Ruizhe Zhang</p><p>We study the classic problem of interpolating a Fourier-sparse signal in the
time duration $[0, T]$ from noisy samples in the same range, where the ground
truth signal can be any $k$-Fourier-sparse signal with band-limit $[-F, F]$.
Our main result is an efficient Fourier Interpolation algorithm that improves
the previous best algorithm by [Chen, Kane, Price and Song, FOCS 2016] in the
following three aspects:
</p>
<p>$\bullet$ The sample complexity is improved from $\widetilde{O}(k^{51})$ to
$\widetilde{O}(k^{4})$.
</p>
<p>$\bullet$ The time complexity is improved from $
\widetilde{O}(k^{10\omega+40})$ to $\widetilde{O}(k^{4 \omega})$.
</p>
<p>$\bullet$ The output sparsity is improved from $\widetilde{O}(k^{10})$ to
$\widetilde{O}(k^{4})$.
</p>
<p>Here, $\omega$ denotes the exponent of fast matrix multiplication. The
state-of-the-art sample complexity of this problem is $\widetilde{O}(k)$, but
can only be achieved by an *exponential-time* algorithm. Our algorithm uses
slightly more samples ($\sim k^4$) in exchange for small polynomial runtime,
laying the groundwork for a practical Fourier Interpolation algorithm.
</p>
<p>The centerpiece of our algorithm is a new sufficient condition for the
frequency estimation task -- a high signal-to-noise (SNR) band condition --
which allows for efficient and accurate signal reconstruction. Based on this
condition together with a new structural decomposition of Fourier signals
(Signal Equivalent Method), we design a cheap algorithm for estimating each
"significant" frequency within a narrow range, which is then combined with a
new high-accuracy signal estimation algorithm to reconstruct the ground-truth
signal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Baocheng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinstein_O/0/1/0/all/0/1">Omri Weinstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruizhe Zhang</a></p><p>We study the classic problem of interpolating a Fourier-sparse signal in the
time duration $[0, T]$ from noisy samples in the same range, where the ground
truth signal can be any $k$-Fourier-sparse signal with band-limit $[-F, F]$.
Our main result is an efficient Fourier Interpolation algorithm that improves
the previous best algorithm by [Chen, Kane, Price and Song, FOCS 2016] in the
following three aspects:
</p>
<p>$\bullet$ The sample complexity is improved from $\widetilde{O}(k^{51})$ to
$\widetilde{O}(k^{4})$.
</p>
<p>$\bullet$ The time complexity is improved from $
\widetilde{O}(k^{10\omega+40})$ to $\widetilde{O}(k^{4 \omega})$.
</p>
<p>$\bullet$ The output sparsity is improved from $\widetilde{O}(k^{10})$ to
$\widetilde{O}(k^{4})$.
</p>
<p>Here, $\omega$ denotes the exponent of fast matrix multiplication. The
state-of-the-art sample complexity of this problem is $\widetilde{O}(k)$, but
can only be achieved by an *exponential-time* algorithm. Our algorithm uses
slightly more samples ($\sim k^4$) in exchange for small polynomial runtime,
laying the groundwork for a practical Fourier Interpolation algorithm.
</p>
<p>The centerpiece of our algorithm is a new sufficient condition for the
frequency estimation task -- a high signal-to-noise (SNR) band condition --
which allows for efficient and accurate signal reconstruction. Based on this
condition together with a new structural decomposition of Fourier signals
(Signal Equivalent Method), we design a cheap algorithm for estimating each
"significant" frequency within a narrow range, which is then combined with a
new high-accuracy signal estimation algorithm to reconstruct the ground-truth
signal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T00:30:00Z">Tuesday, October 25 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12543'>Edge-weighted Online Stochastic Matching: Beating $1-\frac1e$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shuyi Yan</p><p>We study the edge-weighted online stochastic matching problem. Since Feldman,
Mehta, Mirrokni, and Muthukrishnan proposed the $(1-\frac1e)$-competitive
Suggested Matching algorithm, there has been no improvement for the general
edge-weighted online stochastic matching problem. In this paper, we introduce
the first algorithm beating the $1-\frac1e$ bound in this setting, achieving a
competitive ratio of $0.645$. Under the LP proposed by Jaillet and Lu, we
design an algorithmic preprocessing, dividing all edges into two classes. Then
based on the Suggested Matching algorithm, we adjust the matching strategy to
improve the performance on one class in the early stage and on another class in
the late stage, while keeping the matching events of different edges highly
independent. By balancing them, we guarantee the matching probability of every
single edge.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shuyi Yan</a></p><p>We study the edge-weighted online stochastic matching problem. Since Feldman,
Mehta, Mirrokni, and Muthukrishnan proposed the $(1-\frac1e)$-competitive
Suggested Matching algorithm, there has been no improvement for the general
edge-weighted online stochastic matching problem. In this paper, we introduce
the first algorithm beating the $1-\frac1e$ bound in this setting, achieving a
competitive ratio of $0.645$. Under the LP proposed by Jaillet and Lu, we
design an algorithmic preprocessing, dividing all edges into two classes. Then
based on the Suggested Matching algorithm, we adjust the matching strategy to
improve the performance on one class in the early stage and on another class in
the late stage, while keeping the matching events of different edges highly
independent. By balancing them, we guarantee the matching probability of every
single edge.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-25T00:30:00Z">Tuesday, October 25 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, October 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/24/research-fellowship-at-simons-institute-for-the-theory-of-computing-apply-by-december-15-2022/'>Research Fellowship at Simons Institute for the Theory of Computing (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Simons Institute invites applications for Simons-Berkeley Research Fellowships for the Summer 2023, Fall 2023, and Spring 2024 semesters. Simons-Berkeley Research Fellowships are intended for exceptional scientists to participate in at least one of the semester-long programs at the institute. Website: simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications Email: simonsvisitorservices@berkeley.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Simons Institute invites applications for Simons-Berkeley Research Fellowships for the Summer 2023, Fall 2023, and Spring 2024 semesters. Simons-Berkeley Research Fellowships are intended for exceptional scientists to participate in at least one of the semester-long programs at the institute.</p>
<p>Website: <a href="https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications">https://simons.berkeley.edu/simons-berkeley-research-fellowship-call-applications</a><br />
Email: simonsvisitorservices@berkeley.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T22:40:28Z">Monday, October 24 2022, 22:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/10/cheating-in-chess-and-in-class.html'>Cheating in Chess and in Class</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>In the 24th move of the second game of the 1978 Chess Championship, a cup of blueberry yogurt was delivered to the defending champion&nbsp;Anatoly Karpov who offered a draw shortly thereafter. The challenger&nbsp;Victor Korchnoi claimed the flavor of yogurt was a coded message to Karpov and later in the tournament all food deliveries had to be decided on in advance. The good old days.</p><p>With computer chess programs now far more powerful than humans, chess cheating has become far more common and came to a head last month with the controversy between Magnus Carlsen and Hans Niemann. Did Niemann cheat to win in his win over Carlsen in St. Louis or was it just a rare upset? How can we tell?</p><p>This brings up cheating by students in class. Reports and statistics show that cheating has increased over the last few years. The pandemic played a role, but a good rule is that pandemic didn't change behaviors, rather accelerated changes already in progress. Technology has made it easier to cheat. It's difficult to near impossible to create a homework problem where someone couldn't just look up an answer. Sites like Chegg&nbsp;provide solutions to all sorts of problems while there are many sites where you can hire someone to write a paper or do a project for you. Advances in generative AI, like GPT-3 and GitHub co-pilot will soon make cheating as easy as clicking a button.</p><p>But it's more than technology. As students view university education less about learning and more about getting the credentials for a job, the inhibitions to cheat disappear. And while the vast majority of students don't significantly cheat, it's hard for anyone to avoid using Google when they get stuck on a problem.&nbsp;</p><p>We can continue to use technology to fight the technology in a every growing arms race to catch cheaters but it can feel like a losing war. We should take solace that the students who work hard solving problems and projects will be the ones who will succeed in life.&nbsp;</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In the 24th move of the second game of the 1978 Chess Championship, a cup of blueberry yogurt was delivered to the defending champion&nbsp;Anatoly Karpov who offered a draw shortly thereafter. The challenger&nbsp;Victor Korchnoi claimed the flavor of yogurt was a coded message to Karpov and later in the tournament all food deliveries had to be decided on in advance. The good old days.</p><p>With computer chess programs now far more powerful than humans, chess cheating has become far more common and came to a head last month with the controversy between <a href="https://en.wikipedia.org/wiki/Carlsen%E2%80%93Niemann_controversy">Magnus Carlsen and Hans Niemann</a>. Did Niemann cheat to win in his win over Carlsen in St. Louis or was it just a rare upset? How can we tell?</p><p>This brings up cheating by students in class. <a href="https://www.npr.org/2021/08/27/1031255390/reports-of-cheating-at-colleges-soar-during-the-pandemic">Reports</a> and <a href="https://academicintegrity.org/resources/facts-and-statistics">statistics</a> show that cheating has increased over the last few years. The pandemic played a role, but a good rule is that pandemic didn't change behaviors, rather accelerated changes already in progress. Technology has made it easier to cheat. It's difficult to near impossible to create a homework problem where someone couldn't just look up an answer. Sites like Chegg&nbsp;provide solutions to all sorts of problems while there are many sites where you can hire someone to write a paper or do a project for you. Advances in generative AI, like GPT-3 and GitHub co-pilot will soon make cheating as easy as clicking a button.</p><p>But it's more than technology. As students view university education less about learning and more about getting the credentials for a job, the inhibitions to cheat disappear. And while the vast majority of students don't significantly cheat, it's hard for anyone to avoid using Google when they get stuck on a problem.&nbsp;</p><p>We can continue to use technology to fight the technology in a every growing arms race to catch cheaters but it can feel like a losing war. We should take solace that the students who work hard solving problems and projects will be the ones who will succeed in life.&nbsp;</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T14:04:00Z">Monday, October 24 2022, 14:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11568'>Polynomial computational complexity of matrix elements of finite-rank-generated single-particle operators in products of finite bosonic states</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dmitri A. Ivanov</p><p>It is known that computing the permanent $\mathop{\rm Per}(1+A)$, where $A$
is a finite-rank matrix requires a number of operations polynomial in the
matrix size. I generalize this result to the expectation values
$\left\langle\Psi| P(1+A) |\Psi\right\rangle$, where $P()$ is the
multiplicative extension of a single-particle operator and
$\left|\Psi\right\rangle$ is a product of a large number of identical finite
bosonic states (i.e. bosonic states with a bounded number of bosons). I also
improve an earlier polynomial estimate for the fermionic version of the same
problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Ivanov_D/0/1/0/all/0/1">Dmitri A. Ivanov</a></p><p>It is known that computing the permanent $\mathop{\rm Per}(1+A)$, where $A$
is a finite-rank matrix requires a number of operations polynomial in the
matrix size. I generalize this result to the expectation values
$\left\langle\Psi| P(1+A) |\Psi\right\rangle$, where $P()$ is the
multiplicative extension of a single-particle operator and
$\left|\Psi\right\rangle$ is a product of a large number of identical finite
bosonic states (i.e. bosonic states with a bounded number of bosons). I also
improve an earlier polynomial estimate for the fermionic version of the same
problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12036'>On the Longest Flip Sequence to Untangle Segments in the Plane</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guilherme D. da Fonseca, Yan Gerard, Bastien Rivier</p><p>A set of segments in the plane may form a Euclidean TSP tour or a matching.
Optimal TSP tours as well as minimum weight perfect matchings have no crossing
segments, but several heuristics and approximation algorithms may produce
solutions with crossings. To improve such solutions, we can successively apply
a flip operation that replaces a pair of crossing segments by non-crossing
ones. This paper considers the maximum number D(n) of flips performed on n
segments. First, we present reductions relating D(n) for different versions of
matchings and the TSP tour. Second, we show that if all except t points are in
convex position, then D(n) = O(tn^2), providing a smooth transition between the
convex O(n^2) bound and the general O(n^3) bound. Last, we show that if instead
of counting the total number of flips, we only count the number of distinct
flips, then the cubic upper bound improves to O(n^{8/3}).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fonseca_G/0/1/0/all/0/1">Guilherme D. da Fonseca</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerard_Y/0/1/0/all/0/1">Yan Gerard</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivier_B/0/1/0/all/0/1">Bastien Rivier</a></p><p>A set of segments in the plane may form a Euclidean TSP tour or a matching.
Optimal TSP tours as well as minimum weight perfect matchings have no crossing
segments, but several heuristics and approximation algorithms may produce
solutions with crossings. To improve such solutions, we can successively apply
a flip operation that replaces a pair of crossing segments by non-crossing
ones. This paper considers the maximum number D(n) of flips performed on n
segments. First, we present reductions relating D(n) for different versions of
matchings and the TSP tour. Second, we show that if all except t points are in
convex position, then D(n) = O(tn^2), providing a smooth transition between the
convex O(n^2) bound and the general O(n^3) bound. Last, we show that if instead
of counting the total number of flips, we only count the number of distinct
flips, then the cubic upper bound improves to O(n^{8/3}).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.12015'>Blocking Delaunay Triangulations from the Exterior</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Oswin Aichholzer, Thomas Hackl, Maarten L&#xf6;ffler, Alexander Pilz, Irene Parada, Manfred Scheucher, Birgit Vogtenhuber</p><p>Given two distinct point sets $P$ and $Q$ in the plane, we say that $Q$
\emph{blocks} $P$ if no two points of $P$ are adjacent in any Delaunay
triangulation of $P\cup Q$. Aichholzer et al. (2013) showed that any set $P$ of
$n$ points in general position can be blocked by $\frac{3}{2}n$ points and that
every set $P$ of $n$ points in convex position can be blocked by $\frac{5}{4}n$
points. Moreover, they conjectured that, if $P$ is in convex position, $n$
blocking points are sufficient and necessary. The necessity was recently shown
by Biniaz (2021) who proved that every point set in general position requires
$n$ blocking points.
</p>
<p>Here we investigate the variant, where blocking points can only lie outside
of the convex hull of the given point set. We show that $\frac{5}{4}n-O(1)$
such \emph{exterior-blocking} points are sometimes necessary, even if the given
point set is in convex position. As a consequence we obtain that, if the
conjecture of Aichholzer et al. for the original setting was true, then minimal
blocking sets of some point configurations $P$ would have to contain points
inside of the convex hull of $P$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aichholzer_O/0/1/0/all/0/1">Oswin Aichholzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Hackl_T/0/1/0/all/0/1">Thomas Hackl</a>, <a href="http://arxiv.org/find/cs/1/au:+Loffler_M/0/1/0/all/0/1">Maarten L&#xf6;ffler</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilz_A/0/1/0/all/0/1">Alexander Pilz</a>, <a href="http://arxiv.org/find/cs/1/au:+Parada_I/0/1/0/all/0/1">Irene Parada</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheucher_M/0/1/0/all/0/1">Manfred Scheucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogtenhuber_B/0/1/0/all/0/1">Birgit Vogtenhuber</a></p><p>Given two distinct point sets $P$ and $Q$ in the plane, we say that $Q$
\emph{blocks} $P$ if no two points of $P$ are adjacent in any Delaunay
triangulation of $P\cup Q$. Aichholzer et al. (2013) showed that any set $P$ of
$n$ points in general position can be blocked by $\frac{3}{2}n$ points and that
every set $P$ of $n$ points in convex position can be blocked by $\frac{5}{4}n$
points. Moreover, they conjectured that, if $P$ is in convex position, $n$
blocking points are sufficient and necessary. The necessity was recently shown
by Biniaz (2021) who proved that every point set in general position requires
$n$ blocking points.
</p>
<p>Here we investigate the variant, where blocking points can only lie outside
of the convex hull of the given point set. We show that $\frac{5}{4}n-O(1)$
such \emph{exterior-blocking} points are sometimes necessary, even if the given
point set is in convex position. As a consequence we obtain that, if the
conjecture of Aichholzer et al. for the original setting was true, then minimal
blocking sets of some point configurations $P$ would have to contain points
inside of the convex hull of $P$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11778'>Rerouting Planar Curves and Disjoint Paths</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Takehiro Ito, Yuni Iwamasa, Naonori Kakimura, Yusuke Kobayashi, Shun-ichi Maezawa, Yuta Nozaki, Yoshio Okamoto, Kenta Ozeki</p><p>In this paper, we consider a transformation of $k$ disjoint paths in a graph.
For a graph and a pair of $k$ disjoint paths $\mathcal{P}$ and $\mathcal{Q}$
connecting the same set of terminal pairs, we aim to determine whether
$\mathcal{P}$ can be transformed to $\mathcal{Q}$ by repeatedly replacing one
path with another path so that the intermediates are also $k$ disjoint paths.
The problem is called Disjoint Paths Reconfiguration. We first show that
Disjoint Paths Reconfiguration is PSPACE-complete even when $k=2$. On the other
hand, we prove that, when the graph is embedded on a plane and all paths in
$\mathcal{P}$ and $\mathcal{Q}$ connect the boundaries of two faces, Disjoint
Paths Reconfiguration can be solved in polynomial time. The algorithm is based
on a topological characterization for rerouting curves on a plane using the
algebraic intersection number. We also consider a transformation of disjoint
$s$-$t$ paths as a variant. We show that the disjoint $s$-$t$ paths
reconfiguration problem in planar graphs can be determined in polynomial time,
while the problem is PSPACE-complete in general.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1">Takehiro Ito</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwamasa_Y/0/1/0/all/0/1">Yuni Iwamasa</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakimura_N/0/1/0/all/0/1">Naonori Kakimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yusuke Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maezawa_S/0/1/0/all/0/1">Shun-ichi Maezawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Nozaki_Y/0/1/0/all/0/1">Yuta Nozaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Okamoto_Y/0/1/0/all/0/1">Yoshio Okamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozeki_K/0/1/0/all/0/1">Kenta Ozeki</a></p><p>In this paper, we consider a transformation of $k$ disjoint paths in a graph.
For a graph and a pair of $k$ disjoint paths $\mathcal{P}$ and $\mathcal{Q}$
connecting the same set of terminal pairs, we aim to determine whether
$\mathcal{P}$ can be transformed to $\mathcal{Q}$ by repeatedly replacing one
path with another path so that the intermediates are also $k$ disjoint paths.
The problem is called Disjoint Paths Reconfiguration. We first show that
Disjoint Paths Reconfiguration is PSPACE-complete even when $k=2$. On the other
hand, we prove that, when the graph is embedded on a plane and all paths in
$\mathcal{P}$ and $\mathcal{Q}$ connect the boundaries of two faces, Disjoint
Paths Reconfiguration can be solved in polynomial time. The algorithm is based
on a topological characterization for rerouting curves on a plane using the
algebraic intersection number. We also consider a transformation of disjoint
$s$-$t$ paths as a variant. We show that the disjoint $s$-$t$ paths
reconfiguration problem in planar graphs can be determined in polynomial time,
while the problem is PSPACE-complete in general.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11542'>Sketching Meets Differential Privacy: Fast Algorithm for Dynamic Kronecker Projection Maintenance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhao Song, Xin Yang, Yuanyuan Yang, Lichen Zhang</p><p>Projection maintenance is one of the core data structure tasks. Efficient
data structures for projection maintenance have led to recent breakthroughs in
many convex programming algorithms. In this work, we further extend this
framework to the Kronecker product structure. Given a constraint matrix ${\sf
A}$ and a positive semi-definite matrix $W\in \mathbb{R}^{n\times n}$ with a
sparse eigenbasis, we consider the task of maintaining the projection in the
form of ${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}$, where ${\sf B}={\sf
A}(W\otimes I)$ or ${\sf B}={\sf A}(W^{1/2}\otimes W^{1/2})$. At each
iteration, the weight matrix $W$ receives a low rank change and we receive a
new vector $h$. The goal is to maintain the projection matrix and answer the
query ${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}h$ with good approximation
guarantees. We design a fast dynamic data structure for this task and it is
robust against an adaptive adversary. Following the work of [Beimel, Kaplan,
Mansour, Nissim, Saranurak and Stemmer, STOC'22], we use tools from
differential privacy to reduce the randomness required by the data structure
and further improve the running time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuanyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lichen Zhang</a></p><p>Projection maintenance is one of the core data structure tasks. Efficient
data structures for projection maintenance have led to recent breakthroughs in
many convex programming algorithms. In this work, we further extend this
framework to the Kronecker product structure. Given a constraint matrix ${\sf
A}$ and a positive semi-definite matrix $W\in \mathbb{R}^{n\times n}$ with a
sparse eigenbasis, we consider the task of maintaining the projection in the
form of ${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}$, where ${\sf B}={\sf
A}(W\otimes I)$ or ${\sf B}={\sf A}(W^{1/2}\otimes W^{1/2})$. At each
iteration, the weight matrix $W$ receives a low rank change and we receive a
new vector $h$. The goal is to maintain the projection matrix and answer the
query ${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}h$ with good approximation
guarantees. We design a fast dynamic data structure for this task and it is
robust against an adaptive adversary. Following the work of [Beimel, Kaplan,
Mansour, Nissim, Saranurak and Stemmer, STOC'22], we use tools from
differential privacy to reduce the randomness required by the data structure
and further improve the running time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11570'>Online Resource Allocation with Buyback: Optimal Algorithms via Primal-Dual</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Farbod Ekbatani, Yiding Feng, Rad Niazadeh</p><p>Motivated by applications in cloud computing spot markets and selling banner
ads on popular websites, we study the online resource allocation problem with
"costly buyback". To model this problem, we consider the classic edge-weighted
fractional online matching problem with a tweak, where the decision maker can
recall (i.e., buyback) any fraction of an offline resource that is
pre-allocated to an earlier online vertex; however, by doing so not only the
decision maker loses the previously allocated reward (which equates the
edge-weight), it also has to pay a non-negative constant factor $f$ of this
edge-weight as an extra penalty. Parameterizing the problem by the buyback
factor $f$, our main result is obtaining optimal competitive algorithms for all
possible values of $f$ through a novel primal-dual family of algorithms. We
establish the optimality of our results by obtaining separate lower-bounds for
each of small and large buyback factor regimes, and showing how our primal-dual
algorithm exactly matches this lower-bound by appropriately tuning a parameter
as a function of $f$. We further study lower and upper bounds on the
competitive ratio in variants of this model, e.g., single-resource with
different demand sizes, or matching with deterministic integral allocations. We
show how algorithms in the our family of primal-dual algorithms can obtain the
exact optimal competitive ratio in all of these variants -- which in turn
demonstrates the power of our algorithmic framework for online resource
allocations with costly buyback.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ekbatani_F/0/1/0/all/0/1">Farbod Ekbatani</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yiding Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Niazadeh_R/0/1/0/all/0/1">Rad Niazadeh</a></p><p>Motivated by applications in cloud computing spot markets and selling banner
ads on popular websites, we study the online resource allocation problem with
"costly buyback". To model this problem, we consider the classic edge-weighted
fractional online matching problem with a tweak, where the decision maker can
recall (i.e., buyback) any fraction of an offline resource that is
pre-allocated to an earlier online vertex; however, by doing so not only the
decision maker loses the previously allocated reward (which equates the
edge-weight), it also has to pay a non-negative constant factor $f$ of this
edge-weight as an extra penalty. Parameterizing the problem by the buyback
factor $f$, our main result is obtaining optimal competitive algorithms for all
possible values of $f$ through a novel primal-dual family of algorithms. We
establish the optimality of our results by obtaining separate lower-bounds for
each of small and large buyback factor regimes, and showing how our primal-dual
algorithm exactly matches this lower-bound by appropriately tuning a parameter
as a function of $f$. We further study lower and upper bounds on the
competitive ratio in variants of this model, e.g., single-resource with
different demand sizes, or matching with deterministic integral allocations. We
show how algorithms in the our family of primal-dual algorithms can obtain the
exact optimal competitive ratio in all of these variants -- which in turn
demonstrates the power of our algorithmic framework for online resource
allocations with costly buyback.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11634'>A polynomial-time algorithm to solve the large scale of airplane refueling problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jinchuan Cui, Xiaoya Li</p><p>Airplane refueling problem (ARP) is a scheduling problem with an objective
function of fractional form. Given a fleet of $n$ airplanes with mid-air
refueling technique, each airplane has a specific fuel capacity and fuel
consumption rate. The fleet starts to fly together to a same target and during
the trip each airplane could instantaneously refuel to other airplanes and then
be dropped out. The question is how to find the best refueling policy to make
the last remaining airplane travels the farthest. We give a definition of the
sequential feasible solution and construct a sequential search algorithm, whose
computational complexity depends on the number of sequential feasible solutions
referred to $Q_n$. By utilizing combination and recurrence ideas, we prove that
the the upper bound of $Q_n$ is $2^{n-2}$. Then we focus on the worst-case and
investigate the complexity of the sequential search algorithm from a dynamic
perspective. Given a worst-case instance under some assumptions, we prove that
there must exist an index $m$ such that when $n$ is greater than $2m$, $Q_n$
turns out to be upper bounded by $\frac{m^2}{n}C_n^m$. Here the index $m$ is a
constant and could be regarded as an "inflection point": with the increasing
scale of input $n$, $Q_n$ turns out to be a polynomial function of $n$. Hence,
the sequential search algorithm turns out to run in polynomial time of $n$.
Moreover, we build an efficient computability scheme by which we shall predict
the complexity of $Q_n$ to choose a proper algorithm considering the available
running time for decision makers or users.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jinchuan Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoya Li</a></p><p>Airplane refueling problem (ARP) is a scheduling problem with an objective
function of fractional form. Given a fleet of $n$ airplanes with mid-air
refueling technique, each airplane has a specific fuel capacity and fuel
consumption rate. The fleet starts to fly together to a same target and during
the trip each airplane could instantaneously refuel to other airplanes and then
be dropped out. The question is how to find the best refueling policy to make
the last remaining airplane travels the farthest. We give a definition of the
sequential feasible solution and construct a sequential search algorithm, whose
computational complexity depends on the number of sequential feasible solutions
referred to $Q_n$. By utilizing combination and recurrence ideas, we prove that
the the upper bound of $Q_n$ is $2^{n-2}$. Then we focus on the worst-case and
investigate the complexity of the sequential search algorithm from a dynamic
perspective. Given a worst-case instance under some assumptions, we prove that
there must exist an index $m$ such that when $n$ is greater than $2m$, $Q_n$
turns out to be upper bounded by $\frac{m^2}{n}C_n^m$. Here the index $m$ is a
constant and could be regarded as an "inflection point": with the increasing
scale of input $n$, $Q_n$ turns out to be a polynomial function of $n$. Hence,
the sequential search algorithm turns out to run in polynomial time of $n$.
Moreover, we build an efficient computability scheme by which we shall predict
the complexity of $Q_n$ to choose a proper algorithm considering the available
running time for decision makers or users.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11648'>Two-stage Stochastic Matching and Pricing with Applications to Ride Hailing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yiding Feng, Rad Niazadeh, Amin Saberi</p><p>Matching and pricing are two critical levers in two-sided marketplaces to
connect demand and supply. The platform can produce more efficient matching and
pricing decisions by batching the demand requests. We initiate the study of the
two-stage stochastic matching problem, with or without pricing, to enable the
platform to make improved decisions in a batch with an eye toward the imminent
future demand requests. This problem is motivated in part by applications in
online marketplaces such as ride hailing platforms.
</p>
<p>We design online competitive algorithms for vertex-weighted (or unweighted)
two-stage stochastic matching for maximizing supply efficiency, and two-stage
joint matching and pricing for maximizing market efficiency. In the former
problem, using a randomized primal-dual algorithm applied to a family of
``balancing'' convex programs, we obtain the optimal $3/4$ competitive ratio
against the optimum offline benchmark. Using a factor revealing program and
connections to submodular optimization, we improve this ratio against the
optimum online benchmark to $(1-1/e+1/e^2)\approx 0.767$ for the unweighted and
$0.761$ for the weighted case. In the latter problem, we design optimal
$1/2$-competitive joint pricing and matching algorithm by borrowing ideas from
the ex-ante prophet inequality literature. We also show an improved
$(1-1/e)$-competitive algorithm for the special case of demand efficiency
objective using the correlation gap of submodular functions. Finally, we
complement our theoretical study by using DiDi's ride-sharing dataset for
Chengdu city and numerically evaluating the performance of our proposed
algorithms in practical instances of this problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yiding Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Niazadeh_R/0/1/0/all/0/1">Rad Niazadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Saberi_A/0/1/0/all/0/1">Amin Saberi</a></p><p>Matching and pricing are two critical levers in two-sided marketplaces to
connect demand and supply. The platform can produce more efficient matching and
pricing decisions by batching the demand requests. We initiate the study of the
two-stage stochastic matching problem, with or without pricing, to enable the
platform to make improved decisions in a batch with an eye toward the imminent
future demand requests. This problem is motivated in part by applications in
online marketplaces such as ride hailing platforms.
</p>
<p>We design online competitive algorithms for vertex-weighted (or unweighted)
two-stage stochastic matching for maximizing supply efficiency, and two-stage
joint matching and pricing for maximizing market efficiency. In the former
problem, using a randomized primal-dual algorithm applied to a family of
``balancing'' convex programs, we obtain the optimal $3/4$ competitive ratio
against the optimum offline benchmark. Using a factor revealing program and
connections to submodular optimization, we improve this ratio against the
optimum online benchmark to $(1-1/e+1/e^2)\approx 0.767$ for the unweighted and
$0.761$ for the weighted case. In the latter problem, we design optimal
$1/2$-competitive joint pricing and matching algorithm by borrowing ideas from
the ex-ante prophet inequality literature. We also show an improved
$(1-1/e)$-competitive algorithm for the special case of demand efficiency
objective using the correlation gap of submodular functions. Finally, we
complement our theoretical study by using DiDi's ride-sharing dataset for
Chengdu city and numerically evaluating the performance of our proposed
algorithms in practical instances of this problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11784'>A Simple Deterministic Distributed Low-Diameter Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: V&#xe1;clav Rozho&#x148;, Bernhard Haeupler, Christoph Grunau</p><p>We give a simple, local process for nodes in an undirected graph to form
non-adjacent clusters that (1) have at most a polylogarithmic diameter and (2)
contain at least half of all vertices. Efficient deterministic distributed
clustering algorithms for computing strong-diameter network decompositions and
other key tools follow immediately. Overall, our process is a direct and
drastically simplified way for computing these fundamental objects.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rozhon_V/0/1/0/all/0/1">V&#xe1;clav Rozho&#x148;</a>, <a href="http://arxiv.org/find/cs/1/au:+Haeupler_B/0/1/0/all/0/1">Bernhard Haeupler</a>, <a href="http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1">Christoph Grunau</a></p><p>We give a simple, local process for nodes in an undirected graph to form
non-adjacent clusters that (1) have at most a polylogarithmic diameter and (2)
contain at least half of all vertices. Efficient deterministic distributed
clustering algorithms for computing strong-diameter network decompositions and
other key tools follow immediately. Overall, our process is a direct and
drastically simplified way for computing these fundamental objects.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11881'>Solving the Probabilistic Profitable Tour Problem on a Tree</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Enrico Angelelli, Renata Mansini, Romeo Rizzi</p><p>The profitable tour problem (PTP) is a well-known NP-hard routing problem
searching for a tour visiting a subset of customers while maximizing profit as
the difference between total revenue collected and traveling costs. PTP is
known to be solvable in polynomial time when special structures of the
underlying graph are considered. However, the computational complexity of the
corresponding probabilistic generalizations is still an open issue in many
cases. In this paper, we analyze the probabilistic PTP where customers are
located on a tree and need, with a known probability, for a service provision
at a predefined prize. The problem objective is to select a priori a subset of
customers with whom to commit the service so to maximize the expected profit.
We provide a polynomial time algorithm computing the optimal solution in
$O(n^2)$, where $n$ is the number of nodes in the tree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Angelelli_E/0/1/0/all/0/1">Enrico Angelelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansini_R/0/1/0/all/0/1">Renata Mansini</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizzi_R/0/1/0/all/0/1">Romeo Rizzi</a></p><p>The profitable tour problem (PTP) is a well-known NP-hard routing problem
searching for a tour visiting a subset of customers while maximizing profit as
the difference between total revenue collected and traveling costs. PTP is
known to be solvable in polynomial time when special structures of the
underlying graph are considered. However, the computational complexity of the
corresponding probabilistic generalizations is still an open issue in many
cases. In this paper, we analyze the probabilistic PTP where customers are
located on a tree and need, with a known probability, for a service provision
at a predefined prize. The problem objective is to select a priori a subset of
customers with whom to commit the service so to maximize the expected profit.
We provide a polynomial time algorithm computing the optimal solution in
$O(n^2)$, where $n$ is the number of nodes in the tree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11918'>Splay Top Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jacob Holm (1), Eva Rotenberg (2), Alice Ryhl (2) ((1) University of Copenhagen, (2) Technical University of Denmark)</p><p>The top tree data structure is an important and fundamental tool in dynamic
graph algorithms. Top trees have existed for decades, and today serve as an
ingredient in many state-of-the-art algorithms for dynamic graphs. In this
work, we give a new direct proof of the existence of top trees, facilitating
simpler and more direct implementations of top trees, based on ideas from splay
trees. This result hinges on new insights into the structure of top trees, and
in particular the structure of each root path in a top tree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Holm_J/0/1/0/all/0/1">Jacob Holm</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1">Eva Rotenberg</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Ryhl_A/0/1/0/all/0/1">Alice Ryhl</a> (2) ((1) University of Copenhagen, (2) Technical University of Denmark)</p><p>The top tree data structure is an important and fundamental tool in dynamic
graph algorithms. Top trees have existed for decades, and today serve as an
ingredient in many state-of-the-art algorithms for dynamic graphs. In this
work, we give a new direct proof of the existence of top trees, facilitating
simpler and more direct implementations of top trees, based on ideas from splay
trees. This result hinges on new insights into the structure of top trees, and
in particular the structure of each root path in a top tree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11992'>Efficient Submodular Optimization under Noise: Local Search is Robust</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Yuyi Wang, Chunxue Yang, Huanjian Zhou</p><p>The problem of monotone submodular maximization has been studied extensively
due to its wide range of applications. However, there are cases where one can
only access the objective function in a distorted or noisy form because of the
uncertain nature or the errors involved in the evaluation. This paper considers
the problem of constrained monotone submodular maximization with noisy oracles
introduced by [Hassidim et al., 2017]. For a cardinality constraint, we propose
an algorithm achieving a near-optimal
$\left(1-\frac{1}{e}-O(\varepsilon)\right)$-approximation guarantee (for
arbitrary $\varepsilon &gt; 0$) with only a polynomial number of queries to the
noisy value oracle, which improves the exponential query complexity of [Singer
et al., 2018]. For general matroid constraints, we show the first constant
approximation algorithm in the presence of noise. Our main approaches are to
design a novel local search framework that can handle the effect of noise and
to construct certain smoothing surrogate functions for noise reduction.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chunxue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huanjian Zhou</a></p><p>The problem of monotone submodular maximization has been studied extensively
due to its wide range of applications. However, there are cases where one can
only access the objective function in a distorted or noisy form because of the
uncertain nature or the errors involved in the evaluation. This paper considers
the problem of constrained monotone submodular maximization with noisy oracles
introduced by [Hassidim et al., 2017]. For a cardinality constraint, we propose
an algorithm achieving a near-optimal
$\left(1-\frac{1}{e}-O(\varepsilon)\right)$-approximation guarantee (for
arbitrary $\varepsilon &gt; 0$) with only a polynomial number of queries to the
noisy value oracle, which improves the exponential query complexity of [Singer
et al., 2018]. For general matroid constraints, we show the first constant
approximation algorithm in the presence of noise. Our main approaches are to
design a novel local search framework that can handle the effect of noise and
to construct certain smoothing surrogate functions for noise reduction.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11996'>Unbalanced Triangle Detection and Enumeration Hardness for Unions of Conjunctive Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Karl Bringmann, Nofar Carmeli</p><p>We study the enumeration of answers to Unions of Conjunctive Queries (UCQs)
with optimal time guarantees. More precisely, we wish to identify the queries
that can be solved with linear preprocessing time and constant delay. Despite
the basic nature of this problem, it was shown only recently that UCQs can be
solved within these time bounds if they admit free-connex union extensions,
even if all individual CQs in the union are intractable with respect to the
same complexity measure. Our goal is to understand whether there exist
additional tractable UCQs, not covered by the currently known algorithms.
</p>
<p>As a first step, we show that some previously unclassified UCQs are hard
using the classic 3SUM hypothesis, via a known reduction from 3SUM to triangle
listing in graphs. As a second step, we identify a question about a variant of
this graph task which is unavoidable if we want to classify all self-join free
UCQs: is it possible to decide the existence of a triangle in a
vertex-unbalanced tripartite graph in linear time? We prove that this task is
equivalent in hardness to some family of UCQs. Finally, we show a dichotomy for
unions of two self-join-free CQs if we assume the answer to this question is
negative.
</p>
<p>As a result, to reason about a class of enumeration problems defined by UCQs,
it is enough to study the single decision problem of detecting triangles in
unbalanced graphs. As of today, we know of no algorithm that comes close to
solving this decision problem within the required time bounds. Our conclusion
is that, without a breakthrough for triangle detection, we have no hope to find
an efficient algorithm for additional unions of two self-join free CQs. On the
other hand, if we will one day have such a triangle detection algorithm, we
will immediately obtain an efficient algorithm for a family of UCQs that are
currently not known to be tractable.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bringmann_K/0/1/0/all/0/1">Karl Bringmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmeli_N/0/1/0/all/0/1">Nofar Carmeli</a></p><p>We study the enumeration of answers to Unions of Conjunctive Queries (UCQs)
with optimal time guarantees. More precisely, we wish to identify the queries
that can be solved with linear preprocessing time and constant delay. Despite
the basic nature of this problem, it was shown only recently that UCQs can be
solved within these time bounds if they admit free-connex union extensions,
even if all individual CQs in the union are intractable with respect to the
same complexity measure. Our goal is to understand whether there exist
additional tractable UCQs, not covered by the currently known algorithms.
</p>
<p>As a first step, we show that some previously unclassified UCQs are hard
using the classic 3SUM hypothesis, via a known reduction from 3SUM to triangle
listing in graphs. As a second step, we identify a question about a variant of
this graph task which is unavoidable if we want to classify all self-join free
UCQs: is it possible to decide the existence of a triangle in a
vertex-unbalanced tripartite graph in linear time? We prove that this task is
equivalent in hardness to some family of UCQs. Finally, we show a dichotomy for
unions of two self-join-free CQs if we assume the answer to this question is
negative.
</p>
<p>As a result, to reason about a class of enumeration problems defined by UCQs,
it is enough to study the single decision problem of detecting triangles in
unbalanced graphs. As of today, we know of no algorithm that comes close to
solving this decision problem within the required time bounds. Our conclusion
is that, without a breakthrough for triangle detection, we have no hope to find
an efficient algorithm for additional unions of two self-join free CQs. On the
other hand, if we will one day have such a triangle detection algorithm, we
will immediately obtain an efficient algorithm for a family of UCQs that are
currently not known to be tractable.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-24T00:30:00Z">Monday, October 24 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, October 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/141'>TR22-141 |  TFNP Characterizations of Proof Systems and Monotone Circuits | 

	Noah Fleming, 

	Sam Buss, 

	Russell Impagliazzo</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Connections between proof complexity and circuit complexity have become major tools for obtaining lower bounds in both areas. These connections -- which take the form of interpolation theorems and query-to-communication lifting theorems --  translate efficient proofs into small circuits, and vice versa, allowing tools from one area to be applied to the other. Recently, the theory of TFNP has emerged as a unifying framework underlying these connections. For many of the proof systems which admit such a connection there is a TFNP problem which characterizes it: the class of problems which are reducible to this TFNP problem via query-efficient reductions is equivalent to the tautologies that can be efficiently proven in the system. Through this, proof complexity has become a major tool for proving separations in black-box TFNP. Similarly, for certain monotone circuit models, the class of functions that it can compute efficiently is equivalent to what can be reduced to a certain TFNP problem in low communication. When a TFNP problem has both a proof and circuit characterization, one can prove an interpolation theorem. Conversely, many lifting theorems can be viewed as relating the communication and query reductions to TFNP problems. This is exciting, as it suggests that TFNP provides a roadmap for the development of further interpolation theorems and lifting theorems. 

In this paper we begin to develop a more systematic understanding of when these connections to TFNP occur. We give exact conditions under which a proof system or circuit model admits a characterization by a TFNP problem. We show:

- Every well-behaved proof system which can prove its own soundness (a reflection principle) is characterized by a TFNP problem. Conversely, every TFNP problem gives rise to a well-behaved proof system which proves its own soundness.

- Every well-behaved monotone circuit model which admits a universal family  of functions is characterized by a TFNP problem. Conversely, every TFNP problem gives rise to a well-behaved monotone circuit model with a universal problem.

As an example, we provide a TFNP characterization of the Polynomial Calculus, answering a question of Goos et al., and show that it can prove its own soundness.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Connections between proof complexity and circuit complexity have become major tools for obtaining lower bounds in both areas. These connections -- which take the form of interpolation theorems and query-to-communication lifting theorems --  translate efficient proofs into small circuits, and vice versa, allowing tools from one area to be applied to the other. Recently, the theory of TFNP has emerged as a unifying framework underlying these connections. For many of the proof systems which admit such a connection there is a TFNP problem which characterizes it: the class of problems which are reducible to this TFNP problem via query-efficient reductions is equivalent to the tautologies that can be efficiently proven in the system. Through this, proof complexity has become a major tool for proving separations in black-box TFNP. Similarly, for certain monotone circuit models, the class of functions that it can compute efficiently is equivalent to what can be reduced to a certain TFNP problem in low communication. When a TFNP problem has both a proof and circuit characterization, one can prove an interpolation theorem. Conversely, many lifting theorems can be viewed as relating the communication and query reductions to TFNP problems. This is exciting, as it suggests that TFNP provides a roadmap for the development of further interpolation theorems and lifting theorems. 

In this paper we begin to develop a more systematic understanding of when these connections to TFNP occur. We give exact conditions under which a proof system or circuit model admits a characterization by a TFNP problem. We show:

- Every well-behaved proof system which can prove its own soundness (a reflection principle) is characterized by a TFNP problem. Conversely, every TFNP problem gives rise to a well-behaved proof system which proves its own soundness.

- Every well-behaved monotone circuit model which admits a universal family  of functions is characterized by a TFNP problem. Conversely, every TFNP problem gives rise to a well-behaved monotone circuit model with a universal problem.

As an example, we provide a TFNP characterization of the Polynomial Calculus, answering a question of Goos et al., and show that it can prove its own soundness.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-23T01:10:16Z">Sunday, October 23 2022, 01:10</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, October 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2022/10/22/repeated-vertices-tsp.html'>Repeated vertices in TSP tours</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This week my graph algorithms course covered the traveling salesperson problem, which I usually describe in two equivalent forms:
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>This week my graph algorithms course covered the traveling salesperson problem, which I usually describe in two equivalent forms:</p>

<ul>
  <li>
    <p>Given a distance matrix representing a metric space, find a cycle that passes through each point of the space exactly once, of minimum total length</p>
  </li>
  <li>
    <p>Given a connected positively-weighted undirected graph, find a closed walk that passes through each vertex at least once, of minimum total length</p>
  </li>
</ul>

<p>To go from a distance matrix to a graph, we just use the complete graph, and skip any repeated vertices in its closed walk. To go from a graph to a distance matrix, compute all pairs shortest distances, and then form a closed walk by concatenating the shortest paths between consecutive vertices of the non-repeating cycle. But this concatenation may create many unavoidable repeated vertices. For instance, if your graph is an <span style="white-space:nowrap">\(n\)-vertex</span> star, then any closed walk through all the vertices must return to the central vertex \(n-1\) times, like the blue curve past all of the vertices in the nine-vertex star below.</p>

<p style="text-align:center"><img src="/blog/assets/2022/star-tour.svg" alt="A closed walk through all vertices of the star $$K_{1,8}$$ visits the central vertex eight times." /></p>

<p>It occurred to me to wonder: how many repetitions might be necessary, in total? The multigraph of edges used by the closed walk (with one copy for each time the walk uses each edge) is Eulerian, meaning that it connects all the vertices and has even degree at all of them. Any Eulerian multigraph has a closed walk visiting all the vertices, its Euler tour. Among these graphs, the TSP multigraph must be minimal: if it had an Eulerian subgraph we could walk on that instead. And any minimal Eulerian multigraph can be turned into a simple graph and weighted in such a way that all edges are used with their given multiplicities in the optimal TSP walk. So another, more combinatorial, way of asking the same question is: how many edges can a minimal Eulerian multigraph have?</p>

<p>The answer: <span style="white-space:nowrap">\(2n-2\).</span> More precisely, a graph is said to be <a href="https://en.wikipedia.org/wiki/Dense_graph">\((a,b)\)-sparse</a> if every <span style="white-space:nowrap">\(k\)-vertex</span> subgraph has at most \(ak-b\) edges. In this sense, the minimal Eulerian graphs are <span style="white-space:nowrap">\((2,2)\)-sparse.</span></p>

<p>If you were given an Eulerian graph that is not <span style="white-space:nowrap">\((2,2)\)-sparse,</span> it could not be minimal Eulerian. To see this, choose a minimal subset of \(k\) vertices that has more than \(2k-2\) edges. By deleting edges, you can find a subgraph that is <span style="white-space:nowrap">\((2,2)\)-tight:</span> it has exactly \(2k-2\) edges, and every subgraph is <span style="white-space:nowrap">\((2,2)\)-sparse.</span> A result of Nash-Williams from the 1960s states that a subgraph like this can always be decomposed into two spanning trees. But if you combine one of the deleted edges with a path between its endpoints in one of the trees, you get a cycle that you can remove without changing the parity of the vertex degrees. Removing this cycle still leaves a subgraph that is connected through the other spanning tree. Because there is a cycle you can remove leaving an Eulerian subgraph, your starting graph is not minimal.</p>

<p>The bound of \(2(n-1)\) on the number of edges in a minimal Eulerian multigraph cannot be made any smaller. One way to construct a minimal Eulerian multigraph with exactly this many edges (maybe the only way) is just to double all of the edges in a tree.</p>

<p>Instead of counting edges, another way to define sparse graphs involves forbidden <a href="https://en.wikipedia.org/wiki/Shallow_minor">shallow minors</a>. However, this does not work for minimal Eulerian graphs: they have no forbidden shallow minors. For instance, if you subdivide the edges of any Eulerian graph, such as a complete graph on an odd number of vertices, you will get a minimal Eulerian graph that has the complete graph as a depth-1 minor.</p>

<p style="text-align:center"><img src="/blog/assets/2022/subdivided-K7.svg" alt="Subdividing the edges of the complete graph $$K_7$$ produces a minimal Eulerian graph with $$K_7$$ as a 1-shallow minor." /></p>

<p>(<a href="https://mathstodon.xyz/@11011110/109214811068499556">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-22T17:22:00Z">Saturday, October 22 2022, 17:22</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, October 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/21/faculty-at-northeastern-university-apply-by-december-1-2022/'>Faculty at Northeastern University (apply by December 1, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Northeastern&#8217;s Khoury College of Computer Sciences is looking to hire 8 open-rank tenure-track faculty this year! We are specifically targeting cryptography, differential privacy, and quantum computing, but are interested in exceptional candidates in all areas. Website: www.khoury.northeastern.edu/information-for-overview/prospective-faculty/open-positions/tenure-track/ Email: jullman@ccs.neu.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Northeastern&#8217;s Khoury College of Computer Sciences is looking to hire 8 open-rank tenure-track faculty this year! We are specifically targeting cryptography, differential privacy, and quantum computing, but are interested in exceptional candidates in all areas.</p>
<p>Website: <a href="https://www.khoury.northeastern.edu/information-for-overview/prospective-faculty/open-positions/tenure-track/">https://www.khoury.northeastern.edu/information-for-overview/prospective-faculty/open-positions/tenure-track/</a><br />
Email: jullman@ccs.neu.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T17:52:43Z">Friday, October 21 2022, 17:52</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/21/postdoc-at-nanyang-technological-university-apply-by-december-31-2023/'>Postdoc at Nanyang Technological University (apply by December 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I&#8217;m looking for two postdocs to work with me on data stream algorithms, low distortion metric embeddings, randomized numerical linear algebra or other related topics. The starting date is flexible and will be from February 2023 onwards. The initial contract is for one year and an extension is possible based on performance and the funding [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I&#8217;m looking for two postdocs to work with me on data stream algorithms, low distortion metric embeddings, randomized numerical linear algebra or other related topics.</p>
<p>The starting date is flexible and will be from February 2023 onwards. The initial contract is for one year and an extension is possible based on performance and the funding situation.</p>
<p>Website: <a href="https://personal.ntu.edu.sg/yili/">https://personal.ntu.edu.sg/yili/</a><br />
Email: yili@ntu.edu.sg</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T04:49:58Z">Friday, October 21 2022, 04:49</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10917'>Substring Density Estimation from Traces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kayvon Mazooji, Ilan Shomorony</p><p>In the trace reconstruction problem, one seeks to reconstruct a binary string
$s$ from a collection of traces, each of which is obtained by passing $s$
through a deletion channel. It is known that $\exp(\tilde O(n^{1/5}))$ traces
suffice to reconstruct any length-$n$ string with high probability. We consider
a variant of the trace reconstruction problem where the goal is to recover a
"density map" that indicates the locations of each length-$k$ substring
throughout $s$. We show that $\epsilon^{-2}\cdot \text{poly}(n)$ traces suffice
to recover the density map with error at most $\epsilon$. As a result, when
restricted to a set of source strings whose minimum "density map distance" is
at least $1/\text{poly}(n)$, the trace reconstruction problem can be solved
with polynomially many traces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mazooji_K/0/1/0/all/0/1">Kayvon Mazooji</a>, <a href="http://arxiv.org/find/cs/1/au:+Shomorony_I/0/1/0/all/0/1">Ilan Shomorony</a></p><p>In the trace reconstruction problem, one seeks to reconstruct a binary string
$s$ from a collection of traces, each of which is obtained by passing $s$
through a deletion channel. It is known that $\exp(\tilde O(n^{1/5}))$ traces
suffice to reconstruct any length-$n$ string with high probability. We consider
a variant of the trace reconstruction problem where the goal is to recover a
"density map" that indicates the locations of each length-$k$ substring
throughout $s$. We show that $\epsilon^{-2}\cdot \text{poly}(n)$ traces suffice
to recover the density map with error at most $\epsilon$. As a result, when
restricted to a set of source strings whose minimum "density map distance" is
at least $1/\text{poly}(n)$, the trace reconstruction problem can be solved
with polynomially many traces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10968'>Identities and periodic oscillations of divide-and-conquer recurrences splitting at half</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hsien-Kuei Hwang, Svante Janson, Tsung-Hsi Tsai</p><p>We study divide-and-conquer recurrences of the form \begin{equation*}
</p>
<p>f(n)
</p>
<p>= \alpha f(\lfloor \tfrac n2\rfloor)
</p>
<p>+ \beta f(\lceil \tfrac n2\rceil)
</p>
<p>+ g(n) \qquad(n\ge2), \end{equation*} with $g(n)$ and $f(1)$ given, where
$\alpha,\beta\ge0$ with $\alpha+\beta&gt;0$; such recurrences appear often in
analysis of computer algorithms, numeration systems, combinatorial sequences,
and related areas. We show that the solution satisfies always the simple
\emph{identity} \begin{equation*}
</p>
<p>f(n)
</p>
<p>= n^{\log_2(\alpha+\beta)} P(\log_2n) - Q(n) \end{equation*} under an optimum
(iff) condition on $g(n)$. This form is not only an identity but also an
asymptotic expansion because $Q(n)$ is of a smaller order. Explicit forms for
the \emph{continuity} of the periodic function $P$ are provided, together with
a few other smoothness properties. We show how our results can be easily
applied to many dozens of concrete examples collected from the literature, and
how they can be extended in various directions. Our method of proof is
surprisingly simple and elementary, but leads to the strongest types of results
for all examples to which our theory applies.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hwang_H/0/1/0/all/0/1">Hsien-Kuei Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Janson_S/0/1/0/all/0/1">Svante Janson</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_T/0/1/0/all/0/1">Tsung-Hsi Tsai</a></p><p>We study divide-and-conquer recurrences of the form \begin{equation*}
</p>
<p>f(n)
</p>
<p>= \alpha f(\lfloor \tfrac n2\rfloor)
</p>
<p>+ \beta f(\lceil \tfrac n2\rceil)
</p>
<p>+ g(n) \qquad(n\ge2), \end{equation*} with $g(n)$ and $f(1)$ given, where
$\alpha,\beta\ge0$ with $\alpha+\beta&gt;0$; such recurrences appear often in
analysis of computer algorithms, numeration systems, combinatorial sequences,
and related areas. We show that the solution satisfies always the simple
\emph{identity} \begin{equation*}
</p>
<p>f(n)
</p>
<p>= n^{\log_2(\alpha+\beta)} P(\log_2n) - Q(n) \end{equation*} under an optimum
(iff) condition on $g(n)$. This form is not only an identity but also an
asymptotic expansion because $Q(n)$ is of a smaller order. Explicit forms for
the \emph{continuity} of the periodic function $P$ are provided, together with
a few other smoothness properties. We show how our results can be easily
applied to many dozens of concrete examples collected from the literature, and
how they can be extended in various directions. Our method of proof is
surprisingly simple and elementary, but leads to the strongest types of results
for all examples to which our theory applies.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11132'>A general model-and-run solver for multistage robust discrete linear optimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Hartisch, Ulf Lorenz</p><p>The necessity to deal with uncertain data is a major challenge in decision
making. Robust optimization emerged as one of the predominant paradigms to
produce solutions that hedge against uncertainty. In order to obtain an even
more realistic description of the underlying problem where the decision maker
can react to newly disclosed information, multistage models can be used.
However, due to their computational difficulty, multistage problems beyond two
stages have received less attention and are often only addressed using
approximation rather than optimization schemes. Even less attention is paid to
the consideration of decision-dependent uncertainty in a multistage setting. We
explore multistage robust optimization via quantified linear programs, which
are linear programs with ordered variables that are either existentially or
universally quantified. Building upon a (mostly) discrete setting where the
uncertain parameters -- the universally quantified variables -- are only
restricted by their bounds, we present an augmented version that allows stating
the discrete uncertainty set via a linear constraint system that also can be
affected by decision variables. We present a general search-based solution
approach and introduce our solver Yasol that is able to deal with multistage
robust linear discrete optimization problems, with final mixed-integer recourse
actions and a discrete uncertainty set, which even can be decision-dependent.
In doing so, we provide a convenient model-and-run approach, that can serve as
baseline for computational experiments in the field of multistage robust
optimization, providing optimal solutions for problems with an arbitrary number
of decision stages.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Hartisch_M/0/1/0/all/0/1">Michael Hartisch</a>, <a href="http://arxiv.org/find/math/1/au:+Lorenz_U/0/1/0/all/0/1">Ulf Lorenz</a></p><p>The necessity to deal with uncertain data is a major challenge in decision
making. Robust optimization emerged as one of the predominant paradigms to
produce solutions that hedge against uncertainty. In order to obtain an even
more realistic description of the underlying problem where the decision maker
can react to newly disclosed information, multistage models can be used.
However, due to their computational difficulty, multistage problems beyond two
stages have received less attention and are often only addressed using
approximation rather than optimization schemes. Even less attention is paid to
the consideration of decision-dependent uncertainty in a multistage setting. We
explore multistage robust optimization via quantified linear programs, which
are linear programs with ordered variables that are either existentially or
universally quantified. Building upon a (mostly) discrete setting where the
uncertain parameters -- the universally quantified variables -- are only
restricted by their bounds, we present an augmented version that allows stating
the discrete uncertainty set via a linear constraint system that also can be
affected by decision variables. We present a general search-based solution
approach and introduce our solver Yasol that is able to deal with multistage
robust linear discrete optimization problems, with final mixed-integer recourse
actions and a discrete uncertainty set, which even can be decision-dependent.
In doing so, we provide a convenient model-and-run approach, that can serve as
baseline for computational experiments in the field of multistage robust
optimization, providing optimal solutions for problems with an arbitrary number
of decision stages.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11185'>Using Integer Programming Techniques in Real-Time Scheduling Analysis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Abhishek Singh</p><p>Real-time scheduling theory assists developers of embedded systems in
verifying that the timing constraints required by critical software tasks can
be feasibly met on a given hardware platform. Fundamental problems in the
theory are often formulated as search problems for fixed points of functions
and are solved by fixed-point iterations. These fixed-point methods are used
widely because they are simple to understand, simple to implement, and seem to
work well in practice. These fundamental problems can also be formulated as
integer programs and solved with algorithms that are based on theories of
linear programming and cutting planes amongst others. However, such algorithms
are harder to understand and implement than fixed-point iterations. In this
research, we show that ideas like linear programming duality and cutting planes
can be used to develop algorithms that are as easy to implement as existing
fixed-point iteration schemes but have better convergence properties. We
evaluate the algorithms on synthetically generated problem instances to
demonstrate that the new algorithms are faster than the existing algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Abhishek Singh</a></p><p>Real-time scheduling theory assists developers of embedded systems in
verifying that the timing constraints required by critical software tasks can
be feasibly met on a given hardware platform. Fundamental problems in the
theory are often formulated as search problems for fixed points of functions
and are solved by fixed-point iterations. These fixed-point methods are used
widely because they are simple to understand, simple to implement, and seem to
work well in practice. These fundamental problems can also be formulated as
integer programs and solved with algorithms that are based on theories of
linear programming and cutting planes amongst others. However, such algorithms
are harder to understand and implement than fixed-point iterations. In this
research, we show that ideas like linear programming duality and cutting planes
can be used to develop algorithms that are as easy to implement as existing
fixed-point iteration schemes but have better convergence properties. We
evaluate the algorithms on synthetically generated problem instances to
demonstrate that the new algorithms are faster than the existing algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11197'>Noisy Tree Data Structures and Quantum Applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kamil Khadiev, Nikita Savelyev, Mansur Ziatdinov</p><p>The paper presents a technique for constructing noisy data structures called
a walking tree. We apply it for a Red-Black tree (an implementation of a
Self-Balanced Binary Search Tree) and a segment tree. We obtain the same
complexity of the main operations for these data structures as in the case
without noise (asymptotically). We use these data structures in quantum
algorithms for two problems: the Exam Problem and the Largest File Problem.
</p>
<p>Finally, we suggest new quantum solution for strings sorting problem and show
the lower bound. The upper bound and lower bound for the problem are the same
up to log factor. At the same time, it is more effective than classical
counterparts.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Khadiev_K/0/1/0/all/0/1">Kamil Khadiev</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Savelyev_N/0/1/0/all/0/1">Nikita Savelyev</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ziatdinov_M/0/1/0/all/0/1">Mansur Ziatdinov</a></p><p>The paper presents a technique for constructing noisy data structures called
a walking tree. We apply it for a Red-Black tree (an implementation of a
Self-Balanced Binary Search Tree) and a segment tree. We obtain the same
complexity of the main operations for these data structures as in the case
without noise (asymptotically). We use these data structures in quantum
algorithms for two problems: the Exam Problem and the Largest File Problem.
</p>
<p>Finally, we suggest new quantum solution for strings sorting problem and show
the lower bound. The upper bound and lower bound for the problem are the same
up to log factor. At the same time, it is more effective than classical
counterparts.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11222'>Private Algorithms with Private Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kareem Amin, Travis Dick, Mikhail Khodak, Sergei Vassilvitskii</p><p>When applying differential privacy to sensitive data, a common way of getting
improved performance is to use external information such as other sensitive
data, public data, or human priors. We propose to use the algorithms with
predictions framework -- previously applied largely to improve time complexity
or competitive ratios -- as a powerful way of designing and analyzing
privacy-preserving methods that can take advantage of such external information
to improve utility. For four important tasks -- quantile release, its extension
to multiple quantiles, covariance estimation, and data release -- we construct
prediction-dependent differentially private methods whose utility scales with
natural measures of prediction quality. The analyses enjoy several advantages,
including minimal assumptions about the data, natural ways of adding robustness
to noisy predictions, and novel "meta" algorithms that can learn predictions
from other (potentially sensitive) data. Overall, our results demonstrate how
to enable differentially private algorithms to make use of and learn noisy
predictions, which holds great promise for improving utility while preserving
privacy across a variety of tasks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Amin_K/0/1/0/all/0/1">Kareem Amin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dick_T/0/1/0/all/0/1">Travis Dick</a>, <a href="http://arxiv.org/find/cs/1/au:+Khodak_M/0/1/0/all/0/1">Mikhail Khodak</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilvitskii_S/0/1/0/all/0/1">Sergei Vassilvitskii</a></p><p>When applying differential privacy to sensitive data, a common way of getting
improved performance is to use external information such as other sensitive
data, public data, or human priors. We propose to use the algorithms with
predictions framework -- previously applied largely to improve time complexity
or competitive ratios -- as a powerful way of designing and analyzing
privacy-preserving methods that can take advantage of such external information
to improve utility. For four important tasks -- quantile release, its extension
to multiple quantiles, covariance estimation, and data release -- we construct
prediction-dependent differentially private methods whose utility scales with
natural measures of prediction quality. The analyses enjoy several advantages,
including minimal assumptions about the data, natural ways of adding robustness
to noisy predictions, and novel "meta" algorithms that can learn predictions
from other (potentially sensitive) data. Overall, our results demonstrate how
to enable differentially private algorithms to make use of and learn noisy
predictions, which holds great promise for improving utility while preserving
privacy across a variety of tasks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11295'>Block subsampled randomized Hadamard transform for low-rank approximation on distributed architectures</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Oleg Balabanov, Matthias Beaupere, Laura Grigori, Victor Lederer</p><p>This article introduces a novel structured random matrix composed blockwise
from subsampled randomized Hadamard transforms (SRHTs). The block SRHT is
expected to outperform well-known dimension reduction maps, including SRHT and
Gaussian matrices, on distributed architectures with not too many cores
compared to the dimension. We prove that a block SRHT with enough rows is an
oblivious subspace embedding, i.e., an approximate isometry for an arbitrary
low-dimensional subspace with high probability. Our estimate of the required
number of rows is similar to that of the standard SRHT. This suggests that the
two transforms should provide the same accuracy of approximation in the
algorithms. The block SRHT can be readily incorporated into randomized methods,
for instance to compute a low-rank approximation of a large-scale matrix. For
completeness, we revisit some common randomized approaches for this problem
such as Randomized Singular Value Decomposition and Nystr\"{o}m approximation,
with a discussion of their accuracy and implementation on distributed
architectures.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Balabanov_O/0/1/0/all/0/1">Oleg Balabanov</a>, <a href="http://arxiv.org/find/math/1/au:+Beaupere_M/0/1/0/all/0/1">Matthias Beaupere</a>, <a href="http://arxiv.org/find/math/1/au:+Grigori_L/0/1/0/all/0/1">Laura Grigori</a>, <a href="http://arxiv.org/find/math/1/au:+Lederer_V/0/1/0/all/0/1">Victor Lederer</a></p><p>This article introduces a novel structured random matrix composed blockwise
from subsampled randomized Hadamard transforms (SRHTs). The block SRHT is
expected to outperform well-known dimension reduction maps, including SRHT and
Gaussian matrices, on distributed architectures with not too many cores
compared to the dimension. We prove that a block SRHT with enough rows is an
oblivious subspace embedding, i.e., an approximate isometry for an arbitrary
low-dimensional subspace with high probability. Our estimate of the required
number of rows is similar to that of the standard SRHT. This suggests that the
two transforms should provide the same accuracy of approximation in the
algorithms. The block SRHT can be readily incorporated into randomized methods,
for instance to compute a low-rank approximation of a large-scale matrix. For
completeness, we revisit some common randomized approaches for this problem
such as Randomized Singular Value Decomposition and Nystr\"{o}m approximation,
with a discussion of their accuracy and implementation on distributed
architectures.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.11413'>Finding the smallest or largest element of a tensor from its low-rank factors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicholas D. Sidiropoulos, Paris Karakasis, Aritra Konar</p><p>We consider the problem of finding the smallest or largest entry of a tensor
of order $N$ that is specified via its rank decomposition. Stated in a
different way, we are given $N$ sets of $R$-dimensional vectors and we wish to
select one vector from each set such that the sum of the Hadamard product of
the selected vectors is minimized or maximized. This is a fundamental tensor
problem with numerous applications in embedding similarity search, recommender
systems, graph mining, multivariate probability, and statistics. We show that
this discrete optimization problem is NP-hard for any tensor rank higher than
one, but also provide an equivalent continuous problem reformulation which is
amenable to disciplined non-convex optimization. We propose a suite of
gradient-based approximation algorithms whose performance in preliminary
experiments appears to be promising.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/eess/1/au:+Sidiropoulos_N/0/1/0/all/0/1">Nicholas D. Sidiropoulos</a>, <a href="http://arxiv.org/find/eess/1/au:+Karakasis_P/0/1/0/all/0/1">Paris Karakasis</a>, <a href="http://arxiv.org/find/eess/1/au:+Konar_A/0/1/0/all/0/1">Aritra Konar</a></p><p>We consider the problem of finding the smallest or largest entry of a tensor
of order $N$ that is specified via its rank decomposition. Stated in a
different way, we are given $N$ sets of $R$-dimensional vectors and we wish to
select one vector from each set such that the sum of the Hadamard product of
the selected vectors is minimized or maximized. This is a fundamental tensor
problem with numerous applications in embedding similarity search, recommender
systems, graph mining, multivariate probability, and statistics. We show that
this discrete optimization problem is NP-hard for any tensor rank higher than
one, but also provide an equivalent continuous problem reformulation which is
amenable to disciplined non-convex optimization. We propose a suite of
gradient-based approximation algorithms whose performance in preliminary
experiments appears to be promising.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-21T00:30:00Z">Friday, October 21 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, October 20
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/20/tenure-track-faculty-positions-at-simon-fraser-university-apply-by-december-15-2022/'>Tenure-track Faculty Positions at Simon Fraser University (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The School of Computing Science at Simon Fraser University (SFU) invites applications for multiple tenure-track faculty positions. Website: www.sfu.ca/computing/job-opportunities.html Email: cs_faculty_affairs@sfu.ca
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The School of Computing Science at Simon Fraser University (SFU) invites applications for multiple tenure-track faculty positions.</p>
<p>Website: <a href="https://www.sfu.ca/computing/job-opportunities.html">https://www.sfu.ca/computing/job-opportunities.html</a><br />
Email: cs_faculty_affairs@sfu.ca</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T23:49:12Z">Thursday, October 20 2022, 23:49</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/20/faculty-tt-open-to-all-ranks-at-university-of-colorado-boulder-apply-by-december-5-2022/'>Faculty (TT, open to all ranks) at University of Colorado Boulder (apply by December 5, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The University of Colorado Boulder is seeking applications for a tenure-track faculty position at the Assistant Professor rank in theoretical computer science, broadly deﬁned. Associate &#38; Full Professor ranks may be considered for qualified candidates. All researchers working on topics within &#38; adjacent to the broad area of Computer Science Theory are encouraged to apply. [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The University of Colorado Boulder is seeking applications for a tenure-track faculty position at the Assistant Professor rank in theoretical computer science, broadly deﬁned. Associate &amp; Full Professor ranks may be considered for qualified candidates. All researchers working on topics within &amp; adjacent to the broad area of Computer Science Theory are encouraged to apply.</p>
<p>Website: <a href="https://jobs.colorado.edu/jobs/JobDetail/?jobId=43568">https://jobs.colorado.edu/jobs/JobDetail/?jobId=43568</a><br />
Email: jgrochow@colorado.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T18:53:34Z">Thursday, October 20 2022, 18:53</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/20/two-postdoc-positions-in-lisbon-at-university-of-lisbon-apply-by-january-1-2023/'>Two postdoc positions in Lisbon at University of Lisbon (apply by January 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I&#8217;m looking for two postdocs to join me as part of the ERC Starting Grant &#8220;The Hardness of Finding Good Algorithms&#8221;. The project focuses on metacomplexity and unconditional lower-bounds. The starting date is flexible, between March-October 2023. A decision on individual applicants will not be made before November 1, and I expect both positions to [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I&#8217;m looking for two postdocs to join me as part of the ERC Starting Grant &#8220;The Hardness of Finding Good Algorithms&#8221;. The project focuses on metacomplexity and unconditional lower-bounds.</p>
<p>The starting date is flexible, between March-October 2023. A decision on individual applicants will not be made before November 1, and I expect both positions to be filled by mid-late January.</p>
<p>Website: <a href="https://brunoloff.wordpress.com/hofga/">https://brunoloff.wordpress.com/hofga/</a><br />
Email: bruno.loff@gmail.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T17:30:08Z">Thursday, October 20 2022, 17:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/10/alpha-tensor.html'>Alpha Tensor</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>In a recent post, Bill used the announcement of a new AI multiplication algorithm to discuss the applications of Strassen's famous algorithm. For this post I'd like to focus on the new algorithm itself,&nbsp;Alpha Tensor, the algorithm behind the algorithm, what it has actually accomplished&nbsp;and what it means for us theorists.&nbsp;</p><p>To multiply two 2x2 matrices in the usual way you need eight multiplication steps. In 1969 Strassen surprised the world by showing how to multiply those matrices using only seven multiplications.</p><p>You can recurse on larger matrices. For 4x4 matrices you can use 72=49 multiplications instead of the naïve 64. In general for nxn matrices you need roughly nlog27 ≈ n2.81 multiplications.</p><p>No one has found an algorithm for 4x4 matrices that uses less than 49 from recursing on Strassen. Alpha Tensor does so for the special case of working over GF[2], where addition and subtraction are interchangeable. Their algorithm does not work for general fields such as the real numbers.</p><p>Here's the full table of Alpha Tensor results from the Nature paper for multiplying a nxm matrix by a mxp matrix. The Modular column is for GF[2] and the standard column is for general fields. Alpha tensor does improve on the best known for general fields for specific problems like multiplying a 3x4 matrix by a 4x5 matrix. Much of the press failed to make this distinction for 4x4 multiplication leading to some confusion.</p>♦<br>What does this mean for theory? Recursing on 4x4 matrices now reduces the time for matrix multiplication to roughly n2.78 nowhere close to the best theoretical upper bound of about n2.37. The Alpha tensor result may be more practical though time will tell.<br>Manuel Kauers and Jakob Moosbauer shortly after Alpha Tensor announcement, reduced the 5x5 case over GF[2] to 95 multiplications. Nice to see the last word isn't by machine (yet!) but that shouldn't reduce the excitement over Alpha Tensor. Often we see a breakthrough followed by a small improvement. Note that 95 multiplications for 5x5 matrices won't give a faster asymptotic algorithm for nxn multiplication than Strassen.<br>What excites me the most is not the algorithm, but the algorithm to find the algorithm. Alpha Tensor uses the tools that AlphaZero used to play Chess and Go to search the large search space of potential algorithms using Monte Carlo Tree search, basically searching at random and learning and updating the probabilities of the search. Before using machine learning, we had few good approaches to searching large combinatorial spaces of this nature.&nbsp;<br>In general, most new algorithms come from new approaches, not just from the structural decomposition we see in matrix multiplication so theorists won't be out of a job anytime soon. Nevertheless this is just another lesson that using ML has dramatically improved our ability to search through a large number of possibilities looking for a specific solution.&nbsp;<br>The Alpha Tensor Nature paper was submitted in October of 2021. A year is eternity in the ML world. I wonder what is happening now that we don't know about.<p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In a <a href="https://blog.computationalcomplexity.org/2022/10/will-strassens-matrix-mult-alg-ever-be.html">recent post</a>, Bill used the announcement of a new AI multiplication algorithm to discuss the applications of Strassen's famous algorithm. For this post I'd like to focus on the new algorithm itself,&nbsp;<a href="https://www.deepmind.com/blog/discovering-novel-algorithms-with-alphatensor">Alpha Tensor</a>, the algorithm behind the algorithm, what it has actually accomplished&nbsp;and what it means for us theorists.&nbsp;</p><p>To multiply two 2x2 matrices in the usual way you need eight multiplication steps. In 1969 Strassen surprised the world by showing how to <a href="https://en.wikipedia.org/wiki/Strassen_algorithm#Algorithm">multiply those matrices using only seven multiplications</a>.</p><p>You can recurse on larger matrices. For 4x4 matrices you can use 7<sup>2</sup>=49 multiplications instead of the naïve 64. In general for nxn matrices you need roughly n<sup>log<sub>2</sub>7</sup> ≈ n<sup>2.81</sup> multiplications.</p><p>No one has found an algorithm for 4x4 matrices that uses less than 49 from recursing on Strassen. Alpha Tensor does so for the special case of working over GF[2], where addition and subtraction are interchangeable. Their algorithm does not work for general fields such as the real numbers.</p><p>Here's the full table of Alpha Tensor results from the <a href="https://doi.org/10.1038/s41586-022-05172-4">Nature paper</a> for multiplying a nxm matrix by a mxp matrix. The Modular column is for GF[2] and the standard column is for general fields. Alpha tensor does improve on the best known for general fields for specific problems like multiplying a 3x4 matrix by a 4x5 matrix. Much of the press <a href="https://arstechnica.com/information-technology/2022/10/deepmind-breaks-50-year-math-record-using-ai-new-record-falls-a-week-later/">failed to make this distinction</a> for 4x4 multiplication leading to some confusion.</p><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj9-_aNBNNDkLCuUrz9Wz2dzgctRxEAk2Q8ptCHuk1SwBLyNrwentWYhpYulJX3VP64GE3UxlfaQlSHxm2faVnrh44MCnEyHSM2o-998w6P0_gKIk9fPScLQU9PtxKUPmfuFZR6SiYYlvuXw01FhP0Jg24ro1j0YCY99pxg7aTzMI7mzgWCfw/s833/IMG_0190.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="833" data-original-width="702" height="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj9-_aNBNNDkLCuUrz9Wz2dzgctRxEAk2Q8ptCHuk1SwBLyNrwentWYhpYulJX3VP64GE3UxlfaQlSHxm2faVnrh44MCnEyHSM2o-998w6P0_gKIk9fPScLQU9PtxKUPmfuFZR6SiYYlvuXw01FhP0Jg24ro1j0YCY99pxg7aTzMI7mzgWCfw/w540-h640/IMG_0190.jpg" width="540" /></a></div><br /><div class="separator" style="clear: both; text-align: left;">What does this mean for theory? Recursing on 4x4 matrices now reduces the time for matrix multiplication to roughly n<sup>2.78</sup> nowhere close to the best <a href="https://doi.org/10.1137/1.9781611976465.32">theoretical upper bound</a> of about n<sup>2.37</sup>. The Alpha tensor result may be more practical though time will tell.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">Manuel Kauers and Jakob Moosbauer shortly after Alpha Tensor announcement, <a href="https://arxiv.org/abs/2210.04045">reduced</a> the 5x5 case over GF[2] to 95 multiplications. Nice to see the last word isn't by machine (yet!) but that shouldn't reduce the excitement over Alpha Tensor. Often we see a breakthrough followed by a small improvement. Note that 95 multiplications for 5x5 matrices won't give a faster asymptotic algorithm for nxn multiplication than Strassen.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">What excites me the most is not the algorithm, but the algorithm to find the algorithm. Alpha Tensor uses the tools that AlphaZero used to play Chess and Go to search the large search space of potential algorithms using Monte Carlo Tree search, basically searching at random and learning and updating the probabilities of the search. Before using machine learning, we had few good approaches to searching large combinatorial spaces of this nature.&nbsp;</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">In general, most new algorithms come from new approaches, not just from the structural decomposition we see in matrix multiplication so theorists won't be out of a job anytime soon. Nevertheless this is just another lesson that using ML has dramatically improved our ability to search through a large number of possibilities looking for a specific solution.&nbsp;</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">The Alpha Tensor Nature paper was <a href="https://www.nature.com/articles/s41586-022-05172-4#article-info">submitted</a> in October of 2021. A year is eternity in the ML world. I wonder what is happening now that we don't know about.</div><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T14:27:00Z">Thursday, October 20 2022, 14:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2022/10/20/tcs-talk-wednesday-october-26-shay-moran-technion-and-google-research/'>TCS+ talk: Wednesday, October 26 — Shay Moran, Technion and Google Research</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, October 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Shay Moran from Technion and Google Research will speak about &#8220;A Characterization of Multiclass PAC Learning&#8221; (abstract below). You can reserve a spot as an individual or a [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, October 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Shay Moran</strong> from Technion and Google Research will speak about &#8220;<em>A Characterization of Multiclass PAC Learning</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: A seminal result in learning theory characterizes the PAC learnability of binary classes through the VC dimension. Extending this characterization to the general multiclass setting has been open since the late 1980s.</p>
<p>We resolve this problem by characterizing multiclass PAC learnability through the DS dimension, a combinatorial dimension defined by Daniely and Shalev-Shwartz (2014).</p>
<p>The classical characterization of the binary case boils down to empirical risk minimization. In contrast, our characterization of the multiclass case involves a variety of algorithmic ideas; these include a natural setting we call list PAC learning. In the list learning setting, instead of predicting the label of a given unseen input, the goal is to provide a short list of labels which contains the correct one with high probability.</p>
<p>Our second main result concerns the Natarajan dimension, which has been a central candidate for characterizing multiclass learnability. This dimension was introduced by Natarajan (1988) as a barrier for PAC learning. Whether the Natarajan dimension characterizes PAC learnability in general has been posed as an open question in several papers since. We provide a negative answer: we construct a non-learnable class with Natarajan dimension one.</p>
<p>For the construction, we identify a fundamental connection between concept classes and topology. We crucially rely on a deep and involved geometric-group-theoretic construction by Januszkiewicz and Swiatkowski. This proof provides another demonstration of the fruitful links learning theory has with different areas in mathematics.</p>
<p>Joint work with Nataly Brukhim, Daniel Carmon, Irit Dinur, and Amir Yehudayoff</p></blockquote>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T10:29:17Z">Thursday, October 20 2022, 10:29</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/20/teaching-faculty-open-rank-at-university-of-illinois-at-urbana-champaign-apply-by-november-15-2022/'>Teaching Faculty (Open Rank) at University of Illinois at Urbana-Champaign (apply by November 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Computer Science Department at the University of Illinois invites applications for multiple full-time teaching positions to support the continued expansion of our teaching activity in Urbana-Champaign, in Chicago, and online. We welcome applications from instructors able to teach across the computer science curriculum, including candidates who can teach algorithms and theory. Website: cs.illinois.edu/about/positions/faculty-positions/teaching-faculty Email: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Computer Science Department at the University of Illinois invites applications for multiple full-time teaching positions to support the continued expansion of our teaching activity in Urbana-Champaign, in Chicago, and online. We welcome applications from instructors able to teach across the computer science curriculum, including candidates who can teach algorithms and theory.</p>
<p>Website: <a href="https://cs.illinois.edu/about/positions/faculty-positions/teaching-faculty">https://cs.illinois.edu/about/positions/faculty-positions/teaching-faculty</a><br />
Email: facultysearch@cs.illinois.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T01:51:34Z">Thursday, October 20 2022, 01:51</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/10/20/professor-open-rank-at-university-of-illinois-at-urbana-champaign-apply-by-november-15-2022/'>Professor (Open Rank) at University of Illinois at Urbana-Champaign (apply by November 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Department of Computer Science at the University of Illinois Urbana-Champaign invites applications for full-time tenure-track faculty positions at all levels (Assistant Professor, Associate Professor, Full Professor). We particularly encourage applications from candidates working in quantum computing, but all areas of theory will be considered. Website: cs.illinois.edu/about/positions/faculty-positions/tenure-track Email: cs-facultysearch@illinois.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Department of Computer Science at the University of Illinois Urbana-Champaign invites applications for full-time tenure-track faculty positions at all levels (Assistant Professor, Associate Professor, Full Professor). We particularly encourage applications from candidates working in quantum computing, but all areas of theory will be considered.</p>
<p>Website: <a href="https://cs.illinois.edu/about/positions/faculty-positions/tenure-track">https://cs.illinois.edu/about/positions/faculty-positions/tenure-track</a><br />
Email: cs-facultysearch@illinois.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T01:45:15Z">Thursday, October 20 2022, 01:45</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10181'>Comparing Embedded Graphs Using Average Branching Distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Levent Batakci, Abigail Branson, Bryan Castillo, Candace Todd, Erin Wolf Chambers, Elizabeth Munch</p><p>Graphs drawn in the plane are ubiquitous, arising from data sets through a
variety of methods ranging from GIS analysis to image classification to shape
analysis. A fundamental problem in this type of data is comparison: given a set
of such graphs, can we rank how similar they are, in such a way that we capture
their geometric "shape" in the plane? In this paper we explore a method to
compare two such embedded graphs, via a simplified combinatorial representation
called a tail-less merge tree which encodes the structure based on a fixed
direction. First, we examine the properties of a distance designed to compare
merge trees called the branching distance, and show that the distance as
defined in previous work fails to satisfy some of the requirements of a metric.
We incorporate this into a new distance function called average branching
distance to compare graphs by looking at the branching distance for merge trees
defined over many directions. Despite the theoretical issues, we show that the
definition is still quite useful in practice by using our open-source code to
cluster data sets of embedded graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Batakci_L/0/1/0/all/0/1">Levent Batakci</a>, <a href="http://arxiv.org/find/cs/1/au:+Branson_A/0/1/0/all/0/1">Abigail Branson</a>, <a href="http://arxiv.org/find/cs/1/au:+Castillo_B/0/1/0/all/0/1">Bryan Castillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Todd_C/0/1/0/all/0/1">Candace Todd</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambers_E/0/1/0/all/0/1">Erin Wolf Chambers</a>, <a href="http://arxiv.org/find/cs/1/au:+Munch_E/0/1/0/all/0/1">Elizabeth Munch</a></p><p>Graphs drawn in the plane are ubiquitous, arising from data sets through a
variety of methods ranging from GIS analysis to image classification to shape
analysis. A fundamental problem in this type of data is comparison: given a set
of such graphs, can we rank how similar they are, in such a way that we capture
their geometric "shape" in the plane? In this paper we explore a method to
compare two such embedded graphs, via a simplified combinatorial representation
called a tail-less merge tree which encodes the structure based on a fixed
direction. First, we examine the properties of a distance designed to compare
merge trees called the branching distance, and show that the distance as
defined in previous work fails to satisfy some of the requirements of a metric.
We incorporate this into a new distance function called average branching
distance to compare graphs by looking at the branching distance for merge trees
defined over many directions. Despite the theoretical issues, we show that the
definition is still quite useful in practice by using our open-source code to
cluster data sets of embedded graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10535'>Stability of Entropic Wasserstein Barycenters and application to random geometric graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marc Theveneau, Nicolas Keriven</p><p>As interest in graph data has grown in recent years, the computation of
various geometric tools has become essential. In some area such as mesh
processing, they often rely on the computation of geodesics and shortest paths
in discretized manifolds. A recent example of such a tool is the computation of
Wasserstein barycenters (WB), a very general notion of barycenters derived from
the theory of Optimal Transport, and their entropic-regularized variant. In
this paper, we examine how WBs on discretized meshes relate to the geometry of
the underlying manifold. We first provide a generic stability result with
respect to the input cost matrices. We then apply this result to random
geometric graphs on manifolds, whose shortest paths converge to geodesics,
hence proving the consistency of WBs computed on discretized shapes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Theveneau_M/0/1/0/all/0/1">Marc Theveneau</a>, <a href="http://arxiv.org/find/cs/1/au:+Keriven_N/0/1/0/all/0/1">Nicolas Keriven</a></p><p>As interest in graph data has grown in recent years, the computation of
various geometric tools has become essential. In some area such as mesh
processing, they often rely on the computation of geodesics and shortest paths
in discretized manifolds. A recent example of such a tool is the computation of
Wasserstein barycenters (WB), a very general notion of barycenters derived from
the theory of Optimal Transport, and their entropic-regularized variant. In
this paper, we examine how WBs on discretized meshes relate to the geometry of
the underlying manifold. We first provide a generic stability result with
respect to the input cost matrices. We then apply this result to random
geometric graphs on manifolds, whose shortest paths converge to geodesics,
hence proving the consistency of WBs computed on discretized shapes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10677'>List homomorphisms by deleting edges and vertices: tight complexity bounds for bounded-treewidth graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bar&#x131;&#x15f; Can Esmer, Jacob Focke, D&#xe1;niel Marx, Pawe&#x142; Rz&#x105;&#x17c;ewski</p><p>The goal of this paper is to investigate a family of optimization problems
arising from list homomorphisms, and to understand what the best possible
algorithms are if we restrict the problem to bounded-treewidth graphs. For a
fixed $H$, the input of the optimization problem LHomVD($H$) is a graph $G$
with lists $L(v)$, and the task is to find a set $X$ of vertices having minimum
size such that $(G-X,L)$ has a list homomorphism to $H$. We define analogously
the edge-deletion variant LHomED($H$). This expressive family of problems
includes members that are essentially equivalent to fundamental problems such
as Vertex Cover, Max Cut, Odd Cycle Transversal, and Edge/Vertex Multiway Cut.
</p>
<p>For both variants, we first characterize those graphs $H$ that make the
problem polynomial-time solvable and show that the problem is NP-hard for every
other fixed $H$. Second, as our main result, we determine for every graph $H$
for which the problem is NP-hard, the smallest possible constant $c_H$ such
that the problem can be solved in time $c^t_H\cdot n^{O(1)}$ if a tree
decomposition of $G$ having width $t$ is given in the input, assuming the SETH.
Let $i(H)$ be the maximum size of a set of vertices in $H$ that have pairwise
incomparable neighborhoods. For the vertex-deletion variant LHomVD($H$), we
show that the smallest possible constant is $i(H)+1$ for every $H$.
</p>
<p>The situation is more complex for the edge-deletion version. For every $H$,
one can solve LHomED($H$) in time $i(H)^t\cdot n^{O(1)}$ if a tree
decomposition of width $t$ is given. However, the existence of a specific type
of decomposition of $H$ shows that there are graphs $H$ where LHomED($H$) can
be solved significantly more efficiently and the best possible constant can be
arbitrarily smaller than $i(H)$. Nevertheless, we determine this best possible
constant and (assuming the SETH) prove tight bounds for every fixed $H$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Esmer_B/0/1/0/all/0/1">Bar&#x131;&#x15f; Can Esmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Focke_J/0/1/0/all/0/1">Jacob Focke</a>, <a href="http://arxiv.org/find/cs/1/au:+Marx_D/0/1/0/all/0/1">D&#xe1;niel Marx</a>, <a href="http://arxiv.org/find/cs/1/au:+Rzazewski_P/0/1/0/all/0/1">Pawe&#x142; Rz&#x105;&#x17c;ewski</a></p><p>The goal of this paper is to investigate a family of optimization problems
arising from list homomorphisms, and to understand what the best possible
algorithms are if we restrict the problem to bounded-treewidth graphs. For a
fixed $H$, the input of the optimization problem LHomVD($H$) is a graph $G$
with lists $L(v)$, and the task is to find a set $X$ of vertices having minimum
size such that $(G-X,L)$ has a list homomorphism to $H$. We define analogously
the edge-deletion variant LHomED($H$). This expressive family of problems
includes members that are essentially equivalent to fundamental problems such
as Vertex Cover, Max Cut, Odd Cycle Transversal, and Edge/Vertex Multiway Cut.
</p>
<p>For both variants, we first characterize those graphs $H$ that make the
problem polynomial-time solvable and show that the problem is NP-hard for every
other fixed $H$. Second, as our main result, we determine for every graph $H$
for which the problem is NP-hard, the smallest possible constant $c_H$ such
that the problem can be solved in time $c^t_H\cdot n^{O(1)}$ if a tree
decomposition of $G$ having width $t$ is given in the input, assuming the SETH.
Let $i(H)$ be the maximum size of a set of vertices in $H$ that have pairwise
incomparable neighborhoods. For the vertex-deletion variant LHomVD($H$), we
show that the smallest possible constant is $i(H)+1$ for every $H$.
</p>
<p>The situation is more complex for the edge-deletion version. For every $H$,
one can solve LHomED($H$) in time $i(H)^t\cdot n^{O(1)}$ if a tree
decomposition of width $t$ is given. However, the existence of a specific type
of decomposition of $H$ shows that there are graphs $H$ where LHomED($H$) can
be solved significantly more efficiently and the best possible constant can be
arbitrarily smaller than $i(H)$. Nevertheless, we determine this best possible
constant and (assuming the SETH) prove tight bounds for every fixed $H$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10172'>Simplex Range Searching Revisited: How to Shave Logs in Multi-Level Data Structures</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Timothy M. Chan, Da Wei Zheng</p><p>We revisit the classic problem of simplex range searching and related
problems in computational geometry. We present a collection of new results
which improve previous bounds by multiple logarithmic factors that were caused
by the use of multi-level data structures. Highlights include the following:
\begin{itemize} \item For a set of $n$ points in a constant dimension $d$, we
give data structures with $O(n^d)$ (or slightly better) space that can answer
simplex range counting queries in optimal $O(\log n)$ time and simplex range
reporting queries in optimal $O(\log n + k)$ time, where $k$ denotes the output
size. For semigroup range searching, we obtain $O(\log n)$ query time with
$O(n^d\mathop{\rm polylog}n)$ space. Previous data structures with similar
space bounds by Matou\v{s}ek from nearly three decades ago had $O(\log^{d+1}n)$
or $O(\log^{d+1}n + k)$ query time. \item For a set of $n$ simplices in a
constant dimension $d$, we give data structures with $O(n)$ space that can
answer stabbing counting queries (counting the number of simplices containing a
query point) in $O(n^{1-1/d})$ time, and stabbing reporting queries in
$O(n^{1-1/d}+k)$ time. Previous data structures had extra $\log^d n$ factors in
space and query time. \item For a set of $n$ (possibly intersecting) line
segments in 2D, we give a data structure with $O(n)$ space that can answer ray
shooting queries in $O(\sqrt{n})$ time. This improves Wang's recent data
structure [SoCG'20] with $O(n\log n)$ space and $O(\sqrt{n}\log n)$ query time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1">Timothy M. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1">Da Wei Zheng</a></p><p>We revisit the classic problem of simplex range searching and related
problems in computational geometry. We present a collection of new results
which improve previous bounds by multiple logarithmic factors that were caused
by the use of multi-level data structures. Highlights include the following:
\begin{itemize} \item For a set of $n$ points in a constant dimension $d$, we
give data structures with $O(n^d)$ (or slightly better) space that can answer
simplex range counting queries in optimal $O(\log n)$ time and simplex range
reporting queries in optimal $O(\log n + k)$ time, where $k$ denotes the output
size. For semigroup range searching, we obtain $O(\log n)$ query time with
$O(n^d\mathop{\rm polylog}n)$ space. Previous data structures with similar
space bounds by Matou\v{s}ek from nearly three decades ago had $O(\log^{d+1}n)$
or $O(\log^{d+1}n + k)$ query time. \item For a set of $n$ simplices in a
constant dimension $d$, we give data structures with $O(n)$ space that can
answer stabbing counting queries (counting the number of simplices containing a
query point) in $O(n^{1-1/d})$ time, and stabbing reporting queries in
$O(n^{1-1/d}+k)$ time. Previous data structures had extra $\log^d n$ factors in
space and query time. \item For a set of $n$ (possibly intersecting) line
segments in 2D, we give a data structure with $O(n)$ space that can answer ray
shooting queries in $O(\sqrt{n})$ time. This improves Wang's recent data
structure [SoCG'20] with $O(n\log n)$ space and $O(\sqrt{n}\log n)$ query time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10164'>Optimized Telecloning Circuits: Theory and Practice of Nine NISQ Clones</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Elijah Pelofske, Andreas B&#xe4;rtschi, Stephan Eidenbenz</p><p>Although perfect copying of an unknown quantum state is not possible,
approximate cloning is possible in quantum mechanics. Quantum telecloning is a
variant of approximate quantum cloning which uses quantum teleportation to
allow for the use of classical communication to create physically separate
clones of a quantum state. We present results of a of $1 \rightarrow 9$
universal, symmetric, optimal quantum telecloning implementation on a cloud
accessible quantum computer - the Quantinuum H1-1 device. The H1-1 device
allows direct creation of the telecloning protocol due to real time classical
if-statements that are conditional on the mid-circuit measurement outcome of a
Bell measurement. In this implementation, we also provide an improvement over
previous work for the circuit model description of quantum telecloning, which
reduces the required gate depth and gate count for an all-to-all connectivity.
The demonstration of creating $9$ approximate clones on a quantum processor is
the largest number of clones that has been generated, telecloning or otherwise.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Pelofske_E/0/1/0/all/0/1">Elijah Pelofske</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Bartschi_A/0/1/0/all/0/1">Andreas B&#xe4;rtschi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Eidenbenz_S/0/1/0/all/0/1">Stephan Eidenbenz</a></p><p>Although perfect copying of an unknown quantum state is not possible,
approximate cloning is possible in quantum mechanics. Quantum telecloning is a
variant of approximate quantum cloning which uses quantum teleportation to
allow for the use of classical communication to create physically separate
clones of a quantum state. We present results of a of $1 \rightarrow 9$
universal, symmetric, optimal quantum telecloning implementation on a cloud
accessible quantum computer - the Quantinuum H1-1 device. The H1-1 device
allows direct creation of the telecloning protocol due to real time classical
if-statements that are conditional on the mid-circuit measurement outcome of a
Bell measurement. In this implementation, we also provide an improvement over
previous work for the circuit model description of quantum telecloning, which
reduces the required gate depth and gate count for an all-to-all connectivity.
The demonstration of creating $9$ approximate clones on a quantum processor is
the largest number of clones that has been generated, telecloning or otherwise.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10173'>Faster Matrix Multiplication via Asymmetric Hashing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ran Duan, Hongxun Wu, Renfei Zhou</p><p>Fast matrix multiplication is one of the most fundamental problems in
algorithm research. The exponent of the optimal time complexity of matrix
multiplication is usually denoted by $\omega$. This paper discusses new ideas
for improving the laser method for fast matrix multiplication. We observe that
the analysis of higher powers of the Coppersmith-Winograd tensor [Coppersmith &amp;
Winograd 1990] incurs a "combination loss", and we partially compensate it by
using an asymmetric version of CW's hashing method. By analyzing the 8th power
of the CW tensor, we give a new bound of $\omega&lt;2.37188$, which improves the
previous best bound of $\omega&lt;2.37286$ [Alman &amp; V.Williams 2020]. Our result
breaks the lower bound of $2.3725$ in [Ambainis et al. 2014] because of the new
method for analyzing component (constituent) tensors.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Duan_R/0/1/0/all/0/1">Ran Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hongxun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1">Renfei Zhou</a></p><p>Fast matrix multiplication is one of the most fundamental problems in
algorithm research. The exponent of the optimal time complexity of matrix
multiplication is usually denoted by $\omega$. This paper discusses new ideas
for improving the laser method for fast matrix multiplication. We observe that
the analysis of higher powers of the Coppersmith-Winograd tensor [Coppersmith &amp;
Winograd 1990] incurs a "combination loss", and we partially compensate it by
using an asymmetric version of CW's hashing method. By analyzing the 8th power
of the CW tensor, we give a new bound of $\omega&lt;2.37188$, which improves the
previous best bound of $\omega&lt;2.37286$ [Alman &amp; V.Williams 2020]. Our result
breaks the lower bound of $2.3725$ in [Ambainis et al. 2014] because of the new
method for analyzing component (constituent) tensors.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10188'>On Hitting Times for General Quantum Markov Processes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lorenzo Laneve, Francesco Tacchino, Ivano Tavernelli</p><p>Random walks (or Markov chains) are models extensively used in theoretical
computer science. Several tools, including analysis of quantities such as
hitting and mixing times, are helpful for devising randomized algorithms. A
notable example is Sch\"oning's algorithm for the satisfiability (SAT) problem.
In this work, we use the density-matrix formalism to define a quantum Markov
chain model which directly generalizes classical walks, and we show that a
common tools such as hitting times can be computed with a similar formula as
the one found in the classical theory, which we then apply to known quantum
settings such as Grover's algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Laneve_L/0/1/0/all/0/1">Lorenzo Laneve</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tacchino_F/0/1/0/all/0/1">Francesco Tacchino</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tavernelli_I/0/1/0/all/0/1">Ivano Tavernelli</a></p><p>Random walks (or Markov chains) are models extensively used in theoretical
computer science. Several tools, including analysis of quantities such as
hitting and mixing times, are helpful for devising randomized algorithms. A
notable example is Sch\"oning's algorithm for the satisfiability (SAT) problem.
In this work, we use the density-matrix formalism to define a quantum Markov
chain model which directly generalizes classical walks, and we show that a
common tools such as hitting times can be computed with a similar formula as
the one found in the classical theory, which we then apply to known quantum
settings such as Grover's algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10370'>On the Perturbation Function of Ranking and Balance for Weighted Online Bipartite Matching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jingxun Liang, Zhihao Gavin Tang, Yixuan Xu, Yuhao Zhang, Renfei Zhou</p><p>Ranking and Balance are arguably the two most important algorithms in the
online matching literature. They achieve the same optimal competitive ratio of
$1-1/e$ for the integral version and fractional version of online bipartite
matching by Karp, Vazirani, and Vazirani (STOC 1990) respectively. The two
algorithms have been generalized to weighted online bipartite matching
problems, including vertex-weighted online bipartite matching and AdWords, by
utilizing a perturbation function. The canonical choice of the perturbation
function is $f(x)=1-e^{x-1}$ as it leads to the optimal competitive ratio of
$1-1/e$ in both settings.
</p>
<p>We advance the understanding of the weighted generalizations of Ranking and
Balance in this paper, with a focus on studying the effect of different
perturbation functions. First, we prove that the canonical perturbation
function is the \emph{unique} optimal perturbation function for vertex-weighted
online bipartite matching. In stark contrast, all perturbation functions
achieve the optimal competitive ratio of $1-1/e$ in the unweighted setting.
Second, we prove that the generalization of Ranking to AdWords with unknown
budgets using the canonical perturbation function is at most $0.624$
competitive, refuting a conjecture of Vazirani (2021). More generally, as an
application of the first result, we prove that no perturbation function leads
to the prominent competitive ratio of $1-1/e$ by establishing an upper bound of
$1-1/e-0.0003$.
</p>
<p>Finally, we propose the online budget-additive welfare maximization problem
that is intermediate between AdWords and AdWords with unknown budgets, and we
design an optimal $1-1/e$ competitive algorithm by generalizing Balance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jingxun Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhihao Gavin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yixuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1">Renfei Zhou</a></p><p>Ranking and Balance are arguably the two most important algorithms in the
online matching literature. They achieve the same optimal competitive ratio of
$1-1/e$ for the integral version and fractional version of online bipartite
matching by Karp, Vazirani, and Vazirani (STOC 1990) respectively. The two
algorithms have been generalized to weighted online bipartite matching
problems, including vertex-weighted online bipartite matching and AdWords, by
utilizing a perturbation function. The canonical choice of the perturbation
function is $f(x)=1-e^{x-1}$ as it leads to the optimal competitive ratio of
$1-1/e$ in both settings.
</p>
<p>We advance the understanding of the weighted generalizations of Ranking and
Balance in this paper, with a focus on studying the effect of different
perturbation functions. First, we prove that the canonical perturbation
function is the \emph{unique} optimal perturbation function for vertex-weighted
online bipartite matching. In stark contrast, all perturbation functions
achieve the optimal competitive ratio of $1-1/e$ in the unweighted setting.
Second, we prove that the generalization of Ranking to AdWords with unknown
budgets using the canonical perturbation function is at most $0.624$
competitive, refuting a conjecture of Vazirani (2021). More generally, as an
application of the first result, we prove that no perturbation function leads
to the prominent competitive ratio of $1-1/e$ by establishing an upper bound of
$1-1/e-0.0003$.
</p>
<p>Finally, we propose the online budget-additive welfare maximization problem
that is intermediate between AdWords and AdWords with unknown budgets, and we
design an optimal $1-1/e$ competitive algorithm by generalizing Balance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2210.10394'>Near-optimal Coresets for Robust Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Shaofeng H.-C. Jiang, Jianing Lou, Xuan Wu</p><p>We consider robust clustering problems in $\mathbb{R}^d$, specifically
$k$-clustering problems (e.g., $k$-Median and $k$-Means with $m$ outliers,
where the cost for a given center set $C \subset \mathbb{R}^d$ aggregates the
distances from $C$ to all but the furthest $m$ data points, instead of all
points as in classical clustering. We focus on the $\epsilon$-coreset for
robust clustering, a small proxy of the dataset that preserves the clustering
cost within $\epsilon$-relative error for all center sets. Our main result is
an $\epsilon$-coreset of size $O(m + \mathrm{poly}(k \epsilon^{-1}))$ that can
be constructed in near-linear time. This significantly improves previous
results, which either suffers an exponential dependence on $(m + k)$ [Feldman
and Schulman, SODA'12], or has a weaker bi-criteria guarantee [Huang et al.,
FOCS'18]. Furthermore, we show this dependence in $m$ is nearly-optimal, and
the fact that it is isolated from other factors may be crucial for dealing with
large number of outliers. We construct our coresets by adapting to the outlier
setting a recent framework [Braverman et al., FOCS'22] which was designed for
capacity-constrained clustering, overcoming a new challenge that the
participating terms in the cost, particularly the excluded $m$ outlier points,
are dependent on the center set $C$. We validate our coresets on various
datasets, and we observe a superior size-accuracy tradeoff compared with
popular baselines including uniform sampling and sensitivity sampling. We also
achieve a significant speedup of existing approximation algorithms for robust
clustering using our coresets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shaofeng H.-C. Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1">Jianing Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xuan Wu</a></p><p>We consider robust clustering problems in $\mathbb{R}^d$, specifically
$k$-clustering problems (e.g., $k$-Median and $k$-Means with $m$ outliers,
where the cost for a given center set $C \subset \mathbb{R}^d$ aggregates the
distances from $C$ to all but the furthest $m$ data points, instead of all
points as in classical clustering. We focus on the $\epsilon$-coreset for
robust clustering, a small proxy of the dataset that preserves the clustering
cost within $\epsilon$-relative error for all center sets. Our main result is
an $\epsilon$-coreset of size $O(m + \mathrm{poly}(k \epsilon^{-1}))$ that can
be constructed in near-linear time. This significantly improves previous
results, which either suffers an exponential dependence on $(m + k)$ [Feldman
and Schulman, SODA'12], or has a weaker bi-criteria guarantee [Huang et al.,
FOCS'18]. Furthermore, we show this dependence in $m$ is nearly-optimal, and
the fact that it is isolated from other factors may be crucial for dealing with
large number of outliers. We construct our coresets by adapting to the outlier
setting a recent framework [Braverman et al., FOCS'22] which was designed for
capacity-constrained clustering, overcoming a new challenge that the
participating terms in the cost, particularly the excluded $m$ outlier points,
are dependent on the center set $C$. We validate our coresets on various
datasets, and we observe a superior size-accuracy tradeoff compared with
popular baselines including uniform sampling and sensitivity sampling. We also
achieve a significant speedup of existing approximation algorithms for robust
clustering using our coresets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-10-20T00:30:00Z">Thursday, October 20 2022, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
