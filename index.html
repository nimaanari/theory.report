<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2022-11-09T22:37:36Z">Wednesday, November 09 2022, 22:37</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, November 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/09/postdoc-at-foundations-of-data-science-institute-fodsi-apply-by-december-15-2022/'>POSTDOC at FOUNDATIONS OF DATA SCIENCE INSTITUTE (FODSI) (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Foundations of Data Science Institute (FODSI), funded by the National Science Foundation TRIPODS program, is announcing a competitive postdoctoral fellowship. Multiple positions are available. FODSI is a collaboration between UC Berkeley and MIT, partnering with Boston University, Northeastern University, Harvard University, Howard University and Bryn Mawr College. Website: academicjobsonline.org/ajo/jobs/23541 Email: indyk@mit.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Foundations of Data Science Institute (FODSI), funded by the National Science Foundation TRIPODS program, is announcing a competitive postdoctoral fellowship. Multiple positions are available. FODSI is a collaboration between UC Berkeley and MIT, partnering with Boston University, Northeastern University, Harvard University, Howard University and Bryn Mawr College.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/23541">https://academicjobsonline.org/ajo/jobs/23541</a><br />
Email: indyk@mit.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T20:30:55Z">Wednesday, November 09 2022, 20:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/09/postdoc-at-university-of-waterloo-apply-by-december-10-2022/'>Postdoc at University of Waterloo (apply by December 10, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Algorithms &#38; Complexity group at the University of Waterloo is offering postdoctoral positions starting in the Fall of 2023. We seek candidates from all areas of theoretical computer science. Interested applicants should have their CV, research statement, and three recommendation letters emailed to theory.waterloo@gmail.com. Applications are due December 10th. Website: algcomp.uwaterloo.ca/positions/ Email: theory.waterloo@gmail.com
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Algorithms &amp; Complexity group at the University of Waterloo is offering postdoctoral positions starting in the Fall of 2023. We seek candidates from all areas of theoretical computer science.</p>
<p>Interested applicants should have their CV, research statement, and three recommendation letters emailed to theory.waterloo@gmail.com. Applications are due December 10th.</p>
<p>Website: <a href="https://algcomp.uwaterloo.ca/positions/">https://algcomp.uwaterloo.ca/positions/</a><br />
Email: theory.waterloo@gmail.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T19:56:36Z">Wednesday, November 09 2022, 19:56</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/145'>TR22-145 |  Revisiting Time-Space Tradeoffs for Function Inversion | 

	Alexander Golovnev, 

	Siyao Guo, 

	Spencer Peters, 

	Noah Stephens-Davidowitz</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study the black-box function inversion problem, which is the problem of finding $x \in [N]$ such that $f(x) = y$, given as input some challenge point $y$ in the image of a function $f : [N] \to [N]$, using $T$ oracle queries to $f$ and preprocessed advice $\sigma \in \{0,1\}^S$ depending on $f$. We prove a number of new results about this problem, as follows.

1. We show an algorithm that works for any $T$ and $S$ satisfying $T S^2 \cdot \max\{S,T\} = \widetilde{\Theta}(N^3)$. In the important setting when $S &lt; T$, this improves on the celebrated algorithm of Fiat and Naor [STOC, 1991], which requires $T S^3 \geq N^3$. E.g., Fiat and Naor&#39;s algorithm is only non-trivial for $S \gg N^{2/3}$, while our algorithm gives a non-trivial tradeoff for any $S \gg N^{1/2}$. (Our algorithm and analysis are quite simple. As a consequence of this, we also give a self-contained and simple proof of Fiat and Naor&#39;s original result, with certain optimizations left out for simplicity.)

2. We show a non-adaptive algorithm (i.e., an algorithm whose $i$th query $x_i$ is chosen based entirely on $\sigma$ and $y$, and not on the $f(x_1),\ldots, f(x_{i-1})$) that works for any $T$ and $S$ satisfying $S = \Theta(N \log(N/T))$ giving the first non-trivial non-adaptive algorithm for this problem. E.g., setting $T = N/ \mathrm{poly\,log}(N)$ gives $S = \Theta(N \log \log N)$. This answers a question due to Corrigan-Gibbs and Kogan [TCC, 2019], who asked whether it was possible for a non-adaptive algorithm to work with parameters $T$ and $S$ satisfying $T + S/\log N &lt; o(N)$. We also observe that our non-adaptive algorithm is what we call a guess-and-check algorithm, that is, it is non-adaptive and its final output is always one of the oracle queries $x_1,\ldots, x_T$. For guess-and-check algorithms, we prove a matching lower bound, therefore completely characterizing the achievable parameters $(S,T)$ for this natural class of algorithms. (Corrigan-Gibbs and Kogan showed that any such lower bound for arbitrary non-adaptive algorithms would imply new circuit lower bounds.) 

3. We show equivalence between function inversion and a natural decision version of the problem in both the worst case and the average case, and similarly for functions $f : [N] \to [M]$ with different ranges.


All of the above results are most naturally described in a model with shared randomness (i.e., random coins shared between the preprocessing algorithm and the online algorithm). However, as an additional contribution, we show (using a technique from communication complexity due to Newman [IPL, 1991]) how to generically convert any algorithm that uses shared randomness into one that does not.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study the black-box function inversion problem, which is the problem of finding $x \in [N]$ such that $f(x) = y$, given as input some challenge point $y$ in the image of a function $f : [N] \to [N]$, using $T$ oracle queries to $f$ and preprocessed advice $\sigma \in \{0,1\}^S$ depending on $f$. We prove a number of new results about this problem, as follows.

1. We show an algorithm that works for any $T$ and $S$ satisfying $T S^2 \cdot \max\{S,T\} = \widetilde{\Theta}(N^3)$. In the important setting when $S &lt; T$, this improves on the celebrated algorithm of Fiat and Naor [STOC, 1991], which requires $T S^3 \geq N^3$. E.g., Fiat and Naor&#39;s algorithm is only non-trivial for $S \gg N^{2/3}$, while our algorithm gives a non-trivial tradeoff for any $S \gg N^{1/2}$. (Our algorithm and analysis are quite simple. As a consequence of this, we also give a self-contained and simple proof of Fiat and Naor&#39;s original result, with certain optimizations left out for simplicity.)

2. We show a non-adaptive algorithm (i.e., an algorithm whose $i$th query $x_i$ is chosen based entirely on $\sigma$ and $y$, and not on the $f(x_1),\ldots, f(x_{i-1})$) that works for any $T$ and $S$ satisfying $S = \Theta(N \log(N/T))$ giving the first non-trivial non-adaptive algorithm for this problem. E.g., setting $T = N/ \mathrm{poly\,log}(N)$ gives $S = \Theta(N \log \log N)$. This answers a question due to Corrigan-Gibbs and Kogan [TCC, 2019], who asked whether it was possible for a non-adaptive algorithm to work with parameters $T$ and $S$ satisfying $T + S/\log N &lt; o(N)$. We also observe that our non-adaptive algorithm is what we call a guess-and-check algorithm, that is, it is non-adaptive and its final output is always one of the oracle queries $x_1,\ldots, x_T$. For guess-and-check algorithms, we prove a matching lower bound, therefore completely characterizing the achievable parameters $(S,T)$ for this natural class of algorithms. (Corrigan-Gibbs and Kogan showed that any such lower bound for arbitrary non-adaptive algorithms would imply new circuit lower bounds.) 

3. We show equivalence between function inversion and a natural decision version of the problem in both the worst case and the average case, and similarly for functions $f : [N] \to [M]$ with different ranges.


All of the above results are most naturally described in a model with shared randomness (i.e., random coins shared between the preprocessing algorithm and the online algorithm). However, as an additional contribution, we show (using a technique from communication complexity due to Newman [IPL, 1991]) how to generically convert any algorithm that uses shared randomness into one that does not.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T17:55:48Z">Wednesday, November 09 2022, 17:55</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04025'>Complexity of directed Steiner path packing problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuefang Sun</p><p>For a digraph $D=(V(D), A(D))$, and a set $S\subseteq V(D)$ with $r\in S$ and
$|S|\geq 2$, a directed $(S, r)$-Steiner path or, simply, an $(S, r)$-path is a
directed path $P$ started at $r$ with $S\subseteq V(P)$. Two $(S, r)$-paths are
said to be arc-disjoint if they have no common arc. Two arc-disjoint $(S,
r)$-paths are said to be internally disjoint if the set of common vertices of
them is exactly $S$. Let $\kappa^p_{S,r}(D)$ (resp. $\lambda^p_{S,r}(D)$) be
the maximum number of internally disjoint (resp. arc-disjoint) $(S, r)$-paths
in $D$.
</p>
<p>In this paper, we study the complexity for $\kappa^p_{S,r}(D)$ and
$\lambda^p_{S,r}(D)$. When both $k\geq 2, \ell\geq 1$ are fixed integers, we
show that the problem of deciding whether $\kappa^p_{S,r}(D) \geq \ell$ for an
Eulerian digraph $D$ is NP-complete, where $r\in S\subseteq V(D)$ and $|S|=k$.
However, when we consider the class of symmetric digraphs, the problem becomes
polynomial-time solvable. We also show that the problem of deciding whether
$\lambda^p_{S,r}(D) \geq \ell$ for a given digraph $D$ is NP-complete, where
$r\in S\subseteq V(D)$ and $|S|=k$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1">Yuefang Sun</a></p><p>For a digraph $D=(V(D), A(D))$, and a set $S\subseteq V(D)$ with $r\in S$ and
$|S|\geq 2$, a directed $(S, r)$-Steiner path or, simply, an $(S, r)$-path is a
directed path $P$ started at $r$ with $S\subseteq V(P)$. Two $(S, r)$-paths are
said to be arc-disjoint if they have no common arc. Two arc-disjoint $(S,
r)$-paths are said to be internally disjoint if the set of common vertices of
them is exactly $S$. Let $\kappa^p_{S,r}(D)$ (resp. $\lambda^p_{S,r}(D)$) be
the maximum number of internally disjoint (resp. arc-disjoint) $(S, r)$-paths
in $D$.
</p>
<p>In this paper, we study the complexity for $\kappa^p_{S,r}(D)$ and
$\lambda^p_{S,r}(D)$. When both $k\geq 2, \ell\geq 1$ are fixed integers, we
show that the problem of deciding whether $\kappa^p_{S,r}(D) \geq \ell$ for an
Eulerian digraph $D$ is NP-complete, where $r\in S\subseteq V(D)$ and $|S|=k$.
However, when we consider the class of symmetric digraphs, the problem becomes
polynomial-time solvable. We also show that the problem of deciding whether
$\lambda^p_{S,r}(D) \geq \ell$ for a given digraph $D$ is NP-complete, where
$r\in S\subseteq V(D)$ and $|S|=k$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04032'>Non-existence of a short algorithm for multiplication of $3\times3$ matrices with group $S_4\times S_3$, II</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vladimir P. Burichenko</p><p>It is proved that there is no an algorithm for multiplication of $3\times3$
matrices of multiplicative length $\leq23$ that is invariant under a certain
group isomorphic to $S_4\times S_3$. The proof makes use of description of the
orbits of this group on decomposable tensors in the tensor cube $(M_3({\mathbb
C}))^{\otimes3}$ which was obtained earlier.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Burichenko_V/0/1/0/all/0/1">Vladimir P. Burichenko</a></p><p>It is proved that there is no an algorithm for multiplication of $3\times3$
matrices of multiplicative length $\leq23$ that is invariant under a certain
group isomorphic to $S_4\times S_3$. The proof makes use of description of the
orbits of this group on decomposable tensors in the tensor cube $(M_3({\mathbb
C}))^{\otimes3}$ which was obtained earlier.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04420'>Computational indistinguishability and boson sampling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Georgios M. Nikolopoulos</p><p>We introduce a computational problem of distinguishing between the output of
an ideal coarse-grained boson sampler and the output of a true random number
generator, as a resource for cryptographic schemes, which are secure against
computationally unbounded adversaries. Moreover, we define a cryptographic
setting for the implementation of such schemes, including message encryption
and authentication, as well as entity authentication.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Nikolopoulos_G/0/1/0/all/0/1">Georgios M. Nikolopoulos</a></p><p>We introduce a computational problem of distinguishing between the output of
an ideal coarse-grained boson sampler and the output of a true random number
generator, as a resource for cryptographic schemes, which are secure against
computationally unbounded adversaries. Moreover, we define a cryptographic
setting for the implementation of such schemes, including message encryption
and authentication, as well as entity authentication.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03877'>The Need for Seed (in the abstract Tile Assembly Model)</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andrew Alseth, Matthew J. Patitz</p><p>In the abstract Tile Assembly Model (aTAM) square tiles self-assemble,
autonomously binding via glues on their edges, to form structures. Algorithmic
aTAM systems can be designed in which the patterns of tile attachments are
forced to follow the execution of targeted algorithms. Such systems have been
proven to be computationally universal as well as intrinsically universal (IU),
a notion borrowed and adapted from cellular automata showing that a single tile
set exists which is capable of simulating all aTAM systems (FOCS 2012). The
input to an algorithmic aTAM system can be provided in a variety of ways, with
a common method being via the ``seed'' assembly, which is a pre-formed assembly
from which all growth propagates. In this paper we present a series of results
which investigate the the trade-offs of using seeds consisting of a single
tile, versus those containing multiple tiles. We show that arbitrary systems
with multi-tile seeds cannot be converted to functionally equivalent systems
with single-tile seeds without using a scale factor &gt; 1. We prove tight bounds
on the scale factor required, and also present a construction which uses a
large scale factor but an optimal number of unique tile types. That
construction is then used to develop a construction that performs simultaneous
simulation of all aTAM systems in parallel, as well as to display a connection
to other tile-based self-assembly models via the notion of intrinsic
universality.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alseth_A/0/1/0/all/0/1">Andrew Alseth</a>, <a href="http://arxiv.org/find/cs/1/au:+Patitz_M/0/1/0/all/0/1">Matthew J. Patitz</a></p><p>In the abstract Tile Assembly Model (aTAM) square tiles self-assemble,
autonomously binding via glues on their edges, to form structures. Algorithmic
aTAM systems can be designed in which the patterns of tile attachments are
forced to follow the execution of targeted algorithms. Such systems have been
proven to be computationally universal as well as intrinsically universal (IU),
a notion borrowed and adapted from cellular automata showing that a single tile
set exists which is capable of simulating all aTAM systems (FOCS 2012). The
input to an algorithmic aTAM system can be provided in a variety of ways, with
a common method being via the ``seed'' assembly, which is a pre-formed assembly
from which all growth propagates. In this paper we present a series of results
which investigate the the trade-offs of using seeds consisting of a single
tile, versus those containing multiple tiles. We show that arbitrary systems
with multi-tile seeds cannot be converted to functionally equivalent systems
with single-tile seeds without using a scale factor &gt; 1. We prove tight bounds
on the scale factor required, and also present a construction which uses a
large scale factor but an optimal number of unique tile types. That
construction is then used to develop a construction that performs simultaneous
simulation of all aTAM systems in parallel, as well as to display a connection
to other tile-based self-assembly models via the notion of intrinsic
universality.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03891'>A deterministic near-linear time approximation scheme for geometric transportation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kyle Fox (1), Jiashuai Lu (1) ((1) The University of Texas at Dallas)</p><p>Given a set of points $P = (P^+ \sqcup P^-) \subset \mathbb{R}^d$ for some
constant $d$ and a supply function $\mu:P\to \mathbb{R}$ such that $\mu(p) &gt;
0~\forall p \in P^+$, $\mu(p) &lt; 0~\forall p \in P^-$, and $\sum_{p\in
P}{\mu(p)} = 0$, the geometric transportation problem asks one to find a
transportation map $\tau: P^+\times P^-\to \mathbb{R}_{\ge 0}$ such that
$\sum_{q\in P^-}{\tau(p, q)} = \mu(p)~\forall p \in P^+$, $\sum_{p\in
P^+}{\tau(p, q)} = -\mu(q)~ \forall q \in P^-$, and the weighted sum of
Euclidean distances for the pairs $\sum_{(p,q)\in P^+\times P^-}\tau(p, q)\cdot
||q-p||_2$ is minimized. We present the first deterministic algorithm that
computes, in near-linear time, a transportation map whose cost is within a $(1
+ \varepsilon)$ factor of optimal. More precisely, our algorithm runs in
$O(n\varepsilon^{-(d+2)}\log^5{n}\log{\log{n}})$ time for any constant
$\varepsilon &gt; 0$. While a randomized $n\varepsilon^{-O(d)}\log^{O(d)}{n}$ time
algorithm was discovered in the last few years, all previously known
deterministic $(1 + \varepsilon)$-approximation algorithms run in
$\Omega(n^{3/2})$ time. A similar situation existed for geometric bipartite
matching, the special case of geometric transportation where all supplies are
unit, until a deterministic $n\varepsilon^{-O(d)}\log^{O(d)}{n}$ time $(1 +
\varepsilon)$-approximation algorithm was presented at STOC 2022. Surprisingly,
our result is not only a generalization of the bipartite matching one to
arbitrary instances of geometric transportation, but it also reduces the
running time for all previously known $(1 + \varepsilon)$-approximation
algorithms, randomized or deterministic, even for geometric bipartite matching,
by removing the dependence on the dimension $d$ from the exponent in the
running time's polylog.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fox_K/0/1/0/all/0/1">Kyle Fox</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiashuai Lu</a> (1) ((1) The University of Texas at Dallas)</p><p>Given a set of points $P = (P^+ \sqcup P^-) \subset \mathbb{R}^d$ for some
constant $d$ and a supply function $\mu:P\to \mathbb{R}$ such that $\mu(p) &gt;
0~\forall p \in P^+$, $\mu(p) &lt; 0~\forall p \in P^-$, and $\sum_{p\in
P}{\mu(p)} = 0$, the geometric transportation problem asks one to find a
transportation map $\tau: P^+\times P^-\to \mathbb{R}_{\ge 0}$ such that
$\sum_{q\in P^-}{\tau(p, q)} = \mu(p)~\forall p \in P^+$, $\sum_{p\in
P^+}{\tau(p, q)} = -\mu(q)~ \forall q \in P^-$, and the weighted sum of
Euclidean distances for the pairs $\sum_{(p,q)\in P^+\times P^-}\tau(p, q)\cdot
||q-p||_2$ is minimized. We present the first deterministic algorithm that
computes, in near-linear time, a transportation map whose cost is within a $(1
+ \varepsilon)$ factor of optimal. More precisely, our algorithm runs in
$O(n\varepsilon^{-(d+2)}\log^5{n}\log{\log{n}})$ time for any constant
$\varepsilon &gt; 0$. While a randomized $n\varepsilon^{-O(d)}\log^{O(d)}{n}$ time
algorithm was discovered in the last few years, all previously known
deterministic $(1 + \varepsilon)$-approximation algorithms run in
$\Omega(n^{3/2})$ time. A similar situation existed for geometric bipartite
matching, the special case of geometric transportation where all supplies are
unit, until a deterministic $n\varepsilon^{-O(d)}\log^{O(d)}{n}$ time $(1 +
\varepsilon)$-approximation algorithm was presented at STOC 2022. Surprisingly,
our result is not only a generalization of the bipartite matching one to
arbitrary instances of geometric transportation, but it also reduces the
running time for all previously known $(1 + \varepsilon)$-approximation
algorithms, randomized or deterministic, even for geometric bipartite matching,
by removing the dependence on the dimension $d$ from the exponent in the
running time's polylog.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03859'>From approximate to exact integer programming</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Dadush, Friedrich Eisenbrand, Thomas Rothvoss</p><p>Approximate integer programming is the following: For a convex body $K
\subseteq \mathbb{R}^n$, either determine whether $K \cap \mathbb{Z}^n$ is
empty, or find an integer point in the convex body scaled by $2$ from its
center of gravity $c$. Approximate integer programming can be solved in time
$2^{O(n)}$ while the fastest known methods for exact integer programming run in
time $2^{O(n)} \cdot n^n$. So far, there are no efficient methods for integer
programming known that are based on approximate integer programming. Our main
contribution are two such methods, each yielding novel complexity results.
</p>
<p>First, we show that an integer point $x^* \in (K \cap \mathbb{Z}^n)$ can be
found in time $2^{O(n)}$, provided that the remainders of each component $x_i^*
\mod{\ell}$ for some arbitrarily fixed $\ell \geq 5(n+1)$ of $x^*$ are given.
The algorithm is based on a cutting-plane technique, iteratively halving the
volume of the feasible set. The cutting planes are determined via approximate
integer programming. Enumeration of the possible remainders gives a
$2^{O(n)}n^n$ algorithm for general integer programming. This matches the
current best bound of an algorithm by Dadush (2012) that is considerably more
involved. Our algorithm also relies on a new asymmetric approximate
Carath\'eodory theorem that might be of interest on its own.
</p>
<p>Our second method concerns integer programming problems in equation-standard
form $Ax = b, 0 \leq x \leq u, \, x \in \mathbb{Z}^n$ . Such a problem can be
reduced to the solution of $\prod_i O(\log u_i +1)$ approximate integer
programming problems. This implies, for example that knapsack or subset-sum
problems with polynomial variable range $0 \leq x_i \leq p(n)$ can be solved in
time $(\log n)^{O(n)}$. For these problems, the best running time so far was
$n^n \cdot 2^{O(n)}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Dadush_D/0/1/0/all/0/1">Daniel Dadush</a>, <a href="http://arxiv.org/find/math/1/au:+Eisenbrand_F/0/1/0/all/0/1">Friedrich Eisenbrand</a>, <a href="http://arxiv.org/find/math/1/au:+Rothvoss_T/0/1/0/all/0/1">Thomas Rothvoss</a></p><p>Approximate integer programming is the following: For a convex body $K
\subseteq \mathbb{R}^n$, either determine whether $K \cap \mathbb{Z}^n$ is
empty, or find an integer point in the convex body scaled by $2$ from its
center of gravity $c$. Approximate integer programming can be solved in time
$2^{O(n)}$ while the fastest known methods for exact integer programming run in
time $2^{O(n)} \cdot n^n$. So far, there are no efficient methods for integer
programming known that are based on approximate integer programming. Our main
contribution are two such methods, each yielding novel complexity results.
</p>
<p>First, we show that an integer point $x^* \in (K \cap \mathbb{Z}^n)$ can be
found in time $2^{O(n)}$, provided that the remainders of each component $x_i^*
\mod{\ell}$ for some arbitrarily fixed $\ell \geq 5(n+1)$ of $x^*$ are given.
The algorithm is based on a cutting-plane technique, iteratively halving the
volume of the feasible set. The cutting planes are determined via approximate
integer programming. Enumeration of the possible remainders gives a
$2^{O(n)}n^n$ algorithm for general integer programming. This matches the
current best bound of an algorithm by Dadush (2012) that is considerably more
involved. Our algorithm also relies on a new asymmetric approximate
Carath\'eodory theorem that might be of interest on its own.
</p>
<p>Our second method concerns integer programming problems in equation-standard
form $Ax = b, 0 \leq x \leq u, \, x \in \mathbb{Z}^n$ . Such a problem can be
reduced to the solution of $\prod_i O(\log u_i +1)$ approximate integer
programming problems. This implies, for example that knapsack or subset-sum
problems with polynomial variable range $0 \leq x_i \leq p(n)$ can be solved in
time $(\log n)^{O(n)}$. For these problems, the best running time so far was
$n^n \cdot 2^{O(n)}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03874'>Nearly optimal independence oracle algorithms for edge estimation in hypergraphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Holger Dell, John Lapinskas, Kitty Meeks</p><p>We study a query model of computation in which an n-vertex k-hypergraph can
be accessed only via its independence oracle or via its colourful independence
oracle, and each oracle query may incur a cost depending on the size of the
query. In each of these models, we obtain oracle algorithms to approximately
count the hypergraph's edges, and we unconditionally prove that no oracle
algorithm for this problem can have significantly smaller worst-case oracle
cost than our algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dell_H/0/1/0/all/0/1">Holger Dell</a>, <a href="http://arxiv.org/find/cs/1/au:+Lapinskas_J/0/1/0/all/0/1">John Lapinskas</a>, <a href="http://arxiv.org/find/cs/1/au:+Meeks_K/0/1/0/all/0/1">Kitty Meeks</a></p><p>We study a query model of computation in which an n-vertex k-hypergraph can
be accessed only via its independence oracle or via its colourful independence
oracle, and each oracle query may incur a cost depending on the size of the
query. In each of these models, we obtain oracle algorithms to approximately
count the hypergraph's edges, and we unconditionally prove that no oracle
algorithm for this problem can have significantly smaller worst-case oracle
cost than our algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03917'>On the amortized complexity of approximate counting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ishaq Aden-Ali, Yanjun Han, Jelani Nelson, Huacheng Yu</p><p>Naively storing a counter up to value $n$ would require $\Omega(\log n)$ bits
of memory. Nelson and Yu [NY22], following work of [Morris78], showed that if
the query answers need only be $(1+\epsilon)$-approximate with probability at
least $1 - \delta$, then $O(\log\log n + \log\log(1/\delta) +
\log(1/\epsilon))$ bits suffice, and in fact this bound is tight. Morris'
original motivation for studying this problem though, as well as modern
applications, require not only maintaining one counter, but rather $k$ counters
for $k$ large. This motivates the following question: for $k$ large, can $k$
counters be simultaneously maintained using asymptotically less memory than $k$
times the cost of an individual counter? That is to say, does this problem
benefit from an improved {\it amortized} space complexity bound?
</p>
<p>We answer this question in the negative. Specifically, we prove a lower bound
for nearly the full range of parameters showing that, in terms of memory usage,
there is no asymptotic benefit possible via amortization when storing multiple
counters. Our main proof utilizes a certain notion of "information cost"
recently introduced by Braverman, Garg and Woodruff in FOCS 2020 to prove lower
bounds for streaming algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aden_Ali_I/0/1/0/all/0/1">Ishaq Aden-Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yanjun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Nelson_J/0/1/0/all/0/1">Jelani Nelson</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Huacheng Yu</a></p><p>Naively storing a counter up to value $n$ would require $\Omega(\log n)$ bits
of memory. Nelson and Yu [NY22], following work of [Morris78], showed that if
the query answers need only be $(1+\epsilon)$-approximate with probability at
least $1 - \delta$, then $O(\log\log n + \log\log(1/\delta) +
\log(1/\epsilon))$ bits suffice, and in fact this bound is tight. Morris'
original motivation for studying this problem though, as well as modern
applications, require not only maintaining one counter, but rather $k$ counters
for $k$ large. This motivates the following question: for $k$ large, can $k$
counters be simultaneously maintained using asymptotically less memory than $k$
times the cost of an individual counter? That is to say, does this problem
benefit from an improved {\it amortized} space complexity bound?
</p>
<p>We answer this question in the negative. Specifically, we prove a lower bound
for nearly the full range of parameters showing that, in terms of memory usage,
there is no asymptotic benefit possible via amortization when storing multiple
counters. Our main proof utilizes a certain notion of "information cost"
recently introduced by Braverman, Garg and Woodruff in FOCS 2020 to prove lower
bounds for streaming algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04117'>Computing better approximate pure Nash equilibria in cut games via semidefinite programming</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ioannis Caragiannis, Zhile Jiang</p><p>Cut games are among the most fundamental strategic games in algorithmic game
theory. It is well-known that computing an exact pure Nash equilibrium in these
games is PLS-hard, so research has focused on computing approximate equilibria.
We present a polynomial-time algorithm that computes $2.7371$-approximate pure
Nash equilibria in cut games. This is the first improvement to the previously
best-known bound of $3$, due to the work of Bhalgat, Chakraborty, and Khanna
from EC 2010. Our algorithm is based on a general recipe proposed by
Caragiannis, Fanelli, Gravin, and Skopalik from FOCS 2011 and applied on
several potential games since then. The first novelty of our work is the
introduction of a phase that can identify subsets of players who can
simultaneously improve their utilities considerably. This is done via
semidefinite programming and randomized rounding. In particular, a negative
objective value to the semidefinite program guarantees that no such
considerable improvement is possible for a given set of players. Otherwise,
randomized rounding of the SDP solution is used to identify a set of players
who can simultaneously improve their strategies considerably and allows the
algorithm to make progress. The way rounding is performed is another important
novelty of our work. Here, we exploit an idea that dates back to a paper by
Feige and Goemans from 1995, but we take it to an extreme that has not been
analyzed before.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Caragiannis_I/0/1/0/all/0/1">Ioannis Caragiannis</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhile Jiang</a></p><p>Cut games are among the most fundamental strategic games in algorithmic game
theory. It is well-known that computing an exact pure Nash equilibrium in these
games is PLS-hard, so research has focused on computing approximate equilibria.
We present a polynomial-time algorithm that computes $2.7371$-approximate pure
Nash equilibria in cut games. This is the first improvement to the previously
best-known bound of $3$, due to the work of Bhalgat, Chakraborty, and Khanna
from EC 2010. Our algorithm is based on a general recipe proposed by
Caragiannis, Fanelli, Gravin, and Skopalik from FOCS 2011 and applied on
several potential games since then. The first novelty of our work is the
introduction of a phase that can identify subsets of players who can
simultaneously improve their utilities considerably. This is done via
semidefinite programming and randomized rounding. In particular, a negative
objective value to the semidefinite program guarantees that no such
considerable improvement is possible for a given set of players. Otherwise,
randomized rounding of the SDP solution is used to identify a set of players
who can simultaneously improve their strategies considerably and allows the
algorithm to make progress. The way rounding is performed is another important
novelty of our work. Here, we exploit an idea that dates back to a paper by
Feige and Goemans from 1995, but we take it to an extreme that has not been
analyzed before.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04278'>Tight Complexity Bounds for Counting Generalized Dominating Sets in Bounded-Treewidth Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jacob Focke, D&#xe1;niel Marx, Fionn Mc Inerney, Daniel Neuen, Govind S. Sankar, Philipp Schepper, Philip Wellnitz</p><p>We investigate how efficiently a well-studied family of domination-type
problems can be solved on bounded-treewidth graphs. For sets $\sigma,\rho$ of
non-negative integers, a $(\sigma,\rho)$-set of a graph $G$ is a set $S$ of
vertices such that $|N(u)\cap S|\in \sigma$ for every $u\in S$, and $|N(v)\cap
S|\in \rho$ for every $v\not\in S$. The problem of finding a
$(\sigma,\rho)$-set (of a certain size) unifies standard problems such as
Independent Set, Dominating Set, Independent Dominating Set, and many others.
</p>
<p>For all pairs of finite or cofinite sets $(\sigma,\rho)$, we determine (under
standard complexity assumptions) the best possible value $c_{\sigma,\rho}$ such
that there is an algorithm that counts $(\sigma,\rho)$-sets in time
$c_{\sigma,\rho}^{\sf tw}\cdot n^{O(1)}$ (if a tree decomposition of width
${\sf tw}$ is given in the input). For example, for the Exact Independent
Dominating Set problem (also known as Perfect Code) corresponding to
$\sigma=\{0\}$ and $\rho=\{1\}$, we improve the $3^{\sf tw}\cdot n^{O(1)}$
algorithm of [van Rooij, 2020] to $2^{\sf tw}\cdot n^{O(1)}$.
</p>
<p>Despite the unusually delicate definition of $c_{\sigma,\rho}$, we show that
our algorithms are most likely optimal, i.e., for any pair $(\sigma, \rho)$ of
finite or cofinite sets where the problem is non-trivial, and any
$\varepsilon&gt;0$, a $(c_{\sigma,\rho}-\varepsilon)^{\sf tw}\cdot
n^{O(1)}$-algorithm counting the number of $(\sigma,\rho)$-sets would violate
the Counting Strong Exponential-Time Hypothesis (#SETH). For finite sets
$\sigma$ and $\rho$, our lower bounds also extend to the decision version,
showing that our algorithms are optimal in this setting as well. In contrast,
for many cofinite sets, we show that further significant improvements for the
decision and optimization versions are possible using the technique of
representative sets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Focke_J/0/1/0/all/0/1">Jacob Focke</a>, <a href="http://arxiv.org/find/cs/1/au:+Marx_D/0/1/0/all/0/1">D&#xe1;niel Marx</a>, <a href="http://arxiv.org/find/cs/1/au:+Inerney_F/0/1/0/all/0/1">Fionn Mc Inerney</a>, <a href="http://arxiv.org/find/cs/1/au:+Neuen_D/0/1/0/all/0/1">Daniel Neuen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankar_G/0/1/0/all/0/1">Govind S. Sankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Schepper_P/0/1/0/all/0/1">Philipp Schepper</a>, <a href="http://arxiv.org/find/cs/1/au:+Wellnitz_P/0/1/0/all/0/1">Philip Wellnitz</a></p><p>We investigate how efficiently a well-studied family of domination-type
problems can be solved on bounded-treewidth graphs. For sets $\sigma,\rho$ of
non-negative integers, a $(\sigma,\rho)$-set of a graph $G$ is a set $S$ of
vertices such that $|N(u)\cap S|\in \sigma$ for every $u\in S$, and $|N(v)\cap
S|\in \rho$ for every $v\not\in S$. The problem of finding a
$(\sigma,\rho)$-set (of a certain size) unifies standard problems such as
Independent Set, Dominating Set, Independent Dominating Set, and many others.
</p>
<p>For all pairs of finite or cofinite sets $(\sigma,\rho)$, we determine (under
standard complexity assumptions) the best possible value $c_{\sigma,\rho}$ such
that there is an algorithm that counts $(\sigma,\rho)$-sets in time
$c_{\sigma,\rho}^{\sf tw}\cdot n^{O(1)}$ (if a tree decomposition of width
${\sf tw}$ is given in the input). For example, for the Exact Independent
Dominating Set problem (also known as Perfect Code) corresponding to
$\sigma=\{0\}$ and $\rho=\{1\}$, we improve the $3^{\sf tw}\cdot n^{O(1)}$
algorithm of [van Rooij, 2020] to $2^{\sf tw}\cdot n^{O(1)}$.
</p>
<p>Despite the unusually delicate definition of $c_{\sigma,\rho}$, we show that
our algorithms are most likely optimal, i.e., for any pair $(\sigma, \rho)$ of
finite or cofinite sets where the problem is non-trivial, and any
$\varepsilon&gt;0$, a $(c_{\sigma,\rho}-\varepsilon)^{\sf tw}\cdot
n^{O(1)}$-algorithm counting the number of $(\sigma,\rho)$-sets would violate
the Counting Strong Exponential-Time Hypothesis (#SETH). For finite sets
$\sigma$ and $\rho$, our lower bounds also extend to the decision version,
showing that our algorithms are optimal in this setting as well. In contrast,
for many cofinite sets, we show that further significant improvements for the
decision and optimization versions are possible using the technique of
representative sets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04385'>Why we couldn't prove SETH hardness of the Closest Vector Problem for even norms, and of the Subset Sum Problem!</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Divesh Aggarwal, Rajendra Kumar</p><p>Recent work [BGS17,ABGS19] has shown SETH hardness of some constant factor
approximate CVP in the $\ell_p$ norm for any $p$ that is not an even integer.
This result was shown by giving a Karp reduction from $k$-SAT on $n$ variables
to approximate CVP on a lattice of rank $n$. In this work, we show a barrier
towards proving a similar result for CVP in the $\ell_p$ norm where $p$ is an
even integer. We show that for any $c, c'&gt;0$, if for every $k &gt; 0$, there
exists an efficient reduction that maps a $k$-SAT instance on $n$ variables to
a $(1+exp(-n^c)))$-CVP instance for a lattice of rank at most $n^{c'}$ in the
Euclidean norm, then $\mathsf{coNP} \subset \mathsf{NP/Poly}$. We prove a
similar result for $(1+exp(-n^c)))$-CVP for all even norms under a mild
additional promise that the ratio of the distance of the target from the
lattice and the shortest non-zero vector in the lattice is bounded by
$exp(n^{O(1)})$.
</p>
<p>Furthermore, we show that for any $c,c' &gt; 0$, and any even integer $p$, if
for every $k &gt; 0$, there exists an efficient reduction that maps a $k$-SAT
instance on $n$ variables to a $(1+exp(-n^c)))$-$SVP_p$ instance for a lattice
of rank at most $n^{c'}$, then $\mathsf{coNP} \subset \mathsf{NP/Poly}$. The
result for SVP does not require any additional promise.
</p>
<p>While prior results have indicated that lattice problems in the $\ell_2$ norm
(Euclidean norm) are easier than lattice problems in other norms, this is the
first result that shows a separation between these problems.
</p>
<p>We achieve this by using a result by Dell and van Melkebeek [JACM, 2014] on
the impossibility of the existence of a reduction that compresses an arbitrary
$k$-SAT instance into a string of length $\mathcal{O}(n^{k-\epsilon})$ for any
$\epsilon&gt;0$. In addition to CVP, we also show that the same result holds for
the Subset-Sum problem using similar techniques.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_D/0/1/0/all/0/1">Divesh Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Rajendra Kumar</a></p><p>Recent work [BGS17,ABGS19] has shown SETH hardness of some constant factor
approximate CVP in the $\ell_p$ norm for any $p$ that is not an even integer.
This result was shown by giving a Karp reduction from $k$-SAT on $n$ variables
to approximate CVP on a lattice of rank $n$. In this work, we show a barrier
towards proving a similar result for CVP in the $\ell_p$ norm where $p$ is an
even integer. We show that for any $c, c'&gt;0$, if for every $k &gt; 0$, there
exists an efficient reduction that maps a $k$-SAT instance on $n$ variables to
a $(1+exp(-n^c)))$-CVP instance for a lattice of rank at most $n^{c'}$ in the
Euclidean norm, then $\mathsf{coNP} \subset \mathsf{NP/Poly}$. We prove a
similar result for $(1+exp(-n^c)))$-CVP for all even norms under a mild
additional promise that the ratio of the distance of the target from the
lattice and the shortest non-zero vector in the lattice is bounded by
$exp(n^{O(1)})$.
</p>
<p>Furthermore, we show that for any $c,c' &gt; 0$, and any even integer $p$, if
for every $k &gt; 0$, there exists an efficient reduction that maps a $k$-SAT
instance on $n$ variables to a $(1+exp(-n^c)))$-$SVP_p$ instance for a lattice
of rank at most $n^{c'}$, then $\mathsf{coNP} \subset \mathsf{NP/Poly}$. The
result for SVP does not require any additional promise.
</p>
<p>While prior results have indicated that lattice problems in the $\ell_2$ norm
(Euclidean norm) are easier than lattice problems in other norms, this is the
first result that shows a separation between these problems.
</p>
<p>We achieve this by using a result by Dell and van Melkebeek [JACM, 2014] on
the impossibility of the existence of a reduction that compresses an arbitrary
$k$-SAT instance into a string of length $\mathcal{O}(n^{k-\epsilon})$ for any
$\epsilon&gt;0$. In addition to CVP, we also show that the same result holds for
the Subset-Sum problem using similar techniques.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04439'>Sampling from convex sets with a cold start using multiscale decompositions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hariharan Narayanan, Amit Rajaraman, Piyush Srivastava</p><p>A standard approach to sample approximately uniformly from a convex body
$K\subseteq\mathbb{R}^n$ is to run a random walk within $K$. The requirement is
that from a suitable initial distribution, the distribution of the walk comes
close to the uniform distribution $\pi_K$ on $K$ after a number of steps
polynomial in $n$ and the aspect ratio $R/r$ (here, $K$ is assumed to contain a
ball of radius $r$ and to be contained in a ball of radius $R$).
</p>
<p>Proofs of rapid mixing of such walks often require the probability density
$\eta_0$ of the initial distribution with respect to $\pi_K$ to be at most
$\mathrm{poly}(n)$: this is called a "warm start". Achieving a warm start often
requires non-trivial pre-processing before starting the random walk. This
motivates proving rapid mixing from a "cold start", wherein $\eta_0$ can be as
high as $\exp(\mathrm{poly}(n))$. Unlike warm starts, a cold start is usually
trivial to achieve. However, a random walks need not mix rapidly from a cold
start: an example being the well-known "ball walk". On the other hand, Lov\'asz
and Vempala proved that the "hit-and-run" random walk mixes rapidly from a cold
start. For the related coordinate hit-and-run (CHR) walk, which has been found
to be promising in computational experiments, rapid mixing from a warm start
was proved only recently but the question of rapid mixing from a cold start
remained open.
</p>
<p>We construct a family of random walks inspired by classical decompositions of
subsets of $\mathbb{R}^n$ into countably many axis-aligned dyadic cubes. We
show that even with a cold start, the mixing times of these walks are bounded
by a polynomial in $n$ and the aspect ratio. Our main technical ingredient is
an isoperimetric inequality for $K$ for a metric that magnifies distances
between points close to the boundary of $K$. As a corollary, we show that the
CHR walk also mixes rapidly from a cold start.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Narayanan_H/0/1/0/all/0/1">Hariharan Narayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajaraman_A/0/1/0/all/0/1">Amit Rajaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_P/0/1/0/all/0/1">Piyush Srivastava</a></p><p>A standard approach to sample approximately uniformly from a convex body
$K\subseteq\mathbb{R}^n$ is to run a random walk within $K$. The requirement is
that from a suitable initial distribution, the distribution of the walk comes
close to the uniform distribution $\pi_K$ on $K$ after a number of steps
polynomial in $n$ and the aspect ratio $R/r$ (here, $K$ is assumed to contain a
ball of radius $r$ and to be contained in a ball of radius $R$).
</p>
<p>Proofs of rapid mixing of such walks often require the probability density
$\eta_0$ of the initial distribution with respect to $\pi_K$ to be at most
$\mathrm{poly}(n)$: this is called a "warm start". Achieving a warm start often
requires non-trivial pre-processing before starting the random walk. This
motivates proving rapid mixing from a "cold start", wherein $\eta_0$ can be as
high as $\exp(\mathrm{poly}(n))$. Unlike warm starts, a cold start is usually
trivial to achieve. However, a random walks need not mix rapidly from a cold
start: an example being the well-known "ball walk". On the other hand, Lov\'asz
and Vempala proved that the "hit-and-run" random walk mixes rapidly from a cold
start. For the related coordinate hit-and-run (CHR) walk, which has been found
to be promising in computational experiments, rapid mixing from a warm start
was proved only recently but the question of rapid mixing from a cold start
remained open.
</p>
<p>We construct a family of random walks inspired by classical decompositions of
subsets of $\mathbb{R}^n$ into countably many axis-aligned dyadic cubes. We
show that even with a cold start, the mixing times of these walks are bounded
by a polynomial in $n$ and the aspect ratio. Our main technical ingredient is
an isoperimetric inequality for $K$ for a metric that magnifies distances
between points close to the boundary of $K$. As a corollary, we show that the
CHR walk also mixes rapidly from a cold start.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03830'>Further Improvements on Approximating the Uniform Cost-Distance Steiner Tree Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Stephan Held, Yannik Kyle Dustin Spitzley</p><p>In this paper, we consider the Uniform Cost-Distance Steiner Tree Problem in
metric spaces, a generalization of the well-known Steiner tree problem.
Cost-distance Steiner trees minimize the sum of the total length and the
weighted path lengths from a dedicated root to the other terminals, which have
a weight to penalize the path length. They are applied when the tree is
intended for signal transmission, e.g. in chip design or telecommunication
networks, and the signal speed through the tree has to be considered besides
the total length. Constant factor approximation algorithms for the uniform
cost-distance Steiner tree problem have been known since the first mentioning
of the problem by Meyerson, Munagala, and Plotkin. Recently, the approximation
factor was improved from 2.87 to 2.39 by Khazraei and Held. We refine their
approach further and reduce the approximation factor down to 2.15.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Held_S/0/1/0/all/0/1">Stephan Held</a>, <a href="http://arxiv.org/find/cs/1/au:+Spitzley_Y/0/1/0/all/0/1">Yannik Kyle Dustin Spitzley</a></p><p>In this paper, we consider the Uniform Cost-Distance Steiner Tree Problem in
metric spaces, a generalization of the well-known Steiner tree problem.
Cost-distance Steiner trees minimize the sum of the total length and the
weighted path lengths from a dedicated root to the other terminals, which have
a weight to penalize the path length. They are applied when the tree is
intended for signal transmission, e.g. in chip design or telecommunication
networks, and the signal speed through the tree has to be considered besides
the total length. Constant factor approximation algorithms for the uniform
cost-distance Steiner tree problem have been known since the first mentioning
of the problem by Meyerson, Munagala, and Plotkin. Recently, the approximation
factor was improved from 2.87 to 2.39 by Khazraei and Held. We refine their
approach further and reduce the approximation factor down to 2.15.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03883'>Approximating Nash Social Welfare by Matching and Local Search</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jugal Garg, Edin Husi&#x107;, Wenzheng Li, L&#xe1;szl&#xf3; A. V&#xe9;gh, Jan Vondr&#xe1;k</p><p>For any $\varepsilon&gt;0$, we give a simple, deterministic
$(6+\varepsilon)$-approximation algorithm for the Nash social welfare (NSW)
problem under submodular valuations. The previous best approximation factor was
$380$ via a randomized algorithm. We also consider the asymmetric variant of
the problem, where the objective is to maximize the weighted geometric mean of
agents' valuations, and give an $(\omega + 2 +\varepsilon) e$-approximation if
the ratio between the largest weight and the average weight is at most
$\omega$.
</p>
<p>We also show that the $1/2$-EFX envy-freeness property can be attained
simultaneously with a constant-factor approximation. More precisely, we can
find an allocation in polynomial time which is both $1/2$-EFX and a
$(12+\varepsilon)$-approximation to the symmetric NSW problem under submodular
valuations. The previous best approximation factor under $1/2$-EFX was linear
in the number of agents.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Garg_J/0/1/0/all/0/1">Jugal Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Husic_E/0/1/0/all/0/1">Edin Husi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenzheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Vegh_L/0/1/0/all/0/1">L&#xe1;szl&#xf3; A. V&#xe9;gh</a>, <a href="http://arxiv.org/find/cs/1/au:+Vondrak_J/0/1/0/all/0/1">Jan Vondr&#xe1;k</a></p><p>For any $\varepsilon&gt;0$, we give a simple, deterministic
$(6+\varepsilon)$-approximation algorithm for the Nash social welfare (NSW)
problem under submodular valuations. The previous best approximation factor was
$380$ via a randomized algorithm. We also consider the asymmetric variant of
the problem, where the objective is to maximize the weighted geometric mean of
agents' valuations, and give an $(\omega + 2 +\varepsilon) e$-approximation if
the ratio between the largest weight and the average weight is at most
$\omega$.
</p>
<p>We also show that the $1/2$-EFX envy-freeness property can be attained
simultaneously with a constant-factor approximation. More precisely, we can
find an allocation in polynomial time which is both $1/2$-EFX and a
$(12+\varepsilon)$-approximation to the symmetric NSW problem under submodular
valuations. The previous best approximation factor under $1/2$-EFX was linear
in the number of agents.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03893'>Query Complexity of the Metric Steiner Tree Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yu Chen, Sanjeev Khanna, Zihan Tan</p><p>We study the query complexity of the metric Steiner Tree problem, where we
are given an $n \times n$ metric on a set $V$ of vertices along with a set $T
\subseteq V$ of $k$ terminals, and the goal is to find a tree of minimum cost
that contains all terminals in $T$. The query complexity for the related
minimum spanning tree (MST) problem is well-understood: for any fixed
$\varepsilon &gt; 0$, one can estimate the MST cost to within a
$(1+\varepsilon)$-factor using only $\tilde{O}(n)$ queries, and this is known
to be tight. This implies that a $(2 + \varepsilon)$-approximate estimate of
Steiner Tree cost can be obtained with $\tilde{O}(k)$ queries by simply
applying the MST cost estimation algorithm on the metric induced by the
terminals.
</p>
<p>Our first result shows that any (randomized) algorithm that estimates the
Steiner Tree cost to within a $(5/3 - \varepsilon)$-factor requires
$\Omega(n^2)$ queries, even if $k$ is a constant. This lower bound is in sharp
contrast to an upper bound of $O(nk)$ queries for computing a
$(5/3)$-approximate Steiner Tree, which follows from previous work by Du and
Zelikovsky.
</p>
<p>Our second main result, and the main technical contribution of this work, is
a sublinear query algorithm for estimating the Steiner Tree cost to within a
strictly better-than-$2$ factor, with query complexity $\tilde{O}(n^{12/7} +
n^{6/7}\cdot k)=\tilde{O}(n^{13/7})=o(n^2)$. We complement this result by
showing an $\tilde{\Omega}(n + k^{6/5})$ query lower bound for any algorithm
that estimates Steiner Tree cost to a strictly better than $2$ factor. Thus
$\tilde{\Omega}(n^{6/5})$ queries are needed to just beat $2$-approximation
when $k = \Omega(n)$; a sharp contrast to MST cost estimation where a
$(1+o(1))$-approximate estimate of cost is achievable with only $\tilde{O}(n)$
queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Khanna_S/0/1/0/all/0/1">Sanjeev Khanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zihan Tan</a></p><p>We study the query complexity of the metric Steiner Tree problem, where we
are given an $n \times n$ metric on a set $V$ of vertices along with a set $T
\subseteq V$ of $k$ terminals, and the goal is to find a tree of minimum cost
that contains all terminals in $T$. The query complexity for the related
minimum spanning tree (MST) problem is well-understood: for any fixed
$\varepsilon &gt; 0$, one can estimate the MST cost to within a
$(1+\varepsilon)$-factor using only $\tilde{O}(n)$ queries, and this is known
to be tight. This implies that a $(2 + \varepsilon)$-approximate estimate of
Steiner Tree cost can be obtained with $\tilde{O}(k)$ queries by simply
applying the MST cost estimation algorithm on the metric induced by the
terminals.
</p>
<p>Our first result shows that any (randomized) algorithm that estimates the
Steiner Tree cost to within a $(5/3 - \varepsilon)$-factor requires
$\Omega(n^2)$ queries, even if $k$ is a constant. This lower bound is in sharp
contrast to an upper bound of $O(nk)$ queries for computing a
$(5/3)$-approximate Steiner Tree, which follows from previous work by Du and
Zelikovsky.
</p>
<p>Our second main result, and the main technical contribution of this work, is
a sublinear query algorithm for estimating the Steiner Tree cost to within a
strictly better-than-$2$ factor, with query complexity $\tilde{O}(n^{12/7} +
n^{6/7}\cdot k)=\tilde{O}(n^{13/7})=o(n^2)$. We complement this result by
showing an $\tilde{\Omega}(n + k^{6/5})$ query lower bound for any algorithm
that estimates Steiner Tree cost to a strictly better than $2$ factor. Thus
$\tilde{\Omega}(n^{6/5})$ queries are needed to just beat $2$-approximation
when $k = \Omega(n)$; a sharp contrast to MST cost estimation where a
$(1+o(1))$-approximate estimate of cost is achievable with only $\tilde{O}(n)$
queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03916'>Streaming beyond sketching for Maximum Directed Cut</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Raghuvansh R. Saxena, Noah Singer, Madhu Sudan, Santhoshini Velusamy</p><p>We give an $\widetilde{O}(\sqrt{n})$-space single-pass $0.483$-approximation
streaming algorithm for estimating the maximum directed cut size
($\textsf{Max-DICUT}$) in a directed graph on $n$ vertices. This improves over
an $O(\log n)$-space $4/9 &lt; 0.45$ approximation algorithm due to Chou,
Golovnev, Velusamy (FOCS 2020), which was known to be optimal for
$o(\sqrt{n})$-space algorithms.
</p>
<p>$\textsf{Max-DICUT}$ is a special case of a constraint satisfaction problem
(CSP). In this broader context, our work gives the first CSP for which
algorithms with $\widetilde{O}(\sqrt{n})$ space can provably outperform
$o(\sqrt{n})$-space algorithms on general instances. Previously, this was shown
in the restricted case of bounded-degree graphs in a previous work of the
authors (SODA 2023). Prior to that work, the only algorithms for any CSP were
based on generalizations of the $O(\log n)$-space algorithm for
$\textsf{Max-DICUT}$, and were in particular so-called "sketching" algorithms.
In this work, we demonstrate that more sophisticated streaming algorithms can
outperform these algorithms even on general instances.
</p>
<p>Our algorithm constructs a "snapshot" of the graph and then applies a result
of Feige and Jozeph (Algorithmica, 2015) to approximately estimate the
$\textsf{Max-DICUT}$ value from this snapshot. Constructing this snapshot is
easy for bounded-degree graphs and the main contribution of our work is to
construct this snapshot in the general setting. This involves some delicate
sampling methods as well as a host of "continuity" results on the
$\textsf{Max-DICUT}$ behaviour in graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Saxena_R/0/1/0/all/0/1">Raghuvansh R. Saxena</a>, <a href="http://arxiv.org/find/cs/1/au:+Singer_N/0/1/0/all/0/1">Noah Singer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudan_M/0/1/0/all/0/1">Madhu Sudan</a>, <a href="http://arxiv.org/find/cs/1/au:+Velusamy_S/0/1/0/all/0/1">Santhoshini Velusamy</a></p><p>We give an $\widetilde{O}(\sqrt{n})$-space single-pass $0.483$-approximation
streaming algorithm for estimating the maximum directed cut size
($\textsf{Max-DICUT}$) in a directed graph on $n$ vertices. This improves over
an $O(\log n)$-space $4/9 &lt; 0.45$ approximation algorithm due to Chou,
Golovnev, Velusamy (FOCS 2020), which was known to be optimal for
$o(\sqrt{n})$-space algorithms.
</p>
<p>$\textsf{Max-DICUT}$ is a special case of a constraint satisfaction problem
(CSP). In this broader context, our work gives the first CSP for which
algorithms with $\widetilde{O}(\sqrt{n})$ space can provably outperform
$o(\sqrt{n})$-space algorithms on general instances. Previously, this was shown
in the restricted case of bounded-degree graphs in a previous work of the
authors (SODA 2023). Prior to that work, the only algorithms for any CSP were
based on generalizations of the $O(\log n)$-space algorithm for
$\textsf{Max-DICUT}$, and were in particular so-called "sketching" algorithms.
In this work, we demonstrate that more sophisticated streaming algorithms can
outperform these algorithms even on general instances.
</p>
<p>Our algorithm constructs a "snapshot" of the graph and then applies a result
of Feige and Jozeph (Algorithmica, 2015) to approximately estimate the
$\textsf{Max-DICUT}$ value from this snapshot. Constructing this snapshot is
easy for bounded-degree graphs and the main contribution of our work is to
construct this snapshot in the general setting. This involves some delicate
sampling methods as well as a host of "continuity" results on the
$\textsf{Max-DICUT}$ behaviour in graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03963'>Fast Algorithms for $\ell_p$-Regression</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Deeksha Adil, Rasmus Kyng, Richard Peng, Sushant Sachdeva</p><p>The $\ell_p$-norm regression problem is a classic problem in optimization
with wide ranging applications in machine learning and theoretical computer
science. The goal is to compute $x^{\star} =\arg\min_{Ax=b}\|x\|_p^p$, where
$x^{\star}\in \mathbb{R}^n, A\in \mathbb{R}^{d\times n},b \in \mathbb{R}^d$ and
$d\leq n$. Efficient high-accuracy algorithms for the problem have been
challenging both in theory and practice and the state of the art algorithms
require $poly(p)\cdot n^{\frac{1}{2}-\frac{1}{p}}$ linear system solves for
$p\geq 2$. In this paper, we provide new algorithms for $\ell_p$-regression
(and a more general formulation of the problem) that obtain a high-accuracy
solution in $O(p n^{\frac{(p-2)}{(3p-2)}})$ linear system solves. We further
propose a new inverse maintenance procedure that speeds-up our algorithm to
$\widetilde{O}(n^{\omega})$ total runtime, where $O(n^{\omega})$ denotes the
running time for multiplying $n \times n$ matrices. Additionally, we give the
first Iteratively Reweighted Least Squares (IRLS) algorithm that is guaranteed
to converge to an optimum in a few iterations. Our IRLS algorithm has shown
exceptional practical performance, beating the currently available
implementations in MATLAB/CVX by 10-50x.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Adil_D/0/1/0/all/0/1">Deeksha Adil</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyng_R/0/1/0/all/0/1">Rasmus Kyng</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1">Richard Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachdeva_S/0/1/0/all/0/1">Sushant Sachdeva</a></p><p>The $\ell_p$-norm regression problem is a classic problem in optimization
with wide ranging applications in machine learning and theoretical computer
science. The goal is to compute $x^{\star} =\arg\min_{Ax=b}\|x\|_p^p$, where
$x^{\star}\in \mathbb{R}^n, A\in \mathbb{R}^{d\times n},b \in \mathbb{R}^d$ and
$d\leq n$. Efficient high-accuracy algorithms for the problem have been
challenging both in theory and practice and the state of the art algorithms
require $poly(p)\cdot n^{\frac{1}{2}-\frac{1}{p}}$ linear system solves for
$p\geq 2$. In this paper, we provide new algorithms for $\ell_p$-regression
(and a more general formulation of the problem) that obtain a high-accuracy
solution in $O(p n^{\frac{(p-2)}{(3p-2)}})$ linear system solves. We further
propose a new inverse maintenance procedure that speeds-up our algorithm to
$\widetilde{O}(n^{\omega})$ total runtime, where $O(n^{\omega})$ denotes the
running time for multiplying $n \times n$ matrices. Additionally, we give the
first Iteratively Reweighted Least Squares (IRLS) algorithm that is guaranteed
to converge to an optimum in a few iterations. Our IRLS algorithm has shown
exceptional practical performance, beating the currently available
implementations in MATLAB/CVX by 10-50x.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03975'>Optimal Smoothed Analysis and Quantitative Universality for the Smallest Singular Value of Random Matrices</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haoyu Wang</p><p>The smallest singular value and condition number play important roles in
numerical linear algebra and the analysis of algorithms. In numerical analysis
with randomness, many previous works make Gaussian assumptions, which are not
general enough to reflect the arbitrariness of the input. To overcome this
drawback, we prove the first quantitative universality for the smallest
singular value and condition number of random matrices.
</p>
<p>Moreover, motivated by the study of smoothed analysis that random
perturbation makes deterministic matrices well-conditioned, we consider an
analog for random matrices. For a random matrix perturbed by independent
Gaussian noise, we show that this matrix quickly becomes approximately
Gaussian. In particular, we derive an optimal smoothed analysis for random
matrices in terms of a sharp Gaussian approximation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1">Haoyu Wang</a></p><p>The smallest singular value and condition number play important roles in
numerical linear algebra and the analysis of algorithms. In numerical analysis
with randomness, many previous works make Gaussian assumptions, which are not
general enough to reflect the arbitrariness of the input. To overcome this
drawback, we prove the first quantitative universality for the smallest
singular value and condition number of random matrices.
</p>
<p>Moreover, motivated by the study of smoothed analysis that random
perturbation makes deterministic matrices well-conditioned, we consider an
analog for random matrices. For a random matrix perturbed by independent
Gaussian noise, we show that this matrix quickly becomes approximately
Gaussian. In particular, we derive an optimal smoothed analysis for random
matrices in terms of a sharp Gaussian approximation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03995'>Computing palindromes on a trie in linear time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Takuya Mieno, Mitsuru Funakoshi, Shunsuke Inenaga</p><p>A trie $\mathcal{T}$ is a rooted tree such that each edge is labeled by a
single character from the alphabet, and the labels of out-going edges from the
same node are mutually distinct. Given a trie $\mathcal{T}$ with $n$ edges, we
show how to compute all distinct palindromes and all maximal palindromes on
$\mathcal{T}$ in $O(n)$ time, in the case of integer alphabets of size
polynomial in $n$.This improves the state-of-the-art $O(n \log h)$-time
algorithms by Funakoshi et al. [PCS 2019], where $h$ is the height of
$\mathcal{T}$. Using our new algorithms, the eertree with suffix links for a
given trie $\mathcal{T}$ can readily be obtained in $O(n)$ time. Further, our
trie-based $O(n)$-space data structure allows us to report all distinct
palindromes and maximal palindromes in a query string represented in the trie
$\mathcal{T}$, in output optimal time. This is an improvement over an existing
(na\"ive) solution that precomputes and stores all distinct palindromes and
maximal palindromes for each and every string in the trie $\mathcal{T}$
separately, using a total $O(n^2)$ preprocessing time and space, and reports
them in output optimal time upon query.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mieno_T/0/1/0/all/0/1">Takuya Mieno</a>, <a href="http://arxiv.org/find/cs/1/au:+Funakoshi_M/0/1/0/all/0/1">Mitsuru Funakoshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Inenaga_S/0/1/0/all/0/1">Shunsuke Inenaga</a></p><p>A trie $\mathcal{T}$ is a rooted tree such that each edge is labeled by a
single character from the alphabet, and the labels of out-going edges from the
same node are mutually distinct. Given a trie $\mathcal{T}$ with $n$ edges, we
show how to compute all distinct palindromes and all maximal palindromes on
$\mathcal{T}$ in $O(n)$ time, in the case of integer alphabets of size
polynomial in $n$.This improves the state-of-the-art $O(n \log h)$-time
algorithms by Funakoshi et al. [PCS 2019], where $h$ is the height of
$\mathcal{T}$. Using our new algorithms, the eertree with suffix links for a
given trie $\mathcal{T}$ can readily be obtained in $O(n)$ time. Further, our
trie-based $O(n)$-space data structure allows us to report all distinct
palindromes and maximal palindromes in a query string represented in the trie
$\mathcal{T}$, in output optimal time. This is an improvement over an existing
(na\"ive) solution that precomputes and stores all distinct palindromes and
maximal palindromes for each and every string in the trie $\mathcal{T}$
separately, using a total $O(n^2)$ preprocessing time and space, and reports
them in output optimal time upon query.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03997'>A Simple Algorithm for Online Decision Making</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rui Chen, Oktay Gunluk, Andrea Lodi, Guanyi Wang</p><p>Motivated by recent progress on online linear programming (OLP), we study the
online decision making problem (ODMP) as a natural generalization of OLP. In
ODMP, there exists a single decision maker who makes a series of decisions
spread out over a total of $T$ time stages. At each time stage, the decision
maker makes a decision based on information obtained up to that point without
seeing into the future. The task of the decision maker is to maximize the
accumulated reward while overall meeting some predetermined $m$-dimensional
long-term goal (linking) constraints. ODMP significantly broadens the modeling
framework of OLP by allowing more general feasible regions (for local and goal
constraints) potentially involving both discreteness and nonlinearity in each
local decision making problem.
</p>
<p>We propose a Fenchel dual-based online algorithm for ODMP. At each time
stage, the proposed algorithm requires solving a potentially nonconvex
optimization problem over the local feasible set and a convex optimization
problem over the goal set. Under the uniform random permutation model, we show
that our algorithm achieves $O(\sqrt{mT})$ constraint violation
deterministically in meeting the long-term goals, and $O(\sqrt{m\log
m}\sqrt{T})$ competitive difference in expected reward with respect to the
optimal offline decisions. We also extend our results to the grouped random
permutation model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Chen_R/0/1/0/all/0/1">Rui Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Gunluk_O/0/1/0/all/0/1">Oktay Gunluk</a>, <a href="http://arxiv.org/find/math/1/au:+Lodi_A/0/1/0/all/0/1">Andrea Lodi</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_G/0/1/0/all/0/1">Guanyi Wang</a></p><p>Motivated by recent progress on online linear programming (OLP), we study the
online decision making problem (ODMP) as a natural generalization of OLP. In
ODMP, there exists a single decision maker who makes a series of decisions
spread out over a total of $T$ time stages. At each time stage, the decision
maker makes a decision based on information obtained up to that point without
seeing into the future. The task of the decision maker is to maximize the
accumulated reward while overall meeting some predetermined $m$-dimensional
long-term goal (linking) constraints. ODMP significantly broadens the modeling
framework of OLP by allowing more general feasible regions (for local and goal
constraints) potentially involving both discreteness and nonlinearity in each
local decision making problem.
</p>
<p>We propose a Fenchel dual-based online algorithm for ODMP. At each time
stage, the proposed algorithm requires solving a potentially nonconvex
optimization problem over the local feasible set and a convex optimization
problem over the goal set. Under the uniform random permutation model, we show
that our algorithm achieves $O(\sqrt{mT})$ constraint violation
deterministically in meeting the long-term goals, and $O(\sqrt{m\log
m}\sqrt{T})$ competitive difference in expected reward with respect to the
optimal offline decisions. We also extend our results to the grouped random
permutation model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04024'>Comparing Two Counting Methods for Estimating the Probabilities of Strings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ayaka Takamoto, Mitsuo Yoshida, Kyoji Umemura</p><p>There are two methods for counting the number of occurrences of a string in
another large string. One is to count the number of places where the string is
found. The other is to determine how many pieces of string can be extracted
without overlapping. The difference between the two becomes apparent when the
string is part of a periodic pattern. This research reports that the difference
is significant in estimating the occurrence probability of a pattern.
</p>
<p>In this study, the strings used in the experiments are approximated from
time-series data. The task involves classifying strings by estimating the
probability or computing the information quantity. First, the frequencies of
all substrings of a string are computed. Each counting method may sometimes
produce different frequencies for an identical string. Second, the probability
of the most probable segmentation is selected. The probability of the string is
the product of all probabilities of substrings in the selected segmentation.
The classification results demonstrate that the difference in counting methods
is statistically significant, and that the method without overlapping is
better.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Takamoto_A/0/1/0/all/0/1">Ayaka Takamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshida_M/0/1/0/all/0/1">Mitsuo Yoshida</a>, <a href="http://arxiv.org/find/cs/1/au:+Umemura_K/0/1/0/all/0/1">Kyoji Umemura</a></p><p>There are two methods for counting the number of occurrences of a string in
another large string. One is to count the number of places where the string is
found. The other is to determine how many pieces of string can be extracted
without overlapping. The difference between the two becomes apparent when the
string is part of a periodic pattern. This research reports that the difference
is significant in estimating the occurrence probability of a pattern.
</p>
<p>In this study, the strings used in the experiments are approximated from
time-series data. The task involves classifying strings by estimating the
probability or computing the information quantity. First, the frequencies of
all substrings of a string are computed. Each counting method may sometimes
produce different frequencies for an identical string. Second, the probability
of the most probable segmentation is selected. The probability of the string is
the product of all probabilities of substrings in the selected segmentation.
The classification results demonstrate that the difference in counting methods
is statistically significant, and that the method without overlapping is
better.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04112'>Improved Pattern-Avoidance Bounds for Greedy BSTs via Matrix Decomposition</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Parinya Chalermsook, Manoj Gupta, Wanchote Jiamjitrak, Nidia Obscura Acosta, Akash Pareek, Sorrachai Yingchareonthawornchai</p><p>Greedy BST (or simply Greedy) is an online self-adjusting binary search tree
defined in the geometric view ([Lucas, 1988; Munro, 2000; Demaine, Harmon,
Iacono, Kane, Patrascu, SODA 2009). Along with Splay trees (Sleator, Tarjan
1985), Greedy is considered the most promising candidate for being dynamically
optimal, i.e., starting with any initial tree, their access costs on any
sequence is conjectured to be within $O(1)$ factor of the offline optimal.
However, in the past four decades, the question has remained elusive even for
highly restricted input.
</p>
<p>In this paper, we prove new bounds on the cost of Greedy in the ''pattern
avoidance'' regime. Our new results include:
</p>
<p>The (preorder) traversal conjecture for Greedy holds up to a factor of
$O(2^{\alpha(n)})$, improving upon the bound of $2^{\alpha(n)^{O(1)}}$ in
(Chalermsook et al., FOCS 2015). This is the best known bound obtained by any
online BSTs.
</p>
<p>We settle the postorder traversal conjecture for Greedy.
</p>
<p>The deque conjecture for Greedy holds up to a factor of $O(\alpha(n))$,
improving upon the bound $2^{O(\alpha(n))}$ in (Chalermsook, et al., WADS
2015).
</p>
<p>The split conjecture holds for Greedy up to a factor of $O(2^{\alpha(n)})$.
</p>
<p>Key to all these results is to partition (based on the input structures) the
execution log of Greedy into several simpler-to-analyze subsets for which
classical forbidden submatrix bounds can be leveraged. Finally, we show the
applicability of this technique to handle a class of increasingly complex
pattern-avoiding input sequences, called $k$-increasing sequences.
</p>
<p>As a bonus, we discover a new class of permutation matrices whose extremal
bounds are polynomially bounded. This gives a partial progress on an open
question by Jacob Fox (2013).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chalermsook_P/0/1/0/all/0/1">Parinya Chalermsook</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Manoj Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiamjitrak_W/0/1/0/all/0/1">Wanchote Jiamjitrak</a>, <a href="http://arxiv.org/find/cs/1/au:+Acosta_N/0/1/0/all/0/1">Nidia Obscura Acosta</a>, <a href="http://arxiv.org/find/cs/1/au:+Pareek_A/0/1/0/all/0/1">Akash Pareek</a>, <a href="http://arxiv.org/find/cs/1/au:+Yingchareonthawornchai_S/0/1/0/all/0/1">Sorrachai Yingchareonthawornchai</a></p><p>Greedy BST (or simply Greedy) is an online self-adjusting binary search tree
defined in the geometric view ([Lucas, 1988; Munro, 2000; Demaine, Harmon,
Iacono, Kane, Patrascu, SODA 2009). Along with Splay trees (Sleator, Tarjan
1985), Greedy is considered the most promising candidate for being dynamically
optimal, i.e., starting with any initial tree, their access costs on any
sequence is conjectured to be within $O(1)$ factor of the offline optimal.
However, in the past four decades, the question has remained elusive even for
highly restricted input.
</p>
<p>In this paper, we prove new bounds on the cost of Greedy in the ''pattern
avoidance'' regime. Our new results include:
</p>
<p>The (preorder) traversal conjecture for Greedy holds up to a factor of
$O(2^{\alpha(n)})$, improving upon the bound of $2^{\alpha(n)^{O(1)}}$ in
(Chalermsook et al., FOCS 2015). This is the best known bound obtained by any
online BSTs.
</p>
<p>We settle the postorder traversal conjecture for Greedy.
</p>
<p>The deque conjecture for Greedy holds up to a factor of $O(\alpha(n))$,
improving upon the bound $2^{O(\alpha(n))}$ in (Chalermsook, et al., WADS
2015).
</p>
<p>The split conjecture holds for Greedy up to a factor of $O(2^{\alpha(n)})$.
</p>
<p>Key to all these results is to partition (based on the input structures) the
execution log of Greedy into several simpler-to-analyze subsets for which
classical forbidden submatrix bounds can be leveraged. Finally, we show the
applicability of this technique to handle a class of increasingly complex
pattern-avoiding input sequences, called $k$-increasing sequences.
</p>
<p>As a bonus, we discover a new class of permutation matrices whose extremal
bounds are polynomially bounded. This gives a partial progress on an open
question by Jacob Fox (2013).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04145'>Prophet Inequality: Order selection beats random order</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Archit Bubna, Ashish Chiplunkar</p><p>In the prophet inequality problem, a gambler faces a sequence of items
arriving online with values drawn independently from known distributions. On
seeing an item, the gambler must choose whether to accept its value as her
reward and quit the game, or reject it and continue. The gambler's aim is to
maximize her expected reward relative to the expected maximum of the values of
all items. Since the seminal work of Krengel and Sucheston (1977,1978), a tight
bound of 1/2 has been known for this competitive ratio in the setting where the
items arrive in an adversarial order. However, the optimum ratio still remains
unknown in the order selection setting, where the gambler selects the arrival
order, as well as in prophet secretary, where the items arrive in a random
order. Moreover, it is not even known whether a separation exists between the
two settings.
</p>
<p>In this paper, we show that the power of order selection allows the gambler
to guarantee a strictly better competitive ratio than if the items arrive
randomly. For the order selection setting, we identify an instance for which
Peng and Tang's (FOCS'22) state-of-the-art algorithm performs no better than
their claimed competitive ratio of (approximately) 0.7251, thus illustrating
the need for an improved approach. We therefore extend their design and provide
a more general algorithm design framework which allows the use of a different
time-dependent threshold function for each item, as opposed to the common
threshold function employed by Peng and Tang's algorithm. We use this framework
to show that Peng and Tang's ratio can be beaten, by designing a
0.7258-competitive algorithm. For the random order setting, we improve upon
Correa, Saona and Ziliotto's (SODA'19) 0.732-hardness result to show a hardness
of 0.7254 for general algorithms, thus establishing a separation between the
order selection and random order settings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bubna_A/0/1/0/all/0/1">Archit Bubna</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiplunkar_A/0/1/0/all/0/1">Ashish Chiplunkar</a></p><p>In the prophet inequality problem, a gambler faces a sequence of items
arriving online with values drawn independently from known distributions. On
seeing an item, the gambler must choose whether to accept its value as her
reward and quit the game, or reject it and continue. The gambler's aim is to
maximize her expected reward relative to the expected maximum of the values of
all items. Since the seminal work of Krengel and Sucheston (1977,1978), a tight
bound of 1/2 has been known for this competitive ratio in the setting where the
items arrive in an adversarial order. However, the optimum ratio still remains
unknown in the order selection setting, where the gambler selects the arrival
order, as well as in prophet secretary, where the items arrive in a random
order. Moreover, it is not even known whether a separation exists between the
two settings.
</p>
<p>In this paper, we show that the power of order selection allows the gambler
to guarantee a strictly better competitive ratio than if the items arrive
randomly. For the order selection setting, we identify an instance for which
Peng and Tang's (FOCS'22) state-of-the-art algorithm performs no better than
their claimed competitive ratio of (approximately) 0.7251, thus illustrating
the need for an improved approach. We therefore extend their design and provide
a more general algorithm design framework which allows the use of a different
time-dependent threshold function for each item, as opposed to the common
threshold function employed by Peng and Tang's algorithm. We use this framework
to show that Peng and Tang's ratio can be beaten, by designing a
0.7258-competitive algorithm. For the random order setting, we improve upon
Correa, Saona and Ziliotto's (SODA'19) 0.732-hardness result to show a hardness
of 0.7254 for general algorithms, thus establishing a separation between the
order selection and random order settings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04217'>Deterministic Incremental APSP with Polylogarithmic Update Time and Stretch</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sebastian Forster, Yasamin Nazari, Maximilian Probst Gutenberg</p><p>We provide the first deterministic data structure that given a weighted
undirected graph undergoing edge insertions, processes each update with
polylogarithmic amortized update time and answers queries for the distance
between any pair of vertices in the current graph with a polylogarithmic
approximation in $O(\log \log n)$ time.
</p>
<p>Prior to this work, no data structure was known for partially dynamic graphs,
i.e., graphs undergoing either edge insertions or deletions, with less than
$n^{o(1)}$ update time except for dense graphs, even when allowing
randomization against oblivious adversaries or considering only single-source
distances.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Forster_S/0/1/0/all/0/1">Sebastian Forster</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazari_Y/0/1/0/all/0/1">Yasamin Nazari</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutenberg_M/0/1/0/all/0/1">Maximilian Probst Gutenberg</a></p><p>We provide the first deterministic data structure that given a weighted
undirected graph undergoing edge insertions, processes each update with
polylogarithmic amortized update time and answers queries for the distance
between any pair of vertices in the current graph with a polylogarithmic
approximation in $O(\log \log n)$ time.
</p>
<p>Prior to this work, no data structure was known for partially dynamic graphs,
i.e., graphs undergoing either edge insertions or deletions, with less than
$n^{o(1)}$ update time except for dense graphs, even when allowing
randomization against oblivious adversaries or considering only single-source
distances.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04338'>Extracting and Pre-Processing Event Logs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dirk Fahland</p><p>Event data is the basis for all process mining analysis. Most process mining
techniques assume their input to be an event log. However, event data is rarely
recorded in an event log format, but has to be extracted from raw data. Event
log extraction itself is an act of modeling as the analyst has to consciously
choose which features of the raw data are used for describing which behavior of
which entities. Being aware of these choices and subtle but important
differences in concepts such as trace, case, activity, event, table, and log is
crucial for mastering advanced process mining analyses.
</p>
<p>This text provides fundamental concepts and formalizations and discusses
design decisions in event log extraction from a raw event table and for event
log pre-processing. It is intended as study material for an advanced lecture in
a process mining course.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fahland_D/0/1/0/all/0/1">Dirk Fahland</a></p><p>Event data is the basis for all process mining analysis. Most process mining
techniques assume their input to be an event log. However, event data is rarely
recorded in an event log format, but has to be extracted from raw data. Event
log extraction itself is an act of modeling as the analyst has to consciously
choose which features of the raw data are used for describing which behavior of
which entities. Being aware of these choices and subtle but important
differences in concepts such as trace, case, activity, event, table, and log is
crucial for mastering advanced process mining analyses.
</p>
<p>This text provides fundamental concepts and formalizations and discusses
design decisions in event log extraction from a raw event table and for event
log pre-processing. It is intended as study material for an advanced lecture in
a process mining course.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04402'>Summation Problem Revisited -- More Robust Computation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vaclav Skala</p><p>Numerical data processing is a key task across different fields of computer
technology use. However, even simple summation of values is not precise due to
the floating point representation use. This paper presents a practical
algorithm for summation of values convenient for medium and large data sets.
The proposed algorithm is simple, easy to implement. Its computational
complexity is O(N) in the contrary of the Exact Sign Summation Algorithm (ESSA)
approach with O(N^2) run-time complexity. The proposed algorithm is especially
convenient for cases when exponent data differ significantly and many small
values are summed with higher values
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Skala_V/0/1/0/all/0/1">Vaclav Skala</a></p><p>Numerical data processing is a key task across different fields of computer
technology use. However, even simple summation of values is not precise due to
the floating point representation use. This paper presents a practical
algorithm for summation of values convenient for medium and large data sets.
The proposed algorithm is simple, easy to implement. Its computational
complexity is O(N) in the contrary of the Exact Sign Summation Algorithm (ESSA)
approach with O(N^2) run-time complexity. The proposed algorithm is especially
convenient for cases when exponent data differ significantly and many small
values are summed with higher values
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04444'>A Local Search-Based Approach for Set Covering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anupam Gupta, Euiwoong Lee, Jason Li</p><p>In the Set Cover problem, we are given a set system with each set having a
weight, and we want to find a collection of sets that cover the universe,
whilst having low total weight. There are several approaches known (based on
greedy approaches, relax-and-round, and dual-fitting) that achieve a $H_k
\approx \ln k + O(1)$ approximation for this problem, where the size of each
set is bounded by $k$. Moreover, getting a $\ln k - O(\ln \ln k)$ approximation
is hard.
</p>
<p>Where does the truth lie? Can we close the gap between the upper and lower
bounds? An improvement would be particularly interesting for small values of
$k$, which are often used in reductions between Set Cover and other
combinatorial optimization problems.
</p>
<p>We consider a non-oblivious local-search approach: to the best of our
knowledge this gives the first $H_k$-approximation for Set Cover using an
approach based on local-search. Our proof fits in one page, and gives a
integrality gap result as well. Refining our approach by considering larger
moves and an optimized potential function gives an $(H_k - \Omega(\log^2
k)/k)$-approximation, improving on the previous bound of $(H_k -
\Omega(1/k^8))$ (\emph{R.\ Hassin and A.\ Levin, SICOMP '05}) based on a
modified greedy algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Anupam Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1">Euiwoong Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jason Li</a></p><p>In the Set Cover problem, we are given a set system with each set having a
weight, and we want to find a collection of sets that cover the universe,
whilst having low total weight. There are several approaches known (based on
greedy approaches, relax-and-round, and dual-fitting) that achieve a $H_k
\approx \ln k + O(1)$ approximation for this problem, where the size of each
set is bounded by $k$. Moreover, getting a $\ln k - O(\ln \ln k)$ approximation
is hard.
</p>
<p>Where does the truth lie? Can we close the gap between the upper and lower
bounds? An improvement would be particularly interesting for small values of
$k$, which are often used in reductions between Set Cover and other
combinatorial optimization problems.
</p>
<p>We consider a non-oblivious local-search approach: to the best of our
knowledge this gives the first $H_k$-approximation for Set Cover using an
approach based on local-search. Our proof fits in one page, and gives a
integrality gap result as well. Refining our approach by considering larger
moves and an optimized potential function gives an $(H_k - \Omega(\log^2
k)/k)$-approximation, improving on the previous bound of $(H_k -
\Omega(1/k^8))$ (\emph{R.\ Hassin and A.\ Levin, SICOMP '05}) based on a
modified greedy algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04458'>Computing Square Colorings on Bounded-Treewidth and Planar Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Akanksha Agrawal, D&#xe1;niel Marx, Daniel Neuen, Jasper Slusallek</p><p>A square coloring of a graph $G$ is a coloring of the square $G^2$ of $G$,
that is, a coloring of the vertices of $G$ such that any two vertices that are
at distance at most $2$ in $G$ receive different colors. We investigate the
complexity of finding a square coloring with a given number of $q$ colors. We
show that the problem is polynomial-time solvable on graphs of bounded
treewidth by presenting an algorithm with running time $n^{2^{\operatorname{tw}
+ 4}+O(1)}$ for graphs of treewidth at most $\operatorname{tw}$. The somewhat
unusual exponent $2^{\operatorname{tw}}$ in the running time is essentially
optimal: we show that for any $\epsilon&gt;0$, there is no algorithm with running
time $f(\operatorname{tw})n^{(2-\epsilon)^{\operatorname{tw}}}$ unless the
Exponential-Time Hypothesis (ETH) fails.
</p>
<p>We also show that the square coloring problem is NP-hard on planar graphs for
any fixed number $q \ge 4$ of colors. Our main algorithmic result is showing
that the problem (when the number of colors $q$ is part of the input) can be
solved in subexponential time $2^{O(n^{2/3}\log n)}$ on planar graphs. The
result follows from the combination of two algorithms. If the number $q$ of
colors is small ($\le n^{1/3}$), then we can exploit a treewidth bound on the
square of the graph to solve the problem in time $2^{O(\sqrt{qn}\log n)}$. If
the number of colors is large ($\ge n^{1/3}$), then an algorithm based on
protrusion decompositions and building on our result for the bounded-treewidth
case solves the problem in time $2^{O(n\log n/q)}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Akanksha Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Marx_D/0/1/0/all/0/1">D&#xe1;niel Marx</a>, <a href="http://arxiv.org/find/cs/1/au:+Neuen_D/0/1/0/all/0/1">Daniel Neuen</a>, <a href="http://arxiv.org/find/cs/1/au:+Slusallek_J/0/1/0/all/0/1">Jasper Slusallek</a></p><p>A square coloring of a graph $G$ is a coloring of the square $G^2$ of $G$,
that is, a coloring of the vertices of $G$ such that any two vertices that are
at distance at most $2$ in $G$ receive different colors. We investigate the
complexity of finding a square coloring with a given number of $q$ colors. We
show that the problem is polynomial-time solvable on graphs of bounded
treewidth by presenting an algorithm with running time $n^{2^{\operatorname{tw}
+ 4}+O(1)}$ for graphs of treewidth at most $\operatorname{tw}$. The somewhat
unusual exponent $2^{\operatorname{tw}}$ in the running time is essentially
optimal: we show that for any $\epsilon&gt;0$, there is no algorithm with running
time $f(\operatorname{tw})n^{(2-\epsilon)^{\operatorname{tw}}}$ unless the
Exponential-Time Hypothesis (ETH) fails.
</p>
<p>We also show that the square coloring problem is NP-hard on planar graphs for
any fixed number $q \ge 4$ of colors. Our main algorithmic result is showing
that the problem (when the number of colors $q$ is part of the input) can be
solved in subexponential time $2^{O(n^{2/3}\log n)}$ on planar graphs. The
result follows from the combination of two algorithms. If the number $q$ of
colors is small ($\le n^{1/3}$), then we can exploit a treewidth bound on the
square of the graph to solve the problem in time $2^{O(\sqrt{qn}\log n)}$. If
the number of colors is large ($\ge n^{1/3}$), then an algorithm based on
protrusion decompositions and building on our result for the bounded-treewidth
case solves the problem in time $2^{O(n\log n/q)}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, November 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/08/full-time-tenure-track-assistant-professor-position-in-theoretical-computing-science-at-department-of-computing-science-university-of-alberta-apply-by-january-15-2023/'>Full-Time Tenure-Track Assistant Professor Position in Theoretical Computing Science at Department of Computing Science, University of Alberta (apply by January 15, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We are looking for a tenure-track Assistant Professor in Theoretical Computing Science. Areas of interest include: Data structures and Algorithms Streaming, Sketching, and Big Data Algorithms Computational Complexity Algorithmic Economy/Game theory and Mechanism Design Approximation Algorithms Online Algorithms Discrete Optimization Theoretical Aspects of Parallel and Distributed Computing Website: www.careers.ualberta.ca/Competition/A104848950/ Email: cs.ea@ualberta.ca
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We are looking for a tenure-track Assistant Professor in Theoretical Computing Science. Areas of interest include:</p>
<p>Data structures and Algorithms<br />
Streaming, Sketching, and Big Data Algorithms<br />
Computational Complexity<br />
Algorithmic Economy/Game theory and Mechanism Design<br />
Approximation Algorithms<br />
Online Algorithms<br />
Discrete Optimization<br />
Theoretical Aspects of Parallel and Distributed Computing</p>
<p>Website: <a href="https://www.careers.ualberta.ca/Competition/A104848950/">https://www.careers.ualberta.ca/Competition/A104848950/</a><br />
Email: cs.ea@ualberta.ca</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T22:26:24Z">Tuesday, November 08 2022, 22:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/08/faculty-at-george-mason-university-apply-by-december-2-2022/'>faculty at George Mason University (apply by December 2, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Department of Computer Science Multiple Open-Rank, Tenure-Track Faculty Positions The George Mason University Department of Computer Science, within the College of Engineering and Computing (CEC), invites applications for multiple tenure-track or tenured faculty positions beginning Fall 2023. Website: jobs.gmu.edu/postings/55808 Email: gordon@gmu.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Department of Computer Science<br />
Multiple Open-Rank, Tenure-Track Faculty Positions</p>
<p>The George Mason University Department of Computer Science, within the College of Engineering and Computing (CEC), invites applications for multiple tenure-track or tenured faculty positions beginning Fall 2023.</p>
<p>Website: <a href="https://jobs.gmu.edu/postings/55808">https://jobs.gmu.edu/postings/55808</a><br />
Email: gordon@gmu.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T19:44:58Z">Tuesday, November 08 2022, 19:44</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=6790'>The Caesar problem remains open</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          If I haven&#8217;t blogged until now about the midterm election, it&#8217;s because I find the state of the world too depressing. Go vote, obviously, if you&#8217;re eligible and haven&#8217;t yet. How many more chances will you have? While I&#8217;m (to put it mildly) neither especially courageous nor useful as an infantryman, I would&#8217;ve been honored [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>If I haven&#8217;t blogged until now about the midterm election, it&#8217;s because I find the state of the world too depressing.  Go vote, obviously, if you&#8217;re eligible and haven&#8217;t yet.  How many more chances will you have?</p>



<p>While I&#8217;m (to put it mildly) neither especially courageous nor useful as an infantryman, I would&#8217;ve been honored to give up my life for the Israel of Herzl and Ben-Gurion, <em>or</em> for the America of Franklin and Lincoln.  Alas, the Israel of Herzl and Ben-Gurion officially ceased to exist last week, with the election of a coalition some of whose members officially endorse discrimination against Israeli Arab citizens, effectively nullifying Ben-Gurion&#8217;s <a href="https://www.jewishvirtuallibrary.org/the-declaration-of-the-establishment-of-the-state-of-israel">founding declaration</a> that the new state would ensure &#8220;complete equality of social and political rights to all its inhabitants irrespective of religion, race, or sex.&#8221;  The America of Franklin and Lincoln might follow it into oblivion starting tonight, with the election of hundreds of candidates who acknowledge the legimitacy of elections only when their party wins.</p>



<p>The Roman Republic lasted until Caesar.  Weimar Germany lasted until Hitler (no, the destroyer of democracy isn&#8217;t always <em>literally Hitler</em>, but in that instance it was).  Hungary lasted until Orbán.  America lasted until Trump.  Israel lasted until Netanyahu.  After two millennia, democracy still hasn&#8217;t solved this problem, and it&#8217;s always basically the <em>same</em> problem: one individual, one populist authoritarian, who uses the machinery of democracy to end democracy.  How would one design a democracy to prevent this the next time around?</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T17:59:42Z">Tuesday, November 08 2022, 17:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/08/postdoc-at-ens-lyon-apply-by-january-4-2023/'>postdoc at ENS Lyon (apply by January 4, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The &#8220;Laboratoire d&#8217;Excellence&#8221; (LabEx) MILyon offers two postdoctoral positions of two years, with no teaching load, for the period 2023-2025. The application is open to all research areas of LabEx MILyon. For CS theory, Ecole Normale Superieure de Lyon is the relevant host institution. Website: milyon.universite-lyon.fr/postdoctoral-positions-2023-2025-130160.kjsp?RH=EN-MILYON-9659410765 Email: guillaume.hanrot@ens-lyon.fr
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The &#8220;Laboratoire d&#8217;Excellence&#8221; (LabEx) MILyon offers two postdoctoral positions of two years, with no teaching load, for the period 2023-2025. The application is open to<br />
all research areas of LabEx MILyon. For CS theory, Ecole Normale Superieure de Lyon is the relevant host institution.</p>
<p>Website: <a href="https://milyon.universite-lyon.fr/postdoctoral-positions-2023-2025-130160.kjsp?RH=EN-MILYON-9659410765">https://milyon.universite-lyon.fr/postdoctoral-positions-2023-2025-130160.kjsp?RH=EN-MILYON-9659410765</a><br />
Email: guillaume.hanrot@ens-lyon.fr</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T11:54:41Z">Tuesday, November 08 2022, 11:54</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.02694'>Geometry of Rounding</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jason Vander Woude, Peter Dixon, A. Pavan, Jamie Radcliffe, N. V. Vinodchandran</p><p>Rounding has proven to be a fundamental tool in theoretical computer science.
By observing that rounding and partitioning of $\mathbb{R}^d$ are equivalent,
we introduce the following natural partition problem which we call the {\em
secluded hypercube partition problem}: Given $k\in \mathbb{N}$ (ideally small)
and $\epsilon&gt;0$ (ideally large), is there a partition of $\mathbb{R}^d$ with
unit hypercubes such that for every point $p \in \mathbb{R}^d$, its closed
$\epsilon$-neighborhood (in the $\ell_{\infty}$ norm) intersects at most $k$
hypercubes?
</p>
<p>We undertake a comprehensive study of this partition problem. We prove that
for every $d\in \mathbb{N}$, there is an explicit (and efficiently computable)
hypercube partition of $\mathbb{R}^d$ with $k = d+1$ and $\epsilon =
\frac{1}{2d}$. We complement this construction by proving that the value of
$k=d+1$ is the best possible (for any $\epsilon$) for a broad class of
``reasonable'' partitions including hypercube partitions. We also investigate
the optimality of the parameter $\epsilon$ and prove that any partition in this
broad class that has $k=d+1$, must have $\epsilon\leq\frac{1}{2\sqrt{d}}$.
These bounds imply limitations of certain deterministic rounding schemes
existing in the literature. Furthermore, this general bound is based on the
currently known lower bounds for the dissection number of the cube, and
improvements to this bound will yield improvements to our bounds.
</p>
<p>While our work is motivated by the desire to understand rounding algorithms,
one of our main conceptual contributions is the introduction of the {\em
secluded hypercube partition problem}, which fits well with a long history of
investigations by mathematicians on various hypercube partitions/tilings of
Euclidean space.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Woude_J/0/1/0/all/0/1">Jason Vander Woude</a>, <a href="http://arxiv.org/find/cs/1/au:+Dixon_P/0/1/0/all/0/1">Peter Dixon</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavan_A/0/1/0/all/0/1">A. Pavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Radcliffe_J/0/1/0/all/0/1">Jamie Radcliffe</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinodchandran_N/0/1/0/all/0/1">N. V. Vinodchandran</a></p><p>Rounding has proven to be a fundamental tool in theoretical computer science.
By observing that rounding and partitioning of $\mathbb{R}^d$ are equivalent,
we introduce the following natural partition problem which we call the {\em
secluded hypercube partition problem}: Given $k\in \mathbb{N}$ (ideally small)
and $\epsilon&gt;0$ (ideally large), is there a partition of $\mathbb{R}^d$ with
unit hypercubes such that for every point $p \in \mathbb{R}^d$, its closed
$\epsilon$-neighborhood (in the $\ell_{\infty}$ norm) intersects at most $k$
hypercubes?
</p>
<p>We undertake a comprehensive study of this partition problem. We prove that
for every $d\in \mathbb{N}$, there is an explicit (and efficiently computable)
hypercube partition of $\mathbb{R}^d$ with $k = d+1$ and $\epsilon =
\frac{1}{2d}$. We complement this construction by proving that the value of
$k=d+1$ is the best possible (for any $\epsilon$) for a broad class of
``reasonable'' partitions including hypercube partitions. We also investigate
the optimality of the parameter $\epsilon$ and prove that any partition in this
broad class that has $k=d+1$, must have $\epsilon\leq\frac{1}{2\sqrt{d}}$.
These bounds imply limitations of certain deterministic rounding schemes
existing in the literature. Furthermore, this general bound is based on the
currently known lower bounds for the dissection number of the cube, and
improvements to this bound will yield improvements to our bounds.
</p>
<p>While our work is motivated by the desire to understand rounding algorithms,
one of our main conceptual contributions is the introduction of the {\em
secluded hypercube partition problem}, which fits well with a long history of
investigations by mathematicians on various hypercube partitions/tilings of
Euclidean space.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.02926'>Parity Games of Bounded Tree-Depth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Konrad Staniszewski (University of Warsaw, IDEAS NCBR Sp. z o.o.)</p><p>The exact complexity of solving parity games is a major open problem. Several
authors have searched for efficient algorithms over specific classes of graphs.
In particular, Obdr\v{z}\'{a}lek showed that for graphs of bounded tree-width
or clique-width, the problem is in $\mathrm{P}$, which was later improved by
Ganardi, who showed that it is even in $\mathrm{LOGCFL}$ (with an additional
assumption for clique-width case). Here we extend this line of research by
showing that for graphs of bounded tree-depth the problem of solving parity
games is in logspace uniform $\text{AC}^0$. We achieve this by first
considering a parameter that we obtain from a modification of clique-width,
which we call shallow clique-width. We subsequently provide a suitable
reduction.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Staniszewski_K/0/1/0/all/0/1">Konrad Staniszewski</a> (University of Warsaw, IDEAS NCBR Sp. z o.o.)</p><p>The exact complexity of solving parity games is a major open problem. Several
authors have searched for efficient algorithms over specific classes of graphs.
In particular, Obdr\v{z}\'{a}lek showed that for graphs of bounded tree-width
or clique-width, the problem is in $\mathrm{P}$, which was later improved by
Ganardi, who showed that it is even in $\mathrm{LOGCFL}$ (with an additional
assumption for clique-width case). Here we extend this line of research by
showing that for graphs of bounded tree-depth the problem of solving parity
games is in logspace uniform $\text{AC}^0$. We achieve this by first
considering a parameter that we obtain from a modification of clique-width,
which we call shallow clique-width. We subsequently provide a suitable
reduction.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03168'>Approximate Graph Colouring and the Hollow Shadow</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lorenzo Ciardo, Stanislav &#x17d;ivn&#xfd;</p><p>We show that approximate graph colouring is not solved by constantly many
levels of the lift-and-project hierarchy for the combined basic linear
programming and affine integer programming relaxation. The proof involves a
construction of tensors whose fixed-dimensional projections are equal up to
reflection and satisfy a sparsity condition, which may be of independent
interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ciardo_L/0/1/0/all/0/1">Lorenzo Ciardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zivny_S/0/1/0/all/0/1">Stanislav &#x17d;ivn&#xfd;</a></p><p>We show that approximate graph colouring is not solved by constantly many
levels of the lift-and-project hierarchy for the combined basic linear
programming and affine integer programming relaxation. The proof involves a
construction of tensors whose fixed-dimensional projections are equal up to
reflection and satisfy a sparsity condition, which may be of independent
interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.02835'>Approximation of Discs by Octagons on Pixel-Plane via Jaccards Proximity Criterion: Theoretical Approach and Experimental Results Analysis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Irakli Dochviri, Alexander Gamkrelidze, Revaz Kurdiani</p><p>In the present paper we study approximation of discs by octagons on the pixel
plane. To decide which octagon approximates better the given disc we use
Jaccard's distance. The table of Jaccard's distances (calculated by a software
created for these purposes) are presented at the end of the paper. The results
for proximity are given in the form of a graph. Some properties of considered
octagons are also studied
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dochviri_I/0/1/0/all/0/1">Irakli Dochviri</a>, <a href="http://arxiv.org/find/cs/1/au:+Gamkrelidze_A/0/1/0/all/0/1">Alexander Gamkrelidze</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurdiani_R/0/1/0/all/0/1">Revaz Kurdiani</a></p><p>In the present paper we study approximation of discs by octagons on the pixel
plane. To decide which octagon approximates better the given disc we use
Jaccard's distance. The table of Jaccard's distances (calculated by a software
created for these purposes) are presented at the end of the paper. The results
for proximity are given in the form of a graph. Some properties of considered
octagons are also studied
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.02905'>Density of triangulated ternary disc packings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thomas Fernique, Daria Pchelina</p><p>We consider ternary disc packings of the plane, i.e. the packings using discs
of three different radii. Packings in which each ''hole'' is bounded by three
pairwise tangent discs are called triangulated. There are 164 pairs $(r,s)$,
$1{&gt;}r{&gt;}s$, allowing triangulated packings by discs of radii 1, $r$ and $s$.
In this paper, we enhance existing methods of dealing with maximal-density
packings in order to find ternary triangulated packings which maximize the
density among all the packings with the same disc radii. We showed for 16 pairs
that the density is maximized by a triangulated ternary packing; for 15 other
pairs, we proved the density to be maximized by a triangulated packing using
only two sizes of discs; for 40 pairs, we found non-triangulated packings
strictly denser than any triangulated one; finally, we classified the remaining
cases where our methods are not applicable.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fernique_T/0/1/0/all/0/1">Thomas Fernique</a>, <a href="http://arxiv.org/find/cs/1/au:+Pchelina_D/0/1/0/all/0/1">Daria Pchelina</a></p><p>We consider ternary disc packings of the plane, i.e. the packings using discs
of three different radii. Packings in which each ''hole'' is bounded by three
pairwise tangent discs are called triangulated. There are 164 pairs $(r,s)$,
$1{&gt;}r{&gt;}s$, allowing triangulated packings by discs of radii 1, $r$ and $s$.
In this paper, we enhance existing methods of dealing with maximal-density
packings in order to find ternary triangulated packings which maximize the
density among all the packings with the same disc radii. We showed for 16 pairs
that the density is maximized by a triangulated ternary packing; for 15 other
pairs, we proved the density to be maximized by a triangulated packing using
only two sizes of discs; for 40 pairs, we found non-triangulated packings
strictly denser than any triangulated one; finally, we classified the remaining
cases where our methods are not applicable.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.02951'>Map matching queries on realistic input graphs under the Fr\'echet distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Joachim Gudmundsson, Martin P. Seybold, Sampson Wong</p><p>Map matching is a common preprocessing step for analysing vehicle
trajectories. In the theory community, the most popular approach for map
matching is to compute a path on the road network that is the most spatially
similar to the trajectory, where spatial similarity is measured using the
Fr\'echet distance. A shortcoming of existing map matching algorithms under the
Fr\'echet distance is that every time a trajectory is matched, the entire road
network needs to be reprocessed from scratch. An open problem is whether one
can preprocess the road network into a data structure, so that map matching
queries can be answered in sublinear time.
</p>
<p>In this paper, we investigate map matching queries under the Fr\'echet
distance. We provide a negative result for geometric planar graphs. We show
that, unless SETH fails, there is no data structure that can be constructed in
polynomial time that answers map matching queries in $O((pq)^{1-\delta})$ query
time for any $\delta &gt; 0$, where $p$ and $q$ are the complexities of the
geometric planar graph and the query trajectory, respectively. We provide a
positive result for realistic input graphs, which we regard as the main result
of this paper. We show that for $c$-packed graphs, one can construct a data
structure of $\tilde O(cp)$ size that can answer $(1+\varepsilon)$-approximate
map matching queries in $\tilde O(c^4 q \log^4 p)$ time, where $\tilde
O(\cdot)$ hides lower-order factors and dependence of $\varepsilon$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gudmundsson_J/0/1/0/all/0/1">Joachim Gudmundsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Seybold_M/0/1/0/all/0/1">Martin P. Seybold</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_S/0/1/0/all/0/1">Sampson Wong</a></p><p>Map matching is a common preprocessing step for analysing vehicle
trajectories. In the theory community, the most popular approach for map
matching is to compute a path on the road network that is the most spatially
similar to the trajectory, where spatial similarity is measured using the
Fr\'echet distance. A shortcoming of existing map matching algorithms under the
Fr\'echet distance is that every time a trajectory is matched, the entire road
network needs to be reprocessed from scratch. An open problem is whether one
can preprocess the road network into a data structure, so that map matching
queries can be answered in sublinear time.
</p>
<p>In this paper, we investigate map matching queries under the Fr\'echet
distance. We provide a negative result for geometric planar graphs. We show
that, unless SETH fails, there is no data structure that can be constructed in
polynomial time that answers map matching queries in $O((pq)^{1-\delta})$ query
time for any $\delta &gt; 0$, where $p$ and $q$ are the complexities of the
geometric planar graph and the query trajectory, respectively. We provide a
positive result for realistic input graphs, which we regard as the main result
of this paper. We show that for $c$-packed graphs, one can construct a data
structure of $\tilde O(cp)$ size that can answer $(1+\varepsilon)$-approximate
map matching queries in $\tilde O(c^4 q \log^4 p)$ time, where $\tilde
O(\cdot)$ hides lower-order factors and dependence of $\varepsilon$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.02713'>A degree 4 sum-of-squares lower bound for the clique number of the Paley graph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dmitriy Kunisky, Xifan Yu</p><p>We prove that the degree 4 sum-of-squares (SOS) relaxation of the clique
number of the Paley graph on a prime number $p$ of vertices has value at least
$\Omega(p^{1/3})$. This is in contrast to the widely believed conjecture that
the actual clique number of the Paley graph is $O(\mathrm{polylog}(p))$. Our
result may be viewed as a derandomization of that of Deshpande and Montanari
(2015), who showed the same lower bound (up to $\mathrm{polylog}(p)$ terms)
with high probability for the Erd\H{o}s-R\'{e}nyi random graph on $p$ vertices,
whose clique number is with high probability $O(\log(p))$. We also show that
our lower bound is optimal for the Feige-Krauthgamer construction of
pseudomoments, derandomizing an argument of Kelner. Finally, we present
numerical experiments indicating that the value of the degree 4 SOS relaxation
of the Paley graph may scale as $O(p^{1/2 - \epsilon})$ for some $\epsilon &gt;
0$, and give a matrix norm calculation indicating that the pseudocalibration
proof strategy for SOS lower bounds for random graphs will not immediately
transfer to the Paley graph. Taken together, our results suggest that degree 4
SOS may break the "$\sqrt{p}$ barrier" for upper bounds on the clique number of
Paley graphs, but prove that it can at best improve the exponent from $1/2$ to
$1/3$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kunisky_D/0/1/0/all/0/1">Dmitriy Kunisky</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xifan Yu</a></p><p>We prove that the degree 4 sum-of-squares (SOS) relaxation of the clique
number of the Paley graph on a prime number $p$ of vertices has value at least
$\Omega(p^{1/3})$. This is in contrast to the widely believed conjecture that
the actual clique number of the Paley graph is $O(\mathrm{polylog}(p))$. Our
result may be viewed as a derandomization of that of Deshpande and Montanari
(2015), who showed the same lower bound (up to $\mathrm{polylog}(p)$ terms)
with high probability for the Erd\H{o}s-R\'{e}nyi random graph on $p$ vertices,
whose clique number is with high probability $O(\log(p))$. We also show that
our lower bound is optimal for the Feige-Krauthgamer construction of
pseudomoments, derandomizing an argument of Kelner. Finally, we present
numerical experiments indicating that the value of the degree 4 SOS relaxation
of the Paley graph may scale as $O(p^{1/2 - \epsilon})$ for some $\epsilon &gt;
0$, and give a matrix norm calculation indicating that the pseudocalibration
proof strategy for SOS lower bounds for random graphs will not immediately
transfer to the Paley graph. Taken together, our results suggest that degree 4
SOS may break the "$\sqrt{p}$ barrier" for upper bounds on the clique number of
Paley graphs, but prove that it can at best improve the exponent from $1/2$ to
$1/3$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.02717'>A Framework for Approximation Schemes on Disk Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Lokshtanov, Fahad Panolan, Saket Saurabh, Jie Xue, Meirav Zehavi</p><p>We initiate a systematic study of approximation schemes for fundamental
optimization problems on disk graphs, a common generalization of both planar
graphs and unit-disk graphs. Our main contribution is a general framework for
designing efficient polynomial-time approximation schemes (EPTASes) for
vertex-deletion problems on disk graphs, which results in EPTASes for many
problems including Vertex Cover, Feedback Vertex Set, Small Cycle Hitting (in
particular, Triangle Hitting), $P_k$-Hitting for $k\in\{3,4,5\}$, Path
Deletion, Pathwidth $1$-Deletion, Component Order Connectivity, Bounded Degree
Deletion, Pseudoforest Deletion, Finite-Type Component Deletion, etc. All
EPTASes obtained using our framework are robust in the sense that they do not
require a realization of the input graph. To the best of our knowledge, prior
to this work, the only problems known to admit (E)PTASes on disk graphs are
Maximum Clique, Independent Set, Dominating set, and Vertex Cover, among which
the existing PTAS [Erlebach et al., SICOMP'05] and EPTAS [Leeuwen, SWAT'06] for
Vertex Cover require a realization of the input disk graph (while ours does
not).
</p>
<p>The core of our framework is a reduction for a broad class of (approximation)
vertex-deletion problems from (general) disk graphs to disk graphs of bounded
local radius, which is a new invariant of disk graphs introduced in this work.
Disk graphs of bounded local radius can be viewed as a mild generalization of
planar graphs, which preserves certain nice properties of planar graphs.
Specifically, we prove that disk graphs of bounded local radius admit the
Excluded Grid Minor property and have locally bounded treewidth. This allows
existing techniques for designing approximation schemes on planar graphs (e.g.,
bidimensionality and Baker's technique) to be directly applied to disk graphs
of bounded local radius.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lokshtanov_D/0/1/0/all/0/1">Daniel Lokshtanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Panolan_F/0/1/0/all/0/1">Fahad Panolan</a>, <a href="http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1">Saket Saurabh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jie Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zehavi_M/0/1/0/all/0/1">Meirav Zehavi</a></p><p>We initiate a systematic study of approximation schemes for fundamental
optimization problems on disk graphs, a common generalization of both planar
graphs and unit-disk graphs. Our main contribution is a general framework for
designing efficient polynomial-time approximation schemes (EPTASes) for
vertex-deletion problems on disk graphs, which results in EPTASes for many
problems including Vertex Cover, Feedback Vertex Set, Small Cycle Hitting (in
particular, Triangle Hitting), $P_k$-Hitting for $k\in\{3,4,5\}$, Path
Deletion, Pathwidth $1$-Deletion, Component Order Connectivity, Bounded Degree
Deletion, Pseudoforest Deletion, Finite-Type Component Deletion, etc. All
EPTASes obtained using our framework are robust in the sense that they do not
require a realization of the input graph. To the best of our knowledge, prior
to this work, the only problems known to admit (E)PTASes on disk graphs are
Maximum Clique, Independent Set, Dominating set, and Vertex Cover, among which
the existing PTAS [Erlebach et al., SICOMP'05] and EPTAS [Leeuwen, SWAT'06] for
Vertex Cover require a realization of the input disk graph (while ours does
not).
</p>
<p>The core of our framework is a reduction for a broad class of (approximation)
vertex-deletion problems from (general) disk graphs to disk graphs of bounded
local radius, which is a new invariant of disk graphs introduced in this work.
Disk graphs of bounded local radius can be viewed as a mild generalization of
planar graphs, which preserves certain nice properties of planar graphs.
Specifically, we prove that disk graphs of bounded local radius admit the
Excluded Grid Minor property and have locally bounded treewidth. This allows
existing techniques for designing approximation schemes on planar graphs (e.g.,
bidimensionality and Baker's technique) to be directly applied to disk graphs
of bounded local radius.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03161'>4D Range Reporting in the Pointer Machine Model in Almost-Optimal Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yakov Nekrich, Saladi Rahul</p><p>In the orthogonal range reporting problem we must pre-process a set $P$ of
multi-dimensional points, so that for any axis-parallel query rectangle $q$ all
points from $q\cap P$ can be reported efficiently. In this paper we study the
query complexity of multi-dimensional orthogonal range reporting in the pointer
machine model. We present a data structure that answers four-dimensional
orthogonal range reporting queries in almost-optimal time $O(\log n\log\log n +
k)$ and uses $O(n\log^4 n)$ space, where $n$ is the number of points in $P$ and
$k$ is the number of points in $q\cap P$ . This is the first data structure
with nearly-linear space usage that achieves almost-optimal query time in 4d.
This result can be immediately generalized to $d\ge 4$ dimensions: we show that
there is a data structure supporting $d$-dimensional range reporting queries in
time $O(\log^{d-3} n\log\log n+k)$ for any constant $d\ge 4$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nekrich_Y/0/1/0/all/0/1">Yakov Nekrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahul_S/0/1/0/all/0/1">Saladi Rahul</a></p><p>In the orthogonal range reporting problem we must pre-process a set $P$ of
multi-dimensional points, so that for any axis-parallel query rectangle $q$ all
points from $q\cap P$ can be reported efficiently. In this paper we study the
query complexity of multi-dimensional orthogonal range reporting in the pointer
machine model. We present a data structure that answers four-dimensional
orthogonal range reporting queries in almost-optimal time $O(\log n\log\log n +
k)$ and uses $O(n\log^4 n)$ space, where $n$ is the number of points in $P$ and
$k$ is the number of points in $q\cap P$ . This is the first data structure
with nearly-linear space usage that achieves almost-optimal query time in 4d.
This result can be immediately generalized to $d\ge 4$ dimensions: we show that
there is a data structure supporting $d$-dimensional range reporting queries in
time $O(\log^{d-3} n\log\log n+k)$ for any constant $d\ge 4$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.02681'>Deep Distance Sensitivity Oracles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davin Jeong, Chau Pham, Arnav Bhakta, Sarel Cohen, Maximilian Katzmann, Tobias Friedrich, Sang Chin</p><p>One of the most fundamental graph problems is finding a shortest path from a
source to a target node. While in its basic forms the problem has been studied
extensively and efficient algorithms are known, it becomes significantly harder
as soon as parts of the graph are susceptible to failure. Although one can
recompute a shortest replacement path after every outage, this is rather
inefficient both in time and/or storage. One way to overcome this problem is to
shift computational burden from the queries into a pre-processing step, where a
data structure is computed that allows for fast querying of replacement paths,
typically referred to as a Distance Sensitivity Oracle (DSO). While DSOs have
been extensively studied in the theoretical computer science community, to the
best of our knowledge this is the first work to construct DSOs using deep
learning techniques. We show how to use deep learning to utilize a
combinatorial structure of replacement paths. More specifically, we utilize the
combinatorial structure of replacement paths as a concatenation of shortest
paths and use deep learning to find the pivot nodes for stitching shortest
paths into replacement paths.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jeong_D/0/1/0/all/0/1">Davin Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_C/0/1/0/all/0/1">Chau Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhakta_A/0/1/0/all/0/1">Arnav Bhakta</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Sarel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Katzmann_M/0/1/0/all/0/1">Maximilian Katzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrich_T/0/1/0/all/0/1">Tobias Friedrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Chin_S/0/1/0/all/0/1">Sang Chin</a></p><p>One of the most fundamental graph problems is finding a shortest path from a
source to a target node. While in its basic forms the problem has been studied
extensively and efficient algorithms are known, it becomes significantly harder
as soon as parts of the graph are susceptible to failure. Although one can
recompute a shortest replacement path after every outage, this is rather
inefficient both in time and/or storage. One way to overcome this problem is to
shift computational burden from the queries into a pre-processing step, where a
data structure is computed that allows for fast querying of replacement paths,
typically referred to as a Distance Sensitivity Oracle (DSO). While DSOs have
been extensively studied in the theoretical computer science community, to the
best of our knowledge this is the first work to construct DSOs using deep
learning techniques. We show how to use deep learning to utilize a
combinatorial structure of replacement paths. More specifically, we utilize the
combinatorial structure of replacement paths as a concatenation of shortest
paths and use deep learning to find the pivot nodes for stitching shortest
paths into replacement paths.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.02703'>Online Learning and Bandits with Queried Hints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aditya Bhaskara, Sreenivas Gollapudi, Sungjin Im, Kostas Kollias, Kamesh Munagala</p><p>We consider the classic online learning and stochastic multi-armed bandit
(MAB) problems, when at each step, the online policy can probe and find out
which of a small number ($k$) of choices has better reward (or loss) before
making its choice. In this model, we derive algorithms whose regret bounds have
exponentially better dependence on the time horizon compared to the classic
regret bounds. In particular, we show that probing with $k=2$ suffices to
achieve time-independent regret bounds for online linear and convex
optimization. The same number of probes improve the regret bound of stochastic
MAB with independent arms from $O(\sqrt{nT})$ to $O(n^2 \log T)$, where $n$ is
the number of arms and $T$ is the horizon length. For stochastic MAB, we also
consider a stronger model where a probe reveals the reward values of the probed
arms, and show that in this case, $k=3$ probes suffice to achieve
parameter-independent constant regret, $O(n^2)$. Such regret bounds cannot be
achieved even with full feedback after the play, showcasing the power of
limited ``advice'' via probing before making the play. We also present
extensions to the setting where the hints can be imperfect, and to the case of
stochastic MAB where the rewards of the arms can be correlated.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhaskara_A/0/1/0/all/0/1">Aditya Bhaskara</a>, <a href="http://arxiv.org/find/cs/1/au:+Gollapudi_S/0/1/0/all/0/1">Sreenivas Gollapudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Im_S/0/1/0/all/0/1">Sungjin Im</a>, <a href="http://arxiv.org/find/cs/1/au:+Kollias_K/0/1/0/all/0/1">Kostas Kollias</a>, <a href="http://arxiv.org/find/cs/1/au:+Munagala_K/0/1/0/all/0/1">Kamesh Munagala</a></p><p>We consider the classic online learning and stochastic multi-armed bandit
(MAB) problems, when at each step, the online policy can probe and find out
which of a small number ($k$) of choices has better reward (or loss) before
making its choice. In this model, we derive algorithms whose regret bounds have
exponentially better dependence on the time horizon compared to the classic
regret bounds. In particular, we show that probing with $k=2$ suffices to
achieve time-independent regret bounds for online linear and convex
optimization. The same number of probes improve the regret bound of stochastic
MAB with independent arms from $O(\sqrt{nT})$ to $O(n^2 \log T)$, where $n$ is
the number of arms and $T$ is the horizon length. For stochastic MAB, we also
consider a stronger model where a probe reveals the reward values of the probed
arms, and show that in this case, $k=3$ probes suffice to achieve
parameter-independent constant regret, $O(n^2)$. Such regret bounds cannot be
achieved even with full feedback after the play, showcasing the power of
limited ``advice'' via probing before making the play. We also present
extensions to the setting where the hints can be imperfect, and to the case of
stochastic MAB where the rewards of the arms can be correlated.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.02755'>Extension of Simple Algorithms to the Matroid Secretary Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Simon Park</p><p>Whereas there are simple algorithms that are proven to be optimal for the
Classical and the Multiple Choice Secretary Problem, the Matroid Secretary
Problem is less thoroughly understood. This paper proposes the generalization
of some simple algorithms from the Classical and Multiple Choice versions on
the Matroid Secretary Problem. Out of two algorithms that make decisions based
on samples, like the Dynkin's algorithm, one is proven to be an instance of
Greedy Algorithm (Bahrani et al., 2022), while the other is not. A generalized
version of the Virtual Algorithm (Babaioff et al., 2018) obtains a constant
competitive ratio for the Hat Graph, the adversarial example for Greedy
Algorithms, but fails to do so when a slight modificiation is introduced to the
graph. We show that there is no algorithm with Strong Forbidden Sets (Soto et
al., 2021) of size 1 on all graphic matroids.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Simon Park</a></p><p>Whereas there are simple algorithms that are proven to be optimal for the
Classical and the Multiple Choice Secretary Problem, the Matroid Secretary
Problem is less thoroughly understood. This paper proposes the generalization
of some simple algorithms from the Classical and Multiple Choice versions on
the Matroid Secretary Problem. Out of two algorithms that make decisions based
on samples, like the Dynkin's algorithm, one is proven to be an instance of
Greedy Algorithm (Bahrani et al., 2022), while the other is not. A generalized
version of the Virtual Algorithm (Babaioff et al., 2018) obtains a constant
competitive ratio for the Hat Graph, the adversarial example for Greedy
Algorithms, but fails to do so when a slight modificiation is introduced to the
graph. We show that there is no algorithm with Strong Forbidden Sets (Soto et
al., 2021) of size 1 on all graphic matroids.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03077'>Online Nash Welfare Maximization Without Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhiyi Huang, Minming Li, Xinkai Shu, Tianze Wei</p><p>Nash welfare maximization is widely studied because it balances efficiency
and fairness in resource allocation problems. Banerjee, Gkatzelis, Gorokh, and
Jin (2022) recently introduced the model of online Nash welfare maximization
with predictions for $T$ divisible items and $N$ agents with additive
utilities. They gave online algorithms whose competitive ratios are
logarithmic. We initiate the study of online Nash welfare maximization
\emph{without predictions}, assuming either that the agents' utilities for
receiving all items differ by a bounded ratio, or that their utilities for the
Nash welfare maximizing allocation differ by a bounded ratio. We design online
algorithms whose competitive ratios only depend on the logarithms of the
aforementioned ratios of agents' utilities and the number of agents.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiyi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Minming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_X/0/1/0/all/0/1">Xinkai Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1">Tianze Wei</a></p><p>Nash welfare maximization is widely studied because it balances efficiency
and fairness in resource allocation problems. Banerjee, Gkatzelis, Gorokh, and
Jin (2022) recently introduced the model of online Nash welfare maximization
with predictions for $T$ divisible items and $N$ agents with additive
utilities. They gave online algorithms whose competitive ratios are
logarithmic. We initiate the study of online Nash welfare maximization
\emph{without predictions}, assuming either that the agents' utilities for
receiving all items differ by a bounded ratio, or that their utilities for the
Nash welfare maximizing allocation differ by a bounded ratio. We design online
algorithms whose competitive ratios only depend on the logarithms of the
aforementioned ratios of agents' utilities and the number of agents.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03146'>Balancing graph Voronoi diagrams with one more vertex</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guillaume Ducoffe</p><p>Let $G=(V,E)$ be a graph with unit-length edges and nonnegative costs
assigned to its vertices. Being given a list of pairwise different vertices
$S=(s_1,s_2,\ldots,s_p)$, the {\em prioritized Voronoi diagram} of $G$ with
respect to $S$ is the partition of $G$ in $p$ subsets $V_1,V_2,\ldots,V_p$ so
that, for every $i$ with $1 \leq i \leq p$, a vertex $v$ is in $V_i$ if and
only if $s_i$ is a closest vertex to $v$ in $S$ and there is no closest vertex
to $v$ in $S$ within the subset $\{s_1,s_2,\ldots,s_{i-1}\}$. For every $i$
with $1 \leq i \leq p$, the {\em load} of vertex $s_i$ equals the sum of the
costs of all vertices in $V_i$. The load of $S$ equals the maximum load of a
vertex in $S$. We study the problem of adding one more vertex $v$ at the end of
$S$ in order to minimize the load. This problem occurs in the context of
optimally locating a new service facility ({\it e.g.}, a school or a hospital)
while taking into account already existing facilities, and with the goal of
minimizing the maximum congestion at a site. There is a brute-force algorithm
for solving this problem in ${\cal O}(nm)$ time on $n$-vertex $m$-edge graphs.
We prove a matching time lower bound for the special case where $m=n^{1+o(1)}$
and $p=1$, assuming the so called Hitting Set Conjecture of Abboud et al. On
the positive side, we present simple linear-time algorithms for this problem on
cliques, paths and cycles, and almost linear-time algorithms for trees, proper
interval graphs and (assuming $p$ to be a constant) bounded-treewidth graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ducoffe_G/0/1/0/all/0/1">Guillaume Ducoffe</a></p><p>Let $G=(V,E)$ be a graph with unit-length edges and nonnegative costs
assigned to its vertices. Being given a list of pairwise different vertices
$S=(s_1,s_2,\ldots,s_p)$, the {\em prioritized Voronoi diagram} of $G$ with
respect to $S$ is the partition of $G$ in $p$ subsets $V_1,V_2,\ldots,V_p$ so
that, for every $i$ with $1 \leq i \leq p$, a vertex $v$ is in $V_i$ if and
only if $s_i$ is a closest vertex to $v$ in $S$ and there is no closest vertex
to $v$ in $S$ within the subset $\{s_1,s_2,\ldots,s_{i-1}\}$. For every $i$
with $1 \leq i \leq p$, the {\em load} of vertex $s_i$ equals the sum of the
costs of all vertices in $V_i$. The load of $S$ equals the maximum load of a
vertex in $S$. We study the problem of adding one more vertex $v$ at the end of
$S$ in order to minimize the load. This problem occurs in the context of
optimally locating a new service facility ({\it e.g.}, a school or a hospital)
while taking into account already existing facilities, and with the goal of
minimizing the maximum congestion at a site. There is a brute-force algorithm
for solving this problem in ${\cal O}(nm)$ time on $n$-vertex $m$-edge graphs.
We prove a matching time lower bound for the special case where $m=n^{1+o(1)}$
and $p=1$, assuming the so called Hitting Set Conjecture of Abboud et al. On
the positive side, we present simple linear-time algorithms for this problem on
cliques, paths and cycles, and almost linear-time algorithms for trees, proper
interval graphs and (assuming $p$ to be a constant) bounded-treewidth graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03206'>On Vertex Bisection Width of Random $d$-Regular Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Josep D&#xed;az, &#xd6;znur Ya&#x15f;ar Diner, Maria Serna, Oriol Serra</p><p>Vertex bisection is a graph partitioning problem in which the aim is to find
a partition into two equal parts that minimizes the number of vertices in one
partition set that have a neighbor in the other set. We are interested in
giving upper bounds on the vertex bisection width of random $d$-regular graphs
for constant values of $d$. Our approach is based on analyzing a greedy
algorithm by using the Differential Equations Method. In this way, we obtain
the first known upper bounds for the vertex bisection width in random regular
graphs. The results are compared with experimental ones and with lower bounds
obtained by Kolesnik and Wormald, (Lower Bounds for the Isoperimetric Numbers
of Random Regular Graphs, SIAM J. on Disc. Math. 28(1), 553-575, 2014).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Diaz_J/0/1/0/all/0/1">Josep D&#xed;az</a>, <a href="http://arxiv.org/find/cs/1/au:+Diner_O/0/1/0/all/0/1">&#xd6;znur Ya&#x15f;ar Diner</a>, <a href="http://arxiv.org/find/cs/1/au:+Serna_M/0/1/0/all/0/1">Maria Serna</a>, <a href="http://arxiv.org/find/cs/1/au:+Serra_O/0/1/0/all/0/1">Oriol Serra</a></p><p>Vertex bisection is a graph partitioning problem in which the aim is to find
a partition into two equal parts that minimizes the number of vertices in one
partition set that have a neighbor in the other set. We are interested in
giving upper bounds on the vertex bisection width of random $d$-regular graphs
for constant values of $d$. Our approach is based on analyzing a greedy
algorithm by using the Differential Equations Method. In this way, we obtain
the first known upper bounds for the vertex bisection width in random regular
graphs. The results are compared with experimental ones and with lower bounds
obtained by Kolesnik and Wormald, (Lower Bounds for the Isoperimetric Numbers
of Random Regular Graphs, SIAM J. on Disc. Math. 28(1), 553-575, 2014).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T01:30:00Z">Tuesday, November 08 2022, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
