<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel='stylesheet' type='text/css' href='css/font-awesome.css'>
  <link rel='stylesheet' type='text/css' href='css/blank.css'>
</head>
<body>
  <div id='navwrap'>
    <div id='nav'>
      <p>
        Last Update
      </p>
      <p class='small'>
        
          <time class='timeago' datetime="2022-08-17T15:46:48Z">just now</time>
        
      </p>

      <p>Feeds</p>
      <ul class='subscriptions small' >
      
        <li>
          <a href='http://arxiv.org/rss/cs.CC'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.CG'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.DS'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
          
        </li>
      
        <li>
          <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
          
        </li>
      
        <li>
          <a href='https://adamsheffer.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
          
        </li>
      
        <li>
          <a href='https://adamdsmith.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
          
        </li>
      
        <li>
          <a href='https://polylogblog.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
          
        </li>
      
        <li>
          <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
          
        </li>
      
        <li>
          <a href='http://www.argmin.net/feed.xml'><img src='i/feed.png'></a>
          <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
          
        </li>
      
        <li>
          <a href='http://bit-player.org/feed/atom/'><img src='i/feed.png'></a>
          <a href='http://bit-player.org'>bit-player</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-jobs.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-jobs.org'>CCI: jobs</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-events.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-events.org'>CS Theory Events</a>
          
        </li>
      
        <li>
          <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='https://11011110.github.io/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='https://11011110.github.io/blog/'>David Eppstein</a>
          
        </li>
      
        <li>
          <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='i/feed.png'></a>
          <a href='https://daveagp.wordpress.com'>David Pritchard</a>
          
        </li>
      
        <li>
          <a href='https://decentdescent.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://decentdescent.org/'>Decent Descent</a>
          
        </li>
      
        <li>
          <a href='https://decentralizedthoughts.github.io/feed'><img src='i/feed.png'></a>
          <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
          
        </li>
      
        <li>
          <a href='https://differentialprivacy.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
          
        </li>
      
        <li>
          <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='i/feed.png'></a>
          <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
          
        </li>
      
        <li>
          <a href='https://emanueleviola.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
          
        </li>
      
        <li>
          <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='i/feed.png'></a>
          <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
          
        </li>
      
        <li>
          <a href='https://dstheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
          
        </li>
      
        <li>
          <a href='https://francisbach.com/feed/'><img src='i/feed.png'></a>
          <a href='https://francisbach.com'>Francis Bach</a>
          
        </li>
      
        <li>
          <a href='https://gilkalai.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
          
        </li>
      
        <li>
          <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
          
        </li>
      
        <li>
          <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='i/feed.png'></a>
          <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
          
        </li>
      
        <li>
          <a href='https://gradientscience.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://gradientscience.org/'>Gradient Science</a>
          
        </li>
      
        <li>
          <a href='http://grigory.us/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
          
        </li>
      
        <li>
          <a href='https://tcsmath.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
          
        </li>
      
        <li>
          <a href='https://kamathematics.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
          
        </li>
      
        <li>
          <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
          
        </li>
      
        <li>
          <a href='https://lucatrevisan.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
          
        </li>
      
        <li>
          <a href='https://mittheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
          
        </li>
      
        <li>
          <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
          
        </li>
      
        <li>
          <a href='http://blog.mrtz.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
          
        </li>
      
        <li>
          <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
          
        </li>
      
        <li>
          <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
          
        </li>
      
        <li>
          <a href='http://www.solipsistslog.com/feed/'><img src='i/feed.png'></a>
          <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
          
        </li>
      
        <li>
          <a href='http://www.offconvex.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://offconvex.github.io/'>Off the Convex Path</a>
          
        </li>
      
        <li>
          <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
          
        </li>
      
        <li>
          <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
          
        </li>
      
        <li>
          <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='i/feed.png'></a>
          <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
          
        </li>
      
        <li>
          <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
          
        </li>
      
        <li>
          <a href='https://scottaaronson.blog/?feed=atom'><img src='i/feed.png'></a>
          <a href='https://scottaaronson.blog'>Scott Aaronson</a>
          
        </li>
      
        <li>
          <a href='https://blog.simons.berkeley.edu/feed/'><img src='i/feed.png'></a>
          <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
          
        </li>
      
        <li>
          <a href='https://tcsplus.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
          
        </li>
      
        <li>
          <a href='https://toc4fairness.org/feed/'><img src='i/feed.png'></a>
          <a href='https://toc4fairness.org'>TOC for Fairness</a>
          
        </li>
      
        <li>
          <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='i/feed.png'></a>
          <a href='http://blog.geomblog.org/'>The Geomblog</a>
          
        </li>
      
        <li>
          <a href='https://www.let-all.com/blog/feed/'><img src='i/feed.png'></a>
          <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
          
        </li>
      
        <li>
          <a href='https://theorydish.blog/feed/'><img src='i/feed.png'></a>
          <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
          
        </li>
      
        <li>
          <a href='https://thmatters.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://thmatters.wordpress.com'>Theory Matters</a>
          
        </li>
      
        <li>
          <a href='https://mycqstate.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
          
        </li>
      
        <li>
          <a href='https://agtb.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
          
        </li>
      
        <li>
          <a href='https://windowsontheory.org/feed/'><img src='i/feed.png'></a>
          <a href='https://windowsontheory.org'>Windows on Theory</a>
          
        </li>
      
      </ul>

      <p class='small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
      <p class='small'>Subscribe to the <a href="atom.xml">Atom feed</a> or <a href="rss20.xml">RSS feed</a> to stay up to date.</p>
      <p class='small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
      <p class='small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
    </div>
  </div>

  <div id='opts'>
    <div style='width: 100%; text-align: right;'>
    <img src='i/view-headlines.png' id='show-headlines' title='Show Headlines Only' width='24' height='24'>
    <img src='i/view-snippets.png' id='show-snippets' title='Show Snippets' width='24' height='24'>
    <img src='i/view-standard.png' id='show-fulltext' title='Show Full Text' width='24' height='24'>
    </div>
  </div>

  <h1>
    Theory of Computing Report
  </h1>

  <div id="articles">
    
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Wednesday, August 17
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://eccc.weizmann.ac.il/report/2022/115'>TR22-115 |  Polynomial Identity Testing via Evaluation of Rational Functions | 

	Dieter van Melkebeek, 

	Andrew Morgan</a>
        </h3>
        <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We introduce a hitting set generator for Polynomial Identity Testing
based on evaluations of low-degree univariate rational functions at
abscissas associated with the variables. Despite the univariate
nature, we establish an equivalence up to rescaling with a generator
introduced by Shpilka and Volkovich, which has a similar structure but
uses multivariate polynomials in the abscissas. 

We study t
        
        </div>

        <div class='item-content item-summary'>
        
          
          We introduce a hitting set generator for Polynomial Identity Testing
based on evaluations of low-degree univariate rational functions at
abscissas associated with the variables. Despite the univariate
nature, we establish an equivalence up to rescaling with a generator
introduced by Shpilka and Volkovich, which has a similar structure but
uses multivariate polynomials in the abscissas. 

We study the power of the generator by characterizing its vanishing
ideal, i.e., the set of polynomials that it fails to hit. Capitalizing
on the univariate nature, we develop a small collection of polynomials
that jointly produce the vanishing ideal. As corollaries, we obtain
tight bounds on the minimum degree, sparseness, and partition class
size of set-multilinearity in the vanishing ideal. Inspired by an
alternating algebra representation, we develop a structured
deterministic membership test for the vanishing ideal. As a proof of
concept, we rederive known derandomization results based on the
generator by Shpilka and Volkovich and present a new application for
read-once oblivious algebraic branching programs.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T14:04:37Z">2 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://decentralizedthoughts.github.io/2022-08-17-secret-sharing-with-crash/'>Polynomial Secret Sharing with crash failures</a>
        </h3>
        <p class='item-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We continue our series on polynomial secret sharing. In the previous post of this series we discussed secret sharing with a passive adversary. In this post we assume crash failures and in later posts we will extend to malicious failures. As before, we must assume parties have private channels: the...
        
        </div>

        <div class='item-content item-summary'>
        
          
          We continue our series on polynomial secret sharing. In the previous post of this series we discussed secret sharing with a passive adversary. In this post we assume crash failures and in later posts we will extend to malicious failures. As before, we must assume parties have private channels: the...
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T12:00:00Z">4 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://cstheory-jobs.org/2022/08/17/professorships-in-machine-learning-including-theory-at-university-of-copenhagen-apply-by-september-4-2022/'>Professorships in machine learning (including theory) at University of Copenhagen (apply by September 4, 2022)</a>
        </h3>
        <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The University of Copenhagen invites applications for assistant, associate, and full professorships in machine learning, including theoretical, mathematical, aspects. The application deadline is September 4. See di.ku.dk/ominstituttet/ledige_stillinger/tenure-track-assisatant-professorassociate-professorfull-professor-in-machine-learning/ for the full announcement. Website: di.ku.dk/ominstituttet/l
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The University of Copenhagen invites applications for assistant, associate, and full professorships in machine learning, including theoretical, mathematical, aspects. The application deadline is September 4. See <a href="https://di.ku.dk/ominstituttet/ledige_stillinger/tenure-track-assisatant-professorassociate-professorfull-professor-in-machine-learning/">https://di.ku.dk/ominstituttet/ledige_stillinger/tenure-track-assisatant-professorassociate-professorfull-professor-in-machine-learning/</a> for the full announcement.</p>
<p>Website: <a href="https://di.ku.dk/ominstituttet/ledige_stillinger/tenure-track-assisatant-professorassociate-professorfull-professor-in-machine-learning/">https://di.ku.dk/ominstituttet/ledige_stillinger/tenure-track-assisatant-professorassociate-professorfull-professor-in-machine-learning/</a><br />
Email: jn@di.ku.dk</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T10:20:03Z">5 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07730'>Direct Sum Theorems From Fortification</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Hao Wu</p><p>We revisit the direct sum theorems in communication complexity which askes
whether the resource to solve $n$ communication problems together is
(approximately) the sum of resources to solve these problems separately. Our
work starts with the observation that Meir and Dinur's fortification lemma for
protocol size over rectangles can be generalized to a general fortification

        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao Wu</a></p><p>We revisit the direct sum theorems in communication complexity which askes
whether the resource to solve $n$ communication problems together is
(approximately) the sum of resources to solve these problems separately. Our
work starts with the observation that Meir and Dinur's fortification lemma for
protocol size over rectangles can be generalized to a general fortification
lemma for a sub-additive measure over set. By applying this lemma to the case
of cover number, we obtain a dual form of cover number, called
``$\delta$-fooling set'' which is a generalized fooling set. Given a
communication problem $S\subseteq (X\times Y) \times Z$, let $\Lambda \subseteq
X\times Y$ be a $\delta$-fooling set of $S$, then given any subset
$\tilde{\Lambda} \subseteq \Lambda$ such that $|\tilde{\Lambda}|/{|\Lambda|} &gt;
\delta$, there is no monochromatic rectangle that covers the subset
$\tilde{\Lambda}$. Particularly, there is a $\frac{16\log|X| |Y|}{\mathsf{
Cov}(S)}$-fooling set of communication problem $S$. With this fact, we are able
to reprove the classic direct sum theorem of cover number with a simple double
counting argument. And we prove a new direct sum theorem about protocol size
which imply a better direct sum theorem for two functions in terms of protocol
size. Formally, let $\mathsf{L}$ denote the protocol szie, given a
communication problem $F:A \times B \rightarrow
</p>
<p>\{0,1\}$, $
</p>
<p>\log\mathsf{L}\left(F\times F\right)\geq
</p>
<p>\log \mathsf{L}\left(F\right)
+\Omega\left(\sqrt{\log\mathsf{L}\left(F\right)}\right)-\log\log|A||B| -4$.We
also prove a tight cover number lower bound for the agree problem introduced by
Amos Beimel et al.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07567'>Computing Smallest Convex Intersecting Polygons</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Antonios Antoniadis, Mark de Berg, S&#xe1;ndor Kisfaludi-Bak, Antonis Skarlatos</p><p>A polygon C is an intersecting polygon for a set O of objects in the plane if
C intersects each object in O, where the polygon includes its interior. We
study the problem of computing the minimum-perimeter intersecting polygon and
the minimum-area convex intersecting polygon for a given set O of object
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Antoniadis_A/0/1/0/all/0/1">Antonios Antoniadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_M/0/1/0/all/0/1">Mark de Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Kisfaludi_Bak_S/0/1/0/all/0/1">S&#xe1;ndor Kisfaludi-Bak</a>, <a href="http://arxiv.org/find/cs/1/au:+Skarlatos_A/0/1/0/all/0/1">Antonis Skarlatos</a></p><p>A polygon C is an intersecting polygon for a set O of objects in the plane if
C intersects each object in O, where the polygon includes its interior. We
study the problem of computing the minimum-perimeter intersecting polygon and
the minimum-area convex intersecting polygon for a given set O of objects. We
present an FPTAS for both problems for the case where O is a set of possibly
intersecting convex polygons in the plane of total complexity n.
</p>
<p>Furthermore, we present an exact polynomial-time algorithm for the
minimum-perimeter intersecting polygon for the case where O is a set of n
possibly intersecting segments in the plane. So far, polynomial-time exact
algorithms were only known for the minimum perimeter intersecting polygon of
lines or of disjoint segments.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07544'>Mean estimation when you have the source code; or, quantum Monte Carlo methods</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Robin Kothari, Ryan O&#x27;Donnell</p><p>Suppose $\boldsymbol{y}$ is a real random variable, and one is given access
to ``the code'' that generates it (for example, a randomized or quantum circuit
whose output is $\boldsymbol{y}$). We give a quantum procedure that runs the
code $O(n)$ times and returns an estimate $\widehat{\boldsymbol{\mu}}$ for $\mu
= \mathrm{E}[\boldsymbol{y}]$ that 
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Kothari_R/0/1/0/all/0/1">Robin Kothari</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+ODonnell_R/0/1/0/all/0/1">Ryan O&#x27;Donnell</a></p><p>Suppose $\boldsymbol{y}$ is a real random variable, and one is given access
to ``the code'' that generates it (for example, a randomized or quantum circuit
whose output is $\boldsymbol{y}$). We give a quantum procedure that runs the
code $O(n)$ times and returns an estimate $\widehat{\boldsymbol{\mu}}$ for $\mu
= \mathrm{E}[\boldsymbol{y}]$ that with high probability satisfies
$|\widehat{\boldsymbol{\mu}} - \mu| \leq \sigma/n$, where $\sigma =
\mathrm{stddev}[\boldsymbol{y}]$. This dependence on $n$ is optimal for quantum
algorithms. One may compare with classical algorithms, which can only achieve
the quadratically worse $|\widehat{\boldsymbol{\mu}} - \mu| \leq
\sigma/\sqrt{n}$. Our method improves upon previous works, which either made
additional assumptions about $\boldsymbol{y}$, and/or assumed the algorithm
knew an a priori bound on $\sigma$, and/or used additional logarithmic factors
beyond $O(n)$. The central subroutine for our result is essentially Grover's
algorithm but with complex phases.ally Grover's algorithm but with complex
phases.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07410'>Private Query Release via the Johnson-Lindenstrauss Transform</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Aleksandar Nikolov</p><p>We introduce a new method for releasing answers to statistical queries with
differential privacy, based on the Johnson-Lindenstrauss lemma. The key idea is
to randomly project the query answers to a lower dimensional space so that the
distance between any two vectors of feasible query answers is preserved up to
an additive error. Then we answer the projected que
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nikolov_A/0/1/0/all/0/1">Aleksandar Nikolov</a></p><p>We introduce a new method for releasing answers to statistical queries with
differential privacy, based on the Johnson-Lindenstrauss lemma. The key idea is
to randomly project the query answers to a lower dimensional space so that the
distance between any two vectors of feasible query answers is preserved up to
an additive error. Then we answer the projected queries using a simple
noise-adding mechanism, and lift the answers up to the original dimension.
Using this method, we give, for the first time, purely differentially private
mechanisms with optimal worst case sample complexity under average error for
answering a workload of $k$ queries over a universe of size $N$. As other
applications, we give the first purely private efficient mechanisms with
optimal sample complexity for computing the covariance of a bounded
high-dimensional distribution, and for answering 2-way marginal queries. We
also show that, up to the dependence on the error, a variant of our mechanism
is nearly optimal for every given query workload.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07438'>Archimedes Meets Privacy: On Privately Estimating Quantiles in High Dimensions Under Minimal Assumptions</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Omri Ben-Eliezer, Dan Mikulincer, Ilias Zadik</p><p>The last few years have seen a surge of work on high dimensional statistics
under privacy constraints, mostly following two main lines of work: the ``worst
case'' line, which does not make any distributional assumptions on the input
data; and the ``strong assumptions'' line, which assumes that the data is
generated from specific famili
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Ben_Eliezer_O/0/1/0/all/0/1">Omri Ben-Eliezer</a>, <a href="http://arxiv.org/find/math/1/au:+Mikulincer_D/0/1/0/all/0/1">Dan Mikulincer</a>, <a href="http://arxiv.org/find/math/1/au:+Zadik_I/0/1/0/all/0/1">Ilias Zadik</a></p><p>The last few years have seen a surge of work on high dimensional statistics
under privacy constraints, mostly following two main lines of work: the ``worst
case'' line, which does not make any distributional assumptions on the input
data; and the ``strong assumptions'' line, which assumes that the data is
generated from specific families, e.g., subgaussian distributions. In this work
we take a middle ground, obtaining new differentially private algorithms with
polynomial sample complexity for estimating quantiles in high-dimensions, as
well as estimating and sampling points of high Tukey depth, all working under
very mild distributional assumptions. From the technical perspective, our work
relies upon deep robustness results in the convex geometry literature,
demonstrating how such results can be used in a private context.
</p>
<p>Our main object of interest is the (convex) floating body (FB), a notion
going back to Archimedes, which is a robust and well studied high-dimensional
analogue of the interquantile range. We show how one can privately, and with
polynomially many samples, (a) output an approximate interior point of the FB
-- e.g., ``a typical user'' in a high-dimensional database -- by leveraging the
robustness of the Steiner point of the FB; and at the expense of polynomially
many more samples, (b) produce an approximate uniform sample from the FB, by
constructing a private noisy projection oracle.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07572'>Fine-Grained Complexity Lower Bounds for Families of Dynamic Graphs</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Monika Henzinger, Ami Paz, A. R. Sricharan</p><p>A dynamic graph algorithm is a data structure that answers queries about a
property of the current graph while supporting graph modifications such as edge
insertions and deletions. Prior work has shown strong conditional lower bounds
for general dynamic graphs, yet graph families that arise in practice often
exhibit structural properties 
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Paz_A/0/1/0/all/0/1">Ami Paz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sricharan_A/0/1/0/all/0/1">A. R. Sricharan</a></p><p>A dynamic graph algorithm is a data structure that answers queries about a
property of the current graph while supporting graph modifications such as edge
insertions and deletions. Prior work has shown strong conditional lower bounds
for general dynamic graphs, yet graph families that arise in practice often
exhibit structural properties that the existing lower bound constructions do
not possess. We study three specific graph families that are ubiquitous, namely
constant-degree graphs, power-law graphs, and expander graphs, and give the
first conditional lower bounds for them. Our results show that even when
restricting our attention to one of these graph classes, any algorithm for
fundamental graph problems such as distance computation or approximation or
maximum matching, cannot simultaneously achieve a sub-polynomial update time
and query time. For example, we show that the same lower bounds as for general
graphs hold for maximum matching and ($s,t$)-distance in constant-degree
graphs, power-law graphs or expanders. Namely, in an $m$-edge graph, there
exists no dynamic algorithms with both $O(m^{1/2 - \epsilon})$ update time and
$ O(m^{1 -\epsilon})$ query time, for any small $\epsilon &gt; 0$. Note that for
($s,t$)-distance the trivial dynamic algorithm achieves an almost matching
upper bound of constant update time and $O(m)$ query time. We prove similar
bounds for the other graph families and for other fundamental problems such as
densest subgraph detection and perfect matching.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07582'>Deletion Robust Non-Monotone Submodular Maximization over Matroids</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Paul D&#xfc;tting, Federico Fusco, Silvio Lattanzi, Ashkan Norouzi-Fard, Morteza Zadimoghaddam</p><p>Maximizing a submodular function is a fundamental task in machine learning
and in this paper we study the deletion robust version of the problem under the
classic matroids constraint. Here the goal is to extract a small size summary
of the dataset that contains a high value independent s
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dutting_P/0/1/0/all/0/1">Paul D&#xfc;tting</a>, <a href="http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1">Federico Fusco</a>, <a href="http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1">Silvio Lattanzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Norouzi_Fard_A/0/1/0/all/0/1">Ashkan Norouzi-Fard</a>, <a href="http://arxiv.org/find/cs/1/au:+Zadimoghaddam_M/0/1/0/all/0/1">Morteza Zadimoghaddam</a></p><p>Maximizing a submodular function is a fundamental task in machine learning
and in this paper we study the deletion robust version of the problem under the
classic matroids constraint. Here the goal is to extract a small size summary
of the dataset that contains a high value independent set even after an
adversary deleted some elements. We present constant-factor approximation
algorithms, whose space complexity depends on the rank $k$ of the matroid and
the number $d$ of deleted elements. In the centralized setting we present a
$(4.597+O(\varepsilon))$-approximation algorithm with summary size $O(
\frac{k+d}{\varepsilon^2}\log \frac{k}{\varepsilon})$ that is improved to a
$(3.582+O(\varepsilon))$-approximation with $O(k + \frac{d}{\varepsilon^2}\log
\frac{k}{\varepsilon})$ summary size when the objective is monotone. In the
streaming setting we provide a $(9.435 + O(\varepsilon))$-approximation
algorithm with summary size and memory $O(k + \frac{d}{\varepsilon^2}\log
\frac{k}{\varepsilon})$; the approximation factor is then improved to
$(5.582+O(\varepsilon))$ in the monotone case.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07728'>O(n log n) algorithm for finding a solution of Erd\H{o}s-Ginzburg-Ziv theorem</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Seokhwan Choi, Hanpil Kang, Dongjae Lim</p><p>Erd\H{o}s-Ginzburg-Ziv theorem is a popular theorem in additive number
theory, which states any sequence of $2n-1$ integers contains a subsequence of
$n$ elements, with their sum is a multiple of $n$. In this article, we provide
an algorithm finding a solution of Erd\H{o}s-Ginzburg-Ziv in $O(n \log n)$
time. This is the first known quasi-lin
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Seokhwan Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1">Hanpil Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_D/0/1/0/all/0/1">Dongjae Lim</a></p><p>Erd\H{o}s-Ginzburg-Ziv theorem is a popular theorem in additive number
theory, which states any sequence of $2n-1$ integers contains a subsequence of
$n$ elements, with their sum is a multiple of $n$. In this article, we provide
an algorithm finding a solution of Erd\H{o}s-Ginzburg-Ziv in $O(n \log n)$
time. This is the first known quasi-linear time algorithm finding a solution of
Erd\H{o}s-Ginzburg-Ziv theorem.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07789'>Polynomial kernel for immersion hitting in tournaments</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: &#x141;ukasz Bo&#x17c;yk, Micha&#x142; Pilipczuk</p><p>For a fixed simple digraph $H$ without isolated vertices, we consider the
problem of deleting arcs from a given tournament to get a digraph which does
not contain $H$ as an immersion. We prove that for every $H$, this problem
admits a polynomial kernel when parameterized by the number of deleted arcs.
The degree of the bound on the 
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bozyk_L/0/1/0/all/0/1">&#x141;ukasz Bo&#x17c;yk</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Micha&#x142; Pilipczuk</a></p><p>For a fixed simple digraph $H$ without isolated vertices, we consider the
problem of deleting arcs from a given tournament to get a digraph which does
not contain $H$ as an immersion. We prove that for every $H$, this problem
admits a polynomial kernel when parameterized by the number of deleted arcs.
The degree of the bound on the kernel size depends on $H$.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07800'>New Parallel Order Maintenance Data Structure</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Bin Guo, Emil Sekerinski</p><p>The \emph{Order-Maintenance} (OM) data structure maintains a total order list
of items for insertions, deletions, and comparisons. As a basic data structure,
OM has many applications, such as maintaining the topological order, core
numbers, and truss in graphs, and maintaining ordered sets in Unified Modeling
Language (UML) Specification. The prevalence of
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1">Bin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sekerinski_E/0/1/0/all/0/1">Emil Sekerinski</a></p><p>The \emph{Order-Maintenance} (OM) data structure maintains a total order list
of items for insertions, deletions, and comparisons. As a basic data structure,
OM has many applications, such as maintaining the topological order, core
numbers, and truss in graphs, and maintaining ordered sets in Unified Modeling
Language (UML) Specification. The prevalence of multicore machines suggests
parallelizing such a basic data structure. This paper proposes a new parallel
OM data structure that supports insertions, deletions, and comparisons in
parallel. Specifically, parallel insertions and deletions are synchronized by
using locks efficiently, which achieve up to $7$x and $5.6$x speedups with $64$
workers. One big advantage is that the comparisons are lock-free so that they
can execute highly in parallel with other insertions and deletions, which
achieve up to $34.4$x speedups with $64$ workers. Typical real applications
maintain order lists that always have a much larger portion of comparisons than
insertions and deletions. For example, in core maintenance, the number of
comparisons is up to 297 times larger compared with insertions and deletions in
certain graphs. This is why the lock-free order comparison is a breakthrough in
practice.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://arxiv.org/abs/2208.07851'>Optimal algorithms for learning quantum phase states</a>
        </h3>
        <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Srinivasan Arunachalam, Sergey Bravyi, Arkopal Dutt, Theodore J. Yoder</p><p>We analyze the complexity of learning $n$-qubit quantum phase states. A
degree-$d$ phase state is defined as a superposition of all $2^n$ basis vectors
$x$ with amplitudes proportional to $(-1)^{f(x)}$, where $f$ is a degree-$d$
Boolean polynomial over $n$ variables. We show that the sample complexity of
learni
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Arunachalam_S/0/1/0/all/0/1">Srinivasan Arunachalam</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Bravyi_S/0/1/0/all/0/1">Sergey Bravyi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Dutt_A/0/1/0/all/0/1">Arkopal Dutt</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yoder_T/0/1/0/all/0/1">Theodore J. Yoder</a></p><p>We analyze the complexity of learning $n$-qubit quantum phase states. A
degree-$d$ phase state is defined as a superposition of all $2^n$ basis vectors
$x$ with amplitudes proportional to $(-1)^{f(x)}$, where $f$ is a degree-$d$
Boolean polynomial over $n$ variables. We show that the sample complexity of
learning an unknown degree-$d$ phase state is $\Theta(n^d)$ if we allow
separable measurements and $\Theta(n^{d-1})$ if we allow entangled
measurements. Our learning algorithm based on separable measurements has
runtime $\textsf{poly}(n)$ (for constant $d$) and is well-suited for near-term
demonstrations as it requires only single-qubit measurements in the Pauli $X$
and $Z$ bases. We show similar bounds on the sample complexity for learning
generalized phase states with complex-valued amplitudes. We further consider
learning phase states when $f$ has sparsity-$s$, degree-$d$ in its
$\mathbb{F}_2$ representation (with sample complexity $O(2^d sn)$), $f$ has
Fourier-degree-$t$ (with sample complexity $O(2^{2t})$), and learning quadratic
phase states with $\varepsilon$-global depolarizing noise (with sample
complexity $O(n^{1+\varepsilon})$). These learning algorithms give us a
procedure to learn the diagonal unitaries of the Clifford hierarchy and IQP
circuits.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-17T00:30:00Z">15 hours ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Tuesday, August 16
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://eccc.weizmann.ac.il/report/2022/114'>TR22-114 |  Direct Sum  Theorems From Fortification | 

	Hao Wu</a>
        </h3>
        <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We revisit  the direct sum theorems in communication complexity which askes whether the resource to solve $n$ communication problems together is (approximately) the sum of resources to solve these problems separately. Our work starts with the  observation that Meir and Dinur&#39;s fortification lemma for protocol size over rectangles can be generalized to a general fortification lemma for a sub-add
        
        </div>

        <div class='item-content item-summary'>
        
          
          We revisit  the direct sum theorems in communication complexity which askes whether the resource to solve $n$ communication problems together is (approximately) the sum of resources to solve these problems separately. Our work starts with the  observation that Meir and Dinur&#39;s fortification lemma for protocol size over rectangles can be generalized to a general fortification lemma for a sub-additive measure over set. By applying this lemma to the case of cover number, we obtain a dual form of cover number, called ``$\delta$-fooling set&#39;&#39; which is a generalized fooling set. Given a communication problem $S\subseteq (X\times Y) \times Z$, let $\Lambda \subseteq  X\times Y$ be a $\delta$-fooling set of $S$, then given any subset $\tilde{\Lambda} \subseteq \Lambda$ such that $|\tilde{\Lambda}|/{|\Lambda|} &gt; \delta$, there is no  monochromatic rectangle that covers  the subset $\tilde{\Lambda}$. Particularly, there is  a $\frac{16\log|X| |Y|}{{Cov}(S)}$-fooling set of communication problem $S$. 
	
With this fact, we are able to reprove the classic direct sum theorem of cover number with a simple double counting argument. Formally, let  $S  \subseteq (A\times B) \times O$ and $T \subseteq (P\times Q) \times Z$ be two communication problems, $
\log {Cov}\left(S\times T\right)
\geq  \log{Cov}\left(S\right) 
+ \log{Cov}(T)
-\log\log|P||Q|-4.$ where ${Cov}$ denotes the cover number. 

 One issue of current deterministic direct sum theorems about commutation complexity or protocol size is that they provide no information when $n$ is small, especially when $n=2$. In this work,  we prove a new direct sum theorem about protocol size which imply a better direct sum theorem for two functions in terms of protocol size. Formally, let ${L}$ denote the protocol size, given a communication problem $F:A \times B \rightarrow 
 \{0,1\}$, $
 \log{L}\left(F\times F\right)\geq
 \log {L}\left(F\right) +\Omega\left(\sqrt{\log{L}\left(F\right)}\right)-\log\log|A||B| -4$.
 
 We also address other direct sum type problem such like the agree problem introduced by Amos Beimel et. We prove a tight cover number lower bound for  the agree problem. Formally, let $S_i \subseteq X_i \times Y_i \times Z, i\in [k]$ be $k$ two-party communication problems, 
${Cov}
\left({agree}(S_1,\ldots,S_k)\right) \geq \min_{i\in [k]} 
\left\{ \frac{{Cov}(S_i)}{16\log|X_i| |Y_i|} \right\}. 
$

All our direct sum type results are obtained in a similar way, that is using the $\delta$-fooling set to construct a hardcore for the direct sum type problem.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-16T13:21:16Z">a day ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Monday, August 15
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://11011110.github.io/blog/2022/08/15/linkage.html'>Linkage</a>
        </h3>
        <p class='item-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The logic of definite descriptions (\(\mathbb{M}\)). Joel Hamkins wrestles with logical formulations of “the”, indicating that a description uniquely identifies something. If you define a logical operator whose value is the thing identified by its argument, and use it in a context that doesn’t uniquely identify something, does your overall formula still have a truth value? Fortunately(?) the stakes
        
        </div>

        <div class='item-content item-summary'>
        
          
          <ul>
  <li>
    <p><a href="http://jdh.hamkins.org/the-logic-of-definite-descriptions/">The logic of definite descriptions</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108752002958988947">\(\mathbb{M}\)</a>).</span> Joel Hamkins wrestles with logical formulations of “the”, indicating that a description uniquely identifies something. If you define a logical operator whose value is the thing identified by its argument, and use it in a context that doesn’t uniquely identify something, does your overall formula still have a truth value? Fortunately(?) the stakes are low: several plausible choices produce logics with the same power as classical logic.</p>
  </li>
  <li>
    <p><a href="https://twitter.com/QuantumYakar/status/1554432810664054784?s=20&amp;t=0nXoTU04w7Qe1bitINS6QA">DALL-E paintings of people using quantum computers, in the styles of famous artists</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108754837516429391">\(\mathbb{M}\)</a>,</span> <a href="https://scottaaronson.blog/?p=6635">via</a>). I am super-impressed at how this sort of thing can be done quickly by software, rather than human artists with much more time.</p>
  </li>
  <li>
    <p><a href="https://eprint.iacr.org/2022/975.pdf">Supersingular isogeny Diffie–Hellman broken</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108760153729341419">\(\mathbb{M}\)</a>,</span> <a href="https://arstechnica.com/information-technology/2022/08/sike-once-a-post-quantum-encryption-contender-is-koed-in-nist-smackdown/">via</a>). This cryptosystem relied on the unpredictability of <a href="https://en.wikipedia.org/wiki/Supersingular_isogeny_graph">supersingular isogeny graphs</a>, expander graphs with vertices for elliptic curves and edges for certain morphisms between them. Apparently, these graphs are less unpredictable than thought. SIDH and the SIKE protocol built on it were hoped to be impenetrable to quantum computers but the attack does not use quantum.</p>
  </li>
  <li>
    <p><a href="https://www.danapiazza.art/2020">The warped grids of Dana Piazza’s artworks look like curvy woven textiles</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108767757342794473">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=947Ewgue4DM">\(10^5\)-fold speedup for Matt Parker’s Wordle puzzle</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108777561081795507">\(\mathbb{M}\)</a>).</span> This has nothing to do with actual Wordle puzzles; it’s about sets of five-letter words with no repeated letters (see <a href="https://www.youtube.com/watch?v=_-AfhLQfb6w">Parker’s original video</a>). Two ideas for the speedup: first, save a 5! factor by only searching sorted sequences of words. And second, make the repetition tests blazingly fast using 26-bit bitvectors for the sets of characters already used, so repetitions can be found as a bitwise and.</p>
  </li>
  <li>
    <p><a href="https://yangerard.wordpress.com/2019/06/18/open-problem-optimal-area-polygonalization/">Cute puzzle from Sándor Fekete’s 1992 dissertation, via Yan Gerard</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108783731533422343">\(\mathbb{M}\)</a>):</span> prove that any finite set of points in the plane has a simple polygon with all of the points as vertices, covering more than half of the area of its convex hull. More generally, polygons using all of a given point set as vertices are called <a href="https://en.wikipedia.org/wiki/Polygonalization">polygonalizations</a>, and there are many unsolved problems concerning them.</p>
  </li>
  <li>
    <p><a href="http://www.kindofdoon.com/2020/03/prioritizing-color-over-value.html">Prioritizing value (lightness and darkness) versus color (legibility of hue) in imaging</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108786220837380811">\(\mathbb{M}\)</a>).</span> With examples both from digital photo processing and the history of painting, and suggestions for how to achieve either desired effect in Photoshop-like editors. Daniel Dichter, 2020.</p>
  </li>
  <li>
    <p>A philosophical/definitional question <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108791925057208437">\(\mathbb{M}\)</a>):</span> should “problem \(X\) on input class \(Y\) is \(\mathsf{NP}\)-complete” mean there is a specialized decision problem whose valid inputs are exactly \(Y\) that is \(\mathsf{NP}\)-compete, or should it mean that problem \(X\) (allowing wider inputs) is \(\mathsf{NP}\)-complete and has hard inputs in $Y$?</p>

    <p>Case in point: snarks (<a href="https://en.wikipedia.org/wiki/Snark_(graph_theory)">new Good Article on Wikipedia</a>) are \(\mathsf{coNP}\)-complete to recognize. Can it ever be correct to say “problem \(X\) is \(\mathsf{NP}\)-complete for snarks”?</p>
  </li>
  <li>
    <p><a href="https://www.metafilter.com/196124/Along-with-the-chicken-and-the-banana">Interesting discussion on the repeated independent invention of zero as concept and as a digit in positional numbering, in many ancient cultures</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108797547774576065">\(\mathbb{M}\)</a>),</span> prompted by a dubious jingoistic <em>Scientific American</em> article (linked) that somehow assigns “ownership” (!?) of this concept to a Sumatran kingdom contemporary with medieval Europe, who somehow spread their knowledge backwards in time to the ancient world. What has happened to <em>Scientific American</em>?</p>
  </li>
  <li>
    <p>Summer is a time for transitions among my UC Irvine theory colleagues <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108803001555998759">\(\mathbb{M}\)</a>):</span></p>

    <ul>
      <li>
        <p>Sandy Irani went on leave to be <a href="https://simons.berkeley.edu/news/Irani-Associate-Director">associate director for the Simons Institute for the Theory of Computing in Berkeley</a>.</p>
      </li>
      <li>
        <p>Amelia Regan retired (emeritus) to direct the supply chain transportation &amp; logistics graduate program in civil &amp; environmental engineering at the University of Washington.</p>
      </li>
      <li>
        <p>Dan Hirschberg also retired as emeritus, but is teaching on recall.</p>
      </li>
    </ul>

    <p>Congratulations, Sandy, Amelia, and Dan!</p>
  </li>
  <li>
    <p>If you were thinking of submitting a paper to COCOA (the 16th Annual Conference on Combinatorial Optimization and Applications, previously scheduled with initial submission date August 12 and conference in Dallas Texas in December), as I was, think again <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108807238586218956">\(\mathbb{M}\)</a>).</span> It’s now been <a href="https://theory.utdallas.edu/COCOA2023/index.html">pushed back a year and planned to be online-only</a>. I have no more information than what is linked here.</p>
  </li>
  <li>
    <p>I’m sad that an article with the headline <a href="https://www.lppfusion.com/scientists-protest-censorship-in-cosmology/">“Scientists Protest Censorship in Cosmology”</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108811940444664320">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=32443298">via</a>) is only about fringe papers getting rejected as off-topic by arXiv and MNRAS. I wanted it to be about scientists holding big marches with signs in the street in opposition to the <a href="https://en.wikipedia.org/wiki/Cosmic_censorship_hypothesis">cosmic censorship hypotheses</a>, that the universe conspires against scientists to make it impossible to see what singularities in space-time look like.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@xp_eileen_maths/108793591875610453">Does anyone use “lemmata” as the plural of “lemma”</a>?</p>
  </li>
  <li>
    <p><a href="https://aperiodical.com/2022/08/integer-sequence-review-a101544/">David Cushing and Christian Lawson-Perfect critique more OEIS sequences</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@christianp/108815974308227304">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://commons.wikimedia.org/wiki/File:WPBioPctChangedOccupation.png">A bar chart showing occupations for which the English Wikipedia’s coverage of women (as a proportion of biographical articles for that occupation) most improved over the five years from 2016 to 2021</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108829181695783366">\(\mathbb{M}\)</a>).</span> I’m happy to see “scientist” (13% to 25%) and “professor” (11% to 20%) made the list. But they’re still a long way from 50%.</p>
  </li>
</ul>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-15T17:28:00Z">2 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://gilkalai.wordpress.com/2022/08/15/answer-to-test-your-intuition-50-detecting-a-deviator/'>Answer to Test Your Intuition 50: Detecting a Deviator</a>
        </h3>
        <p class='item-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Two weeks ago we asked: Ruth and Ron start together at the origin and take a walk on the integers. Every day they make a move. They take turns in flipping a coin and they move together right or left &#8230; Continue reading &#8594;
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Two weeks ago we asked:</p>
<blockquote><p>Ruth and Ron start together at the origin and take a walk on the integers. Every day they make a move. They take turns in flipping a coin and they move together right or left according to the outcome. Their coin flips create a simple random walk starting at the origin on the integers.</p>
<p>We know for sure that they we will return to the origin infinitely many times. However, their random walk never comes back to the origin, so we know for sure that one of them did not follow the rules!</p>
<h3>Test your intuition: Is it possible to figure out from the walk whether it was Ruth or Ron who did not follow the coin-flipping rule?</h3>
</blockquote>
<p>And the answer is <strong>yes!</strong> This is proved in the following paper:</p>
<p class="title mathjax"><a href="https://arxiv.org/abs/2203.03744">Identifying the Deviator</a>, by Noga Alon, Benjamin Gunby, Xiaoyu He, Eran Shmaya, and Eilon Solan</p>
<p class="title mathjax"><strong>Abstract:</strong> A group of players are supposed to follow a prescribed profile of strategies. If they follow this profile, they will reach a given target. We show that if the target is not reached because some player deviates, then an outside observer can identify the deviator. We also construct identification methods in two nontrivial cases.</p>
<p>The paper gives a non-constructive proof for a strategy to identify the deviator and in the case of two-player random walk it gives an ingenious explicit identification method!</p>
<p><span style="color:#0000ff;">Here is a variant of the problem devoted to Itai Benjamini: Consider planar percolation on the rectangular grid. One player chooses every vertical edge with probability 1/2 and one player chooses every horizontal edge with probability 1/2. Lo and behold, there is an infinite open cluster. Can you (explicitely) detect the deviator?</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2022/08/deviator.png"><img data-attachment-id="23223" data-permalink="https://gilkalai.wordpress.com/2022/08/15/answer-to-test-your-intuition-50-detecting-a-deviator/deviator/" data-orig-file="https://gilkalai.files.wordpress.com/2022/08/deviator.png" data-orig-size="642,242" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="deviator" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/08/deviator.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/08/deviator.png?w=640" class="alignnone size-full wp-image-23223" src="https://gilkalai.files.wordpress.com/2022/08/deviator.png?w=640" alt="deviator" srcset="https://gilkalai.files.wordpress.com/2022/08/deviator.png?w=640 640w, https://gilkalai.files.wordpress.com/2022/08/deviator.png?w=150 150w, https://gilkalai.files.wordpress.com/2022/08/deviator.png?w=300 300w, https://gilkalai.files.wordpress.com/2022/08/deviator.png 642w" sizes="(max-width: 640px) 100vw, 640px"   /></a></p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-15T17:06:03Z">2 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://blog.computationalcomplexity.org/2022/08/a-non-controversial-question-about.html'>A non-controversial question about the Documents Donald Trump had in his house</a>
        </h3>
        <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          This is a non-partisan post. In the interest of disclosure I will divulge that I do not think private citizens should have top secret government documents in their house.<br>One phrase I kept hearing in the reporting was (I paraphrase and may have the number wrong)<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; The FBI remov
        
        </div>

        <div class='item-content item-summary'>
        
          
          This is a non-partisan post. In the interest of disclosure I will divulge that I do not think private citizens should have top secret government documents in their house.<div><br /></div><div>One phrase I kept hearing in the reporting was (I paraphrase and may have the number wrong)</div><div><br /></div><div><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; The FBI removed 15 boxes of documents</i></div><div><br /></div><div>Documents? Like--- on paper?&nbsp;</div><div><br /></div><div>a) Are the documents also online someplace? Perhaps they intentionally are not so that they can't be hacked.&nbsp;</div><div><br /></div><div>b) Is having top secret documents only on paper safer than having them in electronic form? Normally I would think so. Donald Trump&nbsp; having them is a very unusual case.&nbsp;</div><div><br /></div><div>c) Having to store all of those documents on paper would seem to have storage problems. I can imagine someone with NO bad purposes making copies and taking them home since they are tired of only being about to read them in a special room.&nbsp;</div><div><br /></div><div>d) A problem with having them ONLY on paper is that if an accident happens and they get destroyed there is no backup. Or is there? Are there copies somewhere? That leads to twice the storage problems.&nbsp;</div><div><br /></div><div>e) There is a tradeoff of security and convenience. Is having the documents only on paper is an extreme point on the tradeoff, but it may be the right one. It may depend on how important it is to keep the documents secret.&nbsp;</div><div><br /></div><div>f) I've heard (apocryphal?) stories about some top secret document also available in public though quite legal sources (e.g., a physics journal that discusses nuclear stuff).&nbsp; Does the government make to much classified? If so then the problem arises of people not taking the classification seriously and getting careless. I doubt that is what happened here.&nbsp;</div><div><br /></div><div>g) The question I am most curious about is why did he take them? For most of his other actions his motivations are clear (e.g., he is pushing STOP THE STEAL since he wants to be president). But for this one its not clear. Unfortunately,&nbsp; I doubt we'll ever find out. Maybe the answer is in some documents either on paper or electronic.&nbsp;</div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-15T12:13:00Z">2 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Sunday, August 14
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://decentralizedthoughts.github.io/2022-08-14-new-DR-LB/'>A new Dolev-Reischuk style Lower Bound</a>
        </h3>
        <p class='item-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          In a previous post we discussed Crusader Broadcast and showed a $O(n^2)$ words, $O(1)$ time solution for $f&lt;n$ and assuming a PKI. In this post, we overview a new Dolev-Reischuk style bower bound (see our full paper): Theorem AS22: In any deterministic protocol solving Crusader Broadcast with $f&lt;n$ Byzantine failures...
        
        </div>

        <div class='item-content item-summary'>
        
          
          In a previous post we discussed Crusader Broadcast and showed a $O(n^2)$ words, $O(1)$ time solution for $f&lt;n$ and assuming a PKI. In this post, we overview a new Dolev-Reischuk style bower bound (see our full paper): Theorem AS22: In any deterministic protocol solving Crusader Broadcast with $f&lt;n$ Byzantine failures...
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-14T12:00:00Z">3 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://eccc.weizmann.ac.il/report/2022/113'>TR22-113 |  Leakage-Resilient Hardness v.s. Randomness | 

	Yanyi Liu, 

	Rafael Pass</a>
        </h3>
        <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          A central open problem in complexity theory concerns the question of
whether all efficient randomized algorithms can be simulated by
efficient deterministic algorithms. The celebrated ``hardness
v.s. randomness” paradigm pioneered by Blum-Micali (SIAM JoC’84),
Yao (FOCS’84) and Nisan-Wigderson (JCSS’94) presents hardness
assumptions under which $\prBPP = \prP$, but these hardness assumptions 
are n
        
        </div>

        <div class='item-content item-summary'>
        
          
          A central open problem in complexity theory concerns the question of
whether all efficient randomized algorithms can be simulated by
efficient deterministic algorithms. The celebrated ``hardness
v.s. randomness” paradigm pioneered by Blum-Micali (SIAM JoC’84),
Yao (FOCS’84) and Nisan-Wigderson (JCSS’94) presents hardness
assumptions under which $\prBPP = \prP$, but these hardness assumptions 
are not known to also be necessary for such derandomization.
 
In this work, following the recent work by Chen and Tell (FOCS’21) that 
considers “almost-all-input” hardness of a function $f$ (i.e., hardness 
of computing $f$ on more than a finite number of inputs), we consider 
“almost-all-input” \emph{leakage-resilient hardness} of a function $f$
—that is, hardness of computing $f(x)$ even given, say, $\sqrt{|x|}$ 
bits of leakage of $f(x)$. We show that leakage-resilient hardness 
characterizes derandomization of $\prBPP$ (i.e., gives a both \emph{
necessary} and \emph{sufficient} condition for derandomization). In more 
detail, we show that there exists a constant $c$ such that the following 
are equivalent:

- $\prBPP = \prP$;
- Existence of a poly-time computable function $f :\{0, 1\}^n \rightarrow  \{0,1\}^n$
 that is almost-all-input leakage-resilient hard with respect to 
$n^c$-time probabilistic algorithms.

Our characterization naturally extends also to the low-end
derandomization regime, to derandomization of $\prMA$, and also to
average-case derandomization, by appropriately weakening the
requirements on the function $f$.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-14T08:05:23Z">3 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://scottaaronson.blog/?p=6645'>Summer 2022 Quantum Supremacy Updates</a>
        </h3>
        <p class='item-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Update: We&#8217;re now finalizing the lecture notes&#8212;basically, a textbook&#8212;for the brand-new Quantum Information Science II course that I taught this past spring! The notes will be freely shared on this blog. But the bibliographies for the various lectures need to be merged, and we don&#8217;t know how. Would any TeXpert like to help us, in [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Update:</mark></strong> We&#8217;re now finalizing the lecture notes&#8212;basically, a textbook&#8212;for the brand-new Quantum Information Science II course that I taught this past spring!  The notes will be freely shared on this blog.  But the bibliographies for the various lectures need to be merged, and we don&#8217;t know how.  Would any TeXpert like to help us, in exchange for a generous acknowledgment?</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>I returned last week from the <a href="https://chicagoquantum.org/events/nsf-workshop-quantum-advantage-and-next-steps">NSF Workshop on Quantum Advantage and Next Steps</a> at the University of Chicago.  Thanks so much to Chicago CS professor (and my former summer student) <a href="https://www.billfefferman.com/">Bill Fefferman</a> and the other organizers for making this workshop a reality.  Given how vividly I remember the situation 12 years ago, when the idea of sampling-based quantum supremacy was the weird obsession of me and a few others, it was particularly special to attend a workshop on the topic with well over a hundred participants, some in-person and some on Zoom, delayed by covid but still excited by the dramatic experimental progress of the past few years.</p>



<p>Of course there&#8217;s a lot still to do.  Many of the <a href="https://chicagoquantum.org/events/nsf-workshop-quantum-advantage-and-next-steps">talks</a> drew an exclamation point on something I&#8217;ve been saying for the past couple years: that there&#8217;s an urgent need for better quantum supremacy experiments, which will require both theoretical <em>and</em> engineering advances.  The experiments by Google and USTC and now Xanadu represent a big step forward for the field, but since they started being done, the classical spoofing attacks have also steadily improved, to the point that whether &#8220;quantum computational supremacy&#8221; still exists depends on exactly how you define it.</p>



<p>Briefly: if you measure by total operations, energy use, or CO2 footprint, then probably yes, quantum supremacy remains.  But if you measure by number of seconds, then it doesn&#8217;t remain, not if you&#8217;re willing to shell out for enough cores on AWS or your favorite supercomputer.  And even the quantum supremacy that does remain might eventually fall to, e.g., further improvements of the <a href="https://arxiv.org/abs/2112.01657">algorithm due to Gao et al</a>.  For more details, see, e.g., the now-published work of <a href="https://arxiv.org/abs/2111.03011">Pan, Chen, and Zhang</a>, or this <a href="https://www.science.org/content/article/ordinary-computers-can-beat-google-s-quantum-computer-after-all">good popular summary</a> by Adrian Cho for <em>Science</em>.</p>



<p>If the experimentalists care enough, they could easily regain the quantum lead, at least for a couple more years, by (say) repeating random circuit sampling with 72 qubits rather than 53-60, and hopefully circuit depth of 30-40 rather than just 20-25.  But the point I made in <a href="https://www.scottaaronson.com/talks/whatihope.ppt">my talk</a> was that, as long as we remain in the paradigm of sampling experiments that take ~2<sup>n</sup> time to verify classically and <em>also</em> ~2<sup>n</sup> time to spoof classically (where n is the number of qubits), all quantum speedups that we can achieve will be fragile and contingent, however interesting and impressive.  As soon as we go way beyond what classical computers can keep up with, we&#8217;ve <em>also</em> gone way beyond where classical computers can check what was done.</p>



<p>I argued that the only solution to this problem is to design new quantum supremacy experiments: ones where some secret has been inserted in the quantum circuit that lets a classical computer efficiently verify the results.  The fundamental problem is that we need three properties&#8212;</p>



<ol><li>implementability on <em>near-term</em> quantum computers,</li><li>efficient classical verifiability, and</li><li>confidence that quantum computers have a theoretical asymptotic advantage,</li></ol>



<p>and right now we only know how to get any two out of the three.  We can get 1 and 2 with <a href="https://qiskit.org/textbook/ch-applications/qaoa.html">QAOA</a> and various other heuristic quantum algorithms, 1 and 3 with BosonSampling and Random Circuit Sampling, or 2 and 3 with Shor&#8217;s algorithm or <a href="https://arxiv.org/abs/2204.02063">Yamakawa-Zhandry</a> or recent interactive protocols.  To get all three, there are three obvious approaches:</p>



<ol><li>Start with the heuristic algorithms and find a real advantage from them,</li><li>Start with BosonSampling or Random Circuit Sampling or the like and figure out how to make them efficiently verifiable classically, or</li><li>Start with protocols like <a href="https://arxiv.org/abs/2104.00687">Kahanamoku-Meyer et al.&#8217;s</a> and figure out how to run them on near-term devices.</li></ol>



<p>At the Chicago workshop, I&#8217;d say that the most popular approach speakers talked about was 3, although my own focus was more on 2.</p>



<p>Anyway, until a &#8220;best-of-all-worlds&#8221; quantum supremacy experiment is discovered, there&#8217;s plenty to do in the meantime: for example, better understand the classical hardness of spoofing Random Circuit Sampling with a constant or logarithmic number of gate layers.  Understand the best that classical algorithms can do to spoof the Linear Cross-Entropy Benchmark for BosonSampling, and build on <a href="https://arxiv.org/abs/2110.06964">Grier et al.</a> to understand the power of BosonSampling with a linear number of modes.</p>



<p>I&#8217;ll be flying back with my family to Austin today after seven weeks at the Jersey shore, but I&#8217;ll try to field any questions about the state of quantum supremacy in general or this workshop in particular in the comments!</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-13T19:22:09Z">4 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Friday, August 12
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://eccc.weizmann.ac.il/report/2022/112'>TR22-112 |  Randomised Composition and Small-Bias Minimax | 

	Shalev Ben-David, 

	Eric Blais, 

	Mika Göös, 

	Gilbert Maystre</a>
        </h3>
        <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We prove two results about randomised query complexity $\mathrm{R}(f)$. First, we introduce a linearised complexity measure $\mathrm{LR}$ and show that it satisfies an inner-optimal composition theorem: $\mathrm{R}(f\circ g) \geq \Omega(\mathrm{R}(f) \mathrm{LR}(g))$ for all partial $f$ and $g$, and moreover, $\mathrm{LR}$ is the largest possible measure with this property. In particular, $\mathrm{
        
        </div>

        <div class='item-content item-summary'>
        
          
          We prove two results about randomised query complexity $\mathrm{R}(f)$. First, we introduce a linearised complexity measure $\mathrm{LR}$ and show that it satisfies an inner-optimal composition theorem: $\mathrm{R}(f\circ g) \geq \Omega(\mathrm{R}(f) \mathrm{LR}(g))$ for all partial $f$ and $g$, and moreover, $\mathrm{LR}$ is the largest possible measure with this property. In particular, $\mathrm{LR}$ can be polynomially larger than previous measures that satisfy an inner composition theorem, such as the max-conflict complexity of Gavinsky, Lee, Santha, and Sanyal (ICALP 2019).

Our second result addresses a question of Yao (FOCS 1977). He asked if $\epsilon$-error expected query complexity $\bar{\mathrm{R}}_\epsilon(f)$ admits a distributional characterisation relative to some hard input distribution. Vereshchagin (TCS 1998) answered this question affirmatively in the bounded-error case. We show that an analogous theorem fails in the small-bias case $\epsilon=1/2-o(1)$.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-12T19:53:38Z">5 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://decentralizedthoughts.github.io/2022-08-12-hehtlc/'>He-HTLC - Revisiting Incentives in HTLC</a>
        </h3>
        <p class='item-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Hashed Time-locked Contracts (HTLC) find many useful applications in the L2 Layer such as the lightning network and atomic swaps. In this post, we will focus on discussing protocols for implementing HTLC when taking into consideration incentives for parties in the system. We will discuss a line of work —...
        
        </div>

        <div class='item-content item-summary'>
        
          
          Hashed Time-locked Contracts (HTLC) find many useful applications in the L2 Layer such as the lightning network and atomic swaps. In this post, we will focus on discussing protocols for implementing HTLC when taking into consideration incentives for parties in the system. We will discuss a line of work —...
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-12T05:00:00Z">5 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Thursday, August 11
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://gilkalai.wordpress.com/2022/08/11/to-cheer-you-up-in-difficult-times-36-the-immense-joy-of-fake-reverse-parking/'>To cheer you up in difficult times 36: The Immense Joy of Fake Reverse Parking</a>
        </h3>
        <p class='item-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Fake reverse parking Update: fake reverse parking is known already as the much debated &#8220;pull-through parking&#8221;. (Thanks to Gali Weinstein over Facebook for telling me about it.) It is also mentioned as #879 among a thousand awesome things by Neil &#8230; Continue reading &#8594;
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p></p>


<p><img loading="lazy" data-attachment-id="23155" data-permalink="https://gilkalai.wordpress.com/2022/08/11/to-cheer-you-up-in-difficult-times-36-the-immense-joy-of-fake-reverse-parking/frp9/" data-orig-file="https://gilkalai.files.wordpress.com/2022/08/frp9.png" data-orig-size="1051,668" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="frp9" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/08/frp9.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/08/frp9.png?w=640" class="alignnone size-full wp-image-23155" src="https://gilkalai.files.wordpress.com/2022/08/frp9.png" alt="frp9" width="1051" height="668" srcset="https://gilkalai.files.wordpress.com/2022/08/frp9.png 1051w, https://gilkalai.files.wordpress.com/2022/08/frp9.png?w=150&amp;h=95 150w, https://gilkalai.files.wordpress.com/2022/08/frp9.png?w=300&amp;h=191 300w, https://gilkalai.files.wordpress.com/2022/08/frp9.png?w=768&amp;h=488 768w, https://gilkalai.files.wordpress.com/2022/08/frp9.png?w=1024&amp;h=651 1024w" sizes="(max-width: 1051px) 100vw, 1051px" /></p>
<h3 style="text-align:center;"><strong><span style="color:#ff0000;">Fake reverse parking</span></strong></h3>
<p><strong>Update</strong>: fake reverse parking is known already as <a href="//vancouverisland.ctvnews.ca/should-you-pull-through-in-parking-lots-experts-divided-1.4269504">the much debated &#8220;pull-through parking&#8221;</a>. (Thanks to Gali Weinstein over Facebook for telling me about it.) It is also mentioned as <a href="http://1000awesomethings.com/2008/12/08/879-the-parking-lot-pull-through/">#879 among a thousand awesome things</a> by Neil Pasricha.</p>
<p>When I was young my mother <a href="https://gilkalai.wordpress.com/2015/08/02/carmella-kalai-1926-2015/">Carmela Kalai</a> told me: &#8220;Always remember, Gili,  how wonderful movies are and how happy I was to be born in the era of movies.&#8221; My father <a href="https://en.wikipedia.org/wiki/Hanoch_Kalai">Hanoch Kalai</a> told me: &#8220;Everything is interesting! Every subject, no matter how marginal and unimportant or boring it may look to you, Gil, when you study it in depth you will find it fascinating!&#8221;</p>
<p>One thing I tell my children is: &#8220;Remember the joy of fake reverse parking!&#8221;</p>
<p>Let me tell you in this post what fake reverse parking is:</p>
<h2>Fake-reverse parking</h2>
<p>The brief explanation is simple: when there are two (<strong>unoccupied</strong>) parking spaces, one after the other, you drive forward, pass one of the parking lots and locate your car in the second parking lot.</p>
<p>The general law about parking is this: forward parking is often easier than reverse parking but it is often harder afterwards to drive your car away. Reverse parking is harder than forward parking but later it is easier to get out and drive away. Fake reverse driving is easier than both and it is just as easy as ordinary reverse parking when it comes to leaving your parking place and driving away.<span id="more-21813"></span></p>
<h3><img loading="lazy" data-attachment-id="23147" data-permalink="https://gilkalai.wordpress.com/2022/08/11/to-cheer-you-up-in-difficult-times-36-the-immense-joy-of-fake-reverse-parking/frp5/" data-orig-file="https://gilkalai.files.wordpress.com/2022/08/frp5.png" data-orig-size="1000,664" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="frp5" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/08/frp5.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/08/frp5.png?w=640" class="alignnone size-full wp-image-23147" src="https://gilkalai.files.wordpress.com/2022/08/frp5.png" alt="frp5" width="1000" height="664" srcset="https://gilkalai.files.wordpress.com/2022/08/frp5.png 1000w, https://gilkalai.files.wordpress.com/2022/08/frp5.png?w=150&amp;h=100 150w, https://gilkalai.files.wordpress.com/2022/08/frp5.png?w=300&amp;h=199 300w, https://gilkalai.files.wordpress.com/2022/08/frp5.png?w=768&amp;h=510 768w" sizes="(max-width: 1000px) 100vw, 1000px" /></h3>
<h3><span style="color:#ff0000;"><strong>Ordinary reverse parking</strong></span></h3>
<h3> </h3>
<h3><img loading="lazy" data-attachment-id="23148" data-permalink="https://gilkalai.wordpress.com/2022/08/11/to-cheer-you-up-in-difficult-times-36-the-immense-joy-of-fake-reverse-parking/frp3/" data-orig-file="https://gilkalai.files.wordpress.com/2022/08/frp3.png" data-orig-size="1051,668" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="frp3" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/08/frp3.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/08/frp3.png?w=640" class="alignnone size-full wp-image-23148" src="https://gilkalai.files.wordpress.com/2022/08/frp3.png" alt="frp3" width="1051" height="668" srcset="https://gilkalai.files.wordpress.com/2022/08/frp3.png 1051w, https://gilkalai.files.wordpress.com/2022/08/frp3.png?w=150&amp;h=95 150w, https://gilkalai.files.wordpress.com/2022/08/frp3.png?w=300&amp;h=191 300w, https://gilkalai.files.wordpress.com/2022/08/frp3.png?w=768&amp;h=488 768w, https://gilkalai.files.wordpress.com/2022/08/frp3.png?w=1024&amp;h=651 1024w" sizes="(max-width: 1051px) 100vw, 1051px" /></h3>
<h3><span style="color:#ff0000;"><strong>Fake reverse parking</strong> </span></h3>
<p>As you can see and feel by looking at the pictures, fake reverse parking is much easier than ordinary reverse parking and allows you to achieve the same results. As a matter of fact, fake reverse parking is even easier than ordinary forward parking.</p>
<h3><img loading="lazy" data-attachment-id="23152" data-permalink="https://gilkalai.wordpress.com/2022/08/11/to-cheer-you-up-in-difficult-times-36-the-immense-joy-of-fake-reverse-parking/frp7/" data-orig-file="https://gilkalai.files.wordpress.com/2022/08/frp7.png" data-orig-size="954,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="frp7" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/08/frp7.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/08/frp7.png?w=640" class="alignnone size-full wp-image-23152" src="https://gilkalai.files.wordpress.com/2022/08/frp7.png" alt="frp7" width="954" height="600" srcset="https://gilkalai.files.wordpress.com/2022/08/frp7.png 954w, https://gilkalai.files.wordpress.com/2022/08/frp7.png?w=150&amp;h=94 150w, https://gilkalai.files.wordpress.com/2022/08/frp7.png?w=300&amp;h=189 300w, https://gilkalai.files.wordpress.com/2022/08/frp7.png?w=768&amp;h=483 768w" sizes="(max-width: 954px) 100vw, 954px" /></h3>
<p><strong><span style="color:#ff0000;">Ordinary forward parking</span></strong></p>
<p><span style="color:#0000ff;">Again, look at the three pictures above and witness for yourself how the pictures of ordinary reverse and ordinary forward parking can make you nervous, while the pictures of fake reverse parking evoke a calm and joyful mood!</span></p>
<h3><span style="color:#ff00ff;"><strong>Caution in parking is advised!</strong></span></h3>
<p>Like many other joyous activities, some warnings are in place. In any kind of parking, it is a mistake to park your car in a parking place which is already occupied by another car. <strong>For fake reverse parking make sure that there is no simultaneous attempt by another driver to park, using the ordinary reverse parking method inthe same parking space.</strong></p>
<h2>Fake-fake reverse parking?</h2>
<p>One day I went with my youngest son Lior to some parking lot near Rehovot. (Here is a lovely post based on a question of Lior <a href="https://gilkalai.wordpress.com/2019/03/18/tyi38-lior-kalai-monty-hall-meets-survivor/" rel="bookmark">TYI38 Lior Kalai: Monty Hall Meets Survivor</a>.) It was a large parking lot and it was completely empty.  When I parked my son asked me &#8220;why didn&#8217;t you opt for fake reverse parking?&#8221; &#8220;Well&#8221;, I said &#8220;what I did is actually a &#8216;fake-fake reverse parking&#8217;. Later, when the parking space fills up, people will assume that I made a fake-reverse parking. But this was too easy with no cars around so my parking was actually a &#8216;fake-fake-reverse parking&#8217;, aimed at giving a feeling of fake reverse parking, while in reality it is not&#8221;. Lior, thought about it for a minute and then said: &#8220;Daddy, this is complete nonsense! There is no such thing as a &#8216;fake-fake reverse parking&#8217;. What you did is a simple reverse parking!&#8221;</p>
<p>&#8220;Well&#8221;, I thought, &#8220;it is good that my children are skeptical about things I tell them, and shoot down incorrect or silly ideas that I raise.&#8221; Moreover, quickly dismissing my idea about a &#8220;fake-fake reverse parking&#8221; strengthens the value of my classic idea about the importance and joy in ordinary fake reverse parking. Still, I was somewhat sad that my novel idea of fake-fake reverse parking was shot down so quickly. Maybe it has some deep meaning after all?</p>
<p> </p>
<p style="text-align:center;"><span style="color:#ff0000;"><strong>an especially magical opportunity for fake reverse parking</strong></span></p>
<p><img loading="lazy" data-attachment-id="23171" data-permalink="https://gilkalai.wordpress.com/2022/08/11/to-cheer-you-up-in-difficult-times-36-the-immense-joy-of-fake-reverse-parking/ftp11/" data-orig-file="https://gilkalai.files.wordpress.com/2022/08/ftp11.png" data-orig-size="1032,652" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ftp11" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/08/ftp11.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/08/ftp11.png?w=640" class="alignnone size-full wp-image-23171" src="https://gilkalai.files.wordpress.com/2022/08/ftp11.png" alt="ftp11" width="1032" height="652" srcset="https://gilkalai.files.wordpress.com/2022/08/ftp11.png 1032w, https://gilkalai.files.wordpress.com/2022/08/ftp11.png?w=150&amp;h=95 150w, https://gilkalai.files.wordpress.com/2022/08/ftp11.png?w=300&amp;h=190 300w, https://gilkalai.files.wordpress.com/2022/08/ftp11.png?w=768&amp;h=485 768w, https://gilkalai.files.wordpress.com/2022/08/ftp11.png?w=1024&amp;h=647 1024w" sizes="(max-width: 1032px) 100vw, 1032px" /></p>


<p></p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-11T13:01:09Z">6 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Wednesday, August 10
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://processalgebra.blogspot.com/2022/08/concur-through-time-data-and-graph.html'>CONCUR through time: A data- and graph-mining analysis</a>
        </h3>
        <p class='item-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>The 33rd edition of the International Conference on Concurrency Theory (CONCUR) will be held in Warsaw, Poland, in the period 16–19 September 2022. The first CONCUR conference dates back to 1990 and was one of the conferences organized as part of the two-year ESPRIT Basic&nbsp; Research&nbsp; Action&nbsp; 3006&nbsp; with&nbsp; the&nbsp; same&nbsp; name.&nbsp;&nbsp; The&nbsp; CONCUR&nbsp; communi
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The <a href="https://concur2022.mimuw.edu.pl/" target="_blank">33rd edition of the International Conference on Concurrency Theory (CONCUR</a>) will be held in Warsaw, Poland, in the period 16–19 September 2022. The first CONCUR conference dates back to 1990 and was one of the conferences organized as part of the two-year <a href="https://pure.tue.nl/ws/portalfiles/portal/4345371/589768.pdf" target="_blank">ESPRIT Basic&nbsp; Research&nbsp; Action&nbsp; 3006</a>&nbsp; with&nbsp; the&nbsp; same&nbsp; name.&nbsp;&nbsp; The&nbsp; CONCUR&nbsp; community&nbsp; has&nbsp; run&nbsp; the conference ever since and established the <a href="https://concurrency-theory.org/organizations/ifip" target="_blank">IFIP WG 1.8 “Concurrency Theory”</a> in 2005 under Technical Committee TC1 Foundations of Computer Science of IFIP1.</p><p>In light of the well-established nature of the CONCUR conference, and spurred by a <a href="https://slides.com/piluc/icalp-50?token=fl3BBJ8j" target="_blank">data-and graph-mining comparative analysis</a> carried out by Pierluigi Crescenzi and three of his students to celebrate the 50th anniversary of ICALP, Pierluigi and I undertook a similar study for the CONCUR conference using some, by now classic, tools from network science.&nbsp; Our goal was to try and understand the evolution of the CONCUR conference throughout its history, the ebb and flow in the popularity of some research areas in concurrency theory, and the centrality of CONCUR authors, as measured by several metrics from network science, amongst other topics.&nbsp;</p><p>Our article available <a href="http://www.icetcs.ru.is/luca/CONCUR.pdf" target="_blank">here</a> reports on our findings.&nbsp; We hope that members of the CONCUR community will enjoy reading it and playing with the web-based resources that accompany this piece.&nbsp; It goes without saying that the data analysis we present has to be taken with a huge pinch of salt and is only meant to provide an overview of the evolution of CONCUR and to be food for thought for the concurrency theory community. <br /></p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-10T13:55:00Z">7 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Tuesday, August 09
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://thmatters.wordpress.com/2022/08/09/nas-held-prize-call-for-nominations/'>NAS Held Prize: Call for nominations</a>
        </h3>
        <p class='item-feed'>from <a href='https://thmatters.wordpress.com'>Theory Matters</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          From chair of the committee, Dan Spielman:Nominations are now being accepted for the National Academy of Sciences’ 2023 Michael and Sheila Held Prize. The Held Prize honors outstanding, innovative, creative, and influential research in the areas of combinatorial and discrete optimization, or related parts of computer science, such as the design and analysis of algorithms [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>From chair of the committee, Dan Spielman:<br>Nominations are now being accepted for the National Academy of Sciences’ 2023 Michael and Sheila Held Prize. The Held Prize honors outstanding, innovative, creative, and influential research in the areas of combinatorial and discrete optimization, or related parts of computer science, such as the design and analysis of algorithms and complexity theory. This $100,000 prize is intended to recognize recent work (defined as published within the last eight years). Additional information, including past recipients, eligibility requirements, and more, can be found at <a rel="noreferrer noopener" href="http://www.nasonline.org/held" target="_blank">http://www.nasonline.org/held</a> </p>



<p>All nominations must be submitted online. Unless otherwise stated, the following materials must be submitted:&nbsp;</p>



<ol><li><strong>A letter from the nominator&nbsp;</strong><em>describing the candidate&#8217;s work and why he or she should be selected for the award. No more than three (3) pages.</em></li><li><strong>Curriculum vitae</strong>.&nbsp;<em>No more than two (2) pages (similar to CVs included with NSF proposals).</em></li><li><strong>Bibliography&nbsp;</strong><em>listing no more than twelve (12) of the nominee&#8217;s most significant publications.</em></li><li><strong>Suggested citation</strong><em>. A 50-word summary stating why the nominee should be considered for this award</em>. (Citation<br>examples)</li><li><strong>Two letters of support</strong>.&nbsp;<em>Support letters must be written by individuals from institutions outside both the</em><br><em>nominator&#8217;s and the nominee’s institution. Up to three letters of support are accepted.</em></li></ol>



<p>Nominations will be accepted through&nbsp;<strong>Monday, October 3, 2022</strong>. Please help spread the word that the nomination process is underway.&nbsp;</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-09T17:31:06Z">8 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://processalgebra.blogspot.com/2022/08/interview-with-kim-g-larsen-concur-2022.html'>Interview with Kim G. Larsen, CONCUR 2022 ToT Award Recipient</a>
        </h3>
        <p class='item-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>This post is devoted to an interview with Kim G. Larsen, who received the CONCUR 2022 Test-of-Time Award for the paper The Impressive Power of Stopwatches (available also here), which appeared at CONCUR 2000 and was co-authored with Franck Cassez. On behalf of the concurrency theory community, I thank Kim for taking the time to answer my questions. I trust that readers of this blog will enjoy re
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="MsoNormal">This post is devoted to an interview with <a href="https://homes.cs.aau.dk/~kgl/" target="_blank">Kim G. Larsen</a>, who received the <a href="https://concur2022.mimuw.edu.pl/tot-award/" target="_blank">CONCUR 2022 Test-of-Time Award</a> for the paper <a href="https://link.springer.com/content/pdf/10.1007/3-540-44618-4_12.pdf" target="_blank">The Impressive Power of Stopwatches</a> (available also <a href="https://www.researchgate.net/publication/220701029_The_Impressive_Power_of_Stopwatches" target="_blank">here</a>), which appeared at CONCUR 2000 and was co-authored with <a href="https://franck44.github.io/" target="_blank">Franck Cassez</a>. On behalf of the concurrency theory community, I thank Kim for taking the time to answer my questions. I trust that readers of this blog will enjoy reading Kim's answer as much as I did.&nbsp;<span class="im"></span></p><p class="MsoNormal"><b><span lang="EN-US">Luca</span></b><span lang="EN-US">: You receive the CONCUR ToT Award 2022 for your paper &nbsp;The Impressive Power of Stopwatches, which appeared at CONCUR 2000. </span>In that article, you showed that timed automata enriched with  stopwatches and unobservable time delays have the same expressive power  of &nbsp;linear hybrid automata. Could you briefly explain to our readers  what timed automata with stopwatches are? Could  you also tell us how you came to study the question addressed in your  award-winning article? Which of the results in your paper did you find  most surprising or challenging?</p><p class="MsoNormal"><b>Kim:</b> <span class="im"></span><span lang="EN-US">Well, in timed automata all  clocks grow with rate 1 in all locations of the automata. Thus you can  tell the amount of time that has elapsed since a particular clock was  last reset, e.g. due to an external event of interest.&nbsp;  A stopwatch is a real-valued variable similar to a regular clock.&nbsp; In  contrast to a clock, a stopwatch will in certain locations grow with  rate 1 and in other locations grow with rate 0, i.e. it is stopped.&nbsp; As  such, a stopwatch gives you information about  the accumulated time spent in a certain parts of the automata.&nbsp; </span></p><p></p><p class="MsoNormal"><span lang="EN-US"></span><span lang="EN-US">In modelling schedulability  problems for real-time systems, the use of stopwatches is crucial in  order to adequately capture preemption.&nbsp; &nbsp;I definitely believe that it  was our shared interest in schedulability that brought  us to study timed automata with stopwatches.&nbsp; We knew from earlier  results by Alur et al. that properties such as reachability was  undecidable. But what could we do about this? And how much expressive  power would the addition of stopwatches provide?</span></p><p class="MsoNormal"><span lang="EN-US"></span><span lang="EN-US">In the paper we certainly put the  most emphasis on the latter question, in that we showed that stopwatch  automata and linear hybrid automata accept the same class of timed  languages, and this was at least for me the most  surprising and challenging result. However, focusing on impact,  I think the approximate zone-based method that we apply in the paper  has been extremely important from the point of view of having our  verification tool <a href="https://uppaal.org/" target="_blank">UPPAAL</a> being taken-up at large  by the embedded systems community.&nbsp; It has been really interesting to  see how well the over-approximation method actually works.</span><span class="im"></span></p><span class="im"><p class="MsoNormal"><b><span lang="EN-US">Luca</span></b><span lang="EN-US">: In your article, you showed that linear hybrid automata and stopwatch automata accept the same class of timed languages. </span>Would this result still hold if all delays were observable? Do  the two models have the same expressive power with respect to finer  notions of equivalence such as timed bisimilarity, say? Did you, or any  other colleague, study that problem, assuming that  it is an interesting one?</p><p class="MsoNormal"><b>Kim:</b>&nbsp; <span class="im"></span><span lang="EN-US">These are definitely very  interesting questions, and should be studied.&nbsp; As for finer notions of  equivalences – e.g. timed bisimilarity – I believe that our translation  could be shown to be correct up to some timed variant  of chunk-by-chunk simulation introduced by Anders Gammelgaard in his  <a href="https://tidsskrift.dk/daimipb/article/view/6611/5733" target="_blank">Licentiat Thesis</a> from Aarhus University in 1991.&nbsp; That could be a good starting point<b>.</b></span><span class="im"></span><span class="im"></span></p></span><span class="im"><p class="MsoNormal"><span lang="EN-US"><br /><b>Luca</b>: Did any of your subsequent research build explicitly on the  results and the techniques you developed in your award-winning paper? </span>Which of your subsequent results on timed and hybrid automata do  you like best? Is there any result obtained by other researchers that  builds on your work and that you like in particular or found surprising?<br /><br /></p><p class="MsoNormal"><b>Kim:&nbsp;</b> <span lang="EN-US">Looking up in <a href="https://dblp.org/pid/l/KimGuldstrandLarsen.html" target="_blank">DBLP,</a> I see that I  have some 28 papers containing the word “scheduling”.&nbsp; For sure  stopwatches will have been used in one way or another in these.&nbsp; One  thing that we never really examined thoroughly is to  investigate how well the approximate zone-based will worked when  applied to the translation of linear hybrid automata through the translation to stopwatch automata.&nbsp; This  would definitely be interesting to find out.&nbsp; </span></p></span> <span class="im"></span><p class="MsoNormal"><span lang="EN-US">This was the first joint publication between me and Franck.&nbsp; </span><span lang="EN-US">I enjoyed fully the collaboration on all the  next 10 joint papers.&nbsp; Here the most significant ones are probably the  <a href="https://doi.org/10.1007/11539452_9" target="_blank">paper at CONCUR 2005</a>, where we presented the symbolic on-the-fly  algorithms for synthesis for timed games and the branch  UPPAAL TIGA.&nbsp; And later in a European project GASICS with Jean-Francois  Raskin, we used the TIGA in the synthesis of optimal and robust control  of a hydraulic system.&nbsp; </span><span lang="EN-US"></span></p><span class="im"> <p class="MsoNormal"><b><span lang="EN-US">Luca</span></b><span lang="EN-US">:  &nbsp;Could you tell us how you started your collaboration on the  award-winning paper? I recall that Franck was a regular visitor to our  department at Aalborg University for some time,  but I can't recall how his collaboration with the Uppaal group started.  &nbsp;</span></p><p class="MsoNormal"><span lang="EN-US"><b>Kim:</b> </span><span class="im"></span><b><span lang="EN-US"></span></b><span lang="EN-US">I am not quite sure I remember  how and when I first met Franck.&nbsp; For some time we already worked  substantially with French researchers, in particular from LSV Cachan  (Francois Larroussinie and Patricia Bouyer). &nbsp;&nbsp;I have  the feeling that there were quite some strong links between Nantes  (were Franck was) and LSV on timed systems in those days.&nbsp; Also Nantes  was the organizer of the PhD school MOVEP five times in the period  1994-2002, and I was lecturing there in one of the  years, meeting Olivier Roux and Franck who were the organizers.&nbsp;&nbsp;  Funny enough, this year we are organizing <a href="https://movep2022.cs.aau.dk/" target="_blank">MOVEP</a> in Aalborg. Anyway, at some point Franck became a  regular visitor to Aalborg, often for long periods  of time – playing on the Squash team of the city when he was not  working.</span><span class="im"></span><span class="im"></span><span lang="EN-US"></span></p><p class="MsoNormal"><span lang="EN-US"><br /><b>Luca</b>: What are the research topics that you find most interesting right now? </span>Is there any specific problem in your current field of interest that you'd like to see solved?</p></span><span class="im"><p class="MsoNormal"><b>Kim:</b> <span class="im"></span><span lang="EN-US">Currently I am spending quite  some time on marrying symbolic synthesis with reinforcement learning for  Timed Markov Decision Processes in order to achieve optimal as well as safe strategies for  Cyber-Physical Systems.</span><span class="im"></span><span class="im"></span><span lang="EN-US"></span></p><p class="MsoNormal"><span lang="EN-US"><br /><b>Luca</b>: Both Franck and you have a very strong track record in developing theoretical results and in applying them to real-life problems. </span>In my, admittedly biased, opinion, your work exemplifies Ben Schneiderman's Twin-Win Model (<a data-saferedirecturl="https://www.google.com/url?q=https://www.pnas.org/doi/pdf/10.1073/pnas.1802918115&amp;source=gmail&amp;ust=1660131834210000&amp;usg=AOvVaw3C8MqXrhHOcBM8hIz-QekT" href="https://www.pnas.org/doi/pdf/10.1073/pnas.1802918115" target="_blank">https://www.pnas.org/doi/pdf/<wbr></wbr>10.1073/pnas.1802918115</a>),  which propounds the pursuit of "the  dual goals of breakthrough theories in published papers and validated  solutions that are ready for widespread dissemination." Could you say a  few words on your research philosophy? </p></span><span class="im"><p class="MsoNormal"><b>Kim:</b> <span class="im"></span><span lang="EN-US">I completely subscribe to this.&nbsp;  Several early theoretically findings – as the paper on stopwatch  automata – have been key in our sustainable transfer to industry.</span><span class="im"></span><span class="im"></span><span lang="EN-US"></span></p><p class="MsoNormal"><span lang="EN-US"><br /><b>Luca</b>: What advice would you give to a young researcher who is keen to start working on topics related to formal methods? </span></p></span><span class="im"><p class="MsoNormal"><span lang="EN-US">&nbsp;</span></p></span><p class="MsoNormal"><b><span lang="EN-US">Kim: </span></b><span lang="EN-US">Come to Aalborg, and participate in year's MOVEP.</span></p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-09T12:17:00Z">8 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Monday, August 08
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://blog.computationalcomplexity.org/2022/08/the-godfather-of-complexity.html'>The Godfather of Complexity</a>
        </h3>
        <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          ♦Juris Hartmanis 1928-2022<br>On Friday, July 29th, I was in the immigration line at an airport in Mexico. My phone rang with Bill Gasarch on the Caller ID but starting vacation I declined the call. The voicemail gave me the sad news that Juris Hartmanis, the person who founded computational complexity and brought me into it passed away earlier that day. I messaged Bill and told him to write an obi
        
        </div>

        <div class='item-content item-summary'>
        
          
          <table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://news.cornell.edu/sites/default/files/styles/story_thumbnail_xlarge/public/rmc2005_0803-cornell-library-archive-a_0.jpg?itok=aVzB0Cnw" style="margin-left: auto; margin-right: auto;"><img border="0" data-original-height="450" data-original-width="800" height="225" src="https://news.cornell.edu/sites/default/files/styles/story_thumbnail_xlarge/public/rmc2005_0803-cornell-library-archive-a_0.jpg?itok=aVzB0Cnw" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Juris Hartmanis 1928-2022</td></tr></tbody></table><br />On Friday, July 29th, I was in the immigration line at an airport in Mexico. My phone rang with Bill Gasarch on the Caller ID but starting vacation I declined the call. The voicemail gave me the sad news that Juris Hartmanis, the person who founded computational complexity and brought me into it passed away earlier that day. I messaged Bill and told him to write <a href="https://blog.computationalcomplexity.org/2022/07/juris-hartmanis-passed-away-on-july-29.html">an obit</a> and I'd follow with something personal when I returned.<br /><br /><div style="text-align: center;"><br /></div><div><table cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-sMoKiQvVwB8/VVEMTLT-beI/AAAAAAAA2VQ/LMLeAxFklRg/s1600/GE.jpg" style="clear: right; margin-bottom: 1em; margin-left: auto; margin-right: auto;"><img border="0" height="281" src="http://1.bp.blogspot.com/-sMoKiQvVwB8/VVEMTLT-beI/AAAAAAAA2VQ/LMLeAxFklRg/s400/GE.jpg" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Hartmanis and Stearns in 1963</td></tr></tbody></table><div><br /></div><div>In November 1962 Hartmanis, working with Richard Stearns at the GE Labs in Schenectady, determined how to use Turing machines to formalize the basic idea to measure resources, like time and memory, as a function of the problem being solved. Their classic Turing-award winning paper&nbsp;<a href="https://www.ams.org/journals/tran/1965-117-00/S0002-9947-1965-0170805-7/S0002-9947-1965-0170805-7.pdf">On the Computational Complexity of Algorithms</a>, not only gave this formulation but showed that increasing resources increased the problems one can solve. The photo above, from <a href="https://blog.computationalcomplexity.org/2015/05/fiftieth-anniversary-of-publication-of.html">a post celebrating the 50th anniversary of the paper</a>, shows Hartmanis and Stearns with the main theorem of their paper on the board.</div><div><br /></div><div>Twenty-one years later, a junior at Cornell University still trying to find his way took undergraduate theory from the man himself. Juris brought the topics to life and I found my passion. At the beginning of the class, he said the highest grade usually went to an undergrad followed by the grad students in the class. I was a counterexample, as I had the second highest grade. Never did find out who beat me out.</div><div><br /></div><div>In spring of my senior year, 1985, I forgave the traditional senior-slump <i>Wines</i>&nbsp;for graduate complexity with Juris. He focused the course around the <a href="https://blog.computationalcomplexity.org/2003/03/berman-hartmanis-isomorphism.html">isomorphism conjecture</a> he developed with his student Len Berman, which implied P≠NP, and Hartmanis believed using the conjecture might lead to settling P v NP. He offered an automatic A to anyone who could prove the isomorphism conjecture. I guess any other proof of P≠NP only warranted a B?</div><div><br /></div><div>I would later be obsessed by the isomorphism conjecture as an assistant professor, coming up with not <a href="http://doi.org/10.1137/S0097539793248305">one</a> but <a href="http://doi.org/10.1145/276698.276737">two</a> oracles making it true. The isomorphism conjecture didn't end up settling P vs NP, but then again neither did any other approach.</div><div><br /></div><div>It wasn't just me, there was a reason that many of the great American complexity theorists, including Ryan Williams, Scott Aaronson and my own PhD advisor Michael Sipser, were undergrads at Cornell. <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/hartmanisstud.pdf">Many more</a> were PhD students of Hartmanis.</div><div><br /></div><div>Juris Hartmanis had a certain gravitas in the community. Maybe it was his age, the way he dressed up, his seminal research in the field, or just that Latvian accent. He founded the CS department at Cornell in the 60s and served as head of the CISE directorate at the National Science Foundation in the 90s. His 60th birthday party at the 3rd Structures in Complexity conference (now the Computational Complexity Conference) was the only time I've seen complexity theorists in ties.</div><div><br /></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRPQ7nB0GfMGvRD0sysZK398h6M_WyYoyNQwY2-5Bq5vCQfYpQaHyYnxfc1ZQQI-mvMvRQhTXBmh09tGY0LiszZKF7L_DRPr3wsKueny2Vq3DANV4dvbY4PbI_aCjICb2tXwOCXOsiQzghaoc1aeplK9Txg8OybEtZ_7Se8aGK1Sfo0x9Agg/s354/Hartmanis.png" style="margin-left: auto; margin-right: auto;"><img border="0" data-original-height="256" data-original-width="354" height="231" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRPQ7nB0GfMGvRD0sysZK398h6M_WyYoyNQwY2-5Bq5vCQfYpQaHyYnxfc1ZQQI-mvMvRQhTXBmh09tGY0LiszZKF7L_DRPr3wsKueny2Vq3DANV4dvbY4PbI_aCjICb2tXwOCXOsiQzghaoc1aeplK9Txg8OybEtZ_7Se8aGK1Sfo0x9Agg/s320/Hartmanis.png" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Juris Hartmanis (center) being toasted by Janos Simon</td></tr></tbody></table><br /><div>A few of my favorite Hartmanis quotes.</div><div><ul style="text-align: left;"><li>"We all know P is different than NP. We just don't know how to prove it." - Still true.</li><li>"I only make mistakes in the last five minutes of the class." - Sometimes he made a mistake with ten minutes left but only admit it in the last five minutes.</li><li>"Primality is a problem not yet know to be in P but is hanging on by its fingernails with its grip continuing to loosen each day." - Juris Hartmanis said this in 1986, with primality hanging on for another 16 years.</li></ul></div><div>Thanks Juris for creating the foundations of our field and inspiring so many people, yours truly included, to dedicate ourselves to it.</div><div><br /></div><div>Much more to read:</div><div><ul style="text-align: left;"><li>In 1981 Hartmanis wrote a personal&nbsp;<a href="https://doi.org/10.1109/MAHC.1981.10005">article</a>&nbsp;for the Annals of History of Computing describing the birth of computational complexity and his role in it.</li><li>A CACM interview with Hartmanis gives a <a href="https://cacm.acm.org/magazines/2015/4/184690-an-interview-with-juris-hartmanis/fulltext">personal story</a> of his path from Latvia to Kansas City to Pasadena to Schenectady to Ithaca and DC.</li><li>Obits by <a href="https://news.cornell.edu/stories/2022/08/juris-hartmanis-first-cs-department-chair-dies-94">Cornell</a>,&nbsp;<a href="https://scottaaronson.blog/?p=6622">Ryan Williams</a> and <a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/">Dick Lipton and Ken Regan</a>.</li><li>My old blog posts celebrating&nbsp;<a href="https://blog.computationalcomplexity.org/2018/07/happy-90th-juris.html">Hartmanis' 90th birthday</a>&nbsp;and&nbsp;the <a href="https://blog.computationalcomplexity.org/2015/05/fiftieth-anniversary-of-publication-of.html">50th anniversary of Hartmanis-Stearns</a>,</li><li>And the many retrospectives, remembrances, special issues and conferences to come.</li></ul></div></div>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-08T13:11:00Z">9 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://ptreview.sublinear.info/2022/08/news-for-july-2022/'>News for July 2022</a>
        </h3>
        <p class='item-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Last month saw a flurry of activity in Property Testing. We had thirteen papers!! Without further ado, let us dig in. Testing of Index-Invariant Properties in the Huge Object Model (by Sourav Chakraborty, Eldar Fischer, Arijit Ghosh, Gopinath Mishra, and Sayantan Sen)(arXiv) This paper explores a class of distribution testing problems in the Huge Object [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Last month saw a flurry of activity in Property Testing. We had thirteen papers!! Without further ado, let us dig in.</p>



<p></p>



<p></p>



<p><strong>Testing of Index-Invariant Properties in the Huge Object Model</strong> (by Sourav Chakraborty, Eldar Fischer, Arijit Ghosh, Gopinath Mishra, and Sayantan Sen)(<a href="https://arxiv.org/abs/2207.12514">arXiv</a>) This paper explores a class of distribution testing problems in the Huge Object Model introduced by Goldreich and Ron (see our coverage of the model <a href="https://ptreview.sublinear.info/2021/10/news-for-september-2021/">here</a>). A quick refresher of this model: so, suppose you want to test whether a distribution \(\mathcal{D}\) supported over, say the boolean hypercube \(\{0,1\}^n\) has a certain property \(\mathcal{P}\). You pick a string \(x \sim \mathcal{D}\) where the length of \(x\) is \(n\). In situations where \(n\) is really large, you might not want to read all of \(x\) and you may instead want to read only a few bits from it. To this end, Goldreich and Ron formulated a model where you have query access to the strings you sample. The distribution \(\mathcal{D}\) is deemed to be \(\varepsilon\)-far from \(\mathcal{P}\) if \(EMD(\mathcal{D}, \mathcal{P}) \geq \varepsilon\) (here \(EMD\) denotes the earthmover distance with respect to the relative Hamming distance between bitstrings).  In this model, one parameter of interest is the query complexity of your tester.</p>



<p>One of the results in the featured paper above shows the following: Let \(\sf{MONOTONE}\) denote the class of monotone distributions supported over \(\{0,1\}^n\) (a distribution \(D\)  belongs to the class \(\sf{MONOTONE}\) if \(D(x) \leq D(y)\) whenever \(0^n \preceq x \preceq y \preceq 1^n\)). Let \(\mathcal{B}_d\) denote the class of distributions supported over \(\{0,1\}^n\) whose supports have VC dimension at most \(d\). Let \(\mathcal{P} = \sf{MONOTONE} \cap \mathcal{B}_d\). Then, for any \(\varepsilon > 0\), you can test whether a distribution \(\mathcal{D} \in \mathcal{P}\) or whether it is \(\varepsilon\)  far from \(\mathcal{P}\) with query complexity \(poly(1/\varepsilon)\). In fact, the paper shows this for a much richer class \(\mathcal{P}\) which is the class of so-called <em>index-invariant</em> distributions with bounded VC-dimensions. The paper also shows the necessity of both of these conditions for efficient testability. Do check it out!</p>



<p></p>



<p><strong>Identity Testing for High-Dimensional Distributions via Entropy Tensorization</strong> (by Antonio Blanca, Zongchen Chen, Daniel Štefankovič, and Eric Vigoda)(<a href="https://arxiv.org/abs/2207.09102">arXiv</a>) </p>



<p>This paper considers a classic in distribution testing. Namely, the problem of testing whether the hidden input distribution \(\pi\) is identical to an explicitly given distribution \(\mu\). Both distributions are supported over a set \(\Omega\). The caveat is \(\Omega\) is some high dimensional set (think \(\Omega = [k]^n\)) and that it has a size that grows exponentially in \(n\). In this case, identity testing has sample complexity \(\Omega(k^{n/2})\) even when \(\mu\) is the uniform distribution. In an attempt to overcome this apparent intractability of identity testing in high dimensions, this paper takes the following route: in addition to the standard sample access to \(\pi\), you also assume access to a <em>stronger sampling oracle</em> from \(\pi\). And now you would like to understand for which class of explicitly given distributions \(\mu\) can you expect algorithms with efficient sample complexity (assuming the algorithm is equipped with this <em>stronger sampling oracle</em>). For any \(i \in [n]\) and \(\omega \in \Omega\), the stronger oracle considered in this work allows you to sample \(x \sim \pi_{\omega(-i)}\) where \(\pi_{\omega(-i)}\) denotes the conditional marginal distribution of \(\pi\) over the \(i\)-th coordinate when the remaining coordinates have been fixed according to \(\omega\).</p>



<p>The paper shows if the known distribution \(\mu\) satisfies some approximate tensorization of entropy criterion, then identity testing with such distributions \(\mu\) can be done with \(\tilde{O}(n/\varepsilon)\) queries. Thanks to the spectral independence toolkit pioneered by Anari et al, it turns out that the approximate tensorization property holds for a rich class of distributions. (<em>A side note to self</em>: It looks like I am running out of reasons to postpone learning about the new tools like Spectral Independence.)   </p>



<p></p>



<p><strong>Near-Optimal Bounds for Testing Histogram Distributions</strong> (by Clément L. Canonne, Ilias Diakonikolas, Daniel M. Kane, and Sihan Liu)(<a href="https://arxiv.org/abs/2207.06596">arXiv</a>) Histograms comprise one of the most natural and widely used ways for summarizing some relevant aspects of massive datasets. Let \(\Omega\) denote an \(n\)-element dataset (with elements being \(\{1,2, \ldots, n \}\)). A \(k\)-histogram is a function that is piecewise constant over \(k\) interval pieces. This paper studies the sample complexity of the following fundamental task: given a distribution \(\mathcal{P}\) supported over \(\Omega\), is \(\mathcal{P}\) a \(k\)-histogram or is \(\mathcal{P}\) far from being a \(k\)-histogram. The main result of the paper is a (near) sample optimal algorithm for this problem. Specifically, this paper shows that \(k\)-histogram testing has sample complexity \(\Theta\left(\sqrt{nk}/\varepsilon + k/\varepsilon^2 + \sqrt{n}/\varepsilon^2\right)\).</p>



<p><strong>Comments on &#8220;Testing Conditional Independence of Discrete Distributions&#8221;</strong> (by Ilmun Kim)(<a href="https://arxiv.org/abs/2207.02819">arXiv</a>) Probability is full of subtleties and conditional probability is perhaps the biggest landmine of subtleties in this venerable discipline. The featured paper closely examines some subtleties in Theorem 1.3 of the CDKS18 paper on testing conditional independence of discrete distributions. Essentially, this theorem undertakes the following endeavor: you would like to test whether a bivariate discrete distribution has independent marginals conditioned on values assumed by a third random variable. Theorem 1.3 of CDKS18 asserts that there exists a computationally efficient tester for conditional independence with small sample complexity. The featured paper fixes the sample complexity bound claimed in Theorem 1.3 of CDKS18.</p>



<p></p>



<p><strong>Cryptographic Hardness of Learning Halfspaces with Massart Noise</strong> (by Ilias Diakonikolas, Daniel M. Kane, Pasin Manurangsi, and Lisheng Ren)(<a href="https://arxiv.org/abs/2207.14266">arXiv</a>) The study of robust supervised learning in high dimensions has seen a lot of impressive progress in the last few years. The paper under review presents sample complexity lower bounds for the task of learning halfspaces in this overarching framework. Let us unpack this paper slowly. So, let us recall the classic task of learning halfspaces in \(\mathbb{R}^n\). You know the drill. I have a known concept class \(\mathcal{C}\) (comprising of boolean functions) in my hand. Unbeknownst to you, I have a boolean function \(f \in \mathcal{C}\). You get as input a multiset \(\{x_i, f(x_i)\}_{i \in [s]}\) of labeled examples from a distribution \(\mathcal{D}\) where \(x_i \sim \mathcal{D}_x\) and \(\mathcal{D}_x\) is fixed but arbitrary. Your goal is to develop an algorithm that returns a hypothesis with a small misclassification rate. The classic stuff.</p>



<p>Now, consider the same setup with a little twist: the so-called Massart noise setup. The labels \(f(x_i)\) are no longer reliable and the label on each \(x_i\) gets flipped adversarially with probability \(\eta_i \leq \eta &lt; 1/2\). In a breakthrough Diakonikolas, Gouleakis, and Tzamos made the first algorithmic progress on this problem and gave algorithms with running time \(poly(n/\varepsilon)\) and misclassification rate \(\eta + \varepsilon\). The current paper shows a lower-bound result. Assuming the hardness of the so-called &#8220;Learning With Errors&#8221; problem, this paper shows that under Massart Noise, it is not possible for a polynomial time learning algorithm to achieve a misclassification rate of \(o(\eta)\).</p>



<p></p>



<p><strong>Locally-iterative (Δ+1)-Coloring in Sublinear (in Δ) Rounds</strong> (by Xinyu Fu, Yitong Yin, and Chaodong Zheng)(<a href="https://arxiv.org/abs/2207.14458">arXiv</a>) A time-honored problem in Distributed Computing is Distributed graph coloring. Let us first understand what problem this paper studies. So, you are given a graph \(G = (V,E)\) with maximum degree \(\Delta\). In a seminal work, Szegedy and Vishwanathan introduced the framework of <em>locally-iterative algorithms</em> as a natural family of distributed graph coloring algorithms. These algorithms proceed in \(r\) rounds. In each round, you update the color of a vertex \(v\) where the new color of \(v\) is a function of the current color of \(v\) and the current color of its neighbors. The current paper shows that you can in the locally-iterative framework, you can in fact, obtain a proper coloring of \(G\) with \(\Delta(G) + 1\) colors in \(r = O(\Delta^{3/4} \log \Delta) + \log^* n\) rounds. </p>



<p></p>



<p><strong>Learning Hierarchical Structure of Clusterable Graphs</strong> (by Michael Kapralov, Akash Kumar, Silvio Lattanzi, Aida Mousavifar)(<a href="https://arxiv.org/abs/2207.02581">arXiv</a>) [<em>Disclaimer: I am one of the authors of this paper.</em>] Hierarchical clustering of graph data is a fundamentally important task in the current big data era. In 2016, Dasgupta introduced the notion of Dasgupta cost which essentially allows one to measure the quality of a hierarchical clustering. This paper presents algorithms that can estimate the Dasgupta Cost of a graph coming from a special family of \(k\)-clusterable graphs in the semi-supervised setting. These graphs have \(k\) clusters. These clusters are essentially subsets of vertices that induce expanders and these clusters are sparsely connected to each other. We are given query access to the adjacency list of \(G\). Also, for an initial &#8220;warmup&#8221; set of randomly chosen vertices, we are told the clusters they belong to. Armed with this setup, this paper presents algorithms that run in time \(\approx \sqrt{n}\) and return an estimate to the Dasgupta Cost of \(G\) which is within a \(\approx \sqrt{\log k}\) factor of the optimum cost.</p>



<p></p>



<p><strong>Finding a Hidden Edge</strong> (by Ron Kupfer and Noam Nisan)(<a href="https://arxiv.org/abs/2207.02344">arXiv</a>) Let us consider as a warmup (as done in the paper) the following toy problem. You have a graph on \(n\) vertices whose edge set \(E\) is hidden from you. Your objective is to return any \((i,j) \in E\). The only queries you are allowed are of the following form. You may consider any subset \(Q \subseteq V \times V\) and you can ask whether \(Q\) contains any edge. A simple binary search solves this question with \(\log m\) queries (where \(m = {n \choose 2}\)). However, if you want a non-adaptive algorithm for this problem (unlike binary search) you can show that any deterministic algorithm must issue \(m\) non-adaptive queries. Turns out randomness can help you get away with only \(O(\log^2m)\) non-adaptive queries for this special toy problem. Now, let me describe the problem considered in this work in earnest. Suppose the only queries you are allowed are of the following form: you may pick any \(S \subseteq V\) and you may ask whether the graph induced on \(S\) contains an edge. The paper&#8217;s main result is that there is an algorithm for finding an edge in \(G\) which issues nearly linear in \(n\) many non-adaptive queries. The paper also presents an almost matching lower bound.</p>



<p></p>



<p><strong>On One-Sided Testing Affine Subspaces</strong> (by Nader Bshouty)(<a href="https://eccc.weizmann.ac.il/report/2022/104/">ECCC</a>) Dictatorship testing is one of the classics in property testing of boolean functions. A more generalized problem considers testing whether the presented function is a \(k\)-monomial. If you are a regular reader of the posts on PTReview, you might have seen this problem essentially asks you to test whether a boolean function \(f \colon \mathcal{F}^n \to {0,1}\) is an indicator of an \((n-d)\) dimensional affine/linear subspace of \(\mathcal{F}^n\) (here \(\mathcal{F}\) denotes a finite field). Namely, you would like to test whether the set \(f^{-1}\) is an \((n-k)\) dimensional affine subspace of \(\mathcal{F}^n\). The paper under review improves the state-of-the-art query complexity for this problem from a previous value of \(O\left(|\mathcal{F}|/\varepsilon\right)\) to \(\tilde{O}\left(1/\varepsilon\right)\).</p>



<p></p>



<p><strong>Non-Adaptive Edge Counting and Sampling via Bipartite Independent Set Queries</strong> (by Raghavendra Addanki, Andrew McGregor, and Cameron Musco)(<a href="https://arxiv.org/abs/2207.02817">arXiv</a>) If you have been around the PTReview corner for a while, you know that sublinear time estimation of graph properties is one of our favorite pastimes here. Classic work in this area considers the following queries: vertex degree queries, \(i\)-th neighbor queries, and edge existence queries. This classic query model has received a lot of attention and thanks to the work of Eden and Rosenbaum we know algorithms for near-uniform edge sampling with query complexity \(O(n/\sqrt{m}) \cdot poly(\log n) \cdot poly(1/\varepsilon)\). Motivated by a desire to obtain more query-efficient algorithms, Beame et al. introduced an augmented query model where you are also allowed the following queries: you may pick \(L, R \subseteq V\) and you get a yes/no response indicating whether there exists an edge in \(E(L, R)\). These are also called the bipartite independent set <em>(BIS)</em> queries. The featured paper shows that with (<em>BIS</em>) queries you get <em>non-adaptive</em> algorithms for near-uniform edge sampling with query complexity being a mere \(\widetilde{O}(\varepsilon^{-4} \log^6 n)\). The main result of the paper gives a non-adaptive algorithm for estimating the number of edges in \(G\) with query complexity (under <em>BIS</em>) being a mere \(\widetilde{O}(\varepsilon^{-5} \log^5 n)\).</p>



<p></p>



<p><strong>A Query-Optimal Algorithm for Finding Counterfactuals</strong> (by Guy Blanc, Caleb Koch, Jane Lange, Li-Yang Tan)(<a href="https://arxiv.org/abs/2207.07072">arXiv</a>) Given an abstract space \(X^d\), an instance \(x^* \in X^d\) and a model \(f\) (which you think of as a boolean function over \(X^d\)), a point \(x&#8217; \in X^d\) is called a counterfactual to \(x^*\) if \(x^*, x&#8217;\) differ in few features (i.e., have a small Hamming distance) and \(f(x^*) \neq f(x&#8217;)\). Ideally, you would like to find counterfactuals that are as close to each other in Hamming Distance. The main result of this paper is the following: Take a monotone model \(f \colon \{0,1\}^d \to \{0,1\}\), an instance \(x^* \in \{0,1\}^d\) with small sensitivity (say \(\alpha\)). Then there exists an algorithm that makes at most \(\alpha^{\Delta(x^*)}\) queries to \(f\) and returns all optimal counterfactuals of \(f\). Here \(\Delta(x^*) = \min_{x \in \{0,1\}^d} \{\Delta_H(x, x^*) \colon f(x) \neq f(x^*) \}\). The paper also proves a matching lower bound on query complexity which is obtained by some monotone model \(f\).</p>



<p></p>



<p><strong>A Sublinear-Time Quantum Algorithm for Approximating Partition Functions</strong> (by Arjan Cornelissen and Yassine Hamoudi)(<a href="https://arxiv.org/abs/2207.08643">arXiv</a>) For the classical Hamiltonian \(H \colon \Omega \to \{0,1, \ldots, n\}\), at inverse temperature \(\beta\), the probability, under the so-called Gibbs distribution, assigned to a state \(x \in \Omega\) is proportional to \(\exp(-\beta H(x))\). The partition function is given by \(Z(\beta) = \sum_{x \in \Omega} \exp(-\beta H(x))\). At high temperatures (or low values of \(\beta\)) the partition function is typically easy to compute. However, the low-temperature regime is often challenging. You use MCMC methods to compute \(Z(\infty)\). In particular, you write this as the following telescoping product \(Z(\infty) = Z(0) \cdot \prod_{i = 0}^{i = \ell &#8211; 1} \frac{Z(\beta_{i+1})}{Z(\beta_i)}\) where \(0 = \beta_1 &lt; \beta_2 &lt; \ldots &lt; \beta_{\ell} = \infty\) is some increasing sequence of inverse temperatures with limited fluctuations in Gibbs distribution between two consecutive values and you use MCMC methods to estimate each of the \(\ell\) ratios in the above product. The main result of this paper presents a quantum algorithm that on input a Gibbs distribution generated by a Markov Chain with a large spectral gap performs sublinearly few steps (in size of the logarithm of the state space) of the quantum walk operator and returns a \(\pm \varepsilon Z(\infty)\) additive estimate to \(Z(\infty)\).</p>



<p></p>



<p><strong>A Near-Cubic Lower Bound for 3-Query Locally Decodable Codes from Semirandom CSP Refutation</strong> (by Omar Alrabiah, Venkatesan Guruswami, Pravesh Kothari, and Peter Manohar)(<a href="https://eccc.weizmann.ac.il/report/2022/101/">ECCC</a>) If you made it till here, it is time for a treat. Let us close (hopefully, I did not miss any papers this time!) with a breakthrough in Locally Decodable Codes. So, for 2-query LDCs, we know fairly tight bounds on the block length. For 3-query LDCs, on the other hand, we know a sub-exponential upper bound on the block length. However, the best-known lower bound on the block length was merely quadratic. The featured paper improves this to a cubic lower bound on the block length. The main tool used to achieve this is a surprising connection between the existence of locally decodable codes and the refutation of Boolean CSP instances with limited randomness. This looks like a fantastic read to close off this month&#8217;s report!</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-08T08:53:09Z">9 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Sunday, August 07
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://blog.computationalcomplexity.org/2022/08/the-held-prize-for-comb-opt-and-disc.html'>The Held Prize for comb. opt. AND Disc Opt AND Alg AND Complexity theory AND related parts of CS.</a>
        </h3>
        <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>&nbsp;Dan Spielman asked me to blog about the Held Prize. I first present what he send me, and then have some thoughts.</p><p><br></p><p>FROM DAN:&nbsp;</p><p>--------------------------------------------------------------------------------------------------</p><p>Nominations are now being accepted for the National Academy of Sciences’ 2023 Michael and Sheila Held Prize. The Held Prize honors out
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>&nbsp;Dan Spielman asked me to blog about the Held Prize. I first present what he send me, and then have some thoughts.</p><p><br /></p><p>FROM DAN:&nbsp;</p><p>--------------------------------------------------------------------------------------------------</p><p>Nominations are now being accepted for the National Academy of Sciences’ 2023 Michael and Sheila Held Prize. The Held Prize honors outstanding, innovative, creative, and influential research in the areas of combinatorial and discrete optimization, or related parts of computer science, such as the design and analysis of algorithms and complexity theory. This $100,000 prize is intended to recognize recent work (defined as published within the last eight years). Additional information, including past recipients, eligibility requirements, and more, can be found at&nbsp;<a href="http://www.nasonline.org/programs/awards/michael-and-sheila-held-prize.html">here</a>.</p><p>All nominations must be submitted online. Unless otherwise stated, the following materials must be submitted:&nbsp;</p><p>A letter from the nominator describing the candidate's work and why he or she should be selected for the award. No more than three (3) pages.</p><p>Curriculum vitae. No more than two (2) pages (similar to CVs included with NSF proposals).</p><p>Bibliography listing no more than twelve (12) of the nominee's most significant publications.</p><p>Suggested citation. A 50-word summary stating why the nominee should be considered for this award. (Citation</p><p>examples)</p><p>Two letters of support. Support letters must be written by individuals from institutions outside both the</p><p>nominator's and the nominee’s institution. Up to three letters of support are accepted.</p><p>Nominations will be accepted through Monday, October 3, 2022. Please help spread the word that the nomination process is underway.&nbsp;</p><p>----------------------------------------------------------------------------------------------------</p><p>BILL COMMENTS</p><p>1) The scope seems rather broad (Dan confirmed this in private email) in that its Comb Opt AND Discrete Opt OR related fields like algorithms and complexity theory.&nbsp;</p><p>2) The research has to be Outstanding AND Innovative AND creative AND influential. That seems hard to do :-(&nbsp; If they made it an OR instead of an AND I may ask someone to nominate me for my Muffin Work. It does use 0-1 programming!</p><p>3) The past winners are, of course, very impressive. But there is one I want to point out to emphasize that the scope is broad: Amit Sahai won in 2022, and here is what the webpage says about it:</p><p>For a leading role in development of cryptographic Software Obfuscation and its applications, starting from initial conception of "Indistinguishability Obfuscation" and culminating in new constructions based upon well-founded cryptographic assumptions. These breakthroughs highlight how computational complexity can enable secrecy while computing in insecure environments.</p><p>4) Comb Opt and Discrete Opt seem to be Operations Research. So this inspires the following question:</p><p><i>What are the similarities and differences between Operations Research and Research on Algorithms?</i>&nbsp;</p><p>I tend to think of Operations Research&nbsp; as being more tied to the real world- but is that true?</p><p>5) Not enough 2-letter combinations&nbsp; for what you want to say: I had to use the term <i>Operations Research&nbsp;</i>instead of the abbreviation OR since I was using OR for or. Oh well.&nbsp;</p><p><br /></p><p><br /></p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-07T12:21:00Z">10 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Saturday, August 06
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://gilkalai.wordpress.com/2022/08/06/ordinary-computers-can-beat-googles-quantum-computer-after-all/'>Ordinary computers can beat Google’s quantum computer after all</a>
        </h3>
        <p class='item-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Science magazine has an article written by Adrian Cho Ordinary computers can beat Google’s quantum computer after all. It is about the remarkable progress in classical simulations of sampling task like those sampling tasks that led to the 2019 Google&#8217;s &#8230; Continue reading &#8594;
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p></p>


<p>Science magazine has an article written by Adrian Cho <a href="https://www.science.org/content/article/ordinary-computers-can-beat-google-s-quantum-computer-after-all">Ordinary computers can beat Google’s quantum computer after all</a>. It is about the remarkable progress in classical simulations of sampling task like those sampling tasks that led to the 2019 Google&#8217;s announcement of &#8220;quantum supremacy&#8221;. I reported about the breakthrough paper of Feng Pan and Pan Zhang <a href="https://gilkalai.wordpress.com/2021/03/10/amazing-feng-pan-and-pan-zhang-announced-a-way-to-spoof-classically-simulate-the-googles-quantum-supremacy-circuit/">in this post</a> and there are updates in the post itself and the comment section about a variety of related works by several groups of researchers.</p>
<p>The very short summary is that by now classical algorithms are ten orders of magnitude faster than those used in the Google paper and hence the speed-up is ten orders of magnitude lower than Google&#8217;s fantastic claims. (The Google paper claims that their ultimate task that required 300 seconds for the quantum computer will require 10,000 years on a powerful supercomputers. with the new algorithms the task can be done in a matter of seconds.)</p>
<p>Also regarding the Google supremacy paper, my paper with Yosi Rinott and Tomer Shoham,  <a href="https://gilkalai.files.wordpress.com/2022/08/sts836.pdf">Statistical Aspects of the Quantum Supremacy Demonstration,</a> just appeared in &#8220;Statistical Science&#8221;. (Click on the link for the journal version.) The Google 2019 paper and, more generally, NISQ experiments raise various interesting statistical issues. (In addition, it is important to double check various statistical claims of the paper.) One of our findings is that there is a large gap between the empirical distribution and the Google noise model. I hope to devote some future post to our paper and to some further research we were doing.</p>
<p>The leaking of the Google paper in September 23, 2019 led to huge media and academic attention and many very enthusiastic reactions.  I also wrote here on the blog a <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/">few</a> <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/">critical</a> <a href="https://gilkalai.wordpress.com/2019/10/13/the-story-of-poincare-and-his-friend-the-baker/">posts</a> about the Google claims.</p>
<p>Here is a figure with the price of bitcoin around the time of the Google quantum supremacy (unintended) announcement.</p>
<p><img loading="lazy" data-attachment-id="23183" data-permalink="https://gilkalai.wordpress.com/2022/08/06/ordinary-computers-can-beat-googles-quantum-computer-after-all/bc666/" data-orig-file="https://gilkalai.files.wordpress.com/2022/08/bc666.png" data-orig-size="851,487" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="bc666" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/08/bc666.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/08/bc666.png?w=640" class="alignnone size-full wp-image-23183" src="https://gilkalai.files.wordpress.com/2022/08/bc666.png" alt="bc666" width="851" height="487" srcset="https://gilkalai.files.wordpress.com/2022/08/bc666.png 851w, https://gilkalai.files.wordpress.com/2022/08/bc666.png?w=150&amp;h=86 150w, https://gilkalai.files.wordpress.com/2022/08/bc666.png?w=300&amp;h=172 300w, https://gilkalai.files.wordpress.com/2022/08/bc666.png?w=768&amp;h=440 768w" sizes="(max-width: 851px) 100vw, 851px" /></p>
<p><strong>Update</strong>: There is a recent post on Shtetl Optimized with <a href="https://scottaaronson.blog/?p=6645">Scott Aaronson&#8217;s take</a> on the supremacy situation. Overall our assessments are not very far apart. I don&#8217;t understand the claim: &#8220;If the experimentalists care enough, they could easily regain the quantum lead, at least for a couple more years, by (say) repeating random circuit sampling with 72 qubits rather than 53-60, and hopefully circuit depth of 30-40 rather than just 20-25.&#8221; In my view the most crucial task is to try to repeat and to improve some aspects of the Google experiment even for 20-40 qubits. (In any case, nothing is going to be easy.) </p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-06T20:20:51Z">11 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Wednesday, August 03
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://cstheory-jobs.org/2022/08/03/postdoctoral-fellow-at-santa-fe-institute-apply-by-october-14-2022/'>Postdoctoral Fellow at Santa Fe Institute (apply by October 14, 2022)</a>
        </h3>
        <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          An utterly unique opportunity to work on fundamental questions at the intersection of disciplines. The fellowship offers: -unparalleled intellectual freedom -transdisciplinary collaboration with leading researchers worldwide -up to 3 years in residence at SFI -dedicated funds for research &#38; collaboration -a structured leadership training program -competitive salary and paid family leave Website
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>An utterly unique opportunity to work on fundamental questions at the intersection of disciplines.</p>
<p>The fellowship offers:<br />
-unparalleled intellectual freedom<br />
-transdisciplinary collaboration with leading researchers worldwide -up to 3 years in residence at SFI<br />
-dedicated funds for research &amp; collaboration<br />
-a structured leadership training program<br />
-competitive salary and paid family leave</p>
<p>Website: <a href="https://lnkd.in/ga7Cm9AU">https://lnkd.in/ga7Cm9AU</a><br />
Email: Hilary Skolnik</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-03T21:38:25Z">14 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://gilkalai.wordpress.com/2022/08/03/test-your-intuition-50-two-players-random-walk-can-you-detect-who-did-not-follow-the-rules/'>Test Your Intuition 50. Two-Player Random Walk; Can You Detect Who Did Not Follow  the Rules?</a>
        </h3>
        <p class='item-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Ruth and Ron start together at the origin and take a walk on the integers. Every day they make a move. They take turns in flipping a coin and they move together right or left according to the outcome. Their &#8230; Continue reading &#8594;
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Ruth and Ron start together at the origin and take a walk on the integers. Every day they make a move. They take turns in flipping a coin and they move together right or left according to the outcome. <span style="color:#993366;">Their coin flips create a simple random walk starting at the origin on the integers.</span></p>
<p>We know for sure that they we will return to the origin infinitely many times. However, their random walk never comes back to the origin, so we know for sure that one of them did not follow the rules!</p>
<h3><span style="color:#0000ff;">Test your intuition: Is it possible to figure out from the walk whether it was Ruth or Ron who did not follow the coin-flipping rule?</span></h3>
<p><img loading="lazy" data-attachment-id="23142" data-permalink="https://gilkalai.wordpress.com/2022/08/03/test-your-intuition-50-two-players-random-walk-can-you-detect-who-did-not-follow-the-rules/ruthronrw/" data-orig-file="https://gilkalai.files.wordpress.com/2022/08/ruthronrw.png" data-orig-size="997,197" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="RuthRonRW" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/08/ruthronrw.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/08/ruthronrw.png?w=640" class="alignnone size-full wp-image-23142" src="https://gilkalai.files.wordpress.com/2022/08/ruthronrw.png" alt="RuthRonRW" width="997" height="197" srcset="https://gilkalai.files.wordpress.com/2022/08/ruthronrw.png 997w, https://gilkalai.files.wordpress.com/2022/08/ruthronrw.png?w=150&amp;h=30 150w, https://gilkalai.files.wordpress.com/2022/08/ruthronrw.png?w=300&amp;h=59 300w, https://gilkalai.files.wordpress.com/2022/08/ruthronrw.png?w=768&amp;h=152 768w" sizes="(max-width: 997px) 100vw, 997px" /></p>


<p></p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-03T07:03:11Z">14 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Tuesday, August 02
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://scottaaronson.blog/?p=6635'>Updatez</a>
        </h3>
        <p class='item-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          On the IBM Qiskit blog, there&#8217;s an interview with me about the role of complexity theory in the early history of quantum computing. Not much new for regular readers, but I&#8217;m very happy with how it came out&#8212;thanks so much to Robert Davis and Olivia Lanes for making it happen! My only quibble is with [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <ol><li>On the IBM Qiskit blog, there&#8217;s an <a href="https://medium.com/qiskit/scott-aaronson-says-complexity-theory-is-inextricable-from-quantum-computing-18369d0bd05d">interview with me</a> about the role of complexity theory in the early history of quantum computing.  Not much new for regular readers, but I&#8217;m very happy with how it came out&#8212;thanks so much to Robert Davis and Olivia Lanes for making it happen!  My only quibble is with the sketch of my face, which might create the inaccurate impression that I no longer have teeth.</li><li>Boaz Barak pointed me to a Twitter thread of <a href="https://twitter.com/QuantumYakar/status/1554432810664054784?s=20&amp;t=0nXoTU04w7Qe1bitINS6QA">DALL-E paintings of people using quantum computers</a>, in the styles of many of history&#8217;s famous artists.  While the motifs are unsurprising (QCs look like regular computers but glowing, or maybe like giant glowing atoms), highly recommended as another demonstration of the sort of thing DALL-E does best.</li><li>Dan Spielman asked me to announce that the National Academy of Sciences is <a href="http://www.nasonline.org/programs/awards/michael-and-sheila-held-prize.html">seeking nominations for the Held Prize</a> in combinatorial and discrete optimization.  The deadline is October 3.</li><li>I&#8217;m at the <a href="https://chicagoquantum.org/events/nsf-workshop-quantum-advantage-and-next-steps">NSF Workshop on Quantum Advantage and Next Steps</a> at the University of Chicago.  My talk yesterday was entitled &#8220;Verifiable Quantum Advantage: What I Hope Will Be Done&#8221; (yeah yeah, I decided to call it &#8220;advantage&#8221; rather than &#8220;supremacy&#8221; in deference to the name of the workshop).  <a href="https://www.scottaaronson.com/talks/whatihope.ppt">My PowerPoint slides are here</a>.  Meanwhile, this morning was the BosonSampling session.  The talk by <a href="https://quantum.ustc.edu.cn/web/en/node/137">Chaoyang Lu</a>, leader of USTC&#8217;s experimental BosonSampling effort, was punctuated by numerous silly memes and videos, as well as the following striking sentence: &#8220;only by putting the seven dragon balls together can you unlock the true quantum computational power.&#8221;</li><li>Gavin Leech <a href="https://www.gleech.org/aaronson">lists and excerpts his favorite writings of mine</a> over the past 25 years, while complaining that I spend &#8220;a lot of time rebutting fleeting manias&#8221; and &#8220;obsess[ing] over political flotsam.&#8221;</li></ol>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-02T16:48:23Z">15 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Monday, August 01
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://eccc.weizmann.ac.il/report/2022/111'>TR22-111 |  On Matrix Multiplication and Polynomial Identity Testing | 

	Robert Andrews</a>
        </h3>
        <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We show that lower bounds on the border rank of matrix multiplication can be used to non-trivially derandomize polynomial identity testing for small algebraic circuits. Letting $\underline{R}(n)$ denote the border rank of $n \times n \times n$ matrix multiplication, we construct a hitting set generator with seed length $O(\sqrt{n} \cdot \underline{R}^{-1}(s))$ that hits $n$-variate circuits of mult
        
        </div>

        <div class='item-content item-summary'>
        
          
          We show that lower bounds on the border rank of matrix multiplication can be used to non-trivially derandomize polynomial identity testing for small algebraic circuits. Letting $\underline{R}(n)$ denote the border rank of $n \times n \times n$ matrix multiplication, we construct a hitting set generator with seed length $O(\sqrt{n} \cdot \underline{R}^{-1}(s))$ that hits $n$-variate circuits of multiplicative complexity $s$. If the matrix multiplication exponent $\omega$ is not 2, our generator has seed length $O(n^{1 - \varepsilon})$ and hits circuits of size $O(n^{1 + \delta})$ for sufficiently small $\varepsilon, \delta &gt; 0$. Surprisingly, the fact that $\underline{R}(n) \ge n^2$ already yields new, non-trivial hitting set generators for circuits of sublinear multiplicative complexity.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-01T19:32:38Z">16 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://cstheory-jobs.org/2022/08/01/4-year-postdoc-at-idsia-switzerland-apply-by-october-1-2022/'>4-year Postdoc at IDSIA (SWITZERLAND) (apply by October 1, 2022)</a>
        </h3>
        <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          1 postdoc position for up to 4 years is available at IDSIA as part of the SNSF Grant &#8220;Ideal Membership Problems and the Bit Complexity of Sum of Squares Proofs&#8221;. The gross salary is around 80K CHF per year, with low taxes. Candidates with strong background in math or theoretical computer science will be considered. [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>1 postdoc position for up to 4 years is available at IDSIA as part of the SNSF Grant &#8220;Ideal Membership Problems and the Bit Complexity of Sum of Squares Proofs&#8221;. The gross salary is around 80K CHF per year, with low taxes. Candidates with strong background in math or theoretical computer science will be considered. The position will be filled as soon as an eligible candidate apply.</p>
<p>Website: <a href="https://people.idsia.ch/~monaldo/positions/positions.html">https://people.idsia.ch/~monaldo/positions/positions.html</a><br />
Email: monaldo.mastrolilli@idsia.ch</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-01T09:00:54Z">16 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://eccc.weizmann.ac.il/report/2022/110'>TR22-110 |  Scalable and Transparent Proofs over All Large Fields, via Elliptic Curves | 

	Eli Ben-Sasson, 

	Dan Carmon, 

	Swastik Kopparty, 

	David Levit</a>
        </h3>
        <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Concretely efficient interactive oracle proofs (IOPs) are of interest due to their applications to scaling blockchains, their minimal security assumptions, and their potential future-proof resistance to quantum attacks.

Scalable IOPs, in which prover time scales quasilinearly with the computation size and verifier time scales poly-logarithmically with it, have been known to exist thus far only ove
        
        </div>

        <div class='item-content item-summary'>
        
          
          Concretely efficient interactive oracle proofs (IOPs) are of interest due to their applications to scaling blockchains, their minimal security assumptions, and their potential future-proof resistance to quantum attacks.

Scalable IOPs, in which prover time scales quasilinearly with the computation size and verifier time scales poly-logarithmically with it, have been known to exist thus far only over a set of finite fields of negligible density, namely, over &quot;FFT-friendly&quot; fields that contain a sub-group of size  $2^k$.

Our main result is to show that scalable IOPs can be constructed over any sufficiently large finite field, of size that is at least quadratic in the length of computation whose integrity is proved by the IOP. This result has practical applications as well, because it reduces the proving and verification complexity of cryptographic statements that are naturally stated over pre-defined finite fields which are not &quot;FFT-friendly&quot;.

Prior state-of-the-art scalable IOPs relied heavily on arithmetization via univariate polynomials and Reed--Solomon codes over FFT-friendly fields. To prove our main result and extend scalability to all large finite fields, we generalize the prior techniques and use new algebraic geometry codes evaluated on sub-groups of elliptic curves (elliptic curve codes). We also show a new arithmetization scheme that uses the rich and well-understood group structure of elliptic curves to reduce statements of computational integrity to other statements about the proximity of functions evaluated on the elliptic curve to the new family of elliptic curve codes.

This paper continues our recent work [Ben-Sasson et al., ECCC TR21-103] that used elliptic curves and their subgroups to create FFT-based algorithms for polynomial manipulation over generic finite fields. However, our new IOP constructions force us to use new codes (ones that are not based on polynomials), and this poses a new set of challenges involving the more restricted automorphism group of these codes, and the constraints of Riemann--Roch spaces of strictly positive genus.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-08-01T06:52:36Z">16 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Sunday, July 31
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://11011110.github.io/blog/2022/07/31/linkage.html'>Linkage</a>
        </h3>
        <p class='item-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Ars Mathemalchemica: From Math to Art and Back Again (\(\mathbb{M}\)), article in the Notices by Susan Goldstine, Elizabeth Paley, and Henry Segerman about the Mathemalchemy traveling multimedia mathematical art installation.
        
        </div>

        <div class='item-content item-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://www.ams.org/journals/notices/202207/rnoti-p1220.pdf">Ars Mathemalchemica: From
Math to Art and Back Again</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@henryseg/108646207424631021">\(\mathbb{M}\)</a>),</span> article in the <em>Notices</em> by Susan Goldstine, Elizabeth Paley,
and Henry Segerman about the <a href="https://mathemalchemy.org/">Mathemalchemy</a> traveling multimedia mathematical art installation.</p>
  </li>
  <li>
    <p><a href="https://www.galoisrepresentations.com/2022/07/08/30-years-of-modularity-number-theory-since-the-proof-of-fermat/">30 Years of Modularity</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@Ianagol/108665694440173067">\(\mathbb{M}\)</a>),</span> well-produced and accessible number theory talk by Frank Calegary for the ICM.</p>
  </li>
  <li>
    <p>At <a href="https://www.lirmm.fr/icgt-2022/">ICGT</a>, the “detour problem” in graph algorithms was repeatedly mentioned <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108672718210680135">\(\mathbb{M}\)</a>):</span> Given vertices \(s\) and \(t\) in an unweighted digraph, how hard is it to find an \(s\)–\(t\) path that is not a shortest path? It’s polynomial for planar digraphs [<a href="https://doi.org/10.4230/LIPIcs.STACS.2022.29">Fomin et al STACS 2022</a>] and undirected graphs [<a href="https://doi.org/10.4230/LIPIcs.ICALP.2017.54">Bezáková et al ICALP 2017</a>], and \(\mathsf{NP}\)-hard in the weighted case. But the unweighted problem for arbitrary digraphs remains (annoyingly) open.</p>
  </li>
  <li>
    <p><a href="https://leanprover-community.github.io/blog/posts/lte-final/">Successful completion of the Liquid Tensor Experiment</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108678384474425188">\(\mathbb{M}\)</a>),</span> a challenge posed to the Lean prover community by Peter Scholze, after a year and a half of effort, where here “completion” appears to mean that the initial goal has been attained, but the associated repo still seems to be under active development. And apparently <a href="https://leanprover-community.github.io/archive/stream/267928-condensed-mathematics/topic/The.20elephant.20in.20the.20room.html">they are in dependency hell with mathlib</a>.</p>
  </li>
  <li>
    <p><a href="https://www.latimes.com/business/story/2022-07-19/as-professionals-flee-anti-abortion-policies-red-states-start-to-see-a-brain-drain">As professionals flee antiabortion policies, red states face a brain drain</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108680548702822721">\(\mathbb{M}\)</a>,</span> <a href="https://web.archive.org/web/20220719140821/https://www.latimes.com/business/story/2022-07-19/as-professionals-flee-anti-abortion-policies-red-states-start-to-see-a-brain-drain">archived copy</a>), Michael Hiltzik, business columnist for the <em>Los Angeles Times</em>. Despite the headline, it’s not just the antiabortion policies of the red states that are making it hard for their universities to attract good faculty and students; the column also mentions pro-gun, anti-public-health, and anti-LBGTQ policies, and restrictions on the teaching of history.</p>
  </li>
  <li>
    <p><a href="http://dailywrong.com/voronoi-structure-headgear-in-fashion-in-south-korea/">Voronoi structure headgear in fashion in South Korea</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108683840688807470">\(\mathbb{M}\)</a>).</span> (Sadly, not actually true.)</p>
  </li>
  <li>
    <p>Linking to mathstodon.xyz from Wikipedia has been blacklisted, I think for the last two years, as part of a general prohibition on .xyz links as mostly spammy <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108699308200897184">\(\mathbb{M}\)</a>).</span> I successfully petitioned for it to be whitelisted, and linking has become possible again. I don’t recommend this for Wikipedia articles themselves (mathstodon isn’t likely to meet Wikipedia’s standards for reliable sourcing) but <a href="https://en.wikipedia.org/wiki/Wikipedia_talk:WikiProject_Mathematics#Use_of_Latin_in_Mathematics">it could be relevant on some discussion pages</a>.</p>
  </li>
  <li>
    <p><a href="https://www.stuff.co.nz/waikato-times/news/129178200/university-and-film-colleagues-mourn-death-of-leading-film-and-television-academic-geoff-lealand">University and film colleagues mourn death of leading film and television academic Geoff Lealand</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108705013752493928">\(\mathbb{M}\)</a>).</span> Geoff was my uncle. Because of the distance from New Zealand to California I didn’t see him often, but <a href="/blog/2013/04/05/jaffas.html">I posted briefly from a visit by him in 2013</a>.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Twin-width">Twin-width</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108709564090432074">\(\mathbb{M}\)</a>),</span> new Wikipedia article. This is currently a very hot topic in structural graph theory and parameterized graph algorithms, with at least 25 papers all since 2020. So probably this article will need some updating as more results emerge.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1145/3543881">Color Blind Accessibility Manifesto</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108716801597956424">\(\mathbb{M}\)</a>,</span> <a href="https://colorblindaccessibilitymanifesto.com/">alt link</a>), Federico Monaco, <em>CACM</em>.</p>
  </li>
  <li>
    <p><a href="https://web.archive.org/web/20220728003710/https://www.insidehighered.com/news/2022/07/21/academic-freedom-under-threat-india">Academic freedom threatened in India</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108728560621575911">\(\mathbb{M}\)</a>,</span>  <a href="https://www.timeshighereducation.com/news/scholars-reprimanded-universities-criticising-indian-government"><em>THE</em></a>, <a href="https://www.insidehighered.com/news/2022/07/21/academic-freedom-under-threat-india"><em>IHE</em></a>). According to the story, university administrators with government ties have been “reprimanding academics for openly speaking out” against the government or against local misadministration, and keeping records of participation in protests, claiming that faculty are subject to more-restrictive rules aimed at other kinds of civil servants.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Quadrisecant">Quadrisecant</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108737904278232067">\(\mathbb{M}\)</a>),</span> new Wikipedia Good Article on the lines that touch space curves in four points. Why four? Because it is the maximum for generic curves. (In contrast, in 2D generic curves can cross the \(x\)-axis infinitely often.) If you view a curve from far away, most points of view see only simple crossings of two strands, but certain special viewpoints see triple crossings and even-more-special viewpoints see quadruple crossings. Those are the viewpoints on quadrisecants.</p>
  </li>
  <li>
    <p><a href="Juris Hartmanis">Juris Hartmanis</a>, a Turing Award winner and leading figure in computational complexity theory for many years, died on July 29 <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/108739212113153799">\(\mathbb{M}\)</a>).</span> These three blog posts have more about him and his contributions: <a href="http://blog.computationalcomplexity.org/2022/07/juris-hartmanis-passed-away-on-july-29.html">Bill Gasarch</a>; <a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/">Dick Lipton and Ken Regan</a>; <a href="https://scottaaronson.blog/?p=6622">Scott Aaronson and Ryan Williams</a>.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=FpeeFcK3lTk">Video on Cannon–Thurston maps</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@henryseg/108732665623998133">\(\mathbb{M}\)</a>,</span> <a href="https://en.wikipedia.org/wiki/Cannon%E2%80%93Thurston_map">see also</a>), space-filling curves formed from surfaces in hyperbolic 3-manifolds by lifting the boundary of the surface to the boundary of the universal cover of the manifold.</p>
  </li>
</ul>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-31T18:09:00Z">17 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://scottaaronson.blog/?p=6622'>Juris Hartmanis (1928-2022): Guest post by Ryan Williams</a>
        </h3>
        <p class='item-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Scott&#8217;s Introduction Juris Hartmanis — one of the founding figures of theoretical computer science, winner of the Turing Award, cofounder of the Cornell computer science department (of which I’m an alumnus), cofounder of the Conference on Computational Complexity or CCC (which I just attended), PhD adviser to many of the leading complexity theorists — has [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <div class="wp-block-image">
<figure class="aligncenter size-large"><img src="https://www.scottaaronson.com/hartmanis.jpg" alt=""/></figure></div>


<p><strong>Scott&#8217;s Introduction</strong></p>



<p><a href="https://en.wikipedia.org/wiki/Juris_Hartmanis">Juris Hartmanis</a> — one of the founding figures of theoretical computer science, winner of the Turing Award, cofounder of the Cornell computer science department (of which I’m an alumnus), cofounder of the <a href="https://computationalcomplexity.org/">Conference on Computational Complexity</a> or CCC (which I just attended), PhD adviser to many of the <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/hartmanisstud.pdf">leading complexity theorists</a> — has passed away at age 94.</p>



<p>Scientifically, Hartmanis will be remembered as long as our field exists for several contributions.  First and foremost, his 1965 proof, with Richard Stearns, of the <a href="https://en.wikipedia.org/wiki/Time_hierarchy_theorem">time</a> and <a href="https://en.wikipedia.org/wiki/Space_hierarchy_theorem">space</a> hierarchy theorems, which adapt Turing’s undecidability theorems to show that there exist computable problems that are arbitrarily hard (and thus, if you like, that the new field of computational complexity theory would have a subject matter).  Second, his and Berman’s investigation, in the 1970s, of the detailed structure of NP-complete problems (are they “paddable”? can they be <a href="https://eccc.weizmann.ac.il/report/2016/162/download/">sparse</a>? are all NP-complete sets <a href="https://www.cse.iitk.ac.in/users/manindra/survey/Isomorphism-Conjecture.pdf">polynomial-time isomorphic</a>?  or as we now believe, are they not?), which helped start the whole area of “structural complexity theory” (the original subject matter of the CCC conference).  Third, his investigations of logic and complexity theory, including whether problems like P vs. NP could be <a href="http://www.scottaaronson.com/papers/indep.pdf">independent</a> of the axioms of set theory, and the relations of that question to relativization and oracles.</p>



<p>As <a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/">this memorial post</a> by Richard Lipton and Ken Regan points out, some of Hartmanis’s most important contributions are so basic that it feels weird today even to mention them explicitly: the use of Turing machines to model computational complexity (!).  The study of complexity via &#8220;complexity classes,&#8221; consisting of all problems solvable within a given resource bound.  The whole <a href="https://complexityzoo.net/Complexity_Zoo">Complexity Zoo</a> could&#8217;ve been renamed Jurisic Park.</p>



<p>One of my regrets in life is that I didn’t get to know Hartmanis well when I was an undergrad at Cornell.  (This was a stage of my life when I was still intimidated by my professors, or hyper-mega-intimidated if they were Juris Hartmanis.)  I actually conversed with him more after I’d graduated and returned for visits.  He was so considerate and kind, almost grandfatherly, that I realized how foolish I was not to have sought him out as a student.</p>



<p>There was, however, another undergrad at Cornell at the same time as me, who wasn&#8217;t <em>quite</em> as intimidated as I was, and who ended up doing an independent study with Hartmanis, about the possibility of complete problems for NP∩coNP if I remember correctly.  This undergrad’s real goal was to solve the P vs. NP problem, which might sound ridiculous until I tell you that his name was <a href="https://people.csail.mit.edu/rrw/">Ryan Williams</a>.  I asked Ryan to share his own memories of Juris, and he’s graciously done so below.  You won&#8217;t regret reading this.  —SA</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p><strong>Juris Hartmanis by Ryan Williams</strong></p>



<p>I am extremely sad that Professor Juris Hartmanis has passed away. He made an enormous impact on my early career, and on my growth as a scientist: arguably, I wouldn&#8217;t be a scientist at all without him. He was extraordinarily gentle, inspiring, and encouraging to me.</p>



<p>My story of how I know Professor Hartmanis is really my &#8220;origin story&#8221; as a theoretical computer scientist. So I&#8217;ll tell you a little about the situation before I met him, to give some before/after context.</p>



<p>As a freshman at Cornell learning math and computer science, I became captivated by P vs NP and P vs PSPACE. In my teenage hubris, I planned it out: in the spring I&#8217;d take discrete math, fall I&#8217;d take the intro to theory of computing, and the following spring I&#8217;d take the grad complexity course being taught by Prof. Hartmanis that term. After that, I&#8217;d go to grad school in theory, and somewhere along the way tackle P vs NP. Simple enough&#8230;</p>



<p>I did fine in discrete math, but struggled in intro to theory, partly due to the fact that the lectures (and exams) were at 9am. I managed to do well on the final and earned a B+. I began to wonder if my plan was unsound. I went to the instructor and told them of my plan. They recommended that I should not try for grad school, as I didn&#8217;t seem to be particularly talented and there were &#8220;no jobs in theory&#8221;. (Jobs? Who needs jobs?) I asked if my chances of getting in grad school would be improved if I did well in the grad complexity class. They said &#8220;maybe&#8221;, and that was enough to keep me going.</p>



<p>The vibe in Prof. Hartmanis&#8217; class was amazing. He was exceptionally passionate about teaching complexity. His lectures were a revelation; they were exhilarating. He stayed laser-focused on communicating the heart of the ideas, with brevity and levity as needed to avoid the technical details (often nasty in the case of Turing machines). In the margins of my own class notes, I jotted down countless one-liners and antics. One of my favorite memories is that, when he wanted to be done with a proof and was tired of further questions, he would write his Q.E.D. symbol very large, with a little intimidating devil inside of it, like so:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img src="https://www.scottaaronson.com/devil.png" alt=""/></figure></div>


<p>As he&#8217;d often be packing more material in the lecture than time allowed, he joked that he wasn&#8217;t responsible for what was said in the last five minutes of class (when he&#8217;d rush to cover what remained). He was having so much <em>fun</em> with the material, and he repeatedly showed that one could think about these very deep and complex things very simply. My intuition for complexity grew so fast that the rest of my mathematical education was lifted immeasurably by it.</p>



<p>In response, I began to take my studies very seriously that semester. I showed up to every session of his office hours. I peppered him with questions after class. He was unwaveringly patient, helping me sort out my latest confusion. Eventually my questions turned into actual research problems, which occasionally received interesting answers (mostly already answered in the literature). After the semester ended, I began to schedule weekly meetings with him, discussing anything and everything complexity. He always seemed happy to chat, and during conversations he made the development of my research taste a top priority. He made it clear when what I was saying was interesting to him, and when it wasn&#8217;t&#8230; and if it wasn&#8217;t, I needed to explain why I found it interesting. But I understood that all of this was for my education as a future theoretical computer scientist, which he treated as inevitable.</p>



<p>I don&#8217;t know why Professor Hartmanis believed in me. During that period in my life, I felt like nobody else did, and it felt odd that the Turing Award winner was the one who believed the most. On the coattails of his eager recommendation, I was able to attend an REU at DIMACS. Later he was shocked and annoyed when in spite of his letter, I was rejected from every grad school I applied to (I suppose the B+ didn&#8217;t help). However, probably owing to Prof. Hartmanis&#8217; stature at the NSF, I was still awarded an NSF grad fellowship. When I told him of the good and bad news, and that I had no Plan B, he immediately picked up the phone and called someone explaining the situation. He hung up and announced &#8220;Congratulations Ryan, you have been admitted to the MEng program.&#8221; So I spent the next year in Ithaca as an MEng student. He informed me he was retiring, and maybe grad programs are getting skeptical of complexity. Maybe I should try to sneak in by studying something adjacent. He suggested working with Bart Selman on SAT (which I did). My confidence was shaken by the rejections but, seeing how strongly he believed in me, I could not let him down.</p>



<p>He was always full of affirmations for me, with a trademark mix of humor and motivation. After I would report a batch of new observations, he would say something like: &#8220;As they say, the biggest pig eats the most potatoes. And you sir, are a very big pig!&#8221; After I had a paper accepted to SODA, he declared that I was now a computer scientist. After I had a paper accepted to IJCAI, he declared that I had become a world-famous computer scientist. Prof. Hartmanis remained my strongest champion and loudest cheerleader in research, until I was finally admitted to some grad schools the next time around.</p>



<p>I&#8217;m immensely grateful to have known him. Without his faith, I&#8217;d have never become a theoretical computer scientist. Without his initial influence, I&#8217;d have never been a good one. I&#8217;ve been writing entirely through tears; I hope for everyone reading that they too have the chance to impact a young person&#8217;s life so profoundly.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p><strong>SA&#8217;s Endnotes</strong></p>



<p>Besides <a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/">the obituary by Lipton and Regan</a>, see also <a href="https://blog.computationalcomplexity.org/2022/07/juris-hartmanis-passed-away-on-july-29.html">the obituary by Bill Gasarch</a>.  And especially check out Hartmanis&#8217;s <a href="https://cacm.acm.org/magazines/2015/4/184690-an-interview-with-juris-hartmanis/fulltext">extraordinary biographical essay from 2015</a>, in which he describes his childhood in Latvia; his father being taken away by the Soviets to be executed when he was 12 years old; his move to America with his mother, where he worked as a steelworker and a butler while he studied at the University of Kansas City; Caltech&#8217;s farsighted decision to admit him as a graduate student despite his unusual background; and then the beginnings of computational complexity theory and the rest of his distinguished career.</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-30T23:29:04Z">18 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://blog.computationalcomplexity.org/2022/07/juris-hartmanis-passed-away-on-july-29.html'>Juris Hartmanis passed away on July 29 at the age of 94</a>
        </h3>
        <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>&nbsp;Juris Hartmanis, one of the founders of Complexity Theory, passed away on July 29 at the age of 94.&nbsp; The Gödel's Last Letter blog has an obit posted&nbsp;here.&nbsp; Scott Aaronson has some words and a guest post by Ryan Williams here. When other bloggers post obits I will update this paragraph to point to them.&nbsp;</p><p>Here is one non-blog obit:&nbsp;here.&nbsp; For an interview 
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>&nbsp;Juris Hartmanis, one of the founders of Complexity Theory, passed away on July 29 at the age of 94.&nbsp; The Gödel's Last Letter blog has an obit posted&nbsp;<a href="https://rjlipton.wpcomstaging.com/">here</a>.&nbsp; Scott Aaronson has some words and a guest post by Ryan Williams <a href="https://scottaaronson.blog/?p=6622">here</a>. When other bloggers post obits I will update this paragraph to point to them.&nbsp;</p><p>Here is one non-blog obit:&nbsp;<a href="https://usobit.com/obituaries-2022/juris-hartmanis-july-5-1928-july-29-2022-age-94/">here</a>.&nbsp; For an interview with Juris see&nbsp;<a href="https://dl.acm.org/doi/pdf/10.1145/2736346">here</a>.</p><p>Hartmanis and Stearns shared the 1993&nbsp; Turing award for the paper <i>On the Computational Complexity of</i> <i>Algorithms </i>(see&nbsp;<a href="https://www.ams.org/journals/tran/1965-117-00/S0002-9947-1965-0170805-7/S0002-9947-1965-0170805-7.pdf">here</a>&nbsp;for the paper and see&nbsp;<a href="https://doi.org/10.1145/194313.214781">here</a>&nbsp;for his Turing Award Talk). In that paper they define DTIME(T(n)) for Turing Machines. They also proved some theorems about how changes to the model (1-tape, 2-tape, 1-dim, 2-dim others) change the notion of DTIME(T(n))- so they were well aware that the definition was not robust. They also have some theorems about computable numbers.&nbsp;</p><p>We are used to the notion that you can measure how long a computation takes my counting the number of steps on a Turing Machine. Before the Hartmanis-Stearns paper this was not how people thought of things. Knuth (I suspect independently) was looking at what we might now call concrete complexity- how many operations does an algorithm need. Hartmanis-Stearns were beginning what is now called Complexity Theory.&nbsp;</p><p>&nbsp;Recall that later, the Cook-Levin Theorem used Turing Machines.&nbsp;</p><p>If Hartmanis-Stearns did not start the process of putting complexity on a rigorous mathematical basis how might complexity theory have evolved? It is possible we would not have the Cook-Levin Theorem or the notion of NP. It is possible that we would ASSUME that SAT is hard and use that to get other problems hard, and also do reverse reductions as well to get some problems equivalent to SAT. Indeed- this IS what we do in other parts of theory with assuming the following problems are hard (for various definitions of hard): 3SUM, APSP, Unique Games. And in Crypto Factoring, DL, SVP, and other problems.&nbsp;</p><p>Hartmanis did other things as well. I list some of them that are of interest to me - other people will likely list other things of interest to them.&nbsp;</p><p>0) He had 21 PhD Students, some of them quite prominent. The list of them is&nbsp;<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/hartmanisstud.pdf">here</a>.</p><p>1) The Berman-Hartmanis Conjecture: All NP-Complete sets are poly isomorphic. Seems true for all natural NP-complete sets. Still open. This conjecture inspired a lot of work on sparse sets including that if a sparse set S is btt-hard for NP, then P=NP (proven by Ogiwara-Watanabe)</p><p>2) The Boolean Hierarchy: we all know what NP is. What about sets that are the <i>difference </i>of two NP sets? What about sets of the form A - (B-C) where A,B,C are all in NP? These form a hierarchy. We of course do not know if the hierarchy is proper, but if it collapse then PH collapses.</p><p>3) He helped introduce time-bounded Kolmogorov complexity into complexity theory, see&nbsp;<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4568108">here</a>.</p><p>4) He was Lance Fortnow's undergraduate advisor.&nbsp;</p><p>5) There is more but I will stop here.</p><p><br /></p><p><br /></p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-30T16:09:00Z">18 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Saturday, July 30
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/'>Juris Hartmanis 1928–2022</a>
        </h3>
        <p class='item-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          A sure foundation for Computational Complexity source&#8212;wonderful 2015 CACM interview Juris Hartmanis passed away this morning. He was a professor in Cornell&#8217;s computer science department since 1965. He won the 1993 Turing Award with Richard Stearns for their 1963&#8211;1965 paper &#8220;On the Computational Complexity of Algorithms.&#8221; Today, Dick and I express our condolences and al
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>A sure foundation for Computational Complexity</em><br />
<font color="#000000"></p>
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/jurisacm2015/" rel="attachment wp-att-20266"><img data-attachment-id="20266" data-permalink="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/jurisacm2015/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/JurisACM2015.jpg?fit=250%2C250&amp;ssl=1" data-orig-size="250,250" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="JurisACM2015" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/JurisACM2015.jpg?fit=250%2C250&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/JurisACM2015.jpg?fit=250%2C250&amp;ssl=1" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/JurisACM2015.jpg?resize=185%2C185&#038;ssl=1" alt="" width="185" height="185" class="alignright wp-image-20266" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/JurisACM2015.jpg?w=250&amp;ssl=1 250w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/JurisACM2015.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/JurisACM2015.jpg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 185px) 100vw, 185px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://cacm.acm.org/magazines/2015/4/184690-an-interview-with-juris-hartmanis/fulltext">source</a>&#8212;wonderful 2015 CACM interview</font></td>
</tr>
</tbody>
</table>
<p>
Juris Hartmanis passed away this morning. He was a professor in Cornell&#8217;s computer science department since 1965. He won the 1993 Turing Award with Richard Stearns for their 1963&#8211;1965 <a href="https://www.ams.org/journals/tran/1965-117-00/S0002-9947-1965-0170805-7/">paper</a> &#8220;On the Computational Complexity of Algorithms.&#8221;</p>
<p>
Today, Dick and I express our condolences and also appreciation for a long life and career shaping our field of computational complexity theory. </p>
<p>
One mark of a long life is that the <a href="https://link.springer.com/book/10.1007/978-1-4612-4478-3">Complexity Theory Retrospective</a> volume honoring his 60th birthday in 1988 was longer ago than the beginning of my tenure-track career at Buffalo in 1989. In the early 1980s, when I met both him and Alan Selman (who edited the volume), they were progenitors of the vein within computational complexity that emphasizes the structure of classes of problems. </p>
<p>
I mean &#8220;progenitor&#8221; quite strongly: When I joined Cornell as a Mathematical Sciences Institute postdoc in 1986, the Computer Science Department generously gave me office space a few doors down from Juris in Upson Hall. I mixed with a gaggle of his students: Lane Hemaspaandra and Jim Kadin and Richard Chang and Desh Ranjan, also saw much of Jin-Yi Cai on his return visits, and had just missed Ming Li and Luc Longpr&eacute;. We all amplified the energy that Juris brought to the field.</p>
<p>
<p><H2> An Echo in Quantum </H2></p>
<p><p>
The structural framework needed to be filled with combinatorial power from other areas of mathematical sciences. But to see the framework&#8217;s longevity, one need look no further than the Best Paper in the 2022 Computational Complexity Conference and a paper just accepted to FOCS 2022 that was <a href="https://www.quantamagazine.org/quantum-algorithms-conquer-a-new-kind-of-problem-20220711/">featured</a> in <em>Quanta</em>:</p>
<ul>
<li>
&#8220;<a href="https://arxiv.org/abs/2111.10409">The Acrobatics of BQP</a>&#8221; by Scott Aaronson, DeVon Ingram, and William Kretschmer. </p>
<li>
&#8220;<a href="https://arxiv.org/abs/2204.02063">Verifiable Quantum Advantage Without Structure</a>&#8221; by Takashi Yamakawa and Mark Zhandry.
</ul>
<p>
Both are on quantum computing, a field that really began to exist about the time that Juris decided that Pankaj Rohatgi would be his last PhD student. The foci are problems involving Fourier transforms and their correlations, error-correcting codes, and the relationship of randomness to entropy that go well beyond what we thought of as &#8220;Structure.&#8221; Neither paper cites anything by Juris. Yet the former paper&#8217;s results are framed as complexity class relations that jump off the page&#8212;here are just three square centimeters of the abstract:</p>
<p align=center>
<a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/acrobaticssnippet/" rel="attachment wp-att-20268"><img data-attachment-id="20268" data-permalink="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/acrobaticssnippet/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/AcrobaticsSnippet.jpg?fit=610%2C153&amp;ssl=1" data-orig-size="610,153" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1659122901&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="AcrobaticsSnippet" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/AcrobaticsSnippet.jpg?fit=300%2C75&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/AcrobaticsSnippet.jpg?fit=600%2C150&amp;ssl=1" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/AcrobaticsSnippet.jpg?resize=450%2C115&#038;ssl=1" alt="" width="450" height="115" class="aligncenter wp-image-20268" data-recalc-dims="1" /></a></p>
<p>
All three results in the latter paper are relative to a random oracle; the first states: &#8220;There are NP search problems solvable by BQP machines but not BPP machines.&#8221; The expansion of formal machine models from the basic Turing machine, in order to embrace elements of complexity, is the backbone of the paper with Stearns. The relation of machine models to classes in the presence of oracles was the focus of Juris&#8217;s ICALP 1986 <a href="https://link.springer.com/chapter/10.1007/3-540-16761-7_62">paper</a> with Lane, &#8220;Complexity Classes Without Machines.&#8221; </p>
<p>
<p><H2> Founding Paper </H2></p>
<p><p>
My pithiest statement of the 1965 paper&#8217;s impact is that it made Turing&#8217;s tape-machine formulation <em>durable</em>. Indeed, the notions of streaming algorithms, nearly-linear time efficiency, and data locality being one-dimensional that I recall from the 1990s have more affinity to that paper&#8217;s technical development than to the polynomial benchmark of feasibility that yielded the formalizations of P and NP either side of 1970. Here are two machine diagrams from the paper:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/hs65tapes/" rel="attachment wp-att-20269"><img data-attachment-id="20269" data-permalink="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/hs65tapes/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65tapes.jpg?fit=788%2C433&amp;ssl=1" data-orig-size="788,433" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1659128505&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="HS65tapes" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65tapes.jpg?fit=300%2C165&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65tapes.jpg?fit=600%2C330&amp;ssl=1" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65tapes.jpg?resize=525%2C289&#038;ssl=1" alt="" width="525" height="289" class="aligncenter wp-image-20269" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65tapes.jpg?w=788&amp;ssl=1 788w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65tapes.jpg?resize=300%2C165&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65tapes.jpg?resize=768%2C422&amp;ssl=1 768w" sizes="(max-width: 525px) 100vw, 525px" data-recalc-dims="1" /></a></p>
<p><P><br />
Before giving the second diagram, let me note that their simple question of whether there is any algebraic irrational number that can be computed to <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> places in <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{O(n)}" class="latex" /> time by this kind of machine, has yet to be answered.</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/hs65tht/" rel="attachment wp-att-20271"><img data-attachment-id="20271" data-permalink="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/hs65tht/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65THT.jpg?fit=801%2C442&amp;ssl=1" data-orig-size="801,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1659128618&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="HS65THT" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65THT.jpg?fit=300%2C166&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65THT.jpg?fit=600%2C331&amp;ssl=1" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HS65THT.jpg?resize=525%2C294&#038;ssl=1" alt="" width="525" height="294" class="aligncenter wp-image-20271" data-recalc-dims="1" /></a></p>
<p><P><br />
The latter diagram conveys their proof of the <a href="https://en.wikipedia.org/wiki/Time_hierarchy_theorem">Time Hierarchy Theorem</a>&#8212;though needing a quadratic separation, as today&#8217;s logarithmic-gap formulation needed an improvement the following year by Stearns with Frederick Hennie. That is to say, the paper that defined complexity measures also demonstrated how it is possible to prove lower bounds for them. </p>
<p>
<p><H2> It Could Have Been Lambdas </H2></p>
<p><p>
Lest you think the machine formulation was inevitable at the start, consider the following <a href="https://blog.computationalcomplexity.org/2015/05/fiftieth-anniversary-of-publication-of.html?showComment=1431672005603#c7849278842572743298">comment</a> from &#8220;Mathai&#8221;&#8212;whom I take to be <a href="https://en.wikipedia.org/wiki/Mathai_Joseph">Mathai Joseph</a>&#8212;in Lance Fortnow&#8217;s 2015 <a href="https://blog.computationalcomplexity.org/2015/05/fiftieth-anniversary-of-publication-of.html">post</a> marking the paper&#8217;s 50th anniversary:</p>
<blockquote><p><b> </b> <em> &#8220;I talked to Hartmanis about this in 2012 and asked if they had considered using recursive function theory. He said they had and it had made things horribly complicated. Then they came across Turing machines and the whole thing became &#8216;so simple&#8217; !&#8221; </em>
</p></blockquote>
<p><p>
I myself once took part in work trying to re-base complexity on recursion in an alteration of the lambda calculus. So many things have earned the name <a href="https://en.wikipedia.org/wiki/Turing_tarpit">Turing tarpits</a>; theirs based squarely on Turing was not.</p>
<p>
Dick Karp, quoted by Stearns in his <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&#038;arnumber=5272">contribution</a> to the 60th birthday volume, captured the paper&#8217;s importance:</p>
<blockquote><p><em>[I]t is the 1965 paper by Juris Hartmanis and Richard Stearns that marks the beginning of the modern era of complexity theory. Using the Turing machine as their model of an abstract computer, [they] provided a precise definition of the &#8220;complexity class&#8221; consisting of all problems solvable in a number of steps bounded by some given function of the input length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" />. Adapting the diagonalization technique that Turing had used to prove the undecidability of the Halting Problem, they proved many interesting results about the structure of complexity classes. All of us who read their paper could not fail to realize that we now had a satisfactory formal framework for pursuing the questions that [Jack] Edmonds had raised earlier in an intuitive fashion.</em>
</p></blockquote>
<p><p>
Dick and I have talked about the importance of good definitions often on this blog, and here is a similar <a href="https://blog.computationalcomplexity.org/2017/08/what-makes-great-definition.html">post</a> by Lance. In my formative years, I was fortunate to have two texts that wove theirs and the P-NP-based definitions together: <a href="https://en.wikipedia.org/wiki/Computers_and_Intractability">[GJ79]</a> and <a href="https://en.wikipedia.org/wiki/Introduction_to_Automata_Theory,_Languages,_and_Computation">[HU79]</a>. </p>
<p>
<p><H2> Undecidability and Proofs </H2></p>
<p><p>
A second vein of Juris&#8217;s work made a more particular impression on me, even before I met him. For SWAT (now FOCS) in 1967, he wrote a single-author <a href="https://dl.acm.org/doi/abs/10.1145/321495.321507">paper</a>, &#8220;On the Complexity of Undecidable Problems in Automata Theory.&#8221; The essence is that above a certain level of machine sophistication, whenever you prove the &#8220;good news&#8221; of lower bounds to separate classes in a hierarchy, you also get the &#8220;bad news&#8221; of there being problems between the class levels whose status is not resolvable in whatever strong system of logic you employ. </p>
<p>
This raises the question, for classes like P and NP that have not yet been separated, whether the logical independence phenomenon washes over the entire landscape. He and John Hopcroft wrote a short <a href="https://dl.acm.org/doi/10.1145/1008335.1008336">paper</a> for SIGACT News outlining this possibility. The topic was taken up by others, including Dick with Rich De Millo and later myself, and continues to percolate. </p>
<p>
One of his last papers, &#8220;<a href="https://link.springer.com/chapter/10.1007/3-540-44577-3_17">Computational Complexity and Mathematical Proofs</a>,&#8221; takes the opposite avenue of how the structure of computations influences the production of proofs, including interactive proofs. This was based on an earlier paper with Chang, Ranjan, and Rohatgi, which I covered in a 2015 <a href="https://rjlipton.wpcomstaging.com/2015/05/17/the-shapes-of-computations/">post</a>. This diagram conveys the idea:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/proofshapes-3/" rel="attachment wp-att-20272"><img data-attachment-id="20272" data-permalink="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/proofshapes-3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/ProofShapes.png?fit=600%2C378&amp;ssl=1" data-orig-size="600,378" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ProofShapes" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/ProofShapes.png?fit=300%2C189&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/ProofShapes.png?fit=600%2C378&amp;ssl=1" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/ProofShapes.png?resize=540%2C340&#038;ssl=1" alt="" width="540" height="340" class="aligncenter wp-image-20272" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/ProofShapes.png?w=600&amp;ssl=1 600w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/ProofShapes.png?resize=300%2C189&amp;ssl=1 300w" sizes="(max-width: 540px) 100vw, 540px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> A Dinner Before Going to NSF </H2></p>
<p><p>
One of my most delightful memories is sitting next to Juris at the conference dinner at the IFIP 1994 congress in Hamburg. Earlier that day I had met the conference honoree, Konrad Zuse, even speaking a little in German with him. We were not seated close to Zuse&#8212;indeed, I am not confident to say either way whether he was there. But seated across from us was a woman representing the NSF whom Juris was most interested to talk with.</p>
<p>
The strong memory I have is that I did not commandeer the conversation toward technical problems within structural complexity. Juris was eager to convey command and interest in the breadth of Computer Science, and so was I. We three went further: into music and art and culture quite apart from computers. It was a delightful flow of talk for almost two hours. Juris thanked me afterward for not waxing technical. I did not fully get the picture until Juris <a href="https://www.nsf.gov/news/news_summ.jsp?cntn_id=101782">joined</a> NSF as Director of CISE two years later, in 1996. </p>
<p>
There is much more I could say about his work promoting the complexity theory community, about being a founding editor of the Springer-Verlag <em>Lecture Notes in Computer Science</em> series, about helping to found Cornell&#8217;s computer science department. On the last, his longtime Cornell colleague Anil Nerode has sent me this:</p>
<blockquote><p><b> </b> <em> &#8220;I was chairman of the committee of three, which included Bob Walker, that selected him to chair and organize a new computer science department. He already exhibited the scientific and people skills, and the breadth of vision, for which he was later famous. I will miss him very much.&#8221; </em>
</p></blockquote>
<p><p>
One other detail I remember of Juris&#8217;s personal life is that he liked sporty cars. I am not among those who rode with him muscularly in one&#8212;other drivers have filled that niche for me. We invite readers who have done so&#8212;or who wish to give any other personal reminiscences&#8212;to contribute below. I&#8217;ll leave with the observation that of the two scientists in this photo&#8212;</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/juris-and-al/" rel="attachment wp-att-20273"><img data-attachment-id="20273" data-permalink="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/juris-and-al/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/juris-and-al.jpg?fit=1110%2C1413&amp;ssl=1" data-orig-size="1110,1413" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="juris-and-al" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/juris-and-al.jpg?fit=236%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/juris-and-al.jpg?fit=600%2C764&amp;ssl=1" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/juris-and-al.jpg?resize=300%2C382&#038;ssl=1" alt="" width="300" height="382" class="aligncenter wp-image-20273" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/juris-and-al.jpg?resize=804%2C1024&amp;ssl=1 804w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/juris-and-al.jpg?resize=236%2C300&amp;ssl=1 236w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/juris-and-al.jpg?resize=768%2C978&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/juris-and-al.jpg?w=1110&amp;ssl=1 1110w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">&#8220;A Great Man and a Statue&#8221; <a href="https://www.cs.rochester.edu/u/lane/juris-and-al.html">source</a></FONT>
</td>
</tr>
</table>
<p>
&#8212;it was as much in Juris&#8217;s nature to wear a tie as it was for the other guy not to.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Again we give our condolences to his family and surviving colleagues, which set includes the three acknowledged at the end of the 1967 paper mentioned above:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/hartmanisack/" rel="attachment wp-att-20274"><img data-attachment-id="20274" data-permalink="https://rjlipton.wpcomstaging.com/2022/07/29/juris-hartmanis-1928-2022/hartmanisack/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HartmanisAck.jpg?fit=699%2C74&amp;ssl=1" data-orig-size="699,74" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1659135226&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="HartmanisAck" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HartmanisAck.jpg?fit=300%2C32&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HartmanisAck.jpg?fit=600%2C64&amp;ssl=1" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/HartmanisAck.jpg?resize=550%2C60&#038;ssl=1" alt="" width="550" height="60" class="aligncenter wp-image-20274" data-recalc-dims="1" /></a></p>
<p><P><br />
[some small tweaks]</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-30T03:59:10Z">18 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Friday, July 29
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='http://processalgebra.blogspot.com/2022/07/davide-sangiorgis-interview-with-james.html'>Davide Sangiorgi's Interview with James Leifer, CONCUR 2022 ToT Award Recipient</a>
        </h3>
        <p class='item-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>I am pleased to post Davide Sangiorgi's interview with CONCUR 2022 Test-of-Time Award recipient James Leifer, who will receive the award for the paper <br>"Deriving Bisimulation Congruences for Reactive Systems" co-authored with the late Robin Milner. <br></p><p>Thanks to James for painting a rich picture of the scientific and social context within which the work on that paper was done and to Da
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>I am pleased to post <a href="http://www.cs.unibo.it/~sangio/" target="_blank">Davide Sangiorgi</a>'s interview with <a href="https://concur2022.mimuw.edu.pl/tot-award/" target="_blank">CONCUR 2022 Test-of-Time Award</a> recipient <a href="http://pauillac.inria.fr/~leifer/" target="_blank">James Leifer</a>, who will receive the award for the paper <br /><a href="https://link.springer.com/content/pdf/10.1007/3-540-44618-4_19.pdf" target="_blank">"Deriving Bisimulation Congruences for Reactive Systems</a>" co-authored with the late Robin Milner. <br /></p><p>Thanks to James for painting a rich picture of the scientific and social context within which the work on that paper was done and to Davide for conducting the interview. I trust that readers of this blog will enjoy reading it as much as I did. </p><div><b>Davide:</b> How did the work presented in your CONCUR ToT paper come about?</div><div><br /></div><div><b>James:</b> I  was introduced to Robin Milner by my undergraduate advisor Bernard  Sufrin around 1994. Thanks to that meeting, I started with Robin at  Cambridge in 1995 as a fresh Ph.D. student. Robin had recently moved  from Edinburgh and had a wonderful research group, including, at various  times, Peter Sewell, Adriana Compagnoni, Benjamin Pierce, and Philippa  Gardner. There were also many colleagues working or visiting Cambridge  interested in process calculi: Davide Sangiorgi, Andy Gordon, Luca  Cardelli, Martín Abadi,... It was an exciting atmosphere!  I was  particularly close to Peter Sewell, with whom I discussed the ideas here  extensively and who was generous with his guidance.</div><div><br /></div><div>There  was a trend in the community at the time of building complex process  calculi (for encryption, Ambients, etc.) where the free syntax would be  quotiented by a structural congruence to "stir the soup" and allow  different parts of a tree to float together; reaction rules (unlabelled  transitions) then would permit those agglomerated bits to react, to  transform into something new.</div><div><br /></div><div>Robin wanted to  come up with a generalised framework, which he called Action Calculi,  for modelling this style of process calculi.&nbsp; His framework would  describe graph-like "soups" of atoms linked together by arcs  representing binding and sharing; moreover the atoms could contain  subgraphs inside of them for freezing activity (as in prefixing in the pi-calculus), with the possibility of boundary crossing arcs  (similarly to how nu-bound names in pi-calculus can be used in  deeply nested subterms).&nbsp;&nbsp;</div><div><br /></div><div>Robin had an amazing  talent for drawing beautiful graphs! He would "move" the nodes around  on the chalkboard and reveal how a subgraph was in fact a reactum (the  LHS of an unlabelled transition).&nbsp; In the initial phases of my Ph.D. I  just tried to understand these graphs: they were so natural to draw on  the blackboard! And yet, they were also so uncomfortable to use when  written out in linear tree- and list-like syntax, with so many distinct  concrete representations for the&nbsp;same graph.</div><div><br /></div><div>Putting  aside the beauty of these graphs, what was the benefit of this  framework? If one could manage to embed a process calculus in  Action&nbsp;Calculi, using the graph structure and fancy binding and&nbsp;nesting  to represent the quotiented syntax, what then?  We dreamt about a  proposition along the following lines: if you represent your syntax  (quotiented by your structural congruence) in Action Calculi graphs, and  you represent your reaction rules as Action Calculi graph rewrites,  then we will give you a congruential bisimulation for free!</div><div><br /></div><div>Compared  to CCS for example, many of the rich&nbsp;new process calculi lacked  labelled transitions systems. In CCS, there was a clean, simple notion  of labelled transitions and, moreover, bisimulation over those labelled  transitions yielded a congruence: for all processes <i>P</i> and <i>Q</i>, and all  process contexts<i> C[-]</i>, if <i>P ~ Q</i>, then <i>C[P] ~ C[Q]</i>. This is a  key quality for a bisimulation to possess, since it allows modular  reasoning about pieces of a process, something that's so much harder in a  concurrent world than in a sequential one.</div><div><br /></div><div>Returning  to Action Calculi, we set out to make good on the dream that everyone  gets a congruential bisimulation for free! Our&nbsp;idea was to find a  general method to derive labelled transitions systems from the  unlabelled transitions and then to prove that bisimulation built from  those labelled transitions would be a congruence.</div><div><br /></div><div>The  idea was often discussed at that time that there was a duality whereby a  process undergoing a labelled transition could be thought of as the  environment providing a complementary context inducing the process to  react. In the early labelled transition system in pi-calculus for  example, I recall hearing that <i>P</i> undergoing the input labelled  transition <i>xy</i> could be thought of as the environment outputting  payload<i> y </i>on channel <i>x</i> to enable a tau transition with <i>P.</i></div><div><br /></div><div>So  I tried to formalise this notion that labelled transitions are  environmental contexts enabling reaction, i.e. defining <i>P ---C[-]---&gt; P'</i> to mean <i>C[P] ------&gt; P'</i> provided that <i>C[-]</i> was somehow "minimal", i.e. contained nothing superfluous beyond  what was necessary to trigger the reaction. We wanted to get a rigorous  definition of that intuitive idea. There was a long and difficult period  (about 12 months) wandering through the weeds trying to define minimal  contexts for Action Calculi graphs (in terms of minimal nodes and  minimal arcs), but it was hugely complex, frustrating, and ugly and we  seemed no closer to the original goal of achieving congruential  bisimulation with these labelled transitions systems.</div><div><br /></div><div>Eventually  I stepped back from Action Calculi and started to work on a more  theoretical definition of "minimal context" and we took inspiration from  category theory.&nbsp; Robin had always viewed Action Calculi graphs as  categorical arrows between objects (where the objects represented  interfaces for plugging together arcs). At the time, there was much  discussion of category theory in the air (for game theory); I certainly  didn't understand most of it but found it interesting and inspiring. </div><div><br /></div><div>If  we imagine that processes and process-contexts are just categorical  arrows (where the objects are arities) then context composition is arrow  composition. Now, assuming we have a reaction rule <i>R ------&gt; R'</i>,  we can define labelled transitions <i>P ---C[-]---&gt; P'</i> as follows:  there exists a context <i>D</i> such that <i>C[P] = D[R] </i>and <i>P' = D[R']</i>.  The first equality is a commuting diagram and Robin and I thought that  we could formalise minimality by something like a categorical pushout!  But that wasn't quite right as <i>C </i>and <i>D</i> are not <i>the minimum </i>pair (compared to all other candidates), but <i>a minimal</i> pair:  there may be many incomparable minimal pairs all of which are witnesses  of legitimate labelled transitions.&nbsp; There was again a long period of  frustration eventually resolved when I reinvented "relative pushouts"  (in place of pushouts). They are a simple notion in slice categories but  I didn't know that until later...</div><div><br /></div><div>Having found  a reasonable definition of "minimal", I worked excitedly on  bisimulation, trying to get a proof of congruence: <i>P ~ Q</i> implies <i>E[P] ~ E[Q]</i>. For weeks, I was considering the labelled transitions  of <i>E[P] ---F[-]---&gt;</i> and all the ways that could arise. The most  interesting case is when a part of <i>P,</i> a part of <i>E</i>, and <i>F</i> all  "conspire" together to generate a reaction. From that I was able to  derive a labelled transition of <i>P</i> by manipulating relative pushouts,  which by hypothesis yielded a labelled transition of <i>Q</i>, and then, via a  sort of "pushout pasting", a labelled transition <i>E[Q] ---F[-]---&gt;</i>. It was a wonderful moment of elation when I pasted  all the diagrams together on Robin's board and we realised that we had  the congruence property for our synthesised labels!</div><div><br /></div><div>We  looked back again at Action Calculi, using the notion of relative  pushouts to guide us (instead of the arbitrary approach we had  considered before) and we further looked at other kinds of process  calculi syntax to see how relative pushouts could work there...&nbsp;  Returning to the original motivation to make Action Calculi a universal  framework with congruential bisimulation for free, I'm not convinced of  its utility. But it was the challenge that led us to the journey of the  relative pushout work, which I think is beautiful.</div><div><br /></div><div><b>Davide: </b>What influence did this work have in the rest of your career? How much of your subsequent work built on it?</div><div><b><br /></b></div><div><b>James:</b> It  was thanks to this work that I visited INRIA Rocquencourt to discuss  process calculi with Jean-Jacques Lévy and Georges Gonthier. They kindly  invited me to spend a year as postdoc in 2001 after I finished my  thesis with Robin, and I ended up staying in INRIA ever since. I didn't  work on bisimulation again as a research topic, but stayed interested in  concurrency and distribution for a long time, working with Peter Sewell  et al on distributed language design with module migration and  rebinding, and with Cédric Fournet et al on compiler design for  automatically synthesising cryptographic protocols for high level  sessions specifications.</div><div><br /></div><div><b>Davide: </b>Could you tell  us about your interactions with Robin Milner? What&nbsp;was it like to work  with him? What lessons did you learn from him?</div><div><br /></div><div><b>James: </b>I was tremendously inspired by Robin.</div><div><br /></div><div>He  would stand at his huge blackboard, his large hands covered in chalk,  his bicycle clips glinting on his trousers, and he would stalk up and  down the blackboard --- thinking and moving.&nbsp; There was something  theatrical and artistic about it: his thinking was done in physical  movement and his drawings were dynamic as the representations of his  ideas evolved across the board.</div><div><br /></div><div>I loved his  drawings. They would start simple, a circle for a node, a box for a  subgraph, etc. and then develop more and more detail corresponding to  his intuition. (It reminded me of descriptions I had read of Richard  Feynman drawing quantum interactions.)</div><div><br /></div><div>Sometimes  I recall being frustrated because I couldn't read into his formulas  everything that he wanted to convey (and we would then switch back to  drawings) or I would be worried that there was an inconsistency creeping  in or I just couldn't keep up, so the board sessions could be a roller  coaster ride at times!</div><div><br /></div><div>Robin worked  tremendously hard and consistently. He would write out and rewrite out  his ideas, regularly circulating hand written&nbsp;documents. He would refine  over and over his diagrams. Behind his achievements there was an  impressive consistency&nbsp;of effort.</div><div><br /></div><div>He had a lot  of confidence to carry on when the sledding was hard. He had such a  strong intuition of what ought to be possible, that he was able to  sustain years of effort to get there.</div><div><br /></div><div>He was  generous with praise, with credit, with acknowledgement of others'  ideas. He was generous in sharing his own ideas and seemed delighted  when others would pick them up and carry them forward. I've always  admired his openness and lack of jealousy in sharing ideas.</div><div><br /></div><div>In  his personal life, he seemed to have real compatibility with Lucy (his  wife), who also kept him grounded. I still laugh when I remember once  working with him at his dining room table and Lucy announcing, "Robin,  enough of the mathematics. It's time to mow the lawn!" </div><div><br /></div><div>I  visited Oxford for Lucy's funeral and recall Robin putting a brave face  on his future plans; I returned a few weeks later when Robin passed  away himself. I miss him greatly.&nbsp;</div><div><br /></div><div><b>Davide: </b>What research topics are you most interested in right now? How do&nbsp;you see your work develop in the future?</div><div><br /></div><div><b>James:</b> I've  been interested in a totally different area, namely healthcare, for  many years. I'm fascinated by how patients, and information about them,  flows through the complex human and machine interactions in hospital.  When looking at how these flows work, and how they don't, it's possible  to see where errors arise, where blockages happen, where there are  informational and visual deficits that make the job of doctors and  nurses difficult. I like to think visually in terms of graphs  (incrementally adding detail) and physically moving through the space  where the action happens --- all inspired by Robin!</div>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-29T16:29:00Z">19 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Wednesday, July 27
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://scottaaronson.blog/?p=6599'>On black holes, holography, the Quantum Extended Church-Turing Thesis, fully homomorphic encryption, and brain uploading</a>
        </h3>
        <p class='item-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          I promise you: this post is going to tell a scientifically coherent story that involves all five topics listed in the title. Not one can be omitted. My story starts with a Zoom talk that the one and only Lenny Susskind delivered for the Simons Institute for Theory of Computing back in May. There followed [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <figure class="wp-block-image size-large"><img src="https://www.scottaaronson.com/alice.jpg" alt=""/></figure>



<p>I promise you: this post is going to tell a scientifically coherent story that involves <em>all five topics </em>listed in the title.  Not one can be omitted.</p>



<p>My story starts with a <a href="https://www.youtube.com/watch?v=1CpzigpEJnU">Zoom talk</a> that the one and only <a href="https://en.wikipedia.org/wiki/Leonard_Susskind">Lenny Susskind</a> delivered for the Simons Institute for Theory of Computing back in May.  There followed a panel discussion involving Lenny, Edward Witten, Geoffrey Penington, Umesh Vazirani, and your humble shtetlmaster.</p>



<p>Lenny&#8217;s talk led up to a gedankenexperiment involving an observer, Alice, who bravely jumps into a specially-prepared black hole, in order to see the answer to a certain computational problem in her final seconds before being ripped to shreds near the singularity.  Drawing on earlier work by <a href="https://arxiv.org/abs/1910.14646">Bouland, Fefferman, and Vazirani</a>, Lenny speculated that the computational problem could be exponentially hard even for a (standard) quantum computer.  Despite this, Lenny repeatedly insisted&#8212;indeed, he asked me again to stress here&#8212;that he was <em>not</em> claiming to violate the <a href="https://quantumcomputing.stackexchange.com/questions/6088/what-precisely-is-the-quantum-extended-church-turing-thesis">Quantum Extended Church-Turing Thesis</a> (QECTT), the statement that all of nature can be efficiently simulated by a standard quantum computer.  Instead, he was simply investigating how the QECTT needs to be <em>formulated</em> in order to be a true statement.</p>



<p>I didn&#8217;t understand this, to put it mildly.  If what Lenny was saying was right&#8212;i.e., if the infalling observer could see the answer to a computational problem not in <a href="https://en.wikipedia.org/wiki/BQP">BQP</a>, or Bounded-Error Quantum Polynomial-Time&#8212;then why <em>shouldn&#8217;t</em> we call that a violation of the QECTT?  Just like we call Shor&#8217;s quantum factoring algorithm a likely violation of the <em>classical</em> Extended Church-Turing Thesis, the thesis saying that nature can be efficiently simulated by a classical computer?  Granted, you don&#8217;t have to <em>die</em> in order to run Shor&#8217;s algorithm, as you do to run Lenny&#8217;s experiment.  But why should such implementation details matter from the lofty heights of computational complexity?</p>



<p>Alas, not only did Lenny never answer that in a way that made sense to me, he kept trying to shift the focus from real, physical black holes to &#8220;silicon spheres&#8221; made of qubits, which would be programmed to <em>simulate</em> the process of Alice jumping into the black hole (in a dual boundary description).  Say what?  Granting that Lenny&#8217;s silicon spheres, being quantum computers under another name, could clearly be simulated in BQP, wouldn&#8217;t this still leave the question about the computational powers of observers who jump into <em>actual</em> black holes&#8212;i.e., the question that we presumably cared about in the first place?</p>



<p>Confusing me even further, Witten seemed almost dismissive of the idea that Lenny&#8217;s gedankenexperiment raised any new issue for the QECTT&#8212;that is, any issue that wouldn&#8217;t already have been present in a universe without gravity.  But as to Witten&#8217;s reasons, the most I understood from his remarks was that he was worried about various &#8220;engineering&#8221; issues with implementing Lenny&#8217;s gedankenexperiment, involving gravitational backreaction and the like.  Ed Witten, now suddenly the practical guy!  I couldn&#8217;t even isolate the crux of disagreement between Susskind and Witten, since after all, they <em>agreed</em> (bizarrely, from my perspective) that the QECTT wasn&#8217;t violated.  Why wasn&#8217;t it?</p>



<p>Anyway, shortly afterward I <a href="https://scottaaronson.blog/?p=6457">attended the 28th Solvay Conference in Brussels</a>, where one of the central benefits I got&#8212;besides seeing friends after a long COVID absence and eating some amazing chocolate mousse&#8212;was a <em>dramatically</em> clearer understanding of the issues in Lenny&#8217;s gedankenexperiment.  I owe this improved understanding to conversations with many people at Solvay, but above all Daniel Gottesman and Daniel Harlow.  Lenny himself wasn&#8217;t there, other than in spirit, but I ran the Daniels&#8217; picture by him afterwards and he assented to all of its essentials.</p>



<p>The Daniels&#8217; picture is what I want to explain in this post.  Needless to say, I take sole responsibility for any errors in my presentation, as I <em>also</em> take sole responsibility for not understanding (or rather: not doing the work to translate into terms that I understood) what Susskind and Witten had said to me before.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>The first thing you need to understand about Lenny&#8217;s gedankenexperiment is that it takes place entirely in the context of <a href="https://en.wikipedia.org/wiki/AdS/CFT_correspondence">AdS/CFT</a>: the famous holographic duality between two types of physical theories that look wildly different.  Here AdS stands for <em>anti-de-Sitter</em>: a quantum theory of gravity describing a D-dimensional universe with a negative cosmological constant (i.e. hyperbolic geometry), one where black holes can form and evaporate and so forth.  Meanwhile, CFT stands for <em>conformal field theory</em>: a quantum field theory, with no apparent gravity (and hence no black holes), that lives on the (D-1)-dimensional boundary of the D-dimensional AdS space.  The staggering claim of AdS/CFT is that every physical question about the AdS bulk can be translated into an equivalent question about the CFT boundary, and vice versa, with a one-to-one mapping from states to states and observables to observables.  So in that sense, they&#8217;re actually the <em>same</em> theory, just viewed in two radically different ways.  AdS/CFT originally came out of string theory, but then <a href="https://www.math.columbia.edu/~woit/wordpress/?p=12981">notoriously</a> &#8220;swallowed its parent,&#8221; to the point where nowadays, if you go to what are still called &#8220;string theory&#8221; meetings, you&#8217;re liable to hear <em>vastly</em> more discussion of AdS/CFT than of actual strings.</p>



<p>Thankfully, the story I want to tell won&#8217;t depend on fine details of how AdS/CFT works.  Nevertheless, <em>you can&#8217;t just ignore the AdS/CFT part</em> as some technicality, in order to get on with the vivid tale of Alice jumping into a black hole, hoping to learn the answer to a beyond-BQP computational problem in her final seconds of existence.  The reason you can&#8217;t ignore it is that the whole beyond-BQP computational problem we&#8217;ll be talking about, involves the <em>translation</em> (or &#8220;dictionary&#8221;) between the AdS bulk and the CFT boundary.  If you like, then, it&#8217;s actually the chasm between bulk and boundary that plays the starring role in this story.  The more familiar chasm <em>within</em> the bulk, between the interior of a black hole and its exterior (the two separated by an <a href="https://en.wikipedia.org/wiki/Event_horizon">event horizon</a>), plays only a subsidiary role: that of causing the AdS/CFT dictionary to become exponentially complex, as far as anyone can tell.</p>



<p>Pause for a minute.  Previously I led you to believe that we&#8217;d be talking about an actual observer Alice, jumping into an actual physical black hole, and whether Alice could see the answer to a problem that&#8217;s intractable even for quantum computers in her last moments before hitting the singularity, and if so whether we should take that to refute the Quantum Extended Church-Turing Thesis.  What I&#8217;m saying now is so wildly at variance with that picture, that it had to be repeated to me about 10 times before I understood it.  Once I did understand, I then had to repeat it to <em>others</em> about 10 times before <em>they</em> understood.  And I don&#8217;t care if people ridicule me for that admission&#8212;how slow Scott and his friends must be, compared to string theorists!&#8212;because my only goal right now is to get <em>you</em> to understand it.</p>



<p>To say it again: Lenny has <em>not</em> proposed a way for Alice to surpass the complexity-theoretic power of quantum computers, even for a brief moment, by crossing the event horizon of a black hole.  If <em>that</em> was Alice&#8217;s goal when she jumped into the black hole, then alas, she probably sacrificed her life for nothing!  As far as anyone knows, Alice&#8217;s experiences, even after crossing the event horizon, ought to continue to be described extremely well by general relativity and quantum field theory (at least until she nears the singularity and dies), and therefore ought to be simulatable in BQP.  Granted, we don&#8217;t actually <em>know</em> this&#8212;you can call it an open problem if you like&#8212;but it seems like a reasonable guess.</p>



<p>In that case, though, what beyond-BQP problem was Lenny talking about, and what does it have to do with black holes?  Building on the <a href="https://arxiv.org/abs/1910.14646">Bouland-Fefferman-Vazirani paper</a>, Lenny was interested in a class of problems of the following form: Alice is given as input a pure quantum state |ψ⟩, which encodes a boundary CFT state, which is dual to an AdS bulk universe that contains a black hole.  Alice&#8217;s goal is, by examining |ψ⟩, to learn something about what&#8217;s <em>inside</em> the black hole.  For example: does the black hole interior contain &#8220;shockwaves,&#8221; and if so how many and what kind?  Does it contain a wormhole, connecting it to a different black hole in another universe?  If so, what&#8217;s the volume of that wormhole?  (Not the first question <em>I</em> would ask either, but bear with me.)</p>



<p>Now, when I say Alice is &#8220;given&#8221; the state |ψ⟩, this could mean several things: she could just be physically given a collection of <em>n</em> qubits.  Or, she could be given a gigantic table of 2<sup><em>n</em></sup> amplitudes.  Or, as a third possibility, she could be given a description of a quantum circuit that prepares |ψ⟩, say from the all-0 initial state |0<sup><em>n</em></sup>⟩.  Each of these possibilities leads to a different complexity-theoretic picture, and the differences are extremely interesting to <em>me</em>, so that&#8217;s what I mostly focused on in my remarks in the panel discussion after Lenny&#8217;s talk.  But it won&#8217;t matter much for the story I want to tell in this post.</p>



<p>However |ψ⟩ is given to Alice, the prediction of AdS/CFT is that |ψ⟩ encodes everything there is to know about the AdS bulk, <em>including</em> whatever is inside the black hole&#8212;but, and this is crucial, the information about what&#8217;s inside the black hole will be <em>pseudorandomly scrambled</em>.  In other words, it works like this: whatever simple thing you&#8217;d like to know about parts of the bulk that <em>aren&#8217;t</em> hidden behind event horizons&#8212;is there a star over here? some gravitational lensing over there? etc.&#8212;it seems that you could not only learn it by measuring |ψ⟩, but learn it <em>in polynomial time</em>, the dictionary between bulk and boundary being computationally efficient in that case.  (As with almost everything else in this subject, even <em>that</em> hasn&#8217;t been rigorously proven, though my postdoc Jason Pollack and I made <a href="https://www.scottaaronson.com/talks/discretebulk.pdf">some progress</a> this past spring by proving a piece of it.)  On the other hand, as soon as you want to know what&#8217;s <em>inside</em> an event horizon, the fact that there are no probes that an &#8220;observer at infinity&#8221; could apply to find out, seems to translate into the requisite measurements on |ψ⟩ being exponentially complex to apply.  (Technically, you&#8217;d have to measure an ensemble of poly(<em>n</em>) identical copies of |ψ⟩, but I&#8217;ll ignore that in what follows.)</p>



<p>In more detail, the relevant part of |ψ⟩ turns into a pseudorandom, scrambled mess: a mess that it&#8217;s plausible that no polynomial-size quantum circuit could even distinguish from the maximally mixed state.  So, while in principle the information is all there in |ψ⟩, getting it out seems as hard as various well-known problems in symmetric-key cryptography, if not literally NP-hard.  This is <em>way</em> beyond what we expect even a quantum computer to be able to do efficiently: indeed, after 30 years of quantum algorithms research, the best quantum speedup we know for this sort of task is typically just the quadratic speedup from Grover&#8217;s algorithm.</p>



<p>So now you understand why there was some hope that Alice, by jumping into a black hole, could solve a problem that&#8217;s exponentially hard for quantum computers!  Namely because, once she&#8217;s inside the black hole, she can just<em> see</em> the shockwaves, or the volume of the wormhole, or whatever, and no longer faces the exponentially hard task of decoding that information from |ψ⟩.  It&#8217;s as if the black hole has <em>solved the problem for her</em>, by physically instantiating the otherwise exponentially complex transformation between the bulk and boundary descriptions of |ψ⟩.</p>



<p>Having now gotten your hopes up, the next step in the story is to destroy them.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Here&#8217;s the fundamental problem: |ψ⟩ does <em>not</em> represent the CFT dual of a bulk universe that contains the black hole with the shockwaves or whatever, <em>and that also contains Alice herself, floating outside the black hole, and being given |ψ⟩ as an input.</em>&nbsp; Indeed, it&#8217;s unclear what the latter state would even mean: how do we get around the circularity in its definition?  How do we avoid an infinite regress, where |ψ⟩ would have to encode a copy of |ψ⟩ which would have to encode a copy of &#8230; and so on forever?  Furthermore, who created this |ψ⟩ to give to Alice?  We don&#8217;t normally imagine that an &#8220;input state&#8221; contains a complete description of the body and brain of the person whose job it is to learn the output.</p>



<p>By contrast, a scenario that we <em>can</em> define without circularity is this: Alice is given (via physical qubits, a giant table of amplitudes, an obfuscated quantum circuit, or whatever) a pure quantum state |ψ⟩, which represents the CFT dual of a hypothetical universe containing a black hole.&nbsp; Alice wants to learn what shockwaves or wormholes are inside the black hole, a problem plausibly conjectured not to have any ordinary polynomial-size quantum circuit that takes copies of |ψ⟩ as input.&nbsp; To &#8220;solve&#8221; the problem, Alice sets into motion the following sequence of events:</p>



<ol><li>Alice scans and uploads her own brain into a quantum computer, presumably destroying the original meat brain in the process!  The QC represents Alice, who now exists only virtually, via a state |φ⟩.</li><li>The QC performs entangling operations on |φ⟩ and |ψ⟩, which correspond to inserting Alice into the bulk of the universe described by |ψ⟩, and then having her fall into the black hole.</li><li>Now in simulated form, &#8220;Alice&#8221; (or so we assume, depending on our philosophical position) has the subjective experience of falling into the black hole and observing what&#8217;s inside.&nbsp; <em>Success!</em>  Given |ψ⟩ as input, we&#8217;ve now caused &#8220;Alice&#8221; (for some definition of &#8220;Alice&#8221;) to have observed the answer to the beyond-BQP computational problem.</li></ol>



<p>In the panel discussion, I now model Susskind as having proposed scenario 1-3, Witten as going along with 1-2 but rejecting 3 or not wanting to discuss it, and me as having made valid points about the computational complexity of simulating Alice&#8217;s experience in 1-3, yet while being radically mistaken about what the scenario <em>was</em> (I still thought an actual black hole was involved).</p>



<p>An obvious question is whether, having learned the answer, &#8220;Alice&#8221; can now get the answer back out to the &#8220;real, original&#8221; world.  Alas, the expectation is that this would require exponential time.  Why?  Because otherwise, this whole process would&#8217;ve constituted a subexponential-time algorithm for distinguishing random from pseudorandom states using an &#8220;ordinary&#8221; quantum computer!  Which is conjectured not to exist.</p>



<p>And what about Alice herself?  In polynomial time, could she return from &#8220;the Matrix,&#8221; back to a real-world biological body?  Sure she could, in principle&#8212;if, for example, the entire quantum computation were run in reverse.  But notice that reversing the computation would <em>also</em> make Alice forget the answer to the problem!  Which is not at all a coincidence: if the problem is outside BQP, then in general, Alice can know the answer <em>only</em> while she&#8217;s &#8220;inside the Matrix.&#8221;</p>



<p>Now that hopefully everything is crystal-clear and we&#8217;re all on the same page, what can we say about this scenario?&nbsp; In particular: <em>should</em> it cause us to reject or modify the QECTT itself?</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Daniel Gottesman, I thought, offered a brilliant reductio ad absurdum of the view that the simulated black hole scenario should count as a refutation of the QECTT.  Well, he didn&#8217;t <em>call</em> it a &#8220;reductio,&#8221; but I will.</p>



<p>For the reductio, let&#8217;s forget not only about quantum gravity but even about quantum mechanics itself, and go all the way back to classical computer science.&nbsp; A <a href="https://en.wikipedia.org/wiki/Homomorphic_encryption">fully homomorphic encryption scheme</a>, the <a href="https://crypto.stanford.edu/craig/craig-thesis.pdf">first example</a> of which was discovered by Craig Gentry 15 years ago, lets you do arbitrary computations on encrypted data without ever needing to decrypt it.&nbsp; It has both an encryption key, for encrypting the original plaintext data, and a separate decryption key, for decrypting the final answer.</p>



<p>Now suppose Alice has some homomorphically encrypted top-secret emails, which she&#8217;d like to read.&nbsp; She has the encryption key (which is public), but not the decryption key.</p>



<p><em>If</em> the homomorphic encryption scheme is secure against quantum computers&#8212;as the schemes discovered by Gentry and later researchers currently appear to be&#8212;and <em>if</em> the QECTT is true, then Alice&#8217;s goal is obviously infeasible: decrypting the data will take her exponential time.</p>



<p>Now, however, a classical version of Lenny comes along, and explains to Alice that she simply needs to do the following:</p>



<ol><li>Upload her own brain state into a classical computer, destroying the &#8220;meat&#8221; version in the process (who needed it?).</li><li>Using the known encryption key, homomorphically encrypt a computer program that simulates (and thereby, we presume, <em>enacts</em>) Alice&#8217;s consciousness.</li><li>Using the homomorphically encrypted Alice-brain, <em>together with</em> the homomorphically encrypted input data, do the homomorphic computations that simulate the process of Alice&#8217;s brain reading the top-secret emails.</li></ol>



<p>The claim would now be that, <em>inside the homomorphic encryption</em>, the simulated Alice has the subjective experience of reading the emails in the clear.&nbsp; Aha, therefore she &#8220;broke&#8221; the homomorphic encryption scheme!  Therefore, assuming that the scheme was secure even against quantum computers, the QECTT must be false!</p>



<p>According to Gottesman, this is almost perfectly analogous to Lenny&#8217;s black hole scenario.&nbsp; In particular, they share the property that &#8220;encryption is easy but decryption is hard.&#8221;&nbsp; &nbsp;Once she&#8217;s uploaded her brain, Alice can efficiently <em>enter</em> the homomorphically encrypted world to see the solution to a hard problem, just like she can efficiently <em>enter</em> the black hole world to do the same.&nbsp; In both cases, however, getting <em>back</em> to her normal world with the answer would then take Alice exponential time.&nbsp; Note that in the latter case, the difficulty is <em>not</em> so much about &#8220;escaping from a black hole,&#8221; as it is about inverting the AdS/CFT dictionary.</p>



<p>Going further, we can regard the AdS/CFT dictionary for regions behind event horizons as, itself, an <em>example</em> of a fully homomorphic encryption scheme&#8212;in this case, of course, one where the ciphertexts are quantum states.  This strikes me as potentially an important insight about AdS/CFT itself, even if that wasn&#8217;t Gottesman&#8217;s intention.  It complements many other recent connections between AdS/CFT and theoretical computer science, including the <a href="https://arxiv.org/abs/1411.7041">view of AdS/CFT as a quantum error-correcting code</a>, and the <a href="https://arxiv.org/pdf/1604.00354">connection between AdS/CFT and the Max-Flow/Min-Cut Theorem</a> (see also my <a href="https://www.scottaaronson.com/talks/discretebulk.pdf">talk</a> about my work with Jason Pollack).</p>



<p>So where&#8217;s the reductio?&nbsp; Well, when it&#8217;s put so starkly, I suspect that not many would regard Gottesman&#8217;s classical homomorphic encryption scenario as a &#8220;real&#8221; challenge to the QECTT.&nbsp; Or rather, people might say: yes, this raises fascinating questions for the philosophy of mind, but at any rate, we&#8217;re no longer talking about <em>physics</em>.&nbsp; Unlike with (say) quantum computing, no new <em>physical</em> phenomenon is being brought to light that lets an otherwise intractable computational problem be solved.&nbsp; Instead, it&#8217;s all about the <em>user herself</em>, about Alice, and which physical systems get to count as instantiating her.</p>



<p>It&#8217;s like, imagine Alice at the computer store, weighing which laptop to buy.  Besides weight, battery life, and price, she definitely does care about processing power.  She might even consider a quantum computer, if one is available.  Maybe even a computer with a black hole, wormhole, or closed timelike curve inside: as long as it gives the answers she wants, what does she care about the innards?  But a computer whose normal functioning would (pessimistically) kill her or (optimistically) radically change her own nature, trapping her in a simulated universe that she can escape only by forgetting the computer&#8217;s output?  Yeah, I don&#8217;t envy the computer salesman.</p>



<p>Anyway, if we&#8217;re going to say this about the homomorphic encryption scenario, then shouldn&#8217;t we say the same about the simulated black hole scenario?&nbsp; Again, from an &#8220;external&#8221; perspective, all that&#8217;s happening is a giant BQP computation.&nbsp; Anything beyond BQP that we consider to be happening, depends on adopting the standpoint of an observer who &#8220;jumps into the homomorphic encryption on the CFT boundary&#8221;&#8212;at which point, it would seem, we&#8217;re no longer talking about physics but about philosophy of mind.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>So, that was the story!  I promised you that it would integrally involve black holes, holography, the Quantum Extended Church-Turing Thesis, fully homomorphic encryption, <em>and</em> brain uploading, and I hope to have delivered on my promise.</p>



<p>Of course, while this blog post has forever cleared up all philosophical confusions about AdS/CFT and the Quantum Extended Church-Turing Thesis, many questions of a more technical nature remain.  For example: what about the original scenario?  <em>can</em> we argue that the experiences of bulk observers can be simulated in BQP, even when those observers jump into black holes?  Also, what can we say about the complexity class of problems to which the simulated Alice can learn the answers?  Could she even solve NP-complete problems in polynomial time this way, or at least invert one-way functions?  More broadly, what&#8217;s the power of &#8220;BQP with an oracle for applying the AdS/CFT dictionary&#8221;&#8212;once or multiple times, in one direction or both directions?</p>



<p>Lenny himself described his gedankenexperiment as exploring the power of a new complexity class that he called &#8220;JI/poly,&#8221; where the JI stands for &#8220;Jumping In&#8221; (to a black hole, that is).  The nomenclature is transparently ridiculous&#8212;&#8220;/poly&#8221; means &#8220;with polynomial-size advice,&#8221; which we&#8217;re <em>not</em> talking about here&#8212;and I&#8217;ve argued in this post that the &#8220;JI&#8221; is rather misleading as well.  If Alice is &#8220;jumping&#8221; anywhere, it&#8217;s not into a black hole <em>per se</em>, but into a quantum computer that simulates a CFT that&#8217;s dual to a bulk universe containing a black hole.</p>



<p>In a broader sense, though, to contemplate these questions at all is clearly to &#8220;jump in&#8221; to &#8230; <em>something</em>.  It&#8217;s old hat by now that one can start in physics and end up in philosophy: what else is the quantum measurement problem, or the Boltzmann brain problem, or anthropic cosmological puzzles like whether (all else equal) we&#8217;re a hundred times as likely to find ourselves in a universe with a hundred times as many observers?  More recently, it&#8217;s also become commonplace that one can start in physics and end in computational complexity theory: quantum computing itself is the example par excellence, but over the past decade, the <a href="https://arxiv.org/abs/1301.4504">Harlow-Hayden argument</a> about decoding Hawking radiation and the <a href="https://arxiv.org/abs/1509.07876">complexity = action proposal</a> have made clear that it can happen even in quantum gravity.</p>



<p>Lenny&#8217;s new gedankenexperiment, however, is the first case I&#8217;ve seen where you start out in physics, and end up embroiled in some of the hardest questions of philosophy of mind and computational complexity theory <em>simultaneously</em>.</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-27T22:54:34Z">21 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Wednesday, July 27
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://11011110.github.io/blog/2022/07/27/midsphere-facts-fallacies.html'>Midsphere facts and fallacies</a>
        </h3>
        <p class='item-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Some three-dimensional convex polyhedra have a midsphere, a sphere tangent to all of their edges. More strongly, every three-dimensional convex polyhedron has a combinatorially equivalent form, called a “canonical polyhedron”, that has a midsphere. The literature on midspheres is a little sparse and missing some key facts and counterexamples, so I thought I would collect some of them here.
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Some three-dimensional convex polyhedra have a <a href="https://en.wikipedia.org/wiki/Midsphere">midsphere</a>, a sphere tangent to all of their edges. More strongly, every three-dimensional convex polyhedron has a combinatorially equivalent form, called a “canonical polyhedron”, that has a midsphere. The literature on midspheres is a little sparse and missing some key facts and counterexamples, so I thought I would collect some of them here.</p>

<p style="text-align:center"><img src="/blog/assets/2017/midsphere.png" alt="A canonical polyhedron and its midsphere" /></p>

<p>The midsphere, when it exists, has a center equidistant from all the edges, and all of the lines through edges. The set of points equidistant from two <a href="https://en.wikipedia.org/wiki/Skew_lines">skew lines</a> is a curved surface, a <a href="https://en.wikipedia.org/wiki/Paraboloid">hyperbolic paraboloid</a>, but when two lines cross each other the set of points equidistant from both lines is instead the union of two planes, perpendicular to each other and to the plane of the crossing lines, through the crossing point of the two lines. For the midsphere of a polyhedron, and two edges incident on a face of the polyhedron, only one of these two planes is relevant, the one that bisects the interior angle of the face. The center of the midsphere (if it exists) can be found at the point where all of these face-angle-bisecting planes meet.</p>

<p>A convenient class of examples of polyhedra with midspheres is given by “Crelle’s tetrahedra”, the tetrahedra with midspheres. For every such tetrahedron, one can find four spheres, centered at the tetrahedron vertices, tangent in pairs at the points where the midsphere touches the edges. The tetrahedron’s six edge lengths are sums of radii of two of these four spheres. Conversely, for every four pairwise-externally-tangent spheres whose centers are not coplanar, the convex hull of the centers is one of Crelle’s tetrahedra. The radii of the four spheres can be varied continuously, keeping them in contact, although not every quadruple of radii works: the <a href="https://en.wikipedia.org/wiki/Cayley%E2%80%93Menger_determinant">Cayley–Menger determinant</a> of the six sums of pairs of radii must be positive. For instance, if three radii are equal and the fourth is much smaller, the three large spheres will be too far apart for the fourth sphere to touch all three of them and the determinant will be negative. Because Crelle’s tetrahedra can be parameterized by four radii, they form a four-dimensional subspace of the six-dimensional space of all tetrahedra (as parameterized by edge lengths).</p>

<p>Some sources either state that the midsphere touches the polyhedron edges at their midpoints, or define a midsphere to be a sphere through all the edge midpoints. But even when a polyhedron has both a midsphere and a sphere through all of its edge midpoints, these two spheres might not be the same as each other. An example is given by the right pyramids over equilateral triangles, parameterized by the quadruples of radii \((1,1,1,x)\) for \(x\ne 1\). These pyramids have an equilateral-triangle base, which both spheres touch at the edge midpoints. But the three edges of length \(1+x\) meeting at the apex of the pyramid are touched by the midsphere at unit distance from the base, rather than at their midpoints.</p>

<p>Anthony Pugh’s 1976 book <em>Polyhedra: A Visual Approach</em> <a href="https://books.google.com/books?id=IDDxpYQTR7kC&amp;pg=PA4">claims that only the Platonic solids have all three of an insphere, midsphere, and circumsphere</a>, but this is not true. Crelle’s tetrahedra are counterexamples. Even with the midpoint-based alternative definition of midspheres, the pyramids are counterexamples.</p>

<p>For a long time the Wikipedia article on midspheres stated that the midsphere gets its name from being between the insphere and circumsphere. But it is not always between them. For a very tall pyramid (with large \(x\)), the circumsphere passes very close to the plane of the equilateral triangle at the base of the pyramid, and the midsphere pokes out past the circumsphere below the base. I briefly thought that the midsphere might be the same as the smallest sphere that touches or contains all of the edges of a polyhedron. In general, even when a midsphere does not exist, this smallest sphere can be found in linear time, as an instance of <a href="https://arxiv.org/abs/cs.CG/0412046">quasiconvex programming</a>. But for very flat pyramids (\(x\) close to its minimum value), the smallest touching sphere has the incircle of the base as its equator, while the midsphere is larger. The same flat pyramids have an insphere that touches their isosceles-triangle faces at points close to the apex of the pyramid, outside the midsphere, so their insphere pokes out of the midsphere.</p>

<p>For most polyhedra having an insphere and a midsphere, or a midsphere and a circumsphere, these spheres are not concentric. They are concentric for symmetric polyhedra, such as the Platonic solids, but those are not the only cases. For instance, when a polyhedron with concentric midsphere and circumsphere, like a regular icosahedron, is sliced by the plane through a cycle of its edges, the result continues to have the same concentric midsphere and circumsphere. The <a href="https://en.wikipedia.org/wiki/Metabidiminished_icosahedron">metabidiminished icosahedron</a> below is an example. The polar dual of a polyhedron with concentric midsphere and circumsphere instead has concentric insphere and midsphere.</p>

<p style="text-align:center"><img src="/blog/assets/2022/metabidiminished.png" alt="Metabidiminished icosahedron, CC-BY-SA image by AndrewKepert, November 1, 2004, from https://commons.wikimedia.org/wiki/File:Metabidiminished_icosahedron.png" /></p>

<p>It may possibly be the case that the inradius is always less than the midradius (when both exist) and that the midradius is always less than the circumradius (when both exist). I don’t have a proof, but I also don’t have a counterexample.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/108722887534301591">Discuss on Mastodon</a>)</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-27T20:28:00Z">21 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://eccc.weizmann.ac.il/report/2022/109'>TR22-109 |  Searching for Regularity in Bounded Functions | 

	Siddharth Iyer, 

	Michael Whitmeyer</a>
        </h3>
        <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Given a function $f:\mathbb F_2^n \to [-1,1]$, this work seeks to find a large affine subspace $\mathcal U$ such that $f$, when restricted to $\mathcal U$, has small nontrivial Fourier coefficients.

We show that for any function $f:\mathbb F_2^n \to [-1,1]$ with Fourier degree $d$, there exists an affine subspace of dimension at least $ \tilde\Omega(n^{1/d!}k^{-2})$, wherein all of $f$&#39;s nontr
        
        </div>

        <div class='item-content item-summary'>
        
          
          Given a function $f:\mathbb F_2^n \to [-1,1]$, this work seeks to find a large affine subspace $\mathcal U$ such that $f$, when restricted to $\mathcal U$, has small nontrivial Fourier coefficients.

We show that for any function $f:\mathbb F_2^n \to [-1,1]$ with Fourier degree $d$, there exists an affine subspace of dimension at least $ \tilde\Omega(n^{1/d!}k^{-2})$, wherein all of $f$&#39;s nontrivial Fourier coefficients become smaller than $ 2^{-k}$. 
To complement this result, we show the existence of degree $d$ functions with coefficients larger than $2^{-d\log n}$ when restricted to any affine subspace of dimension larger than $\Omega(dn^{1/(d-1)})$. In addition, we give explicit examples of functions with analogous but weaker properties.

Along the way, we provide multiple characterizations of the Fourier coefficients of functions restricted to subspaces of $\mathbb F_2^n$ that may be useful in other contexts. Finally, we highlight applications and connections of our results to parity kill number and affine dispersers/extractors.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-27T12:58:49Z">21 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://tcsplus.wordpress.com/2022/07/26/tcs-we-want-your-feedback/'>TCS+: We want YOU(R feedback)</a>
        </h3>
        <p class='item-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          For the new season of TCS+, the organizers&#8217; team has been discussing a range of suggestions to improve our general format, and adapt it to the all-Zoom, COVID/post-COVID world. We would love your feedback on some of these ideas — if you could take a few minutes to answer the following survey (4-5 questions), this [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>For the new season of TCS+, the organizers&#8217; team has been discussing a range of suggestions to improve our general format, and adapt it to the all-Zoom, COVID/post-COVID world. We would love your feedback on some of these ideas — if you could take a few minutes to answer the following survey (4-5 questions), this would be greatly appreciated!</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f4cb.png" alt="📋" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://docs.google.com/forms/d/e/1FAIpQLSeNhfAeGsbCWHfZpoH3b2A3_pb1iD2h_H4YTgsiomhKNldmZA/viewform">Link to the survey</a> </p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-27T02:00:47Z">22 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Tuesday, July 19
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://scottaaronson.blog/?p=6576'>A low-tech solution</a>
        </h3>
        <p class='item-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Thanks so much to everyone who offered help and support as this blog&#8217;s comment section endured the weirdest, most motivated and sophisticated troll attack in its 17-year history. For a week, a parade of self-assured commenters showed up to demand that I explain and defend my personal hygiene, private thoughts, sexual preferences, and behavior around [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Thanks so much to everyone who offered help and support as this blog&#8217;s comment section endured the weirdest, most motivated and sophisticated troll attack in its 17-year history.  For a week, a parade of self-assured commenters showed up to demand that I explain and defend my personal hygiene, private thoughts, sexual preferences, and behavior around female students (and, absurdly, to cajole me into taking my family on a specific Disney cruise ship).  In many cases, the troll or trolls <em>appropriated the names and email addresses of real academics</em>, imitating them so convincingly that those academics&#8217; closest colleagues told me they were confident it was really them.  And when some trolls finally &#8220;outed&#8221; themselves, I had no way to know whether that was just another chapter in the trolling campaign.  It was enough to precipitate an epistemic crisis, where one actively doubts the authenticity of just about <em>every</em> piece of text.</p>



<p>The irony isn&#8217;t lost on me that I&#8217;ve endured this just as I&#8217;m <a href="https://scottaaronson.blog/?p=6484">starting my year-long gig at OpenAI</a>, to think, among other things, about the potential avenues for misuse of Large Language Models like GPT-3, and what theoretical computer science could contribute to mitigating them.  To say this episode has given me a more vivid understanding of the risks would be an understatement.</p>



<p><strong><em>But why didn&#8217;t I just block and ignore the trolls immediately?  Why did I bother engaging?</em></strong>  </p>



<p>At least a hundred people asked some variant of this question, and the answer is this.  For most of my professional life, this blog has been my forum, where anyone in the world could show up to raise any issue they wanted, as if we were tunic-wearing philosophers in the Athenian agora.  I prided myself on my refusal to take the coward&#8217;s way out and ignore anything&#8212;even, <em>especially</em>, severe personal criticism.  I&#8217;d witnessed how Jon Stewart, let&#8217;s say, would night after night completely eviscerate George W. Bush, his policies and worldview and way of speaking and justifications and lies, and then Bush would just continue the next day, totally oblivious, never deigning to rebut any of it.  And it became a core part of my identity that I&#8217;d never be like that.  If anyone on earth had a narrative of me where I was an arrogant bigot, a clueless idiot, etc., I&#8217;d confront that narrative head-on and refute it&#8212;or if I couldn&#8217;t, I&#8217;d reinvent my whole life.  What I&#8217;d <em>never</em> do is suffer anyone&#8217;s monstrous caricature of me to strut around the Internet unchallenged, as if conceding that only my academic prestige or tenure or power, rather than a reasoned rebuttal, could protect me from the harsh truths that the caricature revealed.</p>



<p>Over the years, of course, I carved out some exceptions: P=NP provers and quantum mechanics deniers enraged that I&#8217;d dismissed their world-changing insights.  Raving antisemites.  <em>Their</em> caricatures of me had no legs in any community I cared about.  But if an attack carried the implied backing of the whole modern social-justice movement, of thousands of angry grad students on Twitter, of <em>Slate</em> and <em>Salon</em> and <em>New York Times</em> writers and Wikipedia editors and university DEI offices, then the coward&#8217;s way out was closed.  The monstrous caricature then loomed directly over me; I could either parry his attacks or die.</p>



<p>With this stance, you might say, the astounding part is not that this blog&#8217;s &#8220;agora&#8221; model eventually broke down, but rather that it survived for so long!  I started blogging in October 2005.  It took until July 2022 for me to endure a full-scale &#8220;social/emotional denial of service attack&#8221; (not counting the comment-171 affair).  Now that I have, though, it&#8217;s obvious even to me that the old way is no longer tenable.</p>



<p>So what&#8217;s the solution?  Some of you liked the idea of requiring registration with real email addresses&#8212;but alas, when I tried to implement that, I found that WordPress&#8217;s registration system is a mess and I couldn&#8217;t see how to make it work.  Others liked the idea of moving to Substack, but others actively hated it, and in any case, even if I moved, I&#8217;d <em>still</em> have to figure out a comment policy!  Still others liked the idea of an army of volunteer moderators.  At least ten people volunteered themselves.</p>



<p>On reflection, the following strikes me as most directly addressing the actual problem.  I&#8217;m hereby establishing the <strong>Shtetl-Optimized Committee of Guardians</strong>, or SOCG (same acronym as the <a href="https://cse.buffalo.edu/socg21/socg.html">computational geometry conference</a> <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /> ).  If you&#8217;re interested in joining, shoot me an email, or leave a comment on this post with your (real!) email address.  I&#8217;ll accept members only if I know them in real life, personally or by reputation, or if they have an honorable history on this blog.</p>



<p>For now, the SOCG&#8217;s only job is this: whenever I get a comment that gives me a feeling of unease&#8212;because, e.g., it seems trollish or nasty or insincere, it asks a too-personal question, or it challenges me to rebut a hostile caricature of myself&#8212;I&#8217;ll email the comment to the SOCG and ask what to do.  I commit to respecting the verdict of those SOCG members who respond, whenever a clear verdict exists.  The verdict could be, e.g., &#8220;this seems fine,&#8221; &#8220;if you won&#8217;t be able to resist responding then don&#8217;t let this appear,&#8221; or &#8220;email the commenter first to confirm their identity.&#8221;  And if I simply need reassurance that the commenter&#8217;s view of me is false, I&#8217;ll seek it from the SOCG before I seek it from the whole world.</p>



<p>Here&#8217;s what SOCG members can expect in return: I continue pouring my heart into this subscription-free, ad-free blog, and I credit you for making it possible&#8212;publicly if you&#8217;re comfortable with your name being listed, privately if not.  I buy you a fancy lunch or dinner if we&#8217;re ever in the same town.</p>



<p>Eventually, we might move to a model where the SOCG members can log in to WordPress and directly moderate comments themselves.  But let&#8217;s try it this way first and see if it works.</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-19T18:27:35Z">29 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://cstheory-jobs.org/2022/07/26/two-2-year-postdocs-at-university-of-oxford-apply-by-september-12-2022/'>Two 2-year postdocs at University of Oxford (apply by September 12, 2022)</a>
        </h3>
        <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Two postdoc positions are available at Oxford as part of the UKRI Consolidator Grant &#8220;New Approaches to Approximability of Satisfiable Problems&#8221; led by Standa Zivny. Strong candidates with any background in maths or theoretical computer science will be considered. Background in approximation algorithms, universal algebra, category theory, combinatorics, or topology would be particularly
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Two postdoc positions are available at Oxford as part of the UKRI Consolidator Grant &#8220;New Approaches to Approximability of Satisfiable Problems&#8221; led by Standa Zivny. Strong candidates with any background in maths or theoretical computer science will be considered. Background in approximation algorithms, universal algebra, category theory, combinatorics, or topology would be particularly useful.</p>
<p>Website: <a href="http://www.cs.ox.ac.uk/news/2075-full.html">http://www.cs.ox.ac.uk/news/2075-full.html</a><br />
Email: standa.zivny@cs.ox.ac.uk</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-26T13:34:18Z">22 days ago</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://cstheory-jobs.org/2022/07/26/assistant-professor-3-posts-at-heriot-watt-university-uk-apply-by-august-15-2022/'>Assistant Professor (3 posts) at Heriot-Watt University, UK (apply by August 15, 2022)</a>
        </h3>
        <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We are looking for three assistant professors (T&#38;R) in Computer Science. The vacancy is not restricted to applicants working in any specific area, but the research of the successful candidate will fall into at least one of three themes the department organises itself around: interactive systems, intelligent systems, and rigorous systems. Website: enzj.fa.em3.oraclecloud.com/hcmUI/CandidateExper
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>We are looking for three assistant professors (T&amp;R) in Computer Science. The vacancy is not restricted to applicants working in any specific area, but the research of the successful candidate will fall into at least one of three themes the department organises itself around: interactive systems, intelligent systems, and rigorous systems.</p>
<p>Website: <a href="https://enzj.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX/job/2282/?utm_medium=jobshare">https://enzj.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX/job/2282/?utm_medium=jobshare</a><br />
Email: j.hage@hw.ac.uk</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-26T08:26:18Z">22 days ago</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Monday, July 25
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <h3 class='item-title'>
          <span class='item-caret'>
            <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
            <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
          </span>
          <a href='https://francisbach.com/rethinking-sgd-noise/'>Rethinking SGD’s noise</a>
        </h3>
        <p class='item-feed'>from <a href='https://francisbach.com'>Francis Bach</a></p>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          It seemed a bit unfair to devote a blog to machine learning (ML) without talking about its current core algorithm: stochastic gradient descent (SGD). Indeed, SGD has become, year after year, the basic foundation of many algorithms used for large-scale ML problems. However, the history of stochastic approximation is much older than that of ML:...
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="has-text-align-justify">It seemed a bit unfair to devote a blog to machine learning (ML) without talking about its current core algorithm: stochastic gradient descent (SGD). Indeed, SGD has become, year after year, the basic foundation of many algorithms used for large-scale ML problems.  However, the history of stochastic approximation is much older than that of ML: its first study by Robbins and Monro [<a rel="noreferrer noopener" href="https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-22/issue-3/A-Stochastic-Approximation-Method/10.1214/aoms/1177729586.full" data-type="URL" data-id="https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-22/issue-3/A-Stochastic-Approximation-Method/10.1214/aoms/1177729586.full" target="_blank">1</a>] dates back to 1951. Their aim was to find the zeros of a function that can only be accessed through noisy measurements; and this set-up was applied (and studied!) later on for many problems [<a rel="noreferrer noopener" href="https://link.springer.com/book/9783540606994" data-type="URL" data-id="https://link.springer.com/book/9783540606994" target="_blank">2</a>]. Stochastic gradient descent, in its most general definition, is simply the application of the Robbins and Monro&#8217;s procedure to find the zeros of the <em>gradient</em> of a function \(f\).</p>



<p class="has-text-align-justify">In this post, I will try to show that the instance of SGD used to solve modern ML problems carries rich particularities. In particular, we will put emphasis on the difference between the under and overparametrised regimes. To provide prototypical representations of these, we will try to cast the typical dynamics of each regime as a known stochastic process.</p>



<h2 class="has-text-align-left" id="fun-and-useful-facts-and-common-mistakes">General set-up</h2>



<p class="has-text-align-justify justify-text"><strong>Stochastic approximation.</strong> At each time \(t \in \mathbb{N}\) of the procedure, let us suppose that we only have access to an unbiased estimate of the gradient, \(\nabla f_t\), of a function \(f\) we want to minimise. More formally this means that given the information of the first \(t-1\) steps, denoted by \(\mathcal{F}_{t-1}\), the estimate we get at time \(t\) is centred around the true gradient: \(\displaystyle \mathbb{E}\left[ \nabla f_t (\theta_{t-1}) | \mathcal{F}_{t-1} \right] = \nabla f (\theta_{t-1})\). Then, the SGD iterates with step-sizes \((\gamma_t)_{t \in \mathbb{N}}\), and initialised at \(\theta_{t=0} = \theta_0\), write $$\theta_t = \theta_{t-1} &#8211; \gamma_t \nabla f_t (\theta_{t-1}).$$ To put the emphasis on the noise induced by the noisy estimates of the true gradient, we prefer sometimes to rephrase the recursion in term of the conditional zero-mean noise sequence \(\varepsilon_t = \nabla f &#8211; \nabla f_t\). $$\theta_t = \theta_{t-1} &#8211; \gamma_t \nabla f (\theta_{t-1}) + \gamma_t\varepsilon_t(\theta_{t-1}).$$ As we will see later, to analyse this discrete time stochastic dynamics, we crucially need to understand the behaviour of \((\varepsilon_t)_{t \in \mathbb{N}}\).</p>



<p class="has-text-align-justify"><strong>Supervised learning reformulation</strong>. This general recursion can be applied to many settings and fits particularly well to the supervised learning framework. In this case, the function to minimise is the empirical risk $$\mathcal{R}_n(\theta)=\mathbb{E}_{(X,Y)\sim\widehat{\rho}_n}\left[\ell((X,Y), \theta)\right] = \frac{1}{n}\sum_{i=1}^n \ell((x_i,y_i), \theta),$$ where \(\widehat{\rho}_n:= \frac{1}{n}\sum_{i=1}^n \delta_{(x_i,y_i)}\) is the empirical measure associated to the samples \((x_i, y_i)_{1 \leqslant i \leqslant n}\). We can derive an unbiased estimate \(\nabla_\theta \ell((x_{i_t},y_{i_t}), \theta)\) of its gradient where \((i_t)_t\) is the sequence of uniformly sampled indices over \(\{1,&#8230;,n\}\). The recursion reads: $$\theta_t = \theta_{t-1} &#8211; \gamma_t \nabla_\theta \ell((x_{i_t},y_{i_t}), \theta_{t-1}).$$ However, one of the real power of SGD is that it can be seen as a direct <em>stochastic</em> gradient method to optimise the true risk [<a rel="noreferrer noopener" href="https://proceedings.neurips.cc/paper/2007/hash/0d3180d672e08b4c5312dcdafdf6ef36-Abstract.html" data-type="URL" data-id="https://proceedings.neurips.cc/paper/2007/hash/0d3180d672e08b4c5312dcdafdf6ef36-Abstract.html" target="_blank">3</a>]. Indeed, recall that the true risk is \(\mathcal{R}(\theta) = \mathbb{E}_\rho\left[\ell((X,Y), \theta)\right]\) and consider an input/output sample pair \((x_i,y_i)\) drawn from \(\rho\). Now, \(\ell((x_i,y_i), \theta)\) is an unbiased estimate of the true risk \(\mathcal{R}(\theta)\) such that \(\nabla_\theta \ell((x_i,y_i), \theta)\) is an unbiased estimate of its  gradient. Hence, if we denote \(\mathcal{F}_t = \sigma((x_i,y_i), \ i\leqslant t)\), then the stochastic gradient descent optimises \(\mathcal{R}\) as long as new points \((x,y)\) are added in the data set  $$\theta_t = \theta_{t-1} &#8211; \gamma_t \nabla_\theta \ell((x_t,y_t), \theta_{t-1}).$$ This reveals the real strength of SGD against other types of gradient descent algorithm: beyond its low computational cost, as long as we use <em>unseen data</em>, SGD optimises <em>directly</em> <em>the true risk</em> although it is an <em>a priori</em> unknown function. As a consequence, the SGD algorithm, when using only fresh samples, cannot overfit the dataset and does not need any regularisation.</p>



<h2 id="matrix-functions">The noise of SGD in practical ML setting</h2>



<p class="has-text-align-justify">The story outlined in the previous paragraph has been very popular to explain the success of SGD. However, nowadays, the number of samples is usually way smaller than the number of iterations performed, i.e. \(t \gg n\): several <em>epochs</em> are made over the dataset and the fact that SGD is a stochastic approximation algorithm that minimises directly the true risk doesn&#8217;t hold any longer. Hence, from now on, let us set the <strong>data to \(n\) input/output pairs</strong> \((x_i,y_i)_{1 \leqslant i \leqslant n}\). </p>



<p class="has-text-align-justify">First, let us briefly present certain crucial properties of SGD in this setting (see also the nice paper [<a rel="noreferrer noopener" href="https://arxiv.org/pdf/2105.01650.pdf" data-type="URL" data-id="https://arxiv.org/pdf/2105.01650.pdf" target="_blank">8</a>] for more details). We take a parameterised family of predictors \(\{x \mapsto h(\theta,x), \ \text{for } \theta \in \Theta\}\), and assume that \(\ell\) is the square-loss. The empirical risk classically writes \(\mathcal{R}_n(\theta)= \frac{1}{2n}\sum_{i=1}^n (h(\theta,x_i)\, &#8211; y_i)^2\) and the SGD recursion can be rewritten as $$ \theta_t = \theta_{t-1} &#8211; \gamma \nabla \mathcal{R}_n (\theta_{t-1}) + \gamma \varepsilon_t(\theta_{t-1}), $$ where \(\varepsilon_t(\theta)\) is the noise term at time \(t\), which writes $$ \varepsilon_t(\theta):= \frac{1}{n} \sum_{j = 1}^n r_j(\theta) \nabla_\theta h(\theta, x_j)\, &#8211; r_{i_t}(\theta) \nabla_\theta h(\theta, x_{i_t}), $$ where for all \(i \in \{1,&#8230;,n \}\), we define the \(i\)-th residual \(r_i(\theta) = h(\theta,x_i)\, &#8211; y_i\). Note that while the expression written requires that the loss is the square-loss, the conclusions of this section extend to different losses (such as the logistic).</p>



<p class="has-text-align-justify"><strong>Multiplicative noise and additive noise.</strong> Let us call \(\theta^*\) any vector belonging to the set of critical points of the loss \(\mathcal{R}_n\), that is \(\nabla \mathcal{R}_n(\theta^*) = 0\) (note that, in the convex case, it is exactly the set of global minima of the loss). We say that we are in the <strong>&#8220;overparametrised&#8221; regime</strong> if there exists at least one interpolator which fits the data set, i.e. if there exists \(\theta^*\) such that \(R_n( \theta^*)=0\).&nbsp;Otherwise, we say that we are in the <strong>&#8220;underparametrised&#8221; regime</strong>. We now decompose the noise as the sum of two different noises, that will contribute differently to the dynamics: $$\varepsilon_t(\theta) = \underbrace{\varepsilon_t(\theta)\, &#8211; \varepsilon_t(\theta^*) }_{\text{Multiplicative noise}} +  \underbrace{\varepsilon_t(\theta^*)}_{\text{Additive noise}}. $$ If \(\varepsilon_t\) is \(L\)-Lipshitz continuous, which can be verified for instance if we use the squared loss, the term \(\varepsilon_t(\theta)\, &#8211; \varepsilon_t(\theta^*) \) converges to \(0\) when \(\theta\) approaches \(\theta^*\). This motivates the &#8220;multiplicative&#8221; denomination of this term. On the contrary, remark that the additive noise does not depend on the state of the dynamics, i.e. it is independent of \(\theta_t\). Notably, in the overparametrised regime, taking \(\theta^*\) as an interpolator, we see that \(\varepsilon_t(\theta^*)=0\): there is no additive noise in this case! This is part of the explanation of the very different optimisation dynamics observed in the underparametrised and overparametrised regimes [<a rel="noreferrer noopener" href="https://proceedings.mlr.press/v89/vaswani19a.html" data-type="URL" data-id="https://proceedings.mlr.press/v89/vaswani19a.html" target="_blank">14</a>, <a rel="noreferrer noopener" href="https://proceedings.mlr.press/v80/ma18a.html" data-type="URL" data-id="https://proceedings.mlr.press/v80/ma18a.html" target="_blank">15</a>].</p>



<p class="has-text-align-justify">As an illustration of these two distinct regimes, consider a least-squares problem: $$ \mathcal{R}_n(\theta)= \frac{1}{2n}\sum_{i=1}^n \big(\langle \theta,x_i\rangle\, &#8211; y_i\big)^2.$$ In the overparametrised setting, which typically requires that \(d \geqslant n\), where \(d\) is the dimension of the inputs, it is possible to interpolate the dataset and the noise vanishes at optimum. On the opposite, in any underparametrised setting, the global minimum of the loss function is strictly positive, and the noise&#8217;s variance is always lower-bounded: the presence of additive noise totally changes the nature of the dynamics as shown by the following pictures.</p>



<div class="wp-container-3 wp-block-columns">
<div class="wp-container-1 wp-block-column is-vertically-aligned-top" style="flex-basis:100%"><div class="wp-block-image justify-text">
<figure class="aligncenter size-full"><img width="720" height="480" src="https://francisbach.com/wp-content/uploads/2022/07/SGD_first-1.gif" alt="" class="wp-image-7442" /></figure></div></div>



<div class="wp-container-2 wp-block-column is-vertically-aligned-center" style="flex-basis:100%"><div class="wp-block-image justify-text">
<figure class="aligncenter size-full"><img loading="lazy" width="720" height="480" src="https://francisbach.com/wp-content/uploads/2022/07/SGD_noise_scale-1.gif" alt="" class="wp-image-7441" /></figure></div></div>
</div>



<div class="wp-container-5 is-vertical wp-block-group">
<div class="wp-container-4 is-vertical wp-block-group">
<p class="has-text-align-justify"><span style="text-decoration: underline">Left:</span> Iterates of SGD for underparametrised (blue) and overparametrised (orange) regimes. The ellipses represent different level sets of \(\mathcal{R}_n\). Inputs \((x_i)_{i\leqslant n}\) are the same in the two models: centred Gaussian with anisotropic covariance (\(n=100,\ d = 2\)). In the underparametrised setting, the outputs have been generated randomly, and there is no interpolator of the dataset, whereas in the overparametrised problem, we generated the outputs according to \(Y = X \theta^* \), where \(\theta^*\) is the unique global minimum of the first setup and hereby of the second as well.</p>



<p class="has-text-align-justify"><span style="text-decoration: underline">Right:</span> The \(\ell_2\)-norm of the SGD noise in \(\mathrm{log}\)-scale along iterations in the underparametrised (blue) and overparametrised (orange) regimes. In the underparametrised regime, the noise stays constant after \(\sim 75\) iterations, whereas the intensity of the noise goes to \(0\) linearly over the iterates.</p>
</div>



<p></p>



<p></p>
</div>



<p class="has-text-align-justify"><strong>Noise geometry.</strong> Another important fact to stress concerning the noise \(\varepsilon_t(\theta)\) is that, at state \(\theta\), it belongs to a specific linear space: \(\text{span}\{\nabla_\theta h(\theta, x_1), &#8230;, \nabla_\theta h(\theta, x_n) \}\). To provide an intuition on how restrictive it can be, consider once again our favourite linear model: in this case, \(\nabla_\theta h(\theta, x_i)=x_i\) and \(\varepsilon_t(\theta)\) belongs to \(\text{span}\{x_1, &#8230;, x_n \}\), which is a space of dimension at most \(n\). In the overparametrised case, this is a strict subspace of \(\mathbb{R}^d\): noise is degenerate in \(d-n\) directions! On the contrary, in the underparametrised setting, as \(d \leqslant n\) there is no specificity at this level.</p>



<div class="wp-container-12 wp-block-group"><div class="wp-block-group__inner-container">
<div class="wp-container-11 wp-block-columns">
<div class="wp-container-10 wp-block-column" style="flex-basis:100%">
<div class="wp-container-9 wp-block-columns">
<div class="wp-container-8 wp-block-column" style="flex-basis:100%">
<div class="wp-container-7 wp-block-columns are-vertically-aligned-top">
<div class="wp-container-6 wp-block-column is-vertically-aligned-top" style="flex-basis:100%"><div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img loading="lazy" src="https://francisbach.com/wp-content/uploads/2022/07/Geometric_bias-1024x691.png" alt="" class="wp-image-7090" width="442" height="297" srcset="https://francisbach.com/wp-content/uploads/2022/07/Geometric_bias-1024x691.png 1024w, https://francisbach.com/wp-content/uploads/2022/07/Geometric_bias-300x202.png 300w, https://francisbach.com/wp-content/uploads/2022/07/Geometric_bias-768x518.png 768w, https://francisbach.com/wp-content/uploads/2022/07/Geometric_bias-1536x1036.png 1536w, https://francisbach.com/wp-content/uploads/2022/07/Geometric_bias-2048x1381.png 2048w, https://francisbach.com/wp-content/uploads/2022/07/Geometric_bias-850x573.png 850w" sizes="(max-width: 442px) 100vw, 442px" /><figcaption>3D picture showing the geometric bias of SGD: in the least-squares setting, the iterates (red lines) stay in the affine space \(\theta_0 + \text{span}(x_i)\). The contours represent different levels set of the loss highlighting the translational invariance along the null space \(\text{Ker}(X)\).</figcaption></figure></div></div>
</div>
</div>
</div>
</div>
</div>
</div></div>



<h2 id="positivity-of-lowner-matrices">SGD as a Markov chain</h2>



<p class="has-text-align-justify">In this section, we develop a different point of view on the general SGD algorithm, that also provides helpful intuition: we try to understand its dynamics through a Markov chain interpretation.</p>



<p class="has-text-align-justify">The first key to understand the behaviour of SGD is that, with constant step-sizes \(\gamma_t = \gamma\), the iterates define an homogeneous <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Markov_chain" data-type="URL" data-id="https://en.wikipedia.org/wiki/Markov_chain" target="_blank">Markov chain</a> [<a rel="noreferrer noopener" href="https://link.springer.com/book/10.1007/978-1-4471-3267-7" data-type="URL" data-id="https://link.springer.com/book/10.1007/978-1-4471-3267-7" target="_blank">4</a>]. Let us recall the SGD recursion to keep it next to us.$$ \theta_t = \theta_{t-1} &#8211; \gamma\nabla \mathcal{R}_n (\theta_{t-1}) + \gamma\varepsilon_t(\theta_{t-1}). $$ This point of view induces a natural question: <em>does the distribution of the iterates converge to some limit we can characterise?</em> This will again depend on the regime: under or overparametrised. Roughly, for the former, with a constant step size \(\gamma\), the distribution will converge to a stationary distribution with a strictly positive variance (e.g. a Gaussian centred around \(\theta^*\) at scale \(\gamma^{1/2}\) [<a rel="noreferrer noopener" href="https://epubs.siam.org/doi/10.1137/0324039" data-type="URL" data-id="https://epubs.siam.org/doi/10.1137/0324039" target="_blank">5</a>]). Less understood is the fact that, for the latter, it will converge to a Dirac distribution \(\delta_{ \theta^*}\), with \(\theta^*\) being one <strong>specific interpolator</strong>, that will depend on the precise structure of the algorithm  (initialisation, set-size, architecture of the model&#8230; more details on this will be discussed in a future blog post)!</p>



<p class="has-text-align-justify"><strong>The underparametrised case.</strong> Recall that in this case, the additive noise is nondegenerate. Hence, the gradient and noise parts of the dynamics cannot cancel simultaneously and under some mild assumption on \(\mathcal{R}_n\), the dynamics equilibrates after a certain time: formally this means that the distribution of the iterates \((\theta_t)_{t \geqslant 0}\) converges to an invariant distribution \(\pi^\gamma\). Hence the question: <em>how far is \(\pi^\gamma\) from \(\delta_{\theta^*}\)</em>? Giving a general and precise answer to this question is not trivial, and more importantly, it depends heavily on the multiplicative part of the noise. For now, let us stick with some common modelling to study the recursion: we make the assumption that the noise does not depend on the current iterate \(\theta\) (multiplicative part is \(0\)). In this case, it has been shown that the iterates of SGD have Gaussian fluctuations around \(\theta^*\) at scale \(\gamma^{1/2}\) [<a rel="noreferrer noopener" href="https://epubs.siam.org/doi/10.1137/0324039" target="_blank">5</a>]. From this point of view, the smaller \(\gamma\), the closer to \(\theta^*\) we get and this justifies a known variance reduction technique: decaying step-sizes. Another technique to reduce the variance is to resort to averaging. Once again, to explain this, ergodic theorems for Markov chains [<a rel="noreferrer noopener" href="https://link.springer.com/book/10.1007/978-1-4471-3267-7" data-type="URL" data-id="https://link.springer.com/book/10.1007/978-1-4471-3267-7" target="_blank">4</a>] give us an important insight: the time-mean \(\bar{\theta}_t = \frac{1}{t+1} \sum_{i = 0}^t \theta_i\) converges to \(\bar{\theta}_\gamma = \mathbb{E}_{\pi^\gamma} [\theta]\) almost surely. Furthermore, some magic happens with the quadratic case, as we can show that \(\bar{\theta}_\gamma = \theta^*\), which implies,&nbsp; as a direct application of the strong law of large numbers, that \(\bar{\theta}_t\) converges almost surely to \(\theta^*\), and proves that averaging the iterates is relevant [<a rel="noreferrer noopener" href="https://papers.nips.cc/paper/2011/hash/40008b9a5380fcacce3976bf7c08af5b-Abstract.html" data-type="URL" data-id="https://papers.nips.cc/paper/2011/hash/40008b9a5380fcacce3976bf7c08af5b-Abstract.html" target="_blank">6</a>].</p>



<div class="wp-container-15 wp-block-columns">
<div class="wp-container-13 wp-block-column is-vertically-aligned-top" style="flex-basis:100%"><div class="wp-block-image justify-text">
<figure class="aligncenter size-full"><img loading="lazy" width="720" height="480" src="https://francisbach.com/wp-content/uploads/2022/07/Large_gamma_comparison-1.gif" alt="" class="wp-image-7446" /></figure></div></div>



<div class="wp-container-14 wp-block-column" style="flex-basis:100%"><div class="wp-block-image justify-text">
<figure class="aligncenter size-full"><img loading="lazy" width="720" height="480" src="https://francisbach.com/wp-content/uploads/2022/07/Medium_gamma_comparison-1.gif" alt="" class="wp-image-7448" /></figure></div></div>
</div>



<div class="wp-container-18 wp-block-columns">
<div class="wp-container-16 wp-block-column is-vertically-aligned-top" style="flex-basis:100%"><div class="wp-block-image justify-text">
<figure class="aligncenter size-full"><img loading="lazy" width="720" height="480" src="https://francisbach.com/wp-content/uploads/2022/07/Small_gamma_comparison-4.gif" alt="" class="wp-image-7447" /></figure></div></div>



<div class="wp-container-17 wp-block-column" style="flex-basis:100%">
<p class="has-text-align-justify">Here is a series of plots corresponding to different step-sizes \(\gamma\) showing the dynamics of plain SGD (blue), averaged SGD (red) and step-sizes decay at \(1/\sqrt{t}\) rate (orange)  in an underparametrised setting (\(n=100\), \(d=2\)). Plain SGD is always faster that the other two methods but the larger the \(\gamma\) the larger the variance at optimum is.</p>
</div>
</div>



<p class="has-text-align-justify">Note also that the same analysis can be done in the convex, yet nonquadratic case, indeed, in <a rel="noreferrer noopener" href="https://projecteuclid.org/journals/annals-of-statistics/volume-48/issue-3/Bridging-the-gap-between-constant-step-size-stochastic-gradient-descent/10.1214/19-AOS1850.full" data-type="URL" data-id="https://projecteuclid.org/journals/annals-of-statistics/volume-48/issue-3/Bridging-the-gap-between-constant-step-size-stochastic-gradient-descent/10.1214/19-AOS1850.full" target="_blank">[7]</a> the authors showed that the order of magnitude of the distance between \(\bar{\theta}_\gamma\) and \({\theta}^*\) is \(\gamma^2\).</p>



<p class="has-text-align-justify"><strong>The overparametrised case.</strong> We have seen in the previous section that both the scale of noise and the geometry are affected in this case. The effect of the geometry is a little bit difficult to handle at a general level and we will detail its role in specific examples (see below and in the next blog post to come). Concerning the scale, we have seen that the noise vanishes at a global optimum and that the closer to a global optimum, the smaller the intensity of the noise is. Hence, global optima are fixed points of the dynamics, and under technical assumptions (e.g. local attractiveness), it can be shown the dynamics eventually converge to one of them [<a rel="noreferrer noopener" href="https://arxiv.org/pdf/2105.01650.pdf" data-type="URL" data-id="https://arxiv.org/pdf/2105.01650.pdf" target="_blank">8</a>, <a rel="noreferrer noopener" href="https://proceedings.neurips.cc/paper/2021/hash/b4a0e0fbaa9f16d8947c49f4e610b549-Abstract.html" data-type="URL" data-id="https://proceedings.neurips.cc/paper/2021/hash/b4a0e0fbaa9f16d8947c49f4e610b549-Abstract.html" target="_blank">9</a>]. In this case, the nature of the dynamics is very different from the previous one: the distribution of the iterates \((\theta_t)_{t \geqslant 0}\) converges to \(\delta_{\theta^*}\) where \(\theta^*\) is a random variable in the set of interpolators! Remarkably, no variance reduction technique are required for convergence towards a global minimum!</p>



<h2 id="characterizing-all-matrix-monotone-functions">The stochastic gradient flow and the least-squares example</h2>



<p class="has-text-align-justify justify-text"><strong>Continuous time model of SGD.</strong> Continuous time counterparts of (discrete) numerical optimisation methods and Markov chains are well-worn subjects in applied mathematics and have found applications in machine learning in particular. Indeed, in recent years, gradient descent has been actively studied through <a rel="noreferrer noopener" href="https://francisbach.com/gradient-flows/" data-type="URL" data-id="https://francisbach.com/gradient-flows/" target="_blank">gradient flows</a>, which have led to convergence results for neural networks discussed in previous <a href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/">blog</a> <a rel="noreferrer noopener" href="https://francisbach.com/gradient-descent-for-wide-two-layer-neural-networks-implicit-bias/" data-type="URL" data-id="https://francisbach.com/gradient-descent-for-wide-two-layer-neural-networks-implicit-bias/" target="_blank">posts</a>. However, due to its stochasticity, SGD cannot be properly modelled as a deterministic flow. An interesting and natural approach is to consider stochastic differential equations (SDEs) $$ d \theta_t = b(t,\theta_t) d t + \sigma(t,\theta_t)d B_t, $$ where \((B_t)_{t \geqslant 0}\) is a standard Brownian motion [<a rel="noreferrer noopener" href="https://link.springer.com/book/10.1007/978-3-642-14394-6" data-type="URL" data-id="https://link.springer.com/book/10.1007/978-3-642-14394-6" target="_blank">10</a>]. In order to accurately represent the SGD dynamics, the drift term \(b\) and the noise \(\sigma\) should meet the following requirements:</p>



<div class="wp-container-19 is-vertical wp-block-group">
<p class="has-text-align-justify justify-text">(i) The drift term \(b\) should match the negative full gradient: \(b=-\nabla \mathcal{R}_n\).</p>



<p>(ii) The noise covariance \(\sigma\sigma^\top(t,\theta)\) should match \(\gamma\mathbb{E}[ \varepsilon_t(\theta_t) \varepsilon_t(\theta_t)^\top | \theta_t = \theta ]\).</p>



<p>(iii) The noise at state \(\theta\) should belong to \(\text{span}\{\nabla_\theta h(\theta, x_1), &#8230;, \nabla_\theta h(\theta, x_n) \}\).</p>



<p>\({\color{white} f} \)</p>
</div>



<p class="has-text-align-justify">Points (i) and (ii) imply that the SGD recursion corresponds in fact to the Euler-Maruyama discretisation with step-size \(\gamma\) of the SDE [<a rel="noreferrer noopener" href="https://jmlr.org/papers/v20/17-526.html" target="_blank">11</a>]. Hence, the SDE and the discrete models match perfectly for infinitesimal step-sizes (up to first order terms in \(\gamma\)) and the model is said to be <em>consistent</em>. Point (iii) states a geometrical property of the SGD noise and is of crucial importance for a proper modelisation.</p>



<p class="has-text-align-justify"><strong>The least-squares model.</strong> Consider once again our favourite least-squares model $$\mathcal{R}_n(\theta)= \frac{1}{2n}\sum_{i=1}^n (\langle \theta,x_i\rangle\, &#8211; y_i)^2,$$ and let \(X:= [x_1, &#8230;, x_n]^\top \in \mathbb{R}^{n \times d}\) be the data matrix and \(y = [y_1, &#8230;, y_n]^\top \in \mathbb{R}^n\) the vector of outputs. Let us explicitly write the SDE model in this case: the drift corresponds to the gradient \(b(\theta)=- \frac{1}{n}X^\top (X\theta &#8211; y) \) and it is simple linear algebra to calculate the covariance of the noise (see also [<a rel="noreferrer noopener" href="https://proceedings.mlr.press/v119/ali20a.html" data-type="URL" data-id="https://proceedings.mlr.press/v119/ali20a.html" target="_blank">19</a>, Remark 4])$$ \sigma \sigma^\top(\theta) =&nbsp; \frac{\gamma}{n} X^\top \left(\textrm{diag}\left[ \big(\langle \theta, x_i\rangle\, &#8211; y_i\big)^2 \right]_{i=1}^n &#8211; \frac{1}{n}&nbsp; \left[ \big(\langle \theta, x_i\rangle\, &#8211; y_i\big)\big(\langle \theta, x_j\rangle\, &#8211; y_j\big) \right]_{i,j=1}^n&nbsp; \right) X. $$ To simplify a bit this analysis let us neglect the residual term of order \(1/n^2\) and assume that the residuals \(\langle \theta, x_i\rangle &#8211; y_i\), are approximately equal across all the samples of the data set: \(\textrm{diag}\left[ \left(\langle \theta, x_i\rangle\, &#8211; y_i\right)^2 \right]_{i=1}^n \simeq \frac{1}{n}\|X \theta\, &#8211; y\|^2 I_n \). Then the SDE model writes: $$d \theta_t =\, &#8211; \frac{1}{n}X^\top (X\theta_t\, &#8211; y) d t + \frac{\sqrt{\gamma}}{n} \| X\theta_t -y \| X^\top d B_t. $$ As stressed before, notice that there is an important difference between the under and overparametrised regimes: in the former, the noise spans all \(\mathbb{R}^d\) and as there exists \(\sigma &gt; 0\) such that \(\| X\theta_t -y \| \geqslant \sigma \), the noise is non degenerate in every direction. Instead, in the overparametrised regime, the noise vanishes at a global optimum \(\theta^*\) and is degenerate in the directions of \([\mathrm{range} (X^\top)]^\perp = \mathrm{Ker} (X)\). As also noticed in [<a rel="noreferrer noopener" href="https://proceedings.mlr.press/v119/ali20a.html" target="_blank">19</a>], this will result in important differences in term of the processes&#8217; behaviour! In the rest of the post, let us denote \(\theta^{\text{LS}}:= X^\dagger y\), where \(X^\dagger\) is the pseudo inverse of \(X\). It corresponds to the ordinary least-square estimator in the underparametrised regime and the projection of \(0\) into \(\mathrm{Ker} (X)\) in the overparametrised setting.</p>



<p class="has-text-align-justify"><strong>The underparametrised regime and the multivariate <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process" data-type="URL" data-id="https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process" target="_blank">Ornstein–Uhlenbeck process</a>.</strong> As written before, let us consider a model where the residuals scale like the best possible fit, i.e.&nbsp; \(\frac{1}{\sqrt{n}}\| X\theta_t -y \| \simeq \sigma \). The dynamics reads: $$ d \theta_t =\, &#8211; \frac{1}{n}X^\top (X\theta_t\, &#8211; y) d t + \sqrt{\frac{\gamma}{n}} \sigma&nbsp; X^\top d B_t. $$ This can be viewed as a <em>multivariate <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process" data-type="URL" data-id="https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process" target="_blank">Ornstein–Uhlenbeck process</a></em> for which we can show the following convergence result: the law \(\pi_t\) of \(\theta_t\) converges to \(\pi^\gamma\), a Gaussian distribution of mean \(\theta^{\text{LS}}\) and covariance \(\frac{\gamma \sigma^2}{2} I_d\): $$\lim_{t \to \infty} \pi_t =\mathcal{N} \left( \theta^{\text{LS}}, \frac{\gamma \sigma^2}{2} I_d \right).$$ From this, as for the Markov chain interpretation, we can nicely interpret the need to decrease step-sizes to \(0\) in order to concentrate to \(\theta^{\text{LS}}\). Similarly, note that the ergodic theorem gives you automatically that the time average of \(\theta_t\) goes to \(\theta^{\text{LS}}\) as $$\qquad \qquad \qquad \lim_{t \to \infty} \frac{1}{t}\int_0^t \theta_s ds = \mathbb{E}[\pi^\gamma]=\theta^{\text{LS}}, \qquad \text{almost surely}.$$ Besides its nice interpretation as a Ornstein-Uhlenbeck process, we illustrate below the predictive power of the SDE model to understand the SGD dynamics.</p>



<div class="wp-container-22 wp-block-columns">
<div class="wp-container-20 wp-block-column is-vertically-aligned-top" style="flex-basis:100%"><div class="wp-block-image justify-text">
<figure class="aligncenter size-full"><img loading="lazy" width="720" height="480" src="https://francisbach.com/wp-content/uploads/2022/07/SGD_SDE_under-1.gif" alt="" class="wp-image-7449" /></figure></div></div>



<div class="wp-container-21 wp-block-column" style="flex-basis:100%"><div class="wp-block-image justify-text">
<figure class="aligncenter size-full"><img loading="lazy" width="720" height="480" src="https://francisbach.com/wp-content/uploads/2022/07/hist-2.gif" alt="" class="wp-image-7444" /></figure></div></div>
</div>



<div class="wp-container-25 wp-block-group"><div class="wp-block-group__inner-container">
<div class="wp-container-24 wp-block-group"><div class="wp-block-group__inner-container">
<div class="wp-container-23 is-vertical wp-block-group">
<p class="has-text-align-justify"><span style="text-decoration: underline">Left</span>: \(10\) realisations of SGD in blue-like colours (corresponding to \(10\) different random sampling sequences), next to \(10\) realisations of the SDE model in red-like colours  (corresponding to \(10\) different realisations of the Brownian motion). </p>



<p class="has-text-align-justify"><span style="text-decoration: underline">Right</span>: A histogram of snap-shots of the SGD dynamics (marginal along the first coordinate) at increasing time intervals that show the convergence (by ergodicity) to the predicted Gaussian \(\mathcal{N}(\theta^{\text{LS}}, \gamma \sigma^2/2)\) ! </p>
</div>
</div></div>
</div></div>



<p></p>



<p class="has-text-align-justify justify-text"><strong>The overparametrised regime and the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Geometric_Brownian_motion" data-type="URL" data-id="https://en.wikipedia.org/wiki/Geometric_Brownian_motion" target="_blank">geometric Brownian motion</a></strong>. We take back our SDE model, initialise it at \(\theta_0 = 0\), but now we are extra careful that the noise cancels at any interpolator \(\theta^*\). We will show that despite being a random process, the dynamics with constant \(\gamma &gt; 0\) converges almost surely to \(\theta^{\text{LS}}\).&nbsp;To do so let us consider the evolution of the  squared difference \(\eta_t = \|\theta_t &#8211; \theta^{\text{LS}}\|^2\). Thanks to <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/It%C3%B4_calculus" data-type="URL" data-id="https://en.wikipedia.org/wiki/It%C3%B4_calculus" target="_blank">Itô calculus</a> (chain rule for stochastic processes), $$\begin{aligned} d \eta_t &amp;= 2 \langle d \theta_t, \theta_t &#8211; \theta^{\text{LS}} \rangle + \frac{\gamma}{n^2} \mathrm{tr} (X^\top X) \| X (\theta_t &#8211; \theta^{\text{LS}}) \|^2 &nbsp; dt \\ &amp;=&nbsp; 2\left( \gamma \mathrm{tr} \left(n^{-1}X^\top X\right) &#8211; 2 \right) \mathcal{R}_n(\theta_t) dt + 4\sqrt{\gamma}\mathcal{R}_n(\theta_t) dW_t, \end{aligned} $$ where \((W_t)_{t \geqslant 0}\) is a one dimensional Brownian motion (see details of this calculation at the end of the post). To simplify the calculation set the step-size such that \(\gamma \mathrm{tr} (n^{-1}X^\top X) = 1\) (note that we retrieve here the usual step-size for least-squares SGD [<a rel="noreferrer noopener" href="https://proceedings.mlr.press/v38/defossez15.html" data-type="URL" data-id="https://proceedings.mlr.press/v38/defossez15.html" target="_blank">16</a>]). Noting \(\mu_t = \frac{2\mathcal{R}_n(\theta_t)}{\eta_t}\) and \(\nu_t = \frac{4\sqrt{\gamma}\mathcal{R}_n(\theta_t)}{\eta_t}\), the dynamics of \((\eta_t)_{t \geqslant 0}\) follows $$d&nbsp; \eta_t =&nbsp; -\mu_t&nbsp; \eta_t dt + \nu_t \eta_t dW_t, $$ Furthermore, as \(\theta_t &#8211; \theta^{\text{LS}} \in \mathrm{span} (X^\top)\) , we have \(\mu\cdot \eta_t\leqslant 2 \mathcal{R}_n(\theta_t) \leqslant L\cdot \eta_t\), where \(\mu\) and \(L\) stand respectively for the minimum and maximum eigenvalues of \(\frac{1}{n}XX^\top\). Hence, the behaviour of \((\eta_t)_{t \geqslant 0}\) is approximately the same as that of the solution to the following SDE: $$d&nbsp; S_t =&nbsp; -\mu&nbsp; S_t dt + \nu S_t dW_t, $$ for \(\nu \simeq 4 L \sqrt{\gamma}\). That is, the dynamics of \((\|\theta_t &#8211; \theta^{\text{LS}}\|^2)_{t \geqslant 0}\) is approximately the one of a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Geometric_Brownian_motion" data-type="URL" data-id="https://en.wikipedia.org/wiki/Geometric_Brownian_motion" target="_blank">Geometric Brownian Motion</a> (GBO), a.k.a. the process underlying the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model" data-type="URL" data-id="https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model" target="_blank">Black-Scholes model</a>! Hence, to understand SGD in the overparametrised regime, one &#8220;simply&#8221; need to study the properties of the GBO. It is known that in fact there is an explicit solution of this SDE $$ S_t =&nbsp; S_0 \exp\left( -\left(\mu + \frac{\nu^2}{2}\right) t&nbsp; + \nu W_t\right). $$ Hence, for all \(t&gt;0\), \(S_t\) is distributed according to a log-normal random variable with mean \(\mathbb{E}(S_t) = S_0 e^{- \mu t}\) and variance \(\text{var}(S_t) = S_0^2 e^{- 2\mu t} (e^{\nu^2 t} &#8211; 1)\). Furthermore, it is a nice application to the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Law_of_the_iterated_logarithm" data-type="URL" data-id="https://en.wikipedia.org/wiki/Law_of_the_iterated_logarithm" target="_blank">law of the iterated logarithm</a> for the Brownian motion to show that&nbsp; $$ \qquad \qquad \qquad \lim_{t \to \infty} S_t = 0, \qquad \text{almost surely!} $$ The almost sure convergence of \((\theta_t)_{t \geqslant 0}\) to \(\theta^{\text{LS}}\) is in stark contrast with the limiting behaviour we have seen in the underparametrised setting. Remarkably, the process does not require any variance reduction to converge to a specific point. Note also that among all the possible interpolators the process could have converged to, the process in fact goes almost surely to \(\theta^{\text{LS}}\). This selection of the minimum norm interpolator [<a rel="noreferrer noopener" href="https://openreview.net/forum?id=Sy8gdB9xx" data-type="URL" data-id="https://openreview.net/forum?id=Sy8gdB9xx" target="_blank">12</a>], known as the implicit bias of the process  will be the core of a next blog post (for more complex architectures).</p>



<p>As in the underparametrised case, below are two plots showing the typical behaviour of the SGD dynamics as a GBO.</p>



<div class="wp-container-28 wp-block-columns">
<div class="wp-container-26 wp-block-column is-vertically-aligned-top" style="flex-basis:100%"><div class="wp-block-image justify-text">
<figure class="aligncenter size-full"><img loading="lazy" width="720" height="480" src="https://francisbach.com/wp-content/uploads/2022/07/SGD_SDE_over-1.gif" alt="" class="wp-image-7445" /></figure></div></div>



<div class="wp-container-27 wp-block-column" style="flex-basis:100%"><div class="wp-block-image justify-text">
<figure class="aligncenter size-full"><img loading="lazy" width="720" height="480" src="https://francisbach.com/wp-content/uploads/2022/07/Geometric_brownian-1.gif" alt="" class="wp-image-7443" /></figure></div></div>
</div>



<div class="wp-container-29 is-vertical wp-block-group">
<p><span style="text-decoration: underline">Left</span>: \(10\) realisations of SGD in blue-like colours (corresponding to \(10\) different random sampling sequences), next to \(10\) realisations of the SDE model in red-like colours (corresponding to \(10\) different realisations of the Brownian motion). </p>



<p><span style="text-decoration: underline">Right</span>: The exponential convergence of  \(\eta_t = \|\theta_t &#8211; \theta^{\text{LS}}\|^2\) to \(0\) for the \(10\) realisations of SGD and the SDE (in log-scale).</p>



<p></p>



<p></p>
</div>



<h2 id="conclusion">Conclusion</h2>



<p class="has-text-align-justify">In this blog post, I have tried to show that despite the old legacy inherited from the stochastic approximation literature, the particularities of the noise of the stochastic gradient descent in machine learning contexts necessitate a fresh look.  This specificity strikes the most in modern overparametrised models as the noise can be largely degenerate, both (i) in direction (which I called <em>noise geometry</em>), and (ii) in scale, as its variance is dominated by the loss and hence vanishes at a global optimum. In fact I have tried to show that SDE models can be a relevant framework to shed light on typical behaviours of stochastic learning dynamics: for overparametrised architectures, they differentiate from the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Langevin_dynamics" data-type="URL" data-id="https://en.wikipedia.org/wiki/Langevin_dynamics" target="_blank">overdamped Langevin diffusion model</a>, and act as multiplicative noise dynamics like the geometric brownian motion.</p>



<p class="has-text-align-justify">Besides, as it is believed that stochasticity plays a role in the generalisation performances of optimisation algorithms [<a rel="noreferrer noopener" href="https://arxiv.org/pdf/1609.04836.pdf" data-type="URL" data-id="https://arxiv.org/pdf/1609.04836.pdf" target="_blank">13</a>], there is a need to consider its action precisely. Yet, grasping its overall nature appears to be particularly hard as it mixes properties from the model’s architecture, the data’s distribution and the loss. In a following post, I will try to analyse some simple non-convex models where we can show that the SGD-noise drives the dynamics to possibly &#8220;good for generalisation&#8221; regions [<a rel="noreferrer noopener" href="https://proceedings.neurips.cc/paper/2021/hash/f4661398cb1a3abd3ffe58600bf11322-Abstract.html" data-type="URL" data-id="https://proceedings.neurips.cc/paper/2021/hash/f4661398cb1a3abd3ffe58600bf11322-Abstract.html" target="_blank">17</a>,<a rel="noreferrer noopener" href="https://proceedings.mlr.press/v178/vivien22a.html" data-type="URL" data-id="https://proceedings.mlr.press/v178/vivien22a.html" target="_blank">18</a>].<br><br><strong>Acknowledgements</strong>. I would like to thank Scott Pesme and Etienne Boursier for fruitful discussions, and especially <a href="https://open.spotify.com/track/1r6EJWSoh9Kzn6L38BhYS6?si=b352952e9bac4420" data-type="URL" data-id="https://open.spotify.com/track/1r6EJWSoh9Kzn6L38BhYS6?si=b352952e9bac4420" target="_blank" rel="noreferrer noopener">Nicolas Le Hir</a> for proofreading this blog post and making good clarifying suggestions.</p>



<h2 id="references">References</h2>



<div class="wp-container-40 is-vertical wp-block-group">
<div class="wp-container-39 is-vertical wp-block-group">
<div class="wp-container-38 is-vertical wp-block-group">
<div class="wp-container-37 wp-block-group"><div class="wp-block-group__inner-container">
<div class="wp-container-36 is-vertical wp-block-group">
<div class="wp-container-35 is-vertical wp-block-group">
<div class="wp-container-34 is-vertical wp-block-group">
<div class="wp-container-33 is-vertical wp-block-group">
<div class="wp-container-32 is-vertical wp-block-group">
<div class="wp-container-31 is-vertical wp-block-group">
<div class="wp-container-30 is-vertical wp-block-group">
<p class="justify-text">[1] Herbert Robbins and Sutton Monro. <a rel="noreferrer noopener" href="https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-22/issue-3/A-Stochastic-Approximation-Method/10.1214/aoms/1177729586.full" data-type="URL" data-id="https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-22/issue-3/A-Stochastic-Approximation-Method/10.1214/aoms/1177729586.full" target="_blank">A Stochastic Approximation Method</a>. The Annals of Mathematical Statistics, 22 (3): 400 &#8211; 407, September, 1951.<br>[2] Marie Duflo. <a rel="noreferrer noopener" href="https://link.springer.com/book/9783540606994" data-type="URL" data-id="https://link.springer.com/book/9783540606994" target="_blank">Algorithmes stochastiques</a>. Volume 23 of Mathématiques &amp; Applications (Berlin) [Mathematics &amp; Applications]. Springer-Verlag, Berlin, 1996<br>[3] Léon Bottou and Olivier Bousquet. <a rel="noreferrer noopener" href="https://proceedings.neurips.cc/paper/2007/hash/0d3180d672e08b4c5312dcdafdf6ef36-Abstract.html" data-type="URL" data-id="https://proceedings.neurips.cc/paper/2007/hash/0d3180d672e08b4c5312dcdafdf6ef36-Abstract.html" target="_blank">The Tradeoffs of Large Scale Learning</a>, In Advances in Neural Information Processing Systems, vol.20, 161-168, 2008.<br>[4] Sean P.Meyn and Richard L. Tweedie. <a rel="noreferrer noopener" href="https://link.springer.com/book/10.1007/978-1-4471-3267-7" data-type="URL" data-id="https://link.springer.com/book/10.1007/978-1-4471-3267-7" target="_blank">Markov Chains and Stochastic Stability.</a> Springer, London, 1993.<br>[5] Georg Ch. Pflug. <a rel="noreferrer noopener" href="https://epubs.siam.org/doi/10.1137/0324039" data-type="URL" data-id="https://epubs.siam.org/doi/10.1137/0324039" target="_blank">Stochastic minimization with constant step-size: asymptotic laws</a>. SIAM Journal on Control and Optimization, 24(4):655–666, 1986.<br>[6] Francis Bach and Eric Moulines. <a rel="noreferrer noopener" href="https://papers.nips.cc/paper/2011/hash/40008b9a5380fcacce3976bf7c08af5b-Abstract.html" data-type="URL" data-id="https://papers.nips.cc/paper/2011/hash/40008b9a5380fcacce3976bf7c08af5b-Abstract.html" target="_blank">Non-asymptotic analysis of stochastic approximation algorithms for machine learning.</a> In Advances in Neural Information Processing Systems (NIPS), 2011.<br>[7] Aymeric Dieuleveut, Alain Durmus and Francis Bach. <a rel="noreferrer noopener" href="https://projecteuclid.org/journals/annals-of-statistics/volume-48/issue-3/Bridging-the-gap-between-constant-step-size-stochastic-gradient-descent/10.1214/19-AOS1850.full" target="_blank">Bridging the gap between constant step size stochastic gradient descent and Markov chains.</a> The Annals of Statistics, 48 (3): 1348 &#8211; 1382, June 2020.<br>[8] Stephan Wojtowytsch. <a rel="noreferrer noopener" href="https://arxiv.org/pdf/2105.01650.pdf" target="_blank">Stochastic gradient descent with noise of machine learning type.</a> Part I: Discrete time analysis Technical Report, arXiv-2105.01650, 2021.<br>[9] Aditya Varre, Loucas Pillaud-Vivien and Nicolas Flammarion. <a rel="noreferrer noopener" href="https://proceedings.neurips.cc/paper/2021/hash/b4a0e0fbaa9f16d8947c49f4e610b549-Abstract.html" target="_blank">Last iterate convergence of SGD for Least-Squares in the Interpolation regime.</a> Advances in Neural Information Processing Systems 34, 21581-21591, 2021.<br>[10] Bernt Øksendal. <a rel="noreferrer noopener" href="https://link.springer.com/content/pdf/10.1007/978-3-642-14394-6_5.pdf" target="_blank">Stochastic Differential Equations: An Introduction with Applications</a>, 6th edition. Springer, New York, 2003.<br>[11] Qianxiao Li, Cheng Tai, and Weinan E. <a rel="noreferrer noopener" href="https://jmlr.org/papers/v20/17-526.html" target="_blank">Stochastic modified equations and dynamics of stochastic gradient algorithms i: Mathematical foundations.</a> Journal of Machine Learning Research, 20(40):1–47, 2019.<br>[12] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. <a rel="noreferrer noopener" href="https://openreview.net/forum?id=Sy8gdB9xx" target="_blank">Understanding deep learning requires rethinking generalization</a>. In International Conference on Learning Representations, 2017.<br>[13] Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. <a rel="noreferrer noopener" href="https://arxiv.org/pdf/1609.04836.pdf" data-type="URL" data-id="https://arxiv.org/pdf/1609.04836.pdf" target="_blank">On large-batch training for deep learning: Generalization gap and sharp minima.</a> In International Conference on Learning Representations, 2017.<br>[14] Sharan Vaswani, Francis Bach and Mark Schmidt. <a rel="noreferrer noopener" href="https://proceedings.mlr.press/v89/vaswani19a.html" data-type="URL" data-id="https://proceedings.mlr.press/v89/vaswani19a.html" target="_blank">Fast and Faster Convergence of SGD for Over-Parameterized Models and an Accelerated Perceptron</a>. Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics, PMLR 89:1195-1204, 2019.<br>[15] Siyuan Ma, Raef Bassily and Mikhail Belkin. <a rel="noreferrer noopener" href="https://proceedings.mlr.press/v80/ma18a.html" data-type="URL" data-id="https://proceedings.mlr.press/v80/ma18a.html" target="_blank">The Power of Interpolation: Understanding the Effectiveness of SGD in Modern Over-parametrized Learning</a>. Proceedings of the 35th International Conference on Machine Learning, PMLR 80:3325-3334, 2018.<br>[16] Alexandre Defossez and Francis Bach. <a rel="noreferrer noopener" href="https://proceedings.mlr.press/v38/defossez15.html" data-type="URL" data-id="https://proceedings.mlr.press/v38/defossez15.html" target="_blank">Averaged Least-Mean-Squares: Bias-Variance Trade-offs and Optimal Sampling Distributions.</a> Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics, PMLR 38:205-213, 2015.<br>[17] Scott Pesme, Loucas Pillaud-Vivien and Nicolas Flammarion. <a rel="noreferrer noopener" href="https://proceedings.neurips.cc/paper/2021/hash/f4661398cb1a3abd3ffe58600bf11322-Abstract.html" data-type="URL" data-id="https://proceedings.neurips.cc/paper/2021/hash/f4661398cb1a3abd3ffe58600bf11322-Abstract.html" target="_blank">Implicit bias of SGD for diagonal linear networks: a provable benefit of stochasticity.</a> In Advances in Neural Information Processing Systems 34, 29218-29230, 2021.<br>[18] Loucas Pillaud Vivien, Julien Reygner and Nicolas Flammarion. <a rel="noreferrer noopener" href="https://proceedings.mlr.press/v178/vivien22a.html" data-type="URL" data-id="https://proceedings.mlr.press/v178/vivien22a.html" target="_blank">Label noise (stochastic) gradient descent implicitly solves the Lasso for quadratic parametrisation.</a> Proceedings of Thirty Fifth Conference on Learning Theory, PMLR 178:2127-2159, 2022.<br>[19] Alnur Ali, Edgar Dobriban and Ryan Tibshirani. <a rel="noreferrer noopener" href="https://proceedings.mlr.press/v119/ali20a.html" data-type="URL" data-id="https://proceedings.mlr.press/v119/ali20a.html" target="_blank">The Implicit Regularization of Stochastic Gradient Flow for Least Squares</a>. Proceedings of the 37th International Conference on Machine Learning, PMLR 119:233-244, 2020.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</div>
</div>
</div>



<p class="justify-text"></p>



<h2>Details on the evolution equation of \(\eta_t = \|\theta_t &#8211; \theta^{\text{LS}}\|^2\).</h2>



<p></p>



<p class="has-text-align-justify">Recall that the evolution of the iterates is given by the SDE: $$ d \theta_t =\, &#8211; \frac{1}{n}X^\top (X\theta_t\, &#8211; y) d t + \frac{\sqrt{\gamma}}{n} \| X\theta_t -y \| X^\top d B_t. $$ Then by <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/It%C3%B4_calculus" data-type="URL" data-id="https://en.wikipedia.org/wiki/It%C3%B4_calculus" target="_blank">Itô calculus</a>, we have $$\begin{aligned} d \eta_t &amp;= 2 \langle d \theta_t, \theta_t &#8211; \theta^{\text{LS}} \rangle + \frac{\gamma}{n^2} \mathrm{tr} (X^\top X) \| X (\theta_t &#8211; \theta^{\text{LS}}) \|^2 &nbsp; dt \\ &amp;= -\frac{2}{n} \langle X^\top (X\theta_t\, &#8211; y), \theta_t &#8211; \theta^{\text{LS}} \rangle dt + 2 \sqrt{\frac{2\gamma}{n}} \sqrt{\mathcal{R}_n(\theta_t)} \langle X^\top d B_t, \theta_t &#8211; \theta^{\text{LS}} \rangle \\ &amp; \hspace{6.5cm}+ 2\gamma \mathrm{tr} (n^{-1}X^\top X) \mathcal{R}_n(\theta_t) &nbsp; dt. \end{aligned}$$ Since,  \(\theta^{\text{LS}}\) is an interpolator, i.e \(X \theta^{\text{LS}} = y\), the first term corresponds to $$ -\frac{2}{n}\langle X^\top (X\theta_t\, &#8211; y), \theta_t &#8211; \theta^{\text{LS}} \rangle = -\frac{2}{n}\langle X(\theta_t &#8211; \theta^{\text{LS}}), X(\theta_t &#8211; \theta^{\text{LS}}) \rangle = -4 \mathcal{R}_n(\theta_t).$$ For the second term, note that \(\langle X^\top d B_t, \theta_t &#8211; \theta^{\text{LS}} \rangle = \langle d B_t, X(\theta_t &#8211; \theta^{\text{LS}}) \rangle\), and by <a rel="noreferrer noopener" href="https://almostsuremath.com/2010/04/13/levys-characterization-of-brownian-motion/" data-type="URL" data-id="https://almostsuremath.com/2010/04/13/levys-characterization-of-brownian-motion/" target="_blank">Lévy’s Characterization of Brownian Motion</a>, the local martingale $$ W_t = \int_0^t \frac{\langle d B_s, X(\theta_s &#8211; \theta^{\text{LS}})\rangle}{\|X(\theta_s &#8211; \theta^{\text{LS}})\|} $$ is in fact a one dimensional Brownian motion. Hence, $$ \langle X^\top d B_t, \theta_t &#8211; \theta^{\text{LS}} \rangle = \|X(\theta_s &#8211; \theta^{\text{LS}})\| dW_t = \sqrt{2 n \mathcal{R}_n(\theta_t)}dW_t,$$ and finally, $$ d \eta_t = -4 \mathcal{R}_n(\theta_t) dt + 4 \sqrt{\gamma} \mathcal{R}_n(\theta_t) d W_t + 2 \gamma \mathrm{tr} (n^{-1}X^\top X) \mathcal{R}_n(\theta_t) &nbsp; dt,$$ which gives the claimed result of the main text.</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-07-25T13:32:15Z">23 days ago</time>
        </div>
      </div>
    </article>
  
  </div>

  <script src='js/jquery-2.0.3.min.js'></script>
  <script src="js/jquery.timeago.js" type="text/javascript"></script>
  <script>
    jQuery(document).ready(function() {
      jQuery("time.timeago").timeago();
    });
  </script>
  <script src='js/blank.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
