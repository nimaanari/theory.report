<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-06-13T12:48:01Z">Tuesday, June 13 2023, 12:48</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://export.arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://export.arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://export.arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, June 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/06/12/phd-student-at-ruhr-university-of-bochum-apply-by-july-10-2023/'>PhD Student at Ruhr University of Bochum (apply by July 10, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We are inviting applications for a fully-funded PhD position at the Cluster of Excellence CASA. As the successful candidate, you will join the project &#8220;Robust Certification of Quantum Devices&#8221; and conduct fundamental research in the areas of: &#8211; Nonlocal games and self-testing. &#8211; Quantum information and cryptography. &#8211; Group and representation theory. Language: English. Salary: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We are inviting applications for a fully-funded PhD position at the Cluster of Excellence CASA. As the successful candidate, you will join the project &#8220;Robust Certification of Quantum Devices&#8221; and conduct fundamental research in the areas of:</p>
<p>&#8211; Nonlocal games and self-testing.<br />
&#8211; Quantum information and cryptography.<br />
&#8211; Group and representation theory.</p>
<p>Language: English. Salary: E-13, 100%.</p>
<p>Website: <a href="https://qi.ruhr-uni-bochum.de/hiring_casa">https://qi.ruhr-uni-bochum.de/hiring_casa</a><br />
Email: qi@rub.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T10:46:22Z">Monday, June 12 2023, 10:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/06/12/postdocs-at-ruhr-university-bochum-apply-by-july-10-2023/'>Postdocs at Ruhr University Bochum (apply by July 10, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We are inviting applications for postdoc positions as part of the ERC project Symmetry and Optimization at the Frontiers of Computation (SYMOPTIC). Website: qi.rub.de/hiring_erc_pd Email: qi@rub.de
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We are inviting applications for postdoc positions as part of the ERC project Symmetry and Optimization at the Frontiers of Computation (SYMOPTIC).</p>
<p>Website: <a href="https://qi.rub.de/hiring_erc_pd">https://qi.rub.de/hiring_erc_pd</a><br />
Email: qi@rub.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T08:56:40Z">Monday, June 12 2023, 08:56</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/06/12/phd-at-ruhr-university-bochum-apply-by-october-7-2023/'>PhD at Ruhr University Bochum (apply by October 7, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We are inviting applications for fully-funded PhD positions as part of the ERC project Symmetry and Optimization at the Frontiers of Computation (SYMOPTIC). Website: qi.rub.de/hiring_erc Email: qi@rub.de
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We are inviting applications for fully-funded PhD positions as part of the ERC project Symmetry and Optimization at the Frontiers of Computation (SYMOPTIC).</p>
<p>Website: <a href="https://qi.rub.de/hiring_erc">https://qi.rub.de/hiring_erc</a><br />
Email: qi@rub.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T08:52:55Z">Monday, June 12 2023, 08:52</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05818'>Complexity of Reachability Problems in Neural Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adrian Wurm</p><p>In this paper we investigate formal verification problems for Neural Network
computations. Various reachability problems will be in the focus, such as:
Given symbolic specifications of allowed inputs and outputs in form of Linear
Programming instances, one question is whether valid inputs exist such that the
given network computes a valid output? Does this property hold for all valid
inputs? The former question's complexity has been investigated recently by
S\"alzer and Lange for nets using the Rectified Linear Unit and the identity
function as their activation functions. We complement their achievements by
showing that the problem is NP-complete for piecewise linear functions with
rational coefficients that are not linear, NP-hard for almost all suitable
activation functions including non-linear ones that are continuous on an
interval, complete for the Existential Theory of the Reals $\exists \mathbb R$
for every non-linear polynomial and $\exists \mathbb R$-hard for the
exponential function and various sigmoidal functions. For the completeness
results, linking the verification tasks with the theory of Constraint
Satisfaction Problems turns out helpful.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wurm_A/0/1/0/all/0/1">Adrian Wurm</a></p><p>In this paper we investigate formal verification problems for Neural Network
computations. Various reachability problems will be in the focus, such as:
Given symbolic specifications of allowed inputs and outputs in form of Linear
Programming instances, one question is whether valid inputs exist such that the
given network computes a valid output? Does this property hold for all valid
inputs? The former question's complexity has been investigated recently by
S\"alzer and Lange for nets using the Rectified Linear Unit and the identity
function as their activation functions. We complement their achievements by
showing that the problem is NP-complete for piecewise linear functions with
rational coefficients that are not linear, NP-hard for almost all suitable
activation functions including non-linear ones that are continuous on an
interval, complete for the Existential Theory of the Reals $\exists \mathbb R$
for every non-linear polynomial and $\exists \mathbb R$-hard for the
exponential function and various sigmoidal functions. For the completeness
results, linking the verification tasks with the theory of Constraint
Satisfaction Problems turns out helpful.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05962'>A dichotomy theorem for $\Gamma$-switchable $H$-colouring on $m$-edge coloured graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Richard Brewster, Arnott Kinder, Gary MacGillivray</p><p>Let $G$ be a graph in which each edge is assigned one of the colours $1, 2,
\ldots, m$, and let $\Gamma$ be a subgroup of $S_m$. The operation of switching
at a vertex $x$ of $G$ with respect to an element $\pi$ of $\Gamma$ permutes
the colours of the edges incident with $x$ according to $\pi$. We investigate
the complexity of whether there exists a sequence of switches that transforms a
given $m$-edge coloured graph $G$ so that it has a colour-preserving
homomorphism to a fixed $m$-edge coloured graph $H$ and give a dichotomy
theorem in the case that $\Gamma$ acts transitively.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Brewster_R/0/1/0/all/0/1">Richard Brewster</a>, <a href="http://arxiv.org/find/math/1/au:+Kinder_A/0/1/0/all/0/1">Arnott Kinder</a>, <a href="http://arxiv.org/find/math/1/au:+MacGillivray_G/0/1/0/all/0/1">Gary MacGillivray</a></p><p>Let $G$ be a graph in which each edge is assigned one of the colours $1, 2,
\ldots, m$, and let $\Gamma$ be a subgroup of $S_m$. The operation of switching
at a vertex $x$ of $G$ with respect to an element $\pi$ of $\Gamma$ permutes
the colours of the edges incident with $x$ according to $\pi$. We investigate
the complexity of whether there exists a sequence of switches that transforms a
given $m$-edge coloured graph $G$ so that it has a colour-preserving
homomorphism to a fixed $m$-edge coloured graph $H$ and give a dichotomy
theorem in the case that $\Gamma$ acts transitively.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05977'>Towards Universally Optimal Shortest Paths Algorithms in the Hybrid Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Philipp Schneider</p><p>A drawback of the classic approach for complexity analysis of distributed
graph problems is that it mostly informs about the complexity of notorious
classes of ``worst case'' graphs. Algorithms that are used to prove a tight
(existential) bound are essentially optimized to perform well on such worst
case graphs. However, such graphs are often either unlikely or actively avoided
in practice, where benign graph instances usually admit much faster solutions.
</p>
<p>To circumnavigate these drawbacks, the concept of universal complexity
analysis in the distributed setting was suggested by [Kutten and Peleg,
PODC'95] and actively pursued by [Haeupler et al., STOC'21]. Here, the aim is
to gauge the complexity of a distributed graph problem depending on the given
graph instance. The challenge is to identify and understand the graph property
that allows to accurately quantify the complexity of a distributed problem on a
given graph.
</p>
<p>In the present work, we consider distributed shortest paths problems in the
HYBRID model of distributed computing, where nodes have simultaneous access to
two different modes of communication: one is restricted by locality and the
other is restricted by congestion. We identify the graph parameter of
neighborhood quality and show that it accurately describes a universal bound
for the complexity of certain class of shortest paths problems in the HYBRID
model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Schneider_P/0/1/0/all/0/1">Philipp Schneider</a></p><p>A drawback of the classic approach for complexity analysis of distributed
graph problems is that it mostly informs about the complexity of notorious
classes of ``worst case'' graphs. Algorithms that are used to prove a tight
(existential) bound are essentially optimized to perform well on such worst
case graphs. However, such graphs are often either unlikely or actively avoided
in practice, where benign graph instances usually admit much faster solutions.
</p>
<p>To circumnavigate these drawbacks, the concept of universal complexity
analysis in the distributed setting was suggested by [Kutten and Peleg,
PODC'95] and actively pursued by [Haeupler et al., STOC'21]. Here, the aim is
to gauge the complexity of a distributed graph problem depending on the given
graph instance. The challenge is to identify and understand the graph property
that allows to accurately quantify the complexity of a distributed problem on a
given graph.
</p>
<p>In the present work, we consider distributed shortest paths problems in the
HYBRID model of distributed computing, where nodes have simultaneous access to
two different modes of communication: one is restricted by locality and the
other is restricted by congestion. We identify the graph parameter of
neighborhood quality and show that it accurately describes a universal bound
for the complexity of certain class of shortest paths problems in the HYBRID
model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05475'>Robust Topological Orderings for Directed Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: James Smith</p><p>We modify the Pearce-Kelly algorithm that maintains a topological ordering
for a directed acyclic graph in order to allow cycles to be tolerated. Cycles
make topological orderings moot, of course, however tolerating them is useful
in practice. A user may mistakenly introduce a cyclic dependency in their
project,, for example, and then subsequently fix their mistake. In these cases
it is better to maintain the relevant data structures so that if and when the
directed graph becomes acyclic again, a topological ordering can be instantly
recovered. It turns out that adding this functionality costs us little, only
small modifications and some attention to detail are needed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1">James Smith</a></p><p>We modify the Pearce-Kelly algorithm that maintains a topological ordering
for a directed acyclic graph in order to allow cycles to be tolerated. Cycles
make topological orderings moot, of course, however tolerating them is useful
in practice. A user may mistakenly introduce a cyclic dependency in their
project,, for example, and then subsequently fix their mistake. In these cases
it is better to maintain the relevant data structures so that if and when the
directed graph becomes acyclic again, a topological ordering can be instantly
recovered. It turns out that adding this functionality costs us little, only
small modifications and some attention to detail are needed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05588'>An Improved Algorithm for Finding Maximum Outerplanar Subgraphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gruia Calinescu, Hemanshu Kaul, Bahareh Kudarzi</p><p>We study the NP-complete Maximum Outerplanar Subgraph problem. The previous
best known approximation ratio for this problem is 2/3. We propose a new
approximation algorithm which improves the ratio to 7/10.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Calinescu_G/0/1/0/all/0/1">Gruia Calinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaul_H/0/1/0/all/0/1">Hemanshu Kaul</a>, <a href="http://arxiv.org/find/cs/1/au:+Kudarzi_B/0/1/0/all/0/1">Bahareh Kudarzi</a></p><p>We study the NP-complete Maximum Outerplanar Subgraph problem. The previous
best known approximation ratio for this problem is 2/3. We propose a new
approximation algorithm which improves the ratio to 7/10.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05684'>Space-time Trade-offs for the LCP Array of Wheeler DFAs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicola Cotumaccio, Travis Gagie, Dominik K&#xf6;ppl, Nicola Prezza</p><p>Recently, Conte et al. generalized the longest-common prefix (LCP) array from
strings to Wheeler DFAs, and they showed that it can be used to efficiently
determine matching statistics on a Wheeler DFA [DCC 2023]. However, storing the
LCP array requires $ O(n \log n) $ bits, $ n $ being the number of states,
while the compact representation of Wheeler DFAs often requires much less
space. In particular, the BOSS representation of a de Bruijn graph only
requires a linear number of bits, if the size of alphabet is constant.
</p>
<p>In this paper, we propose a sampling technique that allows to access an entry
of the LCP array in logarithmic time by only storing a linear number of bits.
We use our technique to provide a space-time trade-off to compute matching
statistics on a Wheeler DFA. In addition, we show that by augmenting the BOSS
representation of a $ k $-th order de Bruijn graph with a linear number of bits
we can navigate the underlying variable-order de Bruijn graph in time
logarithmic in $ k $, thus improving a previous bound by Boucher et al. which
was linear in $ k $ [DCC 2015].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cotumaccio_N/0/1/0/all/0/1">Nicola Cotumaccio</a>, <a href="http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1">Travis Gagie</a>, <a href="http://arxiv.org/find/cs/1/au:+Koppl_D/0/1/0/all/0/1">Dominik K&#xf6;ppl</a>, <a href="http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1">Nicola Prezza</a></p><p>Recently, Conte et al. generalized the longest-common prefix (LCP) array from
strings to Wheeler DFAs, and they showed that it can be used to efficiently
determine matching statistics on a Wheeler DFA [DCC 2023]. However, storing the
LCP array requires $ O(n \log n) $ bits, $ n $ being the number of states,
while the compact representation of Wheeler DFAs often requires much less
space. In particular, the BOSS representation of a de Bruijn graph only
requires a linear number of bits, if the size of alphabet is constant.
</p>
<p>In this paper, we propose a sampling technique that allows to access an entry
of the LCP array in logarithmic time by only storing a linear number of bits.
We use our technique to provide a space-time trade-off to compute matching
statistics on a Wheeler DFA. In addition, we show that by augmenting the BOSS
representation of a $ k $-th order de Bruijn graph with a linear number of bits
we can navigate the underlying variable-order de Bruijn graph in time
logarithmic in $ k $, thus improving a previous bound by Boucher et al. which
was linear in $ k $ [DCC 2015].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05734'>DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hua Wang, Sheng Gao, Huanyu Zhang, Weijie J. Su, Milan Shen</p><p>Hyperparameter optimization, also known as hyperparameter tuning, is a widely
recognized technique for improving model performance. Regrettably, when
training private ML models, many practitioners often overlook the privacy risks
associated with hyperparameter optimization, which could potentially expose
sensitive information about the underlying dataset. Currently, the sole
existing approach to allow privacy-preserving hyperparameter optimization is to
uniformly and randomly select hyperparameters for a number of runs,
subsequently reporting the best-performing hyperparameter. In contrast, in
non-private settings, practitioners commonly utilize "adaptive" hyperparameter
optimization methods such as Gaussian process-based optimization, which select
the next candidate based on information gathered from previous outputs. This
substantial contrast between private and non-private hyperparameter
optimization underscores a critical concern. In our paper, we introduce
DP-HyPO, a pioneering framework for "adaptive" private hyperparameter
optimization, aiming to bridge the gap between private and non-private
hyperparameter optimization. To accomplish this, we provide a comprehensive
differential privacy analysis of our framework. Furthermore, we empirically
demonstrate the effectiveness of DP-HyPO on a diverse set of real-world and
synthetic datasets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hua Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Sheng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huanyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1">Weijie J. Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1">Milan Shen</a></p><p>Hyperparameter optimization, also known as hyperparameter tuning, is a widely
recognized technique for improving model performance. Regrettably, when
training private ML models, many practitioners often overlook the privacy risks
associated with hyperparameter optimization, which could potentially expose
sensitive information about the underlying dataset. Currently, the sole
existing approach to allow privacy-preserving hyperparameter optimization is to
uniformly and randomly select hyperparameters for a number of runs,
subsequently reporting the best-performing hyperparameter. In contrast, in
non-private settings, practitioners commonly utilize "adaptive" hyperparameter
optimization methods such as Gaussian process-based optimization, which select
the next candidate based on information gathered from previous outputs. This
substantial contrast between private and non-private hyperparameter
optimization underscores a critical concern. In our paper, we introduce
DP-HyPO, a pioneering framework for "adaptive" private hyperparameter
optimization, aiming to bridge the gap between private and non-private
hyperparameter optimization. To accomplish this, we provide a comprehensive
differential privacy analysis of our framework. Furthermore, we empirically
demonstrate the effectiveness of DP-HyPO on a diverse set of real-world and
synthetic datasets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05744'>Improved and Deterministic Online Service with Deadlines or Delay</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Noam Touitou</p><p>We consider the problem of online service with delay on a general metric
space, first presented by Azar, Ganesh, Ge and Panigrahi (STOC 2017). The best
known randomized algorithm for this problem, by Azar and Touitou (FOCS 2019),
is $O(\log^2 n)$-competitive, where $n$ is the number of points in the metric
space. This is also the best known result for the special case of online
service with deadlines, which is of independent interest.
</p>
<p>In this paper, we present $O(\log n)$-competitive deterministic algorithms
for online service with deadlines or delay, improving upon the results from
FOCS 2019. Furthermore, our algorithms are the first deterministic algorithms
for online service with deadlines or delay which apply to general metric spaces
and have sub-polynomial competitiveness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Touitou_N/0/1/0/all/0/1">Noam Touitou</a></p><p>We consider the problem of online service with delay on a general metric
space, first presented by Azar, Ganesh, Ge and Panigrahi (STOC 2017). The best
known randomized algorithm for this problem, by Azar and Touitou (FOCS 2019),
is $O(\log^2 n)$-competitive, where $n$ is the number of points in the metric
space. This is also the best known result for the special case of online
service with deadlines, which is of independent interest.
</p>
<p>In this paper, we present $O(\log n)$-competitive deterministic algorithms
for online service with deadlines or delay, improving upon the results from
FOCS 2019. Furthermore, our algorithms are the first deterministic algorithms
for online service with deadlines or delay which apply to general metric spaces
and have sub-polynomial competitiveness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05781'>Adaptivity Complexity for Causal Graph Discovery</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davin Choo, Kirankumar Shiragur</p><p>Causal discovery from interventional data is an important problem, where the
task is to design an interventional strategy that learns the hidden ground
truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of
performed interventions. Most prior interventional strategies broadly fall into
two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a
single fixed set of interventions to be performed while adaptive strategies can
decide on which nodes to intervene on sequentially based on past interventions.
While adaptive algorithms may use exponentially fewer interventions than their
non-adaptive counterparts, there are practical concerns that constrain the
amount of adaptivity allowed. Motivated by this trade-off, we study the problem
of $r$-adaptivity, where the algorithm designer recovers the causal graph under
a total of $r$ sequential rounds whilst trying to minimize the total number of
interventions. For this problem, we provide a $r$-adaptive algorithm that
achieves $O(\min\{r,\log n\} \cdot n^{1/\min\{r,\log n\}})$ approximation with
respect to the verification number, a well-known lower bound for adaptive
algorithms. Furthermore, for every $r$, we show that our approximation is
tight. Our definition of $r$-adaptivity interpolates nicely between the
non-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our
approximation simplifies to $O(n)$ and $O(\log n)$ respectively, matching the
best-known approximation guarantees for both extremes. Our results also extend
naturally to the bounded size interventions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1">Davin Choo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiragur_K/0/1/0/all/0/1">Kirankumar Shiragur</a></p><p>Causal discovery from interventional data is an important problem, where the
task is to design an interventional strategy that learns the hidden ground
truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of
performed interventions. Most prior interventional strategies broadly fall into
two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a
single fixed set of interventions to be performed while adaptive strategies can
decide on which nodes to intervene on sequentially based on past interventions.
While adaptive algorithms may use exponentially fewer interventions than their
non-adaptive counterparts, there are practical concerns that constrain the
amount of adaptivity allowed. Motivated by this trade-off, we study the problem
of $r$-adaptivity, where the algorithm designer recovers the causal graph under
a total of $r$ sequential rounds whilst trying to minimize the total number of
interventions. For this problem, we provide a $r$-adaptive algorithm that
achieves $O(\min\{r,\log n\} \cdot n^{1/\min\{r,\log n\}})$ approximation with
respect to the verification number, a well-known lower bound for adaptive
algorithms. Furthermore, for every $r$, we show that our approximation is
tight. Our definition of $r$-adaptivity interpolates nicely between the
non-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our
approximation simplifies to $O(n)$ and $O(\log n)$ respectively, matching the
best-known approximation guarantees for both extremes. Our results also extend
naturally to the bounded size interventions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05838'>Expectation-Complete Graph Representations with Homomorphisms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pascal Welke, Maximilian Thiessen, Fabian Jogl, Thomas G&#xe4;rtner</p><p>We investigate novel random graph embeddings that can be computed in expected
polynomial time and that are able to distinguish all non-isomorphic graphs in
expectation. Previous graph embeddings have limited expressiveness and either
cannot distinguish all graphs or cannot be computed efficiently for every
graph. To be able to approximate arbitrary functions on graphs, we are
interested in efficient alternatives that become arbitrarily expressive with
increasing resources. Our approach is based on Lov\'asz' characterisation of
graph isomorphism through an infinite dimensional vector of homomorphism
counts. Our empirical evaluation shows competitive results on several benchmark
graph learning tasks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Welke_P/0/1/0/all/0/1">Pascal Welke</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiessen_M/0/1/0/all/0/1">Maximilian Thiessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jogl_F/0/1/0/all/0/1">Fabian Jogl</a>, <a href="http://arxiv.org/find/cs/1/au:+Gartner_T/0/1/0/all/0/1">Thomas G&#xe4;rtner</a></p><p>We investigate novel random graph embeddings that can be computed in expected
polynomial time and that are able to distinguish all non-isomorphic graphs in
expectation. Previous graph embeddings have limited expressiveness and either
cannot distinguish all graphs or cannot be computed efficiently for every
graph. To be able to approximate arbitrary functions on graphs, we are
interested in efficient alternatives that become arbitrarily expressive with
increasing resources. Our approach is based on Lov\'asz' characterisation of
graph isomorphism through an infinite dimensional vector of homomorphism
counts. Our empirical evaluation shows competitive results on several benchmark
graph learning tasks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05865'>Faster Discrete Convex Function Minimization with Predictions: The M-Convex Case</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Taihei Oki, Shinsaku Sakaue</p><p>Recent years have seen a growing interest in accelerating optimization
algorithms with machine-learned predictions. Sakaue and Oki (NeurIPS 2022) have
developed a general framework that warm-starts the L-convex function
minimization method with predictions, revealing the idea's usefulness for
various discrete optimization problems. In this paper, we present a framework
for using predictions to accelerate M-convex function minimization, thus
complementing previous research and extending the range of discrete
optimization algorithms that can benefit from predictions. Our framework is
particularly effective for an important subclass called laminar convex
minimization, which appears in many operations research applications. Our
methods can improve time complexity bounds upon the best worst-case results by
using predictions and even have potential to go beyond a lower-bound result.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Oki_T/0/1/0/all/0/1">Taihei Oki</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakaue_S/0/1/0/all/0/1">Shinsaku Sakaue</a></p><p>Recent years have seen a growing interest in accelerating optimization
algorithms with machine-learned predictions. Sakaue and Oki (NeurIPS 2022) have
developed a general framework that warm-starts the L-convex function
minimization method with predictions, revealing the idea's usefulness for
various discrete optimization problems. In this paper, we present a framework
for using predictions to accelerate M-convex function minimization, thus
complementing previous research and extending the range of discrete
optimization algorithms that can benefit from predictions. Our framework is
particularly effective for an important subclass called laminar convex
minimization, which appears in many operations research applications. Our
methods can improve time complexity bounds upon the best worst-case results by
using predictions and even have potential to go beyond a lower-bound result.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05916'>Differentially Private All-Pairs Shortest Distances for Low Tree-Width Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Javad B. Ebrahimi, Alireza Tofighi Mohammadi, Fatemeh Kermani</p><p>In this paper, we present a polynomial time algorithm for the problem of
differentially private all pair shortest distances over the class of low
tree-width graphs. Our result generalizes the result of Sealfon 2016 for the
case of trees to a much larger family of graphs. Furthermore, if we restrict to
the class of low tree-width graphs, the additive error of our algorithm is
significantly smaller than that of the best known algorithm for this problem,
proposed by Chen et. al. 2023.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ebrahimi_J/0/1/0/all/0/1">Javad B. Ebrahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadi_A/0/1/0/all/0/1">Alireza Tofighi Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kermani_F/0/1/0/all/0/1">Fatemeh Kermani</a></p><p>In this paper, we present a polynomial time algorithm for the problem of
differentially private all pair shortest distances over the class of low
tree-width graphs. Our result generalizes the result of Sealfon 2016 for the
case of trees to a much larger family of graphs. Furthermore, if we restrict to
the class of low tree-width graphs, the additive error of our algorithm is
significantly smaller than that of the best known algorithm for this problem,
proposed by Chen et. al. 2023.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05979'>Optimal distance query reconstruction for graphs without long induced cycles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paul Bastide, Carla Groenland</p><p>Let $G=(V,E)$ be an $n$-vertex connected graph of maximum degree $\Delta$.
Given access to $V$ and an oracle that given two vertices $u,v\in V$, returns
the shortest path distance between $u$ and $v$, how many queries are needed to
reconstruct $E$? We give a simple deterministic algorithm to reconstruct trees
using $\Delta n\log_\Delta n+(\Delta+2)n$ distance queries and show that even
randomised algorithms need to use at least $\frac1{100} \Delta n\log_\Delta n$
queries in expectation. The best previous lower bound was an
information-theoretic lower bound of $\Omega(n\log n/\log \log n)$. Our lower
bound also extends to related query models including distance queries for
phylogenetic trees, membership queries for learning partitions and path queries
in directed trees.
</p>
<p>We extend our deterministic algorithm to reconstruct graphs without induced
cycles of length at least $k$ using $O_{\Delta,k}(n\log n)$ queries, which
includes various graph classes of interest such as chordal graphs, permutation
graphs and AT-free graphs. Since the previously best known randomised algorithm
for chordal graphs uses $O_{\Delta}(n\log^2 n)$ queries in expectation, we both
get rid off the randomness and get the optimal dependency in $n$ for chordal
graphs and various other graph classes.
</p>
<p>Finally, we build on an algorithm of Kannan, Mathieu, and Zhou [ICALP, 2015]
to give a randomised algorithm for reconstructing graphs of treelength $k$
using $O_{\Delta,k}(n\log^2n)$ queries in expectation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bastide_P/0/1/0/all/0/1">Paul Bastide</a>, <a href="http://arxiv.org/find/cs/1/au:+Groenland_C/0/1/0/all/0/1">Carla Groenland</a></p><p>Let $G=(V,E)$ be an $n$-vertex connected graph of maximum degree $\Delta$.
Given access to $V$ and an oracle that given two vertices $u,v\in V$, returns
the shortest path distance between $u$ and $v$, how many queries are needed to
reconstruct $E$? We give a simple deterministic algorithm to reconstruct trees
using $\Delta n\log_\Delta n+(\Delta+2)n$ distance queries and show that even
randomised algorithms need to use at least $\frac1{100} \Delta n\log_\Delta n$
queries in expectation. The best previous lower bound was an
information-theoretic lower bound of $\Omega(n\log n/\log \log n)$. Our lower
bound also extends to related query models including distance queries for
phylogenetic trees, membership queries for learning partitions and path queries
in directed trees.
</p>
<p>We extend our deterministic algorithm to reconstruct graphs without induced
cycles of length at least $k$ using $O_{\Delta,k}(n\log n)$ queries, which
includes various graph classes of interest such as chordal graphs, permutation
graphs and AT-free graphs. Since the previously best known randomised algorithm
for chordal graphs uses $O_{\Delta}(n\log^2 n)$ queries in expectation, we both
get rid off the randomness and get the optimal dependency in $n$ for chordal
graphs and various other graph classes.
</p>
<p>Finally, we build on an algorithm of Kannan, Mathieu, and Zhou [ICALP, 2015]
to give a randomised algorithm for reconstructing graphs of treelength $k$
using $O_{\Delta,k}(n\log^2n)$ queries in expectation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05986'>Fair Allocation with Binary Valuations for Mixed Divisible and Indivisible Goods</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yasushi Kawase, Koichi Nishimura, Hanna Sumita</p><p>The fair allocation of mixed goods, consisting of both divisible and
indivisible goods, among agents with heterogeneous preferences, has been a
prominent topic of study in economics and computer science. In this paper, we
investigate the nature of fair allocations when agents have binary valuations.
We define an allocation as fair if its utility vector minimizes a symmetric
strictly convex function, which includes conventional fairness criteria such as
maximum egalitarian social welfare and maximum Nash social welfare. While a
good structure is known for the continuous case (where only divisible goods
exist) or the discrete case (where only indivisible goods exist), deriving such
a structure in the hybrid case remains challenging. Our contributions are
twofold. First, we demonstrate that the hybrid case does not inherit some of
the nice properties of continuous or discrete cases, while it does inherit the
proximity theorem. Second, we analyze the computational complexity of finding a
fair allocation of mixed goods based on the proximity theorem. In particular,
we provide a polynomial-time algorithm for the case when all divisible goods
are identical and homogeneous, and demonstrate that the problem is NP-hard in
general. Our results also contribute to a deeper understanding of the hybrid
convex analysis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kawase_Y/0/1/0/all/0/1">Yasushi Kawase</a>, <a href="http://arxiv.org/find/cs/1/au:+Nishimura_K/0/1/0/all/0/1">Koichi Nishimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Sumita_H/0/1/0/all/0/1">Hanna Sumita</a></p><p>The fair allocation of mixed goods, consisting of both divisible and
indivisible goods, among agents with heterogeneous preferences, has been a
prominent topic of study in economics and computer science. In this paper, we
investigate the nature of fair allocations when agents have binary valuations.
We define an allocation as fair if its utility vector minimizes a symmetric
strictly convex function, which includes conventional fairness criteria such as
maximum egalitarian social welfare and maximum Nash social welfare. While a
good structure is known for the continuous case (where only divisible goods
exist) or the discrete case (where only indivisible goods exist), deriving such
a structure in the hybrid case remains challenging. Our contributions are
twofold. First, we demonstrate that the hybrid case does not inherit some of
the nice properties of continuous or discrete cases, while it does inherit the
proximity theorem. Second, we analyze the computational complexity of finding a
fair allocation of mixed goods based on the proximity theorem. In particular,
we provide a polynomial-time algorithm for the case when all divisible goods
are identical and homogeneous, and demonstrate that the problem is NP-hard in
general. Our results also contribute to a deeper understanding of the hybrid
convex analysis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.06003'>Semi-online Scheduling with Lookahead</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Debasis Dwibedy, Rakesh Mohanty</p><p>The knowledge of future partial information in the form of a lookahead to
design efficient online algorithms is a theoretically-efficient and realistic
approach to solving computational problems. Design and analysis of semi-online
algorithms with extra-piece-of-information (EPI) as a new input parameter has
gained the attention of the theoretical computer science community in the last
couple of decades. Though competitive analysis is a pessimistic worst-case
performance measure to analyze online algorithms, it has immense theoretical
value in developing the foundation and advancing the state-of-the-art
contributions in online and semi-online scheduling. In this paper, we study and
explore the impact of lookahead as an EPI in the context of online scheduling
in identical machine frameworks. We introduce a $k$-lookahead model and design
improved competitive semi-online algorithms. For a $2$-identical machine
setting, we prove a lower bound of $\frac{4}{3}$ and design an optimal
algorithm with a matching upper bound of $\frac{4}{3}$ on the competitive
ratio. For a $3$-identical machine setting, we show a lower bound of
$\frac{15}{11}$ and design a $\frac{16}{11}$-competitive improved semi-online
algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dwibedy_D/0/1/0/all/0/1">Debasis Dwibedy</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohanty_R/0/1/0/all/0/1">Rakesh Mohanty</a></p><p>The knowledge of future partial information in the form of a lookahead to
design efficient online algorithms is a theoretically-efficient and realistic
approach to solving computational problems. Design and analysis of semi-online
algorithms with extra-piece-of-information (EPI) as a new input parameter has
gained the attention of the theoretical computer science community in the last
couple of decades. Though competitive analysis is a pessimistic worst-case
performance measure to analyze online algorithms, it has immense theoretical
value in developing the foundation and advancing the state-of-the-art
contributions in online and semi-online scheduling. In this paper, we study and
explore the impact of lookahead as an EPI in the context of online scheduling
in identical machine frameworks. We introduce a $k$-lookahead model and design
improved competitive semi-online algorithms. For a $2$-identical machine
setting, we prove a lower bound of $\frac{4}{3}$ and design an optimal
algorithm with a matching upper bound of $\frac{4}{3}$ on the competitive
ratio. For a $3$-identical machine setting, we show a lower bound of
$\frac{15}{11}$ and design a $\frac{16}{11}$-competitive improved semi-online
algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.06050'>Branching via Cutting Plane Selection: Improving Hybrid Branching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mark Turner, Timo Berthold, Mathieu Besan&#xe7;on, Thorsten Koch</p><p>Cutting planes and branching are two of the most important algorithms for
solving mixed-integer linear programs. For both algorithms, disjunctions play
an important role, being used both as branching candidates and as the
foundation for some cutting planes. We relate branching decisions and cutting
planes to each other through the underlying disjunctions that they are based
on, with a focus on Gomory mixed-integer cuts and their corresponding split
disjunctions. We show that selecting branching decisions based on quality
measures of Gomory mixed-integer cuts leads to relatively small
branch-and-bound trees, and that the result improves when using cuts that more
accurately represent the branching decisions. Finally, we show how the history
of previously computed Gomory mixed-integer cuts can be used to improve the
performance of the state-of-the-art hybrid branching rule of SCIP. Our results
show a 4\% decrease in solve time, and an 8\% decrease in number of nodes over
affected instances of MIPLIB 2017.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Turner_M/0/1/0/all/0/1">Mark Turner</a>, <a href="http://arxiv.org/find/math/1/au:+Berthold_T/0/1/0/all/0/1">Timo Berthold</a>, <a href="http://arxiv.org/find/math/1/au:+Besancon_M/0/1/0/all/0/1">Mathieu Besan&#xe7;on</a>, <a href="http://arxiv.org/find/math/1/au:+Koch_T/0/1/0/all/0/1">Thorsten Koch</a></p><p>Cutting planes and branching are two of the most important algorithms for
solving mixed-integer linear programs. For both algorithms, disjunctions play
an important role, being used both as branching candidates and as the
foundation for some cutting planes. We relate branching decisions and cutting
planes to each other through the underlying disjunctions that they are based
on, with a focus on Gomory mixed-integer cuts and their corresponding split
disjunctions. We show that selecting branching decisions based on quality
measures of Gomory mixed-integer cuts leads to relatively small
branch-and-bound trees, and that the result improves when using cuts that more
accurately represent the branching decisions. Finally, we show how the history
of previously computed Gomory mixed-integer cuts can be used to improve the
performance of the state-of-the-art hybrid branching rule of SCIP. Our results
show a 4\% decrease in solve time, and an 8\% decrease in number of nodes over
affected instances of MIPLIB 2017.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-12T00:30:00Z">Monday, June 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, June 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/088'>TR23-088 |  A High Dimensional Goldreich-Levin Theorem | 

	Silas Richelson, 

	Parker Newton, 

	Chase Wilson</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this work we prove a high dimensional analogue of the beloved Goldreich-Levin theorem (STOC 1989).  We consider the following algorithmic problem: given oracle access to a function $f:\mathbb{Z}_q^m\rightarrow\mathbb{Z}_q^n$ such that ${\rm Prob}_{{\bf x}\sim\mathbb{Z}_q^m}\bigl[f({\bf x})={\bf Ax}\bigr]\geq\varepsilon$ for some ${\bf A}\in\mathbb{Z}_q^{n\times m}$ and $\varepsilon&gt;0$, recover ${\bf A}$ (or a list of all such matrices).  We focus on the case $\varepsilon\leq1/q$ since when $\varepsilon\geq1/q+\delta$, the problem is solved by the original Goldreich-Levin theorem.  As stated, this problem cannot be efficiently solved, since when $\varepsilon\leq1/q$ the list of ${\bf A}$ with good agreement with $f$ might be exponentially large.  Our main theorem gives an algorithm which efficiently recovers a list of linear maps of size $\mathcal{O}\bigl(1/\varepsilon\bigr)$ which have good agreement with $f$, and such that every linear map which has good agreement with $f$, also has good agreement with some map in our list.  Our proof makes novel use of Fourier analysis.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In this work we prove a high dimensional analogue of the beloved Goldreich-Levin theorem (STOC 1989).  We consider the following algorithmic problem: given oracle access to a function $f:\mathbb{Z}_q^m\rightarrow\mathbb{Z}_q^n$ such that ${\rm Prob}_{{\bf x}\sim\mathbb{Z}_q^m}\bigl[f({\bf x})={\bf Ax}\bigr]\geq\varepsilon$ for some ${\bf A}\in\mathbb{Z}_q^{n\times m}$ and $\varepsilon&gt;0$, recover ${\bf A}$ (or a list of all such matrices).  We focus on the case $\varepsilon\leq1/q$ since when $\varepsilon\geq1/q+\delta$, the problem is solved by the original Goldreich-Levin theorem.  As stated, this problem cannot be efficiently solved, since when $\varepsilon\leq1/q$ the list of ${\bf A}$ with good agreement with $f$ might be exponentially large.  Our main theorem gives an algorithm which efficiently recovers a list of linear maps of size $\mathcal{O}\bigl(1/\varepsilon\bigr)$ which have good agreement with $f$, and such that every linear map which has good agreement with $f$, also has good agreement with some map in our list.  Our proof makes novel use of Fourier analysis.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-11T04:10:05Z">Sunday, June 11 2023, 04:10</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, June 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/06/posting-book-online-with-password-that.html'>Posting a book online with a password- that you broadcast.</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;Recently Lance, at the request of&nbsp; Vijay Vazirani, tweeted the following (I paraphrase)</p><p>---------------------------------------------------------------------------------------</p><p>Online and Matching-based Market Design book now available as free PDF&nbsp;</p><p>cambridge.org/files/9216/848&nbsp;&nbsp;<br></p><p>The password is OMBMD_CUP</p><p>---------------------------------------------------------------------------------------------</p><p>This tweet raises two questions.</p><p>1) When a book is put online, does it cut into sales? I've heard that people still like paper so the posting on line might be like an ad for the book. Also, for academic books, the authors WANT it to be out there and don't care so much about sales.&nbsp; If Gasarch &amp; Martin's Bounded Queries in Recursion Theory was available for illegal download I would be delighted. And surprised.&nbsp;</p><p>2) SO, they post it to make it more available and generate buzz. So why have a password? Was this a compromise:&nbsp;</p><p>a) We want people to BUY the book so we'll post it with a password and limit access.&nbsp;</p><p>b) We want people to SEE the book since as academics we don't care about sales, and it might generate buzz, so we don't want a password</p><p>c) COMPROMISE: Have a password but tell everyone what it is.&nbsp;</p><p>If you can think of a more plausible scenario, leave a comment.&nbsp;</p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;Recently Lance, at the request of&nbsp; Vijay Vazirani, tweeted the following (I paraphrase)</p><p>---------------------------------------------------------------------------------------</p><p>Online and Matching-based Market Design book now available as free PDF&nbsp;</p><p><a href="https://www.cambridge.org/files/9216/8487/6990/matching_book_pw.pdf">cambridge.org/files/9216/848</a>&nbsp;&nbsp;<br /></p><p>The password is OMBMD_CUP</p><p>---------------------------------------------------------------------------------------------</p><p>This tweet raises two questions.</p><p>1) When a book is put online, does it cut into sales? I've heard that people still like paper so the posting on line might be like an ad for the book. Also, for academic books, the authors WANT it to be out there and don't care so much about sales.&nbsp; If Gasarch &amp; Martin's <i>Bounded Queries in Recursion Theory </i>was available for illegal download I would be delighted. And surprised.&nbsp;</p><p>2) SO, they post it to make it more available and generate buzz. So why have a password? Was this a compromise:&nbsp;</p><p>a) We want people to BUY the book so we'll post it with a password and limit access.&nbsp;</p><p>b) We want people to SEE the book since as academics we don't care about sales, and it might generate buzz, so we don't want a password</p><p>c) COMPROMISE: Have a password but tell everyone what it is.&nbsp;</p><p>If you can think of a more plausible scenario, leave a comment.&nbsp;</p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-10T15:16:00Z">Saturday, June 10 2023, 15:16</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, June 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/087'>TR23-087 |  How to Recover a Secret with $O(n)$ Additions | 

	Benny Applebaum, 

	Oded Nir, 

	Benny Pinkas</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Threshold cryptography is typically based on the idea of secret-sharing a private-key $s\in F$ ``in the exponent&#39;&#39; of some cryptographic group $G$, or more generally, encoding $s$ in some linearly homomorphic domain. In each invocation of the threshold system (e.g., for signing or decrypting) an ``encoding&#39;&#39; of the secret is being recovered and so the complexity, measured as the number of group multiplications over $G$, is equal to the number of $F$-additions that are needed to reconstruct the secret. Motivated by this scenario, we initiate the study of $n$-party secret-sharing schemes whose reconstruction algorithm makes a minimal number of \emph{additions}. The complexity of existing schemes either scales linearly with $n\log |F|$ (e.g., Shamir, CACM&#39;79) or, at least, quadratically with $n$ independently of the size of the domain $F$ (e.g., Cramer-Xing, EUROCRYPT &#39;20). This leaves open the existence of a secret sharing whose recovery algorithm can be computed by performing only $O(n)$ additions.

We resolve the question in the affirmative and present such a near-threshold secret sharing scheme that provides privacy against unauthorized sets of density at most $\tau_p$, and correctness for  authorized sets of density at least $\tau_c$, for any given arbitrarily close constants $\tau_p&lt;\tau_c$. Reconstruction can be computed by making at most $O(n)$ additions and, in addition, (1) the share size is constant, (2) the sharing procedure also makes only $O(n)$ additions, and (3) the scheme is a blackbox secret-sharing scheme, i.e., the sharing and reconstruction algorithms work universally for all finite abelian groups $F$. Prior to our work, no such scheme was known even without features (1)--(3) and even for the ramp setting where $\tau_p$ and $\tau_c$ are far apart. As a by-product, we derive the first blackbox near-threshold secret-sharing scheme with linear-time sharing. We also present several concrete instantiations of our approach that seem practically efficient (e.g., for threshold discrete-log-based signatures).

Our constructions are combinatorial in nature. We combine graph-based erasure codes that support ``peeling-based&#39;&#39; decoding with a new randomness extraction method that is based on inner-product with a small-integer vector. We also introduce a general concatenation-like transform for secret-sharing schemes that allows us to arbitrarily shrink the privacy-correctness gap with a minor overhead. Our techniques enrich the secret-sharing toolbox and, in the context of blackbox secret sharing, provide a new alternative to existing number-theoretic approaches.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Threshold cryptography is typically based on the idea of secret-sharing a private-key $s\in F$ ``in the exponent&#39;&#39; of some cryptographic group $G$, or more generally, encoding $s$ in some linearly homomorphic domain. In each invocation of the threshold system (e.g., for signing or decrypting) an ``encoding&#39;&#39; of the secret is being recovered and so the complexity, measured as the number of group multiplications over $G$, is equal to the number of $F$-additions that are needed to reconstruct the secret. Motivated by this scenario, we initiate the study of $n$-party secret-sharing schemes whose reconstruction algorithm makes a minimal number of \emph{additions}. The complexity of existing schemes either scales linearly with $n\log |F|$ (e.g., Shamir, CACM&#39;79) or, at least, quadratically with $n$ independently of the size of the domain $F$ (e.g., Cramer-Xing, EUROCRYPT &#39;20). This leaves open the existence of a secret sharing whose recovery algorithm can be computed by performing only $O(n)$ additions.

We resolve the question in the affirmative and present such a near-threshold secret sharing scheme that provides privacy against unauthorized sets of density at most $\tau_p$, and correctness for  authorized sets of density at least $\tau_c$, for any given arbitrarily close constants $\tau_p&lt;\tau_c$. Reconstruction can be computed by making at most $O(n)$ additions and, in addition, (1) the share size is constant, (2) the sharing procedure also makes only $O(n)$ additions, and (3) the scheme is a blackbox secret-sharing scheme, i.e., the sharing and reconstruction algorithms work universally for all finite abelian groups $F$. Prior to our work, no such scheme was known even without features (1)--(3) and even for the ramp setting where $\tau_p$ and $\tau_c$ are far apart. As a by-product, we derive the first blackbox near-threshold secret-sharing scheme with linear-time sharing. We also present several concrete instantiations of our approach that seem practically efficient (e.g., for threshold discrete-log-based signatures).

Our constructions are combinatorial in nature. We combine graph-based erasure codes that support ``peeling-based&#39;&#39; decoding with a new randomness extraction method that is based on inner-product with a small-integer vector. We also introduce a general concatenation-like transform for secret-sharing schemes that allows us to arbitrarily shrink the privacy-correctness gap with a minor overhead. Our techniques enrich the secret-sharing toolbox and, in the context of blackbox secret sharing, provide a new alternative to existing number-theoretic approaches.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T13:12:55Z">Friday, June 09 2023, 13:12</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/'>The asymptotics of r(4,t)</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Originally posted on Points And Lines: <br>Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved&#8230;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <div class="wpcom-reblog-snapshot"><div class="reblogger-note"><div class='reblogger-note-content'><blockquote><p><a href="https://sammattheus.wordpress.com/"><img loading="lazy" class="alignnone size-full wp-image-24567" src="https://gilkalai.files.wordpress.com/2023/06/pal.png" alt="pal" width="955" height="323" srcset="https://gilkalai.files.wordpress.com/2023/06/pal.png 955w, https://gilkalai.files.wordpress.com/2023/06/pal.png?w=150&amp;h=51 150w, https://gilkalai.files.wordpress.com/2023/06/pal.png?w=300&amp;h=101 300w, https://gilkalai.files.wordpress.com/2023/06/pal.png?w=768&amp;h=260 768w" sizes="(max-width: 955px) 100vw, 955px" /></a></p>
<p><!-- wp:paragraph --></p>
<p>Sam Mattheus wrote on his blog &#8220;Points and Lines&#8221; a summary with a general overview of the proof for his breakthrough with Jacques Verstraete about <img src="https://s0.wp.com/latex.php?latex=r%284%2Ct%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r(4,t)" class="latex" />. </p>
<p><!-- /wp:paragraph --></p>
</blockquote></div></div><div class="reblog-post"><p class="reblog-from"><img alt='' src='https://1.gravatar.com/avatar/46f67c6ee65d82a59f10b8438d0bdfb7676121b31aff9968cd1dfff4b11acaf7?s=32&#038;d=identicon&#038;r=PG' class='avatar avatar-32' height='32' width='32' /><a href="https://sammattheus.wordpress.com/2023/06/07/the-asymptotics-of-r4t/">Points And Lines</a></p><div class="reblogged-content">
<p></p>

<p>Jacques Verstraete and I posted a <a href="https://arxiv.org/abs/2306.04007">preprint</a> on the arXiv today on the off-diagonal Ramsey number $latex r(4,t)$. In short, we show that $latex r(4,t) = Omega(t^3/log^4t)$, which is just a $latex log^2t$ factor shy from the upper bound $latex r(4,t) = O (t^3/log^2t)$ proved by Ajtai, KomlÃ³s and SzemerÃ©di in 1980. ErdÅs [1] conjectured that up to logarithmic factors, $latex t^3$ is the order of growth:</p>

<p></p>

<p></p>

<p class="has-text-align-center"><img class="wp-image-1130" style="width: 600px" src="https://gilkalai.files.wordpress.com/2023/06/erdos-prize-r4t.png"></p>

<p></p>

<p></p>

<p>We thus confirm this conjecture. The previous best lower bound was due to Bohman and Keevash who studied the random $latex K_4$-free process and obtained $latex r(4,t) = widetilde{Omega}(t^{5/2})$, where the tilde hides logarithmic factors. It is not clear whether our methods can be pushed further to obtain asymptotically sharp bounds. In any case, thatâs not what I want to speculate about, but rather sketch the proof of our result. Itâs in my very biased opinion a nice combination of ideas that existedâ¦</p>
</div><p class="reblog-source"><a href="https://sammattheus.wordpress.com/2023/06/07/the-asymptotics-of-r4t/">View original post</a> <span class="more-words">1,481 more words</span></p></div></div><p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T06:17:30Z">Friday, June 09 2023, 06:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04731'>Free Fermion Distributions Are Hard to Learn</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Nietner</p><p>Free fermions are some of the best studied quantum systems. However, little
is known about the complexity of learning free-fermion distributions. In this
work we establish the hardness of this task in the particle number
non-preserving case. In particular, we give an information theoretical hardness
result for the general task of learning from expectation values and, in the
more general case when the algorithm is given access to samples, we give a
computational hardness result based on the LPN assumption for learning the
probability density function.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Nietner_A/0/1/0/all/0/1">Alexander Nietner</a></p><p>Free fermions are some of the best studied quantum systems. However, little
is known about the complexity of learning free-fermion distributions. In this
work we establish the hardness of this task in the particle number
non-preserving case. In particular, we give an information theoretical hardness
result for the general task of learning from expectation values and, in the
more general case when the algorithm is given access to samples, we give a
computational hardness result based on the LPN assumption for learning the
probability density function.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04843'>Classical Verification of Quantum Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthias C. Caro, Marcel Hinsche, Marios Ioannou, Alexander Nietner, Ryan Sweke</p><p>Quantum data access and quantum processing can make certain classically
intractable learning tasks feasible. However, quantum capabilities will only be
available to a select few in the near future. Thus, reliable schemes that allow
classical clients to delegate learning to untrusted quantum servers are
required to facilitate widespread access to quantum learning advantages.
Building on a recently introduced framework of interactive proof systems for
classical machine learning, we develop a framework for classical verification
of quantum learning. We exhibit learning problems that a classical learner
cannot efficiently solve on their own, but that they can efficiently and
reliably solve when interacting with an untrusted quantum prover. Concretely,
we consider the problems of agnostic learning parities and Fourier-sparse
functions with respect to distributions with uniform input marginal. We propose
a new quantum data access model that we call "mixture-of-superpositions"
quantum examples, based on which we give efficient quantum learning algorithms
for these tasks. Moreover, we prove that agnostic quantum parity and
Fourier-sparse learning can be efficiently verified by a classical verifier
with only random example or statistical query access. Finally, we showcase two
general scenarios in learning and verification in which quantum
mixture-of-superpositions examples do not lead to sample complexity
improvements over classical data. Our results demonstrate that the potential
power of quantum data for learning tasks, while not unlimited, can be utilized
by classical agents through interaction with untrusted quantum entities.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1">Matthias C. Caro</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hinsche_M/0/1/0/all/0/1">Marcel Hinsche</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ioannou_M/0/1/0/all/0/1">Marios Ioannou</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nietner_A/0/1/0/all/0/1">Alexander Nietner</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sweke_R/0/1/0/all/0/1">Ryan Sweke</a></p><p>Quantum data access and quantum processing can make certain classically
intractable learning tasks feasible. However, quantum capabilities will only be
available to a select few in the near future. Thus, reliable schemes that allow
classical clients to delegate learning to untrusted quantum servers are
required to facilitate widespread access to quantum learning advantages.
Building on a recently introduced framework of interactive proof systems for
classical machine learning, we develop a framework for classical verification
of quantum learning. We exhibit learning problems that a classical learner
cannot efficiently solve on their own, but that they can efficiently and
reliably solve when interacting with an untrusted quantum prover. Concretely,
we consider the problems of agnostic learning parities and Fourier-sparse
functions with respect to distributions with uniform input marginal. We propose
a new quantum data access model that we call "mixture-of-superpositions"
quantum examples, based on which we give efficient quantum learning algorithms
for these tasks. Moreover, we prove that agnostic quantum parity and
Fourier-sparse learning can be efficiently verified by a classical verifier
with only random example or statistical query access. Finally, we showcase two
general scenarios in learning and verification in which quantum
mixture-of-superpositions examples do not lead to sample complexity
improvements over classical data. Our results demonstrate that the potential
power of quantum data for learning tasks, while not unlimited, can be utilized
by classical agents through interaction with untrusted quantum entities.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05253'>Quantum computing algorithms for inverse problems on graphs and an NP-complete inverse problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Joonas Ilmavirta, Matti Lassas, Jinpeng Lu, Lauri Oksanen, Lauri Ylinen</p><p>We consider an inverse problem for a finite graph $(X,E)$ where we are given
a subset of vertices $B\subset X$ and the distances $d_{(X,E)}(b_1,b_2)$ of all
vertices $b_1,b_2\in B$. The distance of points $x_1,x_2\in X$ is defined as
the minimal number of edges needed to connect two vertices, so all edges have
length 1. The inverse problem is a discrete version of the boundary rigidity
problem in Riemannian geometry or the inverse travel time problem in
geophysics. We will show that this problem has unique solution under certain
conditions and develop quantum computing methods to solve it. We prove the
following uniqueness result: when $(X,E)$ is a tree and $B$ is the set of
leaves of the tree, the graph $(X,E)$ can be uniquely determined in the class
of all graphs having a fixed number of vertices. We present a quantum computing
algorithm which produces a graph $(X,E)$, or one of those, which has a given
number of vertices and the required distances between vertices in $B$. To this
end we develop an algorithm that takes in a qubit representation of a graph and
combine it with Grover's search algorithm. The algorithm can be implemented
using only $O(|X|^2)$ qubits, the same order as the number of elements in the
adjacency matrix of $(X,E)$. It also has a quadratic improvement in
computational cost compared to standard classical algorithms. Finally, we
consider applications in theory of computation, and show that a slight
modification of the above inverse problem is NP-complete: all NP-problems can
be reduced to a discrete inverse problem we consider.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Ilmavirta_J/0/1/0/all/0/1">Joonas Ilmavirta</a>, <a href="http://arxiv.org/find/math/1/au:+Lassas_M/0/1/0/all/0/1">Matti Lassas</a>, <a href="http://arxiv.org/find/math/1/au:+Lu_J/0/1/0/all/0/1">Jinpeng Lu</a>, <a href="http://arxiv.org/find/math/1/au:+Oksanen_L/0/1/0/all/0/1">Lauri Oksanen</a>, <a href="http://arxiv.org/find/math/1/au:+Ylinen_L/0/1/0/all/0/1">Lauri Ylinen</a></p><p>We consider an inverse problem for a finite graph $(X,E)$ where we are given
a subset of vertices $B\subset X$ and the distances $d_{(X,E)}(b_1,b_2)$ of all
vertices $b_1,b_2\in B$. The distance of points $x_1,x_2\in X$ is defined as
the minimal number of edges needed to connect two vertices, so all edges have
length 1. The inverse problem is a discrete version of the boundary rigidity
problem in Riemannian geometry or the inverse travel time problem in
geophysics. We will show that this problem has unique solution under certain
conditions and develop quantum computing methods to solve it. We prove the
following uniqueness result: when $(X,E)$ is a tree and $B$ is the set of
leaves of the tree, the graph $(X,E)$ can be uniquely determined in the class
of all graphs having a fixed number of vertices. We present a quantum computing
algorithm which produces a graph $(X,E)$, or one of those, which has a given
number of vertices and the required distances between vertices in $B$. To this
end we develop an algorithm that takes in a qubit representation of a graph and
combine it with Grover's search algorithm. The algorithm can be implemented
using only $O(|X|^2)$ qubits, the same order as the number of elements in the
adjacency matrix of $(X,E)$. It also has a quadratic improvement in
computational cost compared to standard classical algorithms. Finally, we
consider applications in theory of computation, and show that a slight
modification of the above inverse problem is NP-complete: all NP-problems can
be reduced to a discrete inverse problem we consider.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04858'>Scenic Routes with Weighted Points in 2D</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vijayraj Shanmugaraj, Lini Thomas, Kamalakar Karlapalem</p><p>In a given 2D space, we can have points with different levels of importance.
One would prefer viewing those points from a closer/farther position per their
level of importance. A point in 2D from where the user can view two given
points per his/her preference of distance is termed a scenic point. We develop
the concept of scenic paths in a 2D space for two points that have weights
associated with them. Subsequently, we propose algorithms to generate scenic
routes a traveler can take, which cater to certain principles which define the
scenic routes. Following are the contributions of this paper: (1) mathematical
formulation of a scenic point, (2) introduction of scenic routes formed by such
scenic points in two-class point configurations in 2D spaces, and (3) design of
scenic route generation algorithms that fulfill certain defined requirements.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Shanmugaraj_V/0/1/0/all/0/1">Vijayraj Shanmugaraj</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_L/0/1/0/all/0/1">Lini Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlapalem_K/0/1/0/all/0/1">Kamalakar Karlapalem</a></p><p>In a given 2D space, we can have points with different levels of importance.
One would prefer viewing those points from a closer/farther position per their
level of importance. A point in 2D from where the user can view two given
points per his/her preference of distance is termed a scenic point. We develop
the concept of scenic paths in a 2D space for two points that have weights
associated with them. Subsequently, we propose algorithms to generate scenic
routes a traveler can take, which cater to certain principles which define the
scenic routes. Following are the contributions of this paper: (1) mathematical
formulation of a scenic point, (2) introduction of scenic routes formed by such
scenic points in two-class point configurations in 2D spaces, and (3) design of
scenic route generation algorithms that fulfill certain defined requirements.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04953'>Scenic Routes over Points in 2D Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Loay Rashid, Lini Thomas, Kamalakar Karlapalem</p><p>Consider a 2D coordinate space with a set of red and a set of blue points. We
define a scenic point as a point that is equidistant to a red point and a blue
point. The set of contiguous scenic points form a scenic path. The
perpendicular bisectors to the line joining a red point and a blue point forms
a scenic path between the red point and the blue point. A scenic route is a
traversal made from scenic paths. In this paper, we address this novel problem
by (i) designing algorithms for scenic route generation, (ii) studying the
algorithms different properties and (iii) analyzing the routes generated by
these algorithms. Scenic routes have applications in geo-spatial visualizations
and visual analytics.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rashid_L/0/1/0/all/0/1">Loay Rashid</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_L/0/1/0/all/0/1">Lini Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlapalem_K/0/1/0/all/0/1">Kamalakar Karlapalem</a></p><p>Consider a 2D coordinate space with a set of red and a set of blue points. We
define a scenic point as a point that is equidistant to a red point and a blue
point. The set of contiguous scenic points form a scenic path. The
perpendicular bisectors to the line joining a red point and a blue point forms
a scenic path between the red point and the blue point. A scenic route is a
traversal made from scenic paths. In this paper, we address this novel problem
by (i) designing algorithms for scenic route generation, (ii) studying the
algorithms different properties and (iii) analyzing the routes generated by
these algorithms. Scenic routes have applications in geo-spatial visualizations
and visual analytics.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04850'>Longest Common Prefix Arrays for Succinct k-Spectra</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jarno N. Alanko, Elena Biagi, Simon J. Puglisi</p><p>The k-spectrum of a string is the set of all distinct substrings of length k
occurring in the string. K-spectra have many applications in bioinformatics
including pseudoalignment and genome assembly. The Spectral Burrows-Wheeler
Transform (SBWT) has been recently introduced as an algorithmic tool to
efficiently represent and query these objects. The longest common prefix (LCP)
array for a k-spectrum is an array of length n that stores the length of the
longest common prefix of adjacent k-mers as they occur in lexicographical
order. The LCP array has at least two important applications, namely to
accelerate pseudoalignment algorithms using the SBWT and to allow simulation of
variable-order de Bruijn graphs within the SBWT framework. In this paper we
explore algorithms to compute the LCP array efficiently from the SBWT
representation of the k-spectrum. Starting with a straightforward O(nk) time
algorithm, we describe algorithms that are efficient in both theory and
practice. We show that the LCP array can be computed in optimal O(n) time,
where n is the length of the SBWT of the spectrum. In practical genomics
scenarios, we show that this theoretically optimal algorithm is indeed
practical, but is often outperformed on smaller values of k by an
asymptotically suboptimal algorithm that interacts better with the CPU cache.
Our algorithms share some features with both classical Burrows-Wheeler
inversion algorithms and LCP array construction algorithms for suffix arrays.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alanko_J/0/1/0/all/0/1">Jarno N. Alanko</a>, <a href="http://arxiv.org/find/cs/1/au:+Biagi_E/0/1/0/all/0/1">Elena Biagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Puglisi_S/0/1/0/all/0/1">Simon J. Puglisi</a></p><p>The k-spectrum of a string is the set of all distinct substrings of length k
occurring in the string. K-spectra have many applications in bioinformatics
including pseudoalignment and genome assembly. The Spectral Burrows-Wheeler
Transform (SBWT) has been recently introduced as an algorithmic tool to
efficiently represent and query these objects. The longest common prefix (LCP)
array for a k-spectrum is an array of length n that stores the length of the
longest common prefix of adjacent k-mers as they occur in lexicographical
order. The LCP array has at least two important applications, namely to
accelerate pseudoalignment algorithms using the SBWT and to allow simulation of
variable-order de Bruijn graphs within the SBWT framework. In this paper we
explore algorithms to compute the LCP array efficiently from the SBWT
representation of the k-spectrum. Starting with a straightforward O(nk) time
algorithm, we describe algorithms that are efficient in both theory and
practice. We show that the LCP array can be computed in optimal O(n) time,
where n is the length of the SBWT of the spectrum. In practical genomics
scenarios, we show that this theoretically optimal algorithm is indeed
practical, but is often outperformed on smaller values of k by an
asymptotically suboptimal algorithm that interacts better with the CPU cache.
Our algorithms share some features with both classical Burrows-Wheeler
inversion algorithms and LCP array construction algorithms for suffix arrays.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04884'>Faster Approximation Algorithms for Parameterized Graph Clustering and Edge Labeling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vedangi Bengali, Nate Veldt</p><p>Graph clustering is a fundamental task in network analysis where the goal is
to detect sets of nodes that are well-connected to each other but sparsely
connected to the rest of the graph. We present faster approximation algorithms
for an NP-hard parameterized clustering framework called LambdaCC, which is
governed by a tunable resolution parameter and generalizes many other
clustering objectives such as modularity, sparsest cut, and cluster deletion.
Previous LambdaCC algorithms are either heuristics with no approximation
guarantees, or computationally expensive approximation algorithms. We provide
fast new approximation algorithms that can be made purely combinatorial. These
rely on a new parameterized edge labeling problem we introduce that generalizes
previous edge labeling problems that are based on the principle of strong
triadic closure and are of independent interest in social network analysis. Our
methods are orders of magnitude more scalable than previous approximation
algorithms and our lower bounds allow us to obtain a posteriori approximation
guarantees for previous heuristics that have no approximation guarantees of
their own.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bengali_V/0/1/0/all/0/1">Vedangi Bengali</a>, <a href="http://arxiv.org/find/cs/1/au:+Veldt_N/0/1/0/all/0/1">Nate Veldt</a></p><p>Graph clustering is a fundamental task in network analysis where the goal is
to detect sets of nodes that are well-connected to each other but sparsely
connected to the rest of the graph. We present faster approximation algorithms
for an NP-hard parameterized clustering framework called LambdaCC, which is
governed by a tunable resolution parameter and generalizes many other
clustering objectives such as modularity, sparsest cut, and cluster deletion.
Previous LambdaCC algorithms are either heuristics with no approximation
guarantees, or computationally expensive approximation algorithms. We provide
fast new approximation algorithms that can be made purely combinatorial. These
rely on a new parameterized edge labeling problem we introduce that generalizes
previous edge labeling problems that are based on the principle of strong
triadic closure and are of independent interest in social network analysis. Our
methods are orders of magnitude more scalable than previous approximation
algorithms and our lower bounds allow us to obtain a posteriori approximation
guarantees for previous heuristics that have no approximation guarantees of
their own.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04902'>A Cover Time Study of a non-Markovian Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guanhua Fang, Gennady Samorodnitsky, Zhiqiang Xu</p><p>Given a traversal algorithm, cover time is the expected number of steps
needed to visit all nodes in a given graph. A smaller cover time means a higher
exploration efficiency of traversal algorithm. Although random walk algorithms
have been studied extensively in the existing literature, there has been no
cover time result for any non-Markovian method. In this work, we stand on a
theoretical perspective and show that the negative feedback strategy (a
count-based exploration method) is better than the naive random walk search. In
particular, the former strategy can locally improve the search efficiency for
an arbitrary graph. It also achieves smaller cover times for special but
important graphs, including clique graphs, tree graphs, etc. Moreover, we make
connections between our results and reinforcement learning literature to give
new insights on why classical UCB and MCTS algorithms are so useful. Various
numerical results corroborate our theoretical findings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fang_G/0/1/0/all/0/1">Guanhua Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Samorodnitsky_G/0/1/0/all/0/1">Gennady Samorodnitsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiqiang Xu</a></p><p>Given a traversal algorithm, cover time is the expected number of steps
needed to visit all nodes in a given graph. A smaller cover time means a higher
exploration efficiency of traversal algorithm. Although random walk algorithms
have been studied extensively in the existing literature, there has been no
cover time result for any non-Markovian method. In this work, we stand on a
theoretical perspective and show that the negative feedback strategy (a
count-based exploration method) is better than the naive random walk search. In
particular, the former strategy can locally improve the search efficiency for
an arbitrary graph. It also achieves smaller cover times for special but
important graphs, including clique graphs, tree graphs, etc. Moreover, we make
connections between our results and reinforcement learning literature to give
new insights on why classical UCB and MCTS algorithms are so useful. Various
numerical results corroborate our theoretical findings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.05243'>Analysis of Knuth's Sampling Algorithm D and D'</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mridul Nandi, Soumit Paul</p><p>In this research paper, we address the Distinct Elements estimation problem
in the context of streaming algorithms. The problem involves estimating the
number of distinct elements in a given data stream $\mathcal{A} = (a_1,
a_2,\ldots, a_m)$, where $a_i \in \{1, 2, \ldots, n\}$. Over the past four
decades, the Distinct Elements problem has received considerable attention,
theoretically and empirically, leading to the development of space-optimal
algorithms. A recent sampling-based algorithm proposed by Chakraborty et
al.[11] has garnered significant interest and has even attracted the attention
of renowned computer scientist Donald E. Knuth, who wrote an article on the
same topic [6] and called the algorithm CVM. In this paper, we thoroughly
examine the algorithms (referred to as CVM1, CVM2 in [6] and DonD, DonD' in
[6]. We first unify all these algorithms and call them cutoff-based algorithms.
Then we provide an approximation and biasedness analysis of these algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nandi_M/0/1/0/all/0/1">Mridul Nandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1">Soumit Paul</a></p><p>In this research paper, we address the Distinct Elements estimation problem
in the context of streaming algorithms. The problem involves estimating the
number of distinct elements in a given data stream $\mathcal{A} = (a_1,
a_2,\ldots, a_m)$, where $a_i \in \{1, 2, \ldots, n\}$. Over the past four
decades, the Distinct Elements problem has received considerable attention,
theoretically and empirically, leading to the development of space-optimal
algorithms. A recent sampling-based algorithm proposed by Chakraborty et
al.[11] has garnered significant interest and has even attracted the attention
of renowned computer scientist Donald E. Knuth, who wrote an article on the
same topic [6] and called the algorithm CVM. In this paper, we thoroughly
examine the algorithms (referred to as CVM1, CVM2 in [6] and DonD, DonD' in
[6]. We first unify all these algorithms and call them cutoff-based algorithms.
Then we provide an approximation and biasedness analysis of these algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-09T00:30:00Z">Friday, June 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, June 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/'>Human Extinction?</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          And some counter-arguments Hava Siegelmann is the Provost Professor in the Manning College of Information and Computer Sciences at U.Mass. Amherst. She returned in 2019 from serving as a DARPA Program Director. Her work at DARPA included leading two AI initiatives: L2M for &#8220;Lifelong Learning Machines&#8221; and GARD for &#8220;Guaranteeing AI Robustness against Deception.&#8221; Today [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><span style="color: #0044cc;"><br />
<em>And some counter-arguments</em><br />
</span></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/dr-hava-siegelmann/" rel="attachment wp-att-21728"><img data-attachment-id="21728" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/dr-hava-siegelmann/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?fit=400%2C500&amp;ssl=1" data-orig-size="400,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Dr. Hava Siegelmann&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Dr. Hava Siegelmann (PRNewsfoto\/Dr. Hava Siegelmann)&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;This image must be used within the context of the news release it accompanied. Request permission from issuer for other uses.&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Dr Hava Siegelmann&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?fit=240%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?fit=400%2C500&amp;ssl=1" decoding="async" loading="lazy" class="alignright wp-image-21728" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?resize=120%2C150&#038;ssl=1" alt="" width="120" height="150" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?w=400&amp;ssl=1 400w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/Dr_Hava_Siegelmann.jpg?resize=240%2C300&amp;ssl=1 240w" sizes="(max-width: 120px) 100vw, 120px" data-recalc-dims="1" /></a></p>
<p>
Hava Siegelmann is the Provost Professor in the Manning College of Information and Computer Sciences at U.Mass. Amherst. She returned in 2019 from serving as a DARPA Program Director. Her work at DARPA included leading two AI initiatives: <a href="https://www.darpa.mil/news-events/2017-03-16">L2M</a> for &#8220;Lifelong Learning Machines&#8221; and <a href="https://www.darpa.mil/program/guaranteeing-ai-robustness-against-deception">GARD</a> for &#8220;Guaranteeing AI Robustness against Deception.&#8221;</p>
<p>
Today we discuss whether we need measures to guarantee human robustness against AI.</p>
<p>
Siegelmann was <a href="https://federalnewsnetwork.com/artificial-intelligence/2020/06/darpa-honors-artificial-intelligence-expert/">awarded</a> the Meritorious Public Service Medal, a rare high honor from the US Department of Defense. Her dean at U.Mass., Laura Haas, stated in a <a href="https://www.prnewswire.com/news-releases/darpa-recognizes-umass-professor-hava-siegelmann-for-major-advances-in-ai-301081766.html">release</a>, &#8220;I am extremely proud of Hava&#8217;s service to DARPA and the nation. Her work at DARPA has helped to advance AI for us all.&#8221; </p>
<p>
One thing that catches our interest, in line with another recent <a href="https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/">post</a>, is that her applied work jumped off from a mainstream topic in theory. Well, one maybe seen as off the mainstream: that of &#8220;super-Turing&#8221; machines. Let&#8217;s discuss that first before coming to AI.</p>
<p><H2> Super-Turing </H2></p>
<p><p>
We who work in polynomial-based complexity often feel that undecidable languages and other aspects of recursion theory are walled off in a different area of theory. Part of the shock of the <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%5E%2A+%3D+RE%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{MIP^* = RE}}" class="latex" /> <a href="https://arxiv.org/abs/2001.04383">result</a> was breaking down this wall. See this great <a href="https://quantumfrontiers.com/2020/03/01/the-shape-of-mip-re/">post</a> by coauthor Henry Yuen for more aspects.</p>
<p>
The same feeling goes even more for <a href="https://en.wikipedia.org/wiki/Hypercomputation">hypercomputing</a> models, defined as able to compute functions that are not Turing-computable. Our own <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%5E%2A+%3D+RE%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{MIP^* = RE}}" class="latex" /> <a href="https://rjlipton.wpcomstaging.com/2020/01/15/halting-is-poly-time-quantum-provable/">post</a> includes a story of how David Deutsch in the mid-1980s originally believed that quantum computers could solve the Halting Problem in finite time. </p>
<p>
Yet many of us have done real work with a hypercomputing model so broad that it can recognize uncountably many languages. The model&#8217;s subtle power arguably poses the most trenchant <a href="http://theory.stanford.edu/~liyang/teaching/projects/natural-proofs-barrier-and-P-NP.pdf">barrier</a> to proving <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{P &#92;neq NP}}" class="latex" />. We refer, of course, to the model of <em>nonuniform</em> polynomial-size circuit families and its associated complexity class, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%2Fpoly%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{P/poly}}" class="latex" />. </p>
<p>
Indeed, poly-size circuits are the basis of Siegelmann&#8217;s celebrated 1995 <a href="https://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf">paper</a> in <em>Science</em> titled &#8220;Computation beyond the Turing Limit&#8221;&#8212;and a full 1996 <a href="https://www.sciencedirect.com/science/article/pii/S0304397596000874?ref=pdf_download&#038;fr=RR-2&#038;rr=7d3d858de9933344">followup</a> in <em>Theoretical Computer Science</em> titled &#8220;the simple dynamics of super Turing theories.&#8221; One point is that individual circuits are finite objects that can be manipulated&#8212;as likewise are finite neural networks. The analog recurrent neural networks (ARNNs) used by Siegelmann are allowed real-number coefficients. They in turn are related to a class of dynamical systems with simply-specified rules built around <em>analog shift</em> (AS) maps that obey a finite-dependence or finite-effect condition. These models define complexity classes <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BARNN%7D%5Bs%28n%29%5D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{ARNN}[s(n)]}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAS%7D%5Bs%28n%29%5D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{AS}[s(n)]}" class="latex" /> in the same manner as when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bs%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{s(n)}" class="latex" /> means Boolean circuit size. The main theorem is:</p>
<p>
<blockquote><p><b>Theorem 1</b> <em> For any function <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bs%28n%29+%5Cgeq+n%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{s(n) &#92;geq n}" class="latex" />, we have <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BARNN%7D%5Bs%28n%29%5D+%5Csubseteq+%5Cmathsf%7BAS%7D%5Bs%28n%29%5E%7BO%281%29%7D%5D%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{ARNN}[s(n)] &#92;subseteq &#92;mathsf{AS}[s(n)^{O(1)}]}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAS%7D%5Bs%28n%29%5D+%5Csubseteq+%5Cmathsf%7BARNN%7D%5Bs%28n%29%5E%7BO%281%29%7D%5D%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{AS}[s(n)] &#92;subseteq &#92;mathsf{ARNN}[s(n)^{O(1)}]}" class="latex" />. In particular, say restricted to languages over a binary alphabet, </em></p>
<p align="center"><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathsf%7BARNN%7D%5Bn%5E%7BO%281%29%7D%5D+%3D+%5Cmathsf%7BAS%7D%5Bn%5E%7BO%281%29%7D%5D+%3D+%5Cmathsf%7BP%2Fpoly%7D.+&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle &#92;mathsf{ARNN}[n^{O(1)}] = &#92;mathsf{AS}[n^{O(1)}] = &#92;mathsf{P/poly}. " class="latex" /></p>
<p>&nbsp;</p></blockquote>
<p>
A 2013 blog <a href="https://www.georgezarkadakis.com/super-turing-machines-and-oracles-the-making-of-a-artificial-mind/">post</a> by George Zarkadakis picks up the thread of how this correspondence fosters the notion of machines that learn by continual adaptation: the &#8220;lifelong learning machines.&#8221; What Siegelmann accomplished with her further work culminating at DARPA was demonstrate that these &#8220;super-Turing&#8221; ideas can be rendered into real applications.</p>
<p>
<p><H2> The View From Inside </H2></p>
<p><p>
The June 2020 PR Newswire item on Siegelmann&#8217;s award has some passages on applications that were at least inspired by her mode of approach (we&#8217;ve added bullets for clarity):</p>
<blockquote><p><b> </b> <em> DARPA points out Siegelmann&#8217;s &#8216;exceptionally productive&#8217; term included </p>
<ul>
<li>
developing a system that intelligently administers insulin and dextrose to maintain safe glucose levels for diabetics and critical care patients; </p>
<li>
sensors to identify dangerous chemicals from a safe distance; </p>
<li>
collaborative, secure learning platforms that allow unaffiliated groups to work synergistically without revealing sensitive data; and </p>
<li>
reverse engineering methods to identify cyber-attacks, secure the system, and find the attacker.
</ul>
<p></em>
</p></blockquote>
<p><p>
And this about Machine Learning (ML):</p>
<blockquote><p><b> </b> <em> Illustrating the difference between current AI and new L2M systems, Siegelmann stated, &#8220;Self-driving cars represent a pinnacle in state-of-the-art computation&#8212;demonstrating how far current technology can take us using increasingly clever programming. However, even these systems fail when encountering circumstances outside their training&#8230;&#8221; [Whereas], L2M systems represent &#8220;a fundamental change in ML,&#8221; she said, &#8220;L2M systems learn; they apply experience and adapt to new situations; instead of failing, they become better, the more they experience.&#8221; </em>
</p></blockquote>
<p><p>
And this: </p>
<blockquote><p><b> </b> <em> &#8220;We made real progress, demonstrated actual learning â something never done before &#8230; L2M improvements are already being incorporated into real-world systems; in five years, AI systems will be mainly of the L2M variety or incorporate L2M components. But it is very hard,&#8221; she adds, &#8220;for a machine to learn actively and there is still much to be done.&#8221; </em>
</p></blockquote>
<p><p>
Note that &#8220;in five years&#8221; meant by <b>2025</b>. We are over halfway there, and the headline-making <a href="https://en.wikipedia.org/wiki/ChatGPT">ChatGPT</a>, <a href="https://en.wikipedia.org/wiki/DALL-E">DALL-E</a>, and other models happened last year. </p>
<p>
<p><H2> The View From Other Insiders </H2></p>
<p><p>
It does not need much experience of dystopian fiction in book or movie form to imagine sinister plot twists of the above items:</p>
<ul>
<li>
The medical system tasked with inferring safe glucose levels discovers circumstances outside its training that enable it to plant chemical time bombs that can be used to control the patients, which include high government officials&#8230; </p>
<li>
The collaborative platform that admits unaffiliated groups reverse-engineers methods to identify cyber-attackers into ones that admit them, then secures the system to find the original defenders and hunt them down&#8230; </p>
<li>
Self-driving cars equipped with manual override learn that the manual operators are idiots (which we are) and &#8230; we get a remake of Alfred Hitchcock&#8217;s <a href="https://en.wikipedia.org/wiki/The_Birds_(film)">The Birds</a> titled <em>The Cars</em>.
</ul>
<p>
Are we being unfair and far-fetched? Perhaps so in these cases. But here are two &#8220;real-life AI risks&#8221; postulated in a <a href="https://www.tableau.com/data-insights/ai/risks#risks">statement</a> by the AI analytics company <a href="https://www.tableau.com">Tableau</a>:</p>
<blockquote><p><b> </b> <em> If companies rely too much on AI predictions for when maintenance will be done without other checks, it could lead to machinery malfunctions that injure workers. Models used in healthcare could cause misdiagnoses. </em>
</p></blockquote>
<p><p>
And a &#8220;hypothetical risk&#8221;:</p>
<blockquote><p><b> </b> <em> [A]n AI system tasked with &#8230; helping to rebuild an endangered marine creatureâs ecosystem [could] decide that other parts of the ecosystem are unimportant and destroy their habitats. And it could also view human intervention to fix or prevent this as a threat to its goal. </em>
</p></blockquote>
<p><p>
Last week, an <a href="https://www.safe.ai/statement-on-ai-risk#open-letter">open letter</a> signed by numerous AI luminaries made a simple statement that went all the way to the risk of <em>human extinction</em>, not just bungling a coral reef:</p>
<blockquote><p><b> </b> <em> Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war. </em>
</p></blockquote>
<p><p>
Dan Hendrycks, director of the Center For AI Safety, stated further in his May 30 Twitter <a href="https://twitter.com/DanHendrycks/status/1663474795865059329">thread</a> releasing the letter:</p>
<blockquote><p><b> </b> <em> &#8220;[T]here are many &#8216;important and urgent risks from AI,&#8217; not just the risk of extinction; for example, systemic bias, misinformation, malicious use, cyberattacks, and weaponization.&#8221; </em>
</p></blockquote>
<p><p>
An accompanying NPR <a href="https://www.npr.org/2023/05/30/1178943163/ai-risk-extinction-chatgpt">story</a> also quotes Geoffrey Hinton, first on the list of the letter&#8217;s <a href="https://www.safe.ai/statement-on-ai-risk#signatories">signatories</a>, to the effect that AI programs are on track to outperform their creators sooner than anyone anticipated:</p>
<blockquote><p><b> </b> <em> &#8220;I thought for a long time that we were, like, 30 to 50 years away from that. &#8230; Now, I think we may be much closer, maybe only five years away from that.&#8221; </em>
</p></blockquote>
<p><p>
That five-year horizon means <b>2028</b>. The second signer is Yoshua Bengio, making two of the three researchers who won the 2018 Turing Award for their research on neural networks. The third, Yann LeCun, who leads Meta&#8217;s AI research efforts, has not signed yet. </p>
<table style="margin: auto;">
<tbody>
<tr>
<td><a href="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/hintonbengiolecun/" rel="attachment wp-att-21730"><img data-attachment-id="21730" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/hintonbengiolecun/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?fit=999%2C374&amp;ssl=1" data-orig-size="999,374" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="HintonBengioLeCun" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?fit=300%2C112&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?fit=600%2C225&amp;ssl=1" decoding="async" loading="lazy" class="aligncenter wp-image-21730" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?resize=360%2C135&#038;ssl=1" alt="" width="360" height="135" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?w=999&amp;ssl=1 999w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?resize=300%2C112&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/HintonBengioLeCun.jpg?resize=768%2C288&amp;ssl=1 768w" sizes="(max-width: 360px) 100vw, 360px" data-recalc-dims="1" /></a></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from AI Builders <a href="https://aibuilders.ai/le-prix-turing-recompense-trois-pionniers-de-lintelligence-artificielle-yann-lecun-yoshua-bengio-et-geoffrey-hinton/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
That third slot is appropriately filled by Google DeepMind CEO Demis Hassabis, who along with his university friend and the letter&#8217;s 26th signer, David Silver, gained prominence for developing AlphaGo and AlphaZero. Scott <a href="https://www.scottaaronson.com">Aaronson</a>&#8212;of course a famed complexity and quantum computing leader who is now working within OpenAI on a watermarking scheme for detecting ChatGPT usage&#8212;is a signer. Others whom Ken and I have met include Bill McKibben, Peter Norvig, David Chalmers, Bart Selman, Roman Yampolskiy, and Steve Petersen of Niagara University near Ken.</p>
<p>
<p><H2> Shock und D&uuml;rrenmatt? </H2></p>
<p>CNN&#8217;s <a href="https://www.cnn.com/2023/05/30/media/artificial-intelligence-warning-reliable-sources/index.html">story</a> on the letter is subtitled, &#8220;Are we taking it seriously enough?&#8221; It ends by quoting Duke&#8217;s Cynthia Rudin, a star student of Ingrid Daubechies whom we recently <a href="https://rjlipton.wpcomstaging.com/2023/05/14/ingrid-daubechies-prizes-and-art/">profiled</a>:</p>
<blockquote><p><b> </b> <em> &#8220;Do we really need more evidence that AIâs negative impact could be as big as nuclear war?&#8221; </em>
</p></blockquote>
<p><p>
This calls to mind the upcoming <a href="https://en.wikipedia.org/wiki/Oppenheimer_(film)">movie</a> about J. Robert Oppenheimer and also Friedrich D&uuml;rrenmatt&#8217;s play <a href="https://en.wikipedia.org/wiki/The_Physicists">The Physicists</a>, whose last scenes clash two tag lines:</p>
<blockquote><p><b> </b> <em> &#8220;We must take back our science&#8230;&#8221; &#8212;but&#8212; &#8220;something once thought cannot be unthought.&#8221; </em>
</p></blockquote>
<p><p>
There is also the old book <a href="https://en.wikipedia.org/wiki/Future_Shock">Future Shock</a> by Alvin Toffler, which warns of &#8220;<a href="https://en.wikipedia.org/wiki/Information_overload">information overload</a>&#8221; but maybe not AI peril <em>per se</em>. </p>
<p>
Let us nudge &#8220;Shock&#8221; to the German word <em>Schach</em> meaning &#8220;chess.&#8221; The person who might feel he was most viscerally slapped down by AI is Garry Kasparov, the former world chess champion who famously lost to IBM&#8217;s Deep Blue computer in 1997. However, he had <a href="https://www.themanufacturer.com/articles/garry-kasparov-intelligent-machines/">this</a> to say in 2017:</p>
<blockquote><p><b> </b> <em> &#8220;Machines that replace physical labour have allowed us to focus more on what makes us human: our minds. Intelligent machines will continue that process, taking over the more menial aspects of cognition and elevating our mental lives toward creativity, curiosity, beauty, and joy. These are what truly make us human, not any particular activity or skill, like swinging a hammer â or even playing chess.&#8221; </em>
</p></blockquote>
<p><p>
Marc Andreesen, of early <a href="https://en.wikipedia.org/wiki/Mosaic_(web_browser)">Mosaic</a> and <a href="https://en.wikipedia.org/wiki/Netscape">Netscape</a> fame, posted on Tuesday a long <a href="https://a16z.com/2023/06/06/ai-will-save-the-world/">response</a> to the open letter titled &#8220;Why AI Will Save the World.&#8221; It rebuts four of the stated AI risks:</p>
<ol>
<li>
Will AI Kill Us All? </p>
<li>
Will AI Ruin Our Society? </p>
<li>
Will AI Take All Our Jobs? </p>
<li>
Will AI Lead To Crippling Inequality?
</ol>
<p>
It concedes as a point 5 that AI will empower bad actors to be badder and more quickly thus. But it ends with a point that both of us have also heard at DARPA: the motive of not being surprised and subjugated by something that an adversary develops first. On that basis he advocates &#8220;Pursuing AI With Maximum Force And Speed.&#8221; </p>
<p>
I (Ken writing this part) agree with Kasparov and Andreesen&#8212;with one further caveat that reflects the &#8220;guardrails&#8221; concern of a March <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter</a> from the Future of Life institute, but without the six-month &#8220;pause&#8221; it advocates. This is that communications should promote their receivers to exercise <em>scientific skepticism</em>, such as we&#8217;ve tried to do in our <a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/">own</a> <a href="https://rjlipton.wpcomstaging.com/2023/04/01/the-chatgpt-conundrum/">jocular</a> <a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/">posts</a> on (Chat)GPT.</p>
<p>
Perhaps the most evocative word will come from the Oscar-nominated film director Bennett Miller. He has evidently <a href="https://www.worldofreel.com/blog/2023/4/1uzqxkaw0hham43fsyux6u7q2vkrd0">revived</a> a documentary project begun in 2016 about the debate over AI. He also opened a Manhattan <a href="https://hypebeast.com/2023/3/bennett-miller-gagosian-exhibition-new-york-ai">exhibit</a> of his own AI-assisted images. The New York Times included his work in a <a href="https://www.nytimes.com/2023/05/03/arts/design/ai-makes-nostalgic-images.html">roundup</a> of AI used to create art that, curiously, is of itself &#8216;borne back ceaselessly into the past.&#8217;</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
I knew some of the early greats in AI. One was Roger <a href="https://en.wikipedia.org/wiki/Roger_Schank">Schank</a> and was at Yale University when I arrived with my then fresh Ph.D. We have talked about Roger previously <a href="https://rjlipton.wpcomstaging.com/2023/02/05/artificial-intelligence-just-lost-a-leader/">here</a>.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/rs-3/" rel="attachment wp-att-21732"><img data-attachment-id="21732" data-permalink="https://rjlipton.wpcomstaging.com/2023/06/08/human-extinction/rs-3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?fit=241%2C241&amp;ssl=1" data-orig-size="241,241" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rs" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?fit=241%2C241&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?fit=241%2C241&amp;ssl=1" decoding="async" loading="lazy" class="aligncenter wp-image-21732" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?resize=150%2C150&#038;ssl=1" alt="" width="150" height="150" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?w=241&amp;ssl=1 241w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/06/rs.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1" /></a></p>
<p>
I wonder a bit about what Roger would say today about the potential of AI on human extinction. I think he loved AI, was a great leader in all aspects of AI, but perhaps never saw it with the potential to extinct humans? What do you all think?</p>
<p>
Ken adds that it might be fruitful to seek more understanding of what exactly <em>circuit complexity</em> had to do with all this. He notes a long <a href="https://www.quantamagazine.org/in-new-paradox-black-holes-appear-to-evade-heat-death-20230606/">article</a> in <em>Quanta</em> on Tuesday that highlights the emerging role of circuit complexity in resolving issues of information and black holes. There is a hint of similarity to Siegelmann&#8217;s machine-learning mechanism in how quantum systems are said to evolve to embody greater circuit complexity.</p>
<p><P><br />
[&#8220;knowledge&#8221;->&#8221;science&#8221; in DÃ¼rrenmatt quote]</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T20:38:23Z">Thursday, June 08 2023, 20:38</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/'>Determining Ramsey numbers using finite geometry</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Originally posted on Anurag&#039;s Math Blog: <br>Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a&#8230;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <div class="wpcom-reblog-snapshot"><div class="reblogger-note"><div class='reblogger-note-content'><blockquote><p>Sam Mattheus and Jacques Verstraete made a remarkable breakthrough for Ramsey numbers <img src="https://s0.wp.com/latex.php?latex=R%284%2Ct%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="R(4,t)" class="latex" />, and Anurag Bishnoi wrote a beautiful blog post about it. Congratulations Sam and Jacques! Mattheus and Verstraete <a href="https://arxiv.org/abs/2306.04007">show that</a> <img src="https://s0.wp.com/latex.php?latex=r%284%2Ct%29+%5Cge+c+%5Cfrac+%7Bt%5E3%7D%7B%5Clog+%5E4+t%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r(4,t) &#092;ge c &#092;frac {t^3}{&#092;log ^4 t}" class="latex" />.</p>
</blockquote></div></div><div class="reblog-post"><p class="reblog-from"><img alt='' src='https://0.gravatar.com/avatar/9b550c7bd755079f79698630b9b84e867941554d901106a5e5428c21cd573092?s=32&#038;d=identicon&#038;r=PG' class='avatar avatar-32' height='32' width='32' /><a href="https://anuragbishnoi.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/">Anurag&#039;s Math Blog</a></p><div class="reblogged-content">
<p></p>

<p><a href="https://sammattheus.wordpress.com/author/sammattheus/">Sam Mattheus</a> and <a href="https://math.ucsd.edu/people/profiles/jacques-verstraete">Jacques Verstraete</a> have posted a <a href="https://arxiv.org/abs/2306.04007">preprint</a> today where they solve the classic open problem of determining the asymptotics of the <a href="https://en.wikipedia.org/wiki/Ramsey%27s_theorem#Ramsey_numbers">Ramsey number</a> $latex r(4, t)$.  They <a href="https://arxiv.org/abs/2306.04007">show that</a></p>

<p></p>

<p></p>

<p class="has-text-align-center">$latex r(4, t) geq c frac{t^3}{log^4 t}$</p>

<p></p>

<p></p>

<p>which is just a factor of $latex log^2 t$ away from the upper bound. The only other off-diagonal Ramsey number for which we knew the correct asymptotics prior to their work was $latex r(3, t)$, and the best lower bounds on $latex r(4, t)$ were $latex câ t^{5/2}/log^2 t$. These earlier bounds are in fact at the limit of what could be proved using the <a href="https://link.springer.com/article/10.1007/s00222-010-0247-x">random $latex H$-free process</a>. That barrier has finally been broken by using completely different techniques involving <a href="https://en.wikipedia.org/wiki/Finite_geometry">finite geometry</a>! Itâs an amazing breakthrough that builds up on the recent developments in Ramsey theory using finite geometry (see <a href="https://anuragbishnoi.wordpress.com/minicourse/">this</a> for an online minicourse I gave in 2021â¦</p>
</div><p class="reblog-source"><a href="https://anuragbishnoi.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/">View original post</a> <span class="more-words">929 more words</span></p></div></div><p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T19:31:29Z">Thursday, June 08 2023, 19:31</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/086'>TR23-086 |  Random $(\log n)$-CNF are Hard for Cutting Planes (Again) | 

	Dmitry Sokolov</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The random $\Delta$-CNF model is one of the most important distribution over $\Delta\text{-}\mathrm{SAT}$ instances. It is closely connected to various areas of computer science, statistical physics, and is a benchmark for satisfiability algorithms. Fleming, Pankratov, Pitassi, and Robere and independently Hrubes and Pudlak showed that when $\Delta = \Theta(\log n)$, any Cutting Planes proof for random $\Delta$-CNF on $n$ variables requires size $2^{n / \mathrm{polylog} n}$ in the regime where the number of clauses guarantees that the formula is unsatisfiable with high probability. In this paper we show tight lower bound $2^{\Omega(n)}$ on size CP-proofs for random $(\log n)$-CNF formulas. Moreover, our proof is much simpler and self-contained in contrast with previous results based on Jukna&#39;s lower bound for monotone circuits.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The random $\Delta$-CNF model is one of the most important distribution over $\Delta\text{-}\mathrm{SAT}$ instances. It is closely connected to various areas of computer science, statistical physics, and is a benchmark for satisfiability algorithms. Fleming, Pankratov, Pitassi, and Robere and independently Hrubes and Pudlak showed that when $\Delta = \Theta(\log n)$, any Cutting Planes proof for random $\Delta$-CNF on $n$ variables requires size $2^{n / \mathrm{polylog} n}$ in the regime where the number of clauses guarantees that the formula is unsatisfiable with high probability. In this paper we show tight lower bound $2^{\Omega(n)}$ on size CP-proofs for random $(\log n)$-CNF formulas. Moreover, our proof is much simpler and self-contained in contrast with previous results based on Jukna&#39;s lower bound for monotone circuits.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T13:55:09Z">Thursday, June 08 2023, 13:55</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://processalgebra.blogspot.com/2023/06/summer-school-on-formal-methods-for.html'>Summer School on Formal Methods for Cyber-Physical Systems and Workshop on Synthesis, Monitoring and Learning in Udine</a></h3>
        <p class='tr-article-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>The third edition of the UniVr/UniUd Summer School on Formal Methods for Cyber-Physical Systems&nbsp; will be held in Udine, Italy, in the period August 28-31. It will be followed by the Workshop on Synthesis, Monitoring and Learning on August 31 and September 1. The list of contributors to those events is top notch.&nbsp;</p><p>The course is offered in a hybrid format giving the possibility to remotely attend the course (on the Microsoft Teams platform).

On-site places are limited and assigned on first come first served basis.

The registration fees are:&nbsp;</p><ul><li>On-site participation, 250.00 Euro + VAT 22%&nbsp;</li><li>Online participation, 120.00 Euro + VAT 22%&nbsp;</li></ul><p>The deadline for online application is August 18, 2023.
Participation application is available at www.cism.it/en/activities/courses/J2303/&nbsp;</p><p>Spread the news and encourage students and young researchers to attend!
</p><p>By Luca Aceto</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The third edition of the <a href="http://tcs.uniud.it/summer-school" target="_blank">UniVr/UniUd Summer School on Formal Methods for Cyber-Physical Systems</a>&nbsp; will be held in Udine, Italy, in the period August 28-31. It will be followed by the <a href="http://tcs.uniud.it/smile" target="_blank">Workshop on Synthesis, Monitoring and Learning</a> on August 31 and September 1. The list of contributors to those events is top notch.&nbsp;</p><p>The course is offered in a hybrid format giving the possibility to remotely attend the course (on the Microsoft Teams platform).

On-site places are limited and assigned on first come first served basis.

The registration fees are:&nbsp;</p><ul style="text-align: left;"><li>On-site participation, 250.00 Euro + VAT 22%&nbsp;</li><li>Online participation, 120.00 Euro + VAT 22%&nbsp;</li></ul><p>The deadline for online application is August 18, 2023.
Participation application is available at <a href="https://www.cism.it/en/activities/courses/J2303/">https://www.cism.it/en/activities/courses/J2303/</a>&nbsp;</p><p>Spread the news and encourage students and young researchers to attend!
</p><p class="authors">By Luca Aceto</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T09:21:00Z">Thursday, June 08 2023, 09:21</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.03912'>Optimizing Sphere Valued Gaussian Noise Stability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Steven Heilman</p><p>We prove a vector-valued inequality for the Gaussian noise stability (i.e. we
prove a vector-valued Borell inequality) for Euclidean functions taking values
in the two-dimensional sphere, for all correlation parameters at most $1/10$ in
absolute value. This inequality was conjectured (for all correlation parameters
at most $1$ in absolute value) by Hwang, Neeman, Parekh, Thompson and Wright.
Such an inequality is needed to prove sharp computational hardness of the
product state Quantum MAX-CUT problem, assuming the Unique Games Conjecture.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Heilman_S/0/1/0/all/0/1">Steven Heilman</a></p><p>We prove a vector-valued inequality for the Gaussian noise stability (i.e. we
prove a vector-valued Borell inequality) for Euclidean functions taking values
in the two-dimensional sphere, for all correlation parameters at most $1/10$ in
absolute value. This inequality was conjectured (for all correlation parameters
at most $1$ in absolute value) by Hwang, Neeman, Parekh, Thompson and Wright.
Such an inequality is needed to prove sharp computational hardness of the
product state Quantum MAX-CUT problem, assuming the Unique Games Conjecture.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04505'>Hardness of Deceptive Certificate Selection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Stephan W&#xe4;ldchen</p><p>Recent progress towards theoretical interpretability guarantees for AI has
been made with classifiers that are based on interactive proof systems. A
prover selects a certificate from the datapoint and sends it to a verifier who
decides the class. In the context of machine learning, such a certificate can
be a feature that is informative of the class. For a setup with high soundness
and completeness, the exchanged certificates must have a high mutual
information with the true class of the datapoint. However, this guarantee
relies on a bound on the Asymmetric Feature Correlation of the dataset, a
property that so far is difficult to estimate for high-dimensional data. It was
conjectured in W\"aldchen et al. that it is computationally hard to exploit the
AFC, which is what we prove here.
</p>
<p>We consider a malicious prover-verifier duo that aims to exploit the AFC to
achieve high completeness and soundness while using uninformative certificates.
We show that this task is $\mathsf{NP}$-hard and cannot be approximated better
than $\mathcal{O}(m^{1/8 - \epsilon})$, where $m$ is the number of possible
certificates, for $\epsilon&gt;0$ under the Dense-vs-Random conjecture. This is
some evidence that AFC should not prevent the use of interactive classification
for real-world tasks, as it is computationally hard to be exploited.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Waldchen_S/0/1/0/all/0/1">Stephan W&#xe4;ldchen</a></p><p>Recent progress towards theoretical interpretability guarantees for AI has
been made with classifiers that are based on interactive proof systems. A
prover selects a certificate from the datapoint and sends it to a verifier who
decides the class. In the context of machine learning, such a certificate can
be a feature that is informative of the class. For a setup with high soundness
and completeness, the exchanged certificates must have a high mutual
information with the true class of the datapoint. However, this guarantee
relies on a bound on the Asymmetric Feature Correlation of the dataset, a
property that so far is difficult to estimate for high-dimensional data. It was
conjectured in W\"aldchen et al. that it is computationally hard to exploit the
AFC, which is what we prove here.
</p>
<p>We consider a malicious prover-verifier duo that aims to exploit the AFC to
achieve high completeness and soundness while using uninformative certificates.
We show that this task is $\mathsf{NP}$-hard and cannot be approximated better
than $\mathcal{O}(m^{1/8 - \epsilon})$, where $m$ is the number of possible
certificates, for $\epsilon&gt;0$ under the Dense-vs-Random conjecture. This is
some evidence that AFC should not prevent the use of interactive classification
for real-world tasks, as it is computationally hard to be exploited.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04546'>Querying Circumscribed Description Logic Knowledge Bases</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Carsten Lutz, Quentin Mani&#xe8;re, Robin Nolte</p><p>Circumscription is one of the main approaches for defining non-monotonic
description logics (DLs). While the decidability and complexity of traditional
reasoning tasks such as satisfiability of circumscribed DL knowledge bases
(KBs) is well understood, for evaluating conjunctive queries (CQs) and unions
thereof (UCQs), not even decidability had been established. In this paper, we
prove decidability of (U)CQ evaluation on circumscribed DL KBs and obtain a
rather complete picture of both the combined complexity and the data
complexity, for DLs ranging from ALCHIO via EL to various versions of DL-Lite.
We also study the much simpler atomic queries (AQs).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lutz_C/0/1/0/all/0/1">Carsten Lutz</a>, <a href="http://arxiv.org/find/cs/1/au:+Maniere_Q/0/1/0/all/0/1">Quentin Mani&#xe8;re</a>, <a href="http://arxiv.org/find/cs/1/au:+Nolte_R/0/1/0/all/0/1">Robin Nolte</a></p><p>Circumscription is one of the main approaches for defining non-monotonic
description logics (DLs). While the decidability and complexity of traditional
reasoning tasks such as satisfiability of circumscribed DL knowledge bases
(KBs) is well understood, for evaluating conjunctive queries (CQs) and unions
thereof (UCQs), not even decidability had been established. In this paper, we
prove decidability of (U)CQ evaluation on circumscribed DL KBs and obtain a
rather complete picture of both the combined complexity and the data
complexity, for DLs ranging from ALCHIO via EL to various versions of DL-Lite.
We also study the much simpler atomic queries (AQs).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04612'>Recognition of Seifert fibered spaces with boundary is in NP</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adele Jackson</p><p>We show that the decision problem of recognising whether a triangulated
3-manifold admits a Seifert fibered structure with non-empty boundary is in NP.
We also show that the problem of producing Seifert data for a triangulation of
such a manifold is in the complexity class FNP. We do this by proving that in
any triangulation of a Seifert fibered space with boundary there is both a
fundamental horizontal surface of small degree and a complete collection of
normal vertical annuli whose total weight is bounded by an exponential in the
square of the triangulation size.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Jackson_A/0/1/0/all/0/1">Adele Jackson</a></p><p>We show that the decision problem of recognising whether a triangulated
3-manifold admits a Seifert fibered structure with non-empty boundary is in NP.
We also show that the problem of producing Seifert data for a triangulation of
such a manifold is in the complexity class FNP. We do this by proving that in
any triangulation of a Seifert fibered space with boundary there is both a
fundamental horizontal surface of small degree and a complete collection of
normal vertical annuli whose total weight is bounded by an exponential in the
square of the triangulation size.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04178'>Optimal Transport Model Distributional Robustness</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Van-Anh Nguyen, Trung Le, Anh Tuan Bui, Thanh-Toan Do, Dinh Phung</p><p>Distributional robustness is a promising framework for training deep learning
models that are less vulnerable to adversarial examples and data distribution
shifts. Previous works have mainly focused on exploiting distributional
robustness in data space. In this work, we explore an optimal transport-based
distributional robustness framework on model spaces. Specifically, we examine a
model distribution in a Wasserstein ball of a given center model distribution
that maximizes the loss. We have developed theories that allow us to learn the
optimal robust center model distribution. Interestingly, through our developed
theories, we can flexibly incorporate the concept of sharpness awareness into
training a single model, ensemble models, and Bayesian Neural Networks by
considering specific forms of the center model distribution, such as a Dirac
delta distribution over a single model, a uniform distribution over several
models, and a general Bayesian Neural Network. Furthermore, we demonstrate that
sharpness-aware minimization (SAM) is a specific case of our framework when
using a Dirac delta distribution over a single model, while our framework can
be viewed as a probabilistic extension of SAM. We conduct extensive experiments
to demonstrate the usefulness of our framework in the aforementioned settings,
and the results show remarkable improvements in our approaches to the
baselines.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Van-Anh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1">Trung Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_A/0/1/0/all/0/1">Anh Tuan Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Do_T/0/1/0/all/0/1">Thanh-Toan Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Phung_D/0/1/0/all/0/1">Dinh Phung</a></p><p>Distributional robustness is a promising framework for training deep learning
models that are less vulnerable to adversarial examples and data distribution
shifts. Previous works have mainly focused on exploiting distributional
robustness in data space. In this work, we explore an optimal transport-based
distributional robustness framework on model spaces. Specifically, we examine a
model distribution in a Wasserstein ball of a given center model distribution
that maximizes the loss. We have developed theories that allow us to learn the
optimal robust center model distribution. Interestingly, through our developed
theories, we can flexibly incorporate the concept of sharpness awareness into
training a single model, ensemble models, and Bayesian Neural Networks by
considering specific forms of the center model distribution, such as a Dirac
delta distribution over a single model, a uniform distribution over several
models, and a general Bayesian Neural Network. Furthermore, we demonstrate that
sharpness-aware minimization (SAM) is a specific case of our framework when
using a Dirac delta distribution over a single model, while our framework can
be viewed as a probabilistic extension of SAM. We conduct extensive experiments
to demonstrate the usefulness of our framework in the aforementioned settings,
and the results show remarkable improvements in our approaches to the
baselines.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04316'>Point in polygon calculation using vector geometric methods with application to geospatial data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eyram Schwinger, Ralph Twum, Thomas Katsekpor, Gladys Schwinger</p><p>In this work, we designed algorithms for the point in polygon problem based
on the ray casting algorithm using equations from vector geometry. The
algorithms were implemented using the python programming language. We tested
the algorithm against the point in polygon algorithms used by the shapely (and
by extension geopandas) library and the OpenCV library using points from the
google Open Buildings project. Our algorithm in pure python performed much
better than the shapely implementation. It also performed better than the
OpenCV implementation when combined with the Numba optimization library. We
also performed simulations to verify that our algorithm performance was of the
order O(n).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Schwinger_E/0/1/0/all/0/1">Eyram Schwinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Twum_R/0/1/0/all/0/1">Ralph Twum</a>, <a href="http://arxiv.org/find/cs/1/au:+Katsekpor_T/0/1/0/all/0/1">Thomas Katsekpor</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwinger_G/0/1/0/all/0/1">Gladys Schwinger</a></p><p>In this work, we designed algorithms for the point in polygon problem based
on the ray casting algorithm using equations from vector geometry. The
algorithms were implemented using the python programming language. We tested
the algorithm against the point in polygon algorithms used by the shapely (and
by extension geopandas) library and the OpenCV library using points from the
google Open Buildings project. Our algorithm in pure python performed much
better than the shapely implementation. It also performed better than the
OpenCV implementation when combined with the Numba optimization library. We
also performed simulations to verify that our algorithm performance was of the
order O(n).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04367'>Linear Time Algorithms for NP-hard Problems restricted to GaTEx Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marc Hellmuth, Guillaume E. Scholz</p><p>The class of Galled-Tree Explainable (GaTEx) graphs has just recently been
discovered as a natural generalization of cographs. Cographs are precisely
those graphs that can be uniquely represented by a rooted tree where the leaves
of the tree correspond to the vertices of the graph. As a generalization, GaTEx
graphs are precisely those graphs that can be uniquely represented by a
particular rooted directed acyclic graph (called galled-tree).
</p>
<p>We consider here four prominent problems that are, in general, NP-hard:
computing the size $\omega(G)$ of a maximum clique, the size $\chi(G)$ of an
optimal vertex-coloring and the size $\alpha(G)$ of a maximum independent set
of a given graph $G$ as well as determining whether a graph is perfectly
orderable. We show here that $\omega(G)$, $\chi(G)$, $\alpha(G)$ can be
computed in linear-time for GaTEx graphs $G$. The crucial idea for the
linear-time algorithms is to avoid working on the GaTEx graphs $G$ directly,
but to use the the galled-trees that explain $G$ as a guide for the algorithms
to compute these invariants. In particular, we show first how to employ the
galled-tree structure to compute a perfect ordering of GaTEx graphs in
linear-time which is then used to determine $\omega(G)$, $\chi(G)$,
$\alpha(G)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hellmuth_M/0/1/0/all/0/1">Marc Hellmuth</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholz_G/0/1/0/all/0/1">Guillaume E. Scholz</a></p><p>The class of Galled-Tree Explainable (GaTEx) graphs has just recently been
discovered as a natural generalization of cographs. Cographs are precisely
those graphs that can be uniquely represented by a rooted tree where the leaves
of the tree correspond to the vertices of the graph. As a generalization, GaTEx
graphs are precisely those graphs that can be uniquely represented by a
particular rooted directed acyclic graph (called galled-tree).
</p>
<p>We consider here four prominent problems that are, in general, NP-hard:
computing the size $\omega(G)$ of a maximum clique, the size $\chi(G)$ of an
optimal vertex-coloring and the size $\alpha(G)$ of a maximum independent set
of a given graph $G$ as well as determining whether a graph is perfectly
orderable. We show here that $\omega(G)$, $\chi(G)$, $\alpha(G)$ can be
computed in linear-time for GaTEx graphs $G$. The crucial idea for the
linear-time algorithms is to avoid working on the GaTEx graphs $G$ directly,
but to use the the galled-trees that explain $G$ as a guide for the algorithms
to compute these invariants. In particular, we show first how to employ the
galled-tree structure to compute a perfect ordering of GaTEx graphs in
linear-time which is then used to determine $\omega(G)$, $\chi(G)$,
$\alpha(G)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04049'>One-sided Matrix Completion from Two Observations Per Row</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Steven Cao, Percy Liang, Gregory Valiant</p><p>Given only a few observed entries from a low-rank matrix $X$, matrix
completion is the problem of imputing the missing entries, and it formalizes a
wide range of real-world settings that involve estimating missing data.
However, when there are too few observed entries to complete the matrix, what
other aspects of the underlying matrix can be reliably recovered? We study one
such problem setting, that of "one-sided" matrix completion, where our goal is
to recover the right singular vectors of $X$, even in the regime where
recovering the left singular vectors is impossible, which arises when there are
more rows than columns and very few observations. We propose a natural
algorithm that involves imputing the missing values of the matrix $X^TX$ and
show that even with only two observations per row in $X$, we can provably
recover $X^TX$ as long as we have at least $\Omega(r^2 d \log d)$ rows, where
$r$ is the rank and $d$ is the number of columns. We evaluate our algorithm on
one-sided recovery of synthetic data and low-coverage genome sequencing. In
these settings, our algorithm substantially outperforms standard matrix
completion and a variety of direct factorization methods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1">Steven Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Percy Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1">Gregory Valiant</a></p><p>Given only a few observed entries from a low-rank matrix $X$, matrix
completion is the problem of imputing the missing entries, and it formalizes a
wide range of real-world settings that involve estimating missing data.
However, when there are too few observed entries to complete the matrix, what
other aspects of the underlying matrix can be reliably recovered? We study one
such problem setting, that of "one-sided" matrix completion, where our goal is
to recover the right singular vectors of $X$, even in the regime where
recovering the left singular vectors is impossible, which arises when there are
more rows than columns and very few observations. We propose a natural
algorithm that involves imputing the missing values of the matrix $X^TX$ and
show that even with only two observations per row in $X$, we can provably
recover $X^TX$ as long as we have at least $\Omega(r^2 d \log d)$ rows, where
$r$ is the rank and $d$ is the number of columns. We evaluate our algorithm on
one-sided recovery of synthetic data and low-coverage genome sequencing. In
these settings, our algorithm substantially outperforms standard matrix
completion and a variety of direct factorization methods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04290'>Quantum Distance Calculation for $\epsilon$-Graph Construction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Naomi Mona Chmielewski (EDF R&amp;D OSIRIS, L2S), Nina Amini (CNRS, L2S), Paulin Jacquot (EDF R&amp;D OSIRIS), Joseph Mikael (EDF R&amp;D OSIRIS)</p><p>In machine learning and particularly in topological data analysis,
$\epsilon$-graphs are important tools but are generally hard to compute as the
distance calculation between n points takes time O(n^2) classically. Recently,
quantum approaches for calculating distances between n quantum states have been
proposed, taking advantage of quantum superposition and entanglement. We
investigate the potential for quantum advantage in the case of quantum distance
calculation for computing $\epsilon$-graphs. We show that, relying on existing
quantum multi-state SWAP test based algorithms, the query complexity for
correctly identifying (with a given probability) that two points are not
$\epsilon$-neighbours is at least O(n^3 / ln n), showing that this approach, if
used directly for $\epsilon$-graph construction, does not bring a computational
advantage when compared to a classical approach.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chmielewski_N/0/1/0/all/0/1">Naomi Mona Chmielewski</a> (EDF R&amp;D OSIRIS, L2S), <a href="http://arxiv.org/find/cs/1/au:+Amini_N/0/1/0/all/0/1">Nina Amini</a> (CNRS, L2S), <a href="http://arxiv.org/find/cs/1/au:+Jacquot_P/0/1/0/all/0/1">Paulin Jacquot</a> (EDF R&amp;D OSIRIS), <a href="http://arxiv.org/find/cs/1/au:+Mikael_J/0/1/0/all/0/1">Joseph Mikael</a> (EDF R&amp;D OSIRIS)</p><p>In machine learning and particularly in topological data analysis,
$\epsilon$-graphs are important tools but are generally hard to compute as the
distance calculation between n points takes time O(n^2) classically. Recently,
quantum approaches for calculating distances between n quantum states have been
proposed, taking advantage of quantum superposition and entanglement. We
investigate the potential for quantum advantage in the case of quantum distance
calculation for computing $\epsilon$-graphs. We show that, relying on existing
quantum multi-state SWAP test based algorithms, the query complexity for
correctly identifying (with a given probability) that two points are not
$\epsilon$-neighbours is at least O(n^3 / ln n), showing that this approach, if
used directly for $\epsilon$-graph construction, does not bring a computational
advantage when compared to a classical approach.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04342'>Matroid-Constrained Vertex Cover</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chien-Chung Huang, Fran&#xe7;ois Sellier</p><p>In this paper, we introduce the problem of Matroid-Constrained Vertex Cover:
given a graph with weights on the edges and a matroid imposed on the vertices,
our problem is to choose a subset of vertices that is independent in the
matroid, with the objective of maximizing the total weight of covered edges.
This problem is a generalization of the much studied max $k$-vertex cover
problem, in which the matroid is the simple uniform matroid, and it is also a
special case of the problem of maximizing a monotone submodular function under
a matroid constraint.
</p>
<p>First, we give a Fixed-Parameter Tractable Approximation Scheme (FPT-AS) when
the given matroid is a partition matroid, a laminar matroid, or a transversal
matroid. Precisely, if $k$ is the rank of the matroid, we obtain $(1 -
\varepsilon)$ approximation using $(1/\varepsilon)^{O(k)}n^{O(1)}$ time for
partition and laminar matroids and using $(1/\varepsilon+k)^{O(k)}n^{O(1)}$
time for transversal matroids. This extends a result of Manurangsi for uniform
matroids [Manurangsi, 2018]. We also show that these ideas can be applied in
the context of (single-pass) streaming algorithms. Besides, our FPT-AS
introduces a new technique based on matroid union, which may be of independent
interest in extremal combinatorics.
</p>
<p>In the second part, we consider general matroids. We propose a simple local
search algorithm that guarantees $2/3 \approx 0.66$ approximation. For the more
general problem where two matroids are imposed on the vertices and a feasible
solution must be a common independent set, we show that a local search
algorithm gives a $2/3 \cdot (1 - 1/(p+1))$ approximation in $n^{O(p)}$ time,
for any integer $p$. We also provide some evidence to show that with the
constraint of one or two matroids, the approximation ratio of $2/3$ is likely
the best possible, using the currently known techniques of local search.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chien-Chung Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sellier_F/0/1/0/all/0/1">Fran&#xe7;ois Sellier</a></p><p>In this paper, we introduce the problem of Matroid-Constrained Vertex Cover:
given a graph with weights on the edges and a matroid imposed on the vertices,
our problem is to choose a subset of vertices that is independent in the
matroid, with the objective of maximizing the total weight of covered edges.
This problem is a generalization of the much studied max $k$-vertex cover
problem, in which the matroid is the simple uniform matroid, and it is also a
special case of the problem of maximizing a monotone submodular function under
a matroid constraint.
</p>
<p>First, we give a Fixed-Parameter Tractable Approximation Scheme (FPT-AS) when
the given matroid is a partition matroid, a laminar matroid, or a transversal
matroid. Precisely, if $k$ is the rank of the matroid, we obtain $(1 -
\varepsilon)$ approximation using $(1/\varepsilon)^{O(k)}n^{O(1)}$ time for
partition and laminar matroids and using $(1/\varepsilon+k)^{O(k)}n^{O(1)}$
time for transversal matroids. This extends a result of Manurangsi for uniform
matroids [Manurangsi, 2018]. We also show that these ideas can be applied in
the context of (single-pass) streaming algorithms. Besides, our FPT-AS
introduces a new technique based on matroid union, which may be of independent
interest in extremal combinatorics.
</p>
<p>In the second part, we consider general matroids. We propose a simple local
search algorithm that guarantees $2/3 \approx 0.66$ approximation. For the more
general problem where two matroids are imposed on the vertices and a feasible
solution must be a common independent set, we show that a local search
algorithm gives a $2/3 \cdot (1 - 1/(p+1))$ approximation in $n^{O(p)}$ time,
for any integer $p$. We also provide some evidence to show that with the
constraint of one or two matroids, the approximation ratio of $2/3$ is likely
the best possible, using the currently known techniques of local search.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04423'>On Computing Optimal Tree Ensembles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Christian Komusiewicz, Pascal Kunz, Frank Sommer, Manuel Sorge</p><p>Random forests and, more generally, (decision\nobreakdash-)tree ensembles are
widely used methods for classification and regression. Recent algorithmic
advances allow to compute decision trees that are optimal for various measures
such as their size or depth. We are not aware of such research for tree
ensembles and aim to contribute to this area. Mainly, we provide two novel
algorithms and corresponding lower bounds. First, we are able to carry over and
substantially improve on tractability results for decision trees, obtaining a
$(6\delta D S)^S \cdot poly$-time algorithm, where $S$ is the number of cuts in
the tree ensemble, $D$ the largest domain size, and $\delta$ is the largest
number of features in which two examples differ. To achieve this, we introduce
the witness-tree technique which also seems promising for practice. Second, we
show that dynamic programming, which has been successful for decision trees,
may also be viable for tree ensembles, providing an $\ell^n \cdot poly$-time
algorithm, where $\ell$ is the number of trees and $n$ the number of examples.
Finally, we compare the number of cuts necessary to classify training data sets
for decision trees and tree ensembles, showing that ensembles may need
exponentially fewer cuts for increasing number of trees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Komusiewicz_C/0/1/0/all/0/1">Christian Komusiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunz_P/0/1/0/all/0/1">Pascal Kunz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sommer_F/0/1/0/all/0/1">Frank Sommer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorge_M/0/1/0/all/0/1">Manuel Sorge</a></p><p>Random forests and, more generally, (decision\nobreakdash-)tree ensembles are
widely used methods for classification and regression. Recent algorithmic
advances allow to compute decision trees that are optimal for various measures
such as their size or depth. We are not aware of such research for tree
ensembles and aim to contribute to this area. Mainly, we provide two novel
algorithms and corresponding lower bounds. First, we are able to carry over and
substantially improve on tractability results for decision trees, obtaining a
$(6\delta D S)^S \cdot poly$-time algorithm, where $S$ is the number of cuts in
the tree ensemble, $D$ the largest domain size, and $\delta$ is the largest
number of features in which two examples differ. To achieve this, we introduce
the witness-tree technique which also seems promising for practice. Second, we
show that dynamic programming, which has been successful for decision trees,
may also be viable for tree ensembles, providing an $\ell^n \cdot poly$-time
algorithm, where $\ell$ is the number of trees and $n$ the number of examples.
Finally, we compare the number of cuts necessary to classify training data sets
for decision trees and tree ensembles, showing that ensembles may need
exponentially fewer cuts for increasing number of trees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.04470'>Maintaining the cycle structure of dynamic permutations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zsuzsanna Lipt&#xe1;k, Francesco Masillo, Gonzalo Navarro</p><p>We present a new data structure for maintaining dynamic permutations, which
we call a $\textit{forest of splay trees (FST)}$. The FST allows one to
efficiently maintain the cycle structure of a permutation $\pi$ when the
allowed updates are transpositions. The structure stores one conceptual splay
tree for each cycle of $\pi$, using the position within the cycle as the key.
Updating $\pi$ to $\tau\cdot\pi$, for a transposition $\tau$, takes
$\mathcal{O}(\log n)$ amortized time, where $n$ is the size of $\pi$. The FST
computes any $\pi(i)$, $\pi^{-1}(i)$, $\pi^k(i)$ and $\pi^{-k}(i)$, in
$\mathcal{O}(\log n)$ amortized time. Further, it supports cycle-specific
queries such as determining whether two elements belong to the same cycle, flip
a segment of a cycle, and others, again within $\mathcal{O}(\log n)$ amortized
time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liptak_Z/0/1/0/all/0/1">Zsuzsanna Lipt&#xe1;k</a>, <a href="http://arxiv.org/find/cs/1/au:+Masillo_F/0/1/0/all/0/1">Francesco Masillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Navarro_G/0/1/0/all/0/1">Gonzalo Navarro</a></p><p>We present a new data structure for maintaining dynamic permutations, which
we call a $\textit{forest of splay trees (FST)}$. The FST allows one to
efficiently maintain the cycle structure of a permutation $\pi$ when the
allowed updates are transpositions. The structure stores one conceptual splay
tree for each cycle of $\pi$, using the position within the cycle as the key.
Updating $\pi$ to $\tau\cdot\pi$, for a transposition $\tau$, takes
$\mathcal{O}(\log n)$ amortized time, where $n$ is the size of $\pi$. The FST
computes any $\pi(i)$, $\pi^{-1}(i)$, $\pi^k(i)$ and $\pi^{-k}(i)$, in
$\mathcal{O}(\log n)$ amortized time. Further, it supports cycle-specific
queries such as determining whether two elements belong to the same cycle, flip
a segment of a cycle, and others, again within $\mathcal{O}(\log n)$ amortized
time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-08T00:30:00Z">Thursday, June 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, June 07
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.03135'>On the complexity of isomorphism problems for tensors, groups, and polynomials III: actions by classical groups</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhili Chen, Joshua A. Grochow, Youming Qiao, Gang Tang, Chuanqi Zhang</p><p>We study the complexity of isomorphism problems for d-way arrays, or tensors,
under natural actions by classical groups such as orthogonal, unitary, and
symplectic groups. Such problems arise naturally in statistical data analysis
and quantum information. We study two types of complexity-theoretic questions.
First, for a fixed action type (isomorphism, conjugacy, etc.), we relate the
complexity of the isomorphism problem over a classical group to that over the
general linear group. Second, for a fixed group type (orthogonal, unitary, or
symplectic), we compare the complexity of the decision problems for different
actions.
</p>
<p>Our main results are as follows. First, for orthogonal and symplectic groups
acting on 3-way arrays, the isomorphism problems reduce to the corresponding
problem over the general linear group. Second, for orthogonal and unitary
groups, the isomorphism problems of five natural actions on 3-way arrays are
polynomial-time equivalent, and the d-tensor isomorphism problem reduces to the
3-tensor isomorphism problem for any fixed d&gt;3. For unitary groups, the
preceding result implies that LOCC classification of tripartite quantum states
is at least as difficult as LOCC classification of d-partite quantum states for
any d. Lastly, we also show that the graph isomorphism problem reduces to the
tensor isomorphism problem over orthogonal and unitary groups.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhili Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Grochow_J/0/1/0/all/0/1">Joshua A. Grochow</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Youming Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_G/0/1/0/all/0/1">Gang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chuanqi Zhang</a></p><p>We study the complexity of isomorphism problems for d-way arrays, or tensors,
under natural actions by classical groups such as orthogonal, unitary, and
symplectic groups. Such problems arise naturally in statistical data analysis
and quantum information. We study two types of complexity-theoretic questions.
First, for a fixed action type (isomorphism, conjugacy, etc.), we relate the
complexity of the isomorphism problem over a classical group to that over the
general linear group. Second, for a fixed group type (orthogonal, unitary, or
symplectic), we compare the complexity of the decision problems for different
actions.
</p>
<p>Our main results are as follows. First, for orthogonal and symplectic groups
acting on 3-way arrays, the isomorphism problems reduce to the corresponding
problem over the general linear group. Second, for orthogonal and unitary
groups, the isomorphism problems of five natural actions on 3-way arrays are
polynomial-time equivalent, and the d-tensor isomorphism problem reduces to the
3-tensor isomorphism problem for any fixed d&gt;3. For unitary groups, the
preceding result implies that LOCC classification of tripartite quantum states
is at least as difficult as LOCC classification of d-partite quantum states for
any d. Lastly, we also show that the graph isomorphism problem reduces to the
tensor isomorphism problem over orthogonal and unitary groups.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-07T00:30:00Z">Wednesday, June 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2306.03161'>On the Role of Entanglement and Statistics in Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Srinivasan Arunachalam, Vojtech Havlicek, Louis Schatzki</p><p>In this work we make progress in understanding the relationship between
learning models with access to entangled, separable and statistical
measurements in the quantum statistical query (QSQ) model. To this end, we show
the following results.
</p>
<p>$\textbf{Entangled versus separable measurements.}$ The goal here is to learn
an unknown $f$ from the concept class $C\subseteq \{f:\{0,1\}^n\rightarrow
[k]\}$ given copies of $\frac{1}{\sqrt{2^n}}\sum_x \vert x,f(x)\rangle$. We
show that, if $T$ copies suffice to learn $f$ using entangled measurements,
then $O(nT^2)$ copies suffice to learn $f$ using just separable measurements.
</p>
<p>$\textbf{Entangled versus statistical measurements}$ The goal here is to
learn a function $f \in C$ given access to separable measurements and
statistical measurements. We exhibit a class $C$ that gives an exponential
separation between QSQ learning and quantum learning with entangled
measurements (even in the presence of noise). This proves the "quantum
analogue" of the seminal result of Blum et al. [BKW'03]. that separates
classical SQ and PAC learning with classification noise.
</p>
<p>$\textbf{QSQ lower bounds for learning states.}$ We introduce a quantum
statistical query dimension (QSD), which we use to give lower bounds on the QSQ
learning. With this we prove superpolynomial QSQ lower bounds for testing
purity, shadow tomography, Abelian hidden subgroup problem, degree-$2$
functions, planted bi-clique states and output states of Clifford circuits of
depth $\textsf{polylog}(n)$.
</p>
<p>$\textbf{Further applications.}$ We give and $\textit{unconditional}$
separation between weak and strong error mitigation and prove lower bounds for
learning distributions in the QSQ model. Prior works by Quek et al. [QFK+'22],
Hinsche et al. [HIN+'22], and Nietner et al. [NIS+'23] proved the analogous
results $\textit{assuming}$ diagonal measurements and our work removes this
assumption.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Arunachalam_S/0/1/0/all/0/1">Srinivasan Arunachalam</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Havlicek_V/0/1/0/all/0/1">Vojtech Havlicek</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Schatzki_L/0/1/0/all/0/1">Louis Schatzki</a></p><p>In this work we make progress in understanding the relationship between
learning models with access to entangled, separable and statistical
measurements in the quantum statistical query (QSQ) model. To this end, we show
the following results.
</p>
<p>$\textbf{Entangled versus separable measurements.}$ The goal here is to learn
an unknown $f$ from the concept class $C\subseteq \{f:\{0,1\}^n\rightarrow
[k]\}$ given copies of $\frac{1}{\sqrt{2^n}}\sum_x \vert x,f(x)\rangle$. We
show that, if $T$ copies suffice to learn $f$ using entangled measurements,
then $O(nT^2)$ copies suffice to learn $f$ using just separable measurements.
</p>
<p>$\textbf{Entangled versus statistical measurements}$ The goal here is to
learn a function $f \in C$ given access to separable measurements and
statistical measurements. We exhibit a class $C$ that gives an exponential
separation between QSQ learning and quantum learning with entangled
measurements (even in the presence of noise). This proves the "quantum
analogue" of the seminal result of Blum et al. [BKW'03]. that separates
classical SQ and PAC learning with classification noise.
</p>
<p>$\textbf{QSQ lower bounds for learning states.}$ We introduce a quantum
statistical query dimension (QSD), which we use to give lower bounds on the QSQ
learning. With this we prove superpolynomial QSQ lower bounds for testing
purity, shadow tomography, Abelian hidden subgroup problem, degree-$2$
functions, planted bi-clique states and output states of Clifford circuits of
depth $\textsf{polylog}(n)$.
</p>
<p>$\textbf{Further applications.}$ We give and $\textit{unconditional}$
separation between weak and strong error mitigation and prove lower bounds for
learning distributions in the QSQ model. Prior works by Quek et al. [QFK+'22],
Hinsche et al. [HIN+'22], and Nietner et al. [NIS+'23] proved the analogous
results $\textit{assuming}$ diagonal measurements and our work removes this
assumption.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-06-07T00:30:00Z">Wednesday, June 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
