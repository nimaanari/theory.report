<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-05-02T23:30:41Z">Tuesday, May 02 2023, 23:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, May 02
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/05/02/isbell-accepts/'>Isbell Accepts</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Charles Isbell was my colleague at Georgia Tech for a long time. He has some news, which I am glad to convey in the words of the UW Madison Chancellor, Jennifer Mnookin: I am delighted to share the terrific news that Dr. Charles Lee Isbell Jr., the John P. Imlay Jr. Dean of the College [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Charles Isbell was my colleague at Georgia Tech for a long time.  He has some news, which I am glad to convey in the words of the UW Madison Chancellor, Jennifer Mnookin:</p>
<blockquote><p>
I am delighted to share the terrific news that Dr. Charles Lee Isbell Jr., the John P. Imlay Jr. Dean of the College of Computing at Georgia Institute of Technology, has accepted my offer to become our next provost at the University of Wisconsin&#8212;Madison. He will begin his work with us on August 1.
</p></blockquote>
<p><a href="https://rjlipton.wpcomstaging.com/2023/05/02/isbell-accepts/isbellmnookin/" rel="attachment wp-att-21584"><img data-attachment-id="21584" data-permalink="https://rjlipton.wpcomstaging.com/2023/05/02/isbell-accepts/isbellmnookin/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?fit=451%2C298&amp;ssl=1" data-orig-size="451,298" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IsbellMnookin" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?fit=300%2C198&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?fit=451%2C298&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?resize=451%2C298&#038;ssl=1" alt="" width="451" height="298" class="aligncenter size-full wp-image-21584" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?w=451&amp;ssl=1 451w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/IsbellMnookin.png?resize=300%2C198&amp;ssl=1 300w" sizes="(max-width: 451px) 100vw, 451px" data-recalc-dims="1" /></a></p>
<p>Isbell will be the next provost:</p>
<blockquote><p>
A <a href="https://en.wikipedia.org/wiki/Provost_(education)">provost</a> is a senior academic administrator. At many institutions of higher education, they are the chief academic officer, a role that may be combined with being deputy to the chief executive officer. They may also be the chief executive officer of a university, of a branch campus of a university, or of a college within a university.
</p></blockquote>
<p>See <a href="https://news.wisc.edu/charles-lee-isbell-jr-named-uw-madison-provost">this</a> for more details about the hiring of Isbell.</p>
<header>
<h2>Chart</h2>
</header>
<p>Here is the level under Chancellor of the <a href="https://www.wisc.edu/pdfs/UW-Madison-Leadership-Org-Chart.pdf">org chart for UW Madison</a>, with Charles&#8217;s place in italics:</p>
<p><em>Provost and Vice Chancellor for Academic Affairs </em><br />
Vice Chancellor for Finance and Administration<br />
Vice Chancellor for Legal Affairs<br />
Vice Chancellor for Research and Graduate Education<br />
Vice Chancellor for Student Affairs<br />
Vice Chancellor for University Relations<br />
Chief Diversity Officer and Deputy Vice Chancellor for Diversity and Inclusion<br />
Vice Chancellor for Medical Affairs and Dean, School of Medicine and Public Health</p>
<header>
<h2>Open Problems</h2>
</header>
<p>Congrads Charles&#8212;wonderful you are going to Madison. That is a wonderful place&#8212;I spent many happy days being a visitor there over the years. He is following UW-Madison Provost John Scholz who was named as the new <a href="https://ls.wisc.edu/about/scholz">president</a> of the University of Oregon in Eugene, Oregon.</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T22:10:14Z">Tuesday, May 02 2023, 22:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/05/02/mathematics-of-the-impossible-chapter-10-constant-depth-circuits/'>Mathematics of the impossible, Chapter 10, Constant-depth circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this chapter we further investigate circuits of constant depth, focusing on two pervasive classes, which indeed we have already encountered under different names. Note on notation: I here use “AC” for AltCkt a.k.a.&#160;alternating circuits. I also use AC for the class of functions computable by an AC of depth and size . 10.1 Threshold [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In this chapter we further investigate circuits of constant depth, focusing on two pervasive classes, which indeed we have already encountered under different names.</p>
<p style="text-align:justify">   Note on notation: I here use “AC” for AltCkt a.k.a.&nbsp;alternating circuits. I also use AC for the class of functions <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> computable by an AC of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{d}" class="latex" />.</p>
<h3 class="sectionHead"><span class="titlemark">10.1   </span> <a id="x1-10700010.1"></a>Threshold circuits</h3>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107001r1"></a> <b>Definition</b> 10.1.  </span>A <em>threshold circuit, </em>abbreviated TC, is a circuit made of Majority gates (of unbounded fan-in). We also denote by TC the class of functions <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> computable by a TC of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{d}" class="latex" /> for some constant <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">TCs are one of the frontiers of our knowledge. It isn’t known how to prove impossibility results even for TCs of depth <img src="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3" class="latex" /> and size, say, <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107002r1"></a> <b>Exercise</b> 10.1.  </span>Prove that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BAC%7D%5Csubseteq+%5Ctext+%7BTC%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BAC%7D%5Csubseteq+%5Ctext+%7BTC%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BAC%7D%5Csubseteq+%5Ctext+%7BTC%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {AC}&#92;subseteq &#92;text {TC}&#92;subseteq &#92;text {NC}^{1}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107003r2"></a> <b>Exercise</b> 10.2.  </span>A function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D+%5E%7B%2A%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;} ^{*}&#92;to &#92;{0,1&#92;} " class="latex" /> is <em>symmetric</em> if it only depends on the weight of the input. Prove that any symmetric function is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TC}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The result <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BPH%7D%5Ctext+%7B%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BP%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BPH%7D%5Ctext+%7B%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BP%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BPH%7D%5Ctext+%7B%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BMaj%7D%5Ccdot+%5Ctext+%7BP%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {PH}&#92;text {&#92;ensuremath {&#92;subseteq &#92;text {Maj}&#92;cdot &#92;text {Maj}&#92;cdot &#92;text {P}}}" class="latex" /> obtained in <a href="#x1-79001r13">6.13<!--tex4ht:ref: xca:power-of-majority --></a> in particular yields the following.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107004r1"></a>                                                                                                                                                                                     <b>Theorem</b> 10.1.  </span><span class="cite">[<a href="#XAll89">5</a>]</span>Any function <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> in AC has TCs of depth <img src="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%5Clog+%5E%7Bc_%7Bf%7D%7Dn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B%5Clog+%5E%7Bc_%7Bf%7D%7Dn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B%5Clog+%5E%7Bc_%7Bf%7D%7Dn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{&#92;log ^{c_{f}}n}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107005r2"></a> <b>Theorem</b> 10.2.  </span> The following problems are in TC:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-107007x1">Addition of two input integers.</li>
<li class="enumerate" id="x1-107009x2">Iterated addition: Addition of any number of input integers.</li>
<li class="enumerate" id="x1-107011x3">Multiplication of two input integers.</li>
<li class="enumerate" id="x1-107013x4">Iterated multiplication: Multiplication of any number of input integers.</li>
<li class="enumerate" id="x1-107015x5">Division of two integers.</li>
</ol>
<p style="text-align:justify">The proof follows closely that for NC<img src="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^{1}" class="latex" /> in section&nbsp;�<a href="#x1-1020009.1">9.1<!--tex4ht:ref: sec:The-power-of-NC1-arithmetic --></a> (which in turn was based on that for L). Only iterated addition requires a new idea.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-107016r3"></a> <b>Exercise</b> 10.3.  </span>Prove the claim about iterated addition. (Hint: Write input as <img src="https://s0.wp.com/latex.php?latex=n%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;times n" class="latex" /> matrix, one number per row. Divide columns into blocks of <img src="https://s0.wp.com/latex.php?latex=t%3Dc%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%3Dc%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%3Dc%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t=c&#92;log n" class="latex" />.)</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">10.2   </span> <a id="x1-10800010.2"></a>TC vs.&nbsp;NC<img src="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^{1}" class="latex" /></h3>
<p style="text-align:justify">Another great question is whether <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%3D%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%3D%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%3D%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TC}=&#92;text {NC}^{1}." class="latex" /> For any <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />, we can show that functions in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{1}" class="latex" />, such as Parity, require depth-<img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> TCs of size <img src="https://s0.wp.com/latex.php?latex=%5Cge+n%5E%7B1%2Bc%5Clog+d%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+n%5E%7B1%2Bc%5Clog+d%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+n%5E%7B1%2Bc%5Clog+d%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge n^{1+c&#92;log d}" class="latex" />, and this is tight up to constants.<span class="cite">[<a href="#XImpagliazzoPS97">34</a>]</span> A natural question is whether we can prove stronger bounds for harder functions in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{1}" class="latex" />. A natural candidate is iterated multiplication of 3&#215;3 matrices. The following result shows that, in fact, stronger bounds would already prove “the whole thing,” that is, <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%5Cne+%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%5Cne+%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTC%7D%5Cne+%5Ctext+%7BNC%7D%5E%7B1%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {TC}&#92;ne &#92;text {NC}^{1}." class="latex" /></p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-108001r3"></a> <b>Theorem</b> 10.3.  </span><span class="cite">[<a href="#XAllenderK10">7</a>,&nbsp;<a href="conf/stoc/ChenT19">17</a>]</span> Let <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> be the set of 3&#215;3 matrices of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{2}" class="latex" />. Suppose that the product of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> elements in <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> can be computed by TCs of size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{k}" class="latex" /> and depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />. Then for any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon " class="latex" /> the product can also be computed by TCs of size <img src="https://s0.wp.com/latex.php?latex=d%27n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%27n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%27n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#039;n^{1+&#92;epsilon }" class="latex" /> and depth <img src="https://s0.wp.com/latex.php?latex=d%27%3A%3Dcdk%5Clog+1%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%27%3A%3Dcdk%5Clog+1%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%27%3A%3Dcdk%5Clog+1%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#039;:=cdk&#92;log 1/&#92;epsilon " class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The same result applies to any constant-size group <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> – we state it for matrices for concreteness.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Exploiting the associativity of the problem, we compute the product recursively according to a regular tree. The root is defined to have level <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" />. At Level <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> we compute <img src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{i}" class="latex" /> products of <img src="https://s0.wp.com/latex.php?latex=%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(n^{1+&#92;epsilon }/n_{i})^{1/k}" class="latex" /> matrices. At the root <img src="https://s0.wp.com/latex.php?latex=%28i%3D0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28i%3D0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28i%3D0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(i=0)" class="latex" /> we have <img src="https://s0.wp.com/latex.php?latex=n_%7B0%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7B0%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7B0%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{0}=1" class="latex" />.</p>
<p style="text-align:justify">   By the assumption, each product at Level <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> has TCs of size <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1+&#92;epsilon }/n_{i}" class="latex" /> and depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />. Hence Level <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> can be computed by TCs of size <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1+&#92;epsilon }" class="latex" /> and depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />.</p>
<p style="text-align:justify">   We have the recursion</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+n_%7Bi%2B1%7D%3Dn_%7Bi%7D%5Ccdot+%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+n_%7Bi%2B1%7D%3Dn_%7Bi%7D%5Ccdot+%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+n_%7Bi%2B1%7D%3Dn_%7Bi%7D%5Ccdot+%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} n_{i+1}=n_{i}&#92;cdot (n^{1+&#92;epsilon }/n_{i})^{1/k}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   The solution to this recursion is <img src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%281-1%2Fk%29%5E%7Bi%7D%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%281-1%2Fk%29%5E%7Bi%7D%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%281-1%2Fk%29%5E%7Bi%7D%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{i}=n^{(1+&#92;epsilon )(1-(1-1/k)^{i})}" class="latex" />, see below.</p>
<p style="text-align:justify">   For <img src="https://s0.wp.com/latex.php?latex=i%3Dck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3Dck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3Dck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i=ck&#92;log (1/&#92;epsilon )" class="latex" /> we have <img src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%5E%7B2%7D%29%7D%3En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%5E%7B2%7D%29%7D%3En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%5E%7B2%7D%29%7D%3En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{i}=n^{(1+&#92;epsilon )(1-&#92;epsilon ^{2})}&gt;n" class="latex" />; this means that we can compute a product of <img src="https://s0.wp.com/latex.php?latex=%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge n" class="latex" /> matrices, as required.</p>
<p style="text-align:justify">   Hence the total depth of the circuit is <img src="https://s0.wp.com/latex.php?latex=d%5Ccdot+ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%5Ccdot+ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%5Ccdot+ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#92;cdot ck&#92;log (1/&#92;epsilon )" class="latex" />, and the total size is the depth times <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{1+&#92;epsilon }" class="latex" />.</p>
<p style="text-align:justify">   It remains to solve the recurrence. Letting <img src="https://s0.wp.com/latex.php?latex=a_%7Bi%7D%3A%3D%5Clog+_%7Bn%7Dn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a_%7Bi%7D%3A%3D%5Clog+_%7Bn%7Dn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a_%7Bi%7D%3A%3D%5Clog+_%7Bn%7Dn_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a_{i}:=&#92;log _{n}n_{i}" class="latex" /> we have the following recurrence for the exponents of <img src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n_{i}" class="latex" />.</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B0%7D+%26+%3D0%5C%5C+a_%7Bi%2B1%7D+%26+%3Da_%7Bi%7D%281-1%2Fk%29%2B%281%2B%5Cepsilon+%29%2Fk%3Da_%7Bi%7D%5Calpha+%2B%5Cgamma+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B0%7D+%26+%3D0%5C%5C+a_%7Bi%2B1%7D+%26+%3Da_%7Bi%7D%281-1%2Fk%29%2B%281%2B%5Cepsilon+%29%2Fk%3Da_%7Bi%7D%5Calpha+%2B%5Cgamma+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B0%7D+%26+%3D0%5C%5C+a_%7Bi%2B1%7D+%26+%3Da_%7Bi%7D%281-1%2Fk%29%2B%281%2B%5Cepsilon+%29%2Fk%3Da_%7Bi%7D%5Calpha+%2B%5Cgamma+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} a_{0} &amp; =0&#92;&#92; a_{i+1} &amp; =a_{i}(1-1/k)+(1+&#92;epsilon )/k=a_{i}&#92;alpha +&#92;gamma &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   where <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3A%3D%281-1%2Fk%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Calpha+%3A%3D%281-1%2Fk%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Calpha+%3A%3D%281-1%2Fk%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;alpha :=(1-1/k)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3A%3D%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+%3A%3D%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+%3A%3D%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma :=(1+&#92;epsilon )/k" class="latex" />.</p>
<p style="text-align:justify">   This gives</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7Bi%7D%3D%5Cgamma+%5Csum+_%7Bj%5Cle+i%7D%5Calpha+%7B%7D%5E%7Bj%7D%3D%5Cgamma+%5Cfrac+%7B1-%5Calpha+%5E%7Bi%2B1%7D%7D%7B1-%5Calpha+%7D%3D%281%2B%5Cepsilon+%29%281-%5Calpha+%5E%7Bi%2B1%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7Bi%7D%3D%5Cgamma+%5Csum+_%7Bj%5Cle+i%7D%5Calpha+%7B%7D%5E%7Bj%7D%3D%5Cgamma+%5Cfrac+%7B1-%5Calpha+%5E%7Bi%2B1%7D%7D%7B1-%5Calpha+%7D%3D%281%2B%5Cepsilon+%29%281-%5Calpha+%5E%7Bi%2B1%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7Bi%7D%3D%5Cgamma+%5Csum+_%7Bj%5Cle+i%7D%5Calpha+%7B%7D%5E%7Bj%7D%3D%5Cgamma+%5Cfrac+%7B1-%5Calpha+%5E%7Bi%2B1%7D%7D%7B1-%5Calpha+%7D%3D%281%2B%5Cepsilon+%29%281-%5Calpha+%5E%7Bi%2B1%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} a_{i}=&#92;gamma &#92;sum _{j&#92;le i}&#92;alpha {}^{j}=&#92;gamma &#92;frac {1-&#92;alpha ^{i+1}}{1-&#92;alpha }=(1+&#92;epsilon )(1-&#92;alpha ^{i+1}). &#92;end{aligned}" class="latex" /></div>
<p><b>QED</b></p>
</div>
<p style="text-align:justify">   Were the recursion of the form <img src="https://s0.wp.com/latex.php?latex=a%27_%7Bi%2B1%7D%3Da%27_%7Bi%7D%2B%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%27_%7Bi%2B1%7D%3Da%27_%7Bi%7D%2B%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%27_%7Bi%2B1%7D%3Da%27_%7Bi%7D%2B%281%2B%5Cepsilon+%29%2Fk&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#039;_{i+1}=a&#039;_{i}+(1+&#92;epsilon )/k" class="latex" /> then obviously <img src="https://s0.wp.com/latex.php?latex=a%27_%7Bck%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%27_%7Bck%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%27_%7Bck%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#039;_{ck}" class="latex" /> would already be <img src="https://s0.wp.com/latex.php?latex=%5Cge+1%2B%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+1%2B%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+1%2B%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 1+&#92;epsilon " class="latex" />. Instead for <img src="https://s0.wp.com/latex.php?latex=a_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a_{i}" class="latex" /> we need to get to <img src="https://s0.wp.com/latex.php?latex=ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=ck%5Clog+%281%2F%5Cepsilon+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="ck&#92;log (1/&#92;epsilon )" class="latex" />.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">10.3   </span> <a id="x1-10900010.3"></a>Impossibility results for AC</h3>
<p style="text-align:justify">In this section we prove impossibility results for ACs, matching several settings of parameters mentioned earlier (cf.&nbsp;section&nbsp;�<a href="#x1-910007.3">7.3<!--tex4ht:ref: sec:Checkpoints --></a>).</p>
<p style="text-align:justify">   To set the stage, let’s prove strong results for depth 2, that is, DNFs.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109001r4"></a> <b>Exercise</b> 10.4.  </span>Prove that Majority requires DNFs of size <img src="https://s0.wp.com/latex.php?latex=%5Cge+2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 2^{cn}" class="latex" />. Hint: What if you have a term with less than <img src="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n " class="latex" /> variables?</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   As discussed, <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bcn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{cn}" class="latex" /> bounds even for depth 3 ACs are unknown, and would imply major separations. The following is close to the state-of-the-art for depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109002r4"></a> <b>Theorem</b> 10.4.  </span><span class="cite">[<a href="#XRaz87">52</a>,&nbsp;<a href="#XSmo87">63</a>]</span>  Let C be an AC of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> computing Majority on <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits. Then <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%5Cge+c%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%5Cge+c%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%5Cge+c%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log ^{d}s&#92;ge c&#92;sqrt {n}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Recall from section&nbsp;�<a href="#x1-910007.3">7.3<!--tex4ht:ref: sec:Checkpoints --></a> that a stronger bound for an explicit function would have major consequences; in particular the function cannot be in L.</p>
<p style="text-align:justify">   The proof uses the simulation of circuits by low-degree polynomials which we saw in Theorem <a href="#x1-77004r5">6.5<!--tex4ht:ref: thm:AC0-Razborov-approx --></a>. Specifically, we use the following corollary:</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109003r1"></a> <b>Corollary</b> 10.1.  </span>Let <img src="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> be an alternating circuit of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" />. Then there is a polynomial <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{2}" class="latex" /> of degree <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bd%7Ds%2F%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log ^{d}s/&#92;epsilon " class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BP%7D_%7Bx%7D%5BC%28x%29%5Cne+p%28x%29%5D%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BP%7D_%7Bx%7D%5BC%28x%29%5Cne+p%28x%29%5D%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BP%7D_%7Bx%7D%5BC%28x%29%5Cne+p%28x%29%5D%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {P}_{x}[C(x)&#92;ne p(x)]&#92;le &#92;epsilon " class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Theorem <a href="#x1-77004r5">6.5<!--tex4ht:ref: thm:AC0-Razborov-approx --></a> gave a distribution <img src="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="P" class="latex" /> on polynomials s.t.&nbsp;for every <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> we have</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{P}[C(x)&#92;ne P(x)]&#92;le &#92;epsilon . &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   Averaging over <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> we also have</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bx%2CP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bx%2CP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7Bx%2CP%7D%5BC%28x%29%5Cne+P%28x%29%5D%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{x,P}[C(x)&#92;ne P(x)]&#92;le &#92;epsilon . &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   Hence we can fix a particular polynomial <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> s.t.&nbsp;the probability over <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+%5Cepsilon+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le &#92;epsilon " class="latex" />, yielding the result. <b>QED</b></p>
</div>
<p style="text-align:justify">   We then show that Majority cannot be approximated by such low-degree polynomials.</p>
<p style="text-align:justify">   The key result is the following:</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109004r1"></a> <b>Lemma</b> 10.1.  </span>Every function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^n &#92;to &#92;{0,1&#92;}" class="latex" /> can be written as <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+%5Ctext+%7BMaj%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+%5Ctext+%7BMaj%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+%5Ctext+%7BMaj%7D%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=p_{0}(x)+p_{1}(x)&#92;cdot &#92;text {Maj}(x)" class="latex" />, for some polynomials <img src="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_{0}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=p_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_{1}" class="latex" /> of degree <img src="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n/2" class="latex" />. This holds for every odd <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Let <img src="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{0}" class="latex" /> be the set of strings with weight <img src="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n/2" class="latex" />. We claim that for every function <img src="https://s0.wp.com/latex.php?latex=f%3AM_%7B0%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AM_%7B0%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AM_%7B0%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:M_{0}&#92;to &#92;{0,1&#92;} " class="latex" /> there is a polynomial <img src="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_{0}" class="latex" /> of degree <img src="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n/2" class="latex" /> s.t.&nbsp;<img src="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_{0}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> agree on <img src="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{0}" class="latex" />.</p>
<p style="text-align:justify">   To verify this, consider the monomials of degree <img src="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n/2" class="latex" />. We claim that (the vectors corresponding to) their truth tables over <img src="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{0}" class="latex" /> are linearly independent. This means that any polynomial gives a different function over <img src="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{0}" class="latex" />, and because the number of polynomials is the same as the number of functions, the result follows. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109005r5"></a> <b>Exercise</b> 10.5.  </span>Prove the claim in the proof.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-109002r4">10.4<!--tex4ht:ref: thm:-Majority-not-in-acz --></a></b>.&nbsp;</span> Apply Corollary <a href="#x1-109003r1">10.1<!--tex4ht:ref: cor:Raz-approx-fixed-p --></a> with <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2F10&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2F10&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2F10&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon =1/10" class="latex" /> to obtain <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />. Let <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> be the set of inputs on which <img src="https://s0.wp.com/latex.php?latex=p%28x%29%3DC%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28x%29%3DC%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28x%29%3DC%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(x)=C(x)" class="latex" />. By Lemma <a href="#x1-109004r1">10.1<!--tex4ht:ref: lem:Maj-versatile --></a>, any function <img src="https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:S&#92;to &#92;{0,1&#92;} " class="latex" /> ca be written as</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+p%28x%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+p%28x%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%28x%29%3Dp_%7B0%7D%28x%29%2Bp_%7B1%7D%28x%29%5Ccdot+p%28x%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} f(x)=p_{0}(x)+p_{1}(x)&#92;cdot p(x). &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   The right-hand size is a polynomial of degree <img src="https://s0.wp.com/latex.php?latex=%5Cle+d%27%3A%3Dn%2F2%2B%5Clog+%5E%7Bd%7D%28cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+d%27%3A%3Dn%2F2%2B%5Clog+%5E%7Bd%7D%28cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+d%27%3A%3Dn%2F2%2B%5Clog+%5E%7Bd%7D%28cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le d&#039;:=n/2+&#92;log ^{d}(cs)" class="latex" />. The number of such polynomials is the number of possible choices for each monomial of degree <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> up to the degree. This number is</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cprod+_%7Bi%3D0%7D%5E%7Bd%27%7D2%5E%7B%7Bn+%5Cchoose+i%7D%7D%3D2%5E%7B%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cprod+_%7Bi%3D0%7D%5E%7Bd%27%7D2%5E%7B%7Bn+%5Cchoose+i%7D%7D%3D2%5E%7B%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cprod+_%7Bi%3D0%7D%5E%7Bd%27%7D2%5E%7B%7Bn+%5Cchoose+i%7D%7D%3D2%5E%7B%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;prod _{i=0}^{d&#039;}2^{{n &#92;choose i}}=2^{&#92;sum _{i}^{d&#039;}{n &#92;choose i}}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   On the other hand, the number of possible functions <img src="https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AS%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:S&#92;to &#92;{0,1&#92;} " class="latex" /> is</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+2%5E%7B%7CS%7C%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+2%5E%7B%7CS%7C%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+2%5E%7B%7CS%7C%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} 2^{|S|}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   Since a polynomial computes at most one function, taking logs we have</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7CS%7C%5Cle+%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7CS%7C%5Cle+%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7CS%7C%5Cle+%5Csum+_%7Bi%7D%5E%7Bd%27%7D%7Bn+%5Cchoose+i%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} |S|&#92;le &#92;sum _{i}^{d&#039;}{n &#92;choose i}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   The right-hand side is at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{n}(1/2+c&#92;log ^{d}(s)/&#92;sqrt {n})" class="latex" />, since each binomial coefficient is <img src="https://s0.wp.com/latex.php?latex=%5Cle+c2%5E%7Bn%7D%2F%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c2%5E%7Bn%7D%2F%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c2%5E%7Bn%7D%2F%5Csqrt+%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c2^{n}/&#92;sqrt {n}" class="latex" />.</p>
<p style="text-align:justify">   On the other hand, <img src="https://s0.wp.com/latex.php?latex=%7CS%7C%5Cge+0.9%5Ccdot+2%5E%7Bn%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CS%7C%5Cge+0.9%5Ccdot+2%5E%7Bn%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CS%7C%5Cge+0.9%5Ccdot+2%5E%7Bn%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|S|&#92;ge 0.9&#92;cdot 2^{n}." class="latex" /></p>
<p style="text-align:justify">   Combining this we get</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.9%5Ccdot+2%5E%7Bn%7D%5Cle+2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.9%5Ccdot+2%5E%7Bn%7D%5Cle+2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.9%5Ccdot+2%5E%7Bn%7D%5Cle+2%5E%7Bn%7D%281%2F2%2Bc%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} 0.9&#92;cdot 2^{n}&#92;le 2^{n}(1/2+c&#92;log ^{d}(s)/&#92;sqrt {n}). &#92;end{aligned}" class="latex" /></div>
<p>This implies</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.4%5Cle+c%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.4%5Cle+c%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+0.4%5Cle+c%5Clog+%5E%7Bd%7D%28s%29%2F%5Csqrt+%7Bn%7D%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} 0.4&#92;le c&#92;log ^{d}(s)/&#92;sqrt {n}, &#92;end{aligned}" class="latex" /></div>
<p>proving the theorem. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-109006r6"></a> <b>Exercise</b> 10.6.  </span>Explain why Theorem <a href="#x1-109002r4">10.4<!--tex4ht:ref: thm:-Majority-not-in-acz --></a> holds even if the circuits have Parity gates (in addition to Or and And gates).</p>
<p style="text-align:justify">
</div>
<div class="thebibliography">
<p class="bibitem"><span class="biblabel">   [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness      results for LCS and other sequence similarity measures.  In Venkatesan Guruswami,      editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS      2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59–78. IEEE Computer Society,      2015.</p>
<p class="bibitem"><span class="biblabel">   [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard  Adleman.   Two  theorems  on  random  polynomial  time.   In  19th IEEE      Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75–83. 1978.</p>
<p class="bibitem"><span class="biblabel">   [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjt83"></a>Mikl�s Ajtai.  <img src="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Sigma &#92;sp {1}&#92;sb {1}" class="latex" />-formulae on finite structures.  Annals of Pure and Applied Logic,      24(1):1–48, 1983.</p>
<p class="bibitem"><span class="biblabel">   [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjtai05"></a>Mikl�s Ajtai. A non-linear time lower bound for boolean branching programs. Theory      of Computing, 1(1):149–176, 2005.</p>
<p class="bibitem"><span class="biblabel">   [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAll89"></a>Eric  Allender.   A  note  on  the  power  of  threshold  circuits.   In  30th Symposium      on Foundations of Computer Science, pages 580–584, Research Triangle Park, North      Carolina, 30 October–1 November 1989. IEEE.</p>
<p class="bibitem"><span class="biblabel">   [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllender01"></a>Eric Allender. The division breakthroughs. Bulletin of the EATCS, 74:61–77, 2001.</p>
<p class="bibitem"><span class="biblabel">   [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllenderK10"></a>Eric  Allender  and  Michal  Koucký.     Amplifying  lower  bounds  by  means  of      self-reducibility. J.&nbsp;of the ACM, 57(3), 2010.</p>
<p class="bibitem"><span class="biblabel">   [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAGHP92"></a>Noga Alon, Oded Goldreich, Johan H�stad, and Ren� Peralta. Simple constructions      of  almost  <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-wise  independent  random  variables.   Random  Structures  &amp;  Algorithms,      3(3):289–304, 1992.</p>
<p class="bibitem"><span class="biblabel">   [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian      circuits and matchings. J. Comput. Syst. Sci., 18(2):155–193, 1979.</p>
<p class="bibitem"><span class="biblabel">  [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.      Proof  verification  and  the  hardness  of  approximation  problems.    J.&nbsp;of  the  ACM,      45(3):501–555, May 1998.</p>
<p class="bibitem"><span class="biblabel">  [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk.  Edit distance cannot be computed in strongly      subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087–1097, 2018.</p>
<p class="bibitem"><span class="biblabel">  [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBatcher68"></a>Kenneth&nbsp;E. Batcher.  Sorting networks and their applications.  In AFIPS Spring      Joint Computing Conference, volume&nbsp;32, pages 307–314, 1968.</p>
<p class="bibitem"><span class="biblabel">  [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBeameCH86"></a>Paul  Beame,  Stephen&nbsp;A.  Cook,  and  H.&nbsp;James  Hoover.   Log  depth  circuits  for      division and related problems. SIAM J. Comput., 15(4):994–1003, 1986.</p>
<p class="bibitem"><span class="biblabel">  [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBSSV03"></a>Paul Beame, Michael Saks, Xiaodong Sun, and Erik Vee.   Time-space trade-off      lower  bounds  for  randomized  computation  of  decision  problems.   J.&nbsp;of  the  ACM,      50(2):154–195, 2003.</p>
<p class="bibitem"><span class="biblabel">  [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBen-OrC92"></a>Michael Ben-Or and Richard Cleve. Computing algebraic formulas using a constant      number of registers. SIAM J.&nbsp;on Computing, 21(1):54–58, 1992.</p>
<p class="bibitem"><span class="biblabel">  [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/cc/BussW15"></a>Samuel&nbsp;R.  Buss  and  Ryan  Williams.   Limits  on  alternation  trading  proofs  for      time-space lower bounds. Comput. Complex., 24(3):533–600, 2015.</p>
<p class="bibitem"><span class="biblabel">  [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/stoc/ChenT19"></a>Lijie Chen and Roei Tell. Bootstrapping results for threshold circuits &#8220;just beyond&#8221;      known lower bounds.  In Moses Charikar and Edith Cohen, editors, Proceedings of the      51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix,      AZ, USA, June 23-26, 2019, pages 34–41. ACM, 2019.</p>
<p class="bibitem"><span class="biblabel">  [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCleve91"></a>Richard  Cleve.    Towards  optimal  simulations  of  formulas  by  bounded-width                                                                                                                                                                                          programs. Computational Complexity, 1:91–105, 1991.</p>
<p class="bibitem"><span class="biblabel">  [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCook73"></a>Stephen&nbsp;A. Cook. A hierarchy for nondeterministic time complexity. J.&nbsp;of Computer      and System Sciences, 7(4):343–353, 1973.</p>
<p class="bibitem"><span class="biblabel">  [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Csanky76"></a>L.&nbsp;Csanky.     Fast  parallel  matrix  inversion  algorithms.     SIAM  J.  Comput.,      5(4):618–623, 1976.</p>
<p class="bibitem"><span class="biblabel">  [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/Fortnow00"></a>Lance  Fortnow.   Time-space  tradeoffs  for  satisfiability.   J.  Comput.  Syst.  Sci.,      60(2):337–353, 2000.</p>
<p class="bibitem"><span class="biblabel">  [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jct/FraenkelL81"></a>Aviezri&nbsp;S. Fraenkel and David Lichtenstein. Computing a perfect strategy for n x n      chess requires time exponential in n. J. Comb. Theory, Ser. A, 31(2):199–214, 1981.</p>
<p class="bibitem"><span class="biblabel">  [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XFredmanS89"></a>Michael&nbsp;L. Fredman and Michael&nbsp;E. Saks.  The cell probe complexity of dynamic      data structures. In ACM Symp.&nbsp;on the Theory of Computing (STOC), pages 345–354,      1989.</p>
<p class="bibitem"><span class="biblabel">  [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational      geometry. Comput. Geom., 5:165–185, 1995.</p>
<p class="bibitem"><span class="biblabel">  [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the      Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel">  [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;G�del.   �ber  formal  unentscheidbare  s�tze  der  Principia  Mathematica  und      verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel">  [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge      University Press, 2008.</p>
<p class="bibitem"><span class="biblabel">  [28]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGreenlawHR-Limits"></a>Raymond  Greenlaw,  H.&nbsp;James  Hoover,  and  Walter  Ruzzo.   Limits  to  Parallel      Computation: P-Completeness Theory. 02 2001.</p>
<p class="bibitem"><span class="biblabel">  [29]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of      Mathematics, 193(2):563 – 617, 2021.</p>
<p class="bibitem"><span class="biblabel">  [30]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie.  One-tape, off-line turing machine computations.  Information and      Control, 8(6):553–578, 1965.</p>
<p class="bibitem"><span class="biblabel">  [31]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred  Hennie  and  Richard  Stearns.    Two-tape  simulation  of  multitape  turing      machines. J.&nbsp;of the ACM, 13:533–546, October 1966.</p>
<p class="bibitem"><span class="biblabel">  [32]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jacm/HopcroftPV77"></a>John&nbsp;E. Hopcroft, Wolfgang&nbsp;J. Paul, and Leslie&nbsp;G. Valiant. On time versus space.      J. ACM, 24(2):332–337, 1977.</p>
<p class="bibitem"><span class="biblabel">  [33]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi.   The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 237–, 1999.</p>
<p class="bibitem"><span class="biblabel">  [34]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImpagliazzoPS97"></a>Russell Impagliazzo, Ramamohan Paturi, and Michael&nbsp;E. Saks. Size-depth tradeoffs      for threshold circuits. SIAM J. Comput., 26(3):693–707, 1997.</p>
<p class="bibitem"><span class="biblabel">  [35]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.  Which problems have      strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512–530, Dec      2001.</p>
<p class="bibitem"><span class="biblabel">  [36]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell  Impagliazzo  and  Avi  Wigderson.    <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" />  if  <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" />  requires  exponential  circuits:      Derandomizing the XOR lemma.  In 29th ACM Symp.&nbsp;on the Theory of Computing      (STOC), pages 220–229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel">  [37]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKarpLi82"></a>Richard&nbsp;M.  Karp  and  Richard&nbsp;J.  Lipton.    Turing  machines  that  take  advice.      L’Enseignement Math�matique. Revue Internationale. IIe S�rie, 28(3-4):191–209, 1982.</p>
<p class="bibitem"><span class="biblabel">  [38]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi.  On the structure of one-tape nondeterministic turing machine      time hierarchy. Theor. Comput. Sci., 40:175–193, 1985.</p>
<p class="bibitem"><span class="biblabel">  [39]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/LarsenWY20"></a>Kasper&nbsp;Green Larsen, Omri Weinstein, and Huacheng Yu. Crossing the logarithmic      barrier for dynamic boolean data structure lower bounds.  SIAM J. Comput., 49(5),      2020.</p>
<p class="bibitem"><span class="biblabel">  [40]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A.  Levin.    Universal  sequential  search  problems.    Problemy  Peredachi      Informatsii, 9(3):115–116, 1973.</p>
<p class="bibitem"><span class="biblabel">  [41]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLundFoKaNi92"></a>Carsten Lund, Lance Fortnow, Howard Karloff, and Noam Nisan. Algebraic methods      for interactive proof systems. J.&nbsp;of the ACM, 39(4):859–868, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [42]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120–140, 1958.</p>
<p class="bibitem"><span class="biblabel">  [43]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMaS87"></a>Wolfgang Maass and Amir Schorr. Speed-up of Turing machines with one work tape      and a two-way input tape. SIAM J.&nbsp;on Computing, 16(1):195–202, 1987.</p>
<p class="bibitem"><span class="biblabel">  [44]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBarrington89"></a>David&nbsp;A.  Mix  Barrington.   Bounded-width  polynomial-size  branching  programs      recognize  exactly  those  languages  in  NC<img src="https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^1" class="latex" />.    J.&nbsp;of  Computer  and  System  Sciences,      38(1):150–164, 1989.</p>
<p class="bibitem"><span class="biblabel">  [45]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNaN93"></a>Joseph Naor and Moni Naor.  Small-bias probability spaces: efficient constructions      and applications. SIAM J.&nbsp;on Computing, 22(4):838–856, 1993.</p>
<p class="bibitem"><span class="biblabel">  [46]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNechiporuk66"></a>E.&nbsp;I. Nechiporuk. A boolean function. Soviet Mathematics-Doklady, 169(4):765–766,      1966.</p>
<p class="bibitem"><span class="biblabel">  [47]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNep70"></a>Valery&nbsp;A. Nepomnjaščiĭ. Rudimentary predicates and Turing calculations. Soviet      Mathematics-Doklady, 11(6):1462–1465, 1970.</p>
<p class="bibitem"><span class="biblabel">  [48]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaNEU-ram2sat-neu-author"></a>NEU. From RAM to SAT. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2012.</p>
<p class="bibitem"><span class="biblabel">                                                                                                                                                                                      [49]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation,      and complexity classes. J. Comput. Syst. Sci., 43(3):425–440, 1991.</p>
<p class="bibitem"><span class="biblabel">  [50]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPPST83"></a>Wolfgang&nbsp;J. Paul, Nicholas Pippenger, Endre Szemer�di, and William&nbsp;T. Trotter.      On determinism versus non-determinism and related problems (preliminary version). In      IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 429–438, 1983.</p>
<p class="bibitem"><span class="biblabel">  [51]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures.      J.&nbsp;of the ACM, 26(2):361–381, 1979.</p>
<p class="bibitem"><span class="biblabel">  [52]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XRaz87"></a>Alexander Razborov. Lower bounds on the dimension of schemes of bounded depth      in a complete basis containing the logical addition function.  Akademiya Nauk SSSR.      Matematicheskie Zametki, 41(4):598–607, 1987.  English translation in Mathematical      Notes of the Academy of Sci. of the USSR, 41(4):333-338, 1987.</p>
<p class="bibitem"><span class="biblabel">  [53]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XReingold08"></a>Omer Reingold. Undirected connectivity in log-space. J.&nbsp;of the ACM, 55(4), 2008.</p>
<p class="bibitem"><span class="biblabel">  [54]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Robson84"></a>J.&nbsp;M.  Robson.    N  by  N  checkers  is  exptime  complete.    SIAM  J.  Comput.,      13(2):252–267, 1984.</p>
<p class="bibitem"><span class="biblabel">  [55]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/coco/Santhanam01"></a>Rahul Santhanam.   On separators, segregators and time versus space.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 286–294, 2001.</p>
<p class="bibitem"><span class="biblabel">  [56]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSAVITCH1970177"></a>Walter&nbsp;J. Savitch.  Relationships between nondeterministic and deterministic tape      complexities. Journal of Computer and System Sciences, 4(2):177–192, 1970.</p>
<p class="bibitem"><span class="biblabel">  [57]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold Sch�nhage. Storage modification machines. SIAM J. Comput., 9(3):490–508,      1980.</p>
<p class="bibitem"><span class="biblabel">  [58]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XShamir92"></a>Adi Shamir. IP = PSPACE. J.&nbsp;of the ACM, 39(4):869–877, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [59]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System                                                                                                                                                                                          Tech. J., 28:59–98, 1949.</p>
<p class="bibitem"><span class="biblabel">  [60]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields.      Mathematics of Computation, 54(189):435–447, 1990.</p>
<p class="bibitem"><span class="biblabel">  [61]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSiegel04"></a>Alan Siegel. On universal classes of extremely random constant-time hash functions.      SIAM J.&nbsp;on Computing, 33(3):505–543, 2004.</p>
<p class="bibitem"><span class="biblabel">  [62]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSip83b"></a>Michael Sipser. A complexity theoretic approach to randomness. In ACM Symp.&nbsp;on      the Theory of Computing (STOC), pages 330–335, 1983.</p>
<p class="bibitem"><span class="biblabel">  [63]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSmo87"></a>Roman Smolensky.  Algebraic methods in the theory of lower bounds for Boolean      circuit complexity.  In 19th ACM Symp.&nbsp;on the Theory of Computing (STOC), pages      77–82. ACM, 1987.</p>
<p class="bibitem"><span class="biblabel">  [64]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer.  Cosmological lower bound on the circuit      complexity of a small problem in logic. J. ACM, 49(6):753–784, 2002.</p>
<p class="bibitem"><span class="biblabel">  [65]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XToda91"></a>Seinosuke Toda.   PP is as hard as the polynomial-time hierarchy.   SIAM J.&nbsp;on      Computing, 20(5):865–877, 1991.</p>
<p class="bibitem"><span class="biblabel">  [66]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M.   Turing.      On   computable   numbers,   with   an   application   to   the      entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230–265, 1937.</p>
<p class="bibitem"><span class="biblabel">  [67]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XVal77"></a>Leslie&nbsp;G.  Valiant.   Graph-theoretic  arguments  in  low-level  complexity.   In  6th      Symposium on Mathematical Foundations of Computer Science, volume&nbsp;53 of Lecture      Notes in Computer Science, pages 162–176. Springer, 1977.</p>
<p class="bibitem"><span class="biblabel">  [68]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/ValiantV86"></a>Leslie&nbsp;G. Valiant and Vijay&nbsp;V. Vazirani. NP is as easy as detecting unique solutions.      Theor. Comput. Sci., 47(3):85–93, 1986.</p>
<p class="bibitem"><span class="biblabel">  [69]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMelkebeek06"></a>Dieter  van  Melkebeek.   A  survey  of  lower  bounds  for  satisfiability  and  related                                                                                                                                                                                          problems. Foundations and Trends in Theoretical Computer Science, 2(3):197–303, 2006.</p>
<p class="bibitem"><span class="biblabel">  [70]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/MelkebeekR05"></a>Dieter van Melkebeek and Ran Raz.  A time lower bound for satisfiability.  Theor.      Comput. Sci., 348(2-3):311–320, 2005.</p>
<p class="bibitem"><span class="biblabel">  [71]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/Vinodchandran05"></a>N.&nbsp;V. Vinodchandran.  A note on the circuit complexity of PP.  Theor. Comput.      Sci., 347(1-2):415–418, 2005.</p>
<p class="bibitem"><span class="biblabel">  [72]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaBPvsE"></a>Emanuele Viola.  On approximate majority and probabilistic time.  Computational      Complexity, 18(3):337–375, 2009.</p>
<p class="bibitem"><span class="biblabel">  [73]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-FTTCS09"></a>Emanuele Viola. On the power of small-depth computation. Foundations and Trends      in Theoretical Computer Science, 5(1):1–72, 2009.</p>
<p class="bibitem"><span class="biblabel">  [74]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola.  Reducing 3XOR to listing triangles, an exposition.  Available at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel">  [75]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-datastructurelb-implies-cclb"></a>Emanuele Viola.  Lower bounds for data structures with space close to maximum      imply  circuit  lower  bounds.    Theory  of  Computing,  15:1–9,  2019.    Available  at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>.</p>
<p class="bibitem"><span class="biblabel">  [76]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele  Viola.   Pseudorandom  bits  and  lower  bounds  for  randomized  turing      machines. Theory of Computing, 18(10):1–12, 2022.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T21:37:15Z">Tuesday, May 02 2023, 21:37</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/05/02/four-assistant-associate-professor-positions-at-university-of-warwick-apply-by-may-15-2023/'>Four Assistant/Associate Professor Positions at University of Warwick (apply by May 15, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Department of Computer Science at the University of Warwick has 4 Assistant/Associate Professor positions available in Foundations of AI / Quantum Computing (broadly interpreted). Candidates with research experience in at least one of these areas are encouraged to apply. Website: warwick.ac.uk/fac/sci/dcs/jobs/ Email: igorcarb@gmail.com
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Department of Computer Science at the University of Warwick has 4 Assistant/Associate Professor positions available in Foundations of AI / Quantum Computing (broadly interpreted). Candidates with research experience in at least one of these areas are encouraged to apply.</p>
<p>Website: <a href="https://warwick.ac.uk/fac/sci/dcs/jobs/">https://warwick.ac.uk/fac/sci/dcs/jobs/</a><br />
Email: igorcarb@gmail.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T20:29:49Z">Tuesday, May 02 2023, 20:29</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/063'>TR23-063 |  Cutting Planes Width and the Complexity of Graph Isomorphism Refutations | 

	Jacobo Toran, 

	Florian Wörz</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The width complexity measure plays a central role in Resolution and other propositional proof systems like Polynomial Calculus (under the name of degree). The study of width lower bounds is the most extended method for proving size lower bounds, and it is known that for these systems, proofs with small width also imply the existence of proofs with small size. Not much has been studied, however, about the width parameter in the Cutting Planes (CP) proof system, a measure that was introduced by Dantchev and Martin in 2011 under the name of CP cutwidth.

In this paper, we study the width complexity of CP refutations of graph isomorphism formulas. For a pair of non-isomorphic graphs $G$ and $H$, we show a direct connection between the Weisfeiler--Leman differentiation number $\mathrm{WL}(G, H)$ of the graphs and the width of a CP refutation for the corresponding isomorphism formula $\mathrm{ISO}(G, H)$. In particular, we show that if $\mathrm{WL}(G, H) \leq k$, then there is a CP refutation of $\mathrm{ISO}(G, H)$ with width $k$, and if $\mathrm{WL}(G, H) &gt; k$, then there are no CP refutations of $\mathrm{ISO}(G, H)$ with width $k-2$. Similar results are known for other proof systems, like Resolution, Sherali–Adams, or Polynomial Calculus. We also obtain polynomial-size CP refutations from our width bound for isomorphism formulas for graphs with constant WL-dimension.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The width complexity measure plays a central role in Resolution and other propositional proof systems like Polynomial Calculus (under the name of degree). The study of width lower bounds is the most extended method for proving size lower bounds, and it is known that for these systems, proofs with small width also imply the existence of proofs with small size. Not much has been studied, however, about the width parameter in the Cutting Planes (CP) proof system, a measure that was introduced by Dantchev and Martin in 2011 under the name of CP cutwidth.

In this paper, we study the width complexity of CP refutations of graph isomorphism formulas. For a pair of non-isomorphic graphs $G$ and $H$, we show a direct connection between the Weisfeiler--Leman differentiation number $\mathrm{WL}(G, H)$ of the graphs and the width of a CP refutation for the corresponding isomorphism formula $\mathrm{ISO}(G, H)$. In particular, we show that if $\mathrm{WL}(G, H) \leq k$, then there is a CP refutation of $\mathrm{ISO}(G, H)$ with width $k$, and if $\mathrm{WL}(G, H) &gt; k$, then there are no CP refutations of $\mathrm{ISO}(G, H)$ with width $k-2$. Similar results are known for other proof systems, like Resolution, Sherali–Adams, or Polynomial Calculus. We also obtain polynomial-size CP refutations from our width bound for isomorphism formulas for graphs with constant WL-dimension.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T19:25:43Z">Tuesday, May 02 2023, 19:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/062'>TR23-062 |  Conflict Checkable and Decodable Codes and Their Applications | 

	Benny Applebaum, 

	Eliran Kachlon</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Let $C$ be an error-correcting code over a large alphabet $q$ of block length $n$, and assume that, a possibly corrupted, codeword $c$ is distributively stored among $n$ servers where the $i$th entry is being held by the $i$th server. Suppose that every pair of servers publicly announce whether the corresponding coordinates are ``consistent&#39;&#39; with some legal codeword or ``conflicted&#39;&#39;. What type of information about $c$ can be inferred from this consistency graph? Can we check whether errors occurred and if so, can we find the error locations and effectively decode? We initiate the study of conflict-checkable and conflict-decodable codes and prove the following main results:

(1) (Almost-MDS conflict-checkable codes:) For every distance $d\leq n$, there exists a code that supports conflict-based error-detection whose dimension $k$ almost achieves the singleton bound, i.e., $k\geq n-d+0.99$. Interestingly, the code is non-linear, and we give some evidence that suggests that this is inherent. Combinatorially, this yields an $n$-partite graph over $[q]^n$ that contains $q^k$ cliques of size $n$ whose pair-wise intersection is at most $n-d\leq k-0.99$ vertices, generalizing a construction of Alon (Random Struct. Algorithms, &#39;02) that achieves a similar result for the special case of triangles ($n=3$).   

(2) (Conflict Decodable Codes below half-distance:) For every distance $d\leq n$ there exists a linear code that supports conflict-based error-decoding up to half of the distance. The code&#39;s dimension $k$ ``half-meets&#39;&#39; the singleton bound, i.e., $k=(n-d+2)/2$, and we prove that this bound is tight for a natural class of such codes. The construction is based on symmetric bivariate polynomials and is rooted in the literature on verifiable secret sharing (Ben-Or, Goldwasser and Wigderson, STOC &#39;88; Cramer, Damg{\aa}rd, and Maurer, EUROCRYPT &#39;00). 

(3) (Robust Conflict Decodable Codes:) We show that the above construction also satisfies a non-trivial notion of robust decoding/detection even when the number of errors is unbounded and up to $d/2$ of the servers are Byzantine and may lie about their conflicts. The resulting conflict-decoder runs in exponential time in this case, and we present an alternative construction that achieves quasipolynomial complexity at the expense of degrading the dimension to $k=(n-d+3)/3$. Our construction is based on trilinear polynomials, and the algorithmic result follows by showing that the induced conflict graph is structured enough to allow efficient recovery of a maximal vertex cover.

As an application of the last result, we present the first polynomial-time statistical two-round Verifiable Secret Sharing (resp., three-round general MPC protocol) that remains secure in the presence of an active adversary that corrupts up to $t&lt;n/3.001$ of the parties. We can upgrade the resiliency threshold to $n/3$, which is known to be optimal in this setting, at the expense of increasing the computational complexity to be quasipolynomial. Previous solutions (Applebaum, Kachlon, and Patra, TCC&#39;20) suffered from an exponential-time complexity even when the adversary corrupts only $n/4$ of the parties.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Let $C$ be an error-correcting code over a large alphabet $q$ of block length $n$, and assume that, a possibly corrupted, codeword $c$ is distributively stored among $n$ servers where the $i$th entry is being held by the $i$th server. Suppose that every pair of servers publicly announce whether the corresponding coordinates are ``consistent&#39;&#39; with some legal codeword or ``conflicted&#39;&#39;. What type of information about $c$ can be inferred from this consistency graph? Can we check whether errors occurred and if so, can we find the error locations and effectively decode? We initiate the study of conflict-checkable and conflict-decodable codes and prove the following main results:

(1) (Almost-MDS conflict-checkable codes:) For every distance $d\leq n$, there exists a code that supports conflict-based error-detection whose dimension $k$ almost achieves the singleton bound, i.e., $k\geq n-d+0.99$. Interestingly, the code is non-linear, and we give some evidence that suggests that this is inherent. Combinatorially, this yields an $n$-partite graph over $[q]^n$ that contains $q^k$ cliques of size $n$ whose pair-wise intersection is at most $n-d\leq k-0.99$ vertices, generalizing a construction of Alon (Random Struct. Algorithms, &#39;02) that achieves a similar result for the special case of triangles ($n=3$).   

(2) (Conflict Decodable Codes below half-distance:) For every distance $d\leq n$ there exists a linear code that supports conflict-based error-decoding up to half of the distance. The code&#39;s dimension $k$ ``half-meets&#39;&#39; the singleton bound, i.e., $k=(n-d+2)/2$, and we prove that this bound is tight for a natural class of such codes. The construction is based on symmetric bivariate polynomials and is rooted in the literature on verifiable secret sharing (Ben-Or, Goldwasser and Wigderson, STOC &#39;88; Cramer, Damg{\aa}rd, and Maurer, EUROCRYPT &#39;00). 

(3) (Robust Conflict Decodable Codes:) We show that the above construction also satisfies a non-trivial notion of robust decoding/detection even when the number of errors is unbounded and up to $d/2$ of the servers are Byzantine and may lie about their conflicts. The resulting conflict-decoder runs in exponential time in this case, and we present an alternative construction that achieves quasipolynomial complexity at the expense of degrading the dimension to $k=(n-d+3)/3$. Our construction is based on trilinear polynomials, and the algorithmic result follows by showing that the induced conflict graph is structured enough to allow efficient recovery of a maximal vertex cover.

As an application of the last result, we present the first polynomial-time statistical two-round Verifiable Secret Sharing (resp., three-round general MPC protocol) that remains secure in the presence of an active adversary that corrupts up to $t&lt;n/3.001$ of the parties. We can upgrade the resiliency threshold to $n/3$, which is known to be optimal in this setting, at the expense of increasing the computational complexity to be quasipolynomial. Previous solutions (Applebaum, Kachlon, and Patra, TCC&#39;20) suffered from an exponential-time complexity even when the adversary corrupts only $n/4$ of the parties.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T18:18:54Z">Tuesday, May 02 2023, 18:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/061'>TR23-061 |  Dependency schemes in CDCL-based QBF solving: a proof-theoretic study | 

	Abhimanyu Choudhury, 

	Meena Mahajan</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We formalize the notion of proof systems obtained by adding normal dependency schemes into the QCDCL proof system underlying algorithms for solving Quantified Boolean Formulas, by exploring the addition of the dependency schemes via two approaches: one as a preprocessing tool, and second in propagation and learnings in the QCDCL trails. 

We show that QCDCL augmented with the reflexive resolution path dependency scheme D=D$^{rrs}$ produces three proof systems of interest: QCDCL(D), D+QCDCL and D+QCDCLD(D). We show that these three systems are not only pairwise incomparable, but also each system is incomparable with the standard QCDCL and QCDCL$^{cube}$, as well as with QCDCL$^{LO}_{NORED}$, QRes, QURes, and Q(D$^{rrs}$)Res.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We formalize the notion of proof systems obtained by adding normal dependency schemes into the QCDCL proof system underlying algorithms for solving Quantified Boolean Formulas, by exploring the addition of the dependency schemes via two approaches: one as a preprocessing tool, and second in propagation and learnings in the QCDCL trails. 

We show that QCDCL augmented with the reflexive resolution path dependency scheme D=D$^{rrs}$ produces three proof systems of interest: QCDCL(D), D+QCDCL and D+QCDCLD(D). We show that these three systems are not only pairwise incomparable, but also each system is incomparable with the standard QCDCL and QCDCL$^{cube}$, as well as with QCDCL$^{LO}_{NORED}$, QRes, QURes, and Q(D$^{rrs}$)Res.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T01:16:22Z">Tuesday, May 02 2023, 01:16</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00467'>The general position number and the iteration time in the P3 convexity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julio Araujo, Mitre C. Dourado, F&#xe1;bio Protti, Rudini Sampaio</p><p>In this paper, we investigate two graph convexity parameters: the iteration
time and the general position number. Harary and Nieminem introduced in 1981
the iteration time in the geodesic convexity, but its computational complexity
was still open. Manuel and Klav\v{z}ar introduced in 2018 the general position
number of the geodesic convexity and proved that it is NP-hard to compute. In
this paper, we extend these parameters to the P3 convexity and prove that it is
NP-hard to compute them. With this, we also prove that the iteration number is
NP-hard on the geodesic convexity even in graphs with diameter two. These
results are the last three missing NP-hardness results regarding the ten most
studied graph convexity parameters in the geodesic and P3 convexities.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Araujo_J/0/1/0/all/0/1">Julio Araujo</a>, <a href="http://arxiv.org/find/cs/1/au:+Dourado_M/0/1/0/all/0/1">Mitre C. Dourado</a>, <a href="http://arxiv.org/find/cs/1/au:+Protti_F/0/1/0/all/0/1">F&#xe1;bio Protti</a>, <a href="http://arxiv.org/find/cs/1/au:+Sampaio_R/0/1/0/all/0/1">Rudini Sampaio</a></p><p>In this paper, we investigate two graph convexity parameters: the iteration
time and the general position number. Harary and Nieminem introduced in 1981
the iteration time in the geodesic convexity, but its computational complexity
was still open. Manuel and Klav\v{z}ar introduced in 2018 the general position
number of the geodesic convexity and proved that it is NP-hard to compute. In
this paper, we extend these parameters to the P3 convexity and prove that it is
NP-hard to compute them. With this, we also prove that the iteration number is
NP-hard on the geodesic convexity even in graphs with diameter two. These
results are the last three missing NP-hardness results regarding the ten most
studied graph convexity parameters in the geodesic and P3 convexities.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00425'>Ortho-Radial Drawing in Near-Linear Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yi-Jun Chang</p><p>An orthogonal drawing is an embedding of a plane graph into a grid. In a
seminal work of Tamassia (SIAM Journal on Computing 1987), a simple
combinatorial characterization of angle assignments that can be realized as
bend-free orthogonal drawings was established, thereby allowing an orthogonal
drawing to be described combinatorially by listing the angles of all corners.
The characterization reduces the need to consider certain geometric aspects,
such as edge lengths and vertex coordinates, and simplifies the task of graph
drawing algorithm design.
</p>
<p>Barth, Niedermann, Rutter, and Wolf (SoCG 2017) established an analogous
combinatorial characterization for ortho-radial drawings, which are a
generalization of orthogonal drawings to cylindrical grids. The proof of the
characterization is existential and does not result in an efficient algorithm.
Niedermann, Rutter, and Wolf (SoCG 2019) later addressed this issue by
developing quadratic-time algorithms for both testing the realizability of a
given angle assignment as an ortho-radial drawing without bends and
constructing such a drawing.
</p>
<p>In this paper, we further improve the time complexity of these tasks to
near-linear time. We establish a new characterization for ortho-radial drawings
based on the concept of a good sequence. Using the new characterization, we
design a simple greedy algorithm for constructing ortho-radial drawings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yi-Jun Chang</a></p><p>An orthogonal drawing is an embedding of a plane graph into a grid. In a
seminal work of Tamassia (SIAM Journal on Computing 1987), a simple
combinatorial characterization of angle assignments that can be realized as
bend-free orthogonal drawings was established, thereby allowing an orthogonal
drawing to be described combinatorially by listing the angles of all corners.
The characterization reduces the need to consider certain geometric aspects,
such as edge lengths and vertex coordinates, and simplifies the task of graph
drawing algorithm design.
</p>
<p>Barth, Niedermann, Rutter, and Wolf (SoCG 2017) established an analogous
combinatorial characterization for ortho-radial drawings, which are a
generalization of orthogonal drawings to cylindrical grids. The proof of the
characterization is existential and does not result in an efficient algorithm.
Niedermann, Rutter, and Wolf (SoCG 2019) later addressed this issue by
developing quadratic-time algorithms for both testing the realizability of a
given angle assignment as an ortho-radial drawing without bends and
constructing such a drawing.
</p>
<p>In this paper, we further improve the time complexity of these tasks to
near-linear time. We establish a new characterization for ortho-radial drawings
based on the concept of a good sequence. Using the new characterization, we
design a simple greedy algorithm for constructing ortho-radial drawings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00033'>Finding agreement cherry-reduced subnetworks in level-1 networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kaari Landry, Olivier Tremblay-Savard, Manuel Lafond</p><p>Phylogenetic networks are increasingly being considered as better suited to
represent the complexity of the evolutionary relationships between species. One
class of phylogenetic networks that has received a lot of attention recently is
the class of orchard networks, which is composed of networks that can be
reduced to a single leaf using cherry reductions. Cherry reductions, also
called cherry-picking operations, remove either a leaf of a simple cherry
(sibling leaves sharing a parent) or a reticulate edge of a reticulate cherry
(two leaves whose parents are connected by a reticulate edge). In this paper,
we present a fixed-parameter tractable algorithm to solve the problem of
finding a maximum agreement cherry-reduced subnetwork (MACRS) between two
rooted binary level-1 networks. This is first exact algorithm proposed to solve
the MACRS problem. As proven in earlier work, there is a direct relationship
between finding an MACRS and calculating a distance based on cherry operations.
As a result, the proposed algorithm also provides a distance that can be used
for the comparison of level-1 networks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Landry_K/0/1/0/all/0/1">Kaari Landry</a>, <a href="http://arxiv.org/find/cs/1/au:+Tremblay_Savard_O/0/1/0/all/0/1">Olivier Tremblay-Savard</a>, <a href="http://arxiv.org/find/cs/1/au:+Lafond_M/0/1/0/all/0/1">Manuel Lafond</a></p><p>Phylogenetic networks are increasingly being considered as better suited to
represent the complexity of the evolutionary relationships between species. One
class of phylogenetic networks that has received a lot of attention recently is
the class of orchard networks, which is composed of networks that can be
reduced to a single leaf using cherry reductions. Cherry reductions, also
called cherry-picking operations, remove either a leaf of a simple cherry
(sibling leaves sharing a parent) or a reticulate edge of a reticulate cherry
(two leaves whose parents are connected by a reticulate edge). In this paper,
we present a fixed-parameter tractable algorithm to solve the problem of
finding a maximum agreement cherry-reduced subnetwork (MACRS) between two
rooted binary level-1 networks. This is first exact algorithm proposed to solve
the MACRS problem. As proven in earlier work, there is a direct relationship
between finding an MACRS and calculating a distance based on cherry operations.
As a result, the proposed algorithm also provides a distance that can be used
for the comparison of level-1 networks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00122'>Faster Submodular Maximization for Several Classes of Matroids</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Monika Henzinger, Paul Liu, Jan Vondrak, Da Wei Zheng</p><p>The maximization of submodular functions have found widespread application in
areas such as machine learning, combinatorial optimization, and economics,
where practitioners often wish to enforce various constraints; the matroid
constraint has been investigated extensively due to its algorithmic properties
and expressive power. Recent progress has focused on fast algorithms for
important classes of matroids given in explicit form. Currently, nearly-linear
time algorithms only exist for graphic and partition matroids [ICALP '19]. In
this work, we develop algorithms for monotone submodular maximization
constrained by graphic, transversal matroids, or laminar matroids in time
near-linear in the size of their representation. Our algorithms achieve an
optimal approximation of $1-1/e-\epsilon$ and both generalize and accelerate
the results of Ene and Nguyen [ICALP '19]. In fact, the running time of our
algorithm cannot be improved within the fast continuous greedy framework of
Badanidiyuru and Vondr\'ak [SODA '14].
</p>
<p>To achieve near-linear running time, we make use of dynamic data structures
that maintain bases with approximate maximum cardinality and weight under
certain element updates. These data structures need to support a weight
decrease operation and a novel FREEZE operation that allows the algorithm to
freeze elements (i.e. force to be contained) in its basis regardless of future
data structure operations.
</p>
<p>For the laminar matroid, we present a new dynamic data structure using the
top tree interface of Alstrup, Holm, de Lichtenberg, and Thorup [TALG '05] that
maintains the maximum weight basis under insertions and deletions of elements
in $O(\log n)$ time. For the transversal matroid the FREEZE operation
corresponds to requiring the data structure to keep a certain set $S$ of
vertices matched, a property that we call $S$-stability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Paul Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vondrak_J/0/1/0/all/0/1">Jan Vondrak</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1">Da Wei Zheng</a></p><p>The maximization of submodular functions have found widespread application in
areas such as machine learning, combinatorial optimization, and economics,
where practitioners often wish to enforce various constraints; the matroid
constraint has been investigated extensively due to its algorithmic properties
and expressive power. Recent progress has focused on fast algorithms for
important classes of matroids given in explicit form. Currently, nearly-linear
time algorithms only exist for graphic and partition matroids [ICALP '19]. In
this work, we develop algorithms for monotone submodular maximization
constrained by graphic, transversal matroids, or laminar matroids in time
near-linear in the size of their representation. Our algorithms achieve an
optimal approximation of $1-1/e-\epsilon$ and both generalize and accelerate
the results of Ene and Nguyen [ICALP '19]. In fact, the running time of our
algorithm cannot be improved within the fast continuous greedy framework of
Badanidiyuru and Vondr\'ak [SODA '14].
</p>
<p>To achieve near-linear running time, we make use of dynamic data structures
that maintain bases with approximate maximum cardinality and weight under
certain element updates. These data structures need to support a weight
decrease operation and a novel FREEZE operation that allows the algorithm to
freeze elements (i.e. force to be contained) in its basis regardless of future
data structure operations.
</p>
<p>For the laminar matroid, we present a new dynamic data structure using the
top tree interface of Alstrup, Holm, de Lichtenberg, and Thorup [TALG '05] that
maintains the maximum weight basis under insertions and deletions of elements
in $O(\log n)$ time. For the transversal matroid the FREEZE operation
corresponds to requiring the data structure to keep a certain set $S$ of
vertices matched, a property that we call $S$-stability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00175'>Clustering What Matters in Constrained Settings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ragesh Jaiswal, Amit Kumar</p><p>Constrained clustering problems generalize classical clustering formulations,
e.g., $k$-median, $k$-means, by imposing additional constraints on the
feasibility of clustering. There has been significant recent progress in
obtaining approximation algorithms for these problems, both in the metric and
the Euclidean settings. However, the outlier version of these problems, where
the solution is allowed to leave out $m$ points from the clustering, is not
well understood. In this work, we give a general framework for reducing the
outlier version of a constrained $k$-median or $k$-means problem to the
corresponding outlier-free version with only $(1+\varepsilon)$-loss in the
approximation ratio. The reduction is obtained by mapping the original instance
of the problem to $f(k,m, \varepsilon)$ instances of the outlier-free version,
where $f(k, m, \varepsilon) = \left( \frac{k+m}{\varepsilon}\right)^{O(m)}$. As
specific applications, we get the following results:
</p>
<p>- First FPT (in the parameters $k$ and $m$) $(1+\varepsilon)$-approximation
algorithm for the outlier version of capacitated $k$-median and $k$-means in
Euclidean spaces with hard capacities.
</p>
<p>- First FPT (in the parameters $k$ and $m$) $(3+\varepsilon)$ and
$(9+\varepsilon)$ approximation algorithms for the outlier version of
capacitated $k$-median and $k$-means, respectively, in general metric spaces
with hard capacities.
</p>
<p>- First FPT (in the parameters $k$ and $m$) $(2-\delta)$-approximation
algorithm for the outlier version of the $k$-median problem under the Ulam
metric. Our work generalizes the known results to a larger class of constrained
clustering problems. Further, our reduction works for arbitrary metric spaces
and so can extend clustering algorithms for outlier-free versions in both
Euclidean and arbitrary metric spaces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jaiswal_R/0/1/0/all/0/1">Ragesh Jaiswal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Amit Kumar</a></p><p>Constrained clustering problems generalize classical clustering formulations,
e.g., $k$-median, $k$-means, by imposing additional constraints on the
feasibility of clustering. There has been significant recent progress in
obtaining approximation algorithms for these problems, both in the metric and
the Euclidean settings. However, the outlier version of these problems, where
the solution is allowed to leave out $m$ points from the clustering, is not
well understood. In this work, we give a general framework for reducing the
outlier version of a constrained $k$-median or $k$-means problem to the
corresponding outlier-free version with only $(1+\varepsilon)$-loss in the
approximation ratio. The reduction is obtained by mapping the original instance
of the problem to $f(k,m, \varepsilon)$ instances of the outlier-free version,
where $f(k, m, \varepsilon) = \left( \frac{k+m}{\varepsilon}\right)^{O(m)}$. As
specific applications, we get the following results:
</p>
<p>- First FPT (in the parameters $k$ and $m$) $(1+\varepsilon)$-approximation
algorithm for the outlier version of capacitated $k$-median and $k$-means in
Euclidean spaces with hard capacities.
</p>
<p>- First FPT (in the parameters $k$ and $m$) $(3+\varepsilon)$ and
$(9+\varepsilon)$ approximation algorithms for the outlier version of
capacitated $k$-median and $k$-means, respectively, in general metric spaces
with hard capacities.
</p>
<p>- First FPT (in the parameters $k$ and $m$) $(2-\delta)$-approximation
algorithm for the outlier version of the $k$-median problem under the Ulam
metric. Our work generalizes the known results to a larger class of constrained
clustering problems. Further, our reduction works for arbitrary metric spaces
and so can extend clustering algorithms for outlier-free versions in both
Euclidean and arbitrary metric spaces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00186'>Uniqueness and Rapid Mixing in the Bipartite Hardcore Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaoyu Chen, Jingcheng Liu, Yitong Yin</p><p>We characterize the uniqueness condition in the hardcore model for bipartite
graphs with degree bounds only on one side, and provide a nearly linear time
sampling algorithm that works up to the uniqueness threshold. We show that the
uniqueness threshold for bipartite graph has almost the same form of the tree
uniqueness threshold for general graphs, except with degree bounds only on one
side of the bipartition. The hardcore model from statistical physics can be
seen as a weighted enumeration of independent sets. Its bipartite version
(#BIS) is a central open problem in approximate counting. Compared to the same
problem in a general graph, surprising tractable regime have been identified
that are believed to be hard in general. This is made possible by two lines of
algorithmic approach: the high-temperature algorithms starting from Liu and Lu
(STOC 2015), and the low-temperature algorithms starting from Helmuth, Perkins,
and Regts (STOC 2019).
</p>
<p>In this work, we study the limit of these algorithms in the high-temperature
case. Our characterization of the uniqueness condition is obtained by proving
decay of correlations for arguably the best possible regime, which involves
locating fixpoints of multivariate iterative rational maps and showing their
contraction. We also give a nearly linear time sampling algorithm based on
simulating field dynamics only on one side of the bipartite graph that works up
to the uniqueness threshold. Our algorithm is very different from the original
high-temperature algorithm of Liu and Lu, and it makes use of a connection
between correlation decay and spectral independence of Markov chains. Last but
not the least, we are able to show that the standard Glauber dynamics on both
side of the bipartite graph mixes in polynomial time up to the uniqueness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingcheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yitong Yin</a></p><p>We characterize the uniqueness condition in the hardcore model for bipartite
graphs with degree bounds only on one side, and provide a nearly linear time
sampling algorithm that works up to the uniqueness threshold. We show that the
uniqueness threshold for bipartite graph has almost the same form of the tree
uniqueness threshold for general graphs, except with degree bounds only on one
side of the bipartition. The hardcore model from statistical physics can be
seen as a weighted enumeration of independent sets. Its bipartite version
(#BIS) is a central open problem in approximate counting. Compared to the same
problem in a general graph, surprising tractable regime have been identified
that are believed to be hard in general. This is made possible by two lines of
algorithmic approach: the high-temperature algorithms starting from Liu and Lu
(STOC 2015), and the low-temperature algorithms starting from Helmuth, Perkins,
and Regts (STOC 2019).
</p>
<p>In this work, we study the limit of these algorithms in the high-temperature
case. Our characterization of the uniqueness condition is obtained by proving
decay of correlations for arguably the best possible regime, which involves
locating fixpoints of multivariate iterative rational maps and showing their
contraction. We also give a nearly linear time sampling algorithm based on
simulating field dynamics only on one side of the bipartite graph that works up
to the uniqueness threshold. Our algorithm is very different from the original
high-temperature algorithm of Liu and Lu, and it makes use of a connection
between correlation decay and spectral independence of Markov chains. Last but
not the least, we are able to show that the standard Glauber dynamics on both
side of the bipartite graph mixes in polynomial time up to the uniqueness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00308'>Improved Complexity Analysis of Quasi-Polynomial Algorithms Solving Parity Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pawe&#x142; Parys, Aleksander Wi&#x105;cek</p><p>We improve the complexity of solving parity games (with priorities in
vertices) for $d={\omega}(\log n)$ by a factor of ${\theta}(d^2)$: the best
complexity known to date was $O(mdn^{1.45+\log_2(d/\log_2(n))})$, while we
obtain $O(mn^{1.45+\log_2(d/\log_2(n))}/d)$, where $n$ is the number of
vertices, $m$ is the number of edges, and $d$ is the number of priorities.
</p>
<p>We base our work on existing algorithms using universal trees, and we improve
their complexity. We present two independent improvements. First, an
improvement by a factor of ${\theta}(d)$ comes from a more careful analysis of
the width of universal trees. Second, we perform (or rather recall) a finer
analysis of requirements for a universal tree: while for solving games with
priorities on edges one needs an $n$-universal tree, in the case of games with
priorities in vertices it is enough to use an $n/2$-universal tree. This way,
we allow to solve games of size $2n$ in the time needed previously to solve
games of size $n$; such a change divides the quasi-polynomial complexity again
by a factor of ${\theta}(d)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Parys_P/0/1/0/all/0/1">Pawe&#x142; Parys</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiacek_A/0/1/0/all/0/1">Aleksander Wi&#x105;cek</a></p><p>We improve the complexity of solving parity games (with priorities in
vertices) for $d={\omega}(\log n)$ by a factor of ${\theta}(d^2)$: the best
complexity known to date was $O(mdn^{1.45+\log_2(d/\log_2(n))})$, while we
obtain $O(mn^{1.45+\log_2(d/\log_2(n))}/d)$, where $n$ is the number of
vertices, $m$ is the number of edges, and $d$ is the number of priorities.
</p>
<p>We base our work on existing algorithms using universal trees, and we improve
their complexity. We present two independent improvements. First, an
improvement by a factor of ${\theta}(d)$ comes from a more careful analysis of
the width of universal trees. Second, we perform (or rather recall) a finer
analysis of requirements for a universal tree: while for solving games with
priorities on edges one needs an $n$-universal tree, in the case of games with
priorities in vertices it is enough to use an $n/2$-universal tree. This way,
we allow to solve games of size $2n$ in the time needed previously to solve
games of size $n$; such a change divides the quasi-polynomial complexity again
by a factor of ${\theta}(d)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00535'>Nearly Optimal Steiner Trees using Graph Neural Network Assisted Monte Carlo Tree Search</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Reyan Ahmed, Mithun Ghosh, Kwang-Sung Jun, Stephen Kobourov</p><p>Graph neural networks are useful for learning problems, as well as for
combinatorial and graph problems such as the Subgraph Isomorphism Problem and
the Traveling Salesman Problem. We describe an approach for computing Steiner
Trees by combining a graph neural network and Monte Carlo Tree Search. We first
train a graph neural network that takes as input a partial solution and
proposes a new node to be added as output. This neural network is then used in
a Monte Carlo search to compute a Steiner tree. The proposed method
consistently outperforms the standard 2-approximation algorithm on many
different types of graphs and often finds the optimal solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ahmed_R/0/1/0/all/0/1">Reyan Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_M/0/1/0/all/0/1">Mithun Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Jun_K/0/1/0/all/0/1">Kwang-Sung Jun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobourov_S/0/1/0/all/0/1">Stephen Kobourov</a></p><p>Graph neural networks are useful for learning problems, as well as for
combinatorial and graph problems such as the Subgraph Isomorphism Problem and
the Traveling Salesman Problem. We describe an approach for computing Steiner
Trees by combining a graph neural network and Monte Carlo Tree Search. We first
train a graph neural network that takes as input a partial solution and
proposes a new node to be added as output. This neural network is then used in
a Monte Carlo search to compute a Steiner tree. The proposed method
consistently outperforms the standard 2-approximation algorithm on many
different types of graphs and often finds the optimal solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00583'>The Art of the Fugue: Minimizing Interleaving in Collaborative Text Editing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthew Weidner, Joseph Gentle, Martin Kleppmann</p><p>Existing algorithms for replicated lists, which are widely used in
collaborative text editors, suffer from a problem: when two users concurrently
insert text at the same position in the document, the merged outcome may
interleave the inserted text passages, resulting in corrupted and potentially
unreadable text. The problem has gone unnoticed for decades, and it affects
both CRDTs and Operational Transformation. This paper presents Fugue, the first
algorithm that guarantees maximal non-interleaving, our new correctness
property for replicated lists. We present two variants of the Fugue algorithm,
one based on a tree and the other based on a list, and prove that they are
semantically equivalent. We also implement Fugue and demonstrate that it offers
performance comparable to state-of-the-art CRDT libraries for text editing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Weidner_M/0/1/0/all/0/1">Matthew Weidner</a>, <a href="http://arxiv.org/find/cs/1/au:+Gentle_J/0/1/0/all/0/1">Joseph Gentle</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleppmann_M/0/1/0/all/0/1">Martin Kleppmann</a></p><p>Existing algorithms for replicated lists, which are widely used in
collaborative text editors, suffer from a problem: when two users concurrently
insert text at the same position in the document, the merged outcome may
interleave the inserted text passages, resulting in corrupted and potentially
unreadable text. The problem has gone unnoticed for decades, and it affects
both CRDTs and Operational Transformation. This paper presents Fugue, the first
algorithm that guarantees maximal non-interleaving, our new correctness
property for replicated lists. We present two variants of the Fugue algorithm,
one based on a tree and the other based on a list, and prove that they are
semantically equivalent. We also implement Fugue and demonstrate that it offers
performance comparable to state-of-the-art CRDT libraries for text editing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00615'>Streaming $k$-edit approximate pattern matching via string decomposition</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sudatta Bhattacharya, Michal Kouck&#xfd;</p><p>In this paper we give an algorithm for streaming $k$-edit approximate pattern
matching which uses space $\widetilde{O}(k^2)$ and time $\widetilde{O}(k^2)$
per arriving symbol. This improves substantially on the recent algorithm of
Kociumaka, Porat and Starikovskaya (2022) which uses space $\widetilde{O}(k^5)$
and time $\widetilde{O}(k^8)$ per arriving symbol. In the $k$-edit approximate
pattern matching problem we get a pattern $P$ and text $T$ and we want to
identify all substrings of the text $T$ that are at edit distance at most $k$
from $P$. In the streaming version of this problem both the pattern and the
text arrive in a streaming fashion symbol by symbol and after each symbol of
the text we need to report whether there is a current suffix of the text with
edit distance at most $k$ from $P$. We measure the total space needed by the
algorithm and time needed per arriving symbol.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Sudatta Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Koucky_M/0/1/0/all/0/1">Michal Kouck&#xfd;</a></p><p>In this paper we give an algorithm for streaming $k$-edit approximate pattern
matching which uses space $\widetilde{O}(k^2)$ and time $\widetilde{O}(k^2)$
per arriving symbol. This improves substantially on the recent algorithm of
Kociumaka, Porat and Starikovskaya (2022) which uses space $\widetilde{O}(k^5)$
and time $\widetilde{O}(k^8)$ per arriving symbol. In the $k$-edit approximate
pattern matching problem we get a pattern $P$ and text $T$ and we want to
identify all substrings of the text $T$ that are at edit distance at most $k$
from $P$. In the streaming version of this problem both the pattern and the
text arrive in a streaming fashion symbol by symbol and after each symbol of
the text we need to report whether there is a current suffix of the text with
edit distance at most $k$ from $P$. We measure the total space needed by the
algorithm and time needed per arriving symbol.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00677'>Robustified Learning for Online Optimization with Memory Costs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pengfei Li, Jianyi Yang, Shaolei Ren</p><p>Online optimization with memory costs has many real-world applications, where
sequential actions are made without knowing the future input. Nonetheless, the
memory cost couples the actions over time, adding substantial challenges.
Conventionally, this problem has been approached by various expert-designed
online algorithms with the goal of achieving bounded worst-case competitive
ratios, but the resulting average performance is often unsatisfactory. On the
other hand, emerging machine learning (ML) based optimizers can improve the
average performance, but suffer from the lack of worst-case performance
robustness. In this paper, we propose a novel expert-robustified learning (ERL)
approach, achieving {both} good average performance and robustness. More
concretely, for robustness, ERL introduces a novel projection operator that
robustifies ML actions by utilizing an expert online algorithm; for average
performance, ERL trains the ML optimizer based on a recurrent architecture by
explicitly considering downstream expert robustification. We prove that, for
any $\lambda\geq1$, ERL can achieve $\lambda$-competitive against the expert
algorithm and $\lambda\cdot C$-competitive against the optimal offline
algorithm (where $C$ is the expert's competitive ratio). Additionally, we
extend our analysis to a novel setting of multi-step memory costs. Finally, our
analysis is supported by empirical experiments for an energy scheduling
application.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pengfei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Shaolei Ren</a></p><p>Online optimization with memory costs has many real-world applications, where
sequential actions are made without knowing the future input. Nonetheless, the
memory cost couples the actions over time, adding substantial challenges.
Conventionally, this problem has been approached by various expert-designed
online algorithms with the goal of achieving bounded worst-case competitive
ratios, but the resulting average performance is often unsatisfactory. On the
other hand, emerging machine learning (ML) based optimizers can improve the
average performance, but suffer from the lack of worst-case performance
robustness. In this paper, we propose a novel expert-robustified learning (ERL)
approach, achieving {both} good average performance and robustness. More
concretely, for robustness, ERL introduces a novel projection operator that
robustifies ML actions by utilizing an expert online algorithm; for average
performance, ERL trains the ML optimizer based on a recurrent architecture by
explicitly considering downstream expert robustification. We prove that, for
any $\lambda\geq1$, ERL can achieve $\lambda$-competitive against the expert
algorithm and $\lambda\cdot C$-competitive against the optimal offline
algorithm (where $C$ is the expert's competitive ratio). Additionally, we
extend our analysis to a novel setting of multi-step memory costs. Finally, our
analysis is supported by empirical experiments for an energy scheduling
application.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.00705'>Efficient dynamic model based testing using greedy test case selection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: P.H.M. van Spaendonck</p><p>Model-based testing (MBT) provides an automated approach for finding
discrepancies between software models and their implementation. If we want to
incorporate MBT into the fast and iterative software development process that
is Continuous Integration Continuous Deployment, then MBT must be able to test
the entire model in as little time as possible. However, current academic MBT
tools either traverse models at random, which we show to be ineffective for
this purpose, or use precalculated optimal paths which can not be efficiently
calculated for large industrial models. We provide a new traversal strategy
that provides an improvement in error-detection rate comparable to using
recalculated paths. We show that the new strategy is able to be applied
efficiently to large models. The benchmarks are performed on a mix of
real-world and pseudo-randomly generated models. We observe no significant
difference between these two types of models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Spaendonck_P/0/1/0/all/0/1">P.H.M. van Spaendonck</a></p><p>Model-based testing (MBT) provides an automated approach for finding
discrepancies between software models and their implementation. If we want to
incorporate MBT into the fast and iterative software development process that
is Continuous Integration Continuous Deployment, then MBT must be able to test
the entire model in as little time as possible. However, current academic MBT
tools either traverse models at random, which we show to be ineffective for
this purpose, or use precalculated optimal paths which can not be efficiently
calculated for large industrial models. We provide a new traversal strategy
that provides an improvement in error-detection rate comparable to using
recalculated paths. We show that the new strategy is able to be applied
efficiently to large models. The benchmarks are performed on a mix of
real-world and pseudo-randomly generated models. We observe no significant
difference between these two types of models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-02T00:30:00Z">Tuesday, May 02 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, May 01
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/05/there-are-infinite-number-of-proofs.html'>There are an infinite number of proofs that there are an infinite number of primes</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>In the last few years there have been four papers that prove the primes are infinite using some number theory and some Ramsey Theory. The papers are:</p><p>Van der Waerden and the primes&nbsp;by Alpoge. See&nbsp;here&nbsp;or&nbsp;here.</p><p>Squares in arithmetic progression and infinitely many primes by Granville. See&nbsp;here&nbsp;or&nbsp;here.</p><p>Fermat's last theorem implies the infinitude of primes by Elsholtz. See&nbsp;here&nbsp;or&nbsp;here.</p><p>Fermat's last theorem, Schur's theorem (in Ramsey Theory), and the infinitude of the primes by Gasarch See&nbsp;here&nbsp;and&nbsp;here.</p><p>(I included the arxiv version and the doi pointer.)</p><p>We also note that</p><p>1) Mestrovic has collected up 183 proofs that the primes are infinite, see&nbsp;here. Some of them are similar so if you mod out by similarity you would get fewer proofs. How many you get depends on your criteria for similarity. This comment applies to other theorems that have many proofs.&nbsp;</p><p>2) Quanta recently published an article about the fact that there are an so many proofs, though highlighting the four mentioned above. See&nbsp;here. (This might be behind a paywall.)&nbsp;</p><p>This raises the obvious question:</p><p>Why are there so many proofs that the primes are infinite?&nbsp;</p><p>Some thoughts</p><p>1) Which other theorems have many proofs?</p><p>a) The Pythagorean Theorem. See&nbsp;here&nbsp;for the claim that there are 371 proofs. There is a recent claim of a proof using trigonometry&nbsp;here&nbsp;(this was thought to be impossible since it would involve a circular argument).&nbsp;</p><p>b) According to Wikipedia (see here) The law of quadratic reciprocity has 240&nbsp; proofs.&nbsp; This paper&nbsp;here&nbsp;has some of them. That paper also shows&nbsp;</p><p>QR IMPLIES primes infinite.</p><p>&nbsp;Actually more: QR IMPLIES&nbsp; primes \(\equiv 4 \pmod 5\) is infinite.</p><p>c) \(\sqrt 2\) is irrational has many proofs. I can't find a clean reference that states there are many proofs---if you know one, leave a comment. Wikipedia (see&nbsp;here) has five proofs, though there are many more.&nbsp;</p><p>d) There is a mathoverflow post about theorems with many proofs&nbsp;here. I had thought only easy theorems had many proofs; however, there are several hard ones on this list.&nbsp;</p><p>2) Primes are so basic that many parts of math can be used to proof they are infinite.</p><p>3) WHY do people do these proofs? For the four papers listed above, and likely for many of the other proofs,&nbsp; the proof that primes are infinite is&nbsp; a springboard to other questions or concepts. We look at those four papers:&nbsp;</p><p>a) Alpoge's showed&nbsp;Van Der Waerden's theorem and Unique factorization&nbsp;IMPLIES&nbsp;primes infinite. Alpoge didn't use this as a springboard to other questions, but is amused that VDW can be used to prove primes infinite. I will note that the proof made me realize (a)&nbsp; the proof of Unique Factorization does NOT use that primes are infinite, and (b) ANY integral domain with Unique Factorization has an infinite number of primes.&nbsp;</p><p>b) Granville's showed&nbsp;VDW's Theorem and also a result of Fermat that there cannot be four squares in arithmetic progression IMPLIES&nbsp;primes infinite.&nbsp;He then uses this as a springboard to talk&nbsp; about other interactions between Ramsey Theory and Number Theory.&nbsp; Let Q(N) be the max number of squares in arithmetic sequence of length N. Find upper and lower asy bounds on Q(N). From Szemeredi's theorem (which is part of Ramsey theory) Szemeredi himself showed that for all \(\delta&gt;0, Q(N) &lt; \delta N\). Granville's paper shows how to get this result from a corollary to Faltings theorem. He also notes that better is known: \(Q(N) &lt; N^{3/5 + \epsilon}\).&nbsp;</p><p>c) Elsholtz showed Schur's theorem (for all c there is an S=S(c) such that for all c-colorings of {1,...,S} there exists x,y,z the same color such that x+y=z) and FLT (the n=3 case or n=4 case) IMPLIES primes infinite.&nbsp;He then looks at various INFINITE Ramsey Theorems that imply the primes are infinite.</p><p>d) Gasarch's proof is identical to Elsholtz. He then looks at (1) for domains with a finite number of primes, what goes wrong? (2) when does the proof apply to other integral domains? The last question involves looking at variants of FLT some of which are open questions.&nbsp;</p><p>4) Gasarch also wondered about the following (though its not in his paper). The four papers above, and also other proofs that the primes are infinite, are of the form&nbsp;</p><p>A&nbsp; IMPLIES Primes are infinite</p><p>Are we really using A? How to pin this down? Find a logical system L such that&nbsp;</p><p>1) From L one can show A IMPLIES&nbsp;Primes are infinite</p><p>2) From L one CANNOT prove Primes are infinite. (You may need some hardness assumption)</p><p>One can also examine this kind of question for other theorems like sqrt(2) is irrational.&nbsp;</p><p>I have shown this to several people and am told its not doable. Oh well.&nbsp;</p><p>I had a prior blog on this, after I saw Alpoge's proof,&nbsp; see&nbsp;here.</p><p>ADDED LATER: a commenter left a link to a math overflow page that has information on the reverse mathematics of Euclid's theorem that the primes are infinite. The link is&nbsp;here.</p><p><br></p><p>5) USUALLY mathematicians want to (or should want to) find EASIER proofs of HARD theorems.&nbsp;</p><p>For some of the proofs that primes are infinite, QR, \(\sqrt 2\) irrational, some other theorems that have many proofs, mathematicians want to find HARD proofs of EASY theorems.&nbsp;</p><p><br></p><p><br></p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In the last few years there have been four papers that prove the primes are infinite using some number theory and some Ramsey Theory. The papers are:</p><p><i>Van der Waerden and the primes</i>&nbsp;by Alpoge. See&nbsp;<a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/alpoge-primes.pdf">here</a>&nbsp;or&nbsp;<a href="https://www.tandfonline.com/doi/abs/10.4169/amer.math.monthly.122.8.784">here</a>.</p><p><i>Squares in arithmetic progression and infinitely many primes </i>by Granville. See&nbsp;<a href="https://arxiv.org/abs/1708.06951">here</a>&nbsp;or&nbsp;<a href="https://www.tandfonline.com/doi/abs/10.4169/amer.math.monthly.124.10.951">here</a>.</p><p><i>Fermat's last theorem implies the infinitude of primes</i> by Elsholtz. See&nbsp;<a href="https://arxiv.org/abs/2009.06722">here</a>&nbsp;or&nbsp;<a href="https://www.tandfonline.com/doi/full/10.1080/00029890.2021.1856544">here</a>.</p><p><i>Fermat's last theorem, Schur's theorem (in Ramsey Theory), and the infinitude of the primes </i>by Gasarch See&nbsp;<a href="https://arxiv.org/abs/2302.04755">here</a>&nbsp;and&nbsp;<a href="https://www.sciencedirect.com/science/article/pii/S0012365X23000225?via%3Dihub">here</a>.</p><p>(I included the arxiv version and the doi pointer.)</p><p>We also note that</p><p>1) Mestrovic has collected up 183 proofs that the primes are infinite, see&nbsp;<a href="https://arxiv.org/pdf/1202.3670.pdf">here</a>. Some of them are similar so if you mod out by similarity you would get fewer proofs. How many you get depends on your criteria for similarity. This comment applies to other theorems that have many proofs.&nbsp;</p><p>2) Quanta recently published an article about the fact that there are an so many proofs, though highlighting the four mentioned above. See&nbsp;<a href="https://www.quantamagazine.org/why-mathematicians-re-prove-what-they-already-know-20230426/">here</a>. (This might be behind a paywall.)&nbsp;</p><p>This raises the obvious question:</p><p>Why are there so many proofs that the primes are infinite?&nbsp;</p><p>Some thoughts</p><p>1) Which other theorems have many proofs?</p><p>a) <i>The Pythagorean Theorem</i>. See&nbsp;<a href="https://link.springer.com/article/10.1057/jt.2009.16#:~:text=There%20are%20well%20over%20371,the%20United%20States%20James%20A.">here</a>&nbsp;for the claim that there are 371 proofs. There is a recent claim of a proof using trigonometry&nbsp;<a href="https://www.youtube.com/watch?v=p6j2nZKwf20">here</a>&nbsp;(this was thought to be impossible since it would involve a circular argument).&nbsp;</p><p>b) According to Wikipedia (see <a href="https://en.wikipedia.org/wiki/Quadratic_reciprocity">here</a>) <i>The law of quadratic reciprocity</i> has 240&nbsp; proofs.&nbsp; This paper&nbsp;<a href="https://egrove.olemiss.edu/cgi/viewcontent.cgi?article=2539&amp;context=etd#:~:text=Having%20a%20total%20of%20246,laws%20in%20the%20natural%20sciences.">here</a>&nbsp;has some of them. That paper also shows&nbsp;</p><p><i>QR IMPLIES primes infinite</i>.</p><p>&nbsp;Actually more: <i>QR IMPLIES&nbsp; primes \(\equiv 4 \pmod 5\) is infinite.</i></p><p>c) \(\sqrt 2\) <i>is irrational</i> has many proofs. I can't find a clean reference that states there are many proofs---if you know one, leave a comment. Wikipedia (see&nbsp;<a href="https://en.wikipedia.org/wiki/Square_root_of_2#:~:text=Geometrically%2C%20the%20square%20root%20of,number%20known%20to%20be%20irrational.">here</a>) has five proofs, though there are many more.&nbsp;</p><p>d) There is a mathoverflow post about theorems with many proofs&nbsp;<a href="https://mathoverflow.net/questions/401493/theorems-with-many-distinct-proofs">here</a>. I had thought only easy theorems had many proofs; however, there are several hard ones on this list.&nbsp;</p><p>2) Primes are so basic that many parts of math can be used to proof they are infinite.</p><p>3) WHY do people do these proofs? For the four papers listed above, and likely for many of the other proofs,&nbsp; the proof that primes are infinite is&nbsp; a springboard to other questions or concepts. We look at those four papers:&nbsp;</p><p>a) Alpoge's showed&nbsp;<i>Van Der Waerden's theorem and Unique factorization</i>&nbsp;IMPLIES&nbsp;<i>primes infinite.</i> Alpoge didn't use this as a springboard to other questions, but is amused that VDW can be used to prove primes infinite. I will note that the proof made me realize (a)&nbsp; the proof of Unique Factorization does NOT use that primes are infinite, and (b) ANY integral domain with Unique Factorization has an infinite number of primes.&nbsp;</p><p>b) Granville's showed&nbsp;<i>VDW's Theorem and also a result of Fermat that there cannot be four squares</i> <i>in arithmetic progression </i>IMPLIES&nbsp;<i>primes infinite</i>.&nbsp;He then uses this as a springboard to talk&nbsp; about other interactions between Ramsey Theory and Number Theory.&nbsp; Let Q(N) be the max number of squares in arithmetic sequence of length N. Find upper and lower asy bounds on Q(N). From Szemeredi's theorem (which is part of Ramsey theory) Szemeredi himself showed that for all \(\delta&gt;0, Q(N) &lt; \delta N\). Granville's paper shows how to get this result from a corollary to Faltings theorem. He also notes that better is known: \(Q(N) &lt; N^{3/5 + \epsilon}\).&nbsp;</p><p>c) Elsholtz showed <i>Schur's theorem (for all c there is an S=S(c) such that for all c-colorings of {1,...,S}</i> <i>there exists x,y,z the same color such that x+y=z)</i> and <i>FLT (the n=3 case or n=4 case) </i>IMPLIES primes infinite.&nbsp;He then looks at various INFINITE Ramsey Theorems that imply the primes are infinite.</p><p>d) Gasarch's proof is identical to Elsholtz. He then looks at (1) for domains with a finite number of primes, what goes wrong? (2) when does the proof apply to other integral domains? The last question involves looking at variants of FLT some of which are open questions.&nbsp;</p><p>4) Gasarch also wondered about the following (though its not in his paper). The four papers above, and also other proofs that the primes are infinite, are of the form&nbsp;</p><p><i>A&nbsp; </i>IMPLIES<i> Primes are infinite</i></p><p>Are we really using A? How to pin this down? Find a logical system L such that&nbsp;</p><p>1) From L one can show <i>A </i>IMPLIES<i>&nbsp;Primes are infinite</i></p><p>2) From L one CANNOT prove <i>Primes are infinite. </i>(You may need some hardness assumption)</p><p>One can also examine this kind of question for other theorems like sqrt(2) is irrational.&nbsp;</p><p>I have shown this to several people and am told its not doable. Oh well.&nbsp;</p><p>I had a prior blog on this, after I saw Alpoge's proof,&nbsp; see&nbsp;<a href="https://blog.computationalcomplexity.org/2017/11/van-der-waerdens-theorem-implies.html#comment-form">here</a>.</p><p>ADDED LATER: a commenter left a link to a math overflow page that has information on the reverse mathematics of Euclid's theorem that the primes are infinite. The link is&nbsp;<a href="https://mathoverflow.net/questions/319686/reverse-mathematics-of-euclids-theorem">here</a>.</p><p><br /></p><p>5) USUALLY mathematicians want to (or should want to) find EASIER proofs of HARD theorems.&nbsp;</p><p>For some of the proofs that primes are infinite, QR, \(\sqrt 2\) irrational, some other theorems that have many proofs, mathematicians want to find HARD proofs of EASY theorems.&nbsp;</p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T13:05:00Z">Monday, May 01 2023, 13:05</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14557'>The Fine-Grained Complexity of Boolean Conjunctive Queries and Sum-Product Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Austen Z. Fan, Paraschos Koutris, Hangdong Zhao</p><p>We study the fine-grained complexity of evaluating Boolean Conjunctive
Queries and their generalization to sum-of-product problems over an arbitrary
semiring. For these problems, we present a general semiring-oblivious reduction
from the k-clique problem to any query structure (hypergraph). Our reduction
uses the notion of embedding a graph to a hypergraph, first introduced by
Marx~\cite{Marx13}. As a consequence of our reduction, we can show tight
conditional lower bounds for many classes of hypergraphs, including cycles,
Loomis-Whitney joins, some bipartite graphs, and chordal graphs. These lower
bounds have a dependence on what we call the clique embedding power of a
hypergraph H, which we believe is a quantity of independent interest. We show
that the clique embedding power is always less than the submodular width of the
hypergraph, and present a decidable algorithm for computing it. We conclude
with many open problems for future research.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1">Austen Z. Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Koutris_P/0/1/0/all/0/1">Paraschos Koutris</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hangdong Zhao</a></p><p>We study the fine-grained complexity of evaluating Boolean Conjunctive
Queries and their generalization to sum-of-product problems over an arbitrary
semiring. For these problems, we present a general semiring-oblivious reduction
from the k-clique problem to any query structure (hypergraph). Our reduction
uses the notion of embedding a graph to a hypergraph, first introduced by
Marx~\cite{Marx13}. As a consequence of our reduction, we can show tight
conditional lower bounds for many classes of hypergraphs, including cycles,
Loomis-Whitney joins, some bipartite graphs, and chordal graphs. These lower
bounds have a dependence on what we call the clique embedding power of a
hypergraph H, which we believe is a quantity of independent interest. We show
that the clique embedding power is always less than the submodular width of the
hypergraph, and present a decidable algorithm for computing it. We conclude
with many open problems for future research.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T00:30:00Z">Monday, May 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14575'>A Critique of Czerwinski's "Separation of ${\rm PSPACE}$ and ${\rm EXP}$"</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ian Clingerman, Quan Luu</p><p>Czerwinski's paper "Separation of ${\rm PSPACE}$ and ${\rm EXP}$" [Cze21]
claims to prove that ${\rm PSPACE} \neq {\rm EXP}$ by showing there is no
length-increasing polynomial-time reduction from a given ${\rm EXP}$-complete
set to a given ${\rm PSPACE}$-complete set. However, in this critique, we show
that there are fundamental flaws within the paper's approach and provide a
counterexample to one of the paper's theorems, which makes the proposed proof
that ${\rm PSPACE} \neq {\rm EXP}$ insufficient.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Clingerman_I/0/1/0/all/0/1">Ian Clingerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_Q/0/1/0/all/0/1">Quan Luu</a></p><p>Czerwinski's paper "Separation of ${\rm PSPACE}$ and ${\rm EXP}$" [Cze21]
claims to prove that ${\rm PSPACE} \neq {\rm EXP}$ by showing there is no
length-increasing polynomial-time reduction from a given ${\rm EXP}$-complete
set to a given ${\rm PSPACE}$-complete set. However, in this critique, we show
that there are fundamental flaws within the paper's approach and provide a
counterexample to one of the paper's theorems, which makes the proposed proof
that ${\rm PSPACE} \neq {\rm EXP}$ insufficient.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T00:30:00Z">Monday, May 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14700'>Stretching Demi-Bits and Nondeterministic-Secure Pseudorandomness</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Iddo Tzameret, Lu-Ming Zhang</p><p>We develop the theory of cryptographic nondeterministic-secure
pseudorandomness beyond the point reached by Rudich's original work (Rudich
1997), and apply it to draw new consequences in average-case complexity and
proof complexity. Specifically, we show the following:
</p>
<p>*Demi-bit stretch*: Super-bits and demi-bits are variants of cryptographic
pseudorandom generators which are secure against nondeterministic statistical
tests (Rudich 1997). They were introduced to rule out certain approaches to
proving strong complexity lower bounds beyond the limitations set out by the
Natural Proofs barrier (Rudich and Razborov 1997). Whether demi-bits are
stretchable at all had been an open problem since their introduction. We answer
this question affirmatively by showing that: every demi-bit $b:\{0,1\}^n\to
\{0,1\}^{n+1}$ can be stretched into sublinear many demi-bits
$b':\{0,1\}^{n}\to \{0,1\}^{n+n^{c}}$, for every constant $0&lt;c&lt;1$.
</p>
<p>&gt;&gt;&gt; see rest of abstract in paper.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tzameret_I/0/1/0/all/0/1">Iddo Tzameret</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu-Ming Zhang</a></p><p>We develop the theory of cryptographic nondeterministic-secure
pseudorandomness beyond the point reached by Rudich's original work (Rudich
1997), and apply it to draw new consequences in average-case complexity and
proof complexity. Specifically, we show the following:
</p>
<p>*Demi-bit stretch*: Super-bits and demi-bits are variants of cryptographic
pseudorandom generators which are secure against nondeterministic statistical
tests (Rudich 1997). They were introduced to rule out certain approaches to
proving strong complexity lower bounds beyond the limitations set out by the
Natural Proofs barrier (Rudich and Razborov 1997). Whether demi-bits are
stretchable at all had been an open problem since their introduction. We answer
this question affirmatively by showing that: every demi-bit $b:\{0,1\}^n\to
\{0,1\}^{n+1}$ can be stretched into sublinear many demi-bits
$b':\{0,1\}^{n}\to \{0,1\}^{n+n^{c}}$, for every constant $0&lt;c&lt;1$.
</p>
<p>&gt;&gt;&gt; see rest of abstract in paper.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T00:30:00Z">Monday, May 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14702'>Upward Translation of Optimal and P-Optimal Proof Systems in the Boolean Hierarchy over NP</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fabian Egidy, Christian Gla&#xdf;er, Martin Herold</p><p>We study the existence of optimal and p-optimal proof systems for classes in
the Boolean hierarchy over $\mathrm{NP}$. Our main results concern
$\mathrm{DP}$, i.e., the second level of this hierarchy:
</p>
<p>If all sets in $\mathrm{DP}$ have p-optimal proof systems, then all sets in
$\mathrm{coDP}$ have p-optimal proof systems. The analogous implication for
optimal proof systems fails relative to an oracle.
</p>
<p>As a consequence, we clarify such implications for all classes $\mathcal{C}$
and $\mathcal{D}$ in the Boolean hierarchy over $\mathrm{NP}$: either we can
prove the implication or show that it fails relative to an oracle. Furthermore,
we show that the sets $\mathrm{SAT}$ and $\mathrm{TAUT}$ have p-optimal proof
systems, if and only if all sets in the Boolean hierarchy over $\mathrm{NP}$
have p-optimal proof systems which is a new characterization of a conjecture
studied by Pudl\'ak.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Egidy_F/0/1/0/all/0/1">Fabian Egidy</a>, <a href="http://arxiv.org/find/cs/1/au:+Glasser_C/0/1/0/all/0/1">Christian Gla&#xdf;er</a>, <a href="http://arxiv.org/find/cs/1/au:+Herold_M/0/1/0/all/0/1">Martin Herold</a></p><p>We study the existence of optimal and p-optimal proof systems for classes in
the Boolean hierarchy over $\mathrm{NP}$. Our main results concern
$\mathrm{DP}$, i.e., the second level of this hierarchy:
</p>
<p>If all sets in $\mathrm{DP}$ have p-optimal proof systems, then all sets in
$\mathrm{coDP}$ have p-optimal proof systems. The analogous implication for
optimal proof systems fails relative to an oracle.
</p>
<p>As a consequence, we clarify such implications for all classes $\mathcal{C}$
and $\mathcal{D}$ in the Boolean hierarchy over $\mathrm{NP}$: either we can
prove the implication or show that it fails relative to an oracle. Furthermore,
we show that the sets $\mathrm{SAT}$ and $\mathrm{TAUT}$ have p-optimal proof
systems, if and only if all sets in the Boolean hierarchy over $\mathrm{NP}$
have p-optimal proof systems which is a new characterization of a conjecture
studied by Pudl\'ak.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T00:30:00Z">Monday, May 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14990'>Robust Stackelberg Equilibria</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jiarui Gan, Minbiao Han, Jibang Wu, Haifeng Xu</p><p>This paper provides a systematic study of the robust Stackelberg equilibrium
(RSE), which naturally generalizes the widely adopted solution concept of the
strong Stackelberg equilibrium (SSE). The RSE accounts for any possible
up-to-$\delta$ suboptimal follower responses in Stackelberg games and is
adopted to improve the robustness of the leader's strategy. While a few
variants of robust Stackelberg equilibrium have been considered in previous
literature, the RSE solution concept we consider is importantly different -- in
some sense, it relaxes previously studied robust Stackelberg strategies and is
applicable to much broader sources of uncertainties.
</p>
<p>We provide a thorough investigation of several fundamental properties of RSE,
including its utility guarantees, algorithmics, and learnability. We first show
that the RSE we defined always exists and thus is well-defined. Then we
characterize how the leader's utility in RSE changes with the robustness level
considered. On the algorithmic side, we show that, in sharp contrast to the
tractability of computing an SSE, it is NP-hard to obtain a fully polynomial
approximation scheme (FPTAS) for any constant robustness level. Nevertheless,
we develop a quasi-polynomial approximation scheme (QPTAS) for RSE. Finally, we
examine the learnability of the RSE in a natural learning scenario, where both
players' utilities are not known in advance, and provide almost tight sample
complexity results on learning the RSE. As a corollary of this result, we also
obtain an algorithm for learning SSE, which strictly improves a key result of
Bai et al. in terms of both utility guarantee and computational efficiency.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gan_J/0/1/0/all/0/1">Jiarui Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1">Minbiao Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jibang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haifeng Xu</a></p><p>This paper provides a systematic study of the robust Stackelberg equilibrium
(RSE), which naturally generalizes the widely adopted solution concept of the
strong Stackelberg equilibrium (SSE). The RSE accounts for any possible
up-to-$\delta$ suboptimal follower responses in Stackelberg games and is
adopted to improve the robustness of the leader's strategy. While a few
variants of robust Stackelberg equilibrium have been considered in previous
literature, the RSE solution concept we consider is importantly different -- in
some sense, it relaxes previously studied robust Stackelberg strategies and is
applicable to much broader sources of uncertainties.
</p>
<p>We provide a thorough investigation of several fundamental properties of RSE,
including its utility guarantees, algorithmics, and learnability. We first show
that the RSE we defined always exists and thus is well-defined. Then we
characterize how the leader's utility in RSE changes with the robustness level
considered. On the algorithmic side, we show that, in sharp contrast to the
tractability of computing an SSE, it is NP-hard to obtain a fully polynomial
approximation scheme (FPTAS) for any constant robustness level. Nevertheless,
we develop a quasi-polynomial approximation scheme (QPTAS) for RSE. Finally, we
examine the learnability of the RSE in a natural learning scenario, where both
players' utilities are not known in advance, and provide almost tight sample
complexity results on learning the RSE. As a corollary of this result, we also
obtain an algorithm for learning SSE, which strictly improves a key result of
Bai et al. in terms of both utility guarantee and computational efficiency.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T00:30:00Z">Monday, May 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14852'>Wasserstein Dictionaries of Persistence Diagrams</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Keanu Sisouk, Julie Delon, Julien Tierny</p><p>This paper presents a computational framework for the concise encoding of an
ensemble of persistence diagrams, in the form of weighted Wasserstein
barycenters [99], [101] of a dictionary of atom diagrams. We introduce a
multi-scale gradient descent approach for the efficient resolution of the
corresponding minimization problem, which interleaves the optimization of the
barycenter weights with the optimization of the atom diagrams. Our approach
leverages the analytic expressions for the gradient of both sub-problems to
ensure fast iterations and it additionally exploits shared-memory parallelism.
Extensive experiments on public ensembles demonstrate the efficiency of our
approach, with Wasserstein dictionary computations in the orders of minutes for
the largest examples. We show the utility of our contributions in two
applications. First, we apply Wassserstein dictionaries to data reduction and
reliably compress persistence diagrams by concisely representing them with
their weights in the dictionary. Second, we present a dimensionality reduction
framework based on a Wasserstein dictionary defined with a small number of
atoms (typically three) and encode the dictionary as a low dimensional simplex
embedded in a visual space (typically in 2D). In both applications,
quantitative experiments assess the relevance of our framework. Finally, we
provide a C++ implementation that can be used to reproduce our results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sisouk_K/0/1/0/all/0/1">Keanu Sisouk</a>, <a href="http://arxiv.org/find/cs/1/au:+Delon_J/0/1/0/all/0/1">Julie Delon</a>, <a href="http://arxiv.org/find/cs/1/au:+Tierny_J/0/1/0/all/0/1">Julien Tierny</a></p><p>This paper presents a computational framework for the concise encoding of an
ensemble of persistence diagrams, in the form of weighted Wasserstein
barycenters [99], [101] of a dictionary of atom diagrams. We introduce a
multi-scale gradient descent approach for the efficient resolution of the
corresponding minimization problem, which interleaves the optimization of the
barycenter weights with the optimization of the atom diagrams. Our approach
leverages the analytic expressions for the gradient of both sub-problems to
ensure fast iterations and it additionally exploits shared-memory parallelism.
Extensive experiments on public ensembles demonstrate the efficiency of our
approach, with Wasserstein dictionary computations in the orders of minutes for
the largest examples. We show the utility of our contributions in two
applications. First, we apply Wassserstein dictionaries to data reduction and
reliably compress persistence diagrams by concisely representing them with
their weights in the dictionary. Second, we present a dimensionality reduction
framework based on a Wasserstein dictionary defined with a small number of
atoms (typically three) and encode the dictionary as a low dimensional simplex
embedded in a visual space (typically in 2D). In both applications,
quantitative experiments assess the relevance of our framework. Finally, we
provide a C++ implementation that can be used to reproduce our results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T00:30:00Z">Monday, May 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14853'>Topological Data Analysis of Electroencephalogram Signals for Pediatric Obstructive Sleep Apnea</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shashank Manjunath, Jose A. Perea, Aarti Sathyanarayana</p><p>Topological data analysis (TDA) is an emerging technique for biological
signal processing. TDA leverages the invariant topological features of signals
in a metric space for robust analysis of signals even in the presence of noise.
In this paper, we leverage TDA on brain connectivity networks derived from
electroencephalogram (EEG) signals to identify statistical differences between
pediatric patients with obstructive sleep apnea (OSA) and pediatric patients
without OSA. We leverage a large corpus of data, and show that TDA enables us
to see a statistical difference between the brain dynamics of the two groups.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Manjunath_S/0/1/0/all/0/1">Shashank Manjunath</a>, <a href="http://arxiv.org/find/math/1/au:+Perea_J/0/1/0/all/0/1">Jose A. Perea</a>, <a href="http://arxiv.org/find/math/1/au:+Sathyanarayana_A/0/1/0/all/0/1">Aarti Sathyanarayana</a></p><p>Topological data analysis (TDA) is an emerging technique for biological
signal processing. TDA leverages the invariant topological features of signals
in a metric space for robust analysis of signals even in the presence of noise.
In this paper, we leverage TDA on brain connectivity networks derived from
electroencephalogram (EEG) signals to identify statistical differences between
pediatric patients with obstructive sleep apnea (OSA) and pediatric patients
without OSA. We leverage a large corpus of data, and show that TDA enables us
to see a statistical difference between the brain dynamics of the two groups.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T00:30:00Z">Monday, May 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14724'>Structural Parameterizations for Two Bounded Degree Problems Revisited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Lampis, Manolis Vasilakis</p><p>We revisit two well-studied problems, Bounded Degree Vertex Deletion and
Defective Coloring, where the input is a graph $G$ and a target degree $\Delta$
and we are asked either to edit or partition the graph so that the maximum
degree becomes bounded by $\Delta$. Both are known to be parameterized
intractable for treewidth.
</p>
<p>We revisit the parameterization by treewidth, as well as several related
parameters and present a more fine-grained picture of the complexity of both
problems.
</p>
<p>Both admit straightforward DP algorithms with table sizes
$(\Delta+2)^\mathrm{tw}$ and $(\chi_\mathrm{d}(\Delta+1))^{\mathrm{tw}}$
respectively, where tw is the input graph's treewidth and $\chi_\mathrm{d}$ the
number of available colors. We show that both algorithms are optimal under
SETH, even if we replace treewidth by pathwidth. Along the way, we also obtain
an algorithm for Defective Coloring with complexity quasi-linear in the table
size, thus settling the complexity of both problems for these parameters.
</p>
<p>We then consider the more restricted parameter tree-depth, and bridge the gap
left by known lower bounds, by showing that neither problem can be solved in
time $n^{o(\mathrm{td})}$ under ETH. In order to do so, we employ a recursive
low tree-depth construction that may be of independent interest.
</p>
<p>Finally, we show that for both problems, an $\mathrm{vc}^{o(\mathrm{vc})}$
algorithm would violate ETH, thus already known algorithms are optimal. Our
proof relies on a new application of the technique of $d$-detecting families
introduced by Bonamy et al.
</p>
<p>Our results, although mostly negative in nature, paint a clear picture
regarding the complexity of both problems in the landscape of parameterized
complexity, since in all cases we provide essentially matching upper and lower
bounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lampis_M/0/1/0/all/0/1">Michael Lampis</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasilakis_M/0/1/0/all/0/1">Manolis Vasilakis</a></p><p>We revisit two well-studied problems, Bounded Degree Vertex Deletion and
Defective Coloring, where the input is a graph $G$ and a target degree $\Delta$
and we are asked either to edit or partition the graph so that the maximum
degree becomes bounded by $\Delta$. Both are known to be parameterized
intractable for treewidth.
</p>
<p>We revisit the parameterization by treewidth, as well as several related
parameters and present a more fine-grained picture of the complexity of both
problems.
</p>
<p>Both admit straightforward DP algorithms with table sizes
$(\Delta+2)^\mathrm{tw}$ and $(\chi_\mathrm{d}(\Delta+1))^{\mathrm{tw}}$
respectively, where tw is the input graph's treewidth and $\chi_\mathrm{d}$ the
number of available colors. We show that both algorithms are optimal under
SETH, even if we replace treewidth by pathwidth. Along the way, we also obtain
an algorithm for Defective Coloring with complexity quasi-linear in the table
size, thus settling the complexity of both problems for these parameters.
</p>
<p>We then consider the more restricted parameter tree-depth, and bridge the gap
left by known lower bounds, by showing that neither problem can be solved in
time $n^{o(\mathrm{td})}$ under ETH. In order to do so, we employ a recursive
low tree-depth construction that may be of independent interest.
</p>
<p>Finally, we show that for both problems, an $\mathrm{vc}^{o(\mathrm{vc})}$
algorithm would violate ETH, thus already known algorithms are optimal. Our
proof relies on a new application of the technique of $d$-detecting families
introduced by Bonamy et al.
</p>
<p>Our results, although mostly negative in nature, paint a clear picture
regarding the complexity of both problems in the landscape of parameterized
complexity, since in all cases we provide essentially matching upper and lower
bounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T00:30:00Z">Monday, May 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14643'>Approximate Nearest Neighbor for Polygonal Curves under Fr\'echet Distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Siu-Wing Cheng, Haoqiang Huang</p><p>We propose $\kappa$-approximate nearest neighbor (ANN) data structures for
$n$ polygonal curves under the Fr\'{e}chet distance in $\real^d$, where $\kappa
\in \{1+\eps,3+\eps\}$ and $d \geq 2$. We assume that every input curve has at
most $m$ vertices, every query curve has at most $k$ vertices, $k \ll m$, and
$k$ is given for preprocessing. The query times are
$\tilde{O}(k(mn)^{0.5+\eps}/\eps^d+ k(d/\eps)^{O(dk)})$ for $(1+\eps)$-ANN and
$\tilde{O}(k(mn)^{0.5+\eps}/\eps^d)$ for $(3+\eps)$-ANN. The space and expected
preprocessing time are $\tilde{O}(k(mnd^d/\eps^d)^{O(k+1/\eps^2)})$ in both
cases. In two and three dimensions, we improve the query times to
$O(1/\eps)^{O(k)} \cdot \tilde{O}(k)$ for $(1+\eps)$-ANN and $\tilde{O}(k)$ for
$(3+\eps)$-ANN. The space and expected preprocessing time improve to
$O(mn/\eps)^{O(k)} \cdot \tilde{O}(k)$ in both cases. For ease of presentation,
we treat factors in our bounds that depend purely on $d$ as~$O(1)$. The hidden
polylog factors in the big-$\tilde{O}$ notation have powers dependent on $d$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1">Siu-Wing Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haoqiang Huang</a></p><p>We propose $\kappa$-approximate nearest neighbor (ANN) data structures for
$n$ polygonal curves under the Fr\'{e}chet distance in $\real^d$, where $\kappa
\in \{1+\eps,3+\eps\}$ and $d \geq 2$. We assume that every input curve has at
most $m$ vertices, every query curve has at most $k$ vertices, $k \ll m$, and
$k$ is given for preprocessing. The query times are
$\tilde{O}(k(mn)^{0.5+\eps}/\eps^d+ k(d/\eps)^{O(dk)})$ for $(1+\eps)$-ANN and
$\tilde{O}(k(mn)^{0.5+\eps}/\eps^d)$ for $(3+\eps)$-ANN. The space and expected
preprocessing time are $\tilde{O}(k(mnd^d/\eps^d)^{O(k+1/\eps^2)})$ in both
cases. In two and three dimensions, we improve the query times to
$O(1/\eps)^{O(k)} \cdot \tilde{O}(k)$ for $(1+\eps)$-ANN and $\tilde{O}(k)$ for
$(3+\eps)$-ANN. The space and expected preprocessing time improve to
$O(mn/\eps)^{O(k)} \cdot \tilde{O}(k)$ in both cases. For ease of presentation,
we treat factors in our bounds that depend purely on $d$ as~$O(1)$. The hidden
polylog factors in the big-$\tilde{O}$ notation have powers dependent on $d$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T00:30:00Z">Monday, May 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14782'>Hardness of Finding Combinatorial Shortest Paths on Graph Associahedra</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Takehiro Ito, Naonori Kakimura, Naoyuki Kamiyama, Yusuke Kobayashi, Shun-ichi Maezawa, Yuta Nozaki, Yoshio Okamoto</p><p>We prove that the computation of a combinatorial shortest path between two
vertices of a graph associahedron, introduced by Carr and Devadoss, is NP-hard.
This resolves an open problem raised by Cardinal. A graph associahedron is a
generalization of the well-known associahedron. The associahedron is obtained
as the graph associahedron of a path. It is a tantalizing and important open
problem in theoretical computer science whether the computation of a
combinatorial shortest path between two vertices of the associahedron can be
done in polynomial time, which is identical to the computation of the flip
distance between two triangulations of a convex polygon, and the rotation
distance between two rooted binary trees. Our result shows that a certain
generalized approach to tackling this open problem is not promising. As a
corollary of our theorem, we prove that the computation of a combinatorial
shortest path between two vertices of a polymatroid base polytope cannot be
done in polynomial time unless P = NP. Since a combinatorial shortest path on
the matroid base polytope can be computed in polynomial time, our result
reveals an unexpected contrast between matroids and polymatroids.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Ito_T/0/1/0/all/0/1">Takehiro Ito</a>, <a href="http://arxiv.org/find/math/1/au:+Kakimura_N/0/1/0/all/0/1">Naonori Kakimura</a>, <a href="http://arxiv.org/find/math/1/au:+Kamiyama_N/0/1/0/all/0/1">Naoyuki Kamiyama</a>, <a href="http://arxiv.org/find/math/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yusuke Kobayashi</a>, <a href="http://arxiv.org/find/math/1/au:+Maezawa_S/0/1/0/all/0/1">Shun-ichi Maezawa</a>, <a href="http://arxiv.org/find/math/1/au:+Nozaki_Y/0/1/0/all/0/1">Yuta Nozaki</a>, <a href="http://arxiv.org/find/math/1/au:+Okamoto_Y/0/1/0/all/0/1">Yoshio Okamoto</a></p><p>We prove that the computation of a combinatorial shortest path between two
vertices of a graph associahedron, introduced by Carr and Devadoss, is NP-hard.
This resolves an open problem raised by Cardinal. A graph associahedron is a
generalization of the well-known associahedron. The associahedron is obtained
as the graph associahedron of a path. It is a tantalizing and important open
problem in theoretical computer science whether the computation of a
combinatorial shortest path between two vertices of the associahedron can be
done in polynomial time, which is identical to the computation of the flip
distance between two triangulations of a convex polygon, and the rotation
distance between two rooted binary trees. Our result shows that a certain
generalized approach to tackling this open problem is not promising. As a
corollary of our theorem, we prove that the computation of a combinatorial
shortest path between two vertices of a polymatroid base polytope cannot be
done in polynomial time unless P = NP. Since a combinatorial shortest path on
the matroid base polytope can be computed in polynomial time, our result
reveals an unexpected contrast between matroids and polymatroids.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-01T00:30:00Z">Monday, May 01 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, April 30
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/04/30/5-worlds-of-ai/'>5 worlds of AI</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Scott Aaronson and I wrote a post about 5 possible worlds for (the progress of) Artificial Intelligence. See Scott&#8217;s blog for the post itself and discussions. The post was, of course, inspired by the classic essay on the 5 worlds of computational complexity by Russell Impagliazzo who will be turning 60 soon &#8211; Happy birthday!
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Scott Aaronson and I wrote a post about<a href="https://scottaaronson.blog/?p=7266"> 5 possible worlds for (the progress of) Artificial Intelligence</a>. See Scott&#8217;s blog for the post itself and discussions.</p>



<p>The post was, of course, inspired by the <a href="https://www.karlin.mff.cuni.cz/~krajicek/ri5svetu.pdf">classic essay</a> on the 5 worlds of computational complexity by <a href="https://cseweb.ucsd.edu/~russell/">Russell Impagliazzo</a> who will be turning 60 soon &#8211; Happy birthday! </p>



<p></p>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2023/04/image-3.png"><img data-attachment-id="8609" data-permalink="https://windowsontheory.org/2023/04/30/5-worlds-of-ai/image-3-3/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/04/image-3.png" data-orig-size="447,640" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-3" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/04/image-3.png?w=210" data-large-file="https://windowsontheory.files.wordpress.com/2023/04/image-3.png?w=447" src="https://windowsontheory.files.wordpress.com/2023/04/image-3.png?w=447" alt="" class="wp-image-8609" srcset="https://windowsontheory.files.wordpress.com/2023/04/image-3.png 447w, https://windowsontheory.files.wordpress.com/2023/04/image-3.png?w=105 105w, https://windowsontheory.files.wordpress.com/2023/04/image-3.png?w=210 210w" sizes="(max-width: 447px) 100vw, 447px" /></a></figure>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-30T21:39:21Z">Sunday, April 30 2023, 21:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/04/30/linkage.html'>Linkage</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We’ve already seen AI-generated peer-review for Wikipedia articles (\(\mathbb{M}\)), with such brilliant insight as:
        
        </div>

        <div class='tr-article-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Wikipedia:Administrators%27_noticeboard/IncidentArchive1125#ChatGPT_comments_at_AFD">We’ve already seen AI-generated peer-review for Wikipedia articles</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110215235459028740">\(\mathbb{M}\)</a>),</span> with such brilliant insight as:</p>

    <blockquote>
      <p>This article is extensive in its coverage of such a rich topic as Ontario Highway 11. It addresses the main points of Ontario Highway 11 in a way that isn’t just understandable to a reader, but also relatable. While Ontario Highway 11 is brimming with fascinating background trivia, the article does a great job staying focused on the topic of Ontario Highway 11 without going into unnecessary detail that isn’t directly related to Ontario Highway 11. Neutral point of view without bias is maintained perfectly in this article, despite Ontario Highway 11 being such a contentious and controversial topic. Images are truly beautiful and done with expert photographic skill. They definitely enhance the reader’s understanding of Ontario Highway 11. Without them, I wouldn’t have any idea what the highway looks like. But thanks to these wonderful images, I now understand that Ontario Highway 11 is a paved road that vehicles use to travel.</p>
    </blockquote>

    <p>I originally asked, how long before this spreads to journal referee reports? But from second-hand reports in the comments, this has also happened already.</p>
  </li>
  <li>
    <p>San Francisco’s move to prevent talented high school students from taking advanced mathematics early, pushed hard by educationist Jo Boaler with the ostensible goal of improving disparities in schooling, <a href="https://www.joannejacobs.com/post/algebra-for-none-fails-in-san-francisco">has predictably failed to improve the ethnic and socioeconomic balance of the city’s advanced mathematics courses</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110223929076976006">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=35595026">via</a>). Instead, “Families face a nightmare of workarounds to get their high-achieving children on track for advanced math”, more easily navigable by the already-privileged.</p>
  </li>
  <li>
    <p><a href="https://www.smh.com.au/national/farmers-crippled-by-satellite-failure-as-gps-guided-tractors-grind-to-a-halt-20230418-p5d1de.html">A signal failure stalled GPS-dependent tractors across farms in Australia and New Zealand</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110234112368256390">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=35643705">via</a>), after one of the Inmarsat satellites providing accuracy enhancements to GPS in that part of the earth stopped working correctly. <a href="https://www.abc.net.au/news/rural/2023-04-19/inmarsat-i-4-f1-satellite-operating-again-after-outage/102239674">The satellite is back after an over-24-hour outage</a> but this event “is prompting farmers and industry groups to examine their backup systems for the technology they are using”.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@mjd/110234853354707289">Math StackExchange report</a> by Mark Dominus: “simplest-possible examples, pointy regions, and nearly-orthogonal vectors”. Also with discussion about what kind of answers get upvoted (not the deepest and most insightful!) and on the value of asking poorly-formulated questions.</p>
  </li>
  <li>
    <p>Danpiker asks: <a href="https://mathstodon.xyz/@Danpiker/110237176309119968">In how many different ways can \(n\) circles be linked in \(\mathbb{R}^3\)?</a> It’s not even entirely clear what the definition of “different” should be, and Ian Agol points out in the comments that even great circles in \(\mathbb{S}^3\) are as-yet unclassified, pointing to <a href="https://arxiv.org/abs/math/0308048">Genevieve Walsh’s dissertation on the subject</a>.</p>
  </li>
  <li>
    <p><a href="https://www.salemreporter.com/2023/04/13/math-breakthrough-inspires-local-educator/">Math breakthrough inspires local educator</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@fractalkitty/110200137077541078">\(\mathbb{M}\)</a>).</span> Profile in the <em>Salem Reporter</em> of Sophia Wood aka Fractal Kitty and her mathematics-inspired crafts.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@robinhouston/110246989262052781">There are cubic graphs that cannot be partitioned into connected subgraphs of two and four vertices</a>. However, <a href="https://mathstodon.xyz/@11011110/110263657563692233">every cubic graph with \(3n\) vertices can be partitioned into subgraphs of size \(n\) without isolated vertices</a>. The proof involves partitioning into connected subgraphs of two and three vertices, with at most one four-vertex subgraph and at least four two-vertex subgraphs, grouping these into six-vertex subgraphs, and then breaking up one or two of the six-vertex subgraphs as needed to even out the three-way partition.</p>
  </li>
  <li>
    <p>A confluent drawing style, in which vertices are connected by systems of “tracks” and are adjacent when there is a smooth curve connecting them through these tracks, allows <a href="https://en.wikipedia.org/wiki/Chv%C3%A1tal_graph">the Chvátal graph</a> to be drawn with only a single crossing <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110254999830816403">\(\mathbb{M}\)</a>):</span></p>

    <p style="text-align:center"><img src="/blog/assets/2023/chvatal.svg" alt="The Chvátal graph, a 4-regular triangle-free graph with 12 vertices, drawn in a confluent style with only one crossing. The edges of the graph are represented as smooth curves following the tracks of the drawing." /></p>
  </li>
  <li>
    <p><a href="https://www.cbsnews.com/news/ukrainian-girls-math-olympiad-2023-top-european-team/">Ukrainian team wins European Girls’ Mathematical Olympiad</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@rcorless/110237385397799751">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@doctroid@vmst.io/110268197226215150">A seven-piece dissection of a \(3\times 3\times 3\) cube into polycubes with a unique solution</a>, leading to some discussion of what it means for the solution of a dissection puzzle to be unique.</p>
  </li>
  <li>
    <p><a href="https://xkcd.com/2769/">xkcd 2769, “Overlapping Circles”</a> is surprisingly inaccurate <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110279268920990941">\(\mathbb{M}\)</a>).</span> The people interested in <a href="https://en.wikipedia.org/wiki/Vesica_piscis">the overlapping circle shape</a> depicted are not just set theorists and astronomers; they also include geometers, scholars of Gothic architecture, and mystics.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@santoleonardo/110277602536887500">Ancient Roman hyperbolic tessellation from Lugdunum Musee de Lyon (France)</a>.</p>
  </li>
  <li>
    <p><a href="https://dailynous.com/2023/04/27/wiley-removes-goodin-as-editor-of-the-journal-of-political-philosophy/">Wiley fires an editor of a philosophy journal</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/110285871753552037">\(\mathbb{M}\)</a>,</span> <a href="https://retractionwatch.com/2023/04/29/weekend-reads-no-gender-bias-in-academic-science-an-editor-is-fired-foreign-research-fraud-in-australia/">via</a>), apparently for refusing to produce tenfold increases in the number of papers it publishes.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@dimpase/110287215596697015">A bug in a 2008 conference paper on simplified fast modular decomposition of graphs</a> leads to the question: what is the right way to correct the record when old conference papers are found to be buggy?</p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-30T16:59:00Z">Sunday, April 30 2023, 16:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-events.org/2023/04/30/fodsi-workshop-on-the-computational-complexity-of-statistical-inference/'>FODSI Workshop on the Computational Complexity of Statistical Inference</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-events.org'>CS Theory Events</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          June 12-16, 2023 MIT, Building 1, Room 1-190 fodsi.us/ccsi.html FODSI @ MIT is organizing tutorial lectures and a workshop on the Computational Complexity of Statistical Inference The workshop will cover topics pertaining to the computational complexity of statistical inference. The workshop (June 14-16) will be preceded by two days of tutorials (June 12-13) on a &#8230; Continue reading FODSI Workshop on the Computational Complexity of Statistical&#160;Inference<p>By shacharlovett</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          June 12-16, 2023 MIT, Building 1, Room 1-190 https://fodsi.us/ccsi.html FODSI @ MIT is organizing tutorial lectures and a workshop on the Computational Complexity of Statistical Inference The workshop will cover topics pertaining to the computational complexity of statistical inference. The workshop (June 14-16) will be preceded by two days of tutorials (June 12-13) on a &#8230; <a href="https://cstheory-events.org/2023/04/30/fodsi-workshop-on-the-computational-complexity-of-statistical-inference/" class="more-link">Continue reading <span class="screen-reader-text">FODSI Workshop on the Computational Complexity of Statistical&#160;Inference</span></a><p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-30T03:39:36Z">Sunday, April 30 2023, 03:39</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, April 29
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/04/29/dark-silicon/'>Dark Silicon</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Ivan Sutherland played a key role in foundational computer technologies back in the 1970s. He won most if not all the major awards&#8212;the Turing Award and the Kyoto Prize in particular. Now he sees a path for America to claim the mantle in &#8220;micro&#8221; chips. Check out this recent New York Times article on his [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Ivan Sutherland played a key role in foundational computer technologies back in the 1970s. He won most if not all the major awards&#8212;the <a href="https://amturing.acm.org">Turing Award</a> and the <a href="https://www.kyotoprize.org/en/award-field/information-science-en/">Kyoto Prize</a> in particular. </p>
<p>
Now he sees a path for America to claim the mantle in &#8220;micro&#8221; chips. Check out this recent New York Times <a href="https://www.nytimes.com/2023/04/19/technology/ivan-sutherland-superconducting-chips.html">article</a> on his view. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/29/dark-silicon/is-3/" rel="attachment wp-att-21520"><img data-attachment-id="21520" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/29/dark-silicon/is-3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/is.jpeg?fit=194%2C260&amp;ssl=1" data-orig-size="194,260" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="is" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/is.jpeg?fit=194%2C260&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/is.jpeg?fit=194%2C260&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/is.jpeg?resize=194%2C260&#038;ssl=1" alt="" width="194" height="260" class="aligncenter size-full wp-image-21520" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/is.jpeg?w=194&amp;ssl=1 194w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/is.jpeg?resize=150%2C200&amp;ssl=1 150w" sizes="(max-width: 194px) 100vw, 194px" data-recalc-dims="1" /></a></p>
<p><span id="more-21518"></span></p>
<p>
<p><H2> Dark Silicon </H2></p>
<p><p>
His insights are based on what is called <a href="https://en.wikipedia.org/wiki/Dark_silicon">Dark Silicon</a>. If all the billions of transistors on a modern microprocessor chip are used simultaneously, the heat they create will melt the chip. This is <b>bad</b>&#8212;to use a technical term. Thus entire sections of modern chips are shut down and only some of the transistors are working at any time. This reins in energy use but makes the chips far less efficient overall.</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/29/dark-silicon/dark2/" rel="attachment wp-att-21521"><img data-attachment-id="21521" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/29/dark-silicon/dark2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/dark2.jpeg?fit=225%2C224&amp;ssl=1" data-orig-size="225,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="dark2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/dark2.jpeg?fit=225%2C224&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/dark2.jpeg?fit=225%2C224&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/dark2.jpeg?resize=225%2C224&#038;ssl=1" alt="" width="225" height="224" class="aligncenter size-full wp-image-21521" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/dark2.jpeg?w=225&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/dark2.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/dark2.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p>
<p><P><br />
The upshot is that parts of a modern chip must be dark. </p>
<p><H2> A Challenge </H2></p>
<p><p>
As math-oriented types we find this issue quite interesting. See this <a href="https://cseweb.ucsd.edu//~gvenkatesh/Publications_files/paper.pdf">paper</a> for more on the practical issues and <a href="https://www.usenix.org/system/files/login/articles/hardavellas12-04.pdf">this</a> too. But the question could we feel be viewed as a theory type question. </p>
<p>
Just as we in complexity theory study <a href="https://www.hackerearth.com/practice/basic-programming/complexity-analysis/time-and-space-complexity/tutorial/">time and space</a> of computations, can we study them from the view of dark silicon? </p>
<p>
Is there some formal model that forces computations to use dark silicon in some clever way? Just like computations that save space or even time could there be power-smart computations? Ken&#8217;s Buffalo colleague Atri Rudra, his student <a href="https://www.unf.edu/~s.roy/">Swapnoneel Roy</a> (now tenured at the University of North Florida), and Akshat Verma of IBM India created an energy consumption <a href="https://dl.acm.org/doi/10.1145/2422436.2422470">model</a> that addresses various components. Can we solve some problem with a dark silicon algorithm? Is it possible to do this with some clever methods?</p>
<p>
This seems like a possible formal theory problem. It also seems possible that certain encodings could be possible to reduce the cost of computation. Perhaps by encoding the problem in a clever way we could make the dark part of the computation smaller? </p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Is there some hope to study computations from the dark silicon direction? Is this a possible formal question?</p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-29T13:46:44Z">Saturday, April 29 2023, 13:46</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, April 28
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/060'>TR23-060 |  The Planted $k$-SUM Problem: Algorithms, Lower Bounds, Hardness Amplification, and Cryptography | 

	Nikolaj Schwartzbach, 

	Sagnik Saha, 

	Prashant Nalini Vasudevan</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In the average-case $k$-SUM problem, given $r$ integers chosen uniformly at random from $\{0,\ldots,M-1\}$, the objective is to find a set of $k$ numbers that sum to $0$ modulo $M$ (this set is called a ``solution&#39;&#39;). In the related $k$-XOR problem, given $k$ uniformly random Boolean vectors of length $\log{M}$, the objective is to find a set of $k$ of them whose bitwise-XOR is the all-zero vector. Both of these problems have widespread applications in the study of fine-grained complexity and cryptanalysis.
    
The feasibility and complexity of these problems depends on the relative values of $k$, $r$, and $M$. The dense regime of $M \leq r^k$, where solutions exist with high probability, is quite well-understood and we have several non-trivial algorithms and hardness conjectures here. Much less is known about the sparse regime of $M\gg r^k$, where solutions are unlikely to exist. The best answers we have for many fundamental questions here are limited to whatever carries over from the dense or worst-case settings. 

We study the planted $k$-SUM and $k$-XOR problems in the sparse regime. In these problems, a random solution is planted in a randomly generated instance and has to be recovered. As $M$ increases past $r^k$, these planted solutions tend to be the only solutions with increasing probability, potentially becoming easier to find. We show several results about the complexity and applications of these problems.

Conditional Lower Bounds: Assuming established conjectures about the hardness of average-case (non-planted) $k$-SUM when $M = r^k$, we show non-trivial lower bounds on the running time of algorithms for planted $k$-SUM when $r^k\leq M\leq r^{2k}$. We show the same for $k$-XOR as well.

Search-to-Decision Reduction: For any $M&gt;r^k$, suppose there is an algorithm running in time $T$ that can distinguish between a random $k$-SUM instance and a random instance with a planted solution, with success probability $(1-o(1))$. Then, for the same $M$, there is an algorithm running in time $\widetilde{O}(T)$ that solves planted $k$-SUM with constant probability. The same holds for $k$-XOR as well.

Hardness Amplification: For any $M\geq r^k$, if an algorithm running in time $T$ solves planted $k$-XOR with success probability $\Omega(1/\text{polylog}(r))$, then there is an algorithm running in time $\widetilde{O}(T)$ that solves it with probability $(1-o(1))$. We show this by constructing a rapidly mixing random walk over $k$-XOR instances that preserves the planted solution.

Cryptography: For some $M \leq 2^{\mathrm{polylog}(r)}$, the hardness of the $k$-XOR problem can be used to construct Public-Key Encryption (PKE) assuming that the Learning Parity with Noise (LPN) problem over $n$-bit vectors with constant noise rate is hard for $2^{n^{0.01}}$-time algorithms. Previous constructions of PKE from LPN needed either a noise rate of $O(1/\sqrt{n})$, or hardness for $2^{n^{0.5}}$-time algorithms.

Algorithms: For any $M \geq 2^{r^2}$, there is a constant $c$ (independent of $k$) and an algorithm running in time $r^c$ that, for any $k$, solves planted $k$-SUM with success probability $\Omega(1/8^k)$. We get this by showing an average-case reduction from planted $k$-SUM to the Subset Sum problem. For $r^k \leq M \ll 2^{r^2}$, the best known algorithms are still the worst-case $k$-SUM algorithms running in time $r^{\lceil{k/2}\rceil-o(1)}$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In the average-case $k$-SUM problem, given $r$ integers chosen uniformly at random from $\{0,\ldots,M-1\}$, the objective is to find a set of $k$ numbers that sum to $0$ modulo $M$ (this set is called a ``solution&#39;&#39;). In the related $k$-XOR problem, given $k$ uniformly random Boolean vectors of length $\log{M}$, the objective is to find a set of $k$ of them whose bitwise-XOR is the all-zero vector. Both of these problems have widespread applications in the study of fine-grained complexity and cryptanalysis.
    
The feasibility and complexity of these problems depends on the relative values of $k$, $r$, and $M$. The dense regime of $M \leq r^k$, where solutions exist with high probability, is quite well-understood and we have several non-trivial algorithms and hardness conjectures here. Much less is known about the sparse regime of $M\gg r^k$, where solutions are unlikely to exist. The best answers we have for many fundamental questions here are limited to whatever carries over from the dense or worst-case settings. 

We study the planted $k$-SUM and $k$-XOR problems in the sparse regime. In these problems, a random solution is planted in a randomly generated instance and has to be recovered. As $M$ increases past $r^k$, these planted solutions tend to be the only solutions with increasing probability, potentially becoming easier to find. We show several results about the complexity and applications of these problems.

Conditional Lower Bounds: Assuming established conjectures about the hardness of average-case (non-planted) $k$-SUM when $M = r^k$, we show non-trivial lower bounds on the running time of algorithms for planted $k$-SUM when $r^k\leq M\leq r^{2k}$. We show the same for $k$-XOR as well.

Search-to-Decision Reduction: For any $M&gt;r^k$, suppose there is an algorithm running in time $T$ that can distinguish between a random $k$-SUM instance and a random instance with a planted solution, with success probability $(1-o(1))$. Then, for the same $M$, there is an algorithm running in time $\widetilde{O}(T)$ that solves planted $k$-SUM with constant probability. The same holds for $k$-XOR as well.

Hardness Amplification: For any $M\geq r^k$, if an algorithm running in time $T$ solves planted $k$-XOR with success probability $\Omega(1/\text{polylog}(r))$, then there is an algorithm running in time $\widetilde{O}(T)$ that solves it with probability $(1-o(1))$. We show this by constructing a rapidly mixing random walk over $k$-XOR instances that preserves the planted solution.

Cryptography: For some $M \leq 2^{\mathrm{polylog}(r)}$, the hardness of the $k$-XOR problem can be used to construct Public-Key Encryption (PKE) assuming that the Learning Parity with Noise (LPN) problem over $n$-bit vectors with constant noise rate is hard for $2^{n^{0.01}}$-time algorithms. Previous constructions of PKE from LPN needed either a noise rate of $O(1/\sqrt{n})$, or hardness for $2^{n^{0.5}}$-time algorithms.

Algorithms: For any $M \geq 2^{r^2}$, there is a constant $c$ (independent of $k$) and an algorithm running in time $r^c$ that, for any $k$, solves planted $k$-SUM with success probability $\Omega(1/8^k)$. We get this by showing an average-case reduction from planted $k$-SUM to the Subset Sum problem. For $r^k \leq M \ll 2^{r^2}$, the best known algorithms are still the worst-case $k$-SUM algorithms running in time $r^{\lceil{k/2}\rceil-o(1)}$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T20:59:43Z">Friday, April 28 2023, 20:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/058'>TR23-058 |  Explicit Directional Affine Extractors and Improved Hardness for Linear Branching Programs | 

	Xin Li, 

	Yan Zhong</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Affine extractors give some of the best-known lower bounds for various computational models, such as AC$^0$ circuits, parity decision trees, and general Boolean circuits. However, they are not known to give strong lower bounds for read-once branching programs (ROBPs). In a recent work, Gryaznov, Pudl\&#39;{a}k, and Talebanfard (CCC&#39; 22) introduced a stronger version of affine extractors known as directional affine extractors, together with a generalization of ROBPs where each node can make linear queries, and showed that the former implies strong lower bound for a certain type of the latter known as strongly read-once linear branching programs (SROLBPs). Their main result gives explicit constructions of directional affine extractors for entropy $k &gt; 2n/3$, which implies average-case complexity $2^{n/3-o(n)}$ against SROLBPs with exponentially small correlation. A follow-up work by Chattopadhyay and Liao (ECCC&#39; 22) improves the hardness to $2^{n-o(n)}$ at the price of increasing the correlation to polynomially large, via a new connection to sumset extractors introduced by Chattopadhyay and Li (STOC&#39; 16) and explicit constructions of such extractors by Chattopadhyay and Liao (STOC&#39; 22). Both works left open the questions of better constructions of directional affine extractors and improved average-case complexity against SROLBPs in the regime of small correlation.

This paper provides a much more in-depth study of directional affine extractors, SROLBPs, and ROBPs. Our main results include:
(1) formal separation between SROLBP and ROBP, showing that SROLBPs can be exponentially more powerful than ROBPs.
(2) An explicit construction of directional affine extractors with $k=o(n)$ and exponentially small error, which gives average-case complexity $2^{n-o(n)}$ against SROLBPs with exponentially small correlation, thus answering the two open questions raised in previous works.
(3) An explicit function in AC$^0$ that gives average-case complexity $2^{(1-\delta)n}$ against ROBPs with negligible correlation, for any constant $\delta&gt;0$. Previously, the best size lower bound for any function in AC$^0$ against ROBPs is only $2^{\Omega(\sqrt{n})}$.


One of the key ingredients in our constructions is a new linear somewhere condenser for affine sources, which is based on dimension expanders. We conjecture that it also works for general weak random sources, and prove it under the Polynomial Freiman-Ruzsa conjecture. The condenser also leads to an unconditional improvement of the entropy requirement of explicit affine extractors with negligible error.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Affine extractors give some of the best-known lower bounds for various computational models, such as AC$^0$ circuits, parity decision trees, and general Boolean circuits. However, they are not known to give strong lower bounds for read-once branching programs (ROBPs). In a recent work, Gryaznov, Pudl\&#39;{a}k, and Talebanfard (CCC&#39; 22) introduced a stronger version of affine extractors known as directional affine extractors, together with a generalization of ROBPs where each node can make linear queries, and showed that the former implies strong lower bound for a certain type of the latter known as strongly read-once linear branching programs (SROLBPs). Their main result gives explicit constructions of directional affine extractors for entropy $k &gt; 2n/3$, which implies average-case complexity $2^{n/3-o(n)}$ against SROLBPs with exponentially small correlation. A follow-up work by Chattopadhyay and Liao (ECCC&#39; 22) improves the hardness to $2^{n-o(n)}$ at the price of increasing the correlation to polynomially large, via a new connection to sumset extractors introduced by Chattopadhyay and Li (STOC&#39; 16) and explicit constructions of such extractors by Chattopadhyay and Liao (STOC&#39; 22). Both works left open the questions of better constructions of directional affine extractors and improved average-case complexity against SROLBPs in the regime of small correlation.

This paper provides a much more in-depth study of directional affine extractors, SROLBPs, and ROBPs. Our main results include:
(1) formal separation between SROLBP and ROBP, showing that SROLBPs can be exponentially more powerful than ROBPs.
(2) An explicit construction of directional affine extractors with $k=o(n)$ and exponentially small error, which gives average-case complexity $2^{n-o(n)}$ against SROLBPs with exponentially small correlation, thus answering the two open questions raised in previous works.
(3) An explicit function in AC$^0$ that gives average-case complexity $2^{(1-\delta)n}$ against ROBPs with negligible correlation, for any constant $\delta&gt;0$. Previously, the best size lower bound for any function in AC$^0$ against ROBPs is only $2^{\Omega(\sqrt{n})}$.


One of the key ingredients in our constructions is a new linear somewhere condenser for affine sources, which is based on dimension expanders. We conjecture that it also works for general weak random sources, and prove it under the Polynomial Freiman-Ruzsa conjecture. The condenser also leads to an unconditional improvement of the entropy requirement of explicit affine extractors with negligible error.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T20:57:45Z">Friday, April 28 2023, 20:57</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/057'>TR23-057 |  Stretching Demi-Bits and Nondeterministic-Secure Pseudorandomness | 

	Iddo  Tzameret, 

	Luming Zhang</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We develop the theory of cryptographic nondeterministic-secure pseudorandomness beyond the point reached by Rudich&#39;s original work (Rudich 1997), and apply it to draw new consequences in average-case complexity and proof complexity. Specifically, we show the following: 

?*Demi-bit stretch*: Super-bits and demi-bits are variants of cryptographic pseudorandom generators which are secure against nondeterministic statistical tests (Rudich 1997). They were introduced to rule out certain approaches to proving strong complexity lower bounds beyond the limitations set out by the Natural Proofs barrier (Rudich and Razborov 1997).  Whether demi-bits are stretchable at all had been an open problem since their introduction. We answer this question affirmatively by showing that: every demi-bit $b:\{0,1\}^n\to \{0,1\}^{n+1}$ can be stretched into sublinear many demi-bits $b&#39;:\{0,1\}^{n}\to \{0,1\}^{n+n^{c}}$, for every constant $0&lt;c&lt;1$.
    
?*Average-case hardness*: Using work by Santhanam (2020), we apply our results to obtain new  average-case Kolmogorov complexity results: we show that K$^{\rm poly}[n-O(1)]$ is zero-error average-case hard against NP/poly machines iff K$^{\rm poly}[n-o(n)]$ is, where  for a function $s(n):\mathbb{N}\to\mathbb{N}$, K$^{\rm poly}[s(n)]$ denotes the languages of all strings $x\in\{0,1\}^n$ for which there are (fixed) poly-time Turing machines of description-length at most $s(n)$ that output $x$.   

?*Characterising super-bits by nondeterministic unpredictability:* In the deterministic setting, Yao proved that super-polynomial hardness of pseudorandom generators is equivalent to (&quot;next-bit&quot;) unpredictability. Unpredictability roughly means that given any strict prefix of a random string, it is infeasible to predict the next bit. We initiate the study of unpredictability beyond the deterministic setting (in the cryptographic regime), and characterise the nondeterministic hardness of generators from an unpredictability perspective. Specifically, we propose four stronger notions of unpredictability:
NP/poly-unpredictability, coNP/poly-unpredictability, $\cap$-unpredictability and $\cup$-unpredictability, and show that super-polynomial nondeterministic hardness of generators lies between $\cap$-unpredictability and $\cup$-unpredictability.

?*Characterising super-bits by nondeterministic hard-core predicates:* We introduce a nondeterministic variant of hard-core predicates, called *super-core* predicates. We show that the existence of a super-bit is equivalent to the existence of a super-core of some non-shrinking function. This serves as an analogue of the equivalence between the existence of a strong pseudorandom generator and the existence of a hard-core of some one-way function (Goldreich and Levin 1989, Hastad, Impagliazzo, Levin and Luby 1999), and provides a first alternative characterisation of super-bits. We also prove that a certain class of functions, which may have hard-cores, cannot possess any super-core.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We develop the theory of cryptographic nondeterministic-secure pseudorandomness beyond the point reached by Rudich&#39;s original work (Rudich 1997), and apply it to draw new consequences in average-case complexity and proof complexity. Specifically, we show the following: 

?*Demi-bit stretch*: Super-bits and demi-bits are variants of cryptographic pseudorandom generators which are secure against nondeterministic statistical tests (Rudich 1997). They were introduced to rule out certain approaches to proving strong complexity lower bounds beyond the limitations set out by the Natural Proofs barrier (Rudich and Razborov 1997).  Whether demi-bits are stretchable at all had been an open problem since their introduction. We answer this question affirmatively by showing that: every demi-bit $b:\{0,1\}^n\to \{0,1\}^{n+1}$ can be stretched into sublinear many demi-bits $b&#39;:\{0,1\}^{n}\to \{0,1\}^{n+n^{c}}$, for every constant $0&lt;c&lt;1$.
    
?*Average-case hardness*: Using work by Santhanam (2020), we apply our results to obtain new  average-case Kolmogorov complexity results: we show that K$^{\rm poly}[n-O(1)]$ is zero-error average-case hard against NP/poly machines iff K$^{\rm poly}[n-o(n)]$ is, where  for a function $s(n):\mathbb{N}\to\mathbb{N}$, K$^{\rm poly}[s(n)]$ denotes the languages of all strings $x\in\{0,1\}^n$ for which there are (fixed) poly-time Turing machines of description-length at most $s(n)$ that output $x$.   

?*Characterising super-bits by nondeterministic unpredictability:* In the deterministic setting, Yao proved that super-polynomial hardness of pseudorandom generators is equivalent to (&quot;next-bit&quot;) unpredictability. Unpredictability roughly means that given any strict prefix of a random string, it is infeasible to predict the next bit. We initiate the study of unpredictability beyond the deterministic setting (in the cryptographic regime), and characterise the nondeterministic hardness of generators from an unpredictability perspective. Specifically, we propose four stronger notions of unpredictability:
NP/poly-unpredictability, coNP/poly-unpredictability, $\cap$-unpredictability and $\cup$-unpredictability, and show that super-polynomial nondeterministic hardness of generators lies between $\cap$-unpredictability and $\cup$-unpredictability.

?*Characterising super-bits by nondeterministic hard-core predicates:* We introduce a nondeterministic variant of hard-core predicates, called *super-core* predicates. We show that the existence of a super-bit is equivalent to the existence of a super-core of some non-shrinking function. This serves as an analogue of the equivalence between the existence of a strong pseudorandom generator and the existence of a hard-core of some one-way function (Goldreich and Levin 1989, Hastad, Impagliazzo, Levin and Luby 1999), and provides a first alternative characterisation of super-bits. We also prove that a certain class of functions, which may have hard-cores, cannot possess any super-core.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T20:57:05Z">Friday, April 28 2023, 20:57</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/04/28/tcs-talk-wednesday-may-3-scott-aaronson-ut-austin/'>TCS+ talk: Wednesday, May 3 — Scott Aaronson, UT Austin</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, May 3rd at 2:30 PM Eastern Time (11:30 AM Pacific Time, 20:30 Central European Time, 18:30 UTC: note the unusual time!). Scott Aaronson from UT Austin will speak about &#8220;Certified Randomness from Quantum Supremacy&#8221; (abstract below). You can reserve a spot as an individual or [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, May 3rd at 2:30 PM Eastern Time (11:30 AM Pacific Time, 20:30 Central European Time, 18:30 UTC: <strong>note the unusual time!</strong>). <strong>Scott Aaronson</strong> from UT Austin will speak about &#8220;<em>Certified Randomness from Quantum Supremacy</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: We propose an application for near-term quantum devices: namely, generating cryptographically certified random bits, to use (for example) in proof-of-stake cryptocurrencies. Our protocol repurposes the existing &#8220;quantum supremacy&#8221; experiments, based on random circuit sampling, that Google and USTC have successfully carried out starting in 2019. We show that, whenever the outputs of these experiments pass the now-standard Linear Cross-Entropy Benchmark (LXEB), under plausible hardness assumptions they necessarily contain Ω(n) min-entropy, where n is the number of qubits. To achieve a net gain in randomness, we use a small random seed to produce pseudorandom challenge circuits. In response to the challenge circuits, the quantum computer generates output strings that, after verification, can then be fed into a randomness extractor to produce certified nearly-uniform bits &#8212; thereby &#8220;bootstrapping&#8221; from pseudorandomness to genuine randomness. We prove our protocol sound in two senses: (i) under a hardness assumption called Long List Quantum Supremacy Verification, which we justify in the random oracle model, and (ii) unconditionally in the random oracle model against an eavesdropper who could share arbitrary entanglement with the device. (Note that our protocol&#8217;s output is unpredictable even to a computationally unbounded adversary who can see the random oracle.) Currently, the central drawback of our protocol is the exponential cost of verification, which in practice will limit its implementation to at most n∼60 qubits, a regime where attacks are expensive but not impossible. Modulo that drawback, our protocol appears to be the only practical application of quantum computing that both requires a QC and is physically realizable today.</p>
<p>Joint work with Shih-Han Hung. To appear in STOC&#8217;2023.<br />
<a href="https://arxiv.org/abs/2303.01625">https://arxiv.org/abs/2303.01625</a></p></blockquote>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T10:27:46Z">Friday, April 28 2023, 10:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7266'>Five Worlds of AI (a joint post with Boaz Barak)</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Artificial intelligence has made incredible progress in the last decade, but in one crucial aspect, it still lags behind the theoretical computer science of the 1990s: namely, there is no essay describing five potential worlds that we could live in and giving each one of them whimsical names.&#160; In other words, no one has done [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="https://www.scottaaronson.com/fiveworlds.jpg" alt=""/></figure></div>


<p>Artificial intelligence has made incredible progress in the last decade, but in one crucial aspect, it still lags behind the theoretical computer science of the 1990s: namely, there is no <a href="https://www.quantamagazine.org/which-computational-universe-do-we-live-in-20220418/">essay describing five potential worlds that we could live in and giving each one of them whimsical names</a>.&nbsp; In other words, no one has done for AI what Russell Impagliazzo did for complexity theory in 1995, when he defined the five worlds Algorithmica, Heuristica, Pessiland, Minicrypt, and Cryptomania, corresponding to five possible resolutions of the P vs. NP problem along with the central unsolved problems of cryptography.</p>



<p>In this blog post, we&#8212;Scott and Boaz&#8212;aim to remedy this gap.  Specifically, we consider 5 possible scenarios for how AI will evolve in the future.&nbsp; (Incidentally, it was at a <a href="http://dimacs.rutgers.edu/archive/Workshops/Cryptography/program.html">2009 workshop</a> devoted to Impagliazzo’s five worlds co-organized by Boaz that Scott met his now wife, complexity theorist <a href="https://www.cs.utexas.edu/~danama/">Dana Moshkovitz</a>.&nbsp; We hope civilization will continue for long enough that someone in the future could meet their soulmate, or neuron-mate,&nbsp;at a future workshop about <em>our</em> five worlds.)</p>



<p>Like in <a href="https://www.karlin.mff.cuni.cz/~krajicek/ri5svetu.pdf">Impagliazzo’s 1995 paper</a> on the five potential worlds of the difficulty of NP problems, we will not try to be exhaustive but rather concentrate on extreme cases.&nbsp; It’s possible that we’ll end up in a mixture of worlds or a situation not described by any of the worlds.&nbsp; Indeed, one crucial difference between our setting and Impagliazzo’s, is that in the complexity case, the worlds corresponded to concrete (and mutually exclusive) mathematical conjectures.&nbsp; So in some sense, the question wasn’t “which world <em>will</em> we live in?” but “which world have we Platonically <em>always</em> lived in, without knowing it?”&nbsp; In contrast, the impact of AI will be a complex mix of mathematical bounds, computational capabilities, human discoveries, and social and legal issues. Hence, the worlds we describe depend on more than just the fundamental capabilities and limitations of artificial intelligence, and humanity could also shift from one of these worlds to another over time.</p>



<p>Without further ado, we name our five worlds “<strong>AI-Fizzle,”</strong> <strong>“Futurama,”</strong> <strong>”AI-Dystopia,”</strong> <strong>“Singularia,”</strong> and <strong>“Paperclipalypse.”</strong>&nbsp; In this essay, we don’t try to assign probabilities to these scenarios; we merely sketch their assumptions and technical and social consequences. We hope that by making assumptions explicit, we can help ground the debate on the various risks around AI.</p>



<p><strong>AI-Fizzle. </strong>In this scenario, AI “runs out of steam” fairly soon. AI still has a significant impact on the world (so it’s not the same as a “cryptocurrency fizzle”), but relative to current expectations, this would be considered a disappointment.&nbsp; Rather than the industrial or computer revolutions, AI might be compared in this case to nuclear power: people were initially thrilled about the seemingly limitless potential, but decades later, that potential remains mostly unrealized.&nbsp; With nuclear power, though, many would argue that the potential went unrealized mostly for sociopolitical rather than technical reasons.&nbsp; Could AI also fizzle by political fiat?</p>



<p>Regardless of the answer, another possibility is that costs (in data and computation) scale up so rapidly as a function of performance and reliability that AI is not cost-effective to apply in many domains. That is, it could be that for most jobs, humans will still be more reliable and energy-efficient (we don’t normally think of <em>low wattage</em> as being key to human specialness, but it might turn out that way!).&nbsp; So, like nuclear fusion, an AI which yields dramatically more value than the resources needed to build and deploy it might always remain a couple of decades in the future.&nbsp; In this scenario, AI would replace and enhance some fraction of human jobs and improve productivity, but the 21st century would not be the “century of AI,” and AI’s impact on society would be limited for both good and bad.</p>



<p><strong>Futurama.</strong> In this scenario, AI unleashes a revolution that’s entirely comparable to the scientific, industrial, or information revolutions (but “merely” those).  AI systems grow significantly in capabilities and perform many of the tasks currently performed by human experts at a small fraction of the cost, in some domains <em>superhumanly</em>.  However, AI systems are still used as <em>tools</em> by humans, and except for a few fringe thinkers, no one treats them as sentient.  AI easily passes the Turing test, can prove hard theorems, and can generate entertaining content (as well as deepfakes). But humanity gets used to that, just like we got used to computers creaming us in chess, translating text, and generating special effects in movies.  Most people no more feel inferior to their AI than they feel inferior to their car because it runs faster.  In this scenario, people will likely anthropomorphize AI <em>less</em> over time (as happened with digital computers themselves).  In <strong>“Futurama,”</strong> AI will, like any revolutionary technology, be used for both good and bad.  But as with prior major technological revolutions, on the whole, AI will have a large positive impact on humanity.  AI will be used to reduce poverty and ensure that more of humanity has access to food, healthcare, education, and economic opportunities.  In <strong>“Futurama,”</strong> AI systems will sometimes cause harm, but the vast majority of these failures will be due to human negligence or maliciousness.  Some AI systems might be so complex that it would be best to model them as potentially behaving  “adversarially,” and part of the practice of deploying AIs responsibly would be to ensure an “operating envelope” that limits their potential damage even under adversarial failures. </p>



<p><strong>AI-Dystopia.</strong> The technical assumptions of <strong>“AI-Dystopia”</strong> are similar to those of <strong>“Futurama,”</strong> but the upshot could hardly be more different.&nbsp; Here, again, AI unleashes a revolution on the scale of the industrial or computer revolutions, but the change is markedly for the worse.&nbsp; AI greatly increases the scale of surveillance by government and private corporations.&nbsp; It causes massive job losses while enriching a tiny elite.&nbsp; It entrenches society’s existing inequalities and biases.&nbsp; And it takes away a central tool against oppression: namely, the ability of humans to refuse or subvert orders.</p>



<p>Interestingly, it’s even possible that <em>the same future</em> could be characterized as <strong>Futurama</strong> by some people and as <strong>AI-Dystopia</strong> by others–just like how some people emphasize how our <em>current</em> technological civilization has lifted billions out of poverty into a standard of living unprecedented in human history, while others focus on the still existing (and in some cases rising) inequalities and suffering, and consider it a neoliberal capitalist dystopia.</p>



<p><strong>Singularia.</strong>  Here AI breaks out of the current paradigm, where increasing capabilities require ever-growing resources of data and computation, and no longer needs human data or human-provided hardware and energy to become stronger at an ever-increasing pace.  AIs improve their own intellectual capabilities, including by developing new science, and (whether by deliberate design or happenstance) they act as goal-oriented agents in the physical world.  They can effectively be thought of as an alien civilization–or perhaps as a new species, which is to us as we were to <em>Homo erectus</em>.</p>



<p>Fortunately, though (and again, whether by careful design or just as a byproduct of their human origins), the AIs act to us like benevolent gods and lead us to an “AI utopia.”&nbsp; They solve our material problems for us, giving us unlimited abundance and presumably virtual-reality adventures of our choosing.&nbsp; (Though maybe, as in <em>The Matrix</em>, the AIs will discover that humans need some conflict, and we will all live in a simulation of 2020’s Twitter, constantly dunking on one another…)&nbsp;</p>



<p><strong>Paperclipalypse.</strong>&nbsp; In <strong>“Paperclipalypse”</strong> or “AI Doom,” we again think of future AIs as a superintelligent “alien race” that doesn’t need humanity for its own development.&nbsp; Here, though, the AIs are either actively opposed to human existence or else indifferent to it in a way that causes our extinction as a byproduct.&nbsp; In this scenario, AIs do not develop a notion of morality comparable to ours or even a notion that keeping a diversity of species and ensuring humans don’t go extinct might be useful to them in the long run.&nbsp; Rather, the interaction between AI and Homo sapiens ends about the same way that the interaction between Homo sapiens and Neanderthals ended.&nbsp;</p>



<p>In fact, the canonical depictions of such a scenario imagine an interaction that is much more abrupt than our brush with the Neanderthals. The idea is that, perhaps because they originated through some optimization procedure, AI systems will have some strong but weirdly-specific goal (a la “maximizing paperclips”), for which the continued existence of humans is, at best, a hindrance.&nbsp; So the AIs quickly play out the scenarios and, in a matter of milliseconds, decide that the optimal solution is to kill all humans, taking a few extra milliseconds to make a plan for that and execute it.&nbsp; If conditions are not yet ripe for executing their plan, the AIs pretend to be docile tools, as in the <strong>“Futurama”</strong> scenario, waiting for the right time to strike.&nbsp; In this scenario, self-improvement happens so quickly that humans might not even notice it.&nbsp; There need be no intermediate stage in which an AI “merely” kills a few thousand humans, raising 9/11-type alarm bells.</p>



<p><strong>Regulations</strong>. The practical impact of AI regulations depends, in large part, on which scenarios we consider most likely.&nbsp; Regulation is not terribly important in the<strong> “AI Fizzle”</strong> scenario where AI, well, fizzles.&nbsp; In “<strong>Futurama,”</strong> regulations would be aimed at ensuring that on balance, AI is used more for good than for bad, and that the world doesn’t devolve into <strong>“AI Dystopia.”</strong>&nbsp; The latter goal requires anti-trust and open-science regulations to ensure that power is not concentrated in a few corporations or governments.&nbsp; Thus, regulations are needed to <em>democratize</em> AI development more than to <em>restrict</em> it.&nbsp; This doesn’t mean that AI would be completely unregulated.&nbsp; It might be treated somewhat similarly to drugs—something that can have complex effects and needs to undergo trials before mass deployment.&nbsp; There would also be regulations aimed at reducing the chance of “bad actors” (whether other nations or individuals) getting access to cutting-edge AIs, but probably the bulk of the effort would be at increasing the chance of thwarting them (e.g., using AI to detect AI-generated misinformation, or using AI to harden systems against AI-aided hackers).&nbsp; This is similar to how most academic experts believe cryptography should be regulated (and how it <em>is</em> largely regulated these days in most democratic countries): it’s a technology that can be used for both good and bad, but the cost of restricting its access to regular citizens outweighs the benefits.&nbsp; However, as we do with security exploits today, we might restrict or delay public releases of AI systems to some extent.</p>



<p>To whatever extent we foresee <strong>“Singularia”</strong> or <strong>“Paperclipalypse,”</strong> however, regulations play a completely different role.&nbsp; If we knew we were headed for <strong>“Singularia,”</strong> then presumably regulations would be superfluous, except perhaps to try to accelerate the development of AIs!&nbsp; Meanwhile, if one accepts the assumptions of <strong>“Paperclipalypse,”</strong> any regulations other than the most draconian might be futile.&nbsp; If, in the near future, almost anyone will be able to spend a few billion dollars to build a recursively self-improving AI that might turn into a superintelligent world-destroying agent, and moreover (unlike with nuclear weapons) they won’t need exotic materials to do so, then it’s hard to see how to forestall the apocalypse, except perhaps via a worldwide, militarily enforced agreement to “<a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">shut it all down</a>,” as Eliezer Yudkowsky indeed now explicitly advocates.&nbsp; “Ordinary” regulations could, at best, delay the end by a short amount–given the current pace of AI advances, perhaps not more than a few years.&nbsp; Thus, regardless of how likely one considers this scenario, one might want to focus more on the other scenarios for methodological reasons alone!</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:37:27Z">Friday, April 28 2023, 00:37</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13816'>Verifying linear temporal specifications of constant-rate multi-mode systems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Blondin, Philip Offtermatt, Alex Sansfa&#xe7;on-Buchanan</p><p>Constant-rate multi-mode systems (MMS) are hybrid systems with finitely many
modes and real-valued variables that evolve over continuous time according to
mode-specific constant rates. We introduce a variant of linear temporal logic
(LTL) for MMS, and we investigate the complexity of the model-checking problem
for syntactic fragments of LTL. We obtain a complexity landscape where each
fragment is either P-complete, NP-complete or undecidable. These results
generalize and unify several results on MMS and continuous counter systems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blondin_M/0/1/0/all/0/1">Michael Blondin</a>, <a href="http://arxiv.org/find/cs/1/au:+Offtermatt_P/0/1/0/all/0/1">Philip Offtermatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Sansfacon_Buchanan_A/0/1/0/all/0/1">Alex Sansfa&#xe7;on-Buchanan</a></p><p>Constant-rate multi-mode systems (MMS) are hybrid systems with finitely many
modes and real-valued variables that evolve over continuous time according to
mode-specific constant rates. We introduce a variant of linear temporal logic
(LTL) for MMS, and we investigate the complexity of the model-checking problem
for syntactic fragments of LTL. We obtain a complexity landscape where each
fragment is either P-complete, NP-complete or undecidable. These results
generalize and unify several results on MMS and continuous counter systems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14058'>A Parameterized Theory of PAC Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Cornelius Brand, Robert Ganian, Kirill Simonov</p><p>Probably Approximately Correct (i.e., PAC) learning is a core concept of
sample complexity theory, and efficient PAC learnability is often seen as a
natural counterpart to the class P in classical computational complexity. But
while the nascent theory of parameterized complexity has allowed us to push
beyond the P-NP ``dichotomy'' in classical computational complexity and
identify the exact boundaries of tractability for numerous problems, there is
no analogue in the domain of sample complexity that could push beyond efficient
PAC learnability.
</p>
<p>As our core contribution, we fill this gap by developing a theory of
parameterized PAC learning which allows us to shed new light on several recent
PAC learning results that incorporated elements of parameterized complexity.
Within the theory, we identify not one but two notions of fixed-parameter
learnability that both form distinct counterparts to the class FPT -- the core
concept at the center of the parameterized complexity paradigm -- and develop
the machinery required to exclude fixed-parameter learnability. We then
showcase the applications of this theory to identify refined boundaries of
tractability for CNF and DNF learning as well as for a range of learning
problems on graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brand_C/0/1/0/all/0/1">Cornelius Brand</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganian_R/0/1/0/all/0/1">Robert Ganian</a>, <a href="http://arxiv.org/find/cs/1/au:+Simonov_K/0/1/0/all/0/1">Kirill Simonov</a></p><p>Probably Approximately Correct (i.e., PAC) learning is a core concept of
sample complexity theory, and efficient PAC learnability is often seen as a
natural counterpart to the class P in classical computational complexity. But
while the nascent theory of parameterized complexity has allowed us to push
beyond the P-NP ``dichotomy'' in classical computational complexity and
identify the exact boundaries of tractability for numerous problems, there is
no analogue in the domain of sample complexity that could push beyond efficient
PAC learnability.
</p>
<p>As our core contribution, we fill this gap by developing a theory of
parameterized PAC learning which allows us to shed new light on several recent
PAC learning results that incorporated elements of parameterized complexity.
Within the theory, we identify not one but two notions of fixed-parameter
learnability that both form distinct counterparts to the class FPT -- the core
concept at the center of the parameterized complexity paradigm -- and develop
the machinery required to exclude fixed-parameter learnability. We then
showcase the applications of this theory to identify refined boundaries of
tractability for CNF and DNF learning as well as for a range of learning
problems on graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14145'>Multiplicity Problems on Algebraic Series and Context-Free Grammars</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nikhil Balaji, Lorenzo Clemente, Klara Nosan, Mahsa Shirmohammadi, James Worrell</p><p>In this paper we obtain complexity bounds for computational problems on
algebraic power series over several commuting variables. The power series are
specified by systems of polynomial equations: a formalism closely related to
weighted context-free grammars. We focus on three problems -- decide whether a
given algebraic series is identically zero, determine whether all but finitely
many coefficients are zero, and compute the coefficient of a specific monomial.
We relate these questions to well-known computational problems on arithmetic
circuits and thereby show that all three problems lie in the counting
hierarchy. Our main result improves the best known complexity bound on deciding
zeroness of an algebraic series. This problem is known to lie in PSPACE by
reduction to the decision problem for the existential fragment of the theory of
real closed fields. Here we show that the problem lies in the counting
hierarchy by reduction to the problem of computing the degree of a polynomial
given by an arithmetic circuit. As a corollary we obtain new complexity bounds
on multiplicity equivalence of context-free grammars restricted to a bounded
language, language inclusion of a nondeterministic finite automaton in an
unambiguous context-free grammar, and language inclusion of a non-deterministic
context-free grammar in an unambiguous finite automaton.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Balaji_N/0/1/0/all/0/1">Nikhil Balaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Clemente_L/0/1/0/all/0/1">Lorenzo Clemente</a>, <a href="http://arxiv.org/find/cs/1/au:+Nosan_K/0/1/0/all/0/1">Klara Nosan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shirmohammadi_M/0/1/0/all/0/1">Mahsa Shirmohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Worrell_J/0/1/0/all/0/1">James Worrell</a></p><p>In this paper we obtain complexity bounds for computational problems on
algebraic power series over several commuting variables. The power series are
specified by systems of polynomial equations: a formalism closely related to
weighted context-free grammars. We focus on three problems -- decide whether a
given algebraic series is identically zero, determine whether all but finitely
many coefficients are zero, and compute the coefficient of a specific monomial.
We relate these questions to well-known computational problems on arithmetic
circuits and thereby show that all three problems lie in the counting
hierarchy. Our main result improves the best known complexity bound on deciding
zeroness of an algebraic series. This problem is known to lie in PSPACE by
reduction to the decision problem for the existential fragment of the theory of
real closed fields. Here we show that the problem lies in the counting
hierarchy by reduction to the problem of computing the degree of a polynomial
given by an arithmetic circuit. As a corollary we obtain new complexity bounds
on multiplicity equivalence of context-free grammars restricted to a bounded
language, language inclusion of a nondeterministic finite automaton in an
unambiguous context-free grammar, and language inclusion of a non-deterministic
context-free grammar in an unambiguous finite automaton.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13896'>Structure-Aware Lower Bounds and Broadening the Horizon of Tractability for QBF</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Johannes K. Fichte, Robert Ganian, Markus Hecher, Friedrich Slivovsky, Sebastian Ordyniak</p><p>The QSAT problem, which asks to evaluate a quantified Boolean formula (QBF),
is of fundamental interest in approximation, counting, decision, and
probabilistic complexity and is also considered the prototypical PSPACEcomplete
problem. As such, it has previously been studied under various structural
restrictions (parameters), most notably parameterizations of the primal graph
representation of instances. Indeed, it is known that QSAT remains
PSPACE-complete even when restricted to instances with constant treewidth of
the primal graph, but the problem admits a double-exponential fixed-parameter
algorithm parameterized by the vertex cover number (primal graph). However,
prior works have left a gap in our understanding of the complexity of QSAT when
viewed from the perspective of other natural representations of instances, most
notably via incidence graphs. In this paper, we develop structure-aware
reductions which allow us to obtain essentially tight lower bounds for highly
restricted instances of QSAT, including instances whose incidence graphs have
bounded treedepth or feedback vertex number. We complement these lower bounds
with novel algorithms for QSAT which establish a nearly-complete picture of the
problem's complexity under standard graph-theoretic parameterizations. We also
show implications for other natural graph representations, and obtain novel
upper as well as lower bounds for QSAT under more fine-grained
parameterizations of the primal graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fichte_J/0/1/0/all/0/1">Johannes K. Fichte</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganian_R/0/1/0/all/0/1">Robert Ganian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hecher_M/0/1/0/all/0/1">Markus Hecher</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivovsky_F/0/1/0/all/0/1">Friedrich Slivovsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Ordyniak_S/0/1/0/all/0/1">Sebastian Ordyniak</a></p><p>The QSAT problem, which asks to evaluate a quantified Boolean formula (QBF),
is of fundamental interest in approximation, counting, decision, and
probabilistic complexity and is also considered the prototypical PSPACEcomplete
problem. As such, it has previously been studied under various structural
restrictions (parameters), most notably parameterizations of the primal graph
representation of instances. Indeed, it is known that QSAT remains
PSPACE-complete even when restricted to instances with constant treewidth of
the primal graph, but the problem admits a double-exponential fixed-parameter
algorithm parameterized by the vertex cover number (primal graph). However,
prior works have left a gap in our understanding of the complexity of QSAT when
viewed from the perspective of other natural representations of instances, most
notably via incidence graphs. In this paper, we develop structure-aware
reductions which allow us to obtain essentially tight lower bounds for highly
restricted instances of QSAT, including instances whose incidence graphs have
bounded treedepth or feedback vertex number. We complement these lower bounds
with novel algorithms for QSAT which establish a nearly-complete picture of the
problem's complexity under standard graph-theoretic parameterizations. We also
show implications for other natural graph representations, and obtain novel
upper as well as lower bounds for QSAT under more fine-grained
parameterizations of the primal graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13915'>Improved Stabilizer Estimation via Bell Difference Sampling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sabee Grewal, Vishnu Iyer, William Kretschmer, Daniel Liang</p><p>We study the complexity of learning quantum states in various models with
respect to the stabilizer formalism and obtain the following results:
</p>
<p>- We prove that $\Omega(n)$ $T$-gates are necessary for any Clifford+$T$
circuit to prepare computationally pseudorandom quantum states, an exponential
improvement over the previously known bound. This bound is asymptotically tight
if linear-time quantum-secure pseudorandom functions exist.
</p>
<p>- Given an $n$-qubit pure quantum state $|\psi\rangle$ that has fidelity at
least $\tau$ with some stabilizer state, we give an algorithm that outputs a
succinct description of a stabilizer state that witnesses fidelity at least
$\tau - \varepsilon$. The algorithm uses $O(n/(\varepsilon^2\tau^4))$ samples
and $\exp\left(O(n/\tau^4)\right) / \varepsilon^2$ time. In the regime of
$\tau$ constant, this algorithm estimates stabilizer fidelity substantially
faster than the na\"ive $\exp(O(n^2))$-time brute-force algorithm over all
stabilizer states.
</p>
<p>- We improve the soundness analysis of the stabilizer state property testing
algorithm due to Gross, Nezami, and Walter [Comms. Math. Phys. 385 (2021)]. As
an application, we exhibit a tolerant property testing algorithm for stabilizer
states.
</p>
<p>The underlying algorithmic primitive in all of our results is Bell difference
sampling. To prove our results, we establish and/or strengthen connections
between Bell difference sampling, symplectic Fourier analysis, and graph
theory.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Grewal_S/0/1/0/all/0/1">Sabee Grewal</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Iyer_V/0/1/0/all/0/1">Vishnu Iyer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kretschmer_W/0/1/0/all/0/1">William Kretschmer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Liang_D/0/1/0/all/0/1">Daniel Liang</a></p><p>We study the complexity of learning quantum states in various models with
respect to the stabilizer formalism and obtain the following results:
</p>
<p>- We prove that $\Omega(n)$ $T$-gates are necessary for any Clifford+$T$
circuit to prepare computationally pseudorandom quantum states, an exponential
improvement over the previously known bound. This bound is asymptotically tight
if linear-time quantum-secure pseudorandom functions exist.
</p>
<p>- Given an $n$-qubit pure quantum state $|\psi\rangle$ that has fidelity at
least $\tau$ with some stabilizer state, we give an algorithm that outputs a
succinct description of a stabilizer state that witnesses fidelity at least
$\tau - \varepsilon$. The algorithm uses $O(n/(\varepsilon^2\tau^4))$ samples
and $\exp\left(O(n/\tau^4)\right) / \varepsilon^2$ time. In the regime of
$\tau$ constant, this algorithm estimates stabilizer fidelity substantially
faster than the na\"ive $\exp(O(n^2))$-time brute-force algorithm over all
stabilizer states.
</p>
<p>- We improve the soundness analysis of the stabilizer state property testing
algorithm due to Gross, Nezami, and Walter [Comms. Math. Phys. 385 (2021)]. As
an application, we exhibit a tolerant property testing algorithm for stabilizer
states.
</p>
<p>The underlying algorithmic primitive in all of our results is Bell difference
sampling. To prove our results, we establish and/or strengthen connections
between Bell difference sampling, symplectic Fourier analysis, and graph
theory.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14295'>On Solution Discovery via Reconfiguration</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael R. Fellows, Mario Grobler, Nicole Megow, Amer E. Mouawad, Vijayaragunathan Ramamoorthi, Frances A. Rosamond, Daniel Schmand, Sebastian Siebertz</p><p>The dynamics of real-world applications and systems require efficient methods
for improving infeasible solutions or restoring corrupted ones by making
modifications to the current state of a system in a restricted way. We propose
a new framework of solution discovery via reconfiguration for constructing a
feasible solution for a given problem by executing a sequence of small
modifications starting from a given state. Our framework integrates and
formalizes different aspects of classical local search, reoptimization, and
combinatorial reconfiguration. We exemplify our framework on a multitude of
fundamental combinatorial problems, namely Vertex Cover, Independent Set,
Dominating Set, and Coloring. We study the classical as well as the
parameterized complexity of the solution discovery variants of those problems
and explore the boundary between tractable and intractable instances.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fellows_M/0/1/0/all/0/1">Michael R. Fellows</a>, <a href="http://arxiv.org/find/cs/1/au:+Grobler_M/0/1/0/all/0/1">Mario Grobler</a>, <a href="http://arxiv.org/find/cs/1/au:+Megow_N/0/1/0/all/0/1">Nicole Megow</a>, <a href="http://arxiv.org/find/cs/1/au:+Mouawad_A/0/1/0/all/0/1">Amer E. Mouawad</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramamoorthi_V/0/1/0/all/0/1">Vijayaragunathan Ramamoorthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosamond_F/0/1/0/all/0/1">Frances A. Rosamond</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmand_D/0/1/0/all/0/1">Daniel Schmand</a>, <a href="http://arxiv.org/find/cs/1/au:+Siebertz_S/0/1/0/all/0/1">Sebastian Siebertz</a></p><p>The dynamics of real-world applications and systems require efficient methods
for improving infeasible solutions or restoring corrupted ones by making
modifications to the current state of a system in a restricted way. We propose
a new framework of solution discovery via reconfiguration for constructing a
feasible solution for a given problem by executing a sequence of small
modifications starting from a given state. Our framework integrates and
formalizes different aspects of classical local search, reoptimization, and
combinatorial reconfiguration. We exemplify our framework on a multitude of
fundamental combinatorial problems, namely Vertex Cover, Independent Set,
Dominating Set, and Coloring. We study the classical as well as the
parameterized complexity of the solution discovery variants of those problems
and explore the boundary between tractable and intractable instances.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13984'>An FPTAS for Budgeted Laminar Matroid Independent Set</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ilan Doron-Arad, Ariel Kulik, Hadas Shachnai</p><p>We study the budgeted laminar matroid independent set problem. The input is a
ground set, where each element has a cost and a non-negative profit, along with
a laminar matroid over the elements and a budget. The goal is to select a
maximum profit independent set of the matroid whose total cost is bounded by
the budget. Several well known special cases, where we have, e.g., no matroid
constraint (the classic knapsack problem) or a uniform matroid constraint
(knapsack with a cardinality constraint), admit a fully polynomial-time
approximation scheme (FPTAS). In contrast, the budgeted matroid independent set
(BMI) problem with a general matroid has an efficient polynomial-time
approximation scheme (EPTAS) but does not admit an FPTAS. This implies an EPTAS
for our problem, which is the best known result prior to this work.
</p>
<p>We present an FPTAS for budgeted laminar matroid independent set, improving
the previous EPTAS for this matroid family and generalizing the FPTAS known for
knapsack with a cardinality constraint and multiple-choice knapsack. Our scheme
is based on a simple dynamic program which utilizes the tree-like structure of
laminar matroids.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Doron_Arad_I/0/1/0/all/0/1">Ilan Doron-Arad</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulik_A/0/1/0/all/0/1">Ariel Kulik</a>, <a href="http://arxiv.org/find/cs/1/au:+Shachnai_H/0/1/0/all/0/1">Hadas Shachnai</a></p><p>We study the budgeted laminar matroid independent set problem. The input is a
ground set, where each element has a cost and a non-negative profit, along with
a laminar matroid over the elements and a budget. The goal is to select a
maximum profit independent set of the matroid whose total cost is bounded by
the budget. Several well known special cases, where we have, e.g., no matroid
constraint (the classic knapsack problem) or a uniform matroid constraint
(knapsack with a cardinality constraint), admit a fully polynomial-time
approximation scheme (FPTAS). In contrast, the budgeted matroid independent set
(BMI) problem with a general matroid has an efficient polynomial-time
approximation scheme (EPTAS) but does not admit an FPTAS. This implies an EPTAS
for our problem, which is the best known result prior to this work.
</p>
<p>We present an FPTAS for budgeted laminar matroid independent set, improving
the previous EPTAS for this matroid family and generalizing the FPTAS known for
knapsack with a cardinality constraint and multiple-choice knapsack. Our scheme
is based on a simple dynamic program which utilizes the tree-like structure of
laminar matroids.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13996'>A barrier for further approximating Sorting By Transpositions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Luiz Augusto G. da Silva, Luis Antonio B. Kowada, Maria Em&#xed;lia M. T. Walter</p><p>The Transposition Distance Problem (TDP) is a classical problem in genome
rearrangements which seeks to determine the minimum number of transpositions
needed to transform a linear chromosome into another represented by the
permutations $\pi$ and $\sigma$. This paper focuses on the equivalent problem
of Sorting By Transpositions (SBT), where $\sigma$ is the identity permutation
$\iota$. Specifically, we investigate properties of palisades, a family of
permutations that are ``hard'' to sort, as they require numerous transpositions
above the celebrated lower bound devised by Bafna and Pevzner. By determining
the transposition distance of palisades, we were able to provide the exact
transposition diameter for $3$-permutations (TD3), a special subset of the
Symmetric Group $S_n$, essential for the study of approximate solutions for SBT
using the simplification technique. The exact value for TD3 has remained
unknown since Elias and Hartman showed an upper bound for it. Another
consequence of determining the transposition distance of palisades is that,
using as lower bound the one by Bafna and Pevzner, it is impossible to
guarantee approximation ratios lower than $1.375$ when approximating SBT. This
finding has significant implications for the study of SBT, as this problem has
been subject of intense research efforts for the past 25 years.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Silva_L/0/1/0/all/0/1">Luiz Augusto G. da Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowada_L/0/1/0/all/0/1">Luis Antonio B. Kowada</a>, <a href="http://arxiv.org/find/cs/1/au:+Walter_M/0/1/0/all/0/1">Maria Em&#xed;lia M. T. Walter</a></p><p>The Transposition Distance Problem (TDP) is a classical problem in genome
rearrangements which seeks to determine the minimum number of transpositions
needed to transform a linear chromosome into another represented by the
permutations $\pi$ and $\sigma$. This paper focuses on the equivalent problem
of Sorting By Transpositions (SBT), where $\sigma$ is the identity permutation
$\iota$. Specifically, we investigate properties of palisades, a family of
permutations that are ``hard'' to sort, as they require numerous transpositions
above the celebrated lower bound devised by Bafna and Pevzner. By determining
the transposition distance of palisades, we were able to provide the exact
transposition diameter for $3$-permutations (TD3), a special subset of the
Symmetric Group $S_n$, essential for the study of approximate solutions for SBT
using the simplification technique. The exact value for TD3 has remained
unknown since Elias and Hartman showed an upper bound for it. Another
consequence of determining the transposition distance of palisades is that,
using as lower bound the one by Bafna and Pevzner, it is impossible to
guarantee approximation ratios lower than $1.375$ when approximating SBT. This
finding has significant implications for the study of SBT, as this problem has
been subject of intense research efforts for the past 25 years.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14127'>Improved Online Scheduling of Moldable Task Graphs under Common Speedup Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lucas Perotin, Hongyang Sun</p><p>We consider the online scheduling problem of moldable task graphs on
multiprocessor systems for minimizing the overall completion time (or
makespan). Moldable job scheduling has been widely studied in the literature,
in particular when tasks have dependencies (i.e., task graphs) or when tasks
are released on-the-fly (i.e., online). However, few studies have focused on
both (i.e., online scheduling of moldable task graphs). In this paper, we
design a new online scheduling algorithm for this problem and derive constant
competitive ratios under several common yet realistic speedup models (i.e.,
roofline, communication, Amdahl, and a general combination). These results
improve the ones we have shown in the preliminary version of this paper. We
also prove, for each speedup model, a lower bound on the competitiveness of any
online list scheduling algorithm that allocates processors to a task based only
on the task's parameters and not on its position in the graph. This lower bound
matches exactly the competitive ratio of our algorithm for the roofline,
communication and Amdahl's model, and is close to the ratio for the general
model. Finally, we provide a lower bound on the competitive ratio of any
deterministic online algorithm for the arbitrary speedup model, which is not
constant but depends on the number of tasks in the longest path of the graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Perotin_L/0/1/0/all/0/1">Lucas Perotin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hongyang Sun</a></p><p>We consider the online scheduling problem of moldable task graphs on
multiprocessor systems for minimizing the overall completion time (or
makespan). Moldable job scheduling has been widely studied in the literature,
in particular when tasks have dependencies (i.e., task graphs) or when tasks
are released on-the-fly (i.e., online). However, few studies have focused on
both (i.e., online scheduling of moldable task graphs). In this paper, we
design a new online scheduling algorithm for this problem and derive constant
competitive ratios under several common yet realistic speedup models (i.e.,
roofline, communication, Amdahl, and a general combination). These results
improve the ones we have shown in the preliminary version of this paper. We
also prove, for each speedup model, a lower bound on the competitiveness of any
online list scheduling algorithm that allocates processors to a task based only
on the task's parameters and not on its position in the graph. This lower bound
matches exactly the competitive ratio of our algorithm for the roofline,
communication and Amdahl's model, and is close to the ratio for the general
model. Finally, we provide a lower bound on the competitive ratio of any
deterministic online algorithm for the arbitrary speedup model, which is not
constant but depends on the number of tasks in the longest path of the graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14184'>Compact Distance Oracles with Large Sensitivity and Low Stretch</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davide Bil&#xf2;, Keerti Choudhary, Sarel Cohen, Tobias Friedrich, Simon Krogmann, Martin Schirneck</p><p>An $f$-edge fault-tolerant distance sensitive oracle ($f$-DSO) with stretch
$\sigma \geq 1$ is a data structure that preprocesses an input graph $G$. When
queried with the triple $(s,t,F)$, where $s, t \in V$ and $F \subseteq E$
contains at most $f$ edges of $G$, the oracle returns an estimate
$\widehat{d}_{G-F}(s,t)$ of the distance $d_{G-F}(s,t)$ between $s$ and $t$ in
the graph $G-F$ such that $d_{G-F}(s,t) \leq \widehat{d}_{G-F}(s,t) \leq \sigma
d_{G-F}(s,t)$. For any positive integer $k \ge 2$ and any $0 &lt; \alpha &lt; 1$, we
present an $f$-DSO with sensitivity $f = o(\log n/\log\log n)$, stretch $2k-1$,
space $O(n^{1+\frac{1}{k}+\alpha+o(1)})$, and an
$\widetilde{O}(n^{1+\frac{1}{k} - \frac{\alpha}{k(f+1)}})$ query time.
</p>
<p>Prior to our work, there were only three known $f$-DSOs with subquadratic
space. The first one by Chechik et al. [Algorithmica 2012] has a stretch of
$(8k-2)(f+1)$, depending on $f$. Another approach is storing an $f$-edge
fault-tolerant $(2k-1)$-spanner of $G$. The bottleneck is the large query time
due to the size of any such spanner, which is $\Omega(n^{1+1/k})$ under the
Erd\H{o}s girth conjecture. Bil\`o et al. [STOC 2023] gave a solution with
stretch $3+\varepsilon$, query time $O(n^{\alpha})$ but space
$O(n^{2-\frac{\alpha}{f+1}})$, approaching the quadratic barrier for large
sensitivity. In the realm of subquadratic space, our $f$-DSOs are the first
ones that guarantee, at the same time, large sensitivity, low stretch, and
non-trivial query time. To obtain our results, we use the approximate distance
oracles of Thorup and Zwick [JACM 2005], and the derandomization of the $f$-DSO
of Weimann and Yuster [TALG 2013], that was recently given by Karthik and
Parter [SODA 2021].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bilo_D/0/1/0/all/0/1">Davide Bil&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_K/0/1/0/all/0/1">Keerti Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Sarel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrich_T/0/1/0/all/0/1">Tobias Friedrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Krogmann_S/0/1/0/all/0/1">Simon Krogmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schirneck_M/0/1/0/all/0/1">Martin Schirneck</a></p><p>An $f$-edge fault-tolerant distance sensitive oracle ($f$-DSO) with stretch
$\sigma \geq 1$ is a data structure that preprocesses an input graph $G$. When
queried with the triple $(s,t,F)$, where $s, t \in V$ and $F \subseteq E$
contains at most $f$ edges of $G$, the oracle returns an estimate
$\widehat{d}_{G-F}(s,t)$ of the distance $d_{G-F}(s,t)$ between $s$ and $t$ in
the graph $G-F$ such that $d_{G-F}(s,t) \leq \widehat{d}_{G-F}(s,t) \leq \sigma
d_{G-F}(s,t)$. For any positive integer $k \ge 2$ and any $0 &lt; \alpha &lt; 1$, we
present an $f$-DSO with sensitivity $f = o(\log n/\log\log n)$, stretch $2k-1$,
space $O(n^{1+\frac{1}{k}+\alpha+o(1)})$, and an
$\widetilde{O}(n^{1+\frac{1}{k} - \frac{\alpha}{k(f+1)}})$ query time.
</p>
<p>Prior to our work, there were only three known $f$-DSOs with subquadratic
space. The first one by Chechik et al. [Algorithmica 2012] has a stretch of
$(8k-2)(f+1)$, depending on $f$. Another approach is storing an $f$-edge
fault-tolerant $(2k-1)$-spanner of $G$. The bottleneck is the large query time
due to the size of any such spanner, which is $\Omega(n^{1+1/k})$ under the
Erd\H{o}s girth conjecture. Bil\`o et al. [STOC 2023] gave a solution with
stretch $3+\varepsilon$, query time $O(n^{\alpha})$ but space
$O(n^{2-\frac{\alpha}{f+1}})$, approaching the quadratic barrier for large
sensitivity. In the realm of subquadratic space, our $f$-DSOs are the first
ones that guarantee, at the same time, large sensitivity, low stretch, and
non-trivial query time. To obtain our results, we use the approximate distance
oracles of Thorup and Zwick [JACM 2005], and the derandomization of the $f$-DSO
of Weimann and Yuster [TALG 2013], that was recently given by Karthik and
Parter [SODA 2021].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14289'>Fast Sampling of $b$-Matchings and $b$-Edge Covers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zongchen Chen, Yuzhou Gu</p><p>For integer $b \ge 1$, a $b$-matching (resp. $b$-edge cover) of a graph
$G=(V,E)$ is a subset $S\subseteq E$ of edges such that every vertex is
incident with at most (resp. at least) $b$ edges from $S$. We prove that for
any $b \ge 1$ the simple Glauber dynamics for sampling (weighted) $b$-matchings
and $b$-edge covers mixes in $O(n\log n)$ time on all $n$-vertex bounded-degree
graphs. This significantly improves upon previous results which have worse
running time and only work for $b$-matchings with $b \le 7$ and for $b$-edge
covers with $b \le 2$.
</p>
<p>Moreover generally, we prove spectral independence for a broad class of
binary symmetric Holant problems with log-concave signatures, including
$b$-matchings, $b$-edge covers, and antiferromagnetic $2$-spin edge models. We
hence deduce optimal mixing time of Glauber dynamics from spectral
independence.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zongchen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuzhou Gu</a></p><p>For integer $b \ge 1$, a $b$-matching (resp. $b$-edge cover) of a graph
$G=(V,E)$ is a subset $S\subseteq E$ of edges such that every vertex is
incident with at most (resp. at least) $b$ edges from $S$. We prove that for
any $b \ge 1$ the simple Glauber dynamics for sampling (weighted) $b$-matchings
and $b$-edge covers mixes in $O(n\log n)$ time on all $n$-vertex bounded-degree
graphs. This significantly improves upon previous results which have worse
running time and only work for $b$-matchings with $b \le 7$ and for $b$-edge
covers with $b \le 2$.
</p>
<p>Moreover generally, we prove spectral independence for a broad class of
binary symmetric Holant problems with log-concave signatures, including
$b$-matchings, $b$-edge covers, and antiferromagnetic $2$-spin edge models. We
hence deduce optimal mixing time of Glauber dynamics from spectral
independence.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14319'>The Covering Canadian Traveller Problem Revisited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Niklas Hahn, Michalis Xefteris</p><p>In this paper, we consider the $k$-Covering Canadian Traveller Problem
($k$-CCTP), which can be seen as a variant of the Travelling Salesperson
Problem. The goal of $k$-CCTP is finding the shortest tour for a traveller to
visit a set of locations in a given graph and return to the origin. Crucially,
unknown to the traveller, up to $k$ edges of the graph are blocked and the
traveller only discovers blocked edges online at one of their respective
endpoints. The currently best known upper bound for $k$-CCTP is $O(\sqrt{k})$
which was shown in [Huang and Liao, ISAAC '12]. We improve this polynomial
bound to a logarithmic one by presenting a deterministic $O(\log
k)$-competitive algorithm that runs in polynomial time. Further, we demonstrate
the tightness of our analysis by giving a lower bound instance for our
algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hahn_N/0/1/0/all/0/1">Niklas Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Xefteris_M/0/1/0/all/0/1">Michalis Xefteris</a></p><p>In this paper, we consider the $k$-Covering Canadian Traveller Problem
($k$-CCTP), which can be seen as a variant of the Travelling Salesperson
Problem. The goal of $k$-CCTP is finding the shortest tour for a traveller to
visit a set of locations in a given graph and return to the origin. Crucially,
unknown to the traveller, up to $k$ edges of the graph are blocked and the
traveller only discovers blocked edges online at one of their respective
endpoints. The currently best known upper bound for $k$-CCTP is $O(\sqrt{k})$
which was shown in [Huang and Liao, ISAAC '12]. We improve this polynomial
bound to a logarithmic one by presenting a deterministic $O(\log
k)$-competitive algorithm that runs in polynomial time. Further, we demonstrate
the tightness of our analysis by giving a lower bound instance for our
algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
