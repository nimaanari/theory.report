<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2022-12-15T07:30:25Z">Thursday, December 15 2022, 07:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, December 15
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.07044'>3D Neuron Morphology Analysis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jiaxiang Jiang, Michael Goebel, Cezar Borba, William Smith, B.S. Manjunath</p><p>We consider the problem of finding an accurate representation of neuron
shapes, extracting sub-cellular features, and classifying neurons based on
neuron shapes. In neuroscience research, the skeleton representation is often
used as a compact and abstract representation of neuron shapes. However,
existing methods are limited to getting and analyzing "curve" skeletons which
can only be applied for tubular shapes. This paper presents a 3D neuron
morphology analysis method for more general and complex neuron shapes. First,
we introduce the concept of skeleton mesh to represent general neuron shapes
and propose a novel method for computing mesh representations from 3D surface
point clouds. A skeleton graph is then obtained from skeleton mesh and is used
to extract sub-cellular features. Finally, an unsupervised learning method is
used to embed the skeleton graph for neuron classification. Extensive
experiment results are provided and demonstrate the robustness of our method to
analyze neuron morphology.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiaxiang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Goebel_M/0/1/0/all/0/1">Michael Goebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Borba_C/0/1/0/all/0/1">Cezar Borba</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_W/0/1/0/all/0/1">William Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Manjunath_B/0/1/0/all/0/1">B.S. Manjunath</a></p><p>We consider the problem of finding an accurate representation of neuron
shapes, extracting sub-cellular features, and classifying neurons based on
neuron shapes. In neuroscience research, the skeleton representation is often
used as a compact and abstract representation of neuron shapes. However,
existing methods are limited to getting and analyzing "curve" skeletons which
can only be applied for tubular shapes. This paper presents a 3D neuron
morphology analysis method for more general and complex neuron shapes. First,
we introduce the concept of skeleton mesh to represent general neuron shapes
and propose a novel method for computing mesh representations from 3D surface
point clouds. A skeleton graph is then obtained from skeleton mesh and is used
to extract sub-cellular features. Finally, an unsupervised learning method is
used to embed the skeleton graph for neuron classification. Extensive
experiment results are provided and demonstrate the robustness of our method to
analyze neuron morphology.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-15T01:30:00Z">Thursday, December 15 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.07201'>Toroidal Coordinates: Decorrelating Circular Coordinates With Lattice Reduction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Luis Scoccola, Hitesh Gakhar, Johnathan Bush, Nikolas Schonsheck, Tatum Rask, Ling Zhou, Jose A. Perea</p><p>The circular coordinates algorithm of de Silva, Morozov, and
Vejdemo-Johansson takes as input a dataset together with a cohomology class
representing a $1$-dimensional hole in the data; the output is a map from the
data into the circle that captures this hole, and that is of minimum energy in
a suitable sense. However, when applied to several cohomology classes, the
output circle-valued maps can be "geometrically correlated" even if the chosen
cohomology classes are linearly independent. It is shown in the original work
that less correlated maps can be obtained with suitable integer linear
combinations of the cohomology classes, with the linear combinations being
chosen by inspection. In this paper, we identify a formal notion of geometric
correlation between circle-valued maps which, in the Riemannian manifold case,
corresponds to the Dirichlet form, a bilinear form derived from the Dirichlet
energy. We describe a systematic procedure for constructing low energy
torus-valued maps on data, starting from a set of linearly independent
cohomology classes. We showcase our procedure with computational examples. Our
main algorithm is based on the Lenstra--Lenstra--Lov\'asz algorithm from
computational number theory.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Scoccola_L/0/1/0/all/0/1">Luis Scoccola</a>, <a href="http://arxiv.org/find/cs/1/au:+Gakhar_H/0/1/0/all/0/1">Hitesh Gakhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bush_J/0/1/0/all/0/1">Johnathan Bush</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonsheck_N/0/1/0/all/0/1">Nikolas Schonsheck</a>, <a href="http://arxiv.org/find/cs/1/au:+Rask_T/0/1/0/all/0/1">Tatum Rask</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Ling Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Perea_J/0/1/0/all/0/1">Jose A. Perea</a></p><p>The circular coordinates algorithm of de Silva, Morozov, and
Vejdemo-Johansson takes as input a dataset together with a cohomology class
representing a $1$-dimensional hole in the data; the output is a map from the
data into the circle that captures this hole, and that is of minimum energy in
a suitable sense. However, when applied to several cohomology classes, the
output circle-valued maps can be "geometrically correlated" even if the chosen
cohomology classes are linearly independent. It is shown in the original work
that less correlated maps can be obtained with suitable integer linear
combinations of the cohomology classes, with the linear combinations being
chosen by inspection. In this paper, we identify a formal notion of geometric
correlation between circle-valued maps which, in the Riemannian manifold case,
corresponds to the Dirichlet form, a bilinear form derived from the Dirichlet
energy. We describe a systematic procedure for constructing low energy
torus-valued maps on data, starting from a set of linearly independent
cohomology classes. We showcase our procedure with computational examples. Our
main algorithm is based on the Lenstra--Lenstra--Lov\'asz algorithm from
computational number theory.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-15T01:30:00Z">Thursday, December 15 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.07124'>Approximate Discrete Fr\'echet distance: simplified, extended and structured</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ivor van der Hoog, Eva Rotenberg, Sampsong Wong</p><p>The Fr\'{e}chet distance is one of the most studied distance measures between
curves $P$ and $Q$. The data structure variant of the problem is a longstanding
open problem: Efficiently preprocess $P$, so that for any $Q$ given at query
time, one can efficiently approximate their Fr\'{e}chet distance. There exist
conditional lower bounds that prohibit $(1 + \varepsilon)$-approximate
Fr\'{e}chet distance computations in subquadratic time, even when preprocessing
$P$ using any polynomial amount of time and space. As a consequence, the
problem has been studied under various restrictions: restricting $Q$ to be a
(horizontal) segment, or requiring $P$ and $Q$ to be so-called \emph{realistic}
input curves.
</p>
<p>We give a data structure for $(1+\varepsilon)$-approximate discrete
Fr\'{e}chet distance in any metric space $\mathcal{X}$ between a realistic
input curve $P$ and any query curve $Q$. After preprocessing the input curve
$P$ (of length $|P|=n$) in $O(n \log n)$ time, we may answer queries specifying
a query curve $Q$ and an $\varepsilon$, and output a value $d(P,Q)$ which is at
most a $(1+\varepsilon)$-factor away from the true Fr\'{e}chet distance between
$Q$ and $P$. Thus, we give the first data structure that adapts to
$\varepsilon$-values specified at query time, and the first data structure to
handle query curves with arbitrarily many vertices. Our query time is
asymptotically linear in $|Q|=m$, $\frac{1}{\varepsilon}$, $\log n$, and the
realism parameter $c$ or $\kappa$.
</p>
<p>The method presented in this paper simplifies and generalizes previous
contributions to the static problem variant. We obtain efficient queries (and
therefore static algorithms) for Fr\'{e}chet distance computation in
high-dimensional spaces and other metric spaces (e.g., when $\mathcal{X}$ is a
graph under the shortest path metric). Our method supports subcurve queries at
no additional cost.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hoog_I/0/1/0/all/0/1">Ivor van der Hoog</a>, <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1">Eva Rotenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_S/0/1/0/all/0/1">Sampsong Wong</a></p><p>The Fr\'{e}chet distance is one of the most studied distance measures between
curves $P$ and $Q$. The data structure variant of the problem is a longstanding
open problem: Efficiently preprocess $P$, so that for any $Q$ given at query
time, one can efficiently approximate their Fr\'{e}chet distance. There exist
conditional lower bounds that prohibit $(1 + \varepsilon)$-approximate
Fr\'{e}chet distance computations in subquadratic time, even when preprocessing
$P$ using any polynomial amount of time and space. As a consequence, the
problem has been studied under various restrictions: restricting $Q$ to be a
(horizontal) segment, or requiring $P$ and $Q$ to be so-called \emph{realistic}
input curves.
</p>
<p>We give a data structure for $(1+\varepsilon)$-approximate discrete
Fr\'{e}chet distance in any metric space $\mathcal{X}$ between a realistic
input curve $P$ and any query curve $Q$. After preprocessing the input curve
$P$ (of length $|P|=n$) in $O(n \log n)$ time, we may answer queries specifying
a query curve $Q$ and an $\varepsilon$, and output a value $d(P,Q)$ which is at
most a $(1+\varepsilon)$-factor away from the true Fr\'{e}chet distance between
$Q$ and $P$. Thus, we give the first data structure that adapts to
$\varepsilon$-values specified at query time, and the first data structure to
handle query curves with arbitrarily many vertices. Our query time is
asymptotically linear in $|Q|=m$, $\frac{1}{\varepsilon}$, $\log n$, and the
realism parameter $c$ or $\kappa$.
</p>
<p>The method presented in this paper simplifies and generalizes previous
contributions to the static problem variant. We obtain efficient queries (and
therefore static algorithms) for Fr\'{e}chet distance computation in
high-dimensional spaces and other metric spaces (e.g., when $\mathcal{X}$ is a
graph under the shortest path metric). Our method supports subcurve queries at
no additional cost.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-15T01:30:00Z">Thursday, December 15 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.07002'>Interweaving Real-Time Jobs with Energy Harvesting to Maximize Throughput</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Baruch Schieber, Bhargav Samineni, Soroush Vahidi</p><p>Motivated by baterryless IoT devices, we consider the following scheduling
problem. The input includes $n$ unit time jobs $\mathcal{J} = \{J_1, \ldots,
J_n\}$, where each job $J_i$ has a release time $r_i$, due date $d_i$, energy
requirement $e_i$, and weight $w_i$. We consider time to be slotted; hence, all
time related job values refer to slots. Let $T=\max_i\{d_i\}$. The input also
includes an $h_t$ value for every time slot $t$ ($1 \leq t \leq T$), which is
the energy harvestable on that slot. Energy is harvested at time slots when no
job is executed. The objective is to find a feasible schedule that maximizes
the weight of the scheduled jobs. A schedule is feasible if for every job $J_j$
in the schedule and its corresponding slot $t_j$, $t_{j} \neq t_{j'}$ if ${j}
\neq {j'}$, $r_j \leq t_j \leq d_j$, and the available energy before $t_j$ is
at least $e_j$. To the best of our knowledge, we are the first to consider the
theoretical aspects of this problem.
</p>
<p>In this work we show the following. (1) A polynomial time algorithm when all
jobs have identical $r_i, d_i$ and $w_i$. (2) A $\frac{1}{2}$-approximation
algorithm when all jobs have identical $w_i$ but arbitrary $r_i$ and $d_i$. (3)
An FPTAS when all jobs have identical $r_i$ and $d_i$ but arbitrary $w_i$. (4)
Reductions showing that all the variants of the problem in which at least one
of the attributes $r_i$, $d_i$, or $w_i$ are not identical for all jobs are
NP-Hard.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Schieber_B/0/1/0/all/0/1">Baruch Schieber</a>, <a href="http://arxiv.org/find/cs/1/au:+Samineni_B/0/1/0/all/0/1">Bhargav Samineni</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahidi_S/0/1/0/all/0/1">Soroush Vahidi</a></p><p>Motivated by baterryless IoT devices, we consider the following scheduling
problem. The input includes $n$ unit time jobs $\mathcal{J} = \{J_1, \ldots,
J_n\}$, where each job $J_i$ has a release time $r_i$, due date $d_i$, energy
requirement $e_i$, and weight $w_i$. We consider time to be slotted; hence, all
time related job values refer to slots. Let $T=\max_i\{d_i\}$. The input also
includes an $h_t$ value for every time slot $t$ ($1 \leq t \leq T$), which is
the energy harvestable on that slot. Energy is harvested at time slots when no
job is executed. The objective is to find a feasible schedule that maximizes
the weight of the scheduled jobs. A schedule is feasible if for every job $J_j$
in the schedule and its corresponding slot $t_j$, $t_{j} \neq t_{j'}$ if ${j}
\neq {j'}$, $r_j \leq t_j \leq d_j$, and the available energy before $t_j$ is
at least $e_j$. To the best of our knowledge, we are the first to consider the
theoretical aspects of this problem.
</p>
<p>In this work we show the following. (1) A polynomial time algorithm when all
jobs have identical $r_i, d_i$ and $w_i$. (2) A $\frac{1}{2}$-approximation
algorithm when all jobs have identical $w_i$ but arbitrary $r_i$ and $d_i$. (3)
An FPTAS when all jobs have identical $r_i$ and $d_i$ but arbitrary $w_i$. (4)
Reductions showing that all the variants of the problem in which at least one
of the attributes $r_i$, $d_i$, or $w_i$ are not identical for all jobs are
NP-Hard.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-15T01:30:00Z">Thursday, December 15 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.07119'>Efficient Non-isomorphic Graph Enumeration Algorithms for Subclasses of Perfect Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jun Kawahara, Toshiki Saitoh, Hirokazu Takeda, Ryo Yoshinaka, Yui Yoshioka</p><p>Intersection graphs are well-studied in the area of graph algorithms. Some
intersection graph classes are known to have algorithms enumerating all
unlabeled graphs by reverse search. Since these algorithms output graphs one by
one and the numbers of graphs in these classes are vast, they work only for a
small number of vertices. Binary decision diagrams (BDDs) are compact data
structures for various types of data and useful for solving optimization and
enumeration problems. This study proposes enumeration algorithms for five
intersection graph classes, which admit $\mathrm{O}(n)$-bit string
representations for their member graphs. Our algorithm for each class
enumerates all unlabeled graphs with $n$ vertices over BDDs representing the
binary strings in time polynomial in $n$. Moreover, our algorithms are extended
to enumerate those with constraints on the maximum (bi)clique size and/or the
number of edges.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kawahara_J/0/1/0/all/0/1">Jun Kawahara</a>, <a href="http://arxiv.org/find/cs/1/au:+Saitoh_T/0/1/0/all/0/1">Toshiki Saitoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeda_H/0/1/0/all/0/1">Hirokazu Takeda</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshinaka_R/0/1/0/all/0/1">Ryo Yoshinaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshioka_Y/0/1/0/all/0/1">Yui Yoshioka</a></p><p>Intersection graphs are well-studied in the area of graph algorithms. Some
intersection graph classes are known to have algorithms enumerating all
unlabeled graphs by reverse search. Since these algorithms output graphs one by
one and the numbers of graphs in these classes are vast, they work only for a
small number of vertices. Binary decision diagrams (BDDs) are compact data
structures for various types of data and useful for solving optimization and
enumeration problems. This study proposes enumeration algorithms for five
intersection graph classes, which admit $\mathrm{O}(n)$-bit string
representations for their member graphs. Our algorithm for each class
enumerates all unlabeled graphs with $n$ vertices over BDDs representing the
binary strings in time polynomial in $n$. Moreover, our algorithms are extended
to enumerate those with constraints on the maximum (bi)clique size and/or the
number of edges.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-15T01:30:00Z">Thursday, December 15 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, December 14
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2022/12/14/postdoc-at-northeastern/'>Postdoc at Northeastern</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Apply here. Exciting opportunity. Two years, and you can also write grants. All areas are being considered.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="https://www.khoury.northeastern.edu/research/postdoctoral-fellowship/">Apply here</a>.  Exciting opportunity.  Two years, and you can also write grants.  All areas are being considered.</p>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T17:56:44Z">Wednesday, December 14 2022, 17:56</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/14/postdoc-and-research-fellow-at-hiit-aalto-university-and-university-of-helsinki-apply-by-january-8-2023/'>Postdoc and research fellow at HIIT (Aalto University and University of Helsinki) (apply by January 8, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Helsinki Institute for Information Technology invites applications for Research Fellow (&#60;=5 years) and Postdoctoral Fellow (&#60;=3 years) positions. In the foundations of computing focus area we welcome applicants working in all areas of TCS, e.g. algorithms, complexity, comp. logic, optimization, cryptography, comp. geometry, natural computation, and distributed, parallel, and quantum computing. Website: www.hiit.fi/hiit-postdoctoral-and-research-fellow-positions/ Email: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Helsinki Institute for Information Technology invites applications for Research Fellow (&lt;=5 years) and Postdoctoral Fellow (&lt;=3 years) positions. In the foundations of computing focus area we welcome applicants working in all areas of TCS, e.g. algorithms, complexity, comp. logic, optimization, cryptography, comp. geometry, natural computation, and distributed, parallel, and quantum computing.</p>
<p>Website: <a href="https://www.hiit.fi/hiit-postdoctoral-and-research-fellow-positions/">https://www.hiit.fi/hiit-postdoctoral-and-research-fellow-positions/</a><br />
Email: coordinator@hiit.fi</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T15:27:54Z">Wednesday, December 14 2022, 15:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.06782'>On computing the vertex connectivity of 1-plane graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Therese Biedl, Karthik Murali</p><p>A graph is called 1-plane if it has an embedding in the plane where each edge
is crossed at most once by another edge. A crossing of a 1-plane graph is
called an $\times$-crossing if the endpoints of the crossing pair of edges
induce a matching. In this paper, we show how to compute the vertex
connectivity of a 1-plane graph $G$ without $\times$-crossings in linear time.
To do so, we show that for any two vertices $u,v$ in a minimum separating set
$S$, the distance between $u$ and $v$ in an auxiliary graph $\Lambda(G)$
(obtained by planarizing $G$ and then inserting into each face a new vertex
adjacent to all vertices of the face) is small. It hence suffices to search for
a minimum separating set in various subgraphs $\Lambda_i$ of $\Lambda(G)$ with
small diameter. Since $\Lambda(G)$ is planar, the subgraphs $\Lambda_i$ have
small treewidth. Each minimum separating set $S$ then gives rise to a partition
of $\Lambda_i$ into three vertex sets with special properties; such a partition
can be found via Courcelle's theorem in linear time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Biedl_T/0/1/0/all/0/1">Therese Biedl</a>, <a href="http://arxiv.org/find/cs/1/au:+Murali_K/0/1/0/all/0/1">Karthik Murali</a></p><p>A graph is called 1-plane if it has an embedding in the plane where each edge
is crossed at most once by another edge. A crossing of a 1-plane graph is
called an $\times$-crossing if the endpoints of the crossing pair of edges
induce a matching. In this paper, we show how to compute the vertex
connectivity of a 1-plane graph $G$ without $\times$-crossings in linear time.
To do so, we show that for any two vertices $u,v$ in a minimum separating set
$S$, the distance between $u$ and $v$ in an auxiliary graph $\Lambda(G)$
(obtained by planarizing $G$ and then inserting into each face a new vertex
adjacent to all vertices of the face) is small. It hence suffices to search for
a minimum separating set in various subgraphs $\Lambda_i$ of $\Lambda(G)$ with
small diameter. Since $\Lambda(G)$ is planar, the subgraphs $\Lambda_i$ have
small treewidth. Each minimum separating set $S$ then gives rise to a partition
of $\Lambda_i$ into three vertex sets with special properties; such a partition
can be found via Courcelle's theorem in linear time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T01:30:00Z">Wednesday, December 14 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.06296'>A (Slightly) Improved Deterministic Approximation Algorithm for Metric TSP</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anna R. Karlin, Nathan Klein, Shayan Oveis Gharan</p><p>We show that the max entropy algorithm can be derandomized (with respect to a
particular objective function) to give a deterministic $3/2-\epsilon$
approximation algorithm for metric TSP for some $\epsilon &gt; 10^{-36}$.
</p>
<p>To obtain our result, we apply the method of conditional expectation to an
objective function constructed in prior work which was used to certify that the
expected cost of the algorithm is at most $3/2-\epsilon$ times the cost of an
optimal solution to the subtour elimination LP. The proof in this work involves
showing that the expected value of this objective function can be computed in
polynomial time (at all stages of the algorithm's execution).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Karlin_A/0/1/0/all/0/1">Anna R. Karlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_N/0/1/0/all/0/1">Nathan Klein</a>, <a href="http://arxiv.org/find/cs/1/au:+Gharan_S/0/1/0/all/0/1">Shayan Oveis Gharan</a></p><p>We show that the max entropy algorithm can be derandomized (with respect to a
particular objective function) to give a deterministic $3/2-\epsilon$
approximation algorithm for metric TSP for some $\epsilon &gt; 10^{-36}$.
</p>
<p>To obtain our result, we apply the method of conditional expectation to an
objective function constructed in prior work which was used to certify that the
expected cost of the algorithm is at most $3/2-\epsilon$ times the cost of an
optimal solution to the subtour elimination LP. The proof in this work involves
showing that the expected value of this objective function can be computed in
polynomial time (at all stages of the algorithm's execution).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T01:30:00Z">Wednesday, December 14 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.06315'>Dynamic Maxflow via Dynamic Interior Point Methods</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jan van den Brand, Yang P. Liu, Aaron Sidford</p><p>In this paper we provide an algorithm for maintaining a
$(1-\epsilon)$-approximate maximum flow in a dynamic, capacitated graph
undergoing edge additions. Over a sequence of $m$-additions to an $n$-node
graph where every edge has capacity $O(\mathrm{poly}(m))$ our algorithm runs in
time $\widehat{O}(m \sqrt{n} \cdot \epsilon^{-1})$. To obtain this result we
design dynamic data structures for the more general problem of detecting when
the value of the minimum cost circulation in a dynamic graph undergoing edge
additions obtains value at most $F$ (exactly) for a given threshold $F$. Over a
sequence $m$-additions to an $n$-node graph where every edge has capacity
$O(\mathrm{poly}(m))$ and cost $O(\mathrm{poly}(m))$ we solve this thresholded
minimum cost flow problem in $\widehat{O}(m \sqrt{n})$. Both of our algorithms
succeed with high probability against an adaptive adversary. We obtain these
results by dynamizing the recent interior point method used to obtain an almost
linear time algorithm for minimum cost flow (Chen, Kyng, Liu, Peng, Probst
Gutenberg, Sachdeva 2022), and introducing a new dynamic data structure for
maintaining minimum ratio cycles in an undirected graph that succeeds with high
probability against adaptive adversaries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brand_J/0/1/0/all/0/1">Jan van den Brand</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang P. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidford_A/0/1/0/all/0/1">Aaron Sidford</a></p><p>In this paper we provide an algorithm for maintaining a
$(1-\epsilon)$-approximate maximum flow in a dynamic, capacitated graph
undergoing edge additions. Over a sequence of $m$-additions to an $n$-node
graph where every edge has capacity $O(\mathrm{poly}(m))$ our algorithm runs in
time $\widehat{O}(m \sqrt{n} \cdot \epsilon^{-1})$. To obtain this result we
design dynamic data structures for the more general problem of detecting when
the value of the minimum cost circulation in a dynamic graph undergoing edge
additions obtains value at most $F$ (exactly) for a given threshold $F$. Over a
sequence $m$-additions to an $n$-node graph where every edge has capacity
$O(\mathrm{poly}(m))$ and cost $O(\mathrm{poly}(m))$ we solve this thresholded
minimum cost flow problem in $\widehat{O}(m \sqrt{n})$. Both of our algorithms
succeed with high probability against an adaptive adversary. We obtain these
results by dynamizing the recent interior point method used to obtain an almost
linear time algorithm for minimum cost flow (Chen, Kyng, Liu, Peng, Probst
Gutenberg, Sachdeva 2022), and introducing a new dynamic data structure for
maintaining minimum ratio cycles in an undirected graph that succeeds with high
probability against adaptive adversaries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T01:30:00Z">Wednesday, December 14 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.06422'>How Does Independence Help Generalization? Sample Complexity of ERM on Product Distributions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tao Lin</p><p>While many classical notions of learnability (e.g., PAC learnability) are
distribution-free, utilizing the specific structures of an input distribution
may improve learning performance. For example, a product distribution on a
multi-dimensional input space has a much simpler structure than a correlated
distribution. A recent paper [GHTZ21] shows that the sample complexity of a
general learning problem on product distributions is polynomial in the input
dimension, which is exponentially smaller than that on correlated
distributions. However, the learning algorithm they use is not the standard
Empirical Risk Minimization (ERM) algorithm. In this note, we characterize the
sample complexity of ERM in a general learning problem on product
distributions. We show that, even though product distributions are simpler than
correlated distributions, ERM still needs an exponential number of samples to
learn on product distributions, instead of a polynomial. This leads to the
conclusion that a product distribution by itself does not make a learning
problem easier -- an algorithm designed specifically for product distributions
is needed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tao Lin</a></p><p>While many classical notions of learnability (e.g., PAC learnability) are
distribution-free, utilizing the specific structures of an input distribution
may improve learning performance. For example, a product distribution on a
multi-dimensional input space has a much simpler structure than a correlated
distribution. A recent paper [GHTZ21] shows that the sample complexity of a
general learning problem on product distributions is polynomial in the input
dimension, which is exponentially smaller than that on correlated
distributions. However, the learning algorithm they use is not the standard
Empirical Risk Minimization (ERM) algorithm. In this note, we characterize the
sample complexity of ERM in a general learning problem on product
distributions. We show that, even though product distributions are simpler than
correlated distributions, ERM still needs an exponential number of samples to
learn on product distributions, instead of a polynomial. This leads to the
conclusion that a product distribution by itself does not make a learning
problem easier -- an algorithm designed specifically for product distributions
is needed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T01:30:00Z">Wednesday, December 14 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.06546'>Streaming Euclidean MST to a Constant Factor</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vincent Cohen-Addad, Xi Chen, Rajesh Jayaram, Amit Levi, Erik Waingarten</p><p>We study streaming algorithms for the fundamental geometric problem of
computing the cost of the Euclidean Minimum Spanning Tree (MST) on an $n$-point
set $X \subset \mathbb{R}^d$. In the streaming model, the points in $X$ can be
added and removed arbitrarily, and the goal is to maintain an approximation in
small space. In low dimensions, $(1+\epsilon)$ approximations are possible in
sublinear space [Frahling, Indyk, Sohler, SoCG '05]. However, for high
dimensional spaces the best known approximation for this problem was
$\tilde{O}(\log n)$, due to [Chen, Jayaram, Levi, Waingarten, STOC '22],
improving on the prior $O(\log^2 n)$ bound due to [Indyk, STOC '04] and
[Andoni, Indyk, Krauthgamer, SODA '08]. In this paper, we break the logarithmic
barrier, and give the first constant factor sublinear space approximation to
Euclidean MST. For any $\epsilon\geq 1$, our algorithm achieves an
$\tilde{O}(\epsilon^{-2})$ approximation in $n^{O(\epsilon)}$ space.
</p>
<p>We complement this by proving that any single pass algorithm which obtains a
better than $1.10$-approximation must use $\Omega(\sqrt{n})$ space,
demonstrating that $(1+\epsilon)$ approximations are not possible in
high-dimensions, and that our algorithm is tight up to a constant.
Nevertheless, we demonstrate that $(1+\epsilon)$ approximations are possible in
sublinear space with $O(1/\epsilon)$ passes over the stream. More generally,
for any $\alpha \geq 2$, we give a $\alpha$-pass streaming algorithm which
achieves a $(1+O(\frac{\log \alpha + 1}{ \alpha \epsilon}))$ approximation in
$n^{O(\epsilon)} d^{O(1)}$ space. Our streaming algorithms are linear sketches,
and therefore extend to the massively-parallel computation model (MPC). Thus,
our results imply the first $(1+\epsilon)$-approximation to Euclidean MST in a
constant number of rounds in the MPC model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1">Vincent Cohen-Addad</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaram_R/0/1/0/all/0/1">Rajesh Jayaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Levi_A/0/1/0/all/0/1">Amit Levi</a>, <a href="http://arxiv.org/find/cs/1/au:+Waingarten_E/0/1/0/all/0/1">Erik Waingarten</a></p><p>We study streaming algorithms for the fundamental geometric problem of
computing the cost of the Euclidean Minimum Spanning Tree (MST) on an $n$-point
set $X \subset \mathbb{R}^d$. In the streaming model, the points in $X$ can be
added and removed arbitrarily, and the goal is to maintain an approximation in
small space. In low dimensions, $(1+\epsilon)$ approximations are possible in
sublinear space [Frahling, Indyk, Sohler, SoCG '05]. However, for high
dimensional spaces the best known approximation for this problem was
$\tilde{O}(\log n)$, due to [Chen, Jayaram, Levi, Waingarten, STOC '22],
improving on the prior $O(\log^2 n)$ bound due to [Indyk, STOC '04] and
[Andoni, Indyk, Krauthgamer, SODA '08]. In this paper, we break the logarithmic
barrier, and give the first constant factor sublinear space approximation to
Euclidean MST. For any $\epsilon\geq 1$, our algorithm achieves an
$\tilde{O}(\epsilon^{-2})$ approximation in $n^{O(\epsilon)}$ space.
</p>
<p>We complement this by proving that any single pass algorithm which obtains a
better than $1.10$-approximation must use $\Omega(\sqrt{n})$ space,
demonstrating that $(1+\epsilon)$ approximations are not possible in
high-dimensions, and that our algorithm is tight up to a constant.
Nevertheless, we demonstrate that $(1+\epsilon)$ approximations are possible in
sublinear space with $O(1/\epsilon)$ passes over the stream. More generally,
for any $\alpha \geq 2$, we give a $\alpha$-pass streaming algorithm which
achieves a $(1+O(\frac{\log \alpha + 1}{ \alpha \epsilon}))$ approximation in
$n^{O(\epsilon)} d^{O(1)}$ space. Our streaming algorithms are linear sketches,
and therefore extend to the massively-parallel computation model (MPC). Thus,
our results imply the first $(1+\epsilon)$-approximation to Euclidean MST in a
constant number of rounds in the MPC model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T01:30:00Z">Wednesday, December 14 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.06605'>Dimensionality reduction on complex vector spaces for dynamic weighted Euclidean distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paolo Pellizzoni, Francesco Silvestri</p><p>The weighted Euclidean distance between two vectors is a Euclidean distance
where the contribution of each dimension is scaled by a given non-negative
weight. The Johnson-Lindenstrauss (JL) lemma can be easily adapted to the
weighted Euclidean distance if weights are known at construction time. Given a
set of $n$ vectors with dimension $d$, it suffices to scale each dimension of
the input vectors according to the weights, and then apply any standard JL
reduction: the weighted Euclidean distance between pairs of vectors is
preserved within a multiplicative factor $\epsilon$ with high probability.
</p>
<p>However, this is not the case when weights are provided after the
dimensionality reduction. In this paper, we show that by applying a linear map
from real vectors to a complex vector space, it is possible to update the
compressed vectors so that the weighted Euclidean distances between pairs of
points can be computed within a multiplicative factor $\epsilon$, even when
weights are provided after the dimensionality reduction. Finally, we consider
the estimation of weighted Euclidean norms in streaming settings: we show how
to estimate the weighted norm when the weights are provided either after or
concurrently with the input vector.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pellizzoni_P/0/1/0/all/0/1">Paolo Pellizzoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Silvestri_F/0/1/0/all/0/1">Francesco Silvestri</a></p><p>The weighted Euclidean distance between two vectors is a Euclidean distance
where the contribution of each dimension is scaled by a given non-negative
weight. The Johnson-Lindenstrauss (JL) lemma can be easily adapted to the
weighted Euclidean distance if weights are known at construction time. Given a
set of $n$ vectors with dimension $d$, it suffices to scale each dimension of
the input vectors according to the weights, and then apply any standard JL
reduction: the weighted Euclidean distance between pairs of vectors is
preserved within a multiplicative factor $\epsilon$ with high probability.
</p>
<p>However, this is not the case when weights are provided after the
dimensionality reduction. In this paper, we show that by applying a linear map
from real vectors to a complex vector space, it is possible to update the
compressed vectors so that the weighted Euclidean distances between pairs of
points can be computed within a multiplicative factor $\epsilon$, even when
weights are provided after the dimensionality reduction. Finally, we consider
the estimation of weighted Euclidean norms in streaming settings: we show how
to estimate the weighted norm when the weights are provided either after or
concurrently with the input vector.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T01:30:00Z">Wednesday, December 14 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.06644'>Fast Number Parsing Without Fallback</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Noble Mushtak, Daniel Lemire</p><p>In recent work, Lemire (2021) presented a fast algorithm to convert number
strings into binary floating-point numbers. The algorithm has been adopted by
several important systems: e.g., it is part of the runtime libraries of GCC 12,
Rust 1.55, and Go 1.16. The algorithm parses any number string with a
significand containing no more than 19 digits into an IEEE floating-point
number. However, there is a check leading to a fallback function to ensure
correctness. This fallback function is never called in practice. We prove that
the fallback is unnecessary. Thus we can slightly simplify the algorithm and
its implementation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mushtak_N/0/1/0/all/0/1">Noble Mushtak</a>, <a href="http://arxiv.org/find/cs/1/au:+Lemire_D/0/1/0/all/0/1">Daniel Lemire</a></p><p>In recent work, Lemire (2021) presented a fast algorithm to convert number
strings into binary floating-point numbers. The algorithm has been adopted by
several important systems: e.g., it is part of the runtime libraries of GCC 12,
Rust 1.55, and Go 1.16. The algorithm parses any number string with a
significand containing no more than 19 digits into an IEEE floating-point
number. However, there is a check leading to a fallback function to ensure
correctness. This fallback function is never called in practice. We prove that
the fallback is unnecessary. Thus we can slightly simplify the algorithm and
its implementation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T01:30:00Z">Wednesday, December 14 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.06646'>Profit Maximization in Social Networks and Non-monotone DR-submodular Maximization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shuyang Gu, Chuangen Gao, Jun Huang, Weili Wu</p><p>In this paper, we study the non-monotone DR-submodular function maximization
over integer lattice. Functions over integer lattice have been defined
submodular property that is similar to submodularity of set functions.
DR-submodular is a further extended submodular concept for functions over the
integer lattice, which captures the diminishing return property. Such functions
find many applications in machine learning, social networks, wireless networks,
etc. The techniques for submodular set function maximization can be applied to
DR-submodular function maximization, e.g., the double greedy algorithm has a
$1/2$-approximation ratio, whose running time is $O(nB)$, where $n$ is the size
of the ground set, $B$ is the integer bound of a coordinate. In our study, we
design a $1/2$-approximate binary search double greedy algorithm, and we prove
that its time complexity is $O(n\log B)$, which significantly improves the
running time. Specifically, we consider its application to the profit
maximization problem in social networks with a bipartite model, the goal of
this problem is to maximize the net profit gained from a product promoting
activity, which is the difference of the influence gain and the promoting cost.
We prove that the objective function is DR-submodular over integer lattice. We
apply binary search double greedy algorithm to this problem and verify the
effectiveness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1">Shuyang Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Chuangen Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Weili Wu</a></p><p>In this paper, we study the non-monotone DR-submodular function maximization
over integer lattice. Functions over integer lattice have been defined
submodular property that is similar to submodularity of set functions.
DR-submodular is a further extended submodular concept for functions over the
integer lattice, which captures the diminishing return property. Such functions
find many applications in machine learning, social networks, wireless networks,
etc. The techniques for submodular set function maximization can be applied to
DR-submodular function maximization, e.g., the double greedy algorithm has a
$1/2$-approximation ratio, whose running time is $O(nB)$, where $n$ is the size
of the ground set, $B$ is the integer bound of a coordinate. In our study, we
design a $1/2$-approximate binary search double greedy algorithm, and we prove
that its time complexity is $O(n\log B)$, which significantly improves the
running time. Specifically, we consider its application to the profit
maximization problem in social networks with a bipartite model, the goal of
this problem is to maximize the net profit gained from a product promoting
activity, which is the difference of the influence gain and the promoting cost.
We prove that the objective function is DR-submodular over integer lattice. We
apply binary search double greedy algorithm to this problem and verify the
effectiveness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T01:30:00Z">Wednesday, December 14 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gradientscience.org/failure-directions2/'>Tailored Data Augmentation to Mitigate Model Failures</a></h3>
        <p class='tr-article-feed'>from <a href='https://gradientscience.org/'>Gradient Science</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          

<!--  -->
<!--  -->









<!--  -->
<!-- 
 -->
<!--  -->


<!--  -->
<!-- chart.js -->


<p>

Â  Â  Paper



Â Â  Code

<br></p>

<p>
In our previous blogpost we described a method for automatically distilling a modelâs failure modes as directions in a latent space. In this post, weâll discuss how we can combine this method with off-the-shelf text-to-image models to perform synthetic data augmentation that specifically targets (and thus helps mitigate) a modelâs classification failures. 
</p>

<p>Machine learning models are prone to failures âespecially on subpopulations which are ambiguous, corrupted, or underrepresented in the training data. For example, a CIFAR-10 classification model might fail to identify cats on grass if its training dataset contained mostly examples of cats indoors.</p>

<p>â¦</p>

<p>Our previous blog post described a method for automatically distilling such meaningful error patterns as directions in a latent space. In the context of our example above, this would correspond to identifying an axis such that the easy examples (e.g., cats inside) lie in one of its directions, and the hard ones (e.g., cats on grass) lie in the opposite direction.</p>

<p>â¦</p>

<p>However, coming up with such a consistent âhardness ratingâ is only half the battle. That is, once weâve identified relevant failure modes, how can we improve the underlying modelâs reliability on them? One approach (as we discuss in the paper) is to simply add more data that belongs to the corresponding subpopulations (e.g., add more examples of cats on grass). For example, we can use our method to filter examples from an external pool of data (if we do not wish to use the entire external pool due to e.g., computational constraints) that would be useful to add to the training dataset (see Figure 6 in our paper).</p>

<p>But what if we donât have access to such an external pool of data?  It turns out that we can directly generate the images we need! Specifically, as we show in the (revised) version of our paper, we can leverage the recent stunning progress in text-to-image generation, as exemplified by diffusion models such as Stable Diffusion, Imagen, and DALL-E 2. That is, by combining our method with off-the-shelf diffusion models, we can perform âsynthetic data augmentationâ to specifically target a modelâs failure modes.</p>

Recap: Identifying and Captioning Model Failure Modes
<p>Our previous blogpost and corresponding paper presented a method for automatically identifying and captioning failure modes in a dataset. The key idea here was that, when exposed to a challenging subpopulation, the errors that a model makes are consistent, and share common features. (In our running example of cats, the hard examples tend to have outdoor backgrounds.) We can thus leverage that consistency and feature sharing by training a simple linear classifier to predict whether the original model is likely to make a mistake. Specifically, by training a linear SVM (per-class) to separate the incorrect and correct examples given their (normalized) feature embeddings.</p>

<p>â¦</p>

<p>In our running example of a cat, the SVM (the black line above) learns to separate cats indoors from cats outside. The vector orthogonal to the SVMâs decision boundary (in gray) thus encapsulates the direction of the captured failure mode: the images that are most aligned (or anti-aligned) with this direction represent the most prototypically âhardâ or âeasyâ examples.</p>

<p>Moreover, by leveraging a joint vision/language space for our underlying featurization (e.g., CLIP) our method provides a convenient way to caption the underlying failure modes with natural language descriptions. That is, since CLIP embeds both images and text in the same space, we can surface sentences whose text embedding is most aligned with our captured direction. In our example of cats from CIFAR-10, this method extracts âa photo of a white cat on the grassâ as a hard subpopulation and âa photo of a cat insideâ as an easy one.</p>

Targeted Data Augmentation with Stable Diffusion

<p>How can we use text-to-image diffusion models, such as Stable Diffusion or DALL-E 2, to generate synthetic images on which to fine-tune our model (thus âhardeningâ it against the corresponding distribution shift)? One straightforward approach is to simply use the name of the class to generate new images. For example, we can generate new examples of cats for CIFAR-10 by plugging in the sentence âa photo of a cat.â</p>

<p>However, just inputting âa photo of a catâ as a caption results in fairly generic examples of cats. But we wanted to perform targeted data augmentation, in order to improve the modelâs reliability on our particular identified challenging subpopulations (e.g., cats on grass). Conveniently, we already discussed how  to automatically surface natural language captions for the extracted failure modes. So, we can just plug these captions into our text-to-image model! Below are examples of such generated images.</p>



<p>How well does fine-tuning on such synthetic images fare? As one might hope, fine-tuning the original modelâs final layer indeed improves model performance on the hard subpopulation (see below).</p>

<p>â¦</p>

Directly synthesizing hard examples

<p>However, the above approach, although successful, feels somewhat suboptimal. After all, our initial SVM âhardâ direction already lives in a joint vision/language spaceâand so does the Stable Diffusion model we use. Can we thus skip the intermediate captioning step and directly decode our extracted SVM direction into synthetic images?</p>

<p>â¦</p>

<p>Yes, we can! We just need to interpolate between a reference class caption (e.g., âa photo of a catâ) and our extracted SVM direction to generate either harder or easier images that correspond to our captured failure mode.</p>

<p>â¦</p>

<p>Below, we display some examples of hard (and easy) images generated for each CIFAR-10 class. Notice that the encoded directions include rich information such as background, pose, and distance to the object, which would not be conveyed by the captions alone. As our revised paper shows, the original model performs worst on the âhardâ images and best on the âeasyâ ones.</p>



<p>So, indeed, by directly decoding the extracted SVM direction, we can capture the failure mode itself as a collection of new (synthetic) images, without relying on the proxy of captions!</p>

Conclusion

<p>In this blog post, we demonstrated how to use off-the-shelf diffusion models to perform targeted âdata augmentationâ, improving test accuracy on hard subpopulations to which a model might be vulnerable. This put forward a fully automated pipeline for identifying, interpreting, and intervening on challenging subpopulations. We believe that as the power of text-to-image models increases, such targeted âdata augmentationâ will become an even more powerful and versatile tool for improving model reliability.</p>


















    var img_root = "gradientscience.org/assets/failure-directions2/images/sd_figs/"
    var thumb_root = "gradientscience.org/assets/failure-directions2/images/sd_figs_thumbnails/"
    var bias_base = [["1", "2", "3", "4"]];

    var thumbnail_imgs = [[], []]
    var main_imgs = [[], []]
    bias_base.forEach(function(base, idx){
        base.forEach(function(b, sec_idx) {
            thumbnail_imgs[idx].push(thumb_root + b + ".png");
            main_imgs[idx].push(img_root + b + ".png");
        });
    });
    make_thumbnail_plot('sd_widget', thumbnail_imgs, main_imgs)



    var img_root = "gradientscience.org/assets/failure-directions2/images/rdm_figs/"
    var thumb_root = "gradientscience.org/assets/failure-directions2/images/rdm_figs_thumbnails/"
    var bias_base = [["1", "2", "3"], [ "4", "5", "6"]];

    var thumbnail_imgs = [[], []]
    var main_imgs = [[], []]
    bias_base.forEach(function(base, idx){
        base.forEach(function(b, sec_idx) {
            thumbnail_imgs[idx].push(thumb_root + b + ".png");
            main_imgs[idx].push(img_root + b + ".png");
        });
    });
    make_thumbnail_plot('rdm_widget', thumbnail_imgs, main_imgs)

        
        </div>

        <div class='tr-article-summary'>
        
          
          <meta charset="utf-8" />

<!-- <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> -->
<!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"> -->

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous" />

<link rel="stylesheet" type="text/css" href="https://gradientscience.org/assets/css/style.css" />

<link rel="stylesheet" href="https://gradientscience.org/assets/multilabel/style.css" />

<link rel="stylesheet" type="text/css" href="https://gradientscience.org/assets/failure-directions2/css/style.css" />

<!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css"> -->
<!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script> -->
<!-- <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script> -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha384-tsQFqpEReu7ZLhBV2VZlAu7zcOV+rXbYlF2cqB8txI/8aZajjp4Bqd+V6D5IgvKT" crossorigin="anonymous"></script>

<!-- <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css"> -->
<!-- chart.js -->
<script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>

<p><a class="bbutton" style="float: left; width: 45%;" href="https://arxiv.org/abs/2206.14754">
<i class="fas fa-file-pdf"></i>
Â  Â  Paper
</a>
<a class="bbutton" style="float: left; width: 45%;" href="https://github.com/MadryLab/failure-directions">
<i class="fab fa-github"></i>
Â Â  Code
</a>
<br /></p>

<p><i>
In our <a href="https://gradientscience.org/failure-directions/">previous blogpost</a> we described a method for automatically distilling a modelâs failure modes as directions in a latent space. In this post, weâll discuss how we can combine this method with off-the-shelf text-to-image models to perform synthetic data augmentation that specifically targets (and thus helps mitigate) a modelâs classification failures. 
</i></p>

<p>Machine learning models are prone to failures âespecially on subpopulations which are ambiguous, corrupted, or underrepresented in the training data. For example, a CIFAR-10 classification model might fail to identify cats on grass if its training dataset contained mostly examples of cats indoors.</p>

<p><img alt="EasyHardCats" src="/assets/failure-directions2/images/easy_hard_cats.png" style="width:100%" /></p>

<p>Our <a href="https://gradientscience.org/failure-directions/">previous blog post</a> described a method for automatically distilling such meaningful error patterns as directions in a latent space. In the context of our example above, this would correspond to identifying an axis such that the easy examples (e.g., cats inside) lie in one of its directions, and the hard ones (e.g., cats on grass) lie in the opposite direction.</p>

<p><img alt="EasyHardCats" src="/assets/failure-directions2/images/cat_axis.png" style="width:100%" /></p>

<p>However, coming up with such a consistent âhardness ratingâ is only half the battle. That is, once weâve identified relevant failure modes, how can we improve the underlying modelâs reliability on them? One approach (as we discuss in the <a href="https://arxiv.org/abs/2206.14754">paper</a>) is to simply add more data that belongs to the corresponding subpopulations (e.g., add more examples of cats on grass). For example, we can use our method to filter examples from an external pool of data (if we do not wish to use the entire external pool due to e.g., computational constraints) that would be useful to add to the training dataset (see Figure 6 in our paper).</p>

<p>But what if we donât have access to such an external pool of data?  It turns out that we can directly generate the images we need! Specifically, as we show in the (revised) version of our <a href="https://arxiv.org/abs/2206.14754">paper</a>, we can leverage the recent stunning progress in text-to-image generation, as exemplified by diffusion models such as <a href="https://huggingface.co/blog/stable_diffusion">Stable Diffusion</a>, <a href="https://imagen.research.google/">Imagen</a>, and <a href="https://openai.com/dall-e-2/">DALL-E 2</a>. That is, by combining our method with off-the-shelf diffusion models, we can perform âsynthetic data augmentationâ to specifically target a modelâs failure modes.</p>

<h2 id="recap-identifying-and-captioning-model-failure-modes">Recap: Identifying and Captioning Model Failure Modes</h2>
<p>Our <a href="https://gradientscience.org/failure-directions/">previous blogpost</a> and corresponding <a href="https://arxiv.org/pdf/2206.14754.pdf">paper</a> presented a method for automatically identifying and captioning failure modes in a dataset. The key idea here was that, when exposed to a challenging subpopulation, the errors that a model makes are consistent, and share common features. (In our running example of cats, the hard examples tend to have outdoor backgrounds.) We can thus leverage that consistency and feature sharing by training a simple linear classifier to predict whether the original model is likely to make a mistake. Specifically, by training a linear SVM (per-class) to separate the incorrect and correct examples given their (normalized) feature embeddings.</p>

<p><img alt="EasyHardCats" src="/assets/failure-directions2/images/cat_megafig.png" style="width:100%" /></p>

<p>In our running example of a cat, the SVM (the black line above) learns to separate cats indoors from cats outside. The vector orthogonal to the SVMâs decision boundary (in gray) thus encapsulates the direction of the captured failure mode: the images that are most aligned (or anti-aligned) with this direction represent the most prototypically âhardâ or âeasyâ examples.</p>

<p>Moreover, by leveraging a joint vision/language space for our underlying featurization (e.g., <a href="https://arxiv.org/abs/2103.00020">CLIP</a>) our method provides a convenient way to caption the underlying failure modes with natural language descriptions. That is, since CLIP embeds both images and text in the same space, we can surface sentences whose text embedding is most aligned with our captured direction. In our example of cats from CIFAR-10, this method extracts âa photo of a white cat on the grassâ as a hard subpopulation and âa photo of a cat insideâ as an easy one.</p>

<h2 id="targeted-data-augmentation-with-stable-diffusion">Targeted Data Augmentation with Stable Diffusion</h2>

<p>How can we use text-to-image diffusion models, such as Stable Diffusion or DALL-E 2, to generate synthetic images on which to fine-tune our model (thus âhardeningâ it against the corresponding distribution shift)? One straightforward approach is to simply use the name of the class to generate new images. For example, we can generate new examples of cats for CIFAR-10 by plugging in the sentence âa photo of a cat.â</p>

<p>However, just inputting âa photo of a catâ as a caption results in fairly generic examples of cats. But we wanted to perform targeted data augmentation, in order to improve the modelâs reliability on our particular identified challenging subpopulations (e.g., cats on grass). Conveniently, we already discussed how  to automatically surface natural language captions for the extracted failure modes. So, we can just plug these captions into our text-to-image model! Below are examples of such generated images.</p>

<div id="sd_widget" style="overflow:auto; text-align: center"></div>

<p>How well does fine-tuning on such synthetic images fare? As one might hope, fine-tuning the original modelâs final layer indeed improves model performance on the hard subpopulation (see below).</p>

<p><img alt="HardFinetune" src="/assets/failure-directions2/images/hard_finetune.png" style="width:100%" /></p>

<h2 id="directly-synthesizing-hard-examples">Directly synthesizing hard examples</h2>

<p>However, the above approach, although successful, feels somewhat suboptimal. After all, our initial SVM âhardâ direction already lives in a joint vision/language spaceâand so does the Stable Diffusion model we use. Can we thus skip the intermediate captioning step and directly decode our extracted SVM direction into synthetic images?</p>

<p><img alt="Direct" src="/assets/failure-directions2/images/direct.png" style="width:100%" /></p>

<p>Yes, we can! We just need to interpolate between a reference class caption (e.g., âa photo of a catâ) and our extracted SVM direction to generate either harder or easier images that correspond to our captured failure mode.</p>

<p><img alt="Circle" src="/assets/failure-directions2/images/circle.png" style="width:40%" /></p>

<p>Below, we display some examples of hard (and easy) images generated for each CIFAR-10 class. Notice that the encoded directions include rich information such as background, pose, and distance to the object, which would not be conveyed by the captions alone. As our revised <a href="https://arxiv.org/abs/2206.14754">paper</a> shows, the original model performs worst on the âhardâ images and best on the âeasyâ ones.</p>

<div id="rdm_widget" style="overflow:auto; text-align: center"></div>

<p>So, indeed, by directly decoding the extracted SVM direction, we can capture the failure mode itself as a collection of new (synthetic) images, without relying on the proxy of captions!</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this blog post, we demonstrated how to use off-the-shelf diffusion models to perform <strong>targeted âdata augmentationâ</strong>, improving test accuracy on hard subpopulations to which a model might be vulnerable. This put forward a fully automated pipeline for identifying, interpreting, and intervening on challenging subpopulations. We believe that as the power of text-to-image models increases, such targeted âdata augmentationâ will become an even more powerful and versatile tool for improving model reliability.</p>

<script src="https://gradientscience.org/assets/scripts/onload.js"></script>

<script src="https://cdn.jsdelivr.net/gh/nicolaspanel/numjs@0.15.1/dist/numjs.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/mathjs@6.6.0/dist/math.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

<script src="https://gradientscience.org/assets/failure-directions2/thumbnail_plot.js"></script>

<script>
    var img_root = "https://gradientscience.org/assets/failure-directions2/images/sd_figs/"
    var thumb_root = "https://gradientscience.org/assets/failure-directions2/images/sd_figs_thumbnails/"
    var bias_base = [["1", "2", "3", "4"]];

    var thumbnail_imgs = [[], []]
    var main_imgs = [[], []]
    bias_base.forEach(function(base, idx){
        base.forEach(function(b, sec_idx) {
            thumbnail_imgs[idx].push(thumb_root + b + ".png");
            main_imgs[idx].push(img_root + b + ".png");
        });
    });
    make_thumbnail_plot('sd_widget', thumbnail_imgs, main_imgs)
</script>

<script>
    var img_root = "https://gradientscience.org/assets/failure-directions2/images/rdm_figs/"
    var thumb_root = "https://gradientscience.org/assets/failure-directions2/images/rdm_figs_thumbnails/"
    var bias_base = [["1", "2", "3"], [ "4", "5", "6"]];

    var thumbnail_imgs = [[], []]
    var main_imgs = [[], []]
    bias_base.forEach(function(base, idx){
        base.forEach(function(b, sec_idx) {
            thumbnail_imgs[idx].push(thumb_root + b + ".png");
            main_imgs[idx].push(img_root + b + ".png");
        });
    });
    make_thumbnail_plot('rdm_widget', thumbnail_imgs, main_imgs)
</script>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-14T00:00:00Z">Wednesday, December 14 2022, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, December 13
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/13/phd-student-at-kings-college-london-apply-by-february-28-2023/'>PhD Student at Kingâs College London (apply by February 28, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          PhD positions are available in the areas of multi-agent systems, game dynamics, game theory, machine learning, reinforcement learning and/or cryptoeconomics (mechanism design/incentives). Funding is available for UK home students and options can be discussed for international students. Website: stefanosleonardos.com/ (This is funding coming from my start-up package and there is no explicit job advert website. [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>PhD positions are available in the areas of multi-agent systems, game dynamics, game theory, machine learning, reinforcement learning and/or cryptoeconomics (mechanism design/incentives). Funding is available for UK home students and options can be discussed for international students.</p>
<p>Website: <a href="http://stefanosleonardos.com/">http://stefanosleonardos.com/</a> (This is funding coming from my start-up package and there is no explicit job advert website. Hope this is acceptable)<br />
Email: stefanos.leonardos@kcl.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-13T21:03:18Z">Tuesday, December 13 2022, 21:03</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2022/12/13/randomly-traceable-graphs.html'>Randomly traceable graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In my recently-concluded graph algorithms course, one of my early homework assignments asked about undirected graphs with the following property: any oriented path that does not cover all vertices can be extended to form a Hamiltonian path. I phrased it in terms of depth-first search: which graphs have the property that, no matter where you start and no matter what order you explore the neighbors of each node, a depth first search tree will automatically produce a Hamiltonian path? The intent was to reinforce the idea that the same graph can have multiple depth first search trees depending on contingent issues of how the graph is represented. I called these âunicursal graphsâ.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In my recently-concluded graph algorithms course, one of my early homework assignments asked about undirected graphs with the following property: any oriented path that does not cover all vertices can be extended to form a Hamiltonian path. I phrased it in terms of depth-first search: which graphs have the property that, no matter where you start and no matter what order you explore the neighbors of each node, a depth first search tree will automatically produce a Hamiltonian path? The intent was to reinforce the idea that the same graph can have multiple depth first search trees depending on contingent issues of how the graph is represented. I called these âunicursal graphsâ.</p>

<p>This is also closely related to <a href="/blog/2019/05/02/playing-model-trains.html">some research I published in WADS 2019 on reconfiguring paths in graphs</a>, although in that work I was focusing on whether all paths of a certain length could be connected to each other by local moves and here the question is merely whether any path could be a dead end without any possible moves.</p>

<p>The homework asked only for an example of a graph that was unicursal but not complete. I had in mind two possibilities, the cycle graphs and the balanced complete bipartite graphs. One of the students in the graduate section of the class, Alvin Chiu, took the problem and ran with it, eventually proving that these are the only examples. Unfortunately, he also discovered that the result was in the literature already: Gary Chartrand and Hudson V. Kronk (1968), âRandomly traceable graphsâ, <em>SIAM J. Appl. Math.</em> 16 (4): 696â700, <a href="https://doi.org/10.1137/0116056">doi:10.1137/0116056</a>.</p>

<p>I think itâs a cute result that deserves to be more widely known, so I thought Iâd outline a proof here.</p>

<ul>
  <li>
    <p>The defining property is that any path can be extended to a Hamiltonian path. If you remove the first edge of a Hamiltonian path and extend the rest, the only possibility is to return to the first vertex of the initial path, by an edge that completes it to form a Hamiltonian cycle. So every path can be extended one step farther, to a Hamiltonian cycle.</p>
  </li>
  <li>
    <p>Find any cycle in your graph. If that is the whole graph, you have one of the three possibilities in the classification of these graphs; otherwise, it has at least one diagonal. By drawing an S-shaped path through this diagonal and around your starting cycle, and then completing it to another cycle, you can show that the graph must include a rotated copy of the diagonal. By repeating this operation you can show that it includes every rotated copy of every diagonal, and therefore that it forms a <a href="https://en.wikipedia.org/wiki/Circulant_graph">circulant graph</a>, a graph whose symmetries include a cyclic rotation of all the vertices.</p>

    <p style="text-align:center"><img src="/blog/assets/2022/unicursal-cases.svg" alt="Case analysis for randomly traceable graphs. Left: completion of an S-shaped path through the diagonal of a Hamiltonian cycle shows the existence of a rotated copy of the diagonal. Right: completion of a C-shaped path skipping the apex of a triangle shows that all vertices are adjacent to the apex." /></p>
  </li>
  <li>
    <p>If the graph contains a triangle, then (by extending the path through two sides of the triangle) you can arrive at a situation where the triangle is formed by three consecutive vertices of your Hamiltonian cycle, and includes a diagonal skipping the center vertex of the three. By drawing C-shaped paths around the cycle that use this diagonal to skip the center vertex, and then completing these paths to cycles, you can show that this center vertex is <a href="https://en.wikipedia.org/wiki/Universal_vertex">universal</a>: it has edges to everything else. By the circulant symmetry of the graph, it must be complete, the second of the three possibilities in the classification of these graphs.</p>
  </li>
  <li>
    <p>In the remaining case, any diagonal of a Hamiltonian cycle and its rotated copy form a four-vertex cycle. As in the previous case, by extending a path through three sides of the cycle you can arrive at a situation where some four-vertex cycle is formed by four consecutive vertices of a Hamiltonian cycle. A similar argument involving C-shaped paths shows that the two central vertices of the 4-cycle are adjacent to all other vertices, and by symmetry every two consecutive vertices of the Hamiltonian cycle are adjacent to all other vertices. This implies that there are at least \(n^2/4\) edges, and by <a href="https://en.wikipedia.org/wiki/Mantel's_theorem">Mantelâs theorem</a> the graph can only be a balanced complete bipartite graph, the third of the three possibilities.</p>
  </li>
</ul>

<p>(<a href="https://mathstodon.xyz/@11011110/109508139457197936">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-13T11:41:00Z">Tuesday, December 13 2022, 11:41</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.05332'>An approach to robust ICP initialization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Kolpakov, Michael Werman</p><p>In this note, we propose an approach for initializing the Iterative Closest
Point (ICP) algorithm that allows us to apply ICP to unlabelled point clouds
that are related by rigid transformations. We also give bounds on the
robustness of our approach to noise. Numerical experiments confirm our
theoretical findings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kolpakov_A/0/1/0/all/0/1">Alexander Kolpakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Werman_M/0/1/0/all/0/1">Michael Werman</a></p><p>In this note, we propose an approach for initializing the Iterative Closest
Point (ICP) algorithm that allows us to apply ICP to unlabelled point clouds
that are related by rigid transformations. We also give bounds on the
robustness of our approach to noise. Numerical experiments confirm our
theoretical findings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-13T01:30:00Z">Tuesday, December 13 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.05484'>Isometric deformable cones and cylinders carrying planar curves</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Georg Nawratil</p><p>We study cones and cylinders with a 1-parametric isometric deformation
carrying at least two planar curves, which remain planar during this continuous
flexion and are located in non-parallel planes. We investigate this
geometric/kinematic problem in the smooth and the discrete setting, as it is
the base for a generalized construction of so-called T-hedral zipper tubes. In
contrast to the cylindrical case, which can be solved easily, the conical one
is more tricky, but we succeed to give a closed form solution for the discrete
case, which is used to prove that these cones correspond to caps of Bricard
octahedra of the plane-symmetric type. For the smooth case we are able to
reduce the problem by means of symbolic computation to an ordinary differential
equation, but its solution remains an open problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nawratil_G/0/1/0/all/0/1">Georg Nawratil</a></p><p>We study cones and cylinders with a 1-parametric isometric deformation
carrying at least two planar curves, which remain planar during this continuous
flexion and are located in non-parallel planes. We investigate this
geometric/kinematic problem in the smooth and the discrete setting, as it is
the base for a generalized construction of so-called T-hedral zipper tubes. In
contrast to the cylindrical case, which can be solved easily, the conical one
is more tricky, but we succeed to give a closed form solution for the discrete
case, which is used to prove that these cones correspond to caps of Bricard
octahedra of the plane-symmetric type. For the smooth case we are able to
reduce the problem by means of symbolic computation to an ordinary differential
equation, but its solution remains an open problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-13T01:30:00Z">Tuesday, December 13 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.05098'>Transcoding Unicode Characters with AVX-512 Instructions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Robert Clausecker, Daniel Lemire</p><p>Intel includes on its recent processors a powerful set of instructions
capable of processing 512-bit registers with a single instruction (AVX-512).
Some of these instructions have no equivalent in earlier instruction sets. We
leverage these instructions to efficiently transcode strings between the most
common formats: UTF-8 and UTF-16. With our novel algorithms, we are often twice
as fast as the previous best solutions. For example, we transcode Chinese text
from UTF-8 to UTF-16 at more than 5 GiB/s using fewer than 2 CPU instructions
per character. To ensure reproducibility, we make our software freely available
as an open source library.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Clausecker_R/0/1/0/all/0/1">Robert Clausecker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lemire_D/0/1/0/all/0/1">Daniel Lemire</a></p><p>Intel includes on its recent processors a powerful set of instructions
capable of processing 512-bit registers with a single instruction (AVX-512).
Some of these instructions have no equivalent in earlier instruction sets. We
leverage these instructions to efficiently transcode strings between the most
common formats: UTF-8 and UTF-16. With our novel algorithms, we are often twice
as fast as the previous best solutions. For example, we transcode Chinese text
from UTF-8 to UTF-16 at more than 5 GiB/s using fewer than 2 CPU instructions
per character. To ensure reproducibility, we make our software freely available
as an open source library.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-13T01:30:00Z">Tuesday, December 13 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.05358'>Efficient and Generic Algorithms for Quantitative Attack Tree Analysis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Milan Lopuha&#xe4;-Zwakenberg, Carlos E. Budde, Mari&#xeb;lle Stoelinga</p><p>Numerous analysis methods for quantitative attack tree analysis have been
proposed. These algorithms compute relevant security metrics, i.e. performance
indicators that quantify how good the security of a system is; typical metrics
being the most likely attack, the cheapest, or the most damaging one. However,
existing methods are only geared towards specific metrics or do not work on
general attack trees. This paper classifies attack trees in two dimensions:
proper trees vs. directed acyclic graphs (i.e. with shared subtrees); and
static vs. dynamic gates. For three out of these four classes, we propose novel
algorithms that work over a generic attribute domain, encompassing a large
number of concrete security metrics defined on the attack tree semantics;
dynamic attack trees with directed acyclic graph structure are left as an open
problem. We also analyse the computational complexity of our methods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lopuhaa_Zwakenberg_M/0/1/0/all/0/1">Milan Lopuha&#xe4;-Zwakenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Budde_C/0/1/0/all/0/1">Carlos E. Budde</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoelinga_M/0/1/0/all/0/1">Mari&#xeb;lle Stoelinga</a></p><p>Numerous analysis methods for quantitative attack tree analysis have been
proposed. These algorithms compute relevant security metrics, i.e. performance
indicators that quantify how good the security of a system is; typical metrics
being the most likely attack, the cheapest, or the most damaging one. However,
existing methods are only geared towards specific metrics or do not work on
general attack trees. This paper classifies attack trees in two dimensions:
proper trees vs. directed acyclic graphs (i.e. with shared subtrees); and
static vs. dynamic gates. For three out of these four classes, we propose novel
algorithms that work over a generic attribute domain, encompassing a large
number of concrete security metrics defined on the attack tree semantics;
dynamic attack trees with directed acyclic graph structure are left as an open
problem. We also analyse the computational complexity of our methods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-13T01:30:00Z">Tuesday, December 13 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.05433'>Beyond circular-arc graphs -- recognizing lollipop graphs and medusa graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Deniz A&#x11f;ao&#x11f;lu &#xc7;a&#x11f;&#x131;r&#x131;c&#x131;, Onur &#xc7;a&#x11f;&#x131;r&#x131;c&#x131;, Jan Derbisz, Tim A. Hartmann, Petr Hlin&#x11b;n&#xfd;, Jan Kratochv&#xed;l, Tomasz Krawczyk, Peter Zeman</p><p>In 1992 Bir\'{o}, Hujter and Tuza introduced, for every fixed connected graph
$H$, the class of $H$-graphs, defined as the intersection graphs of connected
subgraphs of some subdivision of $H$. Recently, quite a lot of research has
been devoted to understanding the tractability border for various computational
problems, such as recognition or isomorphism testing, in classes of $H$-graphs
for different graphs $H$. In this work we undertake this research topic,
focusing on the recognition problem. Chaplick, T\"{o}pfer, Voborn\'{\i}k, and
Zeman showed, for every fixed tree $T$, a polynomial-time algorithm recognizing
$T$-graphs. Tucker showed a polynomial time algorithm recognizing $K_3$-graphs
(circular-arc graphs). On the other hand, Chaplick at al. showed that
recognition of $H$-graphs is $NP$-hard if $H$ contains two different cycles
sharing an edge.
</p>
<p>The main two results of this work narrow the gap between the $NP$-hard and
$P$ cases of $H$-graphs recognition. First, we show that recognition of
$H$-graphs is $NP$-hard when $H$ contains two different cycles. On the other
hand, we show a polynomial-time algorithm recognizing $L$-graphs, where $L$ is
a graph containing a cycle and an edge attached to it ($L$-graphs are called
lollipop graphs). Our work leaves open the recognition problems of $M$-graphs
for every unicyclic graph $M$ different from a cycle and a lollipop. Other
results of this work, which shed some light on the cases that remain open, are
as follows. Firstly, the recognition of $M$-graphs, where $M$ is a fixed
unicyclic graph, admits a polynomial time algorithm if we restrict the input to
graphs containing particular holes (hence recognition of $M$-graphs is probably
most difficult for chordal graphs). Secondly, the recognition of medusa graphs,
which are defined as the union of $M$-graphs, where $M$ runs over all unicyclic
graphs, is $NP$-complete.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cagirici_D/0/1/0/all/0/1">Deniz A&#x11f;ao&#x11f;lu &#xc7;a&#x11f;&#x131;r&#x131;c&#x131;</a>, <a href="http://arxiv.org/find/cs/1/au:+Cagirici_O/0/1/0/all/0/1">Onur &#xc7;a&#x11f;&#x131;r&#x131;c&#x131;</a>, <a href="http://arxiv.org/find/cs/1/au:+Derbisz_J/0/1/0/all/0/1">Jan Derbisz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartmann_T/0/1/0/all/0/1">Tim A. Hartmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Hlineny_P/0/1/0/all/0/1">Petr Hlin&#x11b;n&#xfd;</a>, <a href="http://arxiv.org/find/cs/1/au:+Kratochvil_J/0/1/0/all/0/1">Jan Kratochv&#xed;l</a>, <a href="http://arxiv.org/find/cs/1/au:+Krawczyk_T/0/1/0/all/0/1">Tomasz Krawczyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeman_P/0/1/0/all/0/1">Peter Zeman</a></p><p>In 1992 Bir\'{o}, Hujter and Tuza introduced, for every fixed connected graph
$H$, the class of $H$-graphs, defined as the intersection graphs of connected
subgraphs of some subdivision of $H$. Recently, quite a lot of research has
been devoted to understanding the tractability border for various computational
problems, such as recognition or isomorphism testing, in classes of $H$-graphs
for different graphs $H$. In this work we undertake this research topic,
focusing on the recognition problem. Chaplick, T\"{o}pfer, Voborn\'{\i}k, and
Zeman showed, for every fixed tree $T$, a polynomial-time algorithm recognizing
$T$-graphs. Tucker showed a polynomial time algorithm recognizing $K_3$-graphs
(circular-arc graphs). On the other hand, Chaplick at al. showed that
recognition of $H$-graphs is $NP$-hard if $H$ contains two different cycles
sharing an edge.
</p>
<p>The main two results of this work narrow the gap between the $NP$-hard and
$P$ cases of $H$-graphs recognition. First, we show that recognition of
$H$-graphs is $NP$-hard when $H$ contains two different cycles. On the other
hand, we show a polynomial-time algorithm recognizing $L$-graphs, where $L$ is
a graph containing a cycle and an edge attached to it ($L$-graphs are called
lollipop graphs). Our work leaves open the recognition problems of $M$-graphs
for every unicyclic graph $M$ different from a cycle and a lollipop. Other
results of this work, which shed some light on the cases that remain open, are
as follows. Firstly, the recognition of $M$-graphs, where $M$ is a fixed
unicyclic graph, admits a polynomial time algorithm if we restrict the input to
graphs containing particular holes (hence recognition of $M$-graphs is probably
most difficult for chordal graphs). Secondly, the recognition of medusa graphs,
which are defined as the union of $M$-graphs, where $M$ runs over all unicyclic
graphs, is $NP$-complete.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-13T01:30:00Z">Tuesday, December 13 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.05619'>Algorithms approaching the threshold for semi-random planted clique</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rares-Darius Buhai, Pravesh K. Kothari, David Steurer</p><p>We design new polynomial-time algorithms for recovering planted cliques in
the semi-random graph model introduced by Feige and Kilian~\cite{FK01}. The
previous best algorithms for this model succeed if the planted clique has size
at least \(n^{2/3}\) in a graph with \(n\) vertices (Mehta, Mckenzie, Trevisan,
2019 and Charikar, Steinhardt, Valiant 2017). Our algorithms work for
planted-clique sizes approaching \(n^{1/2}\) -- the information-theoretic
threshold in the semi-random model~\cite{steinhardt2017does} and a conjectured
computational threshold even in the easier fully-random model. This result
comes close to resolving open questions by Feige and Steinhardt.
</p>
<p>Our algorithms are based on higher constant degree sum-of-squares relaxation
and rely on a new conceptual connection that translates certificates of upper
bounds on biclique numbers in \emph{unbalanced} bipartite Erd\H{o}s--R\'enyi
random graphs into algorithms for semi-random planted clique. The use of a
higher-constant degree sum-of-squares is essential in our setting: we prove a
lower bound on the basic SDP for certifying bicliques that shows that the basic
SDP cannot succeed for planted cliques of size $k =o(n^{2/3})$. We also provide
some evidence that the information-computation trade-off of our current
algorithms may be inherent by proving an average-case lower bound for
unbalanced bicliques in the low-degree-polynomials model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Buhai_R/0/1/0/all/0/1">Rares-Darius Buhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1">Pravesh K. Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Steurer_D/0/1/0/all/0/1">David Steurer</a></p><p>We design new polynomial-time algorithms for recovering planted cliques in
the semi-random graph model introduced by Feige and Kilian~\cite{FK01}. The
previous best algorithms for this model succeed if the planted clique has size
at least \(n^{2/3}\) in a graph with \(n\) vertices (Mehta, Mckenzie, Trevisan,
2019 and Charikar, Steinhardt, Valiant 2017). Our algorithms work for
planted-clique sizes approaching \(n^{1/2}\) -- the information-theoretic
threshold in the semi-random model~\cite{steinhardt2017does} and a conjectured
computational threshold even in the easier fully-random model. This result
comes close to resolving open questions by Feige and Steinhardt.
</p>
<p>Our algorithms are based on higher constant degree sum-of-squares relaxation
and rely on a new conceptual connection that translates certificates of upper
bounds on biclique numbers in \emph{unbalanced} bipartite Erd\H{o}s--R\'enyi
random graphs into algorithms for semi-random planted clique. The use of a
higher-constant degree sum-of-squares is essential in our setting: we prove a
lower bound on the basic SDP for certifying bicliques that shows that the basic
SDP cannot succeed for planted cliques of size $k =o(n^{2/3})$. We also provide
some evidence that the information-computation trade-off of our current
algorithms may be inherent by proving an average-case lower bound for
unbalanced bicliques in the low-degree-polynomials model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-13T01:30:00Z">Tuesday, December 13 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.05673'>Binary Error-Correcting Codes with Minimal Noiseless Feedback</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Meghal Gupta, Venkatesan Guruswami, Rachel Yun Zhang</p><p>In the setting of error-correcting codes with feedback, Alice wishes to
communicate a $k$-bit message $x$ to Bob by sending a sequence of bits over a
channel while noiselessly receiving feedback from Bob. It has been long known
(Berlekamp, 1964) that in this model, Bob can still correctly determine $x$
even if $\approx \frac13$ of Alice's bits are flipped adversarially. This
improves upon the classical setting without feedback, where recovery is not
possible for error fractions exceeding $\frac14$.
</p>
<p>The original feedback setting assumes that after transmitting each bit, Alice
knows (via feedback) what bit Bob received. In this work, our focus in on the
limited feedback model, where Bob is only allowed to send a few bits at a small
number of pre-designated points in the protocol. For any desired $\epsilon &gt;
0$, we construct a coding scheme that tolerates a fraction $ 1/3-\epsilon$ of
bit flips relying only on $O_\epsilon(\log k)$ bits of feedback from Bob sent
in a fixed $O_\epsilon(1)$ number of rounds. We complement this with a matching
lower bound showing that $\Omega(\log k)$ bits of feedback are necessary to
recover from an error fraction exceeding $1/4$ (the threshold without any
feedback), and for schemes resilient to a fraction $1/3-\epsilon$ of bit flips,
the number of rounds must grow as $\epsilon \to 0$.
</p>
<p>We also study (and resolve) the question for the simpler model of erasures.
We show that $O_\epsilon(\log k)$ bits of feedback spread over $O_\epsilon(1)$
rounds suffice to tolerate a fraction $(1-\epsilon)$ of erasures. Likewise, our
$\Omega(\log k)$ lower bound applies for erasure fractions exceeding $1/2$, and
an increasing number of rounds are required as the erasure fraction approaches
$1$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Meghal Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Guruswami_V/0/1/0/all/0/1">Venkatesan Guruswami</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rachel Yun Zhang</a></p><p>In the setting of error-correcting codes with feedback, Alice wishes to
communicate a $k$-bit message $x$ to Bob by sending a sequence of bits over a
channel while noiselessly receiving feedback from Bob. It has been long known
(Berlekamp, 1964) that in this model, Bob can still correctly determine $x$
even if $\approx \frac13$ of Alice's bits are flipped adversarially. This
improves upon the classical setting without feedback, where recovery is not
possible for error fractions exceeding $\frac14$.
</p>
<p>The original feedback setting assumes that after transmitting each bit, Alice
knows (via feedback) what bit Bob received. In this work, our focus in on the
limited feedback model, where Bob is only allowed to send a few bits at a small
number of pre-designated points in the protocol. For any desired $\epsilon &gt;
0$, we construct a coding scheme that tolerates a fraction $ 1/3-\epsilon$ of
bit flips relying only on $O_\epsilon(\log k)$ bits of feedback from Bob sent
in a fixed $O_\epsilon(1)$ number of rounds. We complement this with a matching
lower bound showing that $\Omega(\log k)$ bits of feedback are necessary to
recover from an error fraction exceeding $1/4$ (the threshold without any
feedback), and for schemes resilient to a fraction $1/3-\epsilon$ of bit flips,
the number of rounds must grow as $\epsilon \to 0$.
</p>
<p>We also study (and resolve) the question for the simpler model of erasures.
We show that $O_\epsilon(\log k)$ bits of feedback spread over $O_\epsilon(1)$
rounds suffice to tolerate a fraction $(1-\epsilon)$ of erasures. Likewise, our
$\Omega(\log k)$ lower bound applies for erasure fractions exceeding $1/2$, and
an increasing number of rounds are required as the erasure fraction approaches
$1$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-13T01:30:00Z">Tuesday, December 13 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.05823'>Minimum-weight partitioning of a set with associated subsets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yakov Zinder, Bertrand M.T. Lin, Joanna Berli&#x144;ska</p><p>The paper presents complexity results and performance guaranties for a family
of approximation algorithms for an optimisation problem arising in software
testing and manufacturing. The problem is formulated as a partitioning of a set
where each element has an associated subset in another set, but can also be
viewed as a scheduling problem with infinitely large communication delay,
precedence constraints in the form of a bipartite graph, and duplication.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zinder_Y/0/1/0/all/0/1">Yakov Zinder</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Bertrand M.T. Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Berlinska_J/0/1/0/all/0/1">Joanna Berli&#x144;ska</a></p><p>The paper presents complexity results and performance guaranties for a family
of approximation algorithms for an optimisation problem arising in software
testing and manufacturing. The problem is formulated as a partitioning of a set
where each element has an associated subset in another set, but can also be
viewed as a scheduling problem with infinitely large communication delay,
precedence constraints in the form of a bipartite graph, and duplication.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-13T01:30:00Z">Tuesday, December 13 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, December 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/12/assistant-professor-in-computer-science-at-hse-university-apply-by-january-15-2023/'>Assistant Professor in Computer Science at HSE University (apply by January 15, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Faculty of Computer Science, HSE University invites applications for positions of assistant [professor in all areas of computer science including theoretical CS. Candidates must hold a recent PhD in computer science, mathematics or related fields, posess teaching experience and speak fluent English. Tenure track positions are only available on a full-time, residential basis in [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Faculty of Computer Science, HSE University invites applications for positions of assistant [professor in all areas of computer science including theoretical CS.<br />
Candidates must hold a recent PhD in computer science, mathematics or related fields, posess teaching experience and speak fluent English.<br />
Tenure track positions are only available on a full-time, residential basis in Moscow, Russia.</p>
<p>Website: <a href="https://iri.hse.ru/ru/TTCS2223">https://iri.hse.ru/ru/TTCS2223</a><br />
Email: iri@hse.ru</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T11:11:39Z">Monday, December 12 2022, 11:11</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2022-12-12-what-about-validity/'>What about Validity?</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Perhaps the architipical trilemma is consensus - it requires three properties: agreement, liveness, and validity. Getting any two is easy, but all three together is what makes consensus such a facinating problem that continues to create new challenges even after 40 years of research. A lot of research focuses on...
        
        </div>

        <div class='tr-article-summary'>
        
          
          Perhaps the architipical trilemma is consensus - it requires three properties: agreement, liveness, and validity. Getting any two is easy, but all three together is what makes consensus such a facinating problem that continues to create new challenges even after 40 years of research. A lot of research focuses on...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T09:00:00Z">Monday, December 12 2022, 09:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/12/commercials-are-not-logical-ftx-edition.html'>Commercials are not logical.  FTX edition.</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Some people asked me to comment on FTX since I teach Crypto. My insights are no better than anyone else; however, I have wanted to do a blog post about the illogic of commercials, so I will do that with FTX as an example.&nbsp;</p><p>ALL conversations in the post are fictional.</p><p>------------------------------------</p><p>Alice: Bob,&nbsp; why did you invest $1,000,000 with FTX?</p><p>Bob: Because Tom Brady endorsed it. (See&nbsp;here&nbsp;for an article about that and&nbsp;here&nbsp;for a commercial Tom Brady did for FTX.)&nbsp;</p><p>Alice: But Tom Brady is a football player, not a finance person.&nbsp;</p><p>Bob: Well... I know that now.&nbsp;</p><p>(For an absolutely fantastic and now ironic commercial for FTX see&nbsp;here</p><p>------------------------------------------------------------</p><p>The people in commercials are&nbsp; paid to hawk the product.&nbsp;</p><p>a) Are they experts? In the above case about about FTX&nbsp; NO, they are not. So this should not work.&nbsp;</p><p>b) There are commercials where the people ARE experts. For example, a basketball player endorsing Sneaker brand (not quite an expert, but they DO use the product). But even this should not work since the viewers KNOW that the person is being PAID to tell us it's a good product.&nbsp;</p><p>c) Commercial spokesman (Geico-Gecko, Progressive-Flo, Dos&nbsp; XX- the worlds most interesting man, see his commercial&nbsp;here&nbsp;and a Ramsey Meme based on it&nbsp;here) are even stranger- they are fictional characters who are urging me to buy something.&nbsp; So the question are they experts? doesn't even make sense. Someone pretending to be someone they are not is pretending to like a product they do not use.&nbsp;</p><p>d) Some commercials pretend to be&nbsp; informative but are not. For example, the Insurance Companies seem to brag about something that ALL of the insurance companies do (bundling, not-paying-for-what-you-don't-need).&nbsp;</p><p>e) A truly new product may have an informative commercial, just to tell me that its out there. For example. Stephen Colbert's Americone Dream Ice Cream which is awesome. (My spellchecker thinks Americone is not a word. This time they are probably right.)&nbsp;</p><p>f) SO, if I did a commercial for Stephen Colbert's Americone Dream Ice Cream would you try it? Lets say I wasn't being paid and I truly did it for my love of that ice cream. STILL doesn't make sense- my tastes and yours may differ. However, you can try it and decide, and&nbsp; it costs far less than $1,000,000.</p><p>---------------------------------------</p><p>So what are we left with? The only commercials that make logical sense would be those where&nbsp;</p><p>a) the person is an expert</p><p>b) the person is not being paid</p><p>c) the person is telling you something about the product that distinguishes it from its competitors OR p its a new product</p><p>d) Its not a matter of taste- there is an absolute standard that is easily understood.&nbsp;</p><p><br></p><p>Do you know of ANY commercials like that? Influencers who are NOT paid by the people whose product they are hawking (are there such influencers?) might begin to qualify.&nbsp;</p><p>------------------------------------------------------</p><p>So LOGICALLY commercials should not work. So why do they?</p><p>a) They don't. Its possible they just are not that effective. See&nbsp;here&nbsp;for DON"T WORK and&nbsp;here&nbsp;for 8 times when it did work. I think&nbsp;this&nbsp;is a great commercial (watch it to the end) but it does not make me want to out and buy soup. (Stan Freberg wrote some GREAT commercials. They are on You Tube and I recommend them highly for entertainment. He also has several great novelty-song albums.)&nbsp;</p><p>b) Indirectly. They build brand awareness.</p><p>c) Because people are stupid. This is not an interesting answer since I still want to know what their reasoning is, whether or not its faulty.</p><p>d) Because you are part of a movement. Drink the Uncola (7UP) to be rebellious! Or the 1984-Apple commercial (see&nbsp;here). These are both odd since drinking 7UP or having an Apple Computer seem to me to be the opposite of rebellious.&nbsp;</p><p>e) Buying the product to express your philosophy:&nbsp;</p><p>Ted: Carol, why did you invest in $1,000,000 in FTX?&nbsp;</p><p>Carol: Because I believe in effective altruism.</p><p>Ted: Do you still?</p><p>Carol: This might need a rethink. But for now I'll&nbsp; invest by getting a Freedom Unlimited credit card that gets cash back since Kevin Hart says I should (see&nbsp;here).</p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Some people asked me to comment on FTX since I teach Crypto. My insights are no better than anyone else; however, I have wanted to do a blog post about the illogic of commercials, so I will do that with FTX as an example.&nbsp;</p><p>ALL conversations in the post are fictional.</p><p>------------------------------------</p><p>Alice: Bob,&nbsp; why did you invest $1,000,000 with FTX?</p><p>Bob: Because Tom Brady endorsed it. (See&nbsp;<a href="https://nypost.com/2022/11/22/tom-brady-stephen-curry-larry-david-probed-over-ftx-endorsements/">here</a>&nbsp;for an article about that and&nbsp;<a href="https://www.youtube.com/watch?v=gI0oRtEu7s0">here</a>&nbsp;for a commercial Tom Brady did for FTX.)&nbsp;</p><p>Alice: But Tom Brady is a football player, not a finance person.&nbsp;</p><p>Bob: Well... I know that now.&nbsp;</p><p>(For an absolutely fantastic and now ironic commercial for FTX see&nbsp;<a href="https://www.google.com/search?q=you+tube+FTX+superbowl+commercial&amp;rlz=1C1EJFC_enUS884US884&amp;oq=you+tube+FTX+&amp;aqs=chrome.0.69i59j0i13i512j69i57j0i13i512l7.4938j1j15&amp;sourceid=chrome&amp;ie=UTF-8#fpstate=ive&amp;vld=cid:b7e5529a,vid:_-FQqo46CJQ">here</a></p><p>------------------------------------------------------------</p><p>The people in commercials are&nbsp; paid to hawk the product.&nbsp;</p><p>a) Are they experts? In the above case about about FTX&nbsp; NO, they are not. So this should not work.&nbsp;</p><p>b) There are commercials where the people ARE experts. For example, a basketball player endorsing Sneaker brand (not quite an expert, but they DO use the product). But even this should not work since the viewers KNOW that the person is being PAID to tell us it's a good product.&nbsp;</p><p>c) Commercial spokesman (Geico-Gecko, Progressive-Flo, Dos&nbsp; XX- the worlds most interesting man, see his commercial&nbsp;<a href="https://www.youtube.com/watch?v=n5HX7y1yDi4">here</a>&nbsp;and a Ramsey Meme based on it&nbsp;<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/idont.jpg">here</a>) are even stranger- they are fictional characters who are urging me to buy something.&nbsp; So the question <i>are they experts? </i>doesn't even make sense. Someone pretending to be someone they are not is pretending to like a product they do not use.&nbsp;</p><p>d) Some commercials pretend to be&nbsp; informative but are not. For example, the Insurance Companies seem to brag about something that ALL of the insurance companies do (bundling, not-paying-for-what-you-don't-need).&nbsp;</p><p>e) A truly new product may have an informative commercial, just to tell me that its out there. For example. <i>Stephen Colbert's Americone Dream Ice Cream</i> which is awesome. (My spellchecker thinks <i>Americone</i> is not a word. This time they are probably right.)&nbsp;</p><p>f) SO, if I did a commercial for <i>Stephen Colbert's Americone Dream Ice Cream</i> would you try it? Lets say I wasn't being paid and I truly did it for my love of that ice cream. STILL doesn't make sense- my tastes and yours may differ. However, you can try it and decide, and&nbsp; it costs far less than $1,000,000.</p><p>---------------------------------------</p><p>So what are we left with? The only commercials that make logical sense would be those where&nbsp;</p><p>a) the person is an expert</p><p>b) the person is not being paid</p><p>c) the person is telling you something about the product that distinguishes it from its competitors OR p its a new product</p><p>d) Its not a matter of taste- there is an absolute standard that is easily understood.&nbsp;</p><p><br /></p><p>Do you know of ANY commercials like that? Influencers who are NOT paid by the people whose product they are hawking (are there such influencers?) might begin to qualify.&nbsp;</p><p>------------------------------------------------------</p><p>So LOGICALLY commercials should not work. So why do they?</p><p>a) They don't. Its possible they just are not that effective. See&nbsp;<a href="https://insight.kellogg.northwestern.edu/article/tv-advertising-is-usually-not-worth-it">here</a>&nbsp;for DON"T WORK and&nbsp;<a href="https://www.investopedia.com/financial-edge/1111/8-of-the-most-successful-ad-campaigns-of-all-time.aspx">here</a>&nbsp;for 8 times when it did work. I think&nbsp;<a href="https://www.google.com/search?q=you+tube+soup+commercial+stan+freberg&amp;rlz=1C1EJFC_enUS884US884&amp;ei=gaiWY7iVAqae5NoPgum46Ac&amp;ved=0ahUKEwj42avlmfP7AhUmD1kFHYI0Dn0Q4dUDCA8&amp;uact=5&amp;oq=you+tube+soup+commercial+stan+freberg&amp;gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIFCCEQqwI6CggAEEcQ1gQQsAM6BggAEBYQHjoFCAAQhgM6BwghEKABEAo6CAghEBYQHhAdSgQIQRgASgQIRhgAUNkDWOoWYOgXaAFwAXgAgAFyiAH7CJIBBDEwLjOYAQCgAQHIAQi4AQPAAQE&amp;sclient=gws-wiz-serp#fpstate=ive&amp;vld=cid:cf8fea70,vid:lZN86IOv79k">this</a>&nbsp;is a great commercial (watch it to the end) but it does not make me want to out and buy soup. (Stan Freberg wrote some GREAT commercials. They are on You Tube and I recommend them highly for entertainment. He also has several great novelty-song albums.)&nbsp;</p><p>b) Indirectly. They build brand awareness.</p><p>c) Because people are stupid. This is not an interesting answer since I still want to know what their reasoning is, whether or not its faulty.</p><p>d) Because you are part of a movement. Drink the Uncola (7UP) to be rebellious! Or the 1984-Apple commercial (see&nbsp;<a href="https://www.youtube.com/watch?v=zIE-5hg7FoA">here</a>). These are both odd since drinking 7UP or having an Apple Computer seem to me to be the opposite of rebellious.&nbsp;</p><p>e) Buying the product to express your philosophy:&nbsp;</p><p>Ted: Carol, why did you invest in $1,000,000 in FTX?&nbsp;</p><p>Carol: Because I believe in effective altruism.</p><p>Ted: Do you still?</p><p>Carol: This might need a rethink. But for now I'll&nbsp; invest by getting a Freedom Unlimited credit card that gets cash back since Kevin Hart says I should (see&nbsp;<a href="https://www.google.com/search?q=you+tube+kevin+hart+credit+card&amp;rlz=1C1EJFC_enUS884US884&amp;oq=you+tube+kevin+hart+credit+card&amp;aqs=chrome..69i57j69i64.12160j1j4&amp;sourceid=chrome&amp;ie=UTF-8#fpstate=ive&amp;vld=cid:e977cbbb,vid:m3TSpuaQvDo">here</a>).</p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T04:03:00Z">Monday, December 12 2022, 04:03</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04703'>Implementing Neural Network-Based Equalizers in a Coherent Optical Transmission System Using Field-Programmable Gate Arrays</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pedro J. Freire, Sasipim Srivallapanondh, Michael Anderson, Bernhard Spinnler, Thomas Bex, Tobias A. Eriksson, Antonio Napoli, Wolfgang Schairer, Nelson Costa, Michaela Blott, Sergei K. Turitsyn, Jaroslaw E. Prilepsky</p><p>In this work, we demonstrate the offline FPGA realization of both recurrent
and feedforward neural network (NN)-based equalizers for nonlinearity
compensation in coherent optical transmission systems. First, we present a
realization pipeline showing the conversion of the models from Python libraries
to the FPGA chip synthesis and implementation. Then, we review the main
alternatives for the hardware implementation of nonlinear activation functions.
The main results are divided into three parts: a performance comparison, an
analysis of how activation functions are implemented, and a report on the
complexity of the hardware. The performance in Q-factor is presented for the
cases of bidirectional long-short-term memory coupled with convolutional NN
(biLSTM + CNN) equalizer, CNN equalizer, and standard 1-StpS digital
back-propagation (DBP) for the simulation and experiment propagation of a
single channel dual-polarization (SC-DP) 16QAM at 34 GBd along 17x70km of LEAF.
The biLSTM+CNN equalizer provides a similar result to DBP and a 1.7 dB Q-factor
gain compared with the chromatic dispersion compensation baseline in the
experimental dataset. After that, we assess the Q-factor and the impact of
hardware utilization when approximating the activation functions of NN using
Taylor series, piecewise linear, and look-up table (LUT) approximations. We
also show how to mitigate the approximation errors with extra training and
provide some insights into possible gradient problems in the LUT approximation.
Finally, to evaluate the complexity of hardware implementation to achieve 400G
throughput, fixed-point NN-based equalizers with approximated activation
functions are developed and implemented in an FPGA.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/eess/1/au:+Freire_P/0/1/0/all/0/1">Pedro J. Freire</a>, <a href="http://arxiv.org/find/eess/1/au:+Srivallapanondh_S/0/1/0/all/0/1">Sasipim Srivallapanondh</a>, <a href="http://arxiv.org/find/eess/1/au:+Anderson_M/0/1/0/all/0/1">Michael Anderson</a>, <a href="http://arxiv.org/find/eess/1/au:+Spinnler_B/0/1/0/all/0/1">Bernhard Spinnler</a>, <a href="http://arxiv.org/find/eess/1/au:+Bex_T/0/1/0/all/0/1">Thomas Bex</a>, <a href="http://arxiv.org/find/eess/1/au:+Eriksson_T/0/1/0/all/0/1">Tobias A. Eriksson</a>, <a href="http://arxiv.org/find/eess/1/au:+Napoli_A/0/1/0/all/0/1">Antonio Napoli</a>, <a href="http://arxiv.org/find/eess/1/au:+Schairer_W/0/1/0/all/0/1">Wolfgang Schairer</a>, <a href="http://arxiv.org/find/eess/1/au:+Costa_N/0/1/0/all/0/1">Nelson Costa</a>, <a href="http://arxiv.org/find/eess/1/au:+Blott_M/0/1/0/all/0/1">Michaela Blott</a>, <a href="http://arxiv.org/find/eess/1/au:+Turitsyn_S/0/1/0/all/0/1">Sergei K. Turitsyn</a>, <a href="http://arxiv.org/find/eess/1/au:+Prilepsky_J/0/1/0/all/0/1">Jaroslaw E. Prilepsky</a></p><p>In this work, we demonstrate the offline FPGA realization of both recurrent
and feedforward neural network (NN)-based equalizers for nonlinearity
compensation in coherent optical transmission systems. First, we present a
realization pipeline showing the conversion of the models from Python libraries
to the FPGA chip synthesis and implementation. Then, we review the main
alternatives for the hardware implementation of nonlinear activation functions.
The main results are divided into three parts: a performance comparison, an
analysis of how activation functions are implemented, and a report on the
complexity of the hardware. The performance in Q-factor is presented for the
cases of bidirectional long-short-term memory coupled with convolutional NN
(biLSTM + CNN) equalizer, CNN equalizer, and standard 1-StpS digital
back-propagation (DBP) for the simulation and experiment propagation of a
single channel dual-polarization (SC-DP) 16QAM at 34 GBd along 17x70km of LEAF.
The biLSTM+CNN equalizer provides a similar result to DBP and a 1.7 dB Q-factor
gain compared with the chromatic dispersion compensation baseline in the
experimental dataset. After that, we assess the Q-factor and the impact of
hardware utilization when approximating the activation functions of NN using
Taylor series, piecewise linear, and look-up table (LUT) approximations. We
also show how to mitigate the approximation errors with extra training and
provide some insights into possible gradient problems in the LUT approximation.
Finally, to evaluate the complexity of hardware implementation to achieve 400G
throughput, fixed-point NN-based equalizers with approximated activation
functions are developed and implemented in an FPGA.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04718'>Controllability of complex networks: input node placement restricting the longest control chain</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samie Alizadeh, M&#xe1;rton P&#xf3;sfai, Abdorasoul Ghasemi</p><p>The minimum number of inputs needed to control a network is frequently used
to quantify its controllability. Control of linear dynamics through a minimum
set of inputs, however, often has prohibitively large energy requirements and
there is an inherent trade-off between minimizing the number of inputs and
control energy. To better understand this trade-off, we study the problem of
identifying a minimum set of input nodes such that controllabililty is ensured
while restricting the length of the longest control chain. The longest control
chain is the maximum distance from input nodes to any network node, and recent
work found that reducing its length significantly reduces control energy. We
map the longest control chain-constraint minimum input problem to finding a
joint maximum matching and minimum dominating set. We show that this graph
combinatorial problem is NP-complete, and we introduce and validate a heuristic
approximation. Applying this algorithm to a collection of real and model
networks, we investigate how network structure affects the minimum number of
inputs, revealing, for example, that for many real networks reducing the
longest control chain requires only few or no additional inputs, only the
rearrangement of the input nodes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alizadeh_S/0/1/0/all/0/1">Samie Alizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Posfai_M/0/1/0/all/0/1">M&#xe1;rton P&#xf3;sfai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghasemi_A/0/1/0/all/0/1">Abdorasoul Ghasemi</a></p><p>The minimum number of inputs needed to control a network is frequently used
to quantify its controllability. Control of linear dynamics through a minimum
set of inputs, however, often has prohibitively large energy requirements and
there is an inherent trade-off between minimizing the number of inputs and
control energy. To better understand this trade-off, we study the problem of
identifying a minimum set of input nodes such that controllabililty is ensured
while restricting the length of the longest control chain. The longest control
chain is the maximum distance from input nodes to any network node, and recent
work found that reducing its length significantly reduces control energy. We
map the longest control chain-constraint minimum input problem to finding a
joint maximum matching and minimum dominating set. We show that this graph
combinatorial problem is NP-complete, and we introduce and validate a heuristic
approximation. Applying this algorithm to a collection of real and model
networks, we investigate how network structure affects the minimum number of
inputs, revealing, for example, that for many real networks reducing the
longest control chain requires only few or no additional inputs, only the
rearrangement of the input nodes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04659'>A refinement on the structure of vertex-critical ($P_5$, gem)-free graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ben Cameron, Ch&#xed;nh T. Ho&#xe0;ng</p><p>We give a new, stronger proof that there are only finitely many
$k$-vertex-critical ($P_5$,~gem)-free graphs for all $k$. Our proof further
refines the structure of these graphs and allows for the implementation of a
simple exhaustive computer search to completely list all $6$- and
$7$-vertex-critical $(P_5$, gem)-free graphs. Our results imply the existence
of polynomial-time certifying algorithms to decide the $k$-colourability of
$(P_5$, gem)-free graphs for all $k$ where the certificate is either a
$k$-colouring or a $(k+1)$-vertex-critical induced subgraph. Our complete lists
for $k\le 7$ allow for the implementation of these algorithms for all $k\le 6$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Cameron_B/0/1/0/all/0/1">Ben Cameron</a>, <a href="http://arxiv.org/find/math/1/au:+Hoang_C/0/1/0/all/0/1">Ch&#xed;nh T. Ho&#xe0;ng</a></p><p>We give a new, stronger proof that there are only finitely many
$k$-vertex-critical ($P_5$,~gem)-free graphs for all $k$. Our proof further
refines the structure of these graphs and allows for the implementation of a
simple exhaustive computer search to completely list all $6$- and
$7$-vertex-critical $(P_5$, gem)-free graphs. Our results imply the existence
of polynomial-time certifying algorithms to decide the $k$-colourability of
$(P_5$, gem)-free graphs for all $k$ where the certificate is either a
$k$-colouring or a $(k+1)$-vertex-critical induced subgraph. Our complete lists
for $k\le 7$ allow for the implementation of these algorithms for all $k\le 6$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04726'>Breaking the Barrier $2^k$ for Subset Feedback Vertex Set in Chordal Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tian Bai, Mingyu Xiao</p><p>The Subset Feedback Vertex Set problem (SFVS), to delete $k$ vertices from a
given graph such that any vertex in a vertex subset (called a terminal set) is
not in a cycle in the remaining graph, generalizes the famous Feedback Vertex
Set problem and Multiway Cut problem. SFVS remains $\mathrm{NP}$-hard even in
split and chordal graphs, and SFVS in Chordal Graphs can be considered as a
special case of the 3-Hitting Set problem. However, it is not easy to solve
SFVS in Chordal Graphs faster than 3-Hitting Set. In 2019, Philip, Rajan,
Saurabh, and Tale (Algorithmica 2019) proved that SFVS in Chordal Graphs can be
solved in $2^k n^{\mathcal{O}(1)}$, slightly improving the best result $2.076^k
n^{\mathcal{O}(1)}$ for 3-Hitting Set. In this paper, we break the
"$2^k$-barrier" for SFVS in Chordal Graphs by giving a $1.619^k
n^{\mathcal{O}(1)}$-time algorithm. Our algorithm uses reduction and branching
rules based on the Dulmage-Mendelsohn decomposition and a divide-and-conquer
method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bai_T/0/1/0/all/0/1">Tian Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1">Mingyu Xiao</a></p><p>The Subset Feedback Vertex Set problem (SFVS), to delete $k$ vertices from a
given graph such that any vertex in a vertex subset (called a terminal set) is
not in a cycle in the remaining graph, generalizes the famous Feedback Vertex
Set problem and Multiway Cut problem. SFVS remains $\mathrm{NP}$-hard even in
split and chordal graphs, and SFVS in Chordal Graphs can be considered as a
special case of the 3-Hitting Set problem. However, it is not easy to solve
SFVS in Chordal Graphs faster than 3-Hitting Set. In 2019, Philip, Rajan,
Saurabh, and Tale (Algorithmica 2019) proved that SFVS in Chordal Graphs can be
solved in $2^k n^{\mathcal{O}(1)}$, slightly improving the best result $2.076^k
n^{\mathcal{O}(1)}$ for 3-Hitting Set. In this paper, we break the
"$2^k$-barrier" for SFVS in Chordal Graphs by giving a $1.619^k
n^{\mathcal{O}(1)}$-time algorithm. Our algorithm uses reduction and branching
rules based on the Dulmage-Mendelsohn decomposition and a divide-and-conquer
method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04880'>A Polynomial-Time Algorithm for MCS Partial Search Order on Chordal Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guozhen Rong, Yongjie Yang, Wenjun Li</p><p>We study the partial search order problem (PSOP) proposed recently by
Scheffler [WG 2022]. Given a graph $G$ together with a partial order over the
vertices of $G$, this problem determines if there is an $\mathcal{S}$-ordering
that is consistent with the given partial order, where $\mathcal{S}$ is a graph
search paradigm like BFS, DFS, etc. This problem naturally generalizes the
end-vertex problem which has received much attention over the past few years.
It also generalizes the so-called ${\mathcal{F}}$-tree recognition problem
which has just been studied in the literature recently. Our main contribution
is a polynomial-time dynamic programming algorithm for the PSOP on chordal
graphs with respect to the maximum cardinality search (MCS). This resolves one
of the most intriguing open questions left in the work of Sheffler [WG 2022].
To obtain our result, we propose the notion of layer structure and study
numerous related structural properties which might be of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rong_G/0/1/0/all/0/1">Guozhen Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongjie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenjun Li</a></p><p>We study the partial search order problem (PSOP) proposed recently by
Scheffler [WG 2022]. Given a graph $G$ together with a partial order over the
vertices of $G$, this problem determines if there is an $\mathcal{S}$-ordering
that is consistent with the given partial order, where $\mathcal{S}$ is a graph
search paradigm like BFS, DFS, etc. This problem naturally generalizes the
end-vertex problem which has received much attention over the past few years.
It also generalizes the so-called ${\mathcal{F}}$-tree recognition problem
which has just been studied in the literature recently. Our main contribution
is a polynomial-time dynamic programming algorithm for the PSOP on chordal
graphs with respect to the maximum cardinality search (MCS). This resolves one
of the most intriguing open questions left in the work of Sheffler [WG 2022].
To obtain our result, we propose the notion of layer structure and study
numerous related structural properties which might be of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.05015'>Robustness Implies Privacy in Statistical Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel B. Hopkins, Gautam Kamath, Mahbod Majid, Shyam Narayanan</p><p>We study the relationship between adversarial robustness and differential
privacy in high-dimensional algorithmic statistics. We give the first black-box
reduction from privacy to robustness which can produce private estimators with
optimal tradeoffs among sample complexity, accuracy, and privacy for a wide
range of fundamental high-dimensional parameter estimation problems, including
mean and covariance estimation. We show that this reduction can be implemented
in polynomial time in some important special cases. In particular, using
nearly-optimal polynomial-time robust estimators for the mean and covariance of
high-dimensional Gaussians which are based on the Sum-of-Squares method, we
design the first polynomial-time private estimators for these problems with
nearly-optimal samples-accuracy-privacy tradeoffs. Our algorithms are also
robust to a constant fraction of adversarially-corrupted samples.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hopkins_S/0/1/0/all/0/1">Samuel B. Hopkins</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1">Gautam Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Majid_M/0/1/0/all/0/1">Mahbod Majid</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1">Shyam Narayanan</a></p><p>We study the relationship between adversarial robustness and differential
privacy in high-dimensional algorithmic statistics. We give the first black-box
reduction from privacy to robustness which can produce private estimators with
optimal tradeoffs among sample complexity, accuracy, and privacy for a wide
range of fundamental high-dimensional parameter estimation problems, including
mean and covariance estimation. We show that this reduction can be implemented
in polynomial time in some important special cases. In particular, using
nearly-optimal polynomial-time robust estimators for the mean and covariance of
high-dimensional Gaussians which are based on the Sum-of-Squares method, we
design the first polynomial-time private estimators for these problems with
nearly-optimal samples-accuracy-privacy tradeoffs. Our algorithms are also
robust to a constant fraction of adversarially-corrupted samples.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-12T01:30:00Z">Monday, December 12 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, December 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/11/postdocs-in-tcs-at-university-of-copenhagen-apply-by-january-10-2023/'>Postdocs in TCS at University of Copenhagen (apply by January 10, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The CS department at the University of Copenhagen invites applications for postdocs in TCS. The application deadline is January 10, 2023. See www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html for more information and instructions how to apply. Informal enquiries are welcome to Mikkel Abrahamsen (miab@di.ku.dk), Jakob Nordstrom (jn@di.ku.dk), or Rasmus Pagh (pagh@di.ku.dk). Website: www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html Email: jn@di.ku.dk
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The CS department at the University of Copenhagen invites applications for postdocs in TCS. The application deadline is January 10, 2023. See <a href="http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html">http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html</a> for more information and instructions how to apply. Informal enquiries are welcome to Mikkel Abrahamsen (miab@di.ku.dk), Jakob Nordstrom (jn@di.ku.dk), or Rasmus Pagh (pagh@di.ku.dk).</p>
<p>Website: <a href="http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html">http://www.jakobnordstrom.se/openings/Postdoc-UCPH-230110.html</a><br />
Email: jn@di.ku.dk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-11T01:24:45Z">Sunday, December 11 2022, 01:24</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, December 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/10/phd-position-at-u-of-rochester-apply-by-december-15-2022/'>PhD position at U of Rochester (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We invite Ph.D. applicants in theoretical computer science. There is no application fee. Late applications will be considered. Several open positions in many areas such as: computational complexity, approximation and randomized algorithms, pseudorandomness, theoretical machine learning, combinatorics and additive combinatorics, game theory and economics, and computational social choice. Website: www.cs.rochester.edu/research/theory/ Email: robin.clark@rochester.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We invite Ph.D. applicants in theoretical computer science. There is no application fee. Late applications will be considered.</p>
<p>Several open positions in many areas such as:<br />
computational complexity, approximation and randomized algorithms, pseudorandomness, theoretical machine learning, combinatorics and additive combinatorics, game theory and economics, and computational social choice.</p>
<p>Website: <a href="https://www.cs.rochester.edu/research/theory/">https://www.cs.rochester.edu/research/theory/</a><br />
Email: robin.clark@rochester.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-10T16:47:48Z">Saturday, December 10 2022, 16:47</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://dstheory.wordpress.com/2022/12/10/wednesday-dec-14th-2022-omri-ben-eliezer-from-mit/'>Wednesday, Dec 14th, 2022 â Omri Ben-Eliezer from MIT</a></h3>
        <p class='tr-article-feed'>from <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next Foundations of Data Science virtual talk series on recent advances in adversarially robust streaming will take place on Wednesday, December 14th at 1:00 PM Pacific Time (16:00 Eastern Time, 22:00 Central European Time, 20:00 UTC). Omri Ben-Eliezer from MIT will talk about âRobust sampling and online learningâ Details of the talk (Zoom link)Continue reading "Wednesday, Dec 14th, 2022 â Omri Ben-Eliezer from&#160;MIT"
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="has-text-align-justify">The next <a rel="noreferrer noopener" href="https://sites.google.com/view/dstheory/home" target="_blank">Foundations of Data Science</a> virtual talk series on recent advances in <em>adversarially robust streaming</em> will take place on <strong>Wednesday, December 14th</strong> at <strong>1:00 PM Pacific Time</strong> (16:00 Eastern Time, 22:00 Central European Time, 20:00 UTC). <strong>Omri Ben-Eliezer</strong> from<strong> MIT</strong> will talk about <em>âRobust sampling and online learningâ</em></p>



<p><a href="https://sites.google.com/view/dstheory">Details of the talk (Zoom link) are available here.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>:  Random sampling is a fundamental primitive in modern algorithms, statistics and machine learning, used as a generic method to obtain a small yet ârepresentativeâ subset of the data. In this talk we shall explore to what extent random sampling is robust to adaptive inputs in a streaming setting, proposing and studying a model for sampling against a white-box adaptive adversary (where future inputs generated by the adversary are allowed to depend on the current internal state of the sampler). I will demonstrate scenarios where the adaptive sample complexity can be much larger than in the static world, but argue that these scenarios are not entirely realistic. I will then reveal a deep connection between our setting and online learning. As it turns out, the sample complexity in our sampling setting is captured by a sequential version of Rademacher complexity, a notion that is also known to capture the regret in online classification problems. Leveraging this connection, one can bound the sample complexity using the Littlestone dimension of the relevant concept class. The obtained bounds are tight in many regimes, and lead us to resolve a classical open problem on optimal regret bounds in online learning.</p>



<p>Based on joint works with Noga Alon, Yuval Dagan, Shay Moran, Moni Naor, and Eylon Yogev.</p>



<p>&nbsp;The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p>
<p class="authors">By dstheory</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-10T04:13:32Z">Saturday, December 10 2022, 04:13</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, December 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/'>Thanks</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Thanks to you all. I must explain why I have not been active in the last six months. I have had several illnesses. I had a broken hip that needed surgery I also had several COVID related illnesses, and some terrible GI issues. I am trying to get better. Thanks to my dear wife Kathryn [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Thanks to you all. I must explain why I have not been active in the last six months. I have had several illnesses. I had a broken hip that needed surgery</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/bed-4/" rel="attachment wp-att-20604"><img data-attachment-id="20604" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/bed-4/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?fit=480%2C640&amp;ssl=1" data-orig-size="480,640" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="bed" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?fit=480%2C640&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?resize=300%2C400&#038;ssl=1" alt="" width="300" height="400" class="aligncenter wp-image-20604" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?w=480&amp;ssl=1 480w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?resize=300%2C400&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/bed-1-rotated.jpeg?resize=150%2C200&amp;ssl=1 150w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" /></a></p>
<p><P><br />
I also had several COVID related illnesses, and some terrible GI issues. I am trying to get better. Thanks to my dear wife Kathryn Farley I have finally started to get better. I cannot ever thank her enough.  Kenneth Regan and Rich DeMillo and many others have also helped me. Thanks to you all. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/kkrr/" rel="attachment wp-att-20607"><img data-attachment-id="20607" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/kkrr/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?fit=739%2C299&amp;ssl=1" data-orig-size="739,299" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="KKRR" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?fit=300%2C121&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?fit=600%2C243&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?resize=550%2C223&#038;ssl=1" alt="" width="550" height="223" class="aligncenter wp-image-20607" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?w=739&amp;ssl=1 739w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/KKRR.png?resize=300%2C121&amp;ssl=1 300w" sizes="(max-width: 550px) 100vw, 550px" data-recalc-dims="1" /></a></p>
<p><P><br />
I have dodged emails and phone calls in the interim. I feel often that I am overcome with my illnesses. I am finally making some progress and I hope that I will be able to respond to you.</p>
<p>
I also plan on working more on the blog and hope you all will enjoy reading it again. Thanks for your support in the past and hope you enjoy it again.  I have been able to get out more in the past six weeks.</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/coney2/" rel="attachment wp-att-20612"><img data-attachment-id="20612" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/coney2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?fit=1260%2C427&amp;ssl=1" data-orig-size="1260,427" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Coney2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?fit=300%2C102&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?fit=600%2C203&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?resize=600%2C203&#038;ssl=1" alt="" width="600" height="203" class="aligncenter size-large wp-image-20612" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?resize=1024%2C347&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?resize=300%2C102&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?resize=768%2C260&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?resize=1200%2C407&amp;ssl=1 1200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/Coney2.png?w=1260&amp;ssl=1 1260w" sizes="(max-width: 600px) 100vw, 600px" data-recalc-dims="1" /></a></p>
<p><P><br />
Thanks to all your your support over the many years. It means the world to me. Happy holidays to all and a wonderful fruitful 2023 to everyone. (2023 is not a prime by the way.)</p>
<p>
Finally thanks to Kathryn once again. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/card2/" rel="attachment wp-att-20610"><img data-attachment-id="20610" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/09/thanks-2/card2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?fit=640%2C427&amp;ssl=1" data-orig-size="640,427" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="card2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?fit=600%2C400&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?resize=400%2C267&#038;ssl=1" alt="" width="400" height="267" class="aligncenter wp-image-20610" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?w=640&amp;ssl=1 640w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/card2.jpeg?resize=300%2C200&amp;ssl=1 300w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1" /></a></p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T23:25:51Z">Friday, December 09 2022, 23:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/09/faculty-at-university-of-southern-california-apply-by-january-6-2023/'>Faculty at University of Southern California (apply by January 6, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Computer Science Department of the University of Southern California invites applications for multiple positions for tenure-track positions at all ranks. The department is looking for exceptional candidates in all areas of computer science. One or two positions will prioritize candidates in security, privacy, and cryptography. Website: usccareers.usc.edu/job/los-angeles/open-rank-assistant-associate-full-professor-of-computer-science/1209/36964536288 Email: jiapengz@usc.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Computer Science Department of the University of Southern California invites applications for multiple positions for tenure-track positions at all ranks. The department is looking for exceptional candidates in all areas of computer science. One or two positions will prioritize candidates in security, privacy, and cryptography.</p>
<p>Website: <a href="https://usccareers.usc.edu/job/los-angeles/open-rank-assistant-associate-full-professor-of-computer-science/1209/36964536288">https://usccareers.usc.edu/job/los-angeles/open-rank-assistant-associate-full-professor-of-computer-science/1209/36964536288</a><br />
Email: jiapengz@usc.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T18:27:16Z">Friday, December 09 2022, 18:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://processalgebra.blogspot.com/2022/12/report-on-formative-research-evaluation.html'>Report on the formative research evaluation of the Department of Computer Science at Reykjavik University</a></h3>
        <p class='tr-article-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p><br>I am pleased to share with you the report I received yesterday from the panel that carried out a formative research evaluation review for the Department of Computer Science at Reykjavik University last month. (See below for some excerpts from the report.) The (IMHO, stellar) review panel consisted of Geraldine Fitzpatrick (TU Wien, Austria),  Kim Guldstrand Larsen (Aalborg University, Denmark) and Michael Wooldridge (University of Oxford, United Kingdom). </p><p>Our evaluators have given us a lot of food for thought, have identified several challenges for the department and have given us many recommendations we might follow to improve our research environment and work, as well as its impact. I trust that some of those remarks will be useful for the university as a whole.&nbsp;</p><p>Our next task as a department will be to do justice to the work of the review panel and build on it to improve our research environment and output.</p><p>I thank all my colleagues at the department, including postdocs and PhD students of course, whose creativity, drive, enthusiasm and research work have contributed to building a research environment that, in my admittedly very biassed opinion, punches well above its weight. I am very proud of their work.&nbsp;</p><p>However, we have to keep our feet on the ground and realise that, as the challenges identified by the review panel indicate, we are just starting our journey.<br>&nbsp;</p><p>Excerpts from the formative review report</p><p>"Overall we were pleased and impressed to find that a department which is very young in international terms has succeeded in establishing itself as an internationally competitive hub for Computer Science research. This is a noteworthy achievement by any measure, but is particularly impressive when considering the highly competitive culture of international computer science research, where world-class researchers are very highly-sought after and are able to demand highly lucrative packages.</p><p><br>We repeatedly heard that the department is a highly collegial environment, and has largely avoided the curse of factionalism that taints so many university departments.<br>&nbsp;</p><p>We were impressed by the international links that the department has been able to establish, with many visitors who clearly contribute to the research culture of the department at all levels. We saw evidence that directly experiencing this culture has been instrumental in a number of hires and in attracting PhD students.<br>&nbsp;</p><p>The self-evaluation report we were provided with gave a number of key performance indicators, such as volume of publications in internationally competitive journal and conference venues, research awards such as best-paper prizes, and the acquisition of research funding. We were pleased to note that, modulo some expected minor year-on-year variations, all of these measures seem to be on a positive upward trajectory.<br>&nbsp;</p><p>We noted that much of the Departmentâs research portfolio is strongly interdisciplinary, and addresses key societal challenges with demonstrable national impact.<br>&nbsp;</p><p>Finally, we noted that the Department does well in terms of diversity at faculty level, with an increased number of female staff. Other aspects of diversity are less clear, though this perhaps represents Icelandâs racial demographic."</p><p>With my ICE-TCS glasses on, I was delighted to read the panel's opinion on our centre:</p><p>"We were truly impressed by ICE-TCS that in a short span of time (inaugurated in 2005) has established itself as a world-class center within Theoretical Computer Science (TCS). In particular, we find that the center has been extremely successful combining Track A and Track B of TCS with notable research contributions within and recognitions from the sub-fields of Concurrency Theory, Logic, Programming Languages, Combinatorics and Algorithms."</p><p>As a centre, we will strive to improve following the panel's recommendations and to develop a crisp, overarching research vision for the coming few years, which may help us keep spreading the TCS gospel in Iceland and attract talent to the country. <br></p><p>By Luca Aceto</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><br />I am pleased to share with you the <a href="http://icetcs.ru.is/DCS-Reykjavik-Formative-Research-Review-November2022.pdf" target="_blank">report</a> I received yesterday from the panel that carried out a formative research evaluation review for the Department of Computer Science at Reykjavik University last month. (See below for some excerpts from the report.) The (IMHO, stellar) review panel consisted of <a href="http://igw.tuwien.ac.at/hci/people/gfitzpatrick">Geraldine Fitzpatrick</a> (TU Wien, Austria),  <a href="https://homes.cs.aau.dk/~kgl/">Kim Guldstrand Larsen</a> (Aalborg University, Denmark) and <a href="https://www.cs.ox.ac.uk/people/michael.wooldridge/">Michael Wooldridge</a> (University of Oxford, United Kingdom). </p><p>Our evaluators have given us a lot of food for thought, have identified several challenges for the department and have given us many recommendations we might follow to improve our research environment and work, as well as its impact. I trust that some of those remarks will be useful for the university as a whole.&nbsp;</p><p>Our next task as a department will be to do justice to the work of the review panel and build on it to improve our research environment and output.</p><p>I thank all my colleagues at the department, including postdocs and PhD students of course, whose creativity, drive, enthusiasm and research work have contributed to building a research environment that, in my admittedly very biassed opinion, punches well above its weight. I am very proud of their work.&nbsp;</p><p>However, we have to keep our feet on the ground and realise that, as the challenges identified by the review panel indicate, we are just starting our journey.<br />&nbsp;</p><p><b>Excerpts from the formative review report</b></p><p style="margin-left: 40px; text-align: left;">"Overall we were pleased and impressed to find that a department which is very young in international terms has succeeded in establishing itself as an internationally competitive hub for Computer Science research. This is a noteworthy achievement by any measure, but is particularly impressive when considering the highly competitive culture of international computer science research, where world-class researchers are very highly-sought after and are able to demand highly lucrative packages.</p><p style="margin-left: 40px; text-align: left;"><br />We repeatedly heard that the department is a highly collegial environment, and has largely avoided the curse of factionalism that taints so many university departments.<br />&nbsp;</p><p style="margin-left: 40px; text-align: left;">We were impressed by the international links that the department has been able to establish, with many visitors who clearly contribute to the research culture of the department at all levels. We saw evidence that directly experiencing this culture has been instrumental in a number of hires and in attracting PhD students.<br />&nbsp;</p><p style="margin-left: 40px; text-align: left;">The self-evaluation report we were provided with gave a number of key performance indicators, such as volume of publications in internationally competitive journal and conference venues, research awards such as best-paper prizes, and the acquisition of research funding. We were pleased to note that, modulo some expected minor year-on-year variations, all of these measures seem to be on a positive upward trajectory.<br />&nbsp;</p><p style="margin-left: 40px; text-align: left;">We noted that much of the Departmentâs research portfolio is strongly interdisciplinary, and addresses key societal challenges with demonstrable national impact.<br />&nbsp;</p><p style="margin-left: 40px; text-align: left;">Finally, we noted that the Department does well in terms of diversity at faculty level, with an increased number of female staff. Other aspects of diversity are less clear, though this perhaps represents Icelandâs racial demographic."</p><p>With my <a href="http://www.icetcs.ru.is/" target="_blank">ICE-TCS</a> glasses on, I was delighted to read the panel's opinion on our centre:</p><p style="margin-left: 40px; text-align: left;">"We were truly impressed by ICE-TCS that in a short span of time (inaugurated in 2005) has established itself as a world-class center within Theoretical Computer Science (TCS). In particular, we find that the center has been extremely successful combining Track A and Track B of TCS with notable research contributions within and recognitions from the sub-fields of Concurrency Theory, Logic, Programming Languages, Combinatorics and Algorithms."</p><p>As a centre, we will strive to improve following the panel's recommendations and to develop a crisp, overarching research vision for the coming few years, which may help us keep spreading the TCS gospel in Iceland and attract talent to the country. <br /></p><p class="authors">By Luca Aceto</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T10:17:00Z">Friday, December 09 2022, 10:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/09/faculty-at-georgia-tech-apply-by-december-31-2022/'>Faculty at Georgia Tech (apply by December 31, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Faculty Position at Georgia Tech SCS. Website: academicjobsonline.org/ajo/jobs/23304 Email: ssingla@gatech.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Faculty Position at Georgia Tech SCS.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/23304">https://academicjobsonline.org/ajo/jobs/23304</a><br />
Email: ssingla@gatech.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T08:23:00Z">Friday, December 09 2022, 08:23</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04166'>On the strong metric dimension of composed graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marcel Wagner, Yannick Schmitz, Egon Wanke</p><p>Two vertices $u$ and $v$ of an undirected graph $G$ are strongly resolved by
a vertex $w$ if there is a shortest path between $w$ and $u$ containing $v$ or
a shortest path between $w$ and $v$ containing $u$. A vertex set $R$ is a
strong resolving set for $G$ if for each pair of vertices there is a vertex in
$R$ that strongly resolves them. The strong metric dimension of $G$ is the size
of a minimum strong resolving set for $G$. We show that a minimum strong
resolving set for an undirected graph $G$ can be computed efficiently if and
only if a minimum strong resolving set for each biconnected component of $G$
can be computed efficiently.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wagner_M/0/1/0/all/0/1">Marcel Wagner</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmitz_Y/0/1/0/all/0/1">Yannick Schmitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Wanke_E/0/1/0/all/0/1">Egon Wanke</a></p><p>Two vertices $u$ and $v$ of an undirected graph $G$ are strongly resolved by
a vertex $w$ if there is a shortest path between $w$ and $u$ containing $v$ or
a shortest path between $w$ and $v$ containing $u$. A vertex set $R$ is a
strong resolving set for $G$ if for each pair of vertices there is a vertex in
$R$ that strongly resolves them. The strong metric dimension of $G$ is the size
of a minimum strong resolving set for $G$. We show that a minimum strong
resolving set for an undirected graph $G$ can be computed efficiently if and
only if a minimum strong resolving set for each biconnected component of $G$
can be computed efficiently.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04207'>Gap Preserving Reductions between Reconfiguration Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Naoto Ohsaka</p><p>Combinatorial reconfiguration is a growing research field studying problems
on the transformability between a pair of solutions of a search problem. We
consider the approximability of optimization variants of reconfiguration
problems; e.g., for a Boolean formula $\varphi$ and two satisfying truth
assignments $\sigma_{\sf s}$ and $\sigma_{\sf t}$ for $\varphi$, Maxmin SAT
Reconfiguration requires to maximize the minimum fraction of satisfied clauses
of $\varphi$ during transformation from $\sigma_{\sf s}$ to $\sigma_{\sf t}$.
Solving such optimization variants approximately, we may obtain a
reconfiguration sequence comprising almost-satisfying truth assignments.
</p>
<p>In this study, we prove a series of gap-preserving reductions to give
evidence that a host of reconfiguration problems are PSPACE-hard to
approximate, under some plausible assumption. Our starting point is a new
working hypothesis called the Reconfiguration Inapproximability Hypothesis
(RIH), which asserts that a gap version of Maxmin CSP Reconfiguration is
PSPACE-hard. This hypothesis may be thought of as a reconfiguration analogue of
the PCP theorem. Our main result is PSPACE-hardness of approximating Maxmin
$3$-SAT Reconfiguration of bounded occurrence under RIH. The crux of its proof
is a gap-preserving reduction from Maxmin Binary CSP Reconfiguration to itself
of bounded degree. Because a simple application of the degree reduction
technique using expander graphs due to Papadimitriou and Yannakakis does not
preserve the perfect completeness, we modify the alphabet as if each vertex
could take a pair of values simultaneously. To accomplish the soundness
requirement, we further apply an explicit family of near-Ramanujan graphs and
the expander mixing lemma. As an application of the main result, we demonstrate
that under RIH, optimization variants of popular reconfiguration problems are
PSPACE-hard to approximate.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ohsaka_N/0/1/0/all/0/1">Naoto Ohsaka</a></p><p>Combinatorial reconfiguration is a growing research field studying problems
on the transformability between a pair of solutions of a search problem. We
consider the approximability of optimization variants of reconfiguration
problems; e.g., for a Boolean formula $\varphi$ and two satisfying truth
assignments $\sigma_{\sf s}$ and $\sigma_{\sf t}$ for $\varphi$, Maxmin SAT
Reconfiguration requires to maximize the minimum fraction of satisfied clauses
of $\varphi$ during transformation from $\sigma_{\sf s}$ to $\sigma_{\sf t}$.
Solving such optimization variants approximately, we may obtain a
reconfiguration sequence comprising almost-satisfying truth assignments.
</p>
<p>In this study, we prove a series of gap-preserving reductions to give
evidence that a host of reconfiguration problems are PSPACE-hard to
approximate, under some plausible assumption. Our starting point is a new
working hypothesis called the Reconfiguration Inapproximability Hypothesis
(RIH), which asserts that a gap version of Maxmin CSP Reconfiguration is
PSPACE-hard. This hypothesis may be thought of as a reconfiguration analogue of
the PCP theorem. Our main result is PSPACE-hardness of approximating Maxmin
$3$-SAT Reconfiguration of bounded occurrence under RIH. The crux of its proof
is a gap-preserving reduction from Maxmin Binary CSP Reconfiguration to itself
of bounded degree. Because a simple application of the degree reduction
technique using expander graphs due to Papadimitriou and Yannakakis does not
preserve the perfect completeness, we modify the alphabet as if each vertex
could take a pair of values simultaneously. To accomplish the soundness
requirement, we further apply an explicit family of near-Ramanujan graphs and
the expander mixing lemma. As an application of the main result, we demonstrate
that under RIH, optimization variants of popular reconfiguration problems are
PSPACE-hard to approximate.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.04117'>Coloring Inside the Lines: The Jagged Legacy of the HOLC Neighborhood Risk Maps</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arunav Gupta</p><p>There has been a large body of work exploring the discriminatory nature of
the home mortgage risk maps produced by the Home Owners' Loan Corporation in
the late 1930s. However, little attention has been paid to the question of
whether these maps are still descriptive of racial residential boundaries in
their cities 80 years after their creation. To address this gap, Markov Chain
Monte Carlo, previously unutilized in the relevant literature, is employed to
randomly generate many plausible alternative mortgage security maps. Then, the
racial evenness of the HOLC maps and the generated maps is compared using
Shannon's entropy. These findings indicate that the HOLC maps are significantly
descriptive of the precise racial residential boundaries prevalent across
eleven US cities in 2010. The methodology used here is highly modular and
reproducible, allowing for future work measuring different outcome statistics,
locations, and time periods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Gupta_A/0/1/0/all/0/1">Arunav Gupta</a></p><p>There has been a large body of work exploring the discriminatory nature of
the home mortgage risk maps produced by the Home Owners' Loan Corporation in
the late 1930s. However, little attention has been paid to the question of
whether these maps are still descriptive of racial residential boundaries in
their cities 80 years after their creation. To address this gap, Markov Chain
Monte Carlo, previously unutilized in the relevant literature, is employed to
randomly generate many plausible alternative mortgage security maps. Then, the
racial evenness of the HOLC maps and the generated maps is compared using
Shannon's entropy. These findings indicate that the HOLC maps are significantly
descriptive of the precise racial residential boundaries prevalent across
eleven US cities in 2010. The methodology used here is highly modular and
reproducible, allowing for future work measuring different outcome statistics,
locations, and time periods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03906'>Quantum Lower Bounds for Finding Stationary Points of Nonconvex Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chenyi Zhang, Tongyang Li</p><p>Quantum algorithms for optimization problems are of general interest. Despite
recent progress in classical lower bounds for nonconvex optimization under
different settings and quantum lower bounds for convex optimization, quantum
lower bounds for nonconvex optimization are still widely open. In this paper,
we conduct a systematic study of quantum query lower bounds on finding
$\epsilon$-approximate stationary points of nonconvex functions, and we
consider the following two important settings: 1) having access to $p$-th order
derivatives; or 2) having access to stochastic gradients. The classical query
lower bounds is $\Omega\big(\epsilon^{-\frac{1+p}{p}}\big)$ regarding the first
setting, and $\Omega(\epsilon^{-4})$ regarding the second setting (or
$\Omega(\epsilon^{-3})$ if the stochastic gradient function is mean-squared
smooth). In this paper, we extend all these classical lower bounds to the
quantum setting. They match the classical algorithmic results respectively,
demonstrating that there is no quantum speedup for finding
$\epsilon$-stationary points of nonconvex functions with $p$-th order
derivative inputs or stochastic gradient inputs, whether with or without the
mean-squared smoothness assumption. Technically, our quantum lower bounds are
obtained by showing that the sequential nature of classical hard instances in
all these settings also applies to quantum queries, preventing any quantum
speedup other than revealing information of the stationary points sequentially.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Zhang_C/0/1/0/all/0/1">Chenyi Zhang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Li_T/0/1/0/all/0/1">Tongyang Li</a></p><p>Quantum algorithms for optimization problems are of general interest. Despite
recent progress in classical lower bounds for nonconvex optimization under
different settings and quantum lower bounds for convex optimization, quantum
lower bounds for nonconvex optimization are still widely open. In this paper,
we conduct a systematic study of quantum query lower bounds on finding
$\epsilon$-approximate stationary points of nonconvex functions, and we
consider the following two important settings: 1) having access to $p$-th order
derivatives; or 2) having access to stochastic gradients. The classical query
lower bounds is $\Omega\big(\epsilon^{-\frac{1+p}{p}}\big)$ regarding the first
setting, and $\Omega(\epsilon^{-4})$ regarding the second setting (or
$\Omega(\epsilon^{-3})$ if the stochastic gradient function is mean-squared
smooth). In this paper, we extend all these classical lower bounds to the
quantum setting. They match the classical algorithmic results respectively,
demonstrating that there is no quantum speedup for finding
$\epsilon$-stationary points of nonconvex functions with $p$-th order
derivative inputs or stochastic gradient inputs, whether with or without the
mean-squared smoothness assumption. Technically, our quantum lower bounds are
obtained by showing that the sequential nature of classical hard instances in
all these settings also applies to quantum queries, preventing any quantum
speedup other than revealing information of the stationary points sequentially.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03945'>Fast and Practical DAG Decomposition with Reachability Applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Giorgos Kritikakis, Ioannis G. Tollis</p><p>We present practical linear and almost linear-time algorithms to compute a
chain decomposition of a directed acyclic graph (DAG), $G=(V,E)$. The number of
vertex-disjoint chains computed is very close to the minimum. The time
complexity of our algorithm is $O(|E|+c*l)$, where $c$ is the number of path
concatenations and $l$ is the length of a longest path of the graph. We give a
comprehensive explanation on factors $c$ and $l$ in the following sections. Our
techniques have important applications in many areas, including the design of
faster practical transitive closure algorithms. We observe that $|E_{red}|\leq
width*|V|$ ($E_{red}$: non-transitive edges) and show how to find a
substantially large subset of $E_{tr}$ (transitive edges) using a chain
decomposition in linear time, without calculating the transitive closure. Our
extensive experimental results show the interplay between the width, $E_{red}$,
$E_{tr}$ in various models of graphs. We show how to compute a reachability
indexing scheme in $O(k_c*|E_{red}|)$ time, where $k_c$ is the number of chains
and $|E_{red}|$ is the number of non-transitive edges. This scheme can answer
reachabilitiy queries in constant time. The space complexity of the scheme is
$O(k_c*|V|)$. The experimental results reveal that our methods are even better
in practice than the theoretical bounds imply, indicating how fast chain
decomposition algorithms can be applied to the transitive closure problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kritikakis_G/0/1/0/all/0/1">Giorgos Kritikakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tollis_I/0/1/0/all/0/1">Ioannis G. Tollis</a></p><p>We present practical linear and almost linear-time algorithms to compute a
chain decomposition of a directed acyclic graph (DAG), $G=(V,E)$. The number of
vertex-disjoint chains computed is very close to the minimum. The time
complexity of our algorithm is $O(|E|+c*l)$, where $c$ is the number of path
concatenations and $l$ is the length of a longest path of the graph. We give a
comprehensive explanation on factors $c$ and $l$ in the following sections. Our
techniques have important applications in many areas, including the design of
faster practical transitive closure algorithms. We observe that $|E_{red}|\leq
width*|V|$ ($E_{red}$: non-transitive edges) and show how to find a
substantially large subset of $E_{tr}$ (transitive edges) using a chain
decomposition in linear time, without calculating the transitive closure. Our
extensive experimental results show the interplay between the width, $E_{red}$,
$E_{tr}$ in various models of graphs. We show how to compute a reachability
indexing scheme in $O(k_c*|E_{red}|)$ time, where $k_c$ is the number of chains
and $|E_{red}|$ is the number of non-transitive edges. This scheme can answer
reachabilitiy queries in constant time. The space complexity of the scheme is
$O(k_c*|V|)$. The experimental results reveal that our methods are even better
in practice than the theoretical bounds imply, indicating how fast chain
decomposition algorithms can be applied to the transitive closure problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.03957'>DeMEtRIS: Counting (near)-Cliques by Crawling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Suman K.Bera, Jayesh Choudhari, Shahrzad Haddadan, Sara Ahmadian</p><p>We study the problem of approximately counting cliques and near cliques in a
graph, where the access to the graph is only available through crawling its
vertices; thus typically seeing only a small portion of it. This model, known
as the random walk model or the neighborhood query model has been introduced
recently and captures real-life scenarios in which the entire graph is too
massive to be stored as a whole or be scanned entirely and sampling vertices
independently is non-trivial in it. We introduce DeMEtRIS: Dense Motif
Estimation through Random Incident Sampling. This method provides a scalable
algorithm for clique and near clique counting in the random walk model. We
prove the correctness of our algorithm through rigorous mathematical analysis
and extensive experiments. Both our theoretical results and our experiments
show that DeMEtRIS obtains a high precision estimation by only crawling a
sub-linear portion on vertices, thus we demonstrate a significant improvement
over previously known results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bera_S/0/1/0/all/0/1">Suman K.Bera</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhari_J/0/1/0/all/0/1">Jayesh Choudhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddadan_S/0/1/0/all/0/1">Shahrzad Haddadan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmadian_S/0/1/0/all/0/1">Sara Ahmadian</a></p><p>We study the problem of approximately counting cliques and near cliques in a
graph, where the access to the graph is only available through crawling its
vertices; thus typically seeing only a small portion of it. This model, known
as the random walk model or the neighborhood query model has been introduced
recently and captures real-life scenarios in which the entire graph is too
massive to be stored as a whole or be scanned entirely and sampling vertices
independently is non-trivial in it. We introduce DeMEtRIS: Dense Motif
Estimation through Random Incident Sampling. This method provides a scalable
algorithm for clique and near clique counting in the random walk model. We
prove the correctness of our algorithm through rigorous mathematical analysis
and extensive experiments. Both our theoretical results and our experiments
show that DeMEtRIS obtains a high precision estimation by only crawling a
sub-linear portion on vertices, thus we demonstrate a significant improvement
over previously known results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-09T01:30:00Z">Friday, December 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, December 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2022/12/news-for-october-2022-2/'>News for November 2022</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          All the best to everyone for a Happy 2023. The holiday season is ripe with lots of papers to engage our readers. So, we have nine papers and we hope some of those will catch your fancy. As a new year treat, we also feature Gilmer&#8217;s constant lower bound on the union-closed sets problem of [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>All the best to everyone for a Happy 2023. The holiday season is ripe with lots of papers to engage our readers. So, we have nine papers and we hope some of those will catch your fancy. As a new year treat, we also feature Gilmer&#8217;s constant lower bound on the union-closed sets problem of Frankl. On we go.</p>



<p></p>



<p><strong>Sublinear Time Algorithms and Complexity of Approximate Maximum Matching</strong> by Soheil Behnezhad, Mohammad Roghani, Aviad Rubinstein (<a href="https://arxiv.org/abs/2211.15843">arXiv</a>) This paper makes significantly advances our understanding of the maximum matching problem in the sublinear regime. Your goal is to estimate the size of the maximum matching and you may assume that you have query access to the adjacency list of your graph. Our posts from <a href="https://ptreview.sublinear.info/2021/12/">Dec 2021</a> and <a href="https://ptreview.sublinear.info/2022/07/news-for-june-2022/">June 2022</a> reported some impressive progress on this problem. The upshot from these works essentially said that you can beat greedy matching and obtain a \(\frac{1}{2} + \Omega(1)\) approximate maximum matching in sublinear time. Let me first go over the algorithmic results from the current paper. The paper shows the following two algorithmic results:</p>



<p>(1) An algorithm that runs in time \(n^{2 &#8211; \Omega_{\varepsilon}(1)}\) and returns a \(2/3 &#8211; \varepsilon\) approximation to maximum matching in general graphs, and </p>



<p>(2) An algorithm that runs in time \(n^{2 &#8211; \Omega_{\varepsilon}(1)}\) and returns a \(2/3 + \varepsilon\) approximation to maximum matching size in <em>bipartite</em> graphs. </p>



<p>The question remained &#8212; can we show a lower bound that grows superlinearly with \(n\). The current work achieves this and shows that <em>even on bipartite graphs</em>, you must make at least \(n^{1.2 &#8211; o(1)}\) <em>queries </em>to the adjacency list to get a better than \(2/3 + \Omega(1)\) approximation.  (An aside: A concurrent work by <a href="https://arxiv.org/abs/2212.00189">Bhattacharya-Kiss-Saranurak</a> from December also obtains similar algorithmic results for approximating the maximum matching size in general graphs). </p>



<p><strong>Directed Isoperimetric Theorems for Boolean Functions on the Hypergrid and an \(\widetilde{O}(n \sqrt d)\) Monotonicity Tester</strong> by Hadley Black, Deeparnab Chakrabarty, C. Seshadhri (<a href="https://arxiv.org/abs/2211.05281">arXiv</a>) Boolean Monotonicity testing is as classic as classic gets in property testing. Encouraged by the success of isoperimetric theorems over the hypercube domain and the monotonicity testers powered by these isoperimetries (over the hypercube), one may wish to obtain efficient monotonicity testers for the hypergrid \([n]^d\). Indeed, the same gang of authors as above showed in a previous work that a Margulis style directed isoperimetry can be extended from the lowly hypercube to the hypergrid. This resulted in a tester with \(\widetilde{O}(d^{5/6})\) queries. The more intricate task of proving a directed Talagrand style isoperimetry that underlies the Khot-Minzer-Safra breakthrough was a challenge. Was. The featured work extends this isoperimetry from the hypercube to the hypergrid and this gives a tester with query complexity \(\widetilde{O}(n \sqrt d)\) which is an improvement over the \(d^{5/6}\) bound for domains where \(n\) is (say) some small constant. But as they say, when it rains, it pours. This brings us to a concurrent paper with the same result.</p>



<p></p>



<p><strong>Improved Monotonicity Testers via Hypercube Embeddings</strong> by Mark Braverman, Subhash Khot, Guy Kindler, Dor Minzer (<a href="https://arxiv.org/abs/2211.09229">arXiv</a>) Similar to the paper above, this paper also obtains monotonicity testers over the hypergrid domain, \([n]^d\), with \(\widetilde{O}(n^3 \sqrt d)\) queries. This paper also presents monotonicity testers over the standard hypercube domain &#8212; \(\{0,1\}^d\) in the \(p\)-biased setting. In particular, their tester issues \(\widetilde{O}(\sqrt d)\) queries to successfully test monotonicity on the \(p\)-biased cube. Coolly enough, this paper also proves directed Talagrand style isoperimetric inequalities both over the hypergrid and the \(p\)-biased hypercube domains.</p>



<p><strong>Toeplitz Low-Rank Approximation with Sublinear Query Complexity</strong> by Michael Kapralov, Hannah Lawrence, Mikhail Makarov, Cameron Musco, Kshiteej Sheth (<a href="https://arxiv.org/abs/2211.11328">arXiv</a>) Another intriguing paper for the holiday month. So, take a <a href="https://en.wikipedia.org/wiki/Toeplitz_matrix">Toeplitz matrix</a>. Did you know that any <em>psd</em> Toeplitz matrix admits a (near-optimal in the Frobenius norm) low-rank approximation which is itself Toeplitz? This is a remarkable statement. The featured paper proves this result and uses it to get more algorithmic mileage. In particular, suppose you are given a \(d \times d\) Toeplitz matrix \(T\). Armed with the techniques from the paper you get algorithms that return a Toeplitz matrix \(\widetilde{T}\) with rank slightly bigger than \(rank(T)\) which is a very good approximation to \(T\) in the Frobenius norm. Moreover, the algorithm only issues a number of queries sublinear in the size of \(T\).</p>



<p></p>



<p><strong>Sampling an Edge in Sublinear Time Exactly and Optimally</strong> by Talya Eden, Shyam Narayanan and Jakub TÄtek (<a href="https://arxiv.org/abs/2211.04981">arXiv</a>) Regular readers of PTReview are no strangers to the fundamental task of sampling a random edge from a graph which you can access via query access to its vertices. Of course, you don&#8217;t have direct access to the edges of this graph. This paper considers the task of sampling a truly uniform edge from the graph \(G = (V,E)\) with \(|V| = n, |E| = m\). In STOC 22, TÄtek and Thorup presented an algorithm for a relaxation of this problem where you want an \(\varepsilon\)-approximately unifrom edge. This algorithm runs in time \(O\left(\frac{n}{\sqrt{m}} \cdot \log(1/\varepsilon) \right)\). The featured paper presents an algorithm that samples an honest to goodness uniform edge in expected time \(O(n/\sqrt{m})\). This closes the problem as we already know a matching lower bound. Indeed, just consider a graph with \(O(\sqrt m)\) vertices which induce a clique and all the remaining components are singletons. You need to sample at least \(\Omega(n/\sqrt m)\) vertices before you see any edge.</p>



<p></p>



<p><strong>Support Size Estimation: The Power of Conditioning</strong> by Diptarka Chakraborty, Gunjan Kumar, Kuldeep S. Meel (<a href="https://arxiv.org/abs/2211.11967">arXiv</a>) This work considers the classic problem of support size estimation with a slight twist. You are given access to a stronger (conditioning based) sampling oracle. Let me highlight one of the results from this paper. So, you are given a distribution \(D\) where \(supp(D) \subseteq [n]\). You want to obtain an estimate to \(supp(D)\) that lies within \(supp(D) \pm \varepsilon n\) with high probability. Suppose you are also given access to the following sampling oracle. You may choose any subset \(S \subseteq [n]\) and you may request a sample \(x \sim D\vert_S\). An element \(x \in S\) is returned with probability \(D\vert_S(x) = D(x)/D(S)\) (for simplicity of this post, let us assume \(D(S) &gt; 0\)). In addition, this oracle also reveals for you the value \(D(x)\). The paper shows that the algorithmic task of obtaining a high probability estimate to the support size (to within \(\pm \varepsilon n\)) with this sampling oracle admits a lower bound of \(\Omega(\log (\log n)\) calls to the sampling oracle.</p>



<p><strong>Computing (1+epsilon)-Approximate Degeneracy in Sublinear Time</strong> by Valerie King, Alex Thomo, Quinton Yong (<a href="https://arxiv.org/abs/2211.04627">arXiv</a>) Degeneracy is one of the important graph parameters which is relevant to several problems in algorithmic graph theory. A graph \(G = (V,E)\) is \(\delta\)-degenerate if all induced subgraphs of \(G\) contain a vertex with degree at most \(\delta\). The featured paper presents algorithms for a \((1 + \varepsilon)\)-approximation to degeneracy of \(G\) where you are given access to \(G\) via its adjacency list. </p>



<p><strong>Learning and Testing Latent-Tree Ising Models Efficiently</strong> by Davin Choo, Yuval Dagan, Constantinos Daskalakis, Anthimos Vardis Kandiros (<a href="https://arxiv.org/abs/2211.13291">arXiv</a>) Ising models are emerging as a rich and fertile frontier for Property Testing and Learning Theory researchers (at least to the uninitiated ones like me). This paper considers latent-tree ising models. These are ising models that can only be observed at their leaf nodes. One of the results in this paper gives an algorithm for testing whether the leaf distributions attached to two latent-tree ising models are close or far in the TV distance.</p>



<p></p>



<p><strong>A constant lower bound for the union-closed sets conjecture</strong> by Justin Gilmer (<a href="https://arxiv.org/abs/2211.09055">arXiv</a>) The union-closed sets conjecture of Frankl states that for any union closed set system \(\mathcal{F} \subseteq 2^{[n]}\), it holds that there is a mysterious element \(i \in [n]\) that shows up in at least \(c = 1/2\) of the sets in \(\mathcal{F}\). Gilmer took a first swipe on this problem and gave a constant lower bound of \(c = 0.01\). This has already been improved by at least four different groups to \(\frac{3-\sqrt{5}}{2}\), a bound which is the limit of Gilmer&#8217;s method (which takes all of only 9 pages!). </p>



<p>The key lemma Gilmer proves is the following. Suppose you sample two sets: \(A, B \sim \mathcal{D}_n\) <em>(iid)</em> from some distribution \(\mathcal{D}_n\) over the subsets of \([n]\). Suppose for every index \(i \in [n]\), it holds that the probability that the element \(i\) shows up in the random set \(A\) is at most $0.01$. Then you have \(H(A \cup B) \geq 1.26 H(A)\). This is all you need to finish Gilmer&#8217;s proof (of \(c = 0.01\)). The remaining argument is as follows. Suppose, by the way of contradiction, that no element shows up in at least \(0.01\) fraction of sets in the union closed family \(\mathcal{F}\). An application of the key lemma would then give \(H(A \cup B) &gt; H(A)\) which is a contradiction if \(A,B\) are chosen uniformly from \(\mathcal{F}\). The proof of the key lemma is also fairly slick and uses pretty simple information theoretic tools.</p>
<p class="authors">By Akash</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T18:22:31Z">Thursday, December 08 2022, 18:22</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/12/harry-lewiss-talk-on-birth-of-binary-on.html'>Harry Lewis's talk  on The Birth of Binary on Dec 8 (Thats today!)</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;More on the information on Harry Lewis's&nbsp; talk is in his blog post about it:here</p><p><br></p><p>1) On Dec 8, 2022 Harry Lewis is giving the annual Thoraf Skolem Memorial Lecture on</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;The Birth of binary&nbsp;</p><p>Its in Oslo. BOO- I can't get there!</p><p>It will be on Zoom- YEAH I can see it! Here is the link:&nbsp;here</p>It will be at 7:15AM East Coast Time- BOO- I needs my sleep!(Plus, I am posting this after its over)<br>It will be recorded-YEAH I can see it later. CAVEAT- Will I?<br>(It will be linked to at the link in item 4 below.)<br><br>2) Lloyd Strickland and Harry Lewis have a book on the subject:&nbsp;here&nbsp;titled<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Leibniz on binary: The Invention of Computer Arithmetic.<br>3) Questions like who invented binary&nbsp; or who invented parallelism or&nbsp;who first proved the dual-muffin theorem&nbsp;can be hard to answer.&nbsp;First&nbsp; is an ill defined term. In the current era we can see who published first, which is usually well defined, though might not get at the heart of the issue.<br><br>Which brings us to Leibniz on Binary.&nbsp; He had lots of notes, not really intended for modern readers or even for readers in his own time. The notes lay out binary notation and some algorithms, but not in a modern way. Hence the book is quite valuable to tell a modern audience what Leibniz did. Leibniz published very little of it.&nbsp; Even so, seeing what he did, the statement&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Leibnitz invented binary is reasonable. Some of his notes dealt with what we would now call complexity, so I need to add him to my already-long list of people who had modern ideas about complexity.&nbsp;<br>4) For more on the Skolem Lecture, see&nbsp;here<p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;More on the information on Harry Lewis's&nbsp; talk is in his blog post about it:<a href="http://harry-lewis.blogspot.com/2022/11/skolem-lecture-on-birth-of-binary-8.html">here</a></p><p><br /></p><p>1) On Dec 8, 2022 Harry Lewis is giving the annual Thoraf Skolem Memorial Lecture on</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<i>The Birth of binary&nbsp;</i></p><p>Its in Oslo. BOO- I can't get there!</p><p>It will be on Zoom- YEAH I can see it! Here is the link:&nbsp;<a href="https://uio.zoom.us/j/63956167845">here</a></p><div><div>It will be at 7:15AM East Coast Time- BOO- I needs my sleep!</div><div>(Plus, I am posting this after its over)</div><div><br /></div><div>It will be recorded-YEAH I can see it later. CAVEAT- Will I?</div><div><br /></div><div>(It will be linked to at the link in item 4 below.)</div><div><br /></div><div><br /></div><div>2) Lloyd Strickland and Harry Lewis have a book on the subject:&nbsp;<a href="https://mitpress.mit.edu/9780262544344/leibniz-on-binary/">here</a>&nbsp;titled</div><div><br /></div><div><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Leibniz on binary: The Invention of Computer Arithmetic.</i></div></div><div><i><br /></i></div><div><div>3) Questions like <i>who invented binary&nbsp; </i>or <i>who invented parallelism</i> or&nbsp;<i>who first proved the dual-muffin theorem&nbsp;</i>can be hard to answer.&nbsp;<i>First</i>&nbsp; is an ill defined term. In the current era we can see who published first, which is usually well defined, though might not get at the heart of the issue.</div></div><div><br /></div><div><div><br /></div><div>Which brings us to Leibniz on Binary.&nbsp; He had lots of notes, not really intended for modern readers or even for readers in his own time. The notes lay out binary notation and some algorithms, but not in a modern way. Hence the book is quite valuable to tell a modern audience what Leibniz did. Leibniz published very little of it.&nbsp; Even so, seeing what he did, the statement</div><div><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Leibnitz invented binary</i></div><div> is reasonable. Some of his notes dealt with what we would now call complexity, so I need to add him to my already-long list of people who had modern ideas about complexity.&nbsp;</div><div><br /></div><div>4) For more on the Skolem Lecture, see&nbsp;<a href="https://www.hf.uio.no/ifikk/english/research/groups/logic/events/">here</a></div></div><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-08T15:38:00Z">Thursday, December 08 2022, 15:38</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
