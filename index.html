<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-02-27T21:30:28Z">Monday, February 27 2023, 21:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, February 27
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/i-wish-we-had-less-students-in-class.html'>I wish we had less students in a Class. Demographics says I may get my wish.</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;According to&nbsp;this&nbsp;article, in the near future LESS people will be going to college. There is even a name for this upcoming shift: The Enrollment Cliff. Why?</p><p>Is it Covid-related?&nbsp; Is it that College has gotten to expensive? To liberal? To much cancel culture?&nbsp; To many dead white males in the core? The core is to multicultural? Online learning is stealing our students?&nbsp;</p><p>No. The reason is actually very boring and does not serve anyone's political agenda. (thats not quite right).&nbsp; Or any agenda. And you can probably guess the cause from the title of this blog post.</p><p>For some years up until 2007 the birth rate was slowly dropping. Then there was a large drop in the birth rate after the recession of 2007, and the birth rate has never really recovered. And the recession might not have that much to do with it-- the long term move from an agricultural society (where kids are an economic gain) to an industrial one (where, after child labor laws and the expense of college, kids are an economic loss- though that can be debated) has resulted in a very long term decline in births.&nbsp;</p><p>And from personal experience, I know (a) very few people who have 4 or more kids, (b) there is NO stigma about having 0 kids as there once was.&nbsp; Of course the sample size of people I know may be skewed.&nbsp;</p><p>ANYWAY, what will this mean for colleges?&nbsp;</p><p>a) Harvard, Yale, etc will not be affected. Plenty of people will still apply. Note that they draw from all of American and also internationally.&nbsp;</p><p>b) Colleges that draw from a local area may be affected a lot since they depend on locals, and that population may be shrinking.&nbsp;</p><p>c) Schools in between Harvard and Small colleges- hard to say.&nbsp;</p><p>d) The sports betting places paying schools to allow them to promote on campus (and in some cases helping them promote it) may find far less students to sucker into this loser's game. See my blog on this topic&nbsp;here</p><p>Univ of MD has around 4000 Computer Science majors (depending on who tells you this its either a brag or a complaint). In the Spring of 2023 there are three lectures of Discrete math of sizes 240, 270, and 90. Each of those also has recitations of&nbsp; 30 (or so) each. If the decline is gradual (either from demographics or from the CS majors bubble finally bursting, or from the other reasons above) then I am sure we can handle it. If it declines very suddenly we may have a problem adjusting.&nbsp;</p><p>One caveat to this that I've heard is that immigration will save us. Maybe. But America is politically going in the opposite direction. The counterargument of without immigration there will be less students going to college is not that compelling to most Americans. There are other more intelligent and compelling pro-immigration arguments. However, American politics is no longer interested in compelling and logical arguments. (The notion that it once was may be nostalgia for a time that never was.)&nbsp;</p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;According to&nbsp;<a href="https://www.vox.com/the-highlight/23428166/college-enrollment-population-education-crash">this</a>&nbsp;article, in the near future LESS people will be going to college. There is even a name for this upcoming shift: <i>The Enrollment Cliff. </i>Why?</p><p>Is it Covid-related?&nbsp; Is it that College has gotten to expensive? To liberal? To much cancel culture?&nbsp; To many dead white males in the core? The core is to multicultural? Online learning is stealing our students?&nbsp;</p><p>No. The reason is actually very boring and does not serve anyone's political agenda. (thats not quite right).&nbsp; Or any agenda. And you can probably guess the cause from the title of this blog post.</p><p>For some years up until 2007 the birth rate was slowly dropping. Then there was a large drop in the birth rate after the recession of 2007, and the birth rate has never really recovered. And the recession might not have that much to do with it-- the long term move from an agricultural society (where kids are an economic gain) to an industrial one (where, after child labor laws and the expense of college, kids are an economic loss- though that can be debated) has resulted in a very long term decline in births.&nbsp;</p><p>And from personal experience, I know (a) very few people who have 4 or more kids, (b) there is NO stigma about having 0 kids as there once was.&nbsp; Of course the sample size of people I know may be skewed.&nbsp;</p><p>ANYWAY, what will this mean for colleges?&nbsp;</p><p>a) Harvard, Yale, etc will not be affected. Plenty of people will still apply. Note that they draw from all of American and also internationally.&nbsp;</p><p>b) Colleges that draw from a local area may be affected a lot since they depend on locals, and that population may be shrinking.&nbsp;</p><p>c) Schools in between Harvard and Small colleges- hard to say.&nbsp;</p><p>d) The sports betting places paying schools to allow them to promote on campus (and in some cases helping them promote it) may find far less students to sucker into this loser's game. See my blog on this topic&nbsp;<a href="https://blog.computationalcomplexity.org/2023/02/it-is-more-important-than-ever-to-teach.html">here</a></p><p>Univ of MD has around 4000 Computer Science majors (depending on who tells you this its either a brag or a complaint). In the Spring of 2023 there are three lectures of Discrete math of sizes 240, 270, and 90. Each of those also has recitations of&nbsp; 30 (or so) each. If the decline is gradual (either from demographics or from the CS majors bubble finally bursting, or from the other reasons above) then I am sure we can handle it. If it declines very suddenly we may have a problem adjusting.&nbsp;</p><p>One caveat to this that I've heard is that immigration will save us. Maybe. But America is politically going in the opposite direction. The counterargument of <i>without immigration there will be less students</i> <i>going to college </i>is not that compelling to most Americans. There are other more intelligent and compelling pro-immigration arguments. However, American politics is no longer interested in compelling and logical arguments. (The notion that it once was may be nostalgia for a time that never was.)&nbsp;</p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T15:10:00Z">Monday, February 27 2023, 15:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/017'>TR23-017 |  Near-Optimal Set-Multilinear Formula Lower Bounds | 

	Deepanshu Kush, 

	Shubhangi Saraf</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The seminal work of Raz (J. ACM 2013) as well as the recent breakthrough results by Limaye, Srinivasan, and Tavenas (FOCS 2021, STOC 2022) have demonstrated a potential avenue for obtaining lower bounds for general algebraic formulas, via strong enough lower bounds for set-multilinear formulas.

In this paper, we make progress along this direction by proving near-optimal lower bounds against low-depth as well
as unbounded-depth set-multilinear formulas.
More precisely, we show that over any field of characteristic zero, there is a polynomial $f$ computed by a polynomial-sized set-multilinear branching program (i.e., $f$ is in set-multilinear VBP) defined over $\Theta(n^2)$ variables and of degree $\Theta(n)$, such that any product-depth $\Delta$ set-multilinear formula computing $f$ has size at
least $n^{\Omega( n^{1/\Delta}/\Delta)}$. Moreover, we show that any unbounded-depth set-multilinear formula computing $f$ has size at least $n^{\Omega(\log n)}$.


If such strong lower bounds are proven for the iterated matrix multiplication (IMM) polynomial or rather, any polynomial
that is computed by an ordered set-multilinear branching program (i.e., a further restriction of set-multilinear VBP), then this would have dramatic consequences as it would imply super-polynomial lower bounds 
for general algebraic formulas (Raz, J. ACM 2013; Tavenas, Limaye, and Srinivasan, STOC 2022).

Prior to our work, either only weaker lower bounds were known for the IMM polynomial (Tavenas, Limaye, and Srinivasan, STOC 2022), or similar strong lower bounds were known but for a
hard polynomial not known to be even in set-multilinear VP (Kush and Saraf, CCC 2022; Raz, J. ACM 2009).

By known depth-reduction results, our lower bounds are essentially tight
for $f$ and in general, for any hard polynomial that is in set-multilinear VBP or set-multilinear VP.
Any asymptotic improvement in the lower bound (for a hard polynomial, say, in VNP) would imply super-polynomial lower bounds for general set-multilinear circuits.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The seminal work of Raz (J. ACM 2013) as well as the recent breakthrough results by Limaye, Srinivasan, and Tavenas (FOCS 2021, STOC 2022) have demonstrated a potential avenue for obtaining lower bounds for general algebraic formulas, via strong enough lower bounds for set-multilinear formulas.

In this paper, we make progress along this direction by proving near-optimal lower bounds against low-depth as well
as unbounded-depth set-multilinear formulas.
More precisely, we show that over any field of characteristic zero, there is a polynomial $f$ computed by a polynomial-sized set-multilinear branching program (i.e., $f$ is in set-multilinear VBP) defined over $\Theta(n^2)$ variables and of degree $\Theta(n)$, such that any product-depth $\Delta$ set-multilinear formula computing $f$ has size at
least $n^{\Omega( n^{1/\Delta}/\Delta)}$. Moreover, we show that any unbounded-depth set-multilinear formula computing $f$ has size at least $n^{\Omega(\log n)}$.


If such strong lower bounds are proven for the iterated matrix multiplication (IMM) polynomial or rather, any polynomial
that is computed by an ordered set-multilinear branching program (i.e., a further restriction of set-multilinear VBP), then this would have dramatic consequences as it would imply super-polynomial lower bounds 
for general algebraic formulas (Raz, J. ACM 2013; Tavenas, Limaye, and Srinivasan, STOC 2022).

Prior to our work, either only weaker lower bounds were known for the IMM polynomial (Tavenas, Limaye, and Srinivasan, STOC 2022), or similar strong lower bounds were known but for a
hard polynomial not known to be even in set-multilinear VP (Kush and Saraf, CCC 2022; Raz, J. ACM 2009).

By known depth-reduction results, our lower bounds are essentially tight
for $f$ and in general, for any hard polynomial that is in set-multilinear VBP or set-multilinear VP.
Any asymptotic improvement in the lower bound (for a hard polynomial, say, in VNP) would imply super-polynomial lower bounds for general set-multilinear circuits.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T15:04:14Z">Monday, February 27 2023, 15:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12796'>Revisiting Graph Persistence for Updates and Efficiency</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tamal K. Dey, Tao Hou</p><p>It is well known that ordinary persistence on graphs can be computed more
efficiently than the general persistence. Recently, it has also been shown that
zigzag persistence on graphs also exhibits similar behavior. Motivated by these
results, we revisit graph persistence and propose efficient algorithms
especially for local updates on filtrations, similar to what is done in
ordinary persistence for computing the vineyard. We show that, for a filtration
of length $m$ (i) switches (transpositions) in ordinary graph persistence can
be done in $O(\log^4 m)$ amortized time; (ii) zigzag persistence on graphs can
be computed in $O(m\log m)$ time, which improves a recent $O(m\log^4n)$ time
algorithm assuming $n$, the size of the union of all graphs in the filtration,
satisfies $n\in\Omega({m^\varepsilon})$ for any fixed $0&lt;\varepsilon&lt;1$; (iii)
open-closed, closed-open, and closed-closed bars in dimension $0$ for graph
zigzag persistence can be updated in $O(\log^4m)$ amortized time, whereas the
open-open bars in dimension $0$ and closed-closed bars in dimension $1$ can be
done in $O(m)$ time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dey_T/0/1/0/all/0/1">Tamal K. Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_T/0/1/0/all/0/1">Tao Hou</a></p><p>It is well known that ordinary persistence on graphs can be computed more
efficiently than the general persistence. Recently, it has also been shown that
zigzag persistence on graphs also exhibits similar behavior. Motivated by these
results, we revisit graph persistence and propose efficient algorithms
especially for local updates on filtrations, similar to what is done in
ordinary persistence for computing the vineyard. We show that, for a filtration
of length $m$ (i) switches (transpositions) in ordinary graph persistence can
be done in $O(\log^4 m)$ amortized time; (ii) zigzag persistence on graphs can
be computed in $O(m\log m)$ time, which improves a recent $O(m\log^4n)$ time
algorithm assuming $n$, the size of the union of all graphs in the filtration,
satisfies $n\in\Omega({m^\varepsilon})$ for any fixed $0&lt;\varepsilon&lt;1$; (iii)
open-closed, closed-open, and closed-closed bars in dimension $0$ for graph
zigzag persistence can be updated in $O(\log^4m)$ amortized time, whereas the
open-open bars in dimension $0$ and closed-closed bars in dimension $1$ can be
done in $O(m)$ time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12823'>Generative Models of Huge Objects</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lunjia Hu, Inbal Livni-Navon, Omer Reingold</p><p>This work initiates the systematic study of explicit distributions that are
indistinguishable from a single exponential-size combinatorial object. In this
we extend the work of Goldreich, Goldwasser and Nussboim (SICOMP 2010) that
focused on the implementation of huge objects that are indistinguishable from
the uniform distribution, satisfying some global properties (which they coined
truthfulness). Indistinguishability from a single object is motivated by the
study of generative models in learning theory and regularity lemmas in graph
theory. Problems that are well understood in the setting of pseudorandomness
present significant challenges and at times are impossible when considering
generative models of huge objects.
</p>
<p>We demonstrate the versatility of this study by providing a learning
algorithm for huge indistinguishable objects in several natural settings
including: dense functions and graphs with a truthfulness requirement on the
number of ones in the function or edges in the graphs, and a version of the
weak regularity lemma for sparse graphs that satisfy some global properties.
These and other results generalize basic pseudorandom objects as well as
notions introduced in algorithmic fairness. The results rely on notions and
techniques from a variety of areas including learning theory, complexity
theory, cryptography, and game theory.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Lunjia Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Livni_Navon_I/0/1/0/all/0/1">Inbal Livni-Navon</a>, <a href="http://arxiv.org/find/cs/1/au:+Reingold_O/0/1/0/all/0/1">Omer Reingold</a></p><p>This work initiates the systematic study of explicit distributions that are
indistinguishable from a single exponential-size combinatorial object. In this
we extend the work of Goldreich, Goldwasser and Nussboim (SICOMP 2010) that
focused on the implementation of huge objects that are indistinguishable from
the uniform distribution, satisfying some global properties (which they coined
truthfulness). Indistinguishability from a single object is motivated by the
study of generative models in learning theory and regularity lemmas in graph
theory. Problems that are well understood in the setting of pseudorandomness
present significant challenges and at times are impossible when considering
generative models of huge objects.
</p>
<p>We demonstrate the versatility of this study by providing a learning
algorithm for huge indistinguishable objects in several natural settings
including: dense functions and graphs with a truthfulness requirement on the
number of ones in the function or edges in the graphs, and a version of the
weak regularity lemma for sparse graphs that satisfy some global properties.
These and other results generalize basic pseudorandom objects as well as
notions introduced in algorithmic fairness. The results rely on notions and
techniques from a variety of areas including learning theory, complexity
theory, cryptography, and game theory.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12811'>$k$-Center Clustering with Outliers in the MPC and Streaming Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mark de Berg, Leyla Biabani, Morteza Monemizadeh</p><p>Given a point set $P \subseteq X$ of size $n$ in a metric space $(X,dist)$ of
doubling dimension $d$ and two parameters $k \in N$ and $z \in N$, the
$k$-center problem with $z$ outliers asks to return a set $C^\ast \subseteq X$
of $k$ centers such that the maximum distance of all but $z$ points of $P$ to
their nearest center in $C^\ast$ is minimized. An $(\epsilon,k,z)$-coreset for
this problem is a weighted point set $P^*$ such that an optimal solution for
the $k$-center problem with $z$ outliers on $P^*$ gives a
$(1\pm\epsilon)$-approximation for the $k$-center problem with $z$ outliers on
$P$. We study the construction of such coresets in the Massively Parallel
Computing (MPC) model, and in the insertion-only as well as the fully dynamic
streaming model. We obtain the following results, for any given $0 &lt; \epsilon
\le 1$: In all cases, the size of the computed coreset is $O(k/\epsilon^d+z)$.
</p>
<p>- In the MPC model, we present a deterministic $2$-round and a randomized
$1$-round algorithm. Additionally, we provide a deterministic algorithm that
obtains a trade-off between the number of rounds, $R$, and the storage per
machine.
</p>
<p>- For the insertion-only streaming model, we present an algorithm and a tight
lower bound to support it.
</p>
<p>- We also discuss the dynamic streaming model, which allows both insertions
and deletions in the data stream. In this model, we present the first algorithm
and a lower bound.
</p>
<p>- Finally, we consider the sliding window model, where we are interested in
maintaining an $(\epsilon,k,z)$-coreset for the last $W$ points in the stream,
we present a tight lower bound that confirms the optimality of the previous
work by De Berg, Monemizadeh, and Zhong (ESA2020).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berg_M/0/1/0/all/0/1">Mark de Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Biabani_L/0/1/0/all/0/1">Leyla Biabani</a>, <a href="http://arxiv.org/find/cs/1/au:+Monemizadeh_M/0/1/0/all/0/1">Morteza Monemizadeh</a></p><p>Given a point set $P \subseteq X$ of size $n$ in a metric space $(X,dist)$ of
doubling dimension $d$ and two parameters $k \in N$ and $z \in N$, the
$k$-center problem with $z$ outliers asks to return a set $C^\ast \subseteq X$
of $k$ centers such that the maximum distance of all but $z$ points of $P$ to
their nearest center in $C^\ast$ is minimized. An $(\epsilon,k,z)$-coreset for
this problem is a weighted point set $P^*$ such that an optimal solution for
the $k$-center problem with $z$ outliers on $P^*$ gives a
$(1\pm\epsilon)$-approximation for the $k$-center problem with $z$ outliers on
$P$. We study the construction of such coresets in the Massively Parallel
Computing (MPC) model, and in the insertion-only as well as the fully dynamic
streaming model. We obtain the following results, for any given $0 &lt; \epsilon
\le 1$: In all cases, the size of the computed coreset is $O(k/\epsilon^d+z)$.
</p>
<p>- In the MPC model, we present a deterministic $2$-round and a randomized
$1$-round algorithm. Additionally, we provide a deterministic algorithm that
obtains a trade-off between the number of rounds, $R$, and the storage per
machine.
</p>
<p>- For the insertion-only streaming model, we present an algorithm and a tight
lower bound to support it.
</p>
<p>- We also discuss the dynamic streaming model, which allows both insertions
and deletions in the data stream. In this model, we present the first algorithm
and a lower bound.
</p>
<p>- Finally, we consider the sliding window model, where we are interested in
maintaining an $(\epsilon,k,z)$-coreset for the last $W$ points in the stream,
we present a tight lower bound that confirms the optimality of the previous
work by De Berg, Monemizadeh, and Zhong (ESA2020).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12289'>Beyond Moments: Robustly Learning Affine Transformations with Asymptotically Optimal Error</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: He Jia, Pravesh K . Kothari, Santosh S. Vempala</p><p>We present a polynomial-time algorithm for robustly learning an unknown
affine transformation of the standard hypercube from samples, an important and
well-studied setting for independent component analysis (ICA). Specifically,
given an $\epsilon$-corrupted sample from a distribution $D$ obtained by
applying an unknown affine transformation $x \rightarrow Ax+s$ to the uniform
distribution on a $d$-dimensional hypercube $[-1,1]^d$, our algorithm
constructs $\hat{A}, \hat{s}$ such that the total variation distance of the
distribution $\hat{D}$ from $D$ is $O(\epsilon)$ using poly$(d)$ time and
samples. Total variation distance is the information-theoretically strongest
possible notion of distance in our setting and our recovery guarantees in this
distance are optimal up to the absolute constant factor multiplying $\epsilon$.
In particular, if the columns of $A$ are normalized to be unit length, our
total variation distance guarantee implies a bound on the sum of the $\ell_2$
distances between the column vectors of $A$ and $A'$, $\sum_{i =1}^d
\|a_i-\hat{a}_i\|_2 = O(\epsilon)$. In contrast, the strongest known prior
results only yield a $\epsilon^{O(1)}$ (relative) bound on the distance between
individual $a_i$'s and their estimates and translate into an $O(d\epsilon)$
bound on the total variation distance. Our key innovation is a new approach to
ICA (even to outlier-free ICA) that circumvents the difficulties in the
classical method of moments and instead relies on a new geometric certificate
of correctness of an affine transformation. Our algorithm is based on a new
method that iteratively improves an estimate of the unknown affine
transformation whenever the requirements of the certificate are not met.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1">He Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1">Pravesh K . Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1">Santosh S. Vempala</a></p><p>We present a polynomial-time algorithm for robustly learning an unknown
affine transformation of the standard hypercube from samples, an important and
well-studied setting for independent component analysis (ICA). Specifically,
given an $\epsilon$-corrupted sample from a distribution $D$ obtained by
applying an unknown affine transformation $x \rightarrow Ax+s$ to the uniform
distribution on a $d$-dimensional hypercube $[-1,1]^d$, our algorithm
constructs $\hat{A}, \hat{s}$ such that the total variation distance of the
distribution $\hat{D}$ from $D$ is $O(\epsilon)$ using poly$(d)$ time and
samples. Total variation distance is the information-theoretically strongest
possible notion of distance in our setting and our recovery guarantees in this
distance are optimal up to the absolute constant factor multiplying $\epsilon$.
In particular, if the columns of $A$ are normalized to be unit length, our
total variation distance guarantee implies a bound on the sum of the $\ell_2$
distances between the column vectors of $A$ and $A'$, $\sum_{i =1}^d
\|a_i-\hat{a}_i\|_2 = O(\epsilon)$. In contrast, the strongest known prior
results only yield a $\epsilon^{O(1)}$ (relative) bound on the distance between
individual $a_i$'s and their estimates and translate into an $O(d\epsilon)$
bound on the total variation distance. Our key innovation is a new approach to
ICA (even to outlier-free ICA) that circumvents the difficulties in the
classical method of moments and instead relies on a new geometric certificate
of correctness of an affine transformation. Our algorithm is based on a new
method that iteratively improves an estimate of the unknown affine
transformation whenever the requirements of the certificate are not met.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12440'>Optimal Bounds for Noisy Sorting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuzhou Gu, Yinzhan Xu</p><p>Sorting is a fundamental problem in computer science. In the classical
setting, it is well-known that $(1\pm o(1)) n\log_2 n$ comparisons are both
necessary and sufficient to sort a list of $n$ elements. In this paper, we
study the Noisy Sorting problem, where each comparison result is flipped
independently with probability $p$ for some fixed $p\in (0, \frac 12)$. As our
main result, we show that $$(1\pm o(1)) \left( \frac{1}{I(p)} + \frac{1}{(1-2p)
\log_2 \left(\frac{1-p}p\right)} \right) n\log_2 n$$ noisy comparisons are both
necessary and sufficient to sort $n$ elements with error probability $o(1)$
using noisy comparisons, where $I(p)=1 + p\log_2 p+(1-p)\log_2 (1-p)$ is
capacity of BSC channel with crossover probability $p$. This simultaneously
improves the previous best lower and upper bounds (Wang, Ghaddar and Wang, ISIT
2022) for this problem.
</p>
<p>For the related Noisy Binary Search problem, we show that $$
</p>
<p>(1\pm o(1)) \left((1-\delta)\frac{\log_2(n)}{I(p)} + \frac{2 \log_2
\left(\frac 1\delta\right)}{(1-2p)\log_2\left(\frac {1-p}p\right)}\right) $$
noisy comparisons are both necessary and sufficient to find the predecessor of
an element among $n$ sorted elements with error probability $\delta$. This
extends the previous bounds of (Burnashev and Zigangirov, 1974), which are only
tight for $\delta = 1/n^{o(1)}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuzhou Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinzhan Xu</a></p><p>Sorting is a fundamental problem in computer science. In the classical
setting, it is well-known that $(1\pm o(1)) n\log_2 n$ comparisons are both
necessary and sufficient to sort a list of $n$ elements. In this paper, we
study the Noisy Sorting problem, where each comparison result is flipped
independently with probability $p$ for some fixed $p\in (0, \frac 12)$. As our
main result, we show that $$(1\pm o(1)) \left( \frac{1}{I(p)} + \frac{1}{(1-2p)
\log_2 \left(\frac{1-p}p\right)} \right) n\log_2 n$$ noisy comparisons are both
necessary and sufficient to sort $n$ elements with error probability $o(1)$
using noisy comparisons, where $I(p)=1 + p\log_2 p+(1-p)\log_2 (1-p)$ is
capacity of BSC channel with crossover probability $p$. This simultaneously
improves the previous best lower and upper bounds (Wang, Ghaddar and Wang, ISIT
2022) for this problem.
</p>
<p>For the related Noisy Binary Search problem, we show that $$
</p>
<p>(1\pm o(1)) \left((1-\delta)\frac{\log_2(n)}{I(p)} + \frac{2 \log_2
\left(\frac 1\delta\right)}{(1-2p)\log_2\left(\frac {1-p}p\right)}\right) $$
noisy comparisons are both necessary and sufficient to find the predecessor of
an element among $n$ sorted elements with error probability $\delta$. This
extends the previous bounds of (Burnashev and Zigangirov, 1974), which are only
tight for $\delta = 1/n^{o(1)}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12467'>The number of descendants in a random directed acyclic graph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Svante Janson</p><p>We consider a well known model of random directed acyclic graphs of order
$n$, obtained by recursively adding vertices, where each new vertex has a fixed
outdegree $d\ge2$ and the endpoints of the $d$ edges from it are chosen
uniformly at random among previously existing vertices.
</p>
<p>Our main results concern the number $X$ of vertices that are descendants of
$n$. We show that $X/\sqrt n$ converges in distribution; the limit distribution
is, up to a constant factor, given by the $d$th root of a Gamma distributed
variable. $\Gamma(d/(d-1))$. When $d=2$, the limit distribution can also be
described as a chi distribution $\chi(4)$. We also show convergence of moments,
and find thus the asymptotics of the mean and higher moments.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Janson_S/0/1/0/all/0/1">Svante Janson</a></p><p>We consider a well known model of random directed acyclic graphs of order
$n$, obtained by recursively adding vertices, where each new vertex has a fixed
outdegree $d\ge2$ and the endpoints of the $d$ edges from it are chosen
uniformly at random among previously existing vertices.
</p>
<p>Our main results concern the number $X$ of vertices that are descendants of
$n$. We show that $X/\sqrt n$ converges in distribution; the limit distribution
is, up to a constant factor, given by the $d$th root of a Gamma distributed
variable. $\Gamma(d/(d-1))$. When $d=2$, the limit distribution can also be
described as a chi distribution $\chi(4)$. We also show convergence of moments,
and find thus the asymptotics of the mean and higher moments.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T01:30:00Z">Monday, February 27 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, February 26
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://minorfree.github.io/hz-spanner/'>Halperin-Zwick Algorithm for Spanners</a></h3>
        <p class='tr-article-feed'>from <a href='https://minorfree.github.io'>Hung Le</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This post describes a simple linear time algorithm by Halperin-Zwick [6] for constructing a \((2k-1)\)-spanner of unweighted graphs for any given integer \(k\geq 1\). The spanner has \(O(n^{1+1/k})\) edges and hence is sparse. When \(k = \log n\), it only has \(O(n)\) edges. This sparsity makes spanners an important object in many applications. This post was inspired by my past attempt to track down the detail of the Halperin-Zwick algorithm. Halperin and Zwick never published their algorithm, and all papers I am aware of cite their unpublished manuscript [6]. The algorithm by Halperin-Zwick is a simple modification of an earlier algorithm by Pelege and SchÃ¤ffer [8], which, according to Uri Zwick, is the reason why they did not publish their result. The spanner by Pelege and SchÃ¤ffer [8] has stretch \(4k-3\) for the same sparsity. The idea of Halperin-Zwick algorithm was given as Exercise 3 in Chapter 16 of the book by Peleg [7]. First, letâs define spanners. Graphs in this post are connected. \(t\)-Spanner: Given a graph \(G\), a \(t\)-spanner is a subgraph of \(G\), denoted by \(H\), such that for every two vertices \(u,v\in V(G)\): \[d_H(u,v)\leq t\cdot d_G(u,v)\] Here \(d_H\) and \(d_G\) denote the graph distances in \(H\) and in \(G\), respectively. Graph \(G\) could be weighted or unweighted; we only consider unweighted graphs in this post. The distance constraint on \(H\) implies that \(H\) is connected and spanning. Parameter \(t\) is called the stretch of the spanner. We often construct a spanner with an odd stretch: \(t = 2k-1\) for some integer \(k\geq 1\). Why not even stretches? Short answer: there is no gain in terms of the worst case bounds for even stretch [1].
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>This post describes a simple linear time algorithm by Halperin-Zwick [6] for constructing a \((2k-1)\)-spanner of unweighted graphs for any given integer \(k\geq 1\). The spanner  has \(O(n^{1+1/k})\) edges and hence is sparse. When \(k = \log n\), it only has \(O(n)\) edges.  This sparsity makes spanners an important object in many applications.</p>

<p>This post was inspired by my past attempt to track down the detail of the Halperin-Zwick algorithm. Halperin and Zwick never published their algorithm, and all papers I am aware of cite their unpublished manuscript [6]. The algorithm by Halperin-Zwick is a simple modification of an earlier algorithm by Pelege and SchÃ¤ffer [8], which, according to Uri Zwick, is the reason why they did not publish their result. The spanner by Pelege and SchÃ¤ffer [8] has stretch \(4k-3\) for the same sparsity. The idea of Halperin-Zwick algorithm was given as Exercise 3 in Chapter 16 of  the book by Peleg [7].</p>

<p>First, letâs define spanners. Graphs in this post are connected.</p>

<hr />
<p><strong>\(t\)-Spanner</strong>: Given a graph \(G\), a \(t\)-spanner is a subgraph of \(G\), denoted by \(H\),  such that for every two vertices \(u,v\in V(G)\):</p>

\[d_H(u,v)\leq t\cdot d_G(u,v)\]

<hr />

<p>Here \(d_H\) and \(d_G\) denote the graph distances in \(H\) and in \(G\), respectively. Graph \(G\) could be weighted or unweighted; we only consider unweighted graphs in this post. The distance constraint on \(H\) implies that \(H\) is connected and spanning.</p>

<p>Parameter \(t\) is called the <em>stretch</em> of the spanner. We often construct a spanner with an odd stretch: \(t = 2k-1\) for some integer \(k\geq 1\). Why not even stretches? Short answer: there is no gain in terms of the worst case bounds for even stretch [1].</p>

<hr />
<p><strong>Theorem</strong> (Halperin-Zwick): Let \(G\) be an unweighted graph with \(n\) vertices and \(m\) edges. Let \(k\geq 1\) be any given integer. There is an algorithm that runs in time \(O(m)\) and constructs a \((2k-1)\)-spanner of \(G\) with \(O(n^{1+1/k})\) edges.</p>

<hr />

<p>It is often instructive to think about \(k=2\), i.e, constructing a \(3\)-spanner. And this is where we start.</p>

<h1 id="stretch-3">Stretch 3</h1>

<p>Here we seek a \(3\)-spanner with \(O(n^{3/2})\) edges. There are two steps: clustering and connecting the clusters. Letâs focus on clustering first. The idea is to: construct a set of radius-1 clusters (a set of stars) that have at least \(\sqrt{n}\) vertices each. This implies that the number of clusters is \(O(\sqrt{n})\) and hence we can afford to add one edge from each vertex to each cluster. The remaining vertices induce a graph of at most \(O(n^{3/2})\); we can add all the edges.</p>

<p>The cluster can be constructed greedily; the pseudocode of the algorithm is given below. We use \(N_G(v)\) to denote neighbors of \(v\) in a graph \(G\).</p>

<hr />
<p><span style="font-variant: small-caps">Clustering</span>\((G)\)</p>
<blockquote>
  <p>\(1.\) \({\mathcal C} \leftarrow \emptyset, \quad G_1\leftarrow G\)<br />
\(2.\) while \(G_i \not= \emptyset\)<br />
\(3.\) Â Â Â Â  \(x\leftarrow\) an arbitrary vertex in \(G_i\)<br />
\(4.\) Â Â Â Â  \(C_x\leftarrow {x}\)<br />
\(5.\) Â Â Â Â  if \(\lvert N_{G_i}(x)\rvert  \geq \sqrt{n}\)<br />
\(6.\) Â Â Â Â  Â Â Â Â   \(C_v\leftarrow C_v\cup N_{G_i}(x)\)<br />
\(7.\) Â Â Â Â  \({\mathcal C} \leftarrow {\mathcal C}\cup {C_x}\) <br />
\(8.\) Â Â Â Â   \(G_{i+1}\leftarrow G_i\setminus C_v, \quad i\leftarrow i+1\)<br />
\(9.\) return \({\mathcal C}\)</p>
</blockquote>

<hr />
<p>We call the vertex \(v\) in the cluster \(C_v\) in line 4 the <em>center</em> of the cluster. We use \(E(C_v)\) to the edges of \(G\) connecting \(v\) to other vertices in \(C_v\).</p>

<p>Observe  that every cluster \(C\in {\mathcal C}\) has radius at most \(1\) and it has either at least \(\sqrt{n}\) vertices or  exactly one vertex. We call \(C\) a <em>heavy cluster</em> if \(\lvert C \rvert\geq \sqrt{n}\), and a <em>light cluster</em> otherwise.</p>

<hr />
<p><strong>Observation 1</strong>: The number of heavy clusters in \({\mathcal C}\) is at most \(\sqrt{n}\).</p>

<hr />

<p>To get a 3-spanner of \(G\), we simply add an edge from every vertex to each heavy cluster of \({\mathcal C}\), and an edge between every pair of light clusters. (Light clusters are singletons.) 
***
 <span style="font-variant: small-caps">3Spanner</span>\((G)\)</p>
<blockquote>
  <p>\(1.\) \({\mathcal C} \leftarrow\)<span style="font-variant: small-caps">Clustering</span>\((G)\)<br />
\(2.\) \(H\leftarrow (V,\emptyset)\)<br />
\(3.\) for each heavy cluster \(C\in {\mathcal C}\)<br />
\(4.\) Â Â Â Â  add \(E(C)\) to \(H\)<br />
\(5\). Â Â Â Â  for each vertex \(v \in N_G(C)\)<br />
\(6.\) Â Â Â Â   Â Â Â Â  \((v,u)\leftarrow\) an arbitrary edge from \(v\) to \(C\)<br />
\(7.\) Â Â Â Â   Â Â Â Â  add \((u,v)\) to \(H\)<br />
\(8.\) add to \(H\) all edges between light clusters<br />
\(9.\) return \(H\)</p>
</blockquote>

<hr />

<p>In line 5, we use \(N_G(C)\) to denote the set of neighbors of \(C\), which are vertices are not in \(C\) and having at least one edge to \(C\).  The running time is clearly \(O(m)\).</p>

<p><strong>Sparsity analysis.</strong> Note that \(E(C)\leq \lvert C \rvert-1\). Thus, the total number of edges added to \(H\) in line 4 over all iterations is at most \(n-1\). Furthermore, the number of edges added to \(H\) in the loop in line 5 is at most \(n\) and hence by Observation 1, the total number of edges added in lines 3-7 is \(O(n\sqrt{n}) = O(n^{3/2})\).</p>

<p>To bound the number of edges added in line 8, observe that, if we order light clusters by the order it is added to \({\mathcal C}\) in line 7 of algorithm <span style="font-variant: small-caps">Clustering</span>, then each light cluster is incident to at most \(\sqrt{n}\) light clusters following it in the order. It follows that the total number of edges added in line 8 is \(O(n\sqrt{n}) = O(n^{3/2})\).</p>

<p><strong>Stretch analysis.</strong> We show that \(d_G(u,v)\leq 3 d_H(u,v)\). By the triangle inequality, it suffices to show the inequality for every edge \((u,v)\) of \(G\). This means we have to show that \(d_H(u,v)\leq 3\).  This inequality holds if \((u,v)\in E(H)\), and hence we only need to consider the case where at least one of \(u\) and \(v\) is in a heavy cluster.</p>

<p><img src="/assets/figs/clusters.svg" alt="" /></p>

<p><em>Figure 1: (a) stretch-3 path for edge \((u,v)\) and (b) stretch-\((2k-1)\) path for edge \((u,v)\)</em></p>

<p>If \(u\) and \(v\) are in the same heavy cluster \(C\), then \(d_H(u,v)\leq 2\) and the stretch guarantee holds. Otherwise, let \(C_x\) be the heavy cluster centered at \(x\) containing \(v\), say. As \((u,v)\not\in H\), there must be another vertex \(w\in C_x\) such that \((u,w)\in H\) by the construction in line 6. Thus, the path \(u\rightarrow w\rightarrow x\rightarrow v\) is a path of length 3 in \(H\) between \(u\) and \(v\), as desired. See Figure 1(a).</p>

<h1 id="larger-stretches">Larger Stretches</h1>

<p>The algorithm for constructing a \((2k-1)\)-spanner with \(O(n^{1+1/k})\) edges is somewhat similar to the stretch-3 case, but we will need a finer analysis. A key observation, which we also use in the 3-spanner construction, is that if we have a cluster, say \(C\), of radius \(k\), and a vertex \(v\in N_G(C)\), it suffices to keep only one edge from \(v\) to \(C\). Thus, as long as \(N_G(C)\) has at most \(n^{1/k}\lvert C \rvert\) vertices, we can add an edge from \(v\) to \(C\) for each \(v\in N_G(C)\); the <em>average number of edges added per vertex</em> of \(C\) is \(n^{1/k}\).</p>

<p>What if \(\lvert N_G(C) \rvert \geq n^{1/k}\lvert C \rvert\)? In this case, we simply grow \(C\) by adding all of its neighbors. How many times will it grow? At most \(k-1\) times, as every time \(C\) grows, its size increases by a factor of strictly larger than \(n^{1/k}\), and there are only \(n\) vertices in the graph.</p>

<p>The pseudocode of the algorithm is given below. The set \(A\) holds the edges between \(C\) and its neighbors described above. The rest is essentially the same as the clustering for stretch 3.</p>

<hr />
<p><span style="font-variant: small-caps">Clustering</span>\((G,k)\)</p>
<blockquote>
  <p>\(1.\) \({\mathcal C} \leftarrow \emptyset, \quad A\leftarrow \emptyset, \quad G_1\leftarrow G\)<br />
\(2.\) while \(G_i \not= \emptyset\)<br />
\(3.\) Â Â Â Â  \(x\leftarrow\) an arbitrary vertex in \(G_i\)<br />
\(4.\) Â Â Â Â  \(C_x\leftarrow {x}\)<br />
\(5.\) Â Â Â Â  while \(\lvert N_{G_i}(C_x)\rvert \geq n^{1/k} \lvert C_{x} \rvert\)<br />
\(6.\) Â Â Â Â  Â Â Â Â   \(C_v\leftarrow C_x\cup N_{G_i}(C_x)\)<br />
\(7.\) Â Â Â Â  for each \(v \in N_{G_i}(C_x)\)<br />
\(8.\) Â Â Â Â   Â Â Â Â  \((v,u)\leftarrow\) an arbitrary edge from \(v\) to \(C\)<br />
\(9.\) Â Â Â Â   Â Â Â Â  add \((v,u)\) to \(A\)<br />
\(10.\) Â Â Â Â  \({\mathcal C} \leftarrow {\mathcal C}\cup {C_v}\) <br />
\(11.\) Â Â Â Â   \(G_{i+1}\leftarrow G_i\setminus C_v, \quad i\leftarrow i+1\)<br />
\(12.\) return \(({\mathcal C},A)\)</p>
</blockquote>

<hr />

<p>Once we perform clustering, we only need to add the set \(A\) and the edges inside each cluster to the spanner.</p>

<hr />
<p><span style="font-variant: small-caps">Spanner</span>\((G,k)\)</p>
<blockquote>
  <p>\(1.\) \(H\leftarrow (V,\emptyset)\)<br />
\(2.\) \(({\mathcal C},A) \leftarrow\)<span style="font-variant: small-caps">Clustering</span>\((G,k)\)<br />
\(3.\) add \(A\) to \(H\)<br />
\(4.\) for each cluster \(C\in {\mathcal C}\)<br />
\(5.\) Â Â Â Â  add \(E(C)\) to \(H\)<br />
\(6.\) return \(H\)</p>
</blockquote>

<hr />

<p><strong>Sparsity analysis.</strong> The number of edges added in the loop in line 4 is at most \(n-1\). Observe that for each cluster \(C_x\) added to \({\mathcal C}\) in line 6 of <span style="font-variant: small-caps">Clustering</span>, the number of edges added to \(A\) in the loop in line 7 is at most \(n^{1/k}\lvert C_{x} \rvert\). Thus, \(\lvert A \rvert\leq n^{1/k}\sum_{C}\lvert C \rvert \leq n^{1+1/k}\). This implies that \(\lvert E(H) \rvert = O(n^{1+1/k})\).</p>

<p><strong>Stretch analysis.</strong> Let \((u,v)\) be any edge of \(G\) such that \((u,v)\not\in H\). We need to show that \(d_H(u,v)\leq 2k-1\). Observe that:</p>

<hr />
<p><strong>Observation 2</strong>: Every cluster \(C_x\in {\mathcal C}\) has radius at most \(k-1\).</p>

<hr />
<p>Proof: Every time the radius of \(C_x\) increases by \(1\), the size of \(C_x\) increases by a factor of strictly larger than \(n^{1/k}\) by the construction. Thus, after \(t\) rounds, \(n\geq \lvert C_{x} \rvert &gt; n^{t/k}\), which gives \(t\leq k-1\).</p>

<hr />

<p>Let \(C_x\) be the cluster containing \(v\). If \(u\in C_x\), then \(d_G(u,v)\leq 2\cdot (k-1)\). Otherwise, suppose w.l.o.g, that \(v\) is clustered before \(u\). Observe that \(u\in N_{G_{i}}(C_x)\) and hence an edge \((u,w)\) is added to \(A\), which is eventually added to \(H\). See Figure 1(b). Thus, the path consisting of an edge \((u,w)\), the shortest path from \(w\) to \(x\), and the shortest path from \(x\) to \(v\), is a path of length at most \(2(k-1)+1 = 2k-1\) between \(u\) and \(v\) in \(H\), as desired.</p>

<h1 id="optimality-the-girth-conjecture">Optimality: The Girth Conjecture</h1>

<p>It is not hard to construct a class of graphs such that for any graph \(G\) of size \(n\) in the class, the Halperin-Zwick algorithm produces a \((2k-1)\)-spanner for \(G\) that has \(\Omega(n^{1+1/k})\) edges. Could we go below the bound \(\Theta(n^{1+1/k})\) on the number of edges (by a different algorithm, say)? The consensus seems to be no, though currently we do not have a definite answer.</p>

<p>Spanners have a tight connection to the girth of graphs; a graph has girth \(g\) if the shortest simple cycle in the graph has length \(g\).</p>

<hr />
<p><strong>Observation 3</strong>: Let \(H\) be a graph of girth \(2k+1\). Then any \((2k-1)\)-spanner of \(H\) must contain every edge of \(H\).</p>

<hr />

<p>Observation 3 essentially says that any \((2k-1)\)-spanner of \(H\) must be itself. Thus, the question of the optimality of spanners reduces to: is there any graph with \(o(n^{1+1/k})\) edges and girth \((2k+1)\)? The ErdÅsâ Girth Conjecture implies that the answer is no.</p>

<hr />
<p><strong>ErdÅsâ Girth Conjecture [5]</strong>: For any \(n \geq 1\) and \(k\geq 1\), there exists a graph with \(n\) vertices of girth \((2k+1)\) that has \(\Omega(n^{1+1/k})\) edges.</p>

<hr />

<p>ErdÅs stated a lower bound \(c_k\cdot n^{1+1/k}\) on the number of edges in the conjecture [5]; that is, the constant is allowed to degrade as \(k\) increases.  The spanner literature often cites the stronger version above, where the constant remains the same for every \(k\). The ErdÅsâ Girth Conjecture is known to hold for a few small values of \(k\).</p>

<p>While ErdÅsâ Girth Conjecture remains wide open, we could ask: is it possible to construct a \((2k-1)\)-spanner that has girth at least \(2k+1\)? If yes, then the output spanner is (existentially) optimal regardless of the truth of ErdÅsâ Girth Conjecture.</p>

<p>It turns out that the following simple greedy algorithm, formally described in [2] and attributed to Marshall Bern, does the job: consider edges in increasing weight order and add an edge \(e\) to the current spanner if the distance between its endpoints in the spanner is larger than \((2k-1)w(e)\). The algorithm works for weighted graphs as well. It is an instructive exercise to show that the output graph is a \((2k-1)\)-spanner and has girth at least \(2k+1\).</p>

<p>The major downsize of the greedy algorithm is its running time: the current best known implemtation takes \(O(mn^{1+1/k})\) time. Even in unweighted graphs, to the best of my knowledge, the following problem remains open:</p>

<hr />
<p><strong>Open Problem</strong>: Construct a maximal subgraph of girth at least \((2k+1)\) in nearly linear time.</p>

<hr />

<p>For an unweighted graph, a maximal subgraph of girth at least \((2k+1)\) is a \((2k-1)\)-spanner.</p>

<h1 id="conclusion">Conclusion</h1>

<p>We have mentioned two algorithms for constructing a spanner. Another beautiful algorithm that I hope to cover in a future post is the randomized construction by Baswana and Sen [4]. A notable feature of the Baswana-Sen algorithm is that it can be implemented efficiently in both parallel and distributed models. The recent survey paper [1] contains almost all known algorithms for spanners and its sibling problems.</p>

<h1 id="bibliographical-notes">Bibliographical Notes</h1>

<p>The concept of a spanner was formally introduced by Peleg and Schaffer [8], though its conception was much earlier. Peleg and Schaffer constructed a \((4k-3)\)-spanner with \(O(n^{1+1/k})\) edges by connecting every pair of clusters in the output of <span style="font-variant: small-caps">Clustering</span>\((G,k)\) by an edge. This clustering procedure was due to Awerbuch [2].</p>

<h1 id="references">References</h1>

<p>[1] Ahmed, R., Bodwin, G., Sahneh, F. D., Hamm, K., Jebelli, M. J. L., Kobourov, S., and Spence, R. (2020). Graph spanners: A tutorial review. Computer Science Review, 37, 100253.</p>

<p>[2] AlthÃ¶fer, I., Das, G., Dobkin, D., Joseph, D., and Soares, J. (1993). On sparse spanners of weighted graphs. Discrete \&amp; Computational Geometry, 9(1), 81-100.</p>

<p>[3] Awerbuch, B. (1985). Complexity of network synchronization. Journal of the ACM (JACM), 32(4), 804-823.</p>

<p>[4] Baswana, S., and Sen, S. (2007). A simple and linear time randomized algorithm for computing sparse spanners in weighted graphs. Random Structures &amp; Algorithms, 30(4), 532-563.</p>

<p>[5] ErdÅs, P. (1965). Extremal problems in graph theory. In Proceedings of the Symposium on Theory of Graphs and its Applications, page 29-36, 1963.</p>

<p>[6] Halperin, S., and Zwick, U. (1996). Unpublished manuscript.</p>

<p>[7] Peleg, D. (2000). Distributed computing: a locality-sensitive approach. Society for Industrial and Applied Mathematics.</p>

<p>[8] Peleg, D., and SchÃ¤ffer, A. A. (1989). Graph spanners. Journal of graph theory, 13(1), 99-116.</p><p class="authors">By Hung Le</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-26T00:00:00Z">Sunday, February 26 2023, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, February 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/'>STOC 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          STOC 2023 is the 55th Annual ACM Symposium on Theory of Computing. It will be held on June 20-23, 2023 in Orlando, Florida. Perhaps the best paper ever at STOC was by Stephen Cook. His 1971 STOC paper The Complexity of Theorem Proving Procedures formalized the notions of polynomial-time and started the search to prove [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<a href="http://acm-stoc.org/stoc2023/">STOC 2023</a> is the 55th Annual ACM Symposium on Theory of Computing. It will be held on June 20-23, 2023 in Orlando, Florida. </p>
<p>
Perhaps the best paper ever at STOC was by Stephen Cook. His 1971 STOC paper <a href="https://dl.acm.org/doi/10.1145/800157.805047">The Complexity of Theorem Proving Procedures</a> formalized the notions of polynomial-time and started the search to prove <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> is not equal to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BNP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{NP}" class="latex" />. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/cook/" rel="attachment wp-att-21168"><img data-attachment-id="21168" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/cook/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" data-orig-size="290,174" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cook" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?resize=290%2C174&#038;ssl=1" alt="" width="290" height="174" class="aligncenter size-full wp-image-21168" data-recalc-dims="1" /></a></p>
<p>
See <a href="https://en.wikipedia.org/wiki/Symposium_on_Theory_of_Computing">this</a> for more. </p>
<p>
<p><H2> Papers with Pointers </H2></p>
<p><p>
Many web sites on STOC 2023 list the accepted papers but not with pointers. We planned to create these links ourself but we discovered this site that already has them:</p>
<p>
<a href="https://www.conference-publishing.com/list.php?Event=STOC23">List of papers</a> with pointers. </p>
<p>
This saved us having to create the pointers. Try them&#8212;fun to see the accepted papers.</p>
<p>
<p><H2> The Program Committee </H2></p>
<p><p>
Thanks to the program committee for working so hard on putting together such a terrific program. </p>
<ul>
<li>
Amir Abboud (Weizmann Institute of Science) </p>
<li>
Josh Alman (Columbia University) </p>
<li>
Andris Ambainis (University of Latvia) </p>
<li>
Nima Anari (Stanford University) </p>
<li>
Srinivasan Arunachalam (IBM Thomas J. Watson Research Center) </p>
<li>
Petra Berenbrink (Universitat Hamburg) </p>
<li>
Aaron Bernstein (Rutgers University) </p>
<li>
Aditya Bhaskara (University of Utah) </p>
<li>
Sayan Bhattacharya (University of Warwick) </p>
<li>
Eric Blais (University of Waterloo) </p>
<li>
Hans Bodlaender (Utrecht University) </p>
<li>
Adam Bouland (Stanford University) </p>
<li>
Anne Broadbent (University of Ottawa) </p>
<li>
Mark Bun (Boston University) </p>
<li>
Keren Censor-Hillel (Technion) </p>
<li>
Timothy Chan (University of Illinois at Urbana-Champaign) </p>
<li>
Arkadev Chattopadhyay (Tata Institute of Fundamental Research) </p>
<li>
Chandra Chekuri (University of Illinois at Urbana-Champaign) </p>
<li>
Xue Chen (University of Science and Technology of China) </p>
<li>
Gil Cohen (Tel Aviv University) </p>
<li>
Dana Dachman-Soled (University of Maryland College Park) </p>
<li>
Anindya De (University of Pennsylvania) </p>
<li>
Shahar Dobzhinski (Weizmann Institute of Science) </p>
<li>
Shaddin Dughmi (University of Southern California) </p>
<li>
Vida Dujmovic (University of Ottawa) </p>
<li>
Yuval Filmus (Technion) </p>
<li>
Sumegha Garg (Stanford University) </p>
<li>
Rong Ge (Duke University) </p>
<li>
Elena Grigorescu (Purdue University) </p>
<li>
Shuichi Hirahara (National Institute of Informatics, Japan) </p>
<li>
Zhiyi Huang (University of Hong Kong) </p>
<li>
Sungjin Im (University of California, Merced) </p>
<li>
Giuseppe Italiano (LUISS University) </p>
<li>
Ken-ichi Kawarabayashi (National Institute of Informatics, Japan) </p>
<li>
Sanjeev Khanna (University of Pennsylvania) </p>
<li>
Robin Kothari (Google Research) </p>
<li>
Marvin Kunnemann (TU Kaiserslautern) </p>
<li>
Rasmus Kyng (ETH Zurich) </p>
<li>
Sophie Laplante (Universite Paris Cite) </p>
<li>
Hung Le (University of Massachusetts, Amherst) </p>
<li>
Daniel Lokshtanov (University of California, Santa Barbara) </p>
<li>
Sepideh Mahabadi (Microsoft Research) </p>
<li>
Nicole Megow (Universitat Bremen) </p>
<li>
Slobodan Mitrovic (University of California, Davis) </p>
<li>
Ankur Moitra (Massachusetts Institute of Technology) </p>
<li>
Shay Moran (Technion and Google Research) </p>
<li>
Christopher Musco (New York University) </p>
<li>
Krzysztof Onak (Boston University) </p>
<li>
Rotem Oshman (Tel Aviv University) </p>
<li>
Prasad Raghavendra (University of California, Berkeley) </p>
<li>
Susanna Rezende (Lund University) </p>
<li>
Robert Robere (McGill University) </p>
<li>
Alon Rosen (Bocconi University and Reichman University) </p>
<li>
Ron Rothblum (Technion) </p>
<li>
Alex Russell (University of Connecticut) </p>
<li>
Laura Sanita (Bocconi University) </p>
<li>
Thatchaphol Saranurak (University of Michigan) </p>
<li>
Tselil Schramm (Stanford University) </p>
<li>
Rocco Servedio (Columbia University), Chair </p>
<li>
Tasos Sidiropoulos (University of Illinois at Chicago) </p>
<li>
Alex Slivkins (Microsoft Research) </p>
<li>
Srikanth Srinivasan (Aarhus University) </p>
<li>
David Steurer (ETH Zurich) </p>
<li>
Ola Svensson (EPFL) </p>
<li>
Chaitanya Swamy (University of Waterloo) </p>
<li>
Madhur Tulsiani (Toyota Technological Institute at Chicago) </p>
<li>
Christos Tzamos (University of Wisconsin-Madison) </p>
<li>
Muthu Venkitasubramaniam (Georgetown University) </p>
<li>
Ben Lee Volk (Reichman University) </p>
<li>
Andreas Wiese (Technical University of Munich) </p>
<li>
Mary Wootters (Stanford University) </p>
<li>
Yuichi Yoshida (National Institute of Informatics, Japan) </p>
<li>
Huacheng Yu (Princeton University)
</ul>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
I hope having the list of accepted papers with links is of some value. Cook&#8217;s paper might be the best ever, but it did not get the award for best paper at the time. Here are some of the more recent <a href="https://www.sigact.org/prizes/best_paper.html">best papers</a>:</p>
<p>
2020	<a href="https://arxiv.org/abs/1908.08483">Improved Bounds for The Sunflower Lemma</a> <br />
2019	<a href="https://arxiv.org/abs/1809.07115">The Reachability Problem for Petri Nets is Not Elementary</a> </p>
<p>
I like the second one above for personal reasons that I expounded long ago <a href="https://rjlipton.wpcomstaging.com/2009/04/08/an-expspace-lower-bound/">here</a>, and which Ken expanded on <a href="https://rjlipton.wpcomstaging.com/2015/07/12/the-long-reach-of-reachability/">here</a>. </p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-25T23:40:51Z">Saturday, February 25 2023, 23:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/02/25/isohedral-delaunay-complexes.html'>Isohedral Delaunay complexes</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Delaunay complex of a set of points in the Euclidean plane partitions the convex hull of the points into polygonal cells. Each cell is the convex hull of a co-circular subset of the points whose circle does not contain any more points. Itâs often called a Delaunay triangulation, because for points in general position the cells are all triangles, but I do not want to assume general position here. It is isohedral when all of the cells are symmetric to each other (maybe a little more strong than asking for them all to have the same shape). For example, the familiar tilings of the plane by squares or regular hexagons are both isohedral and Delaunay. Another example is a tiling of the plane by 60Â°â90Â°â120Â° kites:
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Delaunay complex of a set of points in the Euclidean plane partitions the convex hull of the points into polygonal cells. Each cell is the convex hull of a co-circular subset of the points whose circle does not contain any more points. Itâs often called a <a href="https://en.wikipedia.org/wiki/Delaunay_triangulation">Delaunay triangulation</a>, because for points in <a href="General position">general position</a> the cells are all triangles, but I do not want to assume general position here. It is <a href="https://en.wikipedia.org/wiki/Isohedral_figure">isohedral</a> when all of the cells are symmetric to each other (maybe a little more strong than asking for them all to have the same shape). For example, the familiar tilings of the plane by squares or regular hexagons are both isohedral and Delaunay. Another example is a <a href="https://en.wikipedia.org/wiki/Deltoidal_trihexagonal_tiling">tiling of the plane by 60Â°â90Â°â120Â° kites</a>:</p>

<p style="text-align:center"><img src="/blog/assets/2023/tetrille-delaunay.svg" alt="Tiling of the plane by 60Â°â90Â°â120Â° kites, with shading showing that the circumcircles of each site are empty of other tiling vertices" style="width:100%;max-width:720px" /></p>

<p>Some other tilings, even very symmetric ones, might not be Delaunay. For instance, it is impossible to make a Delaunay version of the <a href="https://en.wikipedia.org/wiki/Cairo_pentagonal_tiling">Cairo pentagonal tiling</a> because its tiles have two complementary angles or two right angles, impossible for a co-circular pentagon.</p>

<p>In these cases, the symmetries are of the familiar kind, translations and rotations of the plane. But translation symmetry forces us to use infinitely many points. Can finite Delaunay complexes be isohedral? Sort of, maybe, but with a different kind of symmetry.
You can translate between Delaunay complexes on the plane and on a sphere by <a href="https://en.wikipedia.org/wiki/Stereographic_projection">stereographic projection</a>, and translations, rotations, and scaling in the plane become MÃ¶bius transformations on the sphere. So the projection onto the sphere of a square grid becomes a spherical Delaunay complex that is symmetric under MÃ¶bius transformations.</p>

<p style="text-align:center"><img src="/blog/assets/2023/stereographic-square-tiling.svg" alt="Stereographic projection of a square grid from the plane to a sphere" title="CC-BY-SA 4.0 image https://commons.wikimedia.org/wiki/File:Stereogr-proj-netz.svg by Ag2gaeh from Wikimedia commons" style="width:100%;max-width:720px" /></p>

<p>Rotations of the sphere are also a very special case of MÃ¶bius transformations, so we can look for Delaunay complexes with rotational symmetries. Suppose you have a polyhedron all of whose vertices lie on a sphere, and all of whose faces are symmetric to each other by rotations of the sphere. Then the intersection of the sphere with any face plane of the polyhedron is a circle through the vertices of a face that does not contain any other vertices, the defining property of a Delaunay cell. So these polyhedra are isohedral spherical Delaunay complexes. This is true, for instance, for the Platonic solids and for the two infinite families of <a href="https://en.wikipedia.org/wiki/Bipyramid">bipyramids</a> and the <a href="https://en.wikipedia.org/wiki/Trapezohedron">trapezohedra</a> but false for some other isohedral polyhedra like the <a href="https://en.wikipedia.org/wiki/Rhombic_dodecahedron">rhombic dodecahedron</a> and <a href="https://en.wikipedia.org/wiki/Triakis_tetrahedron">triakis tetrahedron</a> whose vertices cannot all be placed on a sphere.</p>

<p>You can map these spherical Delaunay complexes back onto the plane by stereographic projection again. You might think that the result is always a planar Delaunay complex in which all faces are symmetric to each other under MÃ¶bius transformation, but thereâs a catch. The projection preserves circles, but it turns inside out the ones that contain the pole of the projection. If they were empty on the sphere, they instead turn into circles in the plane that contain every other point. These inside-out circles correspond to Delaunay cells on the sphere that do not map to Delaunay cells in the plane. For instance, projecting the cube vertices back down to the plane with the pole at the midpoint of a cube edge produces a Delaunay complex with only four quadrilaterals; the other two faces of the cube come from inside-out circles and do not become Delaunay cells.</p>

<p style="text-align:center"><img src="/blog/assets/2023/cube-edge-projection.svg" alt="Delaunay complex of a cube, stereographically projected onto the plane with its pole at an edge midpoint" style="width:100%;max-width:720px" /></p>

<p>All of this generalizes directly to 3d Delaunay triangulations, and to isohedral 4d polytopes with cospherical vertices, but less is known about what shapes are possible. The regular 4-polytopes, certainly, have symmetric facets and cospherical vertices, but there are other possibilities as well. The <a href="http://www.polytope.net/hedrondude/dice4.htm">isohedral 4-polytopes with up to 20 sides</a> have been classified, but I donât know which of these can have cospherical vertices.</p>

<p>There are, at least, three different infinite families of isohedral 4d polytopes with cospherical vertices, analogous to the bipyramids and trapezohedra. To describe this, it helps to think of four-dimensional Euclidean space as having two complex numbers \(\alpha\) and \(\beta\) as coordinates, and the unit sphere as the points for which \(\vert\alpha\vert^2+\vert\beta\vert^2=1\). These are the state vectors of a <a href="https://en.wikipedia.org/wiki/Qubit">qubit</a>, so we can write these points on the sphere using <a href="https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation">quantum notation</a> as \(\alpha\,\vert0\rangle+\beta\,\vert1\rangle\), where \(\vert0\rangle\) and \(\vert1\rangle\) are just the two basis vectors for the two-complex-number coordinate system. In this notation, consider the following three sets of points, all on the unit sphere, for integer parameters \(n\) and \(m\):</p>

<ul>
  <li>
    <p>Let \(X\) be the set of \(n\) points \(e^{2\pi i/n}\,\vert0\rangle\), for the integers \(i\) with \(0\le i\lt n\). These form a regular \(n\)-gon in the plane \(\beta=0\).</p>
  </li>
  <li>
    <p>Let \(Y\) be the set of \(m\) points \(e^{2\pi j/m}\,\vert1\rangle\), for the integers \(j\) with \(0\le j\lt n\). These form a regular \(m\)-gon, in the perpendicular plane \(\alpha=0\).</p>
  </li>
  <li>
    <p>Let \(Z\) be the set of \(mn\) points</p>

\[\frac{1}{\sqrt 2}e^{2\pi i/n}\,\vert0\rangle + \frac{1}{\sqrt 2}e^{2\pi j/m}\,\vert1\rangle,\]

    <p>for the same ranges of \(i\) and \(j\). These lie on a <a href="https://en.wikipedia.org/wiki/Flat_torus">flat torus</a>, the Cartesian product of two circles, and form the vertices of a tiling of the torus by rectangles.</p>
  </li>
</ul>

<p>Then the convex hull of \(X\cup Y\) has as its facets \(mn\) congruent tetrahedra, each formed as the convex hull of an edge of the \(X\)-polygon and an edge of the \(Y\)-polygon. The convex hull of \(Z\) is a <a href="https://en.wikipedia.org/wiki/Duoprism">duoprism</a> whose facets are two kinds of prisms: the Cartesian product of an edge of the \(X\)-polygon with the whole \(Y\)-polygon, and vice versa. When \(n=m\) these two prisms are congruent and the resulting duoprism is isohedral, and dual to the convex hull of \(X\cup Y\). Here is a stereographic projection for \(n=m=18\), taken from the <a href="https://www.math.cmu.edu/~fho/jenn/polytopes/index.html">Jenn 3d website</a>:</p>

<p style="text-align:center"><img src="/blog/assets/2023/18x18-torus.png" alt="Stereographic projection into 3d of a 4-dimensional polytope, the (18,18)-duoprism, appearing as a torus tiled with squares" title="Public domain image https://www.math.cmu.edu/~fho/jenn/polytopes/18x18-torus.png" style="width:100%;max-width:720px" /></p>

<p>In this image, the most prominent feature is the tiling by squares of the torus containing \(Z\). If you follow sequences of edges of this square grid, through opposite edges at each vertex, you will also see many 18-gons. Some of the 18-gons slice the âinsideâ of the torus radially into distorted prisms; these are Delaunay cells. Many of the perpendicular 18-gons slice across the âdonut holeâ of the torus, forming more Delaunay cells. But some of the remaining 18-gons lie on the convex hull of the shape, and cannot be used as slices for the projected set. The missing slices cause the Delaunay triangulation of the stereographic projection to miss some cells, and that can only happen because the spheres for these cells were inverted by the projection.</p>

<p>You can also take the convex hull of \(X\cup Y\cup Z\). This has two triangular-prism facets for each tetrahedron of \(X\cup Y\), meeting at one of the squares of \(Z\). The reason Iâm interested in this example comes from <a href="/blog/2023/02/20/geometric-graphs-unbounded.html">my most recent post, on flip-width of geometric graphs</a>. If you take an induced subgraph of this polytope, consisting only of the points in \(X\cup Y\cup Z\) whose coefficients \(i\) and \(j\) are both even, the result is a subdivided complete bipartite graph \(K_{n,n}\), where by âsubdividedâ I mean that each edge of \(K_{n,n}\) has been replaced by a two-edge path. This isnât an interchange, in the sense of the previous post, but it has unbounded flip-width, because it is a sparse graph that does not have bounded expansion.</p>

<p>What I really want, though, is a 3d Euclidean Delaunay triangulation with unbounded flip-width, not a non-triangulation complex and not a 4-polytope (I already had one of those in my previous post). To get this, use a stereographic projection whose pole is on the central torus, in the middle of one of the squares (or really on the corresponding point of the unit sphere), and note that the Delaunay spheres of the polytope faces will intersect this torus in Delaunay circles of the squares. But for a square grid, the center of each square belongs only to the circumcircle of that square, not to any of the other circumcircles. So the pole of the projection will only belong to two of the Delaunay spheres, the two sharing the chosen square. The two prisms for these two spheres will be missing from the Delaunay complex (instead, their union, some sort of <a href="https://en.wikipedia.org/wiki/Gyrobifastigium">gyrobifastifium</a>, will form the convex hull of the points), but all the other prisms will still be present. They contain all the edges of the graph, so it still contains a large induced subdivided biclique. Perturbing the points slightly to get a triangulation rather than a complex doesnât change this.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/109926574982696332">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-25T09:19:00Z">Saturday, February 25 2023, 09:19</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, February 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/24/postdoc-at-tu-eindhoven-university-of-amsterdam-leiden-university-cwi-apply-by-march-31-2023/'>postdoc at TU Eindhoven, University of Amsterdam, Leiden University, CWI (apply by March 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Postdoc Positions in Algorithmics and Stochastics, in the NETWORKS project (the Netherlands). The NETWORKS project is a collaboration of researchers from four institutions in The Netherlands: TU Eindhoven, University of Amsterdam, Leiden University and the Centrum Wiskunde &#38; Informatica (CWI). NETWORKS has openings for postdocs working on algorithmics or stochastics for network problems. Website: www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND- [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Postdoc Positions in Algorithmics and Stochastics, in the NETWORKS project (the Netherlands).</p>
<p>The NETWORKS project is a collaboration of researchers from four institutions in The Netherlands: TU Eindhoven, University of Amsterdam, Leiden University and the Centrum Wiskunde &amp; Informatica (CWI). NETWORKS has openings for postdocs working on algorithmics or stochastics for network problems.</p>
<p>Website: <a href="https://www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND-">https://www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND-</a><br />
Email: info@thenetworkcenter.nl</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T12:53:26Z">Friday, February 24 2023, 12:53</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11578'>Guidable Local Hamiltonian Problems with Implications to Heuristic Ans\"atze State Preparation and the Quantum PCP Conjecture</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jordi Weggemans, Marten Folkertsma, Chris Cade</p><p>We introduce 'Merlinized' versions of the recently defined Guided Local
Hamiltonian problem, which we call 'Guidable Local Hamiltonian' problems.
Unlike their guided counterparts, these problems do not have a guiding state
provided as a part of the input, but merely come with the promise that one
exists and that it satisfies certain constraints. We consider in particular two
classes of guiding states: those that can be prepared efficiently by a quantum
circuit; and those belonging to a class of quantum states we call classically
evaluatable, which have a short classical description from which it is possible
to efficiently compute expectation values of local observables classically. We
show that guidable local Hamiltonian problems for both classes of guiding
states are $\mathsf{QCMA}$-complete in the inverse-polynomial precision
setting, but lie within $\mathsf{NP}$ (or $\mathsf{NqP}$) in certain parameter
regimes when the guiding state is classically evaluatable.
</p>
<p>We discuss the implications of these results to heuristic ans\"atze state
preparation and the quantum PCP conjecture. Our completeness results show that,
from a complexity-theoretic perspective, classical ans\"atze prepared by
classical heuristics are just as powerful as quantum ans\"atze prepared by
quantum heuristics, so long as one has access to quantum phase estimation. In
relation to the quantum PCP conjecture, we (i) define a PCP for $\mathsf{QCMA}$
and show that it is equal to $\mathsf{NP}$ under quantum reductions; (ii) show
several no-go results for the existence of quantum gap amplification procedures
that preserve certain ground state properties; and (iii) propose two
conjectures that can be viewed as stronger versions of the NLTS theorem.
Finally, we show that many of our results can be directly modified to obtain
similar results for the class $\mathsf{MA}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Weggemans_J/0/1/0/all/0/1">Jordi Weggemans</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Folkertsma_M/0/1/0/all/0/1">Marten Folkertsma</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Cade_C/0/1/0/all/0/1">Chris Cade</a></p><p>We introduce 'Merlinized' versions of the recently defined Guided Local
Hamiltonian problem, which we call 'Guidable Local Hamiltonian' problems.
Unlike their guided counterparts, these problems do not have a guiding state
provided as a part of the input, but merely come with the promise that one
exists and that it satisfies certain constraints. We consider in particular two
classes of guiding states: those that can be prepared efficiently by a quantum
circuit; and those belonging to a class of quantum states we call classically
evaluatable, which have a short classical description from which it is possible
to efficiently compute expectation values of local observables classically. We
show that guidable local Hamiltonian problems for both classes of guiding
states are $\mathsf{QCMA}$-complete in the inverse-polynomial precision
setting, but lie within $\mathsf{NP}$ (or $\mathsf{NqP}$) in certain parameter
regimes when the guiding state is classically evaluatable.
</p>
<p>We discuss the implications of these results to heuristic ans\"atze state
preparation and the quantum PCP conjecture. Our completeness results show that,
from a complexity-theoretic perspective, classical ans\"atze prepared by
classical heuristics are just as powerful as quantum ans\"atze prepared by
quantum heuristics, so long as one has access to quantum phase estimation. In
relation to the quantum PCP conjecture, we (i) define a PCP for $\mathsf{QCMA}$
and show that it is equal to $\mathsf{NP}$ under quantum reductions; (ii) show
several no-go results for the existence of quantum gap amplification procedures
that preserve certain ground state properties; and (iii) propose two
conjectures that can be viewed as stronger versions of the NLTS theorem.
Finally, we show that many of our results can be directly modified to obtain
similar results for the class $\mathsf{MA}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11667'>Cutting Barnette graphs perfectly is hard</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: &#xc9;douard Bonnet, Dibyayan Chakraborty, Julien Duron</p><p>A perfect matching cut is a perfect matching that is also a cutset, or
equivalently a perfect matching containing an even number of edges on every
cycle. The corresponding algorithmic problem, Perfect Matching Cut, is known to
be NP-complete in subcubic bipartite graphs [Le &amp; Telle, TCS '22] but its
complexity was open in planar graphs and in cubic graphs. We settle both
questions at once by showing that Perfect Matching Cut is NP-complete in
3-connected cubic bipartite planar graphs or Barnette graphs. Prior to our
work, among problems whose input is solely an undirected graph, only Distance-2
4-Coloring was known NP-complete in Barnette graphs. Notably, Hamiltonian Cycle
would only join this private club if Barnette's conjecture were refuted.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1">&#xc9;douard Bonnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1">Dibyayan Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Duron_J/0/1/0/all/0/1">Julien Duron</a></p><p>A perfect matching cut is a perfect matching that is also a cutset, or
equivalently a perfect matching containing an even number of edges on every
cycle. The corresponding algorithmic problem, Perfect Matching Cut, is known to
be NP-complete in subcubic bipartite graphs [Le &amp; Telle, TCS '22] but its
complexity was open in planar graphs and in cubic graphs. We settle both
questions at once by showing that Perfect Matching Cut is NP-complete in
3-connected cubic bipartite planar graphs or Barnette graphs. Prior to our
work, among problems whose input is solely an undirected graph, only Distance-2
4-Coloring was known NP-complete in Barnette graphs. Notably, Hamiltonian Cycle
would only join this private club if Barnette's conjecture were refuted.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11637'>Hitting Sets when the Shallow Cell Complexity is Small</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sander Aarts, David B. Shmoys</p><p>The hitting set problem is a well-known NP-hard optimization problem in
which, given a set of elements and a collection of subsets, the goal is to find
the smallest selection of elements, such that each subset contains at least one
element in the selection. Many geometric set systems enjoy improved
approximation ratios, which have recently been shown to be tight with respect
to the shallow cell complexity of the set system. The algorithms that exploit
the cell complexity, however, tend to be involved and computationally
intensive. This paper shows that comparable approximation ratios for the
hitting set problem can be attained using a much simpler algorithm: solve the
linear programming relaxation, take one initial random sample from the set of
elements with probabilities proportional to the LP-solution, and, while there
is an unhit set, take an additional sample from it proportional to the
LP-solution. Our algorithm is based on a generalization of the elegant
net-finder algorithm of Nabil Mustafa. To analyze this algorithm for the
hitting set problem, we generalize the classic Packing Lemma, and the more
recent Shallow-Packing Lemma, to the setting of weighted epsilon nets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aarts_S/0/1/0/all/0/1">Sander Aarts</a>, <a href="http://arxiv.org/find/cs/1/au:+Shmoys_D/0/1/0/all/0/1">David B. Shmoys</a></p><p>The hitting set problem is a well-known NP-hard optimization problem in
which, given a set of elements and a collection of subsets, the goal is to find
the smallest selection of elements, such that each subset contains at least one
element in the selection. Many geometric set systems enjoy improved
approximation ratios, which have recently been shown to be tight with respect
to the shallow cell complexity of the set system. The algorithms that exploit
the cell complexity, however, tend to be involved and computationally
intensive. This paper shows that comparable approximation ratios for the
hitting set problem can be attained using a much simpler algorithm: solve the
linear programming relaxation, take one initial random sample from the set of
elements with probabilities proportional to the LP-solution, and, while there
is an unhit set, take an additional sample from it proportional to the
LP-solution. Our algorithm is based on a generalization of the elegant
net-finder algorithm of Nabil Mustafa. To analyze this algorithm for the
hitting set problem, we generalize the classic Packing Lemma, and the more
recent Shallow-Packing Lemma, to the setting of weighted epsilon nets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11767'>Adaptive Approximate Implicitization of Planar Parametric Curves via Weak Gradient Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Minghao Guo, Yan Gao, Zheng Pan</p><p>Converting a parametric curve into the implicit form, which is called
implicitization, has always been a popular but challenging problem in geometric
modeling and related applications. However, the existing methods mostly suffer
from the problems of maintaining geometric features and choosing a reasonable
implicit degree. The present paper has two contributions. We first introduce a
new regularization constraint(called the weak gradient constraint) for both
polynomial and non-polynomial curves, which efficiently possesses shape
preserving. We then propose two adaptive algorithms of approximate
implicitization for polynomial and non-polynomial curves respectively, which
find the ``optimal'' implicit degree based on the behavior of the weak gradient
constraint. More precisely, the idea is gradually increasing the implicit
degree, until there is no obvious improvement in the weak gradient loss of the
outputs. Experimental results have shown the effectiveness and high quality of
our proposed methods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Minghao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zheng Pan</a></p><p>Converting a parametric curve into the implicit form, which is called
implicitization, has always been a popular but challenging problem in geometric
modeling and related applications. However, the existing methods mostly suffer
from the problems of maintaining geometric features and choosing a reasonable
implicit degree. The present paper has two contributions. We first introduce a
new regularization constraint(called the weak gradient constraint) for both
polynomial and non-polynomial curves, which efficiently possesses shape
preserving. We then propose two adaptive algorithms of approximate
implicitization for polynomial and non-polynomial curves respectively, which
find the ``optimal'' implicit degree based on the behavior of the weak gradient
constraint. More precisely, the idea is gradually increasing the implicit
degree, until there is no obvious improvement in the weak gradient loss of the
outputs. Experimental results have shown the effectiveness and high quality of
our proposed methods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11922'>Translation of "Simplizialzerlegungen von Beschrankter Flachheit'' by Hans Freudenthal, Annals of Mathematics, Second Series, Volume 43, Number 3, July 1942, Pages 580-583</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mathijs Wintraecken (translator)</p><p>Translation of the paper ``Simplizialzerlegungen von Beschrankter Flachheit''
by Hans Freudenthal (doi.org/10.2307/1968813), in which Freudenthal
answers ``a question by Brouwer about the construction of an infinite series of
subdivisions of a polytope, such that the next element in the sequence is a
subdivision of the previous one and such that the subsimplices that arise do
not become arbitrarily flat.''
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Wintraecken_M/0/1/0/all/0/1">Mathijs Wintraecken</a> (translator)</p><p>Translation of the paper ``Simplizialzerlegungen von Beschrankter Flachheit''
by Hans Freudenthal (https://doi.org/10.2307/1968813), in which Freudenthal
answers ``a question by Brouwer about the construction of an infinite series of
subdivisions of a polytope, such that the next element in the sequence is a
subdivision of the previous one and such that the subsimplices that arise do
not become arbitrarily flat.''
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12219'>Certified Polyhedral Decompositions of Collision-Free Configuration Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hongkai Dai, Alexandre Amice, Peter Werner, Annan Zhang, Russ Tedrake</p><p>Understanding the geometry of collision-free configuration space (C-free) in
the presence of task-space obstacles is an essential ingredient for
collision-free motion planning. While it is possible to check for collisions at
a point using standard algorithms, to date no practical method exists for
computing C-free regions with rigorous certificates due to the complexity of
mapping task-space obstacles through the kinematics. In this work, we present
the first to our knowledge rigorous method for approximately decomposing a
rational parametrization of C-free into certified polyhedral regions. Our
method, called C-IRIS (C-space Iterative Regional Inflation by Semidefinite
programming), generates large, convex polytopes in a rational parameterization
of the configuration space which are rigorously certified to be collision-free.
Such regions have been shown to be useful for both optimization-based and
randomized motion planning. Based on convex optimization, our method works in
arbitrary dimensions, only makes assumptions about the convexity of the
obstacles in the task space, and is fast enough to scale to realistic problems
in manipulation. We demonstrate our algorithm's ability to fill a non-trivial
amount of collision-free C-space in several 2-DOF examples where the C-space
can be visualized, as well as the scalability of our algorithm on a 7-DOF KUKA
iiwa, a 6-DOF UR3e and 12-DOF bimanual manipulators. An implementation of our
algorithm is open-sourced in Drake. We furthermore provide examples of our
algorithm in interactive Python notebooks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hongkai Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Amice_A/0/1/0/all/0/1">Alexandre Amice</a>, <a href="http://arxiv.org/find/cs/1/au:+Werner_P/0/1/0/all/0/1">Peter Werner</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Annan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tedrake_R/0/1/0/all/0/1">Russ Tedrake</a></p><p>Understanding the geometry of collision-free configuration space (C-free) in
the presence of task-space obstacles is an essential ingredient for
collision-free motion planning. While it is possible to check for collisions at
a point using standard algorithms, to date no practical method exists for
computing C-free regions with rigorous certificates due to the complexity of
mapping task-space obstacles through the kinematics. In this work, we present
the first to our knowledge rigorous method for approximately decomposing a
rational parametrization of C-free into certified polyhedral regions. Our
method, called C-IRIS (C-space Iterative Regional Inflation by Semidefinite
programming), generates large, convex polytopes in a rational parameterization
of the configuration space which are rigorously certified to be collision-free.
Such regions have been shown to be useful for both optimization-based and
randomized motion planning. Based on convex optimization, our method works in
arbitrary dimensions, only makes assumptions about the convexity of the
obstacles in the task space, and is fast enough to scale to realistic problems
in manipulation. We demonstrate our algorithm's ability to fill a non-trivial
amount of collision-free C-space in several 2-DOF examples where the C-space
can be visualized, as well as the scalability of our algorithm on a 7-DOF KUKA
iiwa, a 6-DOF UR3e and 12-DOF bimanual manipulators. An implementation of our
algorithm is open-sourced in Drake. We furthermore provide examples of our
algorithm in interactive Python notebooks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11821'>Storage in Computational Geometry</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yijie Han, Sanjeev Saxena</p><p>We show that $n$ real numbers can be stored in a constant number of real
numbers such that each original real number can be fetched in $O(\log n)$ time.
</p>
<p>Although our result has implications for many computational geometry
problems, we show here, combined with Han's $O(n\sqrt{\log n})$ time real
number sorting algorithm [3, arXiv:1801.00776], we can improve the complexity
of Kirkpatrick's point location algorithm [8] to $O(n\sqrt{\log n})$
preprocessing time, a constant number of real numbers for storage and $O(\log
n)$ point location time. Kirkpatrick's algorithm uses $O(n\log n)$
preprocessing time, $O(n)$ storage and $O(\log n)$ point location time. The
complexity results in Kirkpatrick's algorithm was the previous best result.
Although Lipton and Tarjan's algorithm [10] predates Kirkpatrick's algorithm
and has the same complexity, Kirkpatrick's algorithm is simpler and has a
better structure.
</p>
<p>This paper can be viewed as a companion paper of paper [3, arXiv:1801.00776].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yijie Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1">Sanjeev Saxena</a></p><p>We show that $n$ real numbers can be stored in a constant number of real
numbers such that each original real number can be fetched in $O(\log n)$ time.
</p>
<p>Although our result has implications for many computational geometry
problems, we show here, combined with Han's $O(n\sqrt{\log n})$ time real
number sorting algorithm [3, <a href="/abs/1801.00776">arXiv:1801.00776</a>], we can improve the complexity
of Kirkpatrick's point location algorithm [8] to $O(n\sqrt{\log n})$
preprocessing time, a constant number of real numbers for storage and $O(\log
n)$ point location time. Kirkpatrick's algorithm uses $O(n\log n)$
preprocessing time, $O(n)$ storage and $O(\log n)$ point location time. The
complexity results in Kirkpatrick's algorithm was the previous best result.
Although Lipton and Tarjan's algorithm [10] predates Kirkpatrick's algorithm
and has the same complexity, Kirkpatrick's algorithm is simpler and has a
better structure.
</p>
<p>This paper can be viewed as a companion paper of paper [3, <a href="/abs/1801.00776">arXiv:1801.00776</a>].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11619'>Pattern detection in ordered graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guillaume Ducoffe, Laurent Feuilloley, Michel Habib, Fran&#xe7;ois Pitois</p><p>A popular way to define or characterize graph classes is via forbidden
subgraphs or forbidden minors. These characterizations play a key role in graph
theory, but they rarely lead to efficient algorithms to recognize these
classes. In contrast, many essential graph classes can be recognized
efficiently thanks to characterizations of the following form: there must exist
an ordering of the vertices such that some ordered pattern does not appear,
where a pattern is basically an ordered subgraph. These pattern
characterizations have been studied for decades, but there have been recent
efforts to better understand them systematically. In this paper, we focus on a
simple problem at the core of this topic: given an ordered graph of size $n$,
how fast can we detect whether a fixed pattern of size $k$ is present?
</p>
<p>Following the literature on graph classes recognition, we first look for
patterns that can be detected in linear time. We prove, among other results,
that almost all patterns on three vertices (which capture many interesting
classes, such as interval, chordal, split, bipartite, and comparability graphs)
fall in this category. Then, in a finer-grained complexity perspective, we
prove conditional lower bounds for this problem. In particular we show that for
a large family of patterns on four vertices it is unlikely that subquadratic
algorithm exist. Finally, we define a parameter for patterns, the merge-width,
and prove that for patterns of merge-width $t$, one can solve the problem in
$O(n^{ct})$ for some constant~$c$. As a corollary, we get that detecting
outerplanar patterns and other classes of patterns can be done in time
independent of the size of the pattern.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ducoffe_G/0/1/0/all/0/1">Guillaume Ducoffe</a>, <a href="http://arxiv.org/find/cs/1/au:+Feuilloley_L/0/1/0/all/0/1">Laurent Feuilloley</a>, <a href="http://arxiv.org/find/cs/1/au:+Habib_M/0/1/0/all/0/1">Michel Habib</a>, <a href="http://arxiv.org/find/cs/1/au:+Pitois_F/0/1/0/all/0/1">Fran&#xe7;ois Pitois</a></p><p>A popular way to define or characterize graph classes is via forbidden
subgraphs or forbidden minors. These characterizations play a key role in graph
theory, but they rarely lead to efficient algorithms to recognize these
classes. In contrast, many essential graph classes can be recognized
efficiently thanks to characterizations of the following form: there must exist
an ordering of the vertices such that some ordered pattern does not appear,
where a pattern is basically an ordered subgraph. These pattern
characterizations have been studied for decades, but there have been recent
efforts to better understand them systematically. In this paper, we focus on a
simple problem at the core of this topic: given an ordered graph of size $n$,
how fast can we detect whether a fixed pattern of size $k$ is present?
</p>
<p>Following the literature on graph classes recognition, we first look for
patterns that can be detected in linear time. We prove, among other results,
that almost all patterns on three vertices (which capture many interesting
classes, such as interval, chordal, split, bipartite, and comparability graphs)
fall in this category. Then, in a finer-grained complexity perspective, we
prove conditional lower bounds for this problem. In particular we show that for
a large family of patterns on four vertices it is unlikely that subquadratic
algorithm exist. Finally, we define a parameter for patterns, the merge-width,
and prove that for patterns of merge-width $t$, one can solve the problem in
$O(n^{ct})$ for some constant~$c$. As a corollary, we get that detecting
outerplanar patterns and other classes of patterns can be done in time
independent of the size of the pattern.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11651'>Finding a Small Vertex Cut on Distributed Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yonggang Jiang, Sagnik Mukhopadhyay</p><p>We present an algorithm for distributed networks to efficiently find a small
vertex cut in the CONGEST model. Given a positive integer $\kappa$, our
algorithm can, with high probability, either find $\kappa$ vertices whose
removal disconnects the network or return that such $\kappa$ vertices do not
exist. Our algorithm takes $\kappa^3\cdot \tilde{O}(D+\sqrt{n})$ rounds, where
$n$ is the number of vertices in the network and $D$ denotes the network's
diameter. This implies $\tilde{O}(D+\sqrt{n})$ round complexity whenever
$\kappa=\text{polylog}(n)$.
</p>
<p>Prior to our result, a bound of $\tilde{O}(D)$ is known only when
$\kappa=1,2$ [Parter, Petruschka DISC'22]. For $\kappa\geq 3$, this bound can
be obtained only by an $O(\log n)$-approximation algorithm [Censor-Hillel,
Ghaffari, Kuhn PODC'14], and the only known exact algorithm takes
$O\left((\kappa\Delta D)^{O(\kappa)}\right)$ rounds, where $\Delta$ is the
maximum degree [Parter DISC'19]. Our result answers an open problem by
Nanongkai, Saranurak, and Yingchareonthawornchai [STOC'19].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yonggang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukhopadhyay_S/0/1/0/all/0/1">Sagnik Mukhopadhyay</a></p><p>We present an algorithm for distributed networks to efficiently find a small
vertex cut in the CONGEST model. Given a positive integer $\kappa$, our
algorithm can, with high probability, either find $\kappa$ vertices whose
removal disconnects the network or return that such $\kappa$ vertices do not
exist. Our algorithm takes $\kappa^3\cdot \tilde{O}(D+\sqrt{n})$ rounds, where
$n$ is the number of vertices in the network and $D$ denotes the network's
diameter. This implies $\tilde{O}(D+\sqrt{n})$ round complexity whenever
$\kappa=\text{polylog}(n)$.
</p>
<p>Prior to our result, a bound of $\tilde{O}(D)$ is known only when
$\kappa=1,2$ [Parter, Petruschka DISC'22]. For $\kappa\geq 3$, this bound can
be obtained only by an $O(\log n)$-approximation algorithm [Censor-Hillel,
Ghaffari, Kuhn PODC'14], and the only known exact algorithm takes
$O\left((\kappa\Delta D)^{O(\kappa)}\right)$ rounds, where $\Delta$ is the
maximum degree [Parter DISC'19]. Our result answers an open problem by
Nanongkai, Saranurak, and Yingchareonthawornchai [STOC'19].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11829'>Learning to Manipulate a Commitment Optimizer</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yurong Chen, Xiaotie Deng, Jiarui Gan, Yuhao Li</p><p>It is shown in recent studies that in a Stackelberg game the follower can
manipulate the leader by deviating from their true best-response behavior. Such
manipulations are computationally tractable and can be highly beneficial for
the follower. Meanwhile, they may result in significant payoff losses for the
leader, sometimes completely defeating their first-mover advantage. A warning
to commitment optimizers, the risk these findings indicate appears to be
alleviated to some extent by a strict information advantage the manipulations
rely on. That is, the follower knows the full information about both players'
payoffs whereas the leader only knows their own payoffs. In this paper, we
study the manipulation problem with this information advantage relaxed. We
consider the scenario where the follower is not given any information about the
leader's payoffs to begin with but has to learn to manipulate by interacting
with the leader. The follower can gather necessary information by querying the
leader's optimal commitments against contrived best-response behaviors. Our
results indicate that the information advantage is not entirely indispensable
to the follower's manipulations: the follower can learn the optimal way to
manipulate in polynomial time with polynomially many queries of the leader's
optimal commitment.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yurong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1">Xiaotie Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_J/0/1/0/all/0/1">Jiarui Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhao Li</a></p><p>It is shown in recent studies that in a Stackelberg game the follower can
manipulate the leader by deviating from their true best-response behavior. Such
manipulations are computationally tractable and can be highly beneficial for
the follower. Meanwhile, they may result in significant payoff losses for the
leader, sometimes completely defeating their first-mover advantage. A warning
to commitment optimizers, the risk these findings indicate appears to be
alleviated to some extent by a strict information advantage the manipulations
rely on. That is, the follower knows the full information about both players'
payoffs whereas the leader only knows their own payoffs. In this paper, we
study the manipulation problem with this information advantage relaxed. We
consider the scenario where the follower is not given any information about the
leader's payoffs to begin with but has to learn to manipulate by interacting
with the leader. The follower can gather necessary information by querying the
leader's optimal commitments against contrived best-response behaviors. Our
results indicate that the information advantage is not entirely indispensable
to the follower's manipulations: the follower can learn the optimal way to
manipulate in polynomial time with polynomially many queries of the leader's
optimal commitment.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11838'>Minimum-Entropy Coupling Approximation Guarantees Beyond the Majorization Barrier</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Spencer Compton, Dmitriy Katz, Benjamin Qi, Kristjan Greenewald, Murat Kocaoglu</p><p>Given a set of discrete probability distributions, the minimum entropy
coupling is the minimum entropy joint distribution that has the input
distributions as its marginals. This has immediate relevance to tasks such as
entropic causal inference for causal graph discovery and bounding mutual
information between variables that we observe separately. Since finding the
minimum entropy coupling is NP-Hard, various works have studied approximation
algorithms. The work of [Compton, ISIT 2022] shows that the greedy coupling
algorithm of [Kocaoglu et al., AAAI 2017] is always within $log_2(e) \approx
1.44$ bits of the optimal coupling. Moreover, they show that it is impossible
to obtain a better approximation guarantee using the majorization lower-bound
that all prior works have used: thus establishing a majorization barrier. In
this work, we break the majorization barrier by designing a stronger
lower-bound that we call the profile method. Using this profile method, we are
able to show that the greedy algorithm is always within $log_2(e)/e \approx
0.53$ bits of optimal for coupling two distributions (previous best-known bound
is within 1 bit), and within $(1 + log_2(e))/2 \approx 1.22$ bits for coupling
any number of distributions (previous best-known bound is within 1.44 bits). We
also examine a generalization of the minimum entropy coupling problem: Concave
Minimum-Cost Couplings. We are able to obtain similar guarantees for this
generalization in terms of the concave cost function. Additionally, we make
progress on the open problem of [Kova\v{c}evi\'c et al., Inf. Comput. 2015]
regarding NP membership of the minimum entropy coupling problem by showing that
any hardness of minimum entropy coupling beyond NP comes from the difficulty of
computing arithmetic in the complexity class NP. Finally, we present
exponential-time algorithms for computing the exactly optimal solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Compton_S/0/1/0/all/0/1">Spencer Compton</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_D/0/1/0/all/0/1">Dmitriy Katz</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_B/0/1/0/all/0/1">Benjamin Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Greenewald_K/0/1/0/all/0/1">Kristjan Greenewald</a>, <a href="http://arxiv.org/find/cs/1/au:+Kocaoglu_M/0/1/0/all/0/1">Murat Kocaoglu</a></p><p>Given a set of discrete probability distributions, the minimum entropy
coupling is the minimum entropy joint distribution that has the input
distributions as its marginals. This has immediate relevance to tasks such as
entropic causal inference for causal graph discovery and bounding mutual
information between variables that we observe separately. Since finding the
minimum entropy coupling is NP-Hard, various works have studied approximation
algorithms. The work of [Compton, ISIT 2022] shows that the greedy coupling
algorithm of [Kocaoglu et al., AAAI 2017] is always within $log_2(e) \approx
1.44$ bits of the optimal coupling. Moreover, they show that it is impossible
to obtain a better approximation guarantee using the majorization lower-bound
that all prior works have used: thus establishing a majorization barrier. In
this work, we break the majorization barrier by designing a stronger
lower-bound that we call the profile method. Using this profile method, we are
able to show that the greedy algorithm is always within $log_2(e)/e \approx
0.53$ bits of optimal for coupling two distributions (previous best-known bound
is within 1 bit), and within $(1 + log_2(e))/2 \approx 1.22$ bits for coupling
any number of distributions (previous best-known bound is within 1.44 bits). We
also examine a generalization of the minimum entropy coupling problem: Concave
Minimum-Cost Couplings. We are able to obtain similar guarantees for this
generalization in terms of the concave cost function. Additionally, we make
progress on the open problem of [Kova\v{c}evi\'c et al., Inf. Comput. 2015]
regarding NP membership of the minimum entropy coupling problem by showing that
any hardness of minimum entropy coupling beyond NP comes from the difficulty of
computing arithmetic in the complexity class NP. Finally, we present
exponential-time algorithms for computing the exactly optimal solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11902'>On price-induced minmax matchings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Christoph D&#xfc;rr, Mathieu Mari, Ulrike Schmidt-Kraepelin</p><p>We study a natural combinatorial pricing problem for sequentially arriving
buyers with equal budgets. Each buyer is interested in exactly one pair of
items and purchases this pair if and only if, upon arrival, both items are
still available and the sum of the item prices does not exceed the budget. The
goal of the seller is to set prices to the items such that the number of
transactions is maximized when buyers arrive in adversarial order.
</p>
<p>Formally, we are given an undirected graph where vertices represent items and
edges represent buyers. Once prices are set to the vertices, edges with a total
price exceeding the buyers' budgets are evicted. Any arrival order of the
buyers leads to a set of transactions that forms a maximal matching in this
subgraph, and an adversarial arrival order results in a minimum maximal
matching. In order to measure the performance of a pricing strategy, we compare
the size of such a matching to the size of a maximum matching in the original
graph. It was shown by Correa et al. [IPCO 2022] that the best ratio any
pricing strategy can guarantee lies within $[1/2, 2/3]$. Our contribution to
the problem is two-fold: First, we provide several characterizations of
subgraphs that may result from pricing schemes. Second, building upon these, we
show an improved upper bound of $3/5$ and a lower bound of $1/2 + 2/n$, where
$n$ is the number of items.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Durr_C/0/1/0/all/0/1">Christoph D&#xfc;rr</a>, <a href="http://arxiv.org/find/cs/1/au:+Mari_M/0/1/0/all/0/1">Mathieu Mari</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_Kraepelin_U/0/1/0/all/0/1">Ulrike Schmidt-Kraepelin</a></p><p>We study a natural combinatorial pricing problem for sequentially arriving
buyers with equal budgets. Each buyer is interested in exactly one pair of
items and purchases this pair if and only if, upon arrival, both items are
still available and the sum of the item prices does not exceed the budget. The
goal of the seller is to set prices to the items such that the number of
transactions is maximized when buyers arrive in adversarial order.
</p>
<p>Formally, we are given an undirected graph where vertices represent items and
edges represent buyers. Once prices are set to the vertices, edges with a total
price exceeding the buyers' budgets are evicted. Any arrival order of the
buyers leads to a set of transactions that forms a maximal matching in this
subgraph, and an adversarial arrival order results in a minimum maximal
matching. In order to measure the performance of a pricing strategy, we compare
the size of such a matching to the size of a maximum matching in the original
graph. It was shown by Correa et al. [IPCO 2022] that the best ratio any
pricing strategy can guarantee lies within $[1/2, 2/3]$. Our contribution to
the problem is two-fold: First, we provide several characterizations of
subgraphs that may result from pricing schemes. Second, building upon these, we
show an improved upper bound of $3/5$ and a lower bound of $1/2 + 2/n$, where
$n$ is the number of items.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11952'>Simultaneous Drawing of Layered Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julia Katheder, Stephen G. Kobourov, Axel Kuckuk, Maximilian Pfister, Johannes Zink</p><p>We study the crossing minimization problem in a layered graph drawing of
rooted trees whose leaves have a given fixed order on the first layer. The task
is to permute the vertices on the other layers to minimize the number of
crossings. While this problem is known to be NP-hard for multiple trees even on
just two layers, we give a polynomial-time algorithm for the restricted case of
two trees. On the other hand, when restricting the number of layers to three,
we describe an XP-algorithm in the number of trees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Katheder_J/0/1/0/all/0/1">Julia Katheder</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobourov_S/0/1/0/all/0/1">Stephen G. Kobourov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuckuk_A/0/1/0/all/0/1">Axel Kuckuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_M/0/1/0/all/0/1">Maximilian Pfister</a>, <a href="http://arxiv.org/find/cs/1/au:+Zink_J/0/1/0/all/0/1">Johannes Zink</a></p><p>We study the crossing minimization problem in a layered graph drawing of
rooted trees whose leaves have a given fixed order on the first layer. The task
is to permute the vertices on the other layers to minimize the number of
crossings. While this problem is known to be NP-hard for multiple trees even on
just two layers, we give a polynomial-time algorithm for the restricted case of
two trees. On the other hand, when restricting the number of layers to three,
we describe an XP-algorithm in the number of trees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11971'>Efficiently handling constraints with Metropolis-adjusted Langevin algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jinyuan Chang, Cheng Yong Tang, Yuanzheng Zhu</p><p>In this study, we investigate the performance of the Metropolis-adjusted
Langevin algorithm in a setting with constraints on the support of the target
distribution. We provide a rigorous analysis of the resulting Markov chain,
establishing its convergence and deriving an upper bound for its mixing time.
Our results demonstrate that the Metropolis-adjusted Langevin algorithm is
highly effective in handling this challenging situation: the mixing time bound
we obtain is superior to the best known bounds for competing algorithms without
an accept-reject step. Our numerical experiments support these theoretical
findings, indicating that the Metropolis-adjusted Langevin algorithm shows
promising performance when dealing with constraints on the support of the
target distribution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Chang_J/0/1/0/all/0/1">Jinyuan Chang</a>, <a href="http://arxiv.org/find/stat/1/au:+Tang_C/0/1/0/all/0/1">Cheng Yong Tang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1">Yuanzheng Zhu</a></p><p>In this study, we investigate the performance of the Metropolis-adjusted
Langevin algorithm in a setting with constraints on the support of the target
distribution. We provide a rigorous analysis of the resulting Markov chain,
establishing its convergence and deriving an upper bound for its mixing time.
Our results demonstrate that the Metropolis-adjusted Langevin algorithm is
highly effective in handling this challenging situation: the mixing time bound
we obtain is superior to the best known bounds for competing algorithms without
an accept-reject step. Our numerical experiments support these theoretical
findings, indicating that the Metropolis-adjusted Langevin algorithm shows
promising performance when dealing with constraints on the support of the
target distribution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12029'>Online Minimum Spanning Trees with Weight Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Magnus Berg, Joan Boyar, Lene M. Favrholdt, Kim S. Larsen</p><p>We consider the minimum spanning tree problem with predictions, using the
weight-arrival model, i.e., the graph is given, together with predictions for
the weights of all edges. Then the actual weights arrive one at a time and an
irrevocable decision must be made regarding whether or not the edge should be
included into the spanning tree. In order to assess the quality of our
algorithms, we define an appropriate error measure and analyze the performance
of the algorithms as a function of the error. We prove that, according to
competitive analysis, the simplest algorithm, Follow-the-Predictions, is
optimal. However, intuitively, one should be able to do better, and we present
a greedy variant of Follow-the-Predictions. In analyzing that algorithm, we
believe we present the first random order analysis of a non-trivial online
algorithm with predictions, by which we obtain an algorithmic separation. This
may be useful for distinguishing between algorithms for other problems when
Follow-the-Predictions is optimal according to competitive analysis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berg_M/0/1/0/all/0/1">Magnus Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyar_J/0/1/0/all/0/1">Joan Boyar</a>, <a href="http://arxiv.org/find/cs/1/au:+Favrholdt_L/0/1/0/all/0/1">Lene M. Favrholdt</a>, <a href="http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1">Kim S. Larsen</a></p><p>We consider the minimum spanning tree problem with predictions, using the
weight-arrival model, i.e., the graph is given, together with predictions for
the weights of all edges. Then the actual weights arrive one at a time and an
irrevocable decision must be made regarding whether or not the edge should be
included into the spanning tree. In order to assess the quality of our
algorithms, we define an appropriate error measure and analyze the performance
of the algorithms as a function of the error. We prove that, according to
competitive analysis, the simplest algorithm, Follow-the-Predictions, is
optimal. However, intuitively, one should be able to do better, and we present
a greedy variant of Follow-the-Predictions. In analyzing that algorithm, we
believe we present the first random order analysis of a non-trivial online
algorithm with predictions, by which we obtain an algorithmic separation. This
may be useful for distinguishing between algorithms for other problems when
Follow-the-Predictions is optimal according to competitive analysis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12081'>A simple division-free algorithm for computing Pfaffians</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam J. Przezdziecki</p><p>We present a very simple algorithm for computing Pfaffians which uses no
division operations. Essentially, it amounts to iterating matrix multiplication
and truncation. Its complexity, for a $2n\times 2n$ matrix, is $O(nM(n))$,
where $M(n)$ is the cost of matrix multiplication. In case of a sparse matrix,
$M(n)$ is the cost of the dense-sparse matrix multiplication.
</p>
<p>The algorithm is an adaptation of the Bird algorithm for determinants. We
show how to extract, with practically no additional work, the characteristic
polynomial and the Pfaffian characteristic polynomial from these algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Przezdziecki_A/0/1/0/all/0/1">Adam J. Przezdziecki</a></p><p>We present a very simple algorithm for computing Pfaffians which uses no
division operations. Essentially, it amounts to iterating matrix multiplication
and truncation. Its complexity, for a $2n\times 2n$ matrix, is $O(nM(n))$,
where $M(n)$ is the cost of matrix multiplication. In case of a sparse matrix,
$M(n)$ is the cost of the dense-sparse matrix multiplication.
</p>
<p>The algorithm is an adaptation of the Bird algorithm for determinants. We
show how to extract, with practically no additional work, the characteristic
polynomial and the Pfaffian characteristic polynomial from these algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12136'>Warehouse Problem with Bounds, Fixed Costs and Complementarity Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ishan Bansal, Oktay G&#xfc;nl&#xfc;k</p><p>This paper studies an open question in the warehouse problem where a merchant
trading a commodity tries to find an optimal inventory-trading policy to decide
on purchase and sale quantities during a fixed time horizon in order to
maximize their total pay-off, making use of fluctuations in sale and cost
prices. We provide the first known polynomial-time algorithms for the case when
there are fixed costs for purchases and sales, optional complementarity
constraints that prohibit purchasing and selling during the same time period,
and bounds on purchase and sales quantities. We do so by providing an exact
characterization of the extreme points of the feasible region and using this to
construct a suitable network where a min-cost flow computation provides an
optimal solution. We are also able to provide polynomial extended linear
formulations for the original feasible regions. Our methods build on the work
by Wolsey and Yaman (Discrete Optimization 2018). We also consider the problem
without fixed costs and provide a fully polynomial time approximation scheme in
a setting with time-dependent bounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bansal_I/0/1/0/all/0/1">Ishan Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunluk_O/0/1/0/all/0/1">Oktay G&#xfc;nl&#xfc;k</a></p><p>This paper studies an open question in the warehouse problem where a merchant
trading a commodity tries to find an optimal inventory-trading policy to decide
on purchase and sale quantities during a fixed time horizon in order to
maximize their total pay-off, making use of fluctuations in sale and cost
prices. We provide the first known polynomial-time algorithms for the case when
there are fixed costs for purchases and sales, optional complementarity
constraints that prohibit purchasing and selling during the same time period,
and bounds on purchase and sales quantities. We do so by providing an exact
characterization of the extreme points of the feasible region and using this to
construct a suitable network where a min-cost flow computation provides an
optimal solution. We are also able to provide polynomial extended linear
formulations for the original feasible regions. Our methods build on the work
by Wolsey and Yaman (Discrete Optimization 2018). We also consider the problem
without fixed costs and provide a fully polynomial time approximation scheme in
a setting with time-dependent bounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12201'>Dynamic Averaging Load Balancing on Arbitrary Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Petra Berenbrink, Lukas Hintze, Hamed Hosseinpour, Dominik Kaaser, Malin Rau</p><p>In this paper we study dynamic averaging load balancing on general graphs. We
consider infinite time and dynamic processes, where in every step new load
items are assigned to randomly chosen nodes. A matching is chosen, and the load
is averaged over the edges of that matching. We analyze the discrete case where
load items are indivisible, moreover our results also carry over to the
continuous case where load items can be split arbitrarily. For the choice of
the matchings we consider three different models, random matchings of linear
size, random matchings containing only single edges, and deterministic
sequences of matchings covering the whole graph. We bound the discrepancy,
which is defined as the difference between the maximum and the minimum load.
Our results cover a broad range of graph classes and, to the best of our
knowledge, our analysis is the first result for discrete and dynamic averaging
load balancing processes. As our main technical contribution we develop a drift
result that allows us to apply techniques based on the effective resistance in
an electrical network to the setting of dynamic load balancing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berenbrink_P/0/1/0/all/0/1">Petra Berenbrink</a>, <a href="http://arxiv.org/find/cs/1/au:+Hintze_L/0/1/0/all/0/1">Lukas Hintze</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseinpour_H/0/1/0/all/0/1">Hamed Hosseinpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaaser_D/0/1/0/all/0/1">Dominik Kaaser</a>, <a href="http://arxiv.org/find/cs/1/au:+Rau_M/0/1/0/all/0/1">Malin Rau</a></p><p>In this paper we study dynamic averaging load balancing on general graphs. We
consider infinite time and dynamic processes, where in every step new load
items are assigned to randomly chosen nodes. A matching is chosen, and the load
is averaged over the edges of that matching. We analyze the discrete case where
load items are indivisible, moreover our results also carry over to the
continuous case where load items can be split arbitrarily. For the choice of
the matchings we consider three different models, random matchings of linear
size, random matchings containing only single edges, and deterministic
sequences of matchings covering the whole graph. We bound the discrepancy,
which is defined as the difference between the maximum and the minimum load.
Our results cover a broad range of graph classes and, to the best of our
knowledge, our analysis is the first result for discrete and dynamic averaging
load balancing processes. As our main technical contribution we develop a drift
result that allows us to apply techniques based on the effective resistance in
an electrical network to the setting of dynamic load balancing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12210'>Using Colors and Sketches to Count Subgraphs in a Streaming Graph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shirin Handjani, Douglas Jungreis, Mark Tiefenbruck</p><p>Suppose we wish to estimate $\#H$, the number of copies of some small graph
$H$ in a large streaming graph $G$. There are many algorithms for this task
when $H$ is a triangle, but just a few that apply to arbitrary $H$. Here we
focus on one such algorithm, which was introduced by Kane, Mehlhorn, Sauerwald,
and Sun. The storage and update time per edge for their algorithm are both
$O(m^k/(\#H)^2)$, where $m$ is the number of edges in $G$, and $k$ is the
number of edges in $H$. Here, we propose three modifications to their algorithm
that can dramatically reduce both the storage and update time. Suppose that $H$
has no leaves and that $G$ has maximum degree $\leq m^{1/2 - \alpha}$, where
$\alpha &gt; 0$. Define $C = \min(m^{2\alpha},m^{1/3})$. Then in our version of
the algorithm, the update time per edge is $O(1)$, and the storage is
approximately reduced by a factor of $C^{2k-t-2}$, where $t$ is the number of
vertices in $H$; in particular, the storage is $O(C^2 + m^k/(C^{2k-t-2}
(\#H)^2))$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Handjani_S/0/1/0/all/0/1">Shirin Handjani</a>, <a href="http://arxiv.org/find/cs/1/au:+Jungreis_D/0/1/0/all/0/1">Douglas Jungreis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiefenbruck_M/0/1/0/all/0/1">Mark Tiefenbruck</a></p><p>Suppose we wish to estimate $\#H$, the number of copies of some small graph
$H$ in a large streaming graph $G$. There are many algorithms for this task
when $H$ is a triangle, but just a few that apply to arbitrary $H$. Here we
focus on one such algorithm, which was introduced by Kane, Mehlhorn, Sauerwald,
and Sun. The storage and update time per edge for their algorithm are both
$O(m^k/(\#H)^2)$, where $m$ is the number of edges in $G$, and $k$ is the
number of edges in $H$. Here, we propose three modifications to their algorithm
that can dramatically reduce both the storage and update time. Suppose that $H$
has no leaves and that $G$ has maximum degree $\leq m^{1/2 - \alpha}$, where
$\alpha &gt; 0$. Define $C = \min(m^{2\alpha},m^{1/3})$. Then in our version of
the algorithm, the update time per edge is $O(1)$, and the storage is
approximately reduced by a factor of $C^{2k-t-2}$, where $t$ is the number of
vertices in $H$; in particular, the storage is $O(C^2 + m^k/(C^{2k-t-2}
(\#H)^2))$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, February 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/02/23/mathematics-of-the-impossible-computational-complexity-chapter-5-completeness-reducing-arbitrary-computation/'>Mathematics of the impossible: Computational Complexity, Chapter 5, Completeness: Reducing arbitrary computation</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this chapter we show how to reduce arbitrary computation to 3Sat (and hence to the other problems in section&#160;Âº4.3). What powers everything is the following landmark and, in hindsight, simple result which reduces circuit computation to 3Sat. Theorem 5.1. Given a circuit with gates we can compute in a 3CNF formula in variables such [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p style="text-align:justify">In this chapter we show how to reduce arbitrary computation to 3Sat (and hence to the other problems in section&nbsp;Âº<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a>). What powers everything is the following landmark and, in hindsight, simple result which reduces circuit computation to 3Sat.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-56001r1"></a> <b>Theorem</b> 5.1.  </span> Given a circuit <img src="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> gates we can compute in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> a 3CNF formula <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=n%2Bs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Bs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Bs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n+s" class="latex" /> variables such that for every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" />:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bs%7D%3Af_%7BC%7D%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bs%7D%3Af_%7BC%7D%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bs%7D%3Af_%7BC%7D%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} C(x)=1&#92;Leftrightarrow &#92;exists y&#92;in &#92;{0,1&#92;} ^{s}:f_{C}(x,y)=1. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The key idea to <em>guess computation and check it efficiently, using that computation is local.</em> The additional <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> variables one introduces contain the values of the gates during the computation of <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />. We simply have to check that they all correspond to a valid computation, and this can be written as 3CNF because each gate depends on at most two other gates.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Introduce a variable <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i}" class="latex" /> for each non-input gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. The value of <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i}" class="latex" /> is intended to be the value of gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" /> during the computation. Whether the value of a gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" /> is correct is a function of <img src="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3" class="latex" /> variables: <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i}" class="latex" /> and the <img src="https://s0.wp.com/latex.php?latex=%5Cle+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 2" class="latex" /> gates that input <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" />, some of which could be input variables. This can be written as a 3CNF by Theorem <a href="#x1-25003r3">2.3<!--tex4ht:ref: thm:every-function-ckt-Lupanov --></a>. Take an And of all these 3CNFs. Finally, add clause <img src="https://s0.wp.com/latex.php?latex=y_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{o}" class="latex" /> for the output gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{o}" class="latex" />. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-56002r1"></a> <b>Exercise</b> 5.1.  </span>Write down the 3CNF for the circuit in figure&nbsp;<a href="#x1-240062">2.2<!--tex4ht:ref: fig:Ckt --></a>, as given by the proof of Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> is <em>a depth-reduction</em> result. Indeed, note that a 3CNF can be written as a circuit of depth <img src="https://s0.wp.com/latex.php?latex=c%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log s" class="latex" />, whereas the original circuit may have any depth. This is helpful for example if you donât have the depth to run the circuit yourself. You can let someone else produce the computation, and you can check it in small depth.</p>
<p style="text-align:justify">   We can combine Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> with the simulations in Chapter <a href="#x1-180002">2<!--tex4ht:ref: chap:The-alphabet-of --></a> to reduce computation in other models to 3SAT. In particular, we can reduce MTMs running in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> to 3Sat of size <img src="https://s0.wp.com/latex.php?latex=t%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;log ^{c}t" class="latex" />. To obtain such parameters we need the quasilinear simulation of MTMs by circuits, Theorem <a href="#x1-25007r5">2.5<!--tex4ht:ref: thm:simu-TMs-by-CKTs-quasi-linear --></a>.</p>
<p style="text-align:justify">   However, recall that a quasilinear simulation of RAMs by circuits is not known. Only a power simulation is (which is obtained by combining the power simulation of RAMs by MTMs, Theorem <a href="#x1-26003r6">2.6<!--tex4ht:ref: thm:simu-RAM-by-TM --></a>, with a simulation of MTMs by circuits). This would reduce RAM computation running in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> to 3CNFs of size <img src="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t^{c}" class="latex" />. We content ourselves with this power loss for the beginning of this chapter. Later in section&nbsp;Âº<a href="#x1-610005.3">5.3<!--tex4ht:ref: sec:RAM-to-SAT-quasilinear --></a> we will obtain a quasi-linear simulation using an enjoyable argument which also bypasses Theorem <a href="#x1-25007r5">2.5<!--tex4ht:ref: thm:simu-TMs-by-CKTs-quasi-linear --></a>.</p>
<p style="text-align:justify">   In fact, these simulations apply to a more general, <em>non-deterministic</em>, model of computation. We define this model next, and then present the simulation with power loss in <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>.</p>
<h3 class="sectionHead"><span class="titlemark">5.1   </span> <a id="x1-570005.1"></a>Nondeterministic computation</h3>
<p style="text-align:justify">In the concluding equation in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> there is an <img src="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists " class="latex" /> quantifier on the right-hand side, but there isnât one on the left, next to the circuit. However, because the simulation works for every input, we can âstickâ a quantifier on the left and have the same result. The resulting circuit computation <img src="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(x,y)" class="latex" /> has two inputs, <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. We can think of it as a <em>non-deterministic</em> circuit, which on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> outputs <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> iff <img src="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists y:C(x,y)" class="latex" />. Following the discussion before, we could do the same for other models like TMs, MTMs, and RAMs. The message here is that â if we allow for an <img src="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists " class="latex" /> quantifier, or in other words consider nondeterministic computation â efficient computation is <em>equivalent</em> to 3CNF! This is one motivation for formally introducing a <em>nondeterministic </em>computational model.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-57001r1"></a> <b>Definition</b> 5.1.  </span>NTime<img src="https://s0.wp.com/latex.php?latex=%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(t(n))" class="latex" /> is the set of functions <img src="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:X&#92;subseteq &#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> for which there is a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> such that:</p>
<p style="text-align:justify">   &#8211; <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=1" class="latex" /> iff <img src="https://s0.wp.com/latex.php?latex=%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28%7Cx%7C%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28%7Cx%7C%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28%7Cx%7C%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists y&#92;in &#92;{0,1&#92;} ^{t(|x|)}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)=1" class="latex" />, and</p>
<p style="text-align:justify">   &#8211; <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)" class="latex" /> stops within <img src="https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(|x|)" class="latex" /> steps on every input <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" />.</p>
<p style="text-align:justify">   We also define</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNP%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%28n%5E%7Bd%7D%29%2C%5C%5C+%5Ctext+%7BNExp%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%282%5E%7Bn%5E%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNP%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%28n%5E%7Bd%7D%29%2C%5C%5C+%5Ctext+%7BNExp%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%282%5E%7Bn%5E%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNP%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%28n%5E%7Bd%7D%29%2C%5C%5C+%5Ctext+%7BNExp%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%282%5E%7Bn%5E%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {NP}:= &amp; &#92;bigcup _{d&#92;ge 1}&#92;text {NTime}(n^{d}),&#92;&#92; &#92;text {NExp}:= &amp; &#92;bigcup _{d&#92;ge 1}&#92;text {NTime}(2^{n^{d}}). &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Note that the running time of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is a function of <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|" class="latex" />, not <img src="https://s0.wp.com/latex.php?latex=%7C%28x%2Cy%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7C%28x%2Cy%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7C%28x%2Cy%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|(x,y)|" class="latex" />. This difference is inconsequential for NP, since the composition of two powers is another power. But it is important for a more fine-grained analysis. We refer to a RAM machine as in Definition <a href="#x1-57001r1">5.1<!--tex4ht:ref: def:NTime --></a> as a <em>nondeterministic machine</em>, and to the <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)" class="latex" /> as the <em>nondeterministic choices,</em> or <em>guesses, </em>of the machine on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align:justify">   We can also define NTime in a way that is similar to BPTime, Definition <a href="#x1-27001r7">2.7<!--tex4ht:ref: def:BPTime-BPP --></a>. The two definitions are essentially equivalent. Our choice for BPTime is motivated by the identification of BPTime with computation that is actually run. For example, in a programming language one uses an instruction like Rand to obtain random values; one does not think of the                                                                                                                                                                                     randomness as being part of the input. By contrast, NTime is a more abstract model, and the definition with the nondeterministic guesses explicitly laid out is closer in spirit to a 3CNF.</p>
<p style="text-align:justify">   All the problems we studied in section&nbsp;Âº<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a> are in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-57002r1"></a> <b>Fact</b> 5.1.  </span>3Sat, Clique, Cover-by-vertexes, SubsetSum, and 3Color are in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>For a 3Sat instance <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />, the variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> correspond to an assignment. Checking if the assignment satisfies <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is in P. This shows that 3Sat is in NP. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-57003r2"></a> <b>Exercise</b> 5.2.  </span>Finish the proof by ad<br />
dressing the other problems in Fact <a href="#x1-57002r1">5.1<!--tex4ht:ref: fact:3Sa-etc-in-NP --></a></p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h5 class="likesubsubsectionHead"><a id="x1-580005.1"></a>How to think of NP</h5>
<p style="text-align:justify">We can think of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> as the problems which admit a solution that can be verified efficiently, namely in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. For example for 3Sat it is easy to verify if an assignment satisfies the clauses, for 3Color it is easy to verify if a coloring is such that any edge has endpoints of different colors, for SubsetSum it is easy to verify if a subset has a sum equal to a target, and so on. However, as we saw above this verification step can be cast in a restricted model, namely a 3CNF. So we donât have to think of the verification step as using the full power of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> computation.</p>
<p style="text-align:justify">   Hereâs a vivid illustration of NP. Suppose I claim that the following matrix contains a <img src="https://s0.wp.com/latex.php?latex=9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="9" class="latex" />:</p>
<div style="text-align:center">
<div class="fbox">
<div class="minipage">56788565634705634705637480563476</p>
<p style="text-align:justify">70156137805167840132838202386421</p>
<p style="text-align:justify">85720582340570372307580234576423</p>
<p style="text-align:justify">80275880237505788075075802346518</p>
<p style="text-align:justify">78502378564067807582348057285428</p>
<p style="text-align:justify">05723748754543650350562378804337</p>
<p style="text-align:justify">52305723485008160234723884077764</p>
<p style="text-align:justify">86543234567865435674567836738063</p>
<p style="text-align:justify">45463788486754345743457483460040</p>
<p style="text-align:justify">73273873486574375464584895741832</p>
<p style="text-align:justify">85075783485634856237847287422112</p>
<p style="text-align:justify">83748874883753485745788788223201</p>
</div>
</div>
</div>
<p style="text-align:justify">   How can you tell, without tediously examining the whole matrix? However, if I tell you that itâs in row 10, 8 digits from the right, you can quickly check that I am right. I wonât be able to cheat, since you can check my claims. On the other hand I can provide a proof thatâs easy to verify.</p>
<p style="text-align:justify">
<h5 class="likesubsubsectionHead"><a id="x1-590005.1"></a>P vs.&nbsp;NP</h5>
<p style="text-align:justify">The flagship question of complexity theory is whether <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}=&#92;text {NP}" class="latex" /> or not. This is a young, prominent special case of the grand challenge we introduced in Chapter <a href="#x1-370003">3<!--tex4ht:ref: chap:The-grand-challenge --></a>. Contrary to the analogous question for <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}" class="latex" />, cf.&nbsp;section&nbsp;<a href="#x1-290002.5.2">2.5.2<!--tex4ht:ref: subsec:BPTime-vs-time --></a>, the general belief seems to be that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}&#92;ne &#92;text {NP}" class="latex" />. Similarly to BPP, cf.&nbsp;Theorem <a href="#x1-29001r9">2.9<!--tex4ht:ref: thm:Time-vs-BPTime --></a>, the best deterministic simulation of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> runs in exponential time by trying all nondeterministic guesses. This gives the middle inclusion in the following fact; the other two are by definition.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-59001r2"></a> <b>Fact</b> 5.2.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Csubseteq+%5Ctext+%7BNP%7D%5Csubseteq+%5Ctext+%7BExp+%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BNExp%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Csubseteq+%5Ctext+%7BNP%7D%5Csubseteq+%5Ctext+%7BExp+%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BNExp%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Csubseteq+%5Ctext+%7BNP%7D%5Csubseteq+%5Ctext+%7BExp+%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BNExp%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}&#92;subseteq &#92;text {NP}&#92;subseteq &#92;text {Exp &#92;ensuremath {&#92;subseteq &#92;text {NExp}}}" class="latex" />.</p>
<p style="text-align:justify">   A consequence of the Time Hierarchy Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a> is that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}&#92;ne &#92;text {Exp}" class="latex" />. From the inclusions above it follows that</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D%5Ctext+%7B+or+NP%7D%5Cne+%5Ctext+%7BExp%2C+possibly+both%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D%5Ctext+%7B+or+NP%7D%5Cne+%5Ctext+%7BExp%2C+possibly+both%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D%5Ctext+%7B+or+NP%7D%5Cne+%5Ctext+%7BExp%2C+possibly+both%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {P}&#92;ne &#92;text {NP}&#92;text { or NP}&#92;ne &#92;text {Exp, possibly both}. &#92;end{aligned}" class="latex" /></div>
<p>Thus, we are not completely clueless, and we know that at least one important separation is lurking somewhere. Most people appear to think that <em>both</em> separations hold, but we are unable to prove <em>either</em>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   For multi-tape machines, a separation between deterministic and non-deterministic linear time is in <span class="cite">[<a href="#XPPST83">24</a>,&nbsp;<a href="conf/coco/Santhanam01">27</a>]</span>.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.2   </span> <a id="x1-600005.2"></a>NP-completeness</h3>
<p style="text-align:justify">We now go back to the question at the beginning of this chapter about reducing arbitrary computation to 3Sat. We shall reduce all of NP to 3Sat in Theorem <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>. Problems like 3Sat admitting such reductions deserve a definition.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60001r2"></a> <b>Definition</b> 5.2.  </span>We call a problem <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" />:</p>
<p style="text-align:justify">   NP-hard if every problem in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />;</p>
<p style="text-align:justify">   NP-complete if it is NP-hard and in NP.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   One can define <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" />-hard (and hence NP-complete) w.r.t.&nbsp;different reductions, cf.&nbsp;Chapter <a href="#x1-450004">4<!--tex4ht:ref: chap:Reductions --></a>, and we will do so later. But the simple choice above suffices for now.</p>
<p style="text-align:justify">   Complete problems are the âhardest problemsâ in the class, as formalized in the following fact.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60002r3"></a> <b>Fact</b> 5.3.  </span>Suppose <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {L}" class="latex" /> is NP-complete. Then <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CLeftrightarrow+%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CLeftrightarrow+%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CLeftrightarrow+%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {P}&#92;Leftrightarrow &#92;text {P}=&#92;text {NP}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span><img src="https://s0.wp.com/latex.php?latex=%28%5CLeftarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5CLeftarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5CLeftarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;Leftarrow )" class="latex" /> This is because <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {NP}" class="latex" />.</p>
<p style="text-align:justify">   (<img src="https://s0.wp.com/latex.php?latex=%5CRightarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CRightarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CRightarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Rightarrow )" class="latex" /> Let <img src="https://s0.wp.com/latex.php?latex=L%27%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%27%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%27%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#039;&#92;in &#92;text {NP}" class="latex" />. Because <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> is NP-hard we know that <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%5Censuremath+%7B%5CRightarrow+L%27%5Cin+%5Ctext+%7BP%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%5Censuremath+%7B%5CRightarrow+L%27%5Cin+%5Ctext+%7BP%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%5Censuremath+%7B%5CRightarrow+L%27%5Cin+%5Ctext+%7BP%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {P&#92;ensuremath {&#92;Rightarrow L&#039;&#92;in &#92;text {P}}.}" class="latex" /> <b>QED</b></p>
</div>
<p style="text-align:justify">   Fact <a href="#x1-60002r3">5.3<!--tex4ht:ref: fact:np-complete-in-P-iff-p=00003Dnp --></a> points to an important interplay between problems and complexity classes. We can study complexity classes by studying their complete problems, and vice versa.</p>
<p style="text-align:justify">   The central result in the theory of NP completeness is the following.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60003r2"></a> <b>Theorem</b> 5.2.  </span><span class="cite">[<a href="#XCook73">7</a>,&nbsp;<a href="#XLevin73">20</a>]</span> 3Sat is NP-complete.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>3Sat is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> by Fact <a href="#x1-57002r1">5.1<!--tex4ht:ref: fact:3Sa-etc-in-NP --></a>. Next we prove NP-hardness. The main idea is Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>, while the rest of the proof mostly amounts to opening up definitions and using some previous simulations. Let <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {NP}" class="latex" /> and let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be the corresponding TM which runs in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{d}" class="latex" /> on inputs <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|=n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Cy%7C%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cy%7C%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cy%7C%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|y|=n^{d}" class="latex" />, for some constant <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />. We can work with TMs instead of RAMs since they are equivalent up to a power loss, as we saw in Theorem <a href="#x1-26003r6">2.6<!--tex4ht:ref: thm:simu-RAM-by-TM --></a>. We can construct in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P }" class="latex" />a circuit <img src="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(x,y)" class="latex" /> of size <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7Dn%5E%7Bc_%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7Dn%5E%7Bc_%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7Dn%5E%7Bc_%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}n^{c_{d}}" class="latex" /> such that for any <img src="https://s0.wp.com/latex.php?latex=x%2Cy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%2Cy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%2Cy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x,y" class="latex" /> we have <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1%5CLeftrightarrow+C%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1%5CLeftrightarrow+C%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1%5CLeftrightarrow+C%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)=1&#92;Leftrightarrow C(x,y)=1" class="latex" /> by Theorem <a href="#x1-25006r4">2.4<!--tex4ht:ref: thm:simu-tm-by-ckts-simple --></a>.</p>
<p style="text-align:justify">   Now, suppose we are given an input <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> for which we are trying to decide membership in <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" />. This is equivalent to deciding if <img src="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28w%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28w%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28w%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists y:C(w,y)=1" class="latex" /> by what we just said. We can âhard-wireâ <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> into <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> to obtain the circuit <img src="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3A%3DC%28w%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3A%3DC%28w%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3A%3DC%28w%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{w}(y):=C(w,y)" class="latex" /> only on the variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />, with no loss in size. Here by âhard-wiseâ se mean replacing the input gates <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> with the bits of <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" />. Now we can apply Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> to this new circuit to produce a 3CNF <img src="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{w}" class="latex" /> on variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> and new variables <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+z%3Af%28y%2Cz%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+z%3Af%28y%2Cz%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+z%3Af%28y%2Cz%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{w}(y)=1&#92;Leftrightarrow &#92;exists z:f(y,z)=1" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. The size of <img src="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{w}" class="latex" /> and the number of variables <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> is power in the size of the circuit.</p>
<p style="text-align:justify">   We have obtained:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+w%5Cin+L%5CLeftrightarrow+%5Cexists+y%3AM%28w%2Cy%29%3D1%5CLeftrightarrow+%5Cexists+y%3AC_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+y%2Cz%3Af_%7Bw%7D%28y%2Cz%29%3D1%5CLeftrightarrow+f_%7Bw%7D%5Cin+%5Ctext+%7B3Sat%2C%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+w%5Cin+L%5CLeftrightarrow+%5Cexists+y%3AM%28w%2Cy%29%3D1%5CLeftrightarrow+%5Cexists+y%3AC_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+y%2Cz%3Af_%7Bw%7D%28y%2Cz%29%3D1%5CLeftrightarrow+f_%7Bw%7D%5Cin+%5Ctext+%7B3Sat%2C%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+w%5Cin+L%5CLeftrightarrow+%5Cexists+y%3AM%28w%2Cy%29%3D1%5CLeftrightarrow+%5Cexists+y%3AC_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+y%2Cz%3Af_%7Bw%7D%28y%2Cz%29%3D1%5CLeftrightarrow+f_%7Bw%7D%5Cin+%5Ctext+%7B3Sat%2C%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} w&#92;in L&#92;Leftrightarrow &#92;exists y:M(w,y)=1&#92;Leftrightarrow &#92;exists y:C_{w}(y)=1&#92;Leftrightarrow &#92;exists y,z:f_{w}(y,z)=1&#92;Leftrightarrow f_{w}&#92;in &#92;text {3Sat,} &#92;end{aligned}" class="latex" /></div>
<p>as desired. <b>QED</b></p>
</div>
<p style="text-align:justify">   In section&nbsp;Âº<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a> we reduced 3Sat to other problems which are also in NP by Fact <a href="#x1-57002r1">5.1<!--tex4ht:ref: fact:3Sa-etc-in-NP --></a>. This implies that all these problems are NP-complete. Here we use that if problem <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> in P, and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />, then also <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. This is because if <img src="https://s0.wp.com/latex.php?latex=C%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in &#92;text {P}" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B&#92;in &#92;text {P}" class="latex" />, and so <img src="https://s0.wp.com/latex.php?latex=A%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A&#92;in &#92;text {P}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60004r1"></a> <b>Corollary</b> 5.1.  </span> Clique, Cover-by-vertexes, Subset-sum, and 3Color are NP-complete.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   It is important to note that there is nothing special about the <em>existence</em> of NP-complete problems. The following is a simple such problem that does not require any of the machinery in this section.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60005r3"></a> <b>Exercise</b> 5.3.  </span>Consider the problem, given a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, an input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;in &#92;mathbb {N}" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is written in unary, decide if there is <img src="https://s0.wp.com/latex.php?latex=y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y&#92;in &#92;{0,1&#92;} ^{t}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)=1" class="latex" />. Prove that this is NP-complete.</p>
<p style="text-align:justify">   What if <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is written in binary?</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The interesting aspect of NP-complete problems such as 3Sat and those in Corollary <a href="#x1-60004r1">5.1<!--tex4ht:ref: cor:all-probs-NP-complete --></a> is that they are very simple and structured, and donât refer to computational models. This makes them suitable for reductions, and for inferring properties of the complexity class which are not evident from a machine-based definition.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.3   </span> <a id="x1-610005.3"></a>From RAM to 3SAT in quasi-linear time</h3>
<p style="text-align:justify">The framework in the previous section is useful to relate membership in P of different problems in NP, but it is not suitable for a more fine-grained analysis. For example, under the assumption that 3Sat is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(cn)" class="latex" /> we cannot immediately conclude that other problems in NP are solvable in this time or in about this time. We can only conclude that they are in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. In particular, the complexity of 3Sat cannot be related to that of other central conjectures, such as whether 3Sum is in subquadratic time, Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a>.</p>
<p style="text-align:justify">   The culprit is the power loss in reducing RAM computation to circuits, mentioned at the beginning of the chapter. We now remedy this situation and present a quasi-linear reduction. As we did before, cf.&nbsp;Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> and Theorem <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>, we first state a version of the simulation for (deterministic) computation which contains all the main ideas, and then we note that a completeness result follows.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-61001r3"></a> <b>Theorem</b> 5.3.  </span>Given an input length <img src="https://s0.wp.com/latex.php?latex=n%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;in &#92;mathbb {N}" class="latex" />, a time bound <img src="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;in &#92;mathbb {N}" class="latex" />, and a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> that runs in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> on inputs of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits, we can compute in time <img src="https://s0.wp.com/latex.php?latex=t%27%3A%3Dc_%7BM%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27%3A%3Dc_%7BM%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27%3A%3Dc_%7BM%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;:=c_{M}t(&#92;log t)^{c}" class="latex" /> a 3CNF <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> on variables <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%7Cy%7C%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cy%7C%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cy%7C%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|y|&#92;le t&#039;" class="latex" /> such that for every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" />:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%28x%29%3D1%5Ciff+%5Cexists+y%3Af%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%28x%29%3D1%5Ciff+%5Cexists+y%3Af%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%28x%29%3D1%5Ciff+%5Cexists+y%3Af%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} M(x)=1&#92;iff &#92;exists y:f(x,y)=1. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We now present the proof of this amazing result; you may want to refer back to Definition <a href="#x1-26001r5">2.5<!--tex4ht:ref: def:RAM --></a> of a RAM. A key concept in the proof is the following âsnapshotâ of the RAM computation.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-61002r3"></a> <b>Definition</b> 5.3.  </span>The <em>internal configuration, </em>abbreviated IC<em>, </em>of a RAM specifies:</p>
<ul class="itemize1">
<li class="itemize">its registers,</li>
<li class="itemize">the program counter,</li>
<li class="itemize">the word length <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" />, and</li>
<li class="itemize">if the current instruction is a Read <img src="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{i}:=&#92;mu [r_{j}]" class="latex" /> or Write <img src="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D%3A%3Dr_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D%3A%3Dr_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D%3A%3Dr_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mu [r_{j}]:=r_{i}" class="latex" /> then the IC includes the content <img src="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mu [r_{j}]" class="latex" /> of the       memory cell indexed by <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" />.</li>
</ul>
</div>
<p style="text-align:justify">   Note that at most one memory cell is included in one IC. By contrast, the configuration of a TM (Definition <a href="#x1-19001r1">2.1<!--tex4ht:ref: def:TM --></a>) includes all its tape cells. Also note that an IC has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}+c&#92;log t" class="latex" /> bits, where the <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}" class="latex" /> is for the program counter, and the <img src="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log t" class="latex" /> is for the rest, using that the maximum word length of a machine running in time <img src="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge n" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log t" class="latex" />.</p>
<p style="text-align:justify"><span class="paragraphHead"><a id="x1-620005.3"></a>The key idea in the proof.</span>    At the high level, the approach is, like in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>, to guess computation and check it efficiently. We are going to <em>guess </em>the sequence of ICs, and we need additional ideas to check them efficiently by a circuit. This is not immediate, since, again, the RAM can use direct access to read and write in memory at arbitrary locations, something which is not easy to do with a circuit.</p>
<p style="text-align:justify">   The key idea is to check operations involving memory <em>independently </em>from the operations involving registers but not memory. If both checks pass, then the computation is correct. More precisely, a sequence of internal configurations <img src="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{1},s_{2},&#92;ldots ,s_{t}" class="latex" /> corresponds to the computation of the RAM on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> iff for every <img src="https://s0.wp.com/latex.php?latex=i%3Ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3Ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3Ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&lt;t" class="latex" />:
</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-62002x1">If <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i}" class="latex" /> does not access memory, then <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i+1}" class="latex" /> has its registers, program counter, and word length       updated according to the instruction executed in <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i}" class="latex" />,</li>
<li class="enumerate" id="x1-62004x2">If <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i}" class="latex" /> is computing a read operation <img src="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Ctext+%7B%5Censuremath+%7B%5Cmu+%5Br_%7Bj%7D%5D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Ctext+%7B%5Censuremath+%7B%5Cmu+%5Br_%7Bj%7D%5D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Ctext+%7B%5Censuremath+%7B%5Cmu+%5Br_%7Bj%7D%5D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{i}:=&#92;text {&#92;ensuremath {&#92;mu [r_{j}]}}" class="latex" /> then in <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i+1}" class="latex" /> register <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" /> contains <em>the most recent value       written in memory cell <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" /></em>. In case this cell was never written, then <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" /> should contain <img src="https://s0.wp.com/latex.php?latex=x_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{j}" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j&#92;in &#92;{1,2,&#92;ldots ,n&#92;}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />       if <img src="https://s0.wp.com/latex.php?latex=j%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j=0" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> otherwise. The program counter in <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i+1}" class="latex" /> also points to the next instruction.</li>
</ol>
<p style="text-align:justify">Rather than directly constructing a 3CNF that implements these checks, we construct a circuit and then appeal to Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>. It is easy to construct a circuit of quasi-linear size implementing Check 1, since the circuit only has to check adjacent pairs of ICs. As remarked before, these ICs have length <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}+c&#92;log t" class="latex" />. For fixed <img src="https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i," class="latex" /> Check 1 can be implemented by a circuit which depends on the RAM and has size power in the length of an IC. Taking an And of these circuits over the choices of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> gives a circuit of the desired size for Check 1.</p>
<p style="text-align:justify">   The difficulty lies in Check 2, because the circuit needs to find âthe most recent value written.â The solution is to <em>sort</em> the ICs by memory addresses. After sorting, we can implement Check (2) as easily as Check (1), since we just need to check adjacent pairs of ICs.</p>
<p style="text-align:justify">   The emergence of sorting in the theory of NP-completeness cements the pivotal role this operation plays in computer science.</p>
<p style="text-align:justify">   To implement this idea we need to be able to sort with a quasi-linear size circuit. Standard sorting algorithms like Mergesort, Heapsort, or Radixsort run in quasi-linear time on a RAM, but rely on direct addressing (cf.&nbsp;section&nbsp;Âº<a href="#x1-260002.4">2.4<!--tex4ht:ref: sec:RAMs --></a>) and for this reason cannot be easily implemented by a circuit of quasi-linear size. However other algorithms have been developed that do have such an implementation, for example a variant of Mergesort called Odd-Even-Mergesort <span class="cite">[<a href="#XBatcher68">6</a>]</span>, see also <span class="cite">[<a href="#XViolaNEU-ram2sat-neu-author">22</a>]</span>. This gives the following lemma.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-62005r1"></a> <b>Lemma</b> 5.1.  </span>Given <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> we can compute in time <img src="https://s0.wp.com/latex.php?latex=t%27%3A%3Dt%5Ccdot+%28m%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27%3A%3Dt%5Ccdot+%28m%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27%3A%3Dt%5Ccdot+%28m%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;:=t&#92;cdot (m&#92;log t)^{c}" class="latex" /> a circuit (of size <img src="https://s0.wp.com/latex.php?latex=%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le t&#039;" class="latex" />) that sorts <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> integers of <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> bits.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We summarize the key steps in the proof.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-61001r3">5.3<!--tex4ht:ref: thm:redux-RAM-2-3cnf-quasilinear --></a></b>.&nbsp;</span> We construct a circuit <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> and then appeal to Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>. The extra variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> correspond to <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> ICs <img src="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{1},s_{2},&#92;ldots ,s_{t}" class="latex" />. An IC takes <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}+c&#92;log t" class="latex" /> bits to specify, so we need <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7Dt%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7Dt%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7Dt%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}t&#92;log t" class="latex" /> variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. The circuit <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> first performs Check (1) above for each adjacent pair <img src="https://s0.wp.com/latex.php?latex=%28s_%7Bi%7D%2Cs_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28s_%7Bi%7D%2Cs_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28s_%7Bi%7D%2Cs_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(s_{i},s_{i+1})" class="latex" /> of ICs. This takes size <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}&#92;log ^{c}t" class="latex" /> for each pair, and so size <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}t&#92;log ^{c}t" class="latex" /> overall.</p>
<p style="text-align:justify">   Then <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> sorts the ICs by memory addresses, producing sorted ICs <img src="https://s0.wp.com/latex.php?latex=s%27_%7B1%7D%2Cs%27_%7B2%7D%2C%5Cldots+%2Cs%27_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%27_%7B1%7D%2Cs%27_%7B2%7D%2C%5Cldots+%2Cs%27_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%27_%7B1%7D%2Cs%27_%7B2%7D%2C%5Cldots+%2Cs%27_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#039;_{1},s&#039;_{2},&#92;ldots ,s&#039;_{t}" class="latex" />. This takes size <img src="https://s0.wp.com/latex.php?latex=t%5Ccdot+%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Ccdot+%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Ccdot+%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;cdot &#92;log ^{c}t" class="latex" /> by Lemma <a href="#x1-62005r1">5.1<!--tex4ht:ref: lem:sorting-ckt-quasilinear --></a>, using that the memory addresses have <img src="https://s0.wp.com/latex.php?latex=%5Cle+c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c&#92;log t" class="latex" /> bits. Then the circuit performs Check (2) for each adjacent pair <img src="https://s0.wp.com/latex.php?latex=%28s%27_%7Bi%7D%2Cs%27_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28s%27_%7Bi%7D%2Cs%27_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28s%27_%7Bi%7D%2Cs%27_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(s&#039;_{i},s&#039;_{i+1})" class="latex" /> of ICs. The circuit size required for this is no more than for Check (1).</p>
<p style="text-align:justify">   Finally, the circuit takes an And of the results of the two checks, and also checks that <img src="https://s0.wp.com/latex.php?latex=s_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{t}" class="latex" /> is accepting. <b>QED</b></p>
</div>
<p style="text-align:justify">   We can now prove completeness in a manner similar to Theorem <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>, with a relatively simple extension of Theorem <a href="#x1-61001r3">5.3<!--tex4ht:ref: thm:redux-RAM-2-3cnf-quasilinear --></a>.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-62006r4"></a>                                                                                                                                                                                     <b>Theorem</b> 5.4.  </span>Every problem <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NTime}(t)" class="latex" /> map reduces to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28c_%7BL%2Ct%7Dt%5Clog+%5E%7Bc%7Dt%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28c_%7BL%2Ct%7Dt%5Clog+%5E%7Bc%7Dt%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28c_%7BL%2Ct%7Dt%5Clog+%5E%7Bc%7Dt%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(c_{L,t}t&#92;log ^{c}t)" class="latex" />, for every function <img src="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge n" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(x)" class="latex" /> is computable in time <img src="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(x)" class="latex" /> given <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The assumption on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is similar to that in the hierarchy Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>, and is satisfied by all standard functions including all those in this book â cf.&nbsp;discussion after Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be a RAM computing <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> in the assumed time. Given an input <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> we have to efficiently compute a 3CNF <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> such that</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28n%29%7D%3AM%28w%2Cy%29%3D1%5Ciff+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bc_%7BL%2Ct%7Dt%28n%29%5Clog+%5E%7Bc%7Dt%28n%29%7D%3Af%28y%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28n%29%7D%3AM%28w%2Cy%29%3D1%5Ciff+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bc_%7BL%2Ct%7Dt%28n%29%5Clog+%5E%7Bc%7Dt%28n%29%7D%3Af%28y%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28n%29%7D%3AM%28w%2Cy%29%3D1%5Ciff+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bc_%7BL%2Ct%7Dt%28n%29%5Clog+%5E%7Bc%7Dt%28n%29%7D%3Af%28y%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;exists y&#92;in &#92;{0,1&#92;} ^{t(n)}:M(w,y)=1&#92;iff &#92;exists y&#92;in &#92;{0,1&#92;} ^{c_{L,t}t(n)&#92;log ^{c}t(n)}:f(y)=1. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   First we compute <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />, using the assumption. We now apply Theorem <a href="#x1-61001r3">5.3<!--tex4ht:ref: thm:redux-RAM-2-3cnf-quasilinear --></a>, but on a new input length <img src="https://s0.wp.com/latex.php?latex=n%27%3A%3Dc%28n%2Bt%29%5Cle+ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%27%3A%3Dc%28n%2Bt%29%5Cle+ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%27%3A%3Dc%28n%2Bt%29%5Cle+ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#039;:=c(n+t)&#92;le ct" class="latex" />, to accommodate for inputs of the form <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" />. This produces a formula <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> of size <img src="https://s0.wp.com/latex.php?latex=c_%7BL%2Ct%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BL%2Ct%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BL%2Ct%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{L,t}t(&#92;log t)^{c}" class="latex" /> in variables <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" /> and new variables <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" />. We can now set <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> and conclude the proof. <b>QED</b></p>
</div>
<p style="text-align:justify">   With these sharper results we can now study hardness and completenss within time bounds such as <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=n%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;log ^{3}n" class="latex" /> etc. We work out an example in the next section.</p>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.3.1   </span> <a id="x1-630005.3.1"></a>Quasilinear-time completeness</h4>
<p style="text-align:justify">In this section we use the machinery we just developed to study completeness in quasi-linear time, instead of power time.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63001r4"></a> <b>Definition</b> 5.4.  </span>We define the quasi-linear time complexity classes</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BQLin-Time%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BTime%7D%28n%5Clog+%5E%7Bd%7Dn%29%5Ctext+%7B+and%7D%5C%5C+%5Ctext+%7BQLin-NTime%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BNTime%7D%28n%5Clog+%5E%7Bd%7Dn%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BQLin-Time%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BTime%7D%28n%5Clog+%5E%7Bd%7Dn%29%5Ctext+%7B+and%7D%5C%5C+%5Ctext+%7BQLin-NTime%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BNTime%7D%28n%5Clog+%5E%7Bd%7Dn%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BQLin-Time%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BTime%7D%28n%5Clog+%5E%7Bd%7Dn%29%5Ctext+%7B+and%7D%5C%5C+%5Ctext+%7BQLin-NTime%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BNTime%7D%28n%5Clog+%5E%7Bd%7Dn%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {QLin-Time}:= &amp; &#92;bigcup _{d&#92;in &#92;mathbb {N}}&#92;text {Time}(n&#92;log ^{d}n)&#92;text { and}&#92;&#92; &#92;text {QLin-NTime}:= &amp; &#92;bigcup _{d&#92;in &#92;mathbb {N}}&#92;text {NTime}(n&#92;log ^{d}n). &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63002r5"></a> <b>Theorem</b> 5.5.  </span>3Sat is complete for QLin-NTime with respect to mapping reductions in QLin-Time. That is:</p>
<p style="text-align:justify">   &#8211; 3Sat is in QLin-NTime, and</p>
<p style="text-align:justify">   &#8211; every problem in QLin-NTime map reduces to 3Sat in QLin-Time.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>To show that 3Sat is in QLin-NTime, consider a 3CNF instance <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />. This instance has at most <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> variables, and we can guess an assignment <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> to them within our budget of non-deterministic guesses. There remains to verify that <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> satisfies <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />. For this, we can do one pass over the clauses. For each clause, we access the bits in <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> corresponding to the 3 variables in the clause, and check if the clause is satisfied. This takes constant time per clause, and so time <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> overall.</p>
<p style="text-align:justify">   The second part follows from Theorem <a href="#x1-62006r4">5.4<!--tex4ht:ref: thm:redux-NTime-3Sat --></a>, using the fact that the composition of two quasilinear functions is also quasilinear (similarly to the fact that the composition of two power functions is also a power). <b>QED</b></p>
</div>
<p style="text-align:justify">   Note that the proof that 3Sat is in QLin-NTime relies on our computational model being a RAM, because we use direct access to fetch the values for the variables in a clause.</p>
<p style="text-align:justify">   We can now give the following quasi-linear version of Fact <a href="#x1-60002r3">5.3<!--tex4ht:ref: fact:np-complete-in-P-iff-p=00003Dnp --></a>. The only extra observation for the proof is again that the composition of two quasi-linear functions is quasi-linear.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63003r2"></a> <b>Corollary</b> 5.2.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BQLin-NTime%7D%5CLeftrightarrow+%5Ctext+%7BQLin-NTime%7D%3D%5Ctext+%7BQLin-Time.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BQLin-NTime%7D%5CLeftrightarrow+%5Ctext+%7BQLin-NTime%7D%3D%5Ctext+%7BQLin-Time.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BQLin-NTime%7D%5CLeftrightarrow+%5Ctext+%7BQLin-NTime%7D%3D%5Ctext+%7BQLin-Time.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {QLin-NTime}&#92;Leftrightarrow &#92;text {QLin-NTime}=&#92;text {QLin-Time.}" class="latex" /></p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63004r4"></a> <b>Exercise</b> 5.4.  </span>Prove that Theorem <a href="#x1-63002r5">5.5<!--tex4ht:ref: thm:3Sat-is-complete-quasilinear --></a> holds with 3Color instead of 3Sat. What about Clique and Subset-sum?</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63005r5"></a>                                                                                                                                                                                     <b>Exercise</b> 5.5.  </span>Prove that 3Sum reduces to 3Sat in Subquadratic time. That is: <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {SubquadraticTime&#92;ensuremath {&#92;Rightarrow &#92;text {3Sum}&#92;in &#92;text {SubquadraticTime}} (i.e., }" class="latex" />Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a> is false).</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.4   </span> <a id="x1-640005.4"></a>Completeness in other classes</h3>
<p style="text-align:justify">The completeness phenomenon is not special to NP but enjoyed by many other classes. In this section we begin to explore completeness for NExp and Exp. One needs to be careful how hardness (and hence completeness) is defined, since these classes are known to be different from <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> by the hierarchy Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>. So defining a problem <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> to be NExp-hard if <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BNExp%7D%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BNExp%7D%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BNExp%7D%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {P}&#92;Rightarrow &#92;text {NExp}=&#92;text {P}" class="latex" /> would mean simply that <img src="https://s0.wp.com/latex.php?latex=L%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;not &#92;in &#92;text {P}" class="latex" />. To avoid this in this section hardness (hence completeness) is defined w.r.t.&nbsp;mapping reductions, cf.&nbsp;Chapter <a href="#x1-450004">4<!--tex4ht:ref: chap:Reductions --></a>. (Another option would be to replace <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> with say <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}" class="latex" />, since it is not known if <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D%3D%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D%3D%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D%3D%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}=&#92;text {NExp}" class="latex" />.)</p>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.4.1   </span> <a id="x1-650005.4.1"></a>NExp completeness</h4>
<p style="text-align:justify">Complete problems for NExp include <em>succinct</em> versions of problems complete for NExp. Here succinct means that rather than giving the input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to the problem in standard format, the input consists instead of a circuit <img src="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bm%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bm%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bm%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C:&#92;{0,1&#92;} ^{m}&#92;to &#92;{0,1&#92;} " class="latex" /> encoding <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, for example <img src="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(i)" class="latex" /> equals bit <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, for every <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-65001r5"></a> <b>Definition</b> 5.5.  </span>The Succinct-3Sat problem: Given a circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> encoding a 3CNF <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" />, does <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" /> have a satisfying assignment?</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-65002r6"></a> <b>Theorem</b> 5.6.  </span>Succinct-3Sat  is  NExp  complete  with  respect  to  power-time  mapping reductions.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof sketch.</b>.&nbsp;</span> Let us first show that Succinct-3Sat is in NExp. Given a circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, we can run it on every possible input (of length <img src="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n" class="latex" />) and write down the formula <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" /> encoded by <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. This formula has size <img src="https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 2^{n}" class="latex" />. We can then use the fact that 3Sat is in NP to decide satisfiability of this formula in non-deterministic power time in <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{n}" class="latex" />, that is <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%282%5E%7Bcn%7D%29%5Csubseteq+%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%282%5E%7Bcn%7D%29%5Csubseteq+%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%282%5E%7Bcn%7D%29%5Csubseteq+%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NTime}(2^{cn})&#92;subseteq &#92;text {NExp}" class="latex" />.</p>
<p style="text-align:justify">   To prove NExp hardness it is convenient to work with TMs rather than RAMs. The main observation is that in the simulation of a TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on an input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> by a circuit <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" />, Theorem <a href="#x1-25006r4">2.4<!--tex4ht:ref: thm:simu-tm-by-ckts-simple --></a>, the circuit is very regular, in the sense that we can construct another circuit <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> which is a succinct encoding of <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" />. The circuit <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> is given as input indexes to gates in <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> and outputs the type of the gate and its wires. The size of <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> is power in the index length and <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />. Thus, if <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> has size <img src="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t^{c}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> only needs size <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log ^{c}t" class="latex" />. If <img src="https://s0.wp.com/latex.php?latex=t%3D2%5E%7Bn%5E%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%3D2%5E%7Bn%5E%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%3D2%5E%7Bn%5E%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t=2^{n^{d}}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> has size power in <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, as desired. The transformation from circuit to 3CNF in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> is also regular and can be done succinctly. <b>QED</b></p>
</div>
<p style="text-align:justify">   As a consequence, we obtain the following âconcreteâ problem not in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-65003r3"></a> <b>Corollary</b> 5.3.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSuccinct-3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSuccinct-3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BSuccinct-3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Succinct-3Sat}&#92;not &#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.4.2   </span> <a id="x1-660005.4.2"></a>Exp-completeness</h4>
<p style="text-align:justify">Exp-complete problems include several two-player games. The important feature for completeness is that the game may last for an exponential number of steps (otherwise it would belong to a class believed to be stricter which we will investigate in Chapter ??). These games include (generalized versions of) Chess <span class="cite">[<a href="journals/jct/FraenkelL81">8</a>]</span> and Checkers <span class="cite">[<a href="journals/siamcomp/Robson84">26</a>]</span>.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.5   </span> <a id="x1-670005.5"></a>Power from completeness</h3>
<p style="text-align:justify">The realization that arbitrary computation can be reduced to 3Sat and other problems is powerful and liberating. In particular it allows us to significantly widen the net of reductions.</p>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.5.1   </span> <a id="x1-680005.5.1"></a>Optimization problems</h4>
<p style="text-align:justify">As observed in section&nbsp;Âº<a href="#x1-540004.6">4.6<!--tex4ht:ref: sec:Gap-SAT:-The-PCP --></a>, 3Sat trivially reduces to Max-3Sat. The converse will be shown next.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-68001r7"></a> <b>Theorem</b> 5.7.  </span>Max-3Sat reduces to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Consider the problem Atleast-3Sat: Given a 3CNF formula and an integer <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />, is there an assignment that satisfies at least <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> clauses? This is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> and so can be reduced to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. This is the step thatâs not easy without âthinking completeness:â given an algorithm for 3Sat it isnât clear how to use it directly to solve Atleast-3Sat.</p>
<p style="text-align:justify">   Hence, if 3Sat is in P so is Atleast-3Sat. On input a 3CNF <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />, using binary search and the fact that Atleast-3Sat is in P, we can find in P the largest <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> s.t.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%28f%2Ct%29%5Cin+%5Ctext+%7BAtleast-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28f%2Ct%29%5Cin+%5Ctext+%7BAtleast-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28f%2Ct%29%5Cin+%5Ctext+%7BAtleast-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(f,t)&#92;in &#92;text {Atleast-3Sat}" class="latex" />. Having found this <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />, there remains to construct an assignment satisfying the clauses. This can be done fixing one variable at the time as in Theorem <a href="#x1-52002r5">4.5<!--tex4ht:ref: thm:Search-3Sat-power-time-reduces --></a>. <b>QED</b></p>
</div>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.5.2   </span> <a id="x1-690005.5.2"></a>NP is as easy as detecting unique solutions</h4>
<p style="text-align:justify">A satisfiable 3CNF can have multiple satisfying assignments. On the other hand some problems and puzzles have unique solutions. In this section we relate these two scenarios.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69001r6"></a>                                                                                                                                                                                     <b>Definition</b> 5.6.  </span>Unique-CktSat is the problem: Given a circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> s.t.&nbsp;there is at most one input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> for which <img src="https://s0.wp.com/latex.php?latex=C%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(x)=1" class="latex" />, decide if such an input exists.</p>
<p style="text-align:justify">   Unique-3Sat is the Unique-CktSat problem restricted to 3CNF circuits.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69002r8"></a> <b>Theorem</b> 5.8.  </span> <span class="cite">[<a href="journals/tcs/ValiantV86">33</a>]</span> 3Sat reduces to Unique-3Sat in BPP.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We in fact reduce 3Sat to Unique-CktSat. Then Unique-CktSat can be reduced to Unique-3Sat observing that the reduction in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> preserves uniqueness.</p>
<p style="text-align:justify">   The beautiful proof uses a powerful and general technique in randomized computation: <em>pairwise uniformity</em>, sometimes more generically referred to as <em>hashing. </em>We first define such functions and give efficient constructions. Then we show how to use them to âisolateâ assignments.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69003r7"></a> <b>Definition</b> 5.7.  </span>A distribution <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> on functions mapping <img src="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S&#92;to T" class="latex" /> is called <em>pairwise uniform</em> if for every <img src="https://s0.wp.com/latex.php?latex=x%2Cx%27%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%2Cx%27%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%2Cx%27%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x,x&#039;&#92;in S" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y%2Cy%27%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%2Cy%27%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%2Cy%27%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y,y&#039;&#92;in T" class="latex" /> one has</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BH%7D%5BH%28x%29%3Dy%5Cwedge+H%28x%27%29%3Dy%27%5D%3D1%2F%7CT%7C%5E%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BH%7D%5BH%28x%29%3Dy%5Cwedge+H%28x%27%29%3Dy%27%5D%3D1%2F%7CT%7C%5E%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BH%7D%5BH%28x%29%3Dy%5Cwedge+H%28x%27%29%3Dy%27%5D%3D1%2F%7CT%7C%5E%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{H}[H(x)=y&#92;wedge H(x&#039;)=y&#039;]=1/|T|^{2}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   This is saying that on every pair of inputs <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> is behaving as a completely uniform function. Yet unlike completely uniform functions, the next lemma shows that pairwise uniform functions can have a short description, which makes them suitable for use in algorithms.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69004r6"></a> <b>Exercise</b> 5.6.  </span>Let <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{q}" class="latex" /> be a finite field. Define the random function <img src="https://s0.wp.com/latex.php?latex=H%3A%5Cmathbb+%7BF%7D_%7Bq%7D%5Cto+%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%3A%5Cmathbb+%7BF%7D_%7Bq%7D%5Cto+%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%3A%5Cmathbb+%7BF%7D_%7Bq%7D%5Cto+%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H:&#92;mathbb {F}_{q}&#92;to &#92;mathbb {F}_{q}" class="latex" /> as <img src="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3DAx%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3DAx%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28x%29%3A%3DAx%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(x):=Ax+B" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A,B" class="latex" /> are uniform in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{q}" class="latex" />.</p>
<p style="text-align:justify">   Prove that <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> is pairwise uniform.</p>
<p style="text-align:justify">   Explain how to use <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> to obtain a pairwise uniform function from <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{t}" class="latex" /> for any given <img src="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;le n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69005r7"></a> <b>Exercise</b> 5.7.  </span>Define the random function <img src="https://s0.wp.com/latex.php?latex=H_%7B1%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H_%7B1%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H_%7B1%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H_{1}:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> as <img src="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3D%5Csum+_%7Bi%5Cle+n%7DA_%7Bi%7Dx_%7Bi%7D%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3D%5Csum+_%7Bi%5Cle+n%7DA_%7Bi%7Dx_%7Bi%7D%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28x%29%3A%3D%5Csum+_%7Bi%5Cle+n%7DA_%7Bi%7Dx_%7Bi%7D%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(x):=&#92;sum _{i&#92;le n}A_{i}x_{i}+B" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> is uniform in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> is uniform in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} " class="latex" />.</p>
<p style="text-align:justify">   Prove that <img src="https://s0.wp.com/latex.php?latex=H_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H_{1}" class="latex" /> is pairwise uniform.</p>
<p style="text-align:justify">   Explain how to use <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> to obtain a pairwise uniform function from <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{t}" class="latex" /> for any given <img src="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;le n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We can now state the lemma that we use to isolate assignments.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69006r2"></a> <b>Lemma</b> 5.2.  </span>Let <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> be a pairwise uniform function mapping <img src="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S&#92;to T" class="latex" />, and let <img src="https://s0.wp.com/latex.php?latex=1%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1&#92;in T" class="latex" />. The probability that there is a unique element <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=H%28s%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28s%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28s%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(s)=1" class="latex" /> is</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B%7CS%7C%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C%5E%7B2%7D%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B%7CS%7C%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C%5E%7B2%7D%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B%7CS%7C%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C%5E%7B2%7D%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;ge &#92;frac {|S|}{|T|}-&#92;frac {|S|^{2}}{|T|^{2}}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   In particular, if <img src="https://s0.wp.com/latex.php?latex=%7CT%7C%2F8%5Cle+%7CS%7C%5Cle+%7CT%7C%2F4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CT%7C%2F8%5Cle+%7CS%7C%5Cle+%7CT%7C%2F4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CT%7C%2F8%5Cle+%7CS%7C%5Cle+%7CT%7C%2F4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|T|/8&#92;le |S|&#92;le |T|/4" class="latex" /> this prob.&nbsp;is <img src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cfrac+%7B1%7D%7B8%7D-%5Cfrac+%7B1%7D%7B16%7D%5Cge+1%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+%5Cfrac+%7B1%7D%7B8%7D-%5Cfrac+%7B1%7D%7B16%7D%5Cge+1%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+%5Cfrac+%7B1%7D%7B8%7D-%5Cfrac+%7B1%7D%7B16%7D%5Cge+1%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge &#92;frac {1}{8}-&#92;frac {1}{16}&#92;ge 1/8" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>For fixed <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" />, the probability <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> is the unique element mapped to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> is at least the prob.&nbsp;that <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> is mapped to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> minus the prob.&nbsp;that both <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> and some other <img src="https://s0.wp.com/latex.php?latex=s%27%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%27%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%27%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#039;&#92;ne s" class="latex" /> are mapped to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />. This is</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B1%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C-1%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B1%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C-1%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B1%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C-1%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;ge &#92;frac {1}{|T|}-&#92;frac {|S|-1}{|T|^{2}}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   These events for different <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" /> are disjoint; so the target probability is at least the sum of the above over <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" />. <b>QED</b></p>
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-69002r8">5.8<!--tex4ht:ref: thm:3Sat-reduces-to-unique --></a></b>.&nbsp;</span> Given a 3Sat instance <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n" class="latex" /> variables <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, we pick a random <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> from <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=n%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n+c" class="latex" />. We then pick a pairwise uniform function mapping <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{i}" class="latex" />, and consider the circuit</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%3A%3D%5Cphi+%28x%29%5Cwedge+H%28x%29%3D0%5E%7Bi%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%3A%3D%5Cphi+%28x%29%5Cwedge+H%28x%29%3D0%5E%7Bi%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%3A%3D%5Cphi+%28x%29%5Cwedge+H%28x%29%3D0%5E%7Bi%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} C:=&#92;phi (x)&#92;wedge H(x)=0^{i}. &#92;end{aligned}" class="latex" /></div>
<p>This circuit has size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{c}" class="latex" />.</p>
<p style="text-align:justify">   If <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> is not satisfiable, <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> is not satisfiable, for any random choices.</p>
<p style="text-align:justify">   Now suppose that <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> has <img src="https://s0.wp.com/latex.php?latex=s%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;ge 1" class="latex" /> satisfying assignment. With prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 1/n" class="latex" /> we will have <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bi-3%7D%5Cle+s%5Cle+2%5E%7Bi-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bi-3%7D%5Cle+s%5Cle+2%5E%7Bi-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bi-3%7D%5Cle+s%5Cle+2%5E%7Bi-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{i-3}&#92;le s&#92;le 2^{i-2}" class="latex" />, in which case Lemma <a href="#x1-69006r2">5.2<!--tex4ht:ref: lem:pairwise-uniform-unique --></a> guarantees that <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> has a unique satisfying assignment with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c" class="latex" />.</p>
<p style="text-align:justify">   Overall, <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> has a unique satisfying assignment with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c/n" class="latex" />. Hence the Unique-3Sat algorithm on <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> outputs <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c/n" class="latex" />. If we repeat this process <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> times, with independent random choices, the Or of the outcomes gives the correct answer with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 2/3" class="latex" />. <b>QED</b></p>
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.6   </span> <a id="x1-700005.6"></a>Problems</h3>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-70001r1"></a> <b>Problem</b> 5.1.  </span>In Theorem <a href="#x1-52002r5">4.5<!--tex4ht:ref: thm:Search-3Sat-power-time-reduces --></a> we reduced Search-3Sat to 3Sat.</p>
<p style="text-align:justify">   &#8211; Suppose 3Sat is computable by circuits of depth <img src="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log n" class="latex" />. What would be the depth of the circuits for Search-3Sat given by the reduction?</p>
<p style="text-align:justify">   &#8211; Reduce Search-3Sat to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B%5Censuremath+%7B%5Cbigcup+_%7Ba%3E0%7D%7D%7D%5Ctext+%7BDepth%7D%28a%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B%5Censuremath+%7B%5Cbigcup+_%7Ba%3E0%7D%7D%7D%5Ctext+%7BDepth%7D%28a%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B%5Censuremath+%7B%5Cbigcup+_%7Ba%3E0%7D%7D%7D%5Ctext+%7BDepth%7D%28a%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {&#92;ensuremath {&#92;bigcup _{a&gt;0}}}&#92;text {Depth}(a&#92;log n)" class="latex" />.</p>
<p style="text-align:justify">   Hint: First work with randomized circuits. Use ideas in proof of Theorem <a href="#x1-52002r5">4.5<!--tex4ht:ref: thm:Search-3Sat-power-time-reduces --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="likesectionHead"><a id="x1-710005.6"></a>References</h3>
<p style="text-align:justify">
<div class="thebibliography">
<p class="bibitem"><span class="biblabel">   [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness      results for LCS and other sequence similarity measures.  In Venkatesan Guruswami,      editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS      2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59â78. IEEE Computer Society,      2015.</p>
<p class="bibitem"><span class="biblabel">   [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard  Adleman.   Two  theorems  on  random  polynomial  time.   In  19th IEEE      Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75â83. 1978.</p>
<p class="bibitem"><span class="biblabel">   [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian      circuits and matchings. J. Comput. Syst. Sci., 18(2):155â193, 1979.</p>
<p class="bibitem"><span class="biblabel">   [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.      Proof  verification  and  the  hardness  of  approximation  problems.    J.&nbsp;of  the  ACM,      45(3):501â555, May 1998.</p>
<p class="bibitem"><span class="biblabel">   [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk.  Edit distance cannot be computed in strongly      subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087â1097, 2018.</p>
<p class="bibitem"><span class="biblabel">   [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBatcher68"></a>Kenneth&nbsp;E. Batcher.  Sorting networks and their applications.  In AFIPS Spring      Joint Computing Conference, volume&nbsp;32, pages 307â314, 1968.</p>
<p class="bibitem"><span class="biblabel">   [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCook73"></a>Stephen&nbsp;A. Cook. A hierarchy for nondeterministic time complexity. J.&nbsp;of Computer      and System Sciences, 7(4):343â353, 1973.</p>
<p class="bibitem"><span class="biblabel">   [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jct/FraenkelL81"></a>Aviezri&nbsp;S. Fraenkel and David Lichtenstein. Computing a perfect strategy for n x n      chess requires time exponential in n. J. Comb. Theory, Ser. A, 31(2):199â214, 1981.</p>
<p class="bibitem"><span class="biblabel">   [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational      geometry. Comput. Geom., 5:165â185, 1995.</p>
<p class="bibitem"><span class="biblabel">  [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the      Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel">  [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;GÃ·del.   âber  formal  unentscheidbare  sÎ£tze  der  Principia  Mathematica  und      verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel">  [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge      University Press, 2008.</p>
<p class="bibitem"><span class="biblabel">  [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of      Mathematics, 193(2):563 â 617, 2021.</p>
<p class="bibitem"><span class="biblabel">  [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie.  One-tape, off-line turing machine computations.  Information and      Control, 8(6):553â578, 1965.</p>
<p class="bibitem"><span class="biblabel">  [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred  Hennie  and  Richard  Stearns.    Two-tape  simulation  of  multitape  turing      machines. J.&nbsp;of the ACM, 13:533â546, October 1966.</p>
<p class="bibitem"><span class="biblabel">  [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi.   The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 237â, 1999.</p>
<p class="bibitem"><span class="biblabel">  [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.  Which problems have      strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512â530, Dec      2001.</p>
<p class="bibitem"><span class="biblabel">  [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell  Impagliazzo  and  Avi  Wigderson.    <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" />  if  <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" />  requires  exponential  circuits:      Derandomizing the XOR lemma.  In 29th ACM Symp.&nbsp;on the Theory of Computing      (STOC), pages 220â229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel">  [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi.  On the structure of one-tape nondeterministic turing machine      time hierarchy. Theor. Comput. Sci., 40:175â193, 1985.</p>
<p class="bibitem"><span class="biblabel">  [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A.  Levin.    Universal  sequential  search  problems.    Problemy  Peredachi      Informatsii, 9(3):115â116, 1973.</p>
<p class="bibitem"><span class="biblabel">  [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120â140, 1958.</p>
<p class="bibitem"><span class="biblabel">  [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaNEU-ram2sat-neu-author"></a>NEU. From RAM to SAT. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2012.</p>
<p class="bibitem"><span class="biblabel">  [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation,                                                                                                                                                                                          and complexity classes. J. Comput. Syst. Sci., 43(3):425â440, 1991.</p>
<p class="bibitem"><span class="biblabel">  [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPPST83"></a>Wolfgang&nbsp;J. Paul, Nicholas Pippenger, Endre SzemerÎdi, and William&nbsp;T. Trotter.      On determinism versus non-determinism and related problems (preliminary version). In      IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 429â438, 1983.</p>
<p class="bibitem"><span class="biblabel">  [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures.      J.&nbsp;of the ACM, 26(2):361â381, 1979.</p>
<p class="bibitem"><span class="biblabel">  [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Robson84"></a>J.&nbsp;M.  Robson.    N  by  N  checkers  is  exptime  complete.    SIAM  J.  Comput.,      13(2):252â267, 1984.</p>
<p class="bibitem"><span class="biblabel">  [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/coco/Santhanam01"></a>Rahul Santhanam.   On separators, segregators and time versus space.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 286â294, 2001.</p>
<p class="bibitem"><span class="biblabel">  [28]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold SchÃ·nhage. Storage modification machines. SIAM J. Comput., 9(3):490â508,      1980.</p>
<p class="bibitem"><span class="biblabel">  [29]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System      Tech. J., 28:59â98, 1949.</p>
<p class="bibitem"><span class="biblabel">  [30]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields.      Mathematics of Computation, 54(189):435â447, 1990.</p>
<p class="bibitem"><span class="biblabel">  [31]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer.  Cosmological lower bound on the circuit      complexity of a small problem in logic. J. ACM, 49(6):753â784, 2002.</p>
<p class="bibitem"><span class="biblabel">  [32]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M.   Turing.      On   computable   numbers,   with   an   application   to   the      entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230â265, 1937.</p>
<p class="bibitem"><span class="biblabel">  [33]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/ValiantV86"></a>Leslie&nbsp;G. Valiant and Vijay&nbsp;V. Vazirani. NP is as easy as detecting unique solutions.      Theor. Comput. Sci., 47(3):85â93, 1986.</p>
<p class="bibitem"><span class="biblabel">  [34]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola.  Reducing 3XOR to listing triangles, an exposition.  Available at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel">  [35]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele  Viola.   Pseudorandom  bits  and  lower  bounds  for  randomized  turing      machines. Theory of Computing, 18(10):1â12, 2022.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T19:33:28Z">Thursday, February 23 2023, 19:33</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/the-virtual-grad-student.html'>The Virtual Grad Student</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Martin Haug, who is working on a LaTeX alternative Typst, asked me if I had updates on a LaTeX rant from 2011. I haven't seen any new serious backward compatibility problems. We have easier collaboration through on-line editors like Overleaf. We have got closer to WSYWIG thanks to quick compiling but still not at the level of Word or Google Docs. The big problem of user friendliness remains. There's a reason LaTeX has its own Stack Exchange.&nbsp;</p><p>But we live in a new machine learning world. Can we use generative AI to make LaTeX easier to use?</p><p>Mandatory Disclaimer: Generative AI can sometimes create inaccurate, inappropriate or previously-published material. You are ultimately responsible for the contents of your paper no matter how you produced it.</p><p>Since I sometimes think of LaTeX as a programming language for papers, I tweeted</p>
<blockquote><p>Can we have GitHub co-pilot for LaTeX?</p>â Lance Fortnow (@fortnow) February 17, 2023</blockquote><p>Thanks for the responses. The answer to the question is yes, GitHub Copilot&nbsp;works for LaTeX if you edit LaTeX in a programming environment like VS Code, Neovim or Jet Brains. It helps with formatting of formulas and pictures, less so on the text itself. I made a video so you can see how it works.</p>
<p>Latext AI offers a chrome extension that will let you generate text via GPT in Overleaf based on a prompt or previous text, though Latext requires a subscription after a one-week trial. You can also just cut and paste between any text editor and ChatGPT.</p><p>ChatGPT notoriously makes up references if you ask for them. Can we have a good system that finds relevant articles to cite and adds them automatically into your bibliography?</p><p>Ideally all these should work together seamlessly, suggestions that happen as you type. A true co-pilot for research papers.</p><p>There are many more tools out there, feel free to add them to the comments. I expect the integration to improve over time as we develop new APIs and models.</p><p>I look forward to the days of a virtual grad student: Here's a research goal and an idea to get there. Now go figure out the details and write the paper.&nbsp;</p><p>It will be a long wait.</p> <p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Martin Haug, who is working on a LaTeX alternative <a href="https://typst.app/">Typst</a>, asked me if I had updates on a <a href="https://blog.computationalcomplexity.org/2011/07/problems-of-latex.html">LaTeX rant</a> from 2011. I haven't seen any new serious backward compatibility problems. We have easier collaboration through on-line editors like <a href="https://blog.computationalcomplexity.org/2011/07/problems-of-latex.html">Overleaf</a>. We have got closer to WSYWIG thanks to quick compiling but still not at the level of Word or Google Docs. The big problem of user friendliness remains. There's a reason LaTeX has its own <a href="https://tex.stackexchange.com/">Stack Exchange</a>.&nbsp;</p><p>But we live in a new machine learning world. Can we use generative AI to make LaTeX easier to use?</p><p><b>Mandatory Disclaimer</b>: Generative AI can sometimes create inaccurate, inappropriate or previously-published material. You are ultimately responsible for the contents of your paper no matter how you produced it.</p><p>Since I sometimes think of LaTeX as a programming language for papers, I <a href="https://twitter.com/fortnow/status/1626576896132542464">tweeted</a></p>
<blockquote class="twitter-tweet"><p dir="ltr" lang="en">Can we have GitHub co-pilot for LaTeX?</p>â Lance Fortnow (@fortnow) <a href="https://twitter.com/fortnow/status/1626576896132542464?ref_src=twsrc%5Etfw">February 17, 2023</a></blockquote><p>Thanks for the responses. The answer to the question is yes, <a href="https://github.com/features/copilot">GitHub Copilot</a>&nbsp;works for LaTeX if you edit LaTeX in a programming environment like <a href="https://code.visualstudio.com/">VS Code</a>, <a href="https://code.visualstudio.com/">Neovim</a> or <a href="https://code.visualstudio.com/">Jet Brains</a>. It helps with formatting of formulas and pictures, less so on the text itself. I made a <a href="https://www.youtube.com/watch?v=bt0BNdujIy8">video</a> so you can see how it works.</p>
<div style="text-align: center;"><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/bt0BNdujIy8" title="YouTube video player" width="560"></iframe></div><p><a href="https://www.latextai.com/">Latext AI</a> offers a chrome extension that will let you generate text via GPT in Overleaf based on a prompt or previous text, though Latext requires a subscription after a one-week trial. You can also just cut and paste between any text editor and ChatGPT.</p><p>ChatGPT notoriously makes up references if you ask for them. Can we have a good system that finds relevant articles to cite and adds them automatically into your bibliography?</p><p>Ideally all these should work together seamlessly, suggestions that happen as you type. A true co-pilot for research papers.</p><p>There are many more tools out there, feel free to add them to the comments. I expect the integration to improve over time as we develop new APIs and models.</p><p>I look forward to the days of a virtual grad student: Here's a research goal and an idea to get there. Now go figure out the details and write the paper.&nbsp;</p><p>It will be a long wait.</p> <script async="" charset="utf-8" src="https://platform.twitter.com/widgets.js"></script><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T15:02:00Z">Thursday, February 23 2023, 15:02</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.10972'>Complexity of Maker-Breaker Games on Edge Sets of Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eric Duch&#xea;ne, Valentin Gledel, Fionn Mc Inerney, Nicolas Nisse, Nacim Oijid, Aline Parreau, Milo&#x161; Stojakovi&#x107;</p><p>We initiate the study of the algorithmic complexity of Maker-Breaker games
played on edge sets of graphs for general graphs. We mainly consider three of
the big four such games: the connectivity game, perfect matching game, and
$H$-game. Maker wins if she claims the edges of a spanning tree in the first, a
perfect matching in the second, and a copy of a fixed graph $H$ in the third.
We prove that deciding who wins the perfect matching game and the $H$-game is
PSPACE-complete, even for the latter in graphs of small diameter if $H$ is a
tree. Seeking to find the smallest graph $H$ such that the $H$-game is
PSPACE-complete, we also prove that there exists such an $H$ of order 51 and
size 57.
</p>
<p>On the positive side, we show that the connectivity game and arboricity-$k$
game are polynomial-time solvable. We then give several positive results for
the $H$-game, first giving a structural characterization for Breaker to win the
$P_4$-game, which gives a linear-time algorithm for the $P_4$-game. We provide
a structural characterization for Maker to win the $K_{1,\ell}$-game in trees,
which implies a linear-time algorithm for the $K_{1,\ell}$-game in trees.
Lastly, we prove that the $K_{1,\ell}$-game in any graph, and the $H$-game in
trees are both FPT parameterized by the length of the game. We leave the
complexity of the last of the big four games, the Hamiltonicity game, as an
open question.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Duchene_E/0/1/0/all/0/1">Eric Duch&#xea;ne</a>, <a href="http://arxiv.org/find/cs/1/au:+Gledel_V/0/1/0/all/0/1">Valentin Gledel</a>, <a href="http://arxiv.org/find/cs/1/au:+Inerney_F/0/1/0/all/0/1">Fionn Mc Inerney</a>, <a href="http://arxiv.org/find/cs/1/au:+Nisse_N/0/1/0/all/0/1">Nicolas Nisse</a>, <a href="http://arxiv.org/find/cs/1/au:+Oijid_N/0/1/0/all/0/1">Nacim Oijid</a>, <a href="http://arxiv.org/find/cs/1/au:+Parreau_A/0/1/0/all/0/1">Aline Parreau</a>, <a href="http://arxiv.org/find/cs/1/au:+Stojakovic_M/0/1/0/all/0/1">Milo&#x161; Stojakovi&#x107;</a></p><p>We initiate the study of the algorithmic complexity of Maker-Breaker games
played on edge sets of graphs for general graphs. We mainly consider three of
the big four such games: the connectivity game, perfect matching game, and
$H$-game. Maker wins if she claims the edges of a spanning tree in the first, a
perfect matching in the second, and a copy of a fixed graph $H$ in the third.
We prove that deciding who wins the perfect matching game and the $H$-game is
PSPACE-complete, even for the latter in graphs of small diameter if $H$ is a
tree. Seeking to find the smallest graph $H$ such that the $H$-game is
PSPACE-complete, we also prove that there exists such an $H$ of order 51 and
size 57.
</p>
<p>On the positive side, we show that the connectivity game and arboricity-$k$
game are polynomial-time solvable. We then give several positive results for
the $H$-game, first giving a structural characterization for Breaker to win the
$P_4$-game, which gives a linear-time algorithm for the $P_4$-game. We provide
a structural characterization for Maker to win the $K_{1,\ell}$-game in trees,
which implies a linear-time algorithm for the $K_{1,\ell}$-game in trees.
Lastly, we prove that the $K_{1,\ell}$-game in any graph, and the $H$-game in
trees are both FPT parameterized by the length of the game. We leave the
complexity of the last of the big four games, the Hamiltonicity game, as an
open question.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11290'>Logical Equivalences, Homomorphism Indistinguishability, and Forbidden Minors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tim Seppelt</p><p>Two graphs $G$ and $H$ are homomorphism indistinguishable over a class of
graphs $\mathcal{F}$ if for all graphs $F \in \mathcal{F}$ the number of
homomorphisms from $F$ to $G$ equals the number of homomorphisms from $F$ to
$H$. Many natural equivalence relations comparing graphs such as (quantum)
isomorphism, spectral, and logical equivalences can be characterised as
homomorphism indistinguishability relations over certain graph classes.
</p>
<p>In this article, the interplay of the properties of a graph class and its
homomorphism indistinguishability relation are studied. As an application,
self-complementarity, a property of logics on graphs satisfied by many
well-studied logics, is identified. It is proven that the equivalence over a
self-complementary logic admitting a characterisation as homomorphism
indistinguishability relation can be characterised by homomorphism
indistinguishability over a minor-closed graph class. Thereby, first evidences
are provided for a possible connection between minors and homomorphism
indistinguishability as conjectured by Roberson (2022).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Seppelt_T/0/1/0/all/0/1">Tim Seppelt</a></p><p>Two graphs $G$ and $H$ are homomorphism indistinguishable over a class of
graphs $\mathcal{F}$ if for all graphs $F \in \mathcal{F}$ the number of
homomorphisms from $F$ to $G$ equals the number of homomorphisms from $F$ to
$H$. Many natural equivalence relations comparing graphs such as (quantum)
isomorphism, spectral, and logical equivalences can be characterised as
homomorphism indistinguishability relations over certain graph classes.
</p>
<p>In this article, the interplay of the properties of a graph class and its
homomorphism indistinguishability relation are studied. As an application,
self-complementarity, a property of logics on graphs satisfied by many
well-studied logics, is identified. It is proven that the equivalence over a
self-complementary logic admitting a characterisation as homomorphism
indistinguishability relation can be characterised by homomorphism
indistinguishability over a minor-closed graph class. Thereby, first evidences
are provided for a possible connection between minors and homomorphism
indistinguishability as conjectured by Roberson (2022).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11417'>Hitting the Romans</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Henning Fernau, Kevin Mann</p><p>Roman domination is one of few examples where the related extension problem
is polynomial-time solvable even if the original decision problem is
NP-complete. This is interesting, as it allows to establish polynomial-delay
enumeration algorithms for finding minimal Roman dominating functions, while it
is open for more than four decades if all minimal dominating sets of a graph or
if all hitting sets of a hypergraph can be enumerated with polynomial delay. To
find the reason why this is the case, we combine the idea of hitting set with
the idea of Roman domination. We hence obtain and study two new problems,
called Roman Hitting Function and Roman Hitting Set, both generalizing Roman
Domination. This allows us to delineate the borderline of polynomial-delay
enumerability. Here, we assume what we call the Hitting Set Transversal Thesis,
claiming that it is impossible to enumerate all minimal hitting sets of a
hypergraph with polynomial delay. Our first focus is on the extension versions
of these problems. While doing this, we find some conditions under which the
Extension Roman Hitting Function problem is NP-complete. We then use
parameterized complexity to get a better understanding of why Extension Roman
Hitting Function behaves in this way. Furthermore, we analyze the parameterized
and approximation complexity of the underlying optimization problems. We also
discuss consequences for Roman variants of other problems like Vertex Cover.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fernau_H/0/1/0/all/0/1">Henning Fernau</a>, <a href="http://arxiv.org/find/cs/1/au:+Mann_K/0/1/0/all/0/1">Kevin Mann</a></p><p>Roman domination is one of few examples where the related extension problem
is polynomial-time solvable even if the original decision problem is
NP-complete. This is interesting, as it allows to establish polynomial-delay
enumeration algorithms for finding minimal Roman dominating functions, while it
is open for more than four decades if all minimal dominating sets of a graph or
if all hitting sets of a hypergraph can be enumerated with polynomial delay. To
find the reason why this is the case, we combine the idea of hitting set with
the idea of Roman domination. We hence obtain and study two new problems,
called Roman Hitting Function and Roman Hitting Set, both generalizing Roman
Domination. This allows us to delineate the borderline of polynomial-delay
enumerability. Here, we assume what we call the Hitting Set Transversal Thesis,
claiming that it is impossible to enumerate all minimal hitting sets of a
hypergraph with polynomial delay. Our first focus is on the extension versions
of these problems. While doing this, we find some conditions under which the
Extension Roman Hitting Function problem is NP-complete. We then use
parameterized complexity to get a better understanding of why Extension Roman
Hitting Function behaves in this way. Furthermore, we analyze the parameterized
and approximation complexity of the underlying optimization problems. We also
discuss consequences for Roman variants of other problems like Vertex Cover.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11454'>Quantum complexity of the Kronecker coefficients</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sergey Bravyi, Anirban Chowdhury, David Gosset, Vojtech Havlicek, Guanyu Zhu</p><p>Whether or not the Kronecker coefficients of the symmetric group count some
set of combinatorial objects is a longstanding open question. In this work we
show that a given Kronecker coefficient is proportional to the rank of a
projector that can be measured efficiently using a quantum computer. In other
words a Kronecker coefficient counts the dimension of the vector space spanned
by the accepting witnesses of a QMA verifier, where QMA is the quantum analogue
of NP. This implies that approximating the Kronecker coefficients to within a
given relative error is not harder than a certain natural class of quantum
approximate counting problems that captures the complexity of estimating
thermal properties of quantum many-body systems. A second consequence is that
deciding positivity of Kronecker coefficients is contained in QMA,
complementing a recent NP-hardness result of Ikenmeyer, Mulmuley and Walter. We
obtain similar results for the related problem of approximating row sums of the
character table of the symmetric group. Finally, we discuss an efficient
quantum algorithm that approximates normalized Kronecker coefficients to
inverse-polynomial additive error.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Bravyi_S/0/1/0/all/0/1">Sergey Bravyi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chowdhury_A/0/1/0/all/0/1">Anirban Chowdhury</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gosset_D/0/1/0/all/0/1">David Gosset</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Havlicek_V/0/1/0/all/0/1">Vojtech Havlicek</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhu_G/0/1/0/all/0/1">Guanyu Zhu</a></p><p>Whether or not the Kronecker coefficients of the symmetric group count some
set of combinatorial objects is a longstanding open question. In this work we
show that a given Kronecker coefficient is proportional to the rank of a
projector that can be measured efficiently using a quantum computer. In other
words a Kronecker coefficient counts the dimension of the vector space spanned
by the accepting witnesses of a QMA verifier, where QMA is the quantum analogue
of NP. This implies that approximating the Kronecker coefficients to within a
given relative error is not harder than a certain natural class of quantum
approximate counting problems that captures the complexity of estimating
thermal properties of quantum many-body systems. A second consequence is that
deciding positivity of Kronecker coefficients is contained in QMA,
complementing a recent NP-hardness result of Ikenmeyer, Mulmuley and Walter. We
obtain similar results for the related problem of approximating row sums of the
character table of the symmetric group. Finally, we discuss an efficient
quantum algorithm that approximates normalized Kronecker coefficients to
inverse-polynomial additive error.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11476'>Matrix Multiplication and Number On the Forehead Communication</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Josh Alman, Jaros&#x142;aw B&#x142;asiok</p><p>Three-player Number On the Forehead communication may be thought of as a
three-player Number In the Hand promise model, in which each player is given
the inputs that are supposedly on the other two players' heads, and promised
that they are consistent with the inputs of of the other players. The set of
all allowed inputs under this promise may be thought of as an order-3 tensor.
We surprisingly observe that this tensor is exactly the matrix multiplication
tensor, which is widely studied in the design of fast matrix multiplication
algorithms.
</p>
<p>Using this connection, we prove a number of results about both Number On the
Forehead communication and matrix multiplication, each by using known results
or techniques about the other. For example, we show how the Laser method, a key
technique used to design the best matrix multiplication algorithms, can also be
used to design communication protocols for a variety of problems. We also show
how known lower bounds for Number On the Forehead communication can be used to
bound properties of the matrix multiplication tensor such as its zeroing out
subrank. Finally, we substantially generalize known methods based on slice-rank
for studying communication, and show how they directly relate to the matrix
multiplication exponent $\omega$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alman_J/0/1/0/all/0/1">Josh Alman</a>, <a href="http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1">Jaros&#x142;aw B&#x142;asiok</a></p><p>Three-player Number On the Forehead communication may be thought of as a
three-player Number In the Hand promise model, in which each player is given
the inputs that are supposedly on the other two players' heads, and promised
that they are consistent with the inputs of of the other players. The set of
all allowed inputs under this promise may be thought of as an order-3 tensor.
We surprisingly observe that this tensor is exactly the matrix multiplication
tensor, which is widely studied in the design of fast matrix multiplication
algorithms.
</p>
<p>Using this connection, we prove a number of results about both Number On the
Forehead communication and matrix multiplication, each by using known results
or techniques about the other. For example, we show how the Laser method, a key
technique used to design the best matrix multiplication algorithms, can also be
used to design communication protocols for a variety of problems. We also show
how known lower bounds for Number On the Forehead communication can be used to
bound properties of the matrix multiplication tensor such as its zeroing out
subrank. Finally, we substantially generalize known methods based on slice-rank
for studying communication, and show how they directly relate to the matrix
multiplication exponent $\omega$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11433'>Lower Bounds for Intersection Reporting among Flat Objects</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Peyman Afshani, Pingan Cheng</p><p>Recently, Ezra and Sharir [ES22a] showed an $O(n^{3/2+\sigma})$ space and
$O(n^{1/2+\sigma})$ query time data structure for ray shooting among triangles
in $\mathbb{R}^3$. This improves the upper bound given by the classical
$S(n)Q(n)^4=O(n^{4+\sigma})$ space-time tradeoff for the first time in almost
25 years and in fact lies on the tradeoff curve of
$S(n)Q(n)^3=O(n^{3+\sigma})$. However, it seems difficult to apply their
techniques beyond this specific space and time combination. This pheonomenon
appears persistently in almost all recent advances of flat object intersection
searching, e.g., line-tetrahedron intersection in $\mathbb{R}^4$ [ES22b],
triangle-triangle intersection in $\mathbb{R}^4$ [ES22b], or even among flat
semialgebraic objects [AAEKS22].
</p>
<p>We give a timely explanation to this phenomenon from a lower bound
perspective. We prove that given a set $\mathcal{S}$ of $(d-1)$-dimensional
simplicies in $\mathbb{R}^d$, any data structure that can report all
intersections with small ($n^{o(1)}$) query time must use
$\Omega(n^{2(d-1)-o(1)})$ space. This dashes the hope of any significant
improvement to the tradeoff curves for small query time and almost matches the
classical upper bound. We also obtain an almost matching space lower bound of
$\Omega(n^{6-o(1)})$ for triangle-triangle intersection reporting in
$\mathbb{R}^4$ when the query time is small. Along the way, we further develop
the previous lower bound techniques by Afshani and Cheng [AC21, AC22].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Afshani_P/0/1/0/all/0/1">Peyman Afshani</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Pingan Cheng</a></p><p>Recently, Ezra and Sharir [ES22a] showed an $O(n^{3/2+\sigma})$ space and
$O(n^{1/2+\sigma})$ query time data structure for ray shooting among triangles
in $\mathbb{R}^3$. This improves the upper bound given by the classical
$S(n)Q(n)^4=O(n^{4+\sigma})$ space-time tradeoff for the first time in almost
25 years and in fact lies on the tradeoff curve of
$S(n)Q(n)^3=O(n^{3+\sigma})$. However, it seems difficult to apply their
techniques beyond this specific space and time combination. This pheonomenon
appears persistently in almost all recent advances of flat object intersection
searching, e.g., line-tetrahedron intersection in $\mathbb{R}^4$ [ES22b],
triangle-triangle intersection in $\mathbb{R}^4$ [ES22b], or even among flat
semialgebraic objects [AAEKS22].
</p>
<p>We give a timely explanation to this phenomenon from a lower bound
perspective. We prove that given a set $\mathcal{S}$ of $(d-1)$-dimensional
simplicies in $\mathbb{R}^d$, any data structure that can report all
intersections with small ($n^{o(1)}$) query time must use
$\Omega(n^{2(d-1)-o(1)})$ space. This dashes the hope of any significant
improvement to the tradeoff curves for small query time and almost matches the
classical upper bound. We also obtain an almost matching space lower bound of
$\Omega(n^{6-o(1)})$ for triangle-triangle intersection reporting in
$\mathbb{R}^4$ when the query time is small. Along the way, we further develop
the previous lower bound techniques by Afshani and Cheng [AC21, AC22].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11250'>The Complexity of Debt Swapping</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Henri Froese, Martin Hoefer, Lisa Wilhelmi</p><p>A debt swap is an elementary edge swap in a directed, weighted graph, where
two edges with the same weight swap their targets. Debt swaps are a natural and
appealing operation in financial networks, in which nodes are banks and edges
represent debt contracts. They can improve the clearing payments and the
stability of these networks. However, their algorithmic properties are not
well-understood.
</p>
<p>We analyze the computational complexity of debt swapping in networks with
ranking-based clearing. Our main interest lies in semi-positive swaps, in which
no creditor strictly suffers and at least one strictly profits. These swaps
lead to a Pareto-improvement in the entire network. We consider network
optimization via sequences of $v$-improving debt swaps from which a given bank
$v$ strictly profits. We show that every sequence of semi-positive
$v$-improving swaps has polynomial length. In contrast, for arbitrary
$v$-improving swaps, the problem of reaching a network configuration that
allows no further swaps is PLS-complete. We identify cases in which short
sequences of semi-positive swaps exist even without the $v$-improving property.
</p>
<p>In addition, we study reachability problems, i.e., deciding if a sequence of
swaps exists between given initial and final networks. We identify a
polynomial-time algorithm for arbitrary swaps, show NP-hardness for
semi-positive swaps and even PSPACE-completeness for $v$-improving swaps or
swaps that only maintain a lower bound on the assets of a given bank $v$. A
variety of our results can be extended to arbitrary monotone clearing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Froese_H/0/1/0/all/0/1">Henri Froese</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoefer_M/0/1/0/all/0/1">Martin Hoefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilhelmi_L/0/1/0/all/0/1">Lisa Wilhelmi</a></p><p>A debt swap is an elementary edge swap in a directed, weighted graph, where
two edges with the same weight swap their targets. Debt swaps are a natural and
appealing operation in financial networks, in which nodes are banks and edges
represent debt contracts. They can improve the clearing payments and the
stability of these networks. However, their algorithmic properties are not
well-understood.
</p>
<p>We analyze the computational complexity of debt swapping in networks with
ranking-based clearing. Our main interest lies in semi-positive swaps, in which
no creditor strictly suffers and at least one strictly profits. These swaps
lead to a Pareto-improvement in the entire network. We consider network
optimization via sequences of $v$-improving debt swaps from which a given bank
$v$ strictly profits. We show that every sequence of semi-positive
$v$-improving swaps has polynomial length. In contrast, for arbitrary
$v$-improving swaps, the problem of reaching a network configuration that
allows no further swaps is PLS-complete. We identify cases in which short
sequences of semi-positive swaps exist even without the $v$-improving property.
</p>
<p>In addition, we study reachability problems, i.e., deciding if a sequence of
swaps exists between given initial and final networks. We identify a
polynomial-time algorithm for arbitrary swaps, show NP-hardness for
semi-positive swaps and even PSPACE-completeness for $v$-improving swaps or
swaps that only maintain a lower bound on the assets of a given bank $v$. A
variety of our results can be extended to arbitrary monotone clearing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11295'>Fair Correlation Clustering in Forests</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Katrin Casel, Tobias Friedrich, Martin Schirneck, Simon Wietheger</p><p>The study of algorithmic fairness received growing attention recently. This
stems from the awareness that bias in the input data for machine learning
systems may result in discriminatory outputs. For clustering tasks, one of the
most central notions of fairness is the formalization by Chierichetti, Kumar,
Lattanzi, and Vassilvitskii [NeurIPS 2017]. A clustering is said to be fair, if
each cluster has the same distribution of manifestations of a sensitive
attribute as the whole input set. This is motivated by various applications
where the objects to be clustered have sensitive attributes that should not be
over- or underrepresented.
</p>
<p>We discuss the applicability of this fairness notion to Correlation
Clustering. The existing literature on the resulting Fair Correlation
Clustering problem either presents approximation algorithms with poor
approximation guarantees or severely limits the possible distributions of the
sensitive attribute (often only two manifestations with a 1:1 ratio are
considered). Our goal is to understand if there is hope for better results in
between these two extremes. To this end, we consider restricted graph classes
which allow us to characterize the distributions of sensitive attributes for
which this form of fairness is tractable from a complexity point of view.
</p>
<p>While existing work on Fair Correlation Clustering gives approximation
algorithms, we focus on exact solutions and investigate whether there are
efficiently solvable instances. The unfair version of Correlation Clustering is
trivial on forests, but adding fairness creates a surprisingly rich picture of
complexities. We give an overview of the distributions and types of forests
where Fair Correlation Clustering turns from tractable to intractable. The most
surprising insight to us is the fact that the cause of the hardness of Fair
Correlation Clustering is not the strictness of the fairness condition.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Casel_K/0/1/0/all/0/1">Katrin Casel</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrich_T/0/1/0/all/0/1">Tobias Friedrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Schirneck_M/0/1/0/all/0/1">Martin Schirneck</a>, <a href="http://arxiv.org/find/cs/1/au:+Wietheger_S/0/1/0/all/0/1">Simon Wietheger</a></p><p>The study of algorithmic fairness received growing attention recently. This
stems from the awareness that bias in the input data for machine learning
systems may result in discriminatory outputs. For clustering tasks, one of the
most central notions of fairness is the formalization by Chierichetti, Kumar,
Lattanzi, and Vassilvitskii [NeurIPS 2017]. A clustering is said to be fair, if
each cluster has the same distribution of manifestations of a sensitive
attribute as the whole input set. This is motivated by various applications
where the objects to be clustered have sensitive attributes that should not be
over- or underrepresented.
</p>
<p>We discuss the applicability of this fairness notion to Correlation
Clustering. The existing literature on the resulting Fair Correlation
Clustering problem either presents approximation algorithms with poor
approximation guarantees or severely limits the possible distributions of the
sensitive attribute (often only two manifestations with a 1:1 ratio are
considered). Our goal is to understand if there is hope for better results in
between these two extremes. To this end, we consider restricted graph classes
which allow us to characterize the distributions of sensitive attributes for
which this form of fairness is tractable from a complexity point of view.
</p>
<p>While existing work on Fair Correlation Clustering gives approximation
algorithms, we focus on exact solutions and investigate whether there are
efficiently solvable instances. The unfair version of Correlation Clustering is
trivial on forests, but adding fairness creates a surprisingly rich picture of
complexities. We give an overview of the distributions and types of forests
where Fair Correlation Clustering turns from tractable to intractable. The most
surprising insight to us is the fact that the cause of the hardness of Fair
Correlation Clustering is not the strictness of the fairness condition.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11336'>Approximability of the Four-Vertex Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhiguo Fu, Tianyu Liu, Xiongxin Yang</p><p>We study the approximability of the four-vertex model, a special case of the
six-vertex model.We prove that, despite being NP-hard to approximate in the
worst case, the four-vertex model admits a fully polynomial randomized
approximation scheme (FPRAS) when the input satisfies certain linear equation
system.The FPRAS is given by a Markov chain called the worm process whose state
space and rapid mixing rely on the solution of the linear equation system.This
is the first attempt to design an FPRAS for the six-vertex model with unwinable
constraint functions.Furthermore, we consider the application of this technique
on planar graphs to give efficient sampling algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zhiguo Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiongxin Yang</a></p><p>We study the approximability of the four-vertex model, a special case of the
six-vertex model.We prove that, despite being NP-hard to approximate in the
worst case, the four-vertex model admits a fully polynomial randomized
approximation scheme (FPRAS) when the input satisfies certain linear equation
system.The FPRAS is given by a Markov chain called the worm process whose state
space and rapid mixing rely on the solution of the linear equation system.This
is the first attempt to design an FPRAS for the six-vertex model with unwinable
constraint functions.Furthermore, we consider the application of this technique
on planar graphs to give efficient sampling algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11151'>Improved Coresets for Clustering with Capacity and Fairness Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Pinyan Lu, Xuan Wu</p><p>We study coresets for clustering with capacity and fairness constraints. Our
main result is a near-linear time algorithm to construct
$\tilde{O}(k^2\varepsilon^{-2z-2})$-sized $\varepsilon$-coresets for
capacitated $(k,z)$-clustering which improves a recent
$\tilde{O}(k^3\varepsilon^{-3z-2})$ bound by [BCAJ+22, HJLW23]. As a corollary,
we also save a factor of $k \varepsilon^{-z}$ on the coreset size for fair
$(k,z)$-clustering compared to them.
</p>
<p>We fundamentally improve the hierarchical uniform sampling framework of
[BCAJ+22] by adaptively selecting sample size on each ring instance,
proportional to its clustering cost to an optimal solution. Our analysis relies
on a key geometric observation that reduces the number of total ``effective
centers" from [BCAJ+22]'s $\tilde{O}(k^2\varepsilon^{-z})$ to merely $O(k\log
\varepsilon^{-1})$ by being able to ``ignore'' all center points that are too
far or too close to the ring center.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pinyan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xuan Wu</a></p><p>We study coresets for clustering with capacity and fairness constraints. Our
main result is a near-linear time algorithm to construct
$\tilde{O}(k^2\varepsilon^{-2z-2})$-sized $\varepsilon$-coresets for
capacitated $(k,z)$-clustering which improves a recent
$\tilde{O}(k^3\varepsilon^{-3z-2})$ bound by [BCAJ+22, HJLW23]. As a corollary,
we also save a factor of $k \varepsilon^{-z}$ on the coreset size for fair
$(k,z)$-clustering compared to them.
</p>
<p>We fundamentally improve the hierarchical uniform sampling framework of
[BCAJ+22] by adaptively selecting sample size on each ring instance,
proportional to its clustering cost to an optimal solution. Our analysis relies
on a key geometric observation that reduces the number of total ``effective
centers" from [BCAJ+22]'s $\tilde{O}(k^2\varepsilon^{-z})$ to merely $O(k\log
\varepsilon^{-1})$ by being able to ``ignore'' all center points that are too
far or too close to the ring center.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11044'>The Target-Charging Technique for Privacy Accounting across Interactive Computations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Edith Cohen, Xin Lyu</p><p>We propose the \emph{Target Charging Technique} (TCT), a unified privacy
accounting framework for interactive settings where a sensitive dataset is
accessed multiple times using differentially private algorithms. Unlike
traditional composition, where privacy guarantees deteriorate quickly with the
number of accesses, TCT allows computations that don't hit a specified
\emph{target}, often the vast majority, to be essentially free (while incurring
instead a small overhead on those that do hit their targets). TCT generalizes
tools such as the sparse vector technique and top-$k$ selection from private
candidates and extends their remarkable privacy accounting benefits from noisy
Lipschitz functions to general private algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cohen_E/0/1/0/all/0/1">Edith Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1">Xin Lyu</a></p><p>We propose the \emph{Target Charging Technique} (TCT), a unified privacy
accounting framework for interactive settings where a sensitive dataset is
accessed multiple times using differentially private algorithms. Unlike
traditional composition, where privacy guarantees deteriorate quickly with the
number of accesses, TCT allows computations that don't hit a specified
\emph{target}, often the vast majority, to be essentially free (while incurring
instead a small overhead on those that do hit their targets). TCT generalizes
tools such as the sparse vector technique and top-$k$ selection from private
candidates and extends their remarkable privacy accounting benefits from noisy
Lipschitz functions to general private algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11068'>Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuzhou Gu, Zhao Song, Junze Yin, Lichen Zhang</p><p>Given a matrix $M\in \mathbb{R}^{m\times n}$, the low rank matrix completion
problem asks us to find a rank-$k$ approximation of $M$ as $UV^\top$ for $U\in
\mathbb{R}^{m\times k}$ and $V\in \mathbb{R}^{n\times k}$ by only observing a
few entries masked by a binary matrix $P_{\Omega}\in \{0, 1 \}^{m\times n}$. As
a particular instance of the weighted low rank approximation problem, solving
low rank matrix completion is known to be computationally hard even to find an
approximate solution [RSW16]. However, due to its practical importance, many
heuristics have been proposed for this problem. In the seminal work of Jain,
Netrapalli, and Sanghavi [JNS13], they show that the alternating minimization
framework provides provable guarantees for low rank matrix completion problem
whenever $M$ admits an incoherent low rank factorization. Unfortunately, their
algorithm requires solving two exact multiple response regressions per
iteration and their analysis is non-robust as they exploit the structure of the
exact solution.
</p>
<p>In this paper, we take a major step towards a more efficient and robust
alternating minimization framework for low rank matrix completion. Our main
result is a robust alternating minimization algorithm that can tolerate
moderate errors even though the regressions are solved approximately.
Consequently, we also significantly improve the running time of [JNS13] from
$\widetilde{O}(mnk^2 )$ to $\widetilde{O}(mnk )$ which is nearly linear in the
problem size, as verifying the low rank approximation takes $O(mnk)$ time. Our
core algorithmic building block is a high accuracy regression solver that
solves the regression in nearly linear time per iteration.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuzhou Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Junze Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lichen Zhang</a></p><p>Given a matrix $M\in \mathbb{R}^{m\times n}$, the low rank matrix completion
problem asks us to find a rank-$k$ approximation of $M$ as $UV^\top$ for $U\in
\mathbb{R}^{m\times k}$ and $V\in \mathbb{R}^{n\times k}$ by only observing a
few entries masked by a binary matrix $P_{\Omega}\in \{0, 1 \}^{m\times n}$. As
a particular instance of the weighted low rank approximation problem, solving
low rank matrix completion is known to be computationally hard even to find an
approximate solution [RSW16]. However, due to its practical importance, many
heuristics have been proposed for this problem. In the seminal work of Jain,
Netrapalli, and Sanghavi [JNS13], they show that the alternating minimization
framework provides provable guarantees for low rank matrix completion problem
whenever $M$ admits an incoherent low rank factorization. Unfortunately, their
algorithm requires solving two exact multiple response regressions per
iteration and their analysis is non-robust as they exploit the structure of the
exact solution.
</p>
<p>In this paper, we take a major step towards a more efficient and robust
alternating minimization framework for low rank matrix completion. Our main
result is a robust alternating minimization algorithm that can tolerate
moderate errors even though the regressions are solved approximately.
Consequently, we also significantly improve the running time of [JNS13] from
$\widetilde{O}(mnk^2 )$ to $\widetilde{O}(mnk )$ which is nearly linear in the
problem size, as verifying the low rank approximation takes $O(mnk)$ time. Our
core algorithmic building block is a high accuracy regression solver that
solves the regression in nearly linear time per iteration.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11081'>Differentially Private $L_2$-Heavy Hitters in the Sliding Window Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jeremiah Blocki, Seunghoon Lee, Tamalika Mukherjee, Samson Zhou</p><p>The data management of large companies often prioritize more recent data, as
a source of higher accuracy prediction than outdated data. For example, the
Facebook data policy retains user search histories for $6$ months while the
Google data retention policy states that browser information may be stored for
up to $9$ months. These policies are captured by the sliding window model, in
which only the most recent $W$ statistics form the underlying dataset.
</p>
<p>In this paper, we consider the problem of privately releasing the $L_2$-heavy
hitters in the sliding window model, which include $L_p$-heavy hitters for
$p\le 2$ and in some sense are the strongest possible guarantees that can be
achieved using polylogarithmic space, but cannot be handled by existing
techniques due to the sub-additivity of the $L_2$ norm. Moreover, existing
non-private sliding window algorithms use the smooth histogram framework, which
has high sensitivity.
</p>
<p>To overcome these barriers, we introduce the first differentially private
algorithm for $L_2$-heavy hitters in the sliding window model by initiating a
number of $L_2$-heavy hitter algorithms across the stream with significantly
lower threshold. Similarly, we augment the algorithms with an approximate
frequency tracking algorithm with significantly higher accuracy. We then use
smooth sensitivity and statistical distance arguments to show that we can add
noise proportional to an estimation of the $L_2$ norm. To the best of our
knowledge, our techniques are the first to privately release statistics that
are related to a sub-additive function in the sliding window model, and may be
of independent interest to future differentially private algorithmic design in
the sliding window model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blocki_J/0/1/0/all/0/1">Jeremiah Blocki</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seunghoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_T/0/1/0/all/0/1">Tamalika Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Samson Zhou</a></p><p>The data management of large companies often prioritize more recent data, as
a source of higher accuracy prediction than outdated data. For example, the
Facebook data policy retains user search histories for $6$ months while the
Google data retention policy states that browser information may be stored for
up to $9$ months. These policies are captured by the sliding window model, in
which only the most recent $W$ statistics form the underlying dataset.
</p>
<p>In this paper, we consider the problem of privately releasing the $L_2$-heavy
hitters in the sliding window model, which include $L_p$-heavy hitters for
$p\le 2$ and in some sense are the strongest possible guarantees that can be
achieved using polylogarithmic space, but cannot be handled by existing
techniques due to the sub-additivity of the $L_2$ norm. Moreover, existing
non-private sliding window algorithms use the smooth histogram framework, which
has high sensitivity.
</p>
<p>To overcome these barriers, we introduce the first differentially private
algorithm for $L_2$-heavy hitters in the sliding window model by initiating a
number of $L_2$-heavy hitter algorithms across the stream with significantly
lower threshold. Similarly, we augment the algorithms with an approximate
frequency tracking algorithm with significantly higher accuracy. We then use
smooth sensitivity and statistical distance arguments to show that we can add
noise proportional to an estimation of the $L_2$ norm. To the best of our
knowledge, our techniques are the first to privately release statistics that
are related to a sub-additive function in the sliding window model, and may be
of independent interest to future differentially private algorithmic design in
the sliding window model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11264'>Approximation Ineffectiveness of a Tour-Untangling Heuristic</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bodo Manthey, Jesse van Rhijn</p><p>We analyze a tour-uncrossing heuristic for the Travelling Salesperson
Problem, showing that its worst-case approximation ratio is $\Omega(n)$ and its
average-case approximation ratio is $\Omega(\sqrt{n})$ in expectation. We
furthermore evaluate the approximation performance of this heuristic
numerically on average-case instances, and find that it performs far better
than the average-case lower bound suggests. This indicates a shortcoming in the
approach we use for our analysis, which is a rather common approach in the
analysis of local search heuristics.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Manthey_B/0/1/0/all/0/1">Bodo Manthey</a>, <a href="http://arxiv.org/find/cs/1/au:+Rhijn_J/0/1/0/all/0/1">Jesse van Rhijn</a></p><p>We analyze a tour-uncrossing heuristic for the Travelling Salesperson
Problem, showing that its worst-case approximation ratio is $\Omega(n)$ and its
average-case approximation ratio is $\Omega(\sqrt{n})$ in expectation. We
furthermore evaluate the approximation performance of this heuristic
numerically on average-case instances, and find that it performs far better
than the average-case lower bound suggests. This indicates a shortcoming in the
approach we use for our analysis, which is a rather common approach in the
analysis of local search heuristics.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11339'>The Power of Uniform Sampling for $k$-Median</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Shaofeng H.-C. Jiang, Jianing Lou</p><p>We study the power of uniform sampling for $k$-Median in various metric
spaces. We relate the query complexity for approximating $k$-Median, to a key
parameter of the dataset, called the balancedness $\beta \in (0, 1]$ (with $1$
being perfectly balanced). We show that any algorithm must make $\Omega(1 /
\beta)$ queries to the point set in order to achieve $O(1)$-approximation for
$k$-Median. This particularly implies existing constructions of coresets, a
popular data reduction technique, cannot be query-efficient. On the other hand,
we show a simple uniform sample of $\mathrm{poly}(k \epsilon^{-1} \beta^{-1})$
points suffices for $(1 + \epsilon)$-approximation for $k$-Median for various
metric spaces, which nearly matches the lower bound. We conduct experiments to
verify that in many real datasets, the balancedness parameter is usually well
bounded, and that the uniform sampling performs consistently well even for the
case with moderately large balancedness, which justifies that uniform sampling
is indeed a viable approach for solving $k$-Median.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shaofeng H.-C. Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1">Jianing Lou</a></p><p>We study the power of uniform sampling for $k$-Median in various metric
spaces. We relate the query complexity for approximating $k$-Median, to a key
parameter of the dataset, called the balancedness $\beta \in (0, 1]$ (with $1$
being perfectly balanced). We show that any algorithm must make $\Omega(1 /
\beta)$ queries to the point set in order to achieve $O(1)$-approximation for
$k$-Median. This particularly implies existing constructions of coresets, a
popular data reduction technique, cannot be query-efficient. On the other hand,
we show a simple uniform sample of $\mathrm{poly}(k \epsilon^{-1} \beta^{-1})$
points suffices for $(1 + \epsilon)$-approximation for $k$-Median for various
metric spaces, which nearly matches the lower bound. We conduct experiments to
verify that in many real datasets, the balancedness parameter is usually well
bounded, and that the uniform sampling performs consistently well even for the
case with moderately large balancedness, which justifies that uniform sampling
is indeed a viable approach for solving $k$-Median.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11341'>Differentially Private Data Structures under Continual Observation for Histograms and Related Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Monika Henzinger, A. R. Sricharan, Teresa Anna Steiner</p><p>Binary counting under continual observation is a well-studied fundamental
problem in differential privacy. A natural extension is maintaining column
sums, also known as histogram, over a stream of rows from $\{0,1\}^d$, and
answering queries about those sums, e.g. the maximum column sum or the median,
while satisfying differential privacy. Jain et al. (2021) showed that computing
the maximum column sum under continual observation while satisfying event-level
differential privacy requires an error either polynomial in the dimension $d$
or the stream length $T$. On the other hand, no $o(d\log^2 T)$ upper bound for
$\epsilon$-differential privacy or $o(\sqrt{d}\log^{3/2} T)$ upper bound for
$(\epsilon,\delta)$-differential privacy are known. In this work, we give new
parameterized upper bounds for maintaining histogram, maximum column sum,
quantiles of the column sums, and any set of at most $d$ low-sensitivity,
monotone, real valued queries on the column sums. Our solutions achieve an
error of approximately $O(d\log^2 c_{\max}+\log T)$ for $\epsilon$-differential
privacy and approximately $O(\sqrt{d}\log^{3/2}c_{\max}+\log T)$ for
$(\epsilon,\delta)$-differential privacy, where $c_{\max}$ is the maximum value
that the queries we want to answer can assume on the given data set.
</p>
<p>Furthermore, we show that such an improvement is not possible for a slightly
expanded notion of neighboring streams by giving a lower bound of $\Omega(d
\log T)$. This explains why our improvement cannot be achieved with the
existing mechanisms for differentially private histograms, as they remain
differentially private even for this expanded notion of neighboring streams.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Sricharan_A/0/1/0/all/0/1">A. R. Sricharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_T/0/1/0/all/0/1">Teresa Anna Steiner</a></p><p>Binary counting under continual observation is a well-studied fundamental
problem in differential privacy. A natural extension is maintaining column
sums, also known as histogram, over a stream of rows from $\{0,1\}^d$, and
answering queries about those sums, e.g. the maximum column sum or the median,
while satisfying differential privacy. Jain et al. (2021) showed that computing
the maximum column sum under continual observation while satisfying event-level
differential privacy requires an error either polynomial in the dimension $d$
or the stream length $T$. On the other hand, no $o(d\log^2 T)$ upper bound for
$\epsilon$-differential privacy or $o(\sqrt{d}\log^{3/2} T)$ upper bound for
$(\epsilon,\delta)$-differential privacy are known. In this work, we give new
parameterized upper bounds for maintaining histogram, maximum column sum,
quantiles of the column sums, and any set of at most $d$ low-sensitivity,
monotone, real valued queries on the column sums. Our solutions achieve an
error of approximately $O(d\log^2 c_{\max}+\log T)$ for $\epsilon$-differential
privacy and approximately $O(\sqrt{d}\log^{3/2}c_{\max}+\log T)$ for
$(\epsilon,\delta)$-differential privacy, where $c_{\max}$ is the maximum value
that the queries we want to answer can assume on the given data set.
</p>
<p>Furthermore, we show that such an improvement is not possible for a slightly
expanded notion of neighboring streams by giving a lower bound of $\Omega(d
\log T)$. This explains why our improvement cannot be achieved with the
existing mechanisms for differentially private histograms, as they remain
differentially private even for this expanded notion of neighboring streams.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11390'>Easy testability for posets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Panna T&#xed;mea Fekete, G&#xe1;bor Kun</p><p>Alon and Shapira proved that every class of undirected graphs closed under
the removal of edges and vertices is strongly testable. We show that every
class of posets closed under the removal of edges is easily testable, that is,
strongly testable with a polynomial bound on the queries. We get this result
via a removal lemma with polynomial bound. We also give a simple
classification: for every class of posets closed under the removal of edges and
vertices there is an $h$ such that the class is indistinguishable from the
class of posets without chains of length $h$ (by testing with a constant number
of queries). The analogous results hold for comparability graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Fekete_P/0/1/0/all/0/1">Panna T&#xed;mea Fekete</a>, <a href="http://arxiv.org/find/math/1/au:+Kun_G/0/1/0/all/0/1">G&#xe1;bor Kun</a></p><p>Alon and Shapira proved that every class of undirected graphs closed under
the removal of edges and vertices is strongly testable. We show that every
class of posets closed under the removal of edges is easily testable, that is,
strongly testable with a polynomial bound on the queries. We get this result
via a removal lemma with polynomial bound. We also give a simple
classification: for every class of posets closed under the removal of edges and
vertices there is an $h$ such that the class is indistinguishable from the
class of posets without chains of length $h$ (by testing with a constant number
of queries). The analogous results hold for comparability graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
