<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-04-26T04:32:14Z">Wednesday, April 26 2023, 04:32</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, April 26
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12517'>The 2-MAXSAT Problem Can Be Solved in Polynomial Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yangjun Chen</p><p>By the MAXSAT problem, we are given a set $V$ of $m$ variables and a
collection $C$ of $n$ clauses over $V$. We will seek a truth assignment to
maximize the number of satisfied clauses. This problem is $\textit{NP}$-hard
even for its restricted version, the 2-MAXSAT problem by which every clause
contains at most 2 literals. In this paper, we discuss a polynomial time
algorithm to solve this problem. Its time complexity is bounded by O($n^2m^3$).
Hence, we provide a proof of $P$ = $\textit{NP}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yangjun Chen</a></p><p>By the MAXSAT problem, we are given a set $V$ of $m$ variables and a
collection $C$ of $n$ clauses over $V$. We will seek a truth assignment to
maximize the number of satisfied clauses. This problem is $\textit{NP}$-hard
even for its restricted version, the 2-MAXSAT problem by which every clause
contains at most 2 literals. In this paper, we discuss a polynomial time
algorithm to solve this problem. Its time complexity is bounded by O($n^2m^3$).
Hence, we provide a proof of $P$ = $\textit{NP}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12871'>Network Satisfaction Problems Solved by k-Consistency</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Manuel Bodirsky, Simon Kn&#xe4;uer</p><p>We show that the problem of deciding for a given finite relation algebra A
whether the network satisfaction problem for A can be solved by the
k-consistency procedure, for some natural number k, is undecidable. For the
important class of finite relation algebras A with a normal representation,
however, the decidability of this problem remains open. We show that if A is
symmetric and has a flexible atom, then the question whether NSP(A) can be
solved by k-consistency, for some natural number k, is decidable (even in
polynomial time in the number of atoms of A). This result follows from a more
general sufficient condition for the correctness of the k-consistency procedure
for finite symmetric relation algebras. In our proof we make use of a result of
Alexandr Kazda about finite binary conservative structures.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Bodirsky_M/0/1/0/all/0/1">Manuel Bodirsky</a>, <a href="http://arxiv.org/find/math/1/au:+Knauer_S/0/1/0/all/0/1">Simon Kn&#xe4;uer</a></p><p>We show that the problem of deciding for a given finite relation algebra A
whether the network satisfaction problem for A can be solved by the
k-consistency procedure, for some natural number k, is undecidable. For the
important class of finite relation algebras A with a normal representation,
however, the decidability of this problem remains open. We show that if A is
symmetric and has a flexible atom, then the question whether NSP(A) can be
solved by k-consistency, for some natural number k, is decidable (even in
polynomial time in the number of atoms of A). This result follows from a more
general sufficient condition for the correctness of the k-consistency procedure
for finite symmetric relation algebras. In our proof we make use of a result of
Alexandr Kazda about finite binary conservative structures.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12948'>Simulating Logspace-Recursion with Logarithmic Quantifier Depth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Steffen van Bergerem, Martin Grohe, Sandra Kiefer, Luca Oeljeklaus</p><p>The fixed-point logic LREC= was developed by Grohe et al. (CSL 2011) in the
quest for a logic to capture all problems decidable in logarithmic space. It
extends FO+C, first-order logic with counting, by an operator that formalises a
limited form of recursion. We show that for every LREC=-definable property on
relational structures, there is a constant k such that the k-variable fragment
of first-order logic with counting quantifiers expresses the property via
formulae of logarithmic quantifier depth. This yields that any pair of graphs
separable by the property can be distinguished with the k-dimensional
Weisfeiler-Leman algorithm in a logarithmic number of iterations. In
particular, it implies that a constant dimension of the algorithm identifies
every interval graph and every chordal claw-free graph in logarithmically many
iterations, since every such graph admits LREC=-definable canonisation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bergerem_S/0/1/0/all/0/1">Steffen van Bergerem</a>, <a href="http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1">Martin Grohe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiefer_S/0/1/0/all/0/1">Sandra Kiefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Oeljeklaus_L/0/1/0/all/0/1">Luca Oeljeklaus</a></p><p>The fixed-point logic LREC= was developed by Grohe et al. (CSL 2011) in the
quest for a logic to capture all problems decidable in logarithmic space. It
extends FO+C, first-order logic with counting, by an operator that formalises a
limited form of recursion. We show that for every LREC=-definable property on
relational structures, there is a constant k such that the k-variable fragment
of first-order logic with counting quantifiers expresses the property via
formulae of logarithmic quantifier depth. This yields that any pair of graphs
separable by the property can be distinguished with the k-dimensional
Weisfeiler-Leman algorithm in a logarithmic number of iterations. In
particular, it implies that a constant dimension of the algorithm identifies
every interval graph and every chordal claw-free graph in logarithmically many
iterations, since every such graph admits LREC=-definable canonisation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12435'>Computing Circuit Polynomials in the Algebraic Rigidity Matroid</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Goran Malic, Ileana Streinu</p><p>We present an algorithm for computing circuit polynomials in the algebraic
rigidity matroid $\mathcal{A}(\text{CM}_n)$ associated to the Cayley-Menger
ideal CM$_n$ for $n$ points in 2D. It relies on combinatorial resultants, a new
operation on graphs that captures properties of the Sylvester resultant of two
polynomials in this ideal. We show that every rigidity circuit has a
construction tree from K4 graphs based on this operation. Our algorithm
performs an algebraic elimination guided by such a construction tree, and uses
classical resultants, factorization and ideal membership. To highlight its
effectiveness, we implemented the algorithm in Mathematica: it took less than
15 seconds on an example where a Gr\"obner Basis calculation took 5 days and 6
hrs. Additional speed-ups are obtained using non-$K_4$ generators of the
Cayley-Menger ideal and simple variations on our main algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Malic_G/0/1/0/all/0/1">Goran Malic</a>, <a href="http://arxiv.org/find/math/1/au:+Streinu_I/0/1/0/all/0/1">Ileana Streinu</a></p><p>We present an algorithm for computing circuit polynomials in the algebraic
rigidity matroid $\mathcal{A}(\text{CM}_n)$ associated to the Cayley-Menger
ideal CM$_n$ for $n$ points in 2D. It relies on combinatorial resultants, a new
operation on graphs that captures properties of the Sylvester resultant of two
polynomials in this ideal. We show that every rigidity circuit has a
construction tree from K4 graphs based on this operation. Our algorithm
performs an algebraic elimination guided by such a construction tree, and uses
classical resultants, factorization and ideal membership. To highlight its
effectiveness, we implemented the algorithm in Mathematica: it took less than
15 seconds on an example where a Gr\"obner Basis calculation took 5 days and 6
hrs. Additional speed-ups are obtained using non-$K_4$ generators of the
Cayley-Menger ideal and simple variations on our main algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12381'>Recognizing and generating unswitchable graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Asish Mukhopadhyay, Daniel John, Srivatsan Vasudevan</p><p>In this paper, we show that unswitchable graphs are a proper subclass of
split graphs, and exploit this fact to propose efficient algorithms for their
recognition and generation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mukhopadhyay_A/0/1/0/all/0/1">Asish Mukhopadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+John_D/0/1/0/all/0/1">Daniel John</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasudevan_S/0/1/0/all/0/1">Srivatsan Vasudevan</a></p><p>In this paper, we show that unswitchable graphs are a proper subclass of
split graphs, and exploit this fact to propose efficient algorithms for their
recognition and generation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12610'>Fast Continuous Subgraph Matching over Streaming Graphs via Backtracking Reduction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rongjian Yang, Zhijie Zhang, Weiguo Zheng, Jeffery Xu Yu</p><p>Streaming graphs are drawing increasing attention in both academic and
industrial communities as many graphs in real applications evolve over time.
Continuous subgraph matching (shorted as CSM) aims to report the incremental
matches of a query graph in such streaming graphs. It involves two major steps,
i.e., candidate maintenance and incremental match generation, to answer CSM.
Throughout the course of continuous subgraph matching, incremental match
generation backtracking over the search space dominates the total cost.
However, most previous approaches focus on developing techniques for efficient
candidate maintenance, while incremental match generation receives less
attention despite its importance in CSM. Aiming to minimize the overall cost,
we propose two techniques to reduce backtrackings in this paper. We present a
cost-effective index CaLiG that yields tighter candidate maintenance, shrinking
the search space of backtracking. In addition, we develop a novel incremental
matching paradigm KSS that decomposes the query vertices into conditional
kernel vertices and shell vertices. With the matches of kernel vertices, the
incremental matches can be produced immediately by joining the candidates of
shell vertices without any backtrackings. Benefiting from reduced
backtrackings, the elapsed time of CSM decreases significantly. Extensive
experiments over real graphs show that our method runs faster than the
state-of-the-art algorithm orders of magnitude.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Rongjian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhijie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Weiguo Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jeffery Xu Yu</a></p><p>Streaming graphs are drawing increasing attention in both academic and
industrial communities as many graphs in real applications evolve over time.
Continuous subgraph matching (shorted as CSM) aims to report the incremental
matches of a query graph in such streaming graphs. It involves two major steps,
i.e., candidate maintenance and incremental match generation, to answer CSM.
Throughout the course of continuous subgraph matching, incremental match
generation backtracking over the search space dominates the total cost.
However, most previous approaches focus on developing techniques for efficient
candidate maintenance, while incremental match generation receives less
attention despite its importance in CSM. Aiming to minimize the overall cost,
we propose two techniques to reduce backtrackings in this paper. We present a
cost-effective index CaLiG that yields tighter candidate maintenance, shrinking
the search space of backtracking. In addition, we develop a novel incremental
matching paradigm KSS that decomposes the query vertices into conditional
kernel vertices and shell vertices. With the matches of kernel vertices, the
incremental matches can be produced immediately by joining the candidates of
shell vertices without any backtrackings. Benefiting from reduced
backtrackings, the elapsed time of CSM decreases significantly. Extensive
experiments over real graphs show that our method runs faster than the
state-of-the-art algorithm orders of magnitude.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12656'>Towards Generating Hop-constrained s-t Simple Path Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuzheng Cai, Siyuan Liu, Weiguo Zheng, Xuemin Lin</p><p>Graphs have been widely used in real-world applications, in which
investigating relations between vertices is an important task. In this paper,
we study the problem of generating the k-hop-constrained s-t simple path graph,
i.e., the subgraph consisting of all simple paths from vertex s to vertex t of
length no larger than k. To our best knowledge, we are the first to formalize
this problem and prove its NP-hardness on directed graphs. To tackle this
challenging problem, we propose an efficient algorithm named EVE, which
exploits the paradigm of edge-wise examination rather than exhaustively
enumerating all paths. Powered by essential vertices appearing in all simple
paths between vertex pairs, EVE distinguishes the edges that are definitely (or
not) contained in the desired simple path graph, producing a tight upper-bound
graph in the time cost $\mathcal{O}(k^2|E|)$. Each remaining undetermined edge
is further verified to deliver the exact answer. Extensive experiments are
conducted on 15 real networks. The results show that EVE significantly
outperforms all baselines by several orders of magnitude. Moreover, by taking
EVE as a built-in block, state-of-the-art for hop-constrained simple path
enumeration can be accelerated by up to an order of magnitude.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yuzheng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Weiguo Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xuemin Lin</a></p><p>Graphs have been widely used in real-world applications, in which
investigating relations between vertices is an important task. In this paper,
we study the problem of generating the k-hop-constrained s-t simple path graph,
i.e., the subgraph consisting of all simple paths from vertex s to vertex t of
length no larger than k. To our best knowledge, we are the first to formalize
this problem and prove its NP-hardness on directed graphs. To tackle this
challenging problem, we propose an efficient algorithm named EVE, which
exploits the paradigm of edge-wise examination rather than exhaustively
enumerating all paths. Powered by essential vertices appearing in all simple
paths between vertex pairs, EVE distinguishes the edges that are definitely (or
not) contained in the desired simple path graph, producing a tight upper-bound
graph in the time cost $\mathcal{O}(k^2|E|)$. Each remaining undetermined edge
is further verified to deliver the exact answer. Extensive experiments are
conducted on 15 real networks. The results show that EVE significantly
outperforms all baselines by several orders of magnitude. Moreover, by taking
EVE as a built-in block, state-of-the-art for hop-constrained simple path
enumeration can be accelerated by up to an order of magnitude.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12779'>An Approximation Algorithm for Covering Vertices by 4^+-Paths</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mingyang Gong, Zhi-Zhong Chen, Guohui Lin, Zhaohui Zhan</p><p>This paper deals with the problem of finding a collection of vertex-disjoint
paths in a given graph G=(V,E) such that each path has at least four vertices
and the total number of vertices in these paths is maximized. The problem is
NP-hard and admits an approximation algorithm which achieves a ratio of 2 and
runs in O(|V|^8) time. The known algorithm is based on time-consuming local
search, and its authors ask whether one can design a better approximation
algorithm by a completely different approach. In this paper, we answer their
question in the affirmative by presenting a new approximation algorithm for the
problem. Our algorithm achieves a ratio of 1.874 and runs in O(min{|E|^2|V|^2,
|V|^5}) time. Unlike the previously best algorithm, ours starts with a maximum
matching M of G and then tries to transform M into a solution by utilizing a
maximum-weight path-cycle cover in a suitably constructed graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Mingyang Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhi-Zhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guohui Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_Z/0/1/0/all/0/1">Zhaohui Zhan</a></p><p>This paper deals with the problem of finding a collection of vertex-disjoint
paths in a given graph G=(V,E) such that each path has at least four vertices
and the total number of vertices in these paths is maximized. The problem is
NP-hard and admits an approximation algorithm which achieves a ratio of 2 and
runs in O(|V|^8) time. The known algorithm is based on time-consuming local
search, and its authors ask whether one can design a better approximation
algorithm by a completely different approach. In this paper, we answer their
question in the affirmative by presenting a new approximation algorithm for the
problem. Our algorithm achieves a ratio of 1.874 and runs in O(min{|E|^2|V|^2,
|V|^5}) time. Unlike the previously best algorithm, ours starts with a maximum
matching M of G and then tries to transform M into a solution by utilizing a
maximum-weight path-cycle cover in a suitably constructed graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12872'>Anti-crossings occurrence as exponentially closing gaps in Quantum Annealing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arthur Braida, Simon Martiel, Ioan Todinca</p><p>This paper explores the phenomenon of avoided level crossings in quantum
annealing, a promising framework for quantum computing that may provide a
quantum advantage for certain tasks. Quantum annealing involves letting a
quantum system evolve according to the Schr\"odinger equation, with the goal of
obtaining the optimal solution to an optimization problem through measurements
of the final state. However, the continuous nature of quantum annealing makes
analytical analysis challenging, particularly with regard to the instantaneous
eigenenergies. The adiabatic theorem provides a theoretical result for the
annealing time required to obtain the optimal solution with high probability,
which is inversely proportional to the square of the minimum spectral gap.
Avoided level crossings can create exponentially closing gaps, which can lead
to exponentially long running times for optimization problems. In this paper,
we use a perturbative expansion to derive a condition for the occurrence of an
avoided level crossing during the annealing process. We then apply this
condition to the MaxCut problem on bipartite graphs. We show that no
exponentially small gaps arise for regular bipartite graphs, implying that QA
can efficiently solve MaxCut in that case. On the other hand, we show that
irregularities in the vertex degrees can lead to the satisfaction of the
avoided level crossing occurrence condition. We provide numerical evidence to
support this theoretical development, and discuss the relation between the
presence of exponentially closing gaps and the failure of quantum annealing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Braida_A/0/1/0/all/0/1">Arthur Braida</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Martiel_S/0/1/0/all/0/1">Simon Martiel</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Todinca_I/0/1/0/all/0/1">Ioan Todinca</a></p><p>This paper explores the phenomenon of avoided level crossings in quantum
annealing, a promising framework for quantum computing that may provide a
quantum advantage for certain tasks. Quantum annealing involves letting a
quantum system evolve according to the Schr\"odinger equation, with the goal of
obtaining the optimal solution to an optimization problem through measurements
of the final state. However, the continuous nature of quantum annealing makes
analytical analysis challenging, particularly with regard to the instantaneous
eigenenergies. The adiabatic theorem provides a theoretical result for the
annealing time required to obtain the optimal solution with high probability,
which is inversely proportional to the square of the minimum spectral gap.
Avoided level crossings can create exponentially closing gaps, which can lead
to exponentially long running times for optimization problems. In this paper,
we use a perturbative expansion to derive a condition for the occurrence of an
avoided level crossing during the annealing process. We then apply this
condition to the MaxCut problem on bipartite graphs. We show that no
exponentially small gaps arise for regular bipartite graphs, implying that QA
can efficiently solve MaxCut in that case. On the other hand, we show that
irregularities in the vertex degrees can lead to the satisfaction of the
avoided level crossing occurrence condition. We provide numerical evidence to
support this theoretical development, and discuss the relation between the
presence of exponentially closing gaps and the failure of quantum annealing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12875'>Alternating Local Enumeration (TnALE): Solving Tensor Network Structure Search with Fewer Evaluations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chao Li, Junhua Zeng, Chunmei Li, Cesar Caiafa, Qibin Zhao</p><p>Tensor network (TN) is a powerful framework in machine learning, but
selecting a good TN model, known as TN structure search (TN-SS), is a
challenging and computationally intensive task. The recent approach
TNLS~\cite{li2022permutation} showed promising results for this task, however,
its computational efficiency is still unaffordable, requiring too many
evaluations of the objective function. We propose TnALE, a new algorithm that
updates each structure-related variable alternately by local enumeration,
\emph{greatly} reducing the number of evaluations compared to TNLS. We
theoretically investigate the descent steps for TNLS and TnALE, proving that
both algorithms can achieve linear convergence up to a constant if a sufficient
reduction of the objective is \emph{reached} in each neighborhood. We also
compare the evaluation efficiency of TNLS and TnALE, revealing that
$\Omega(2^N)$ evaluations are typically required in TNLS for \emph{reaching}
the objective reduction in the neighborhood, while ideally $O(N^2R)$
evaluations are sufficient in TnALE, where $N$ denotes the tensor order and $R$
reflects the \emph{``low-rankness''} of the neighborhood. Experimental results
verify that TnALE can find practically good TN-ranks and permutations with
vastly fewer evaluations than the state-of-the-art algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1">Junhua Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunmei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Caiafa_C/0/1/0/all/0/1">Cesar Caiafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qibin Zhao</a></p><p>Tensor network (TN) is a powerful framework in machine learning, but
selecting a good TN model, known as TN structure search (TN-SS), is a
challenging and computationally intensive task. The recent approach
TNLS~\cite{li2022permutation} showed promising results for this task, however,
its computational efficiency is still unaffordable, requiring too many
evaluations of the objective function. We propose TnALE, a new algorithm that
updates each structure-related variable alternately by local enumeration,
\emph{greatly} reducing the number of evaluations compared to TNLS. We
theoretically investigate the descent steps for TNLS and TnALE, proving that
both algorithms can achieve linear convergence up to a constant if a sufficient
reduction of the objective is \emph{reached} in each neighborhood. We also
compare the evaluation efficiency of TNLS and TnALE, revealing that
$\Omega(2^N)$ evaluations are typically required in TNLS for \emph{reaching}
the objective reduction in the neighborhood, while ideally $O(N^2R)$
evaluations are sufficient in TnALE, where $N$ denotes the tensor order and $R$
reflects the \emph{``low-rankness''} of the neighborhood. Experimental results
verify that TnALE can find practically good TN-ranks and permutations with
vastly fewer evaluations than the state-of-the-art algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12967'>The Incremental Knapsack Problem with Monotone Submodular All-or-Nothing Profits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Federico D&#x27;Onofrio, Yuri Faenza, Lingyi Zhang</p><p>We study incremental knapsack problems with profits given by a special class
of monotone submodular functions, that we dub all-or-nothing. We show that
these problems are not harder to approximate than a less general class of
modular incremental knapsack problems, that have been investigated in the
literature. We also show that certain extensions to more general submodular
functions are APX-hard.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+DOnofrio_F/0/1/0/all/0/1">Federico D&#x27;Onofrio</a>, <a href="http://arxiv.org/find/cs/1/au:+Faenza_Y/0/1/0/all/0/1">Yuri Faenza</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lingyi Zhang</a></p><p>We study incremental knapsack problems with profits given by a special class
of monotone submodular functions, that we dub all-or-nothing. We show that
these problems are not harder to approximate than a less general class of
modular incremental knapsack problems, that have been investigated in the
literature. We also show that certain extensions to more general submodular
functions are APX-hard.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12992'>Faster High Accuracy Multi-Commodity Flow from Single-Commodity Techniques</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jan van den Brand, Daniel Zhang</p><p>Since the development of efficient linear program solvers in the 80s, all
major improvements for solving multi-commodity flows to high accuracy came from
improvements to general linear program solvers. This differs from the single
commodity problem (e.g.~maximum flow) where all recent improvements also rely
on graph specific techniques such as graph decompositions or the Laplacian
paradigm (see e.g.~[CMSV17,KLS20,BLL+21,CKL+22]).
</p>
<p>This phenomenon sparked research to understand why these graph techniques are
unlikely to help for multi-commodity flow. [Kyng, Zhang'20] reduced solving
multi-commodity Laplacians to general linear systems and [Ding, Kyng, Zhang'22]
showed that general linear programs can be reduced to 2-commodity flow.
However, the reductions create sparse graph instances, so improvement to
multi-commodity flows on denser graphs might exist.
</p>
<p>We show that one can indeed speed up multi-commodity flow algorithms on
non-sparse graphs using graph techniques from single-commodity flow algorithms.
This is the first improvement to high accuracy multi-commodity flow algorithms
that does not just stem from improvements to general linear program solvers. In
particular, using graph data structures from recent min-cost flow algorithm by
[BLL+21] based on the celebrated expander decomposition framework, we show that
2-commodity flow on an $n$-vertex $m$-edge graph can be solved in
$\tilde{O}(\sqrt{m}n^{\omega-1/2})$ time for current bounds on fast matrix
multiplication $\omega \approx 2.373$, improving upon the previous fastest
algorithms with $\tilde{O}(m^\omega)$ [CLS19] and $\tilde{O}(\sqrt{m}n^2)$
[KV96] time complexity. For general $k$ commodities, our algorithm runs in
$\tilde{O}(k^{2.5}\sqrt{m}n^{\omega-1/2})$ time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brand_J/0/1/0/all/0/1">Jan van den Brand</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Daniel Zhang</a></p><p>Since the development of efficient linear program solvers in the 80s, all
major improvements for solving multi-commodity flows to high accuracy came from
improvements to general linear program solvers. This differs from the single
commodity problem (e.g.~maximum flow) where all recent improvements also rely
on graph specific techniques such as graph decompositions or the Laplacian
paradigm (see e.g.~[CMSV17,KLS20,BLL+21,CKL+22]).
</p>
<p>This phenomenon sparked research to understand why these graph techniques are
unlikely to help for multi-commodity flow. [Kyng, Zhang'20] reduced solving
multi-commodity Laplacians to general linear systems and [Ding, Kyng, Zhang'22]
showed that general linear programs can be reduced to 2-commodity flow.
However, the reductions create sparse graph instances, so improvement to
multi-commodity flows on denser graphs might exist.
</p>
<p>We show that one can indeed speed up multi-commodity flow algorithms on
non-sparse graphs using graph techniques from single-commodity flow algorithms.
This is the first improvement to high accuracy multi-commodity flow algorithms
that does not just stem from improvements to general linear program solvers. In
particular, using graph data structures from recent min-cost flow algorithm by
[BLL+21] based on the celebrated expander decomposition framework, we show that
2-commodity flow on an $n$-vertex $m$-edge graph can be solved in
$\tilde{O}(\sqrt{m}n^{\omega-1/2})$ time for current bounds on fast matrix
multiplication $\omega \approx 2.373$, improving upon the previous fastest
algorithms with $\tilde{O}(m^\omega)$ [CLS19] and $\tilde{O}(\sqrt{m}n^2)$
[KV96] time complexity. For general $k$ commodities, our algorithm runs in
$\tilde{O}(k^{2.5}\sqrt{m}n^{\omega-1/2})$ time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, April 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11325'>Deterministic identity testing paradigms for bounded top-fanin depth-4 circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pranjal Dutta, Prateek Dwivedi, Nitin Saxena</p><p>Polynomial Identity Testing (PIT) is a fundamental computational problem. The
famous depth-$4$ reduction result by Agrawal and Vinay (FOCS 2008) has made PIT
for depth-$4$ circuits an enticing pursuit. A restricted depth-4 circuit
computing a $n$-variate degree-$d$ polynomial of the form $\sum_{i = 1}^{k}
\prod_{j} g_{ij}$, where $\deg g_{ij} \leq \delta$ is called
$\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ circuit. On further restricting $g_{ij}$
to be sum of univariates we obtain $\Sigma^{[k]}\Pi\Sigma\wedge$ circuits. The
largely open, special-cases of $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ for
constant $k$ and $\delta$, and $\Sigma^{[k]}\Pi\Sigma\wedge$ have been a source
of many great ideas in the last two decades. For eg. depth-$3$ ideas of Dvir
and Shpilka (STOC 2005), Kayal and Saxena (CCC 2006), and Saxena and Seshadhri
(FOCS 2010 and STOC 2011). Further, depth-$4$ ideas of Beecken, Mittmann and
Saxena (ICALP 2011), Saha, Saxena and Saptharishi (Comput.Compl. 2013), Forbes
(FOCS 2015), and Kumar and Saraf (CCC 2016). Additionally, geometric
Sylvester-Gallai ideas of Kayal and Saraf (FOCS 2009), Shpilka (STOC 2019), and
Peleg and Shpilka (CCC 2020, STOC 2021). Very recently, a subexponential-time
blackbox PIT algorithm for constant-depth circuits was obtained via lower bound
breakthrough of Limaye, Srinivasan, Tavenas (FOCS 2021). We solve two of the
basic underlying open problems in this work.
</p>
<p>We give the first polynomial-time PIT for $\Sigma^{[k]}\Pi\Sigma\wedge$. We
also give the first quasipolynomial time blackbox PIT for both
$\Sigma^{[k]}\Pi\Sigma\wedge$ and $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$. A key
technical ingredient in all the three algorithms is how the logarithmic
derivative, and its power-series, modify the top $\Pi$-gate to $\wedge$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dutta_P/0/1/0/all/0/1">Pranjal Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwivedi_P/0/1/0/all/0/1">Prateek Dwivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_N/0/1/0/all/0/1">Nitin Saxena</a></p><p>Polynomial Identity Testing (PIT) is a fundamental computational problem. The
famous depth-$4$ reduction result by Agrawal and Vinay (FOCS 2008) has made PIT
for depth-$4$ circuits an enticing pursuit. A restricted depth-4 circuit
computing a $n$-variate degree-$d$ polynomial of the form $\sum_{i = 1}^{k}
\prod_{j} g_{ij}$, where $\deg g_{ij} \leq \delta$ is called
$\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ circuit. On further restricting $g_{ij}$
to be sum of univariates we obtain $\Sigma^{[k]}\Pi\Sigma\wedge$ circuits. The
largely open, special-cases of $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ for
constant $k$ and $\delta$, and $\Sigma^{[k]}\Pi\Sigma\wedge$ have been a source
of many great ideas in the last two decades. For eg. depth-$3$ ideas of Dvir
and Shpilka (STOC 2005), Kayal and Saxena (CCC 2006), and Saxena and Seshadhri
(FOCS 2010 and STOC 2011). Further, depth-$4$ ideas of Beecken, Mittmann and
Saxena (ICALP 2011), Saha, Saxena and Saptharishi (Comput.Compl. 2013), Forbes
(FOCS 2015), and Kumar and Saraf (CCC 2016). Additionally, geometric
Sylvester-Gallai ideas of Kayal and Saraf (FOCS 2009), Shpilka (STOC 2019), and
Peleg and Shpilka (CCC 2020, STOC 2021). Very recently, a subexponential-time
blackbox PIT algorithm for constant-depth circuits was obtained via lower bound
breakthrough of Limaye, Srinivasan, Tavenas (FOCS 2021). We solve two of the
basic underlying open problems in this work.
</p>
<p>We give the first polynomial-time PIT for $\Sigma^{[k]}\Pi\Sigma\wedge$. We
also give the first quasipolynomial time blackbox PIT for both
$\Sigma^{[k]}\Pi\Sigma\wedge$ and $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$. A key
technical ingredient in all the three algorithms is how the logarithmic
derivative, and its power-series, modify the top $\Pi$-gate to $\wedge$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11495'>Explicit Directional Affine Extractors and Improved Hardness for Linear Branching Programs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xin Li, Yan Zhong</p><p>In a recent work, Gryaznov, Pudl\'{a}k, and Talebanfard (CCC' 22) introduced
a stronger version of affine extractors known as directional affine extractors,
together with a generalization of $\mathsf{ROBP}$s where each node can make
linear queries, and showed that the former implies strong lower bound for a
certain type of the latter known as strongly read-once linear branching
programs ($\mathsf{SROLBP}$s). Their main result gives explicit constructions
of directional affine extractors for entropy $k &gt; 2n/3$, which implies
average-case complexity $2^{n/3-o(n)}$ against $\mathsf{SROLBP}$s with
exponentially small correlation. A follow-up work by Chattopadhyay and Liao
(ECCC' 22) improves the hardness to $2^{n-o(n)}$ at the price of increasing the
correlation to polynomially large.
</p>
<p>This paper provides a much more in-depth study of directional affine
extractors, $\mathsf{SROLBP}$s, and $\mathsf{ROBP}$s. Our main results include:
</p>
<p>A formal separation between $\mathsf{SROLBP}$ and $\mathsf{ROBP}$, showing
that $\mathsf{SROLBP}$s can be exponentially more powerful than
$\mathsf{ROBP}$s.
</p>
<p>An explicit construction of directional affine extractors with $k=o(n)$ and
exponentially small error, which gives average-case complexity $2^{n-o(n)}$
against $\mathsf{SROLBP}$s with exponentially small correlation, thus answering
the two open questions raised in previous works.
</p>
<p>An explicit function in $\mathsf{AC}^0$ that gives average-case complexity
$2^{(1-\delta)n}$ against $\mathsf{ROBP}$s with negligible correlation, for any
constant $\delta&gt;0$. Previously, the best size lower bound for any function in
$\mathsf{AC}^0$ against $\mathsf{ROBP}$s is only $2^{\Omega(\sqrt{n})}$.
</p>
<p>One of the key ingredients in our constructions is a new linear somewhere
condenser for affine sources.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yan Zhong</a></p><p>In a recent work, Gryaznov, Pudl\'{a}k, and Talebanfard (CCC' 22) introduced
a stronger version of affine extractors known as directional affine extractors,
together with a generalization of $\mathsf{ROBP}$s where each node can make
linear queries, and showed that the former implies strong lower bound for a
certain type of the latter known as strongly read-once linear branching
programs ($\mathsf{SROLBP}$s). Their main result gives explicit constructions
of directional affine extractors for entropy $k &gt; 2n/3$, which implies
average-case complexity $2^{n/3-o(n)}$ against $\mathsf{SROLBP}$s with
exponentially small correlation. A follow-up work by Chattopadhyay and Liao
(ECCC' 22) improves the hardness to $2^{n-o(n)}$ at the price of increasing the
correlation to polynomially large.
</p>
<p>This paper provides a much more in-depth study of directional affine
extractors, $\mathsf{SROLBP}$s, and $\mathsf{ROBP}$s. Our main results include:
</p>
<p>A formal separation between $\mathsf{SROLBP}$ and $\mathsf{ROBP}$, showing
that $\mathsf{SROLBP}$s can be exponentially more powerful than
$\mathsf{ROBP}$s.
</p>
<p>An explicit construction of directional affine extractors with $k=o(n)$ and
exponentially small error, which gives average-case complexity $2^{n-o(n)}$
against $\mathsf{SROLBP}$s with exponentially small correlation, thus answering
the two open questions raised in previous works.
</p>
<p>An explicit function in $\mathsf{AC}^0$ that gives average-case complexity
$2^{(1-\delta)n}$ against $\mathsf{ROBP}$s with negligible correlation, for any
constant $\delta&gt;0$. Previously, the best size lower bound for any function in
$\mathsf{AC}^0$ against $\mathsf{ROBP}$s is only $2^{\Omega(\sqrt{n})}$.
</p>
<p>One of the key ingredients in our constructions is a new linear somewhere
condenser for affine sources.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11429'>The Voronoi Diagram of Rotating Rays with applications to Floodlight Illumination</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Carlos Alegr&#xed;a, Ioannis Mantas, Evanthia Papadopoulou, Marko Savi&#x107;, Carlos Seara, Martin Suderland</p><p>We study the Voronoi Diagram of Rotating Rays, a Voronoi structure where the
input sites are rays and the distance function between a point and a site/ray,
is the counterclockwise angular distance. This novel Voronoi diagram is
motivated by illumination or coverage problems, where a domain must be covered
by floodlights/wedges of uniform angle, and the goal is to find the minimum
angle necessary to cover the domain. We study the diagram in the plane, and we
present structural properties, combinatorial complexity bounds, and a
construction algorithm. If the rays are induced by a convex polygon, we show
how to construct the Voronoi diagram within this polygon in linear time. Using
this information, we can find in optimal linear time the Brocard angle, the
minimum angle required to illuminate a convex polygon with floodlights of
uniform angle.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alegria_C/0/1/0/all/0/1">Carlos Alegr&#xed;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Mantas_I/0/1/0/all/0/1">Ioannis Mantas</a>, <a href="http://arxiv.org/find/cs/1/au:+Papadopoulou_E/0/1/0/all/0/1">Evanthia Papadopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Savic_M/0/1/0/all/0/1">Marko Savi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Seara_C/0/1/0/all/0/1">Carlos Seara</a>, <a href="http://arxiv.org/find/cs/1/au:+Suderland_M/0/1/0/all/0/1">Martin Suderland</a></p><p>We study the Voronoi Diagram of Rotating Rays, a Voronoi structure where the
input sites are rays and the distance function between a point and a site/ray,
is the counterclockwise angular distance. This novel Voronoi diagram is
motivated by illumination or coverage problems, where a domain must be covered
by floodlights/wedges of uniform angle, and the goal is to find the minimum
angle necessary to cover the domain. We study the diagram in the plane, and we
present structural properties, combinatorial complexity bounds, and a
construction algorithm. If the rays are induced by a convex polygon, we show
how to construct the Voronoi diagram within this polygon in linear time. Using
this information, we can find in optimal linear time the Brocard angle, the
minimum angle required to illuminate a convex polygon with floodlights of
uniform angle.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11252'>High-Accuracy Multicommodity Flows via Iterative Refinement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Li Chen, Mingquan Ye</p><p>The multicommodity flow problem is a classic problem in network flow and
combinatorial optimization, with applications in transportation, communication,
logistics, and supply chain management, etc. Existing algorithms often focus on
low-accuracy approximate solutions, while high-accuracy algorithms typically
rely on general linear program solvers. In this paper, we present efficient
high-accuracy algorithms for a broad family of multicommodity flow problems on
undirected graphs, demonstrating improved running times compared to general
linear program solvers. Our main result shows that we can solve the $\ell_{q,
p}$-norm multicommodity flow problem to a $(1 + \varepsilon)$ approximation in
time $O_{q, p}(m^{1+o(1)} k^2 \log(1 / \varepsilon))$, where $k$ is the number
of commodities, and $O_{q, p}(\cdot)$ hides constants depending only on $q$ or
$p$. As $q$ and $p$ approach to $1$ and infinity respectively, $\ell_{q,
p}$-norm flow tends to maximum concurrent flow.
</p>
<p>We introduce the first iterative refinement framework for $\ell_{q, p}$-norm
minimization problems, which reduces the problem to solving a series of
decomposable residual problems. In the case of $k$-commodity flow, each
residual problem can be decomposed into $k$ single commodity convex flow
problems, each of which can be solved in almost-linear time. As many classical
variants of multicommodity flows were shown to be complete for linear programs
in the high-accuracy regime [Ding-Kyng-Zhang, ICALP'22], our result provides
new directions for studying more efficient high-accuracy multicommodity flow
algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Mingquan Ye</a></p><p>The multicommodity flow problem is a classic problem in network flow and
combinatorial optimization, with applications in transportation, communication,
logistics, and supply chain management, etc. Existing algorithms often focus on
low-accuracy approximate solutions, while high-accuracy algorithms typically
rely on general linear program solvers. In this paper, we present efficient
high-accuracy algorithms for a broad family of multicommodity flow problems on
undirected graphs, demonstrating improved running times compared to general
linear program solvers. Our main result shows that we can solve the $\ell_{q,
p}$-norm multicommodity flow problem to a $(1 + \varepsilon)$ approximation in
time $O_{q, p}(m^{1+o(1)} k^2 \log(1 / \varepsilon))$, where $k$ is the number
of commodities, and $O_{q, p}(\cdot)$ hides constants depending only on $q$ or
$p$. As $q$ and $p$ approach to $1$ and infinity respectively, $\ell_{q,
p}$-norm flow tends to maximum concurrent flow.
</p>
<p>We introduce the first iterative refinement framework for $\ell_{q, p}$-norm
minimization problems, which reduces the problem to solving a series of
decomposable residual problems. In the case of $k$-commodity flow, each
residual problem can be decomposed into $k$ single commodity convex flow
problems, each of which can be solved in almost-linear time. As many classical
variants of multicommodity flows were shown to be complete for linear programs
in the high-accuracy regime [Ding-Kyng-Zhang, ICALP'22], our result provides
new directions for studying more efficient high-accuracy multicommodity flow
algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11281'>Euclidean Capacitated Vehicle Routing in Random Setting: A $1.55$-Approximation Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zipei Nie, Hang Zhou</p><p>We study the unit-demand capacitated vehicle routing problem in the random
setting of the Euclidean plane. The objective is to visit $n$ random terminals
in a square using a set of tours of minimum total length, such that each tour
visits the depot and at most $k$ terminals.
</p>
<p>We design an elegant algorithm combining the classical sweep heuristic and
Arora's framework for the Euclidean traveling salesman problem [Journal of the
ACM 1998]. We show that our algorithm is a polynomial-time approximation of
ratio at most $1.55$ asymptotically almost surely. This improves on previous
approximation ratios of $1.995$ due to Bompadre, Dror, and Orlin [Journal of
Applied Probability 2007] and $1.915$ due to Mathieu and Zhou [Random
Structures and Algorithms 2022]. In addition, we conjecture that, for any
$\varepsilon&gt;0$, our algorithm is a $(1+\varepsilon)$-approximation
asymptotically almost surely.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nie_Z/0/1/0/all/0/1">Zipei Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hang Zhou</a></p><p>We study the unit-demand capacitated vehicle routing problem in the random
setting of the Euclidean plane. The objective is to visit $n$ random terminals
in a square using a set of tours of minimum total length, such that each tour
visits the depot and at most $k$ terminals.
</p>
<p>We design an elegant algorithm combining the classical sweep heuristic and
Arora's framework for the Euclidean traveling salesman problem [Journal of the
ACM 1998]. We show that our algorithm is a polynomial-time approximation of
ratio at most $1.55$ asymptotically almost surely. This improves on previous
approximation ratios of $1.995$ due to Bompadre, Dror, and Orlin [Journal of
Applied Probability 2007] and $1.915$ due to Mathieu and Zhou [Random
Structures and Algorithms 2022]. In addition, we conjecture that, for any
$\varepsilon&gt;0$, our algorithm is a $(1+\varepsilon)$-approximation
asymptotically almost surely.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11691'>Covering multigraphs with bipartite graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jaehoon Kim, Hyunwoo Lee</p><p>Hansel's lemma states that $\sum_{H\in \mathcal{H}}|H| \geq n \log_2 n$ holds
where $\mathcal{H}$ is a collection of bipartite graphs covering all the edges
of $K_n$. We generalize this lemma to the corresponding multigraph covering
problem and the graphon covering problem. We also prove an upper bound on
$\sum_{H\in \mathcal{H}}|H|$ which shows that our generalization is
asymptotically tight in some sense.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Kim_J/0/1/0/all/0/1">Jaehoon Kim</a>, <a href="http://arxiv.org/find/math/1/au:+Lee_H/0/1/0/all/0/1">Hyunwoo Lee</a></p><p>Hansel's lemma states that $\sum_{H\in \mathcal{H}}|H| \geq n \log_2 n$ holds
where $\mathcal{H}$ is a collection of bipartite graphs covering all the edges
of $K_n$. We generalize this lemma to the corresponding multigraph covering
problem and the graphon covering problem. We also prove an upper bound on
$\sum_{H\in \mathcal{H}}|H|$ which shows that our generalization is
asymptotically tight in some sense.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, April 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10570'>Geometry of Tensors: Open problems and research directions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fulvio Gesmundo</p><p>This is a collection of open problems and research ideas following the
presentations and the discussions of the AGATES Kickoff Workshop held at the
Institute of Mathematics of the Polish Academy of Sciences (IMPAN) and at the
Department of Mathematics of University of Warsaw (MIM UW), September 19-26,
2022.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gesmundo_F/0/1/0/all/0/1">Fulvio Gesmundo</a></p><p>This is a collection of open problems and research ideas following the
presentations and the discussions of the AGATES Kickoff Workshop held at the
Institute of Mathematics of the Polish Academy of Sciences (IMPAN) and at the
Department of Mathematics of University of Warsaw (MIM UW), September 19-26,
2022.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10594'>Comparative Analysis of Deterministic and Nondeterministic Decision Trees for Decision Tables from Closed Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Azimkhon Ostonov, Mikhail Moshkov</p><p>In this paper, we consider classes of decision tables with many-valued
decisions closed under operations of removal of columns, changing of decisions,
permutation of columns, and duplication of columns. We study relationships
among three parameters of these tables: the complexity of a decision table (if
we consider the depth of decision trees, then the complexity of a decision
table is the number of columns in it), the minimum complexity of a
deterministic decision tree, and the minimum complexity of a nondeterministic
decision tree. We consider rough classification of functions characterizing
relationships and enumerate all possible seven types of the relationships.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ostonov_A/0/1/0/all/0/1">Azimkhon Ostonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshkov_M/0/1/0/all/0/1">Mikhail Moshkov</a></p><p>In this paper, we consider classes of decision tables with many-valued
decisions closed under operations of removal of columns, changing of decisions,
permutation of columns, and duplication of columns. We study relationships
among three parameters of these tables: the complexity of a decision table (if
we consider the depth of decision trees, then the complexity of a decision
table is the number of columns in it), the minimum complexity of a
deterministic decision tree, and the minimum complexity of a nondeterministic
decision tree. We consider rough classification of functions characterizing
relationships and enumerate all possible seven types of the relationships.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10661'>A Conjecture Related to the Traveling Salesman Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jian Yang</p><p>We show that certain ways of solving some combinatorial optimization problems
can be understood as using query planes to divide the space of problem
instances into polyhedra that could fit into those that characterize the
problem's various solutions. This viewpoint naturally leads to a
splinter-proneness property that is then shown to be responsible for the
hardness of the concerned problem. We conjecture that the $NP$-equivalent
traveling salesman problem (TSP) has this property and hence is hard to solve
to a certain extent.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jian Yang</a></p><p>We show that certain ways of solving some combinatorial optimization problems
can be understood as using query planes to divide the space of problem
instances into polyhedra that could fit into those that characterize the
problem's various solutions. This viewpoint naturally leads to a
splinter-proneness property that is then shown to be responsible for the
hardness of the concerned problem. We conjecture that the $NP$-equivalent
traveling salesman problem (TSP) has this property and hence is hard to solve
to a certain extent.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11017'>Breaking the Log Barrier: a Novel Universal Restart Strategy for Faster Las Vegas Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kevin Scaman</p><p>Let $\mathcal{A}$ be a Las Vegas algorithm, i.e. an algorithm whose running
time $T$ is a random variable drawn according to a certain probability
distribution $p$. In 1993, Luby, Sinclair and Zuckerman [LSZ93] proved that a
simple universal restart strategy can, for any probability distribution $p$,
provide an algorithm executing $\mathcal{A}$ and whose expected running time is
$O(\ell^\star_p\log\ell^\star_p)$, where $\ell^\star_p=\Theta\left(\inf_{q\in
(0,1]}Q_p(q)/q\right)$ is the minimum expected running time achievable with
full prior knowledge of the probability distribution $p$, and $Q_p(q)$ is the
$q$-quantile of $p$. Moreover, the authors showed that the logarithmic term
could not be removed for universal restart strategies and was, in a certain
sense, optimal. In this work, we show that, quite surprisingly, the logarithmic
term can be replaced by a smaller quantity, thus reducing the expected running
time in practical settings of interest. More precisely, we propose a novel
restart strategy that executes $\mathcal{A}$ and whose expected running time is
$O\big(\inf_{q\in (0,1]}\frac{Q_p(q)}{q}\,\psi\big(\log Q_p(q),\,\log
(1/q)\big)\big)$ where $\psi(a,b)=1+\min\left\{a+b,a\log^2 a,\,b\log^2
b\right\}$. This quantity is, up to a multiplicative factor, better than: 1)
the universal restart strategy of [LSZ93], 2) any $q$-quantile of $p$ for
$q\in(0,1]$, 3) the original algorithm, and 4) any quantity of the form
$\phi^{-1}(\mathbb{E}[\phi(T)])$ for a large class of concave functions $\phi$.
The latter extends the recent restart strategy of [Zam22] achieving
$O\left(e^{\mathbb{E}[\ln(T)]}\right)$, and can be thought of as algorithmic
reverse Jensen's inequalities. Finally, we show that the behavior of
$\frac{t\phi''(t)}{\phi'(t)}$ at infinity controls the existence of reverse
Jensen's inequalities by providing a necessary and a sufficient condition for
these inequalities to hold.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Scaman_K/0/1/0/all/0/1">Kevin Scaman</a></p><p>Let $\mathcal{A}$ be a Las Vegas algorithm, i.e. an algorithm whose running
time $T$ is a random variable drawn according to a certain probability
distribution $p$. In 1993, Luby, Sinclair and Zuckerman [LSZ93] proved that a
simple universal restart strategy can, for any probability distribution $p$,
provide an algorithm executing $\mathcal{A}$ and whose expected running time is
$O(\ell^\star_p\log\ell^\star_p)$, where $\ell^\star_p=\Theta\left(\inf_{q\in
(0,1]}Q_p(q)/q\right)$ is the minimum expected running time achievable with
full prior knowledge of the probability distribution $p$, and $Q_p(q)$ is the
$q$-quantile of $p$. Moreover, the authors showed that the logarithmic term
could not be removed for universal restart strategies and was, in a certain
sense, optimal. In this work, we show that, quite surprisingly, the logarithmic
term can be replaced by a smaller quantity, thus reducing the expected running
time in practical settings of interest. More precisely, we propose a novel
restart strategy that executes $\mathcal{A}$ and whose expected running time is
$O\big(\inf_{q\in (0,1]}\frac{Q_p(q)}{q}\,\psi\big(\log Q_p(q),\,\log
(1/q)\big)\big)$ where $\psi(a,b)=1+\min\left\{a+b,a\log^2 a,\,b\log^2
b\right\}$. This quantity is, up to a multiplicative factor, better than: 1)
the universal restart strategy of [LSZ93], 2) any $q$-quantile of $p$ for
$q\in(0,1]$, 3) the original algorithm, and 4) any quantity of the form
$\phi^{-1}(\mathbb{E}[\phi(T)])$ for a large class of concave functions $\phi$.
The latter extends the recent restart strategy of [Zam22] achieving
$O\left(e^{\mathbb{E}[\ln(T)]}\right)$, and can be thought of as algorithmic
reverse Jensen's inequalities. Finally, we show that the behavior of
$\frac{t\phi''(t)}{\phi'(t)}$ at infinity controls the existence of reverse
Jensen's inequalities by providing a necessary and a sufficient condition for
these inequalities to hold.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11102'>Solid angle measure of polyhedral cones</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Allison Fitisone, Yuan Zhou</p><p>This paper addresses the computation of normalized solid angle measure of
polyhedral cones. This is well understood in dimensions two and three. For
higher dimensions, assuming that a positive-definite criterion is met, the
measure can be computed via a multivariable hypergeometric series. We present
two decompositions of full-dimensional simplicial cones into finite families of
cones satisfying the positive-definite criterion, enabling the use of the
hypergeometric series to compute the solid angle measure of any polyhedral
cone. Additionally, our second decomposition method yields cones with a special
tridiagonal structure, reducing the number of required coordinates for the
hypergeometric series formula. Furthermore, we investigate the convergence of
the hypergeometric series for this case. Our findings provide a powerful tool
for computing solid angle measures in high-dimensional spaces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Fitisone_A/0/1/0/all/0/1">Allison Fitisone</a>, <a href="http://arxiv.org/find/math/1/au:+Zhou_Y/0/1/0/all/0/1">Yuan Zhou</a></p><p>This paper addresses the computation of normalized solid angle measure of
polyhedral cones. This is well understood in dimensions two and three. For
higher dimensions, assuming that a positive-definite criterion is met, the
measure can be computed via a multivariable hypergeometric series. We present
two decompositions of full-dimensional simplicial cones into finite families of
cones satisfying the positive-definite criterion, enabling the use of the
hypergeometric series to compute the solid angle measure of any polyhedral
cone. Additionally, our second decomposition method yields cones with a special
tridiagonal structure, reducing the number of required coordinates for the
hypergeometric series formula. Furthermore, we investigate the convergence of
the hypergeometric series for this case. Our findings provide a powerful tool
for computing solid angle measures in high-dimensional spaces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10647'>New Lower Bounds for Adaptive Tolerant Junta Testing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xi Chen, Shyamal Patel</p><p>We prove a $k^{-\Omega(\log(\varepsilon_2 - \varepsilon_1))}$ lower bound for
adaptively testing whether a Boolean function is $\varepsilon_1$-close to or
$\varepsilon_2$-far from $k$-juntas. Our results provide the first
superpolynomial separation between tolerant and non-tolerant testing for a
natural property of boolean functions under the adaptive setting. Furthermore,
our techniques generalize to show that adaptively testing whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from $(k +
o(k))$-juntas cannot be done with $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries. This is in contrast to an algorithm by Iyer, Tal
and Whitmeyer [CCC 2021] which uses $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries to test whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from
$O(k/(\varepsilon_2-\varepsilon_1)^2)$-juntas.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1">Shyamal Patel</a></p><p>We prove a $k^{-\Omega(\log(\varepsilon_2 - \varepsilon_1))}$ lower bound for
adaptively testing whether a Boolean function is $\varepsilon_1$-close to or
$\varepsilon_2$-far from $k$-juntas. Our results provide the first
superpolynomial separation between tolerant and non-tolerant testing for a
natural property of boolean functions under the adaptive setting. Furthermore,
our techniques generalize to show that adaptively testing whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from $(k +
o(k))$-juntas cannot be done with $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries. This is in contrast to an algorithm by Iyer, Tal
and Whitmeyer [CCC 2021] which uses $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries to test whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from
$O(k/(\varepsilon_2-\varepsilon_1)^2)$-juntas.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10848'>How Well Does the Metropolis Algorithm Cope With Local Optima?</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benjamin Doerr, Taha El Ghazi El Houssaini, Amirhossein Rajabi, Carsten Wit</p><p>The Metropolis algorithm (MA) is a classic stochastic local search heuristic.
It avoids getting stuck in local optima by occasionally accepting inferior
solutions. To better and in a rigorous manner understand this ability, we
conduct a mathematical runtime analysis of the MA on the CLIFF benchmark. Apart
from one local optimum, cliff functions are monotonically increasing towards
the global optimum. Consequently, to optimize a cliff function, the MA only
once needs to accept an inferior solution. Despite seemingly being an ideal
benchmark for the MA to profit from its main working principle, our
mathematical runtime analysis shows that this hope does not come true. Even
with the optimal temperature (the only parameter of the MA), the MA optimizes
most cliff functions less efficiently than simple elitist evolutionary
algorithms (EAs), which can only leave the local optimum by generating a
superior solution possibly far away. This result suggests that our
understanding of why the MA is often very successful in practice is not yet
complete. Our work also suggests to equip the MA with global mutation
operators, an idea supported by our preliminary experiments.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1">Benjamin Doerr</a>, <a href="http://arxiv.org/find/cs/1/au:+Houssaini_T/0/1/0/all/0/1">Taha El Ghazi El Houssaini</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajabi_A/0/1/0/all/0/1">Amirhossein Rajabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wit_C/0/1/0/all/0/1">Carsten Wit</a></p><p>The Metropolis algorithm (MA) is a classic stochastic local search heuristic.
It avoids getting stuck in local optima by occasionally accepting inferior
solutions. To better and in a rigorous manner understand this ability, we
conduct a mathematical runtime analysis of the MA on the CLIFF benchmark. Apart
from one local optimum, cliff functions are monotonically increasing towards
the global optimum. Consequently, to optimize a cliff function, the MA only
once needs to accept an inferior solution. Despite seemingly being an ideal
benchmark for the MA to profit from its main working principle, our
mathematical runtime analysis shows that this hope does not come true. Even
with the optimal temperature (the only parameter of the MA), the MA optimizes
most cliff functions less efficiently than simple elitist evolutionary
algorithms (EAs), which can only leave the local optimum by generating a
superior solution possibly far away. This result suggests that our
understanding of why the MA is often very successful in practice is not yet
complete. Our work also suggests to equip the MA with global mutation
operators, an idea supported by our preliminary experiments.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10962'>Faster Prefix-Sorting Algorithms for Deterministic Finite Automata</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sung-Hwan Kim, Francisco Olivares, Nicola Prezza</p><p>Sorting is a fundamental algorithmic pre-processing technique which often
allows to represent data more compactly and, at the same time, speeds up search
queries on it. In this paper, we focus on the well-studied problem of sorting
and indexing string sets. Since the introduction of suffix trees in 1973,
dozens of suffix sorting algorithms have been described in the literature. In
2017, these techniques were extended to sets of strings described by means of
finite automata: the theory of Wheeler graphs [Gagie et al., TCS'17] introduced
automata whose states can be totally-sorted according to the co-lexicographic
(co-lex in the following) order of the prefixes of words accepted by the
automaton. More recently, in [Cotumaccio, Prezza, SODA'21] it was shown how to
extend these ideas to arbitrary automata by means of partial co-lex orders.
This work showed that a co-lex order of minimum width (thus optimizing search
query times) on deterministic finite automata (DFAs) can be computed in $O(m^2
+ n^{5/2})$ time, $m$ being the number of transitions and $n$ the number of
states of the input DFA.
</p>
<p>In this paper, we exhibit new combinatorial properties of the minimum-width
co-lex order of DFAs and exploit them to design faster prefix sorting
algorithms. In particular, we describe two algorithms sorting arbitrary DFAs in
$O(mn)$ and $O(n^2\log n)$ time, respectively, and an algorithm sorting acyclic
DFAs in $O(m\log n)$ time. Within these running times, all algorithms compute
also a smallest chain partition of the partial order (required to index the
DFA). We present an experiment result to show that an optimized implementation
of the $O(n^2\log n)$-time algorithm exhibits a nearly-linear behaviour on
large deterministic pan-genomic graphs and is thus also of practical interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sung-Hwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Olivares_F/0/1/0/all/0/1">Francisco Olivares</a>, <a href="http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1">Nicola Prezza</a></p><p>Sorting is a fundamental algorithmic pre-processing technique which often
allows to represent data more compactly and, at the same time, speeds up search
queries on it. In this paper, we focus on the well-studied problem of sorting
and indexing string sets. Since the introduction of suffix trees in 1973,
dozens of suffix sorting algorithms have been described in the literature. In
2017, these techniques were extended to sets of strings described by means of
finite automata: the theory of Wheeler graphs [Gagie et al., TCS'17] introduced
automata whose states can be totally-sorted according to the co-lexicographic
(co-lex in the following) order of the prefixes of words accepted by the
automaton. More recently, in [Cotumaccio, Prezza, SODA'21] it was shown how to
extend these ideas to arbitrary automata by means of partial co-lex orders.
This work showed that a co-lex order of minimum width (thus optimizing search
query times) on deterministic finite automata (DFAs) can be computed in $O(m^2
+ n^{5/2})$ time, $m$ being the number of transitions and $n$ the number of
states of the input DFA.
</p>
<p>In this paper, we exhibit new combinatorial properties of the minimum-width
co-lex order of DFAs and exploit them to design faster prefix sorting
algorithms. In particular, we describe two algorithms sorting arbitrary DFAs in
$O(mn)$ and $O(n^2\log n)$ time, respectively, and an algorithm sorting acyclic
DFAs in $O(m\log n)$ time. Within these running times, all algorithms compute
also a smallest chain partition of the partial order (required to index the
DFA). We present an experiment result to show that an optimized implementation
of the $O(n^2\log n)$-time algorithm exhibits a nearly-linear behaviour on
large deterministic pan-genomic graphs and is thus also of practical interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10995'>Solving the List Coloring Problem through a Branch-and-Price algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mauro Lucci, Daniel Severin, Graciela Nasini</p><p>In this work, we present a branch-and-price algorithm to solve the weighted
version of the List Coloring Problem, based on a vertex cover formulation by
stable sets. This problem is interesting for its applications and also for the
many other problems that it generalizes, including the well-known Graph
Coloring Problem. With the introduction of the concept of indistinguishable
colors, some theoretical results are presented which are later incorporated
into the algorithm. We propose two branching strategies based on others for the
Graph Coloring Problem, the first is an adaptation of the one used by Mehrotra
and Trick in their pioneering branch-and-price algorithm, and the other is
inspired by the one used by M\'endez-D\'iaz and Zabala in their branch-and-cut
algorithm. The rich structure of this problem makes both branching strategies
robust. Extended computation experimentation on a wide variety of instances
shows the effectiveness of this approach and evidences the different behaviors
that the algorithm can have according to the structure of each type of
instance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lucci_M/0/1/0/all/0/1">Mauro Lucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Severin_D/0/1/0/all/0/1">Daniel Severin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasini_G/0/1/0/all/0/1">Graciela Nasini</a></p><p>In this work, we present a branch-and-price algorithm to solve the weighted
version of the List Coloring Problem, based on a vertex cover formulation by
stable sets. This problem is interesting for its applications and also for the
many other problems that it generalizes, including the well-known Graph
Coloring Problem. With the introduction of the concept of indistinguishable
colors, some theoretical results are presented which are later incorporated
into the algorithm. We propose two branching strategies based on others for the
Graph Coloring Problem, the first is an adaptation of the one used by Mehrotra
and Trick in their pioneering branch-and-price algorithm, and the other is
inspired by the one used by M\'endez-D\'iaz and Zabala in their branch-and-cut
algorithm. The rich structure of this problem makes both branching strategies
robust. Extended computation experimentation on a wide variety of instances
shows the effectiveness of this approach and evidences the different behaviors
that the algorithm can have according to the structure of each type of
instance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11012'>Learned Monotone Minimal Perfect Hashing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paolo Ferragina, Hans-Peter Lehmann, Peter Sanders, Giorgio Vinciguerra</p><p>A Monotone Minimal Perfect Hash Function (MMPHF) constructed on a set S of
keys is a function that maps each key in S to its rank. On keys not in S, the
function returns an arbitrary value. Applications range from databases, search
engines, data encryption, to pattern-matching algorithms.
</p>
<p>In this paper, we describe LeMonHash, a new technique for constructing MMPHFs
for integers. The core idea of LeMonHash is surprisingly simple and effective:
we learn a monotone mapping from keys to their rank via an error-bounded
piecewise linear model (the PGM-index), and then we solve the collisions that
might arise among keys mapping to the same rank estimate by associating small
integers with them in a retrieval data structure (BuRR). On synthetic random
datasets, LeMonHash needs 35% less space than the next best competitor, while
achieving about 16 times faster queries. On real-world datasets, the space
usage is very close to or much better than the best competitors, while
achieving up to 19 times faster queries than the next larger competitor. As far
as the construction of LeMonHash is concerned, we get an improvement by a
factor of up to 2, compared to the competitor with the next best space usage.
</p>
<p>We also investigate the case of keys being variable-length strings,
introducing the so-called LeMonHash-VL: it needs space within 10% of the best
competitors while achieving up to 3 times faster queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ferragina_P/0/1/0/all/0/1">Paolo Ferragina</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehmann_H/0/1/0/all/0/1">Hans-Peter Lehmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanders_P/0/1/0/all/0/1">Peter Sanders</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinciguerra_G/0/1/0/all/0/1">Giorgio Vinciguerra</a></p><p>A Monotone Minimal Perfect Hash Function (MMPHF) constructed on a set S of
keys is a function that maps each key in S to its rank. On keys not in S, the
function returns an arbitrary value. Applications range from databases, search
engines, data encryption, to pattern-matching algorithms.
</p>
<p>In this paper, we describe LeMonHash, a new technique for constructing MMPHFs
for integers. The core idea of LeMonHash is surprisingly simple and effective:
we learn a monotone mapping from keys to their rank via an error-bounded
piecewise linear model (the PGM-index), and then we solve the collisions that
might arise among keys mapping to the same rank estimate by associating small
integers with them in a retrieval data structure (BuRR). On synthetic random
datasets, LeMonHash needs 35% less space than the next best competitor, while
achieving about 16 times faster queries. On real-world datasets, the space
usage is very close to or much better than the best competitors, while
achieving up to 19 times faster queries than the next larger competitor. As far
as the construction of LeMonHash is concerned, we get an improvement by a
factor of up to 2, compared to the competitor with the next best space usage.
</p>
<p>We also investigate the case of keys being variable-length strings,
introducing the so-called LeMonHash-VL: it needs space within 10% of the best
competitors while achieving up to 3 times faster queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, April 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/thoughts-on-gordon-moore.html'>Thoughts on Gordon Moore</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;Gordon Moore passed away on March 24, 2023. He was 94 years old.&nbsp;</p><p>He is best known for the article&nbsp;</p><p><br></p><p>Cramming more components onto integrated circuits.&nbsp;</p><p>It appeared in the magazine Electronics (it is now defunct), Volume 38, No. 8, April 19, 1965. Do you need to track it down in the basement of your library. No. Its&nbsp;here&nbsp;and here.&nbsp;I wonder if Moore would have predicted that his article would be available easily over 50 years later. Or is it? Link rot is a serious problem so you might want to download it to your local files. Note that the first link is some sort of official version and the second version is my local version. Not clear which link will rot first. The article also has an addition which is an interview with Moore that was done later.</p><p>In the article Moore said that the number of components-per-circuit (I think that means chip) will double every year. Moore credits Dave House with modifying it to `doubling every 18 months' and Carver Mead with calling it `Moore's Law'.&nbsp; Later it came to be quoted as computer SPEED would double every 18 months. We will take this to be Moore's Law in this blog post.&nbsp;</p><p>Is Moore's law dead? Browsing Google the answer seems to be that it is slowing down but not dead yet. (IDEA for a comedy sketch: Redo the Monty Python Dead Parrot sketch about the death of Moore's law.)&nbsp;</p><p>If Moore had 1 penny in April 1965 and it doubled every 18 months then how rich would he be now? How rich was he in April 2022? Compare the two numbers.&nbsp;</p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;Gordon Moore passed away on March 24, 2023. He was 94 years old.&nbsp;</p><p>He is best known for the article&nbsp;</p><p><br /></p><p><i>Cramming more components onto integrated circuits.&nbsp;</i></p><p>It appeared in the magazine Electronics (it is now defunct), Volume 38, No. 8, April 19, 1965. Do you need to track it down in the basement of your library. No. Its&nbsp;<a href="https://hasler.ece.gatech.edu/Published_papers/Technology_overview/gordon_moore_1965_article.pdf">here</a>&nbsp;and <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/gmoore.pdf">here</a>.&nbsp;I wonder if Moore would have predicted that his article would be available easily over 50 years later. Or is it? Link rot is a serious problem so you might want to download it to your local files. Note that the first link is some sort of official version and the second version is my local version. Not clear which link will rot first. The article also has an addition which is an interview with Moore that was done later.</p><p>In the article Moore said that the number of components-per-circuit (I think that means chip) will double every year. Moore credits Dave House with modifying it to `doubling every 18 months' and Carver Mead with calling it `Moore's Law'.&nbsp; Later it came to be quoted as computer SPEED would double every 18 months. We will take this to be Moore's Law in this blog post.&nbsp;</p><p>Is Moore's law dead? Browsing Google the answer seems to be that it is slowing down but not dead yet. (IDEA for a comedy sketch: Redo the Monty Python Dead Parrot sketch about the death of Moore's law.)&nbsp;</p><p>If Moore had 1 penny in April 1965 and it doubled every 18 months then how rich would he be now? How rich was he in April 2022? Compare the two numbers.&nbsp;</p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-23T20:05:00Z">Sunday, April 23 2023, 20:05</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, April 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/'>Some Rice News</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Lydia Kavraki is the Noah Harding Professor of Computer Science at Rice University. She is also professor of Bioengineering, professor of Electrical and Computer Engineering, and professor of Mechanical Engineering at Rice. She is the current Director of the Ken Kennedy Institute at Rice. Today we congratulate her on being elected to the American Academy [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Lydia Kavraki is the Noah Harding Professor of Computer Science at Rice University. She is also professor of Bioengineering, professor of Electrical and Computer Engineering, and professor of Mechanical Engineering at Rice. She is the current Director of the <a href="https://kenkennedy.rice.edu">Ken Kennedy Institute</a> at Rice. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/lk2/" rel="attachment wp-att-21504"><img data-attachment-id="21504" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/lk2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?fit=192%2C241&amp;ssl=1" data-orig-size="192,241" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="lk2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?fit=192%2C241&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?fit=192%2C241&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?resize=192%2C241&#038;ssl=1" alt="" width="192" height="241" class="aligncenter size-full wp-image-21504" data-recalc-dims="1" /></a></p>
<p>
Today we congratulate her on being elected to the American Academy of Arts and Sciences (<a href="https://www.amacad.org">AAAS</a>). </p>
<p>
Kavraki has multiple other affiliations listed on her <a href="https://www.cs.rice.edu/~kavraki/">home page</a>, including her own <a href="https://www.kavrakilab.org/">laboratory</a> on computational robotics and biomedicine. Now with AAAS, she acquires one more. It is enough to make us wonder whether her growth-of-affiliations function per year is additive or multiplicative. </p>
<p>
If the latter, then it would call to mind the story of rice grains on a chessboard. The emperor thinks it would be trivial to grant a reward of one grain of rice on the first square, two on the second square, four on the third square, eight on the fourth, and so on. It does not take many doublings for the number of grains to grow far in excess of this picture:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/rice/" rel="attachment wp-att-21494"><img data-attachment-id="21494" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/rice/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?fit=302%2C167&amp;ssl=1" data-orig-size="302,167" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rice" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?fit=300%2C166&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?fit=302%2C167&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?resize=302%2C167&#038;ssl=1" alt="" width="302" height="167" class="aligncenter size-full wp-image-21494" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?w=302&amp;ssl=1 302w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?resize=300%2C167&amp;ssl=1 300w" sizes="(max-width: 302px) 100vw, 302px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Brief Roadmap to Her Work </H2></p>
<p><p>
Suppose a chess queen has outstretched arms that made it difficult to move her on a board without knocking over other pieces. We will require her to make a legal move in chess, but not necessarily take the direct route to her destination square. If a roundabout route through a less-crowded area of the board can get her safely to her goal, we will allow our player to move her that way. Naturally, the player could be a robot arm that can picture the whole board but may only slide the queen, not hoist her vertically to hop her to a square.</p>
<p>
What&#8217;s the best way in practice to find a route, if one exists? We could try all possible paths, but here is where the grains-of-rice factor comes in. This is not because there are many squares, but because the queen&#8217;s arms may leave her little wiggle room on a square. She may have to shimmy to get by the nose of an enemy knight, but then find herself unable to twist around a chain of pawns. To avoid such backtracks, we&#8217;d need to make a roadmap of the entire board not in the space of squares, but in the possible <em>configuration space</em> of the queen, given the positioning of other pieces as obstacles. That space can be too large to map exhaustively.</p>
<p>
In work with her PhD adviser Jean-Clause Latombe and others, Kavraki was the guiding force in discovering that random sampling of the configuration space almost always efficiently finds a route when one exists. The sampling grows progressively longer transitions between configurations that the queen is able to make, and proclaims success when the goal configuration is connected to the origin. Then a deterministic shortest-path algorithm can be run on the resulting graph&#8212;a manageable subset of the whole configuration space&#8212;to find an optimal route through that graph. By the nature of physical space, this is usually optimum overall.</p>
<p>
Kavraki&#8217;s <a href="https://en.wikipedia.org/wiki/Probabilistic_roadmap">probabilistic roadmap</a> <em>paradigm</em> extends to many other settings besides moving robots. In biomedicine it applies to how a drug molecule can be designed to maximize its expectation of finding configurations that will combat a pathogen. Her 2017 ACM Athena Lecturer Award <a href="https://www.acm.org/articles/bulletins/2017/april/athena-2017-kavraki">citation</a> notes how her work has found paths into &#8220;an impressively wide range of areas.&#8221;</p>
<p>
<p><H2> Ken Kennedy&#8217;s Institute </H2></p>
<p><p>
Rice University is one of the top university especially when we look at its computer science <a href="https://csweb.rice.edu">program</a>. This historically was thanks to Ken Kennedy who sadly died years ago on 2007 February 7th. Ken was one of the world&#8217;s foremost experts on high-performance computing. He attended Rice University, receiving a B.A. in mathematics (summa cum laude) in 1967. He pursued graduate studies at New York University, where he earned a M.S. in mathematics in 1969 and a Ph.D. in computer science in 1971. Then he returned to Rice.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/kk-2/" rel="attachment wp-att-21495"><img data-attachment-id="21495" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/kk-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?fit=140%2C158&amp;ssl=1" data-orig-size="140,158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kk" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?fit=140%2C158&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?fit=140%2C158&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?resize=140%2C158&#038;ssl=1" alt="" width="140" height="158" class="aligncenter size-full wp-image-21495" data-recalc-dims="1" /></a></p>
<p>
Rice president David Leebron said: </p>
<blockquote><p>
&#8220;In Ken Kennedy, Rice has lost one of its great intellectual leaders and a great human being.  [He] early on realized the power of computers to address real problems that confront people and the Earth. Ken leaves a great legacy for Rice and for mankind. He will be missed.&#8221;
</p></blockquote>
<p><a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/owls2/" rel="attachment wp-att-21496"><img data-attachment-id="21496" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/owls2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?fit=253%2C199&amp;ssl=1" data-orig-size="253,199" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="owls2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?fit=253%2C199&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?fit=253%2C199&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?resize=253%2C199&#038;ssl=1" alt="" width="253" height="199" class="aligncenter size-full wp-image-21496" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Previous Leader </H2></p>
<p>
<p>
A previous leader of the Kennedy Institute is Moshe Vardi, an old friend whose work we first covered <a href="https://rjlipton.wpcomstaging.com/2011/07/28/logic-in-action/">here</a> and whom we&#8217;ve mentioned numerous times since, including about <a href="https://rjlipton.wpcomstaging.com/2020/09/10/hybrid-versus-remote-teaching/">teaching</a> during the pandemic. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/mv2/" rel="attachment wp-att-21499"><img data-attachment-id="21499" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/mv2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?fit=240%2C240&amp;ssl=1" data-orig-size="240,240" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mv2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?fit=240%2C240&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?fit=240%2C240&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?resize=160%2C160&#038;ssl=1" alt="" width="160" height="160" class="aligncenter wp-image-21499" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?w=240&amp;ssl=1 240w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 160px) 100vw, 160px" data-recalc-dims="1" /></a></p>
<p>
He also has a bunch of titles, including Professor of Computer Science, University Professor, the Karen Ostrum George Professor in Computational Engineering, and Distinguished Service Professor&#8212;but more notable is that he <a href="https://www.cs.rice.edu/~vardi/long-bio.html">has</a> even more honorary doctorates than affiliations:</p>
<blockquote>
<p>
He holds honorary doctorates from the University of Saarland, Germany, the University of Orleans in France, UFRGS in Brazil, the University of Liege in Belgium, the Technical University of Vienna, Austria, the University of Edinburgh in Scotland, the University of Grenoble-Alpes, and Gothenburg University in Sweden.
</p></blockquote>
<p>
<p>
<p><H2> AAAS </H2></p>
<p><p>
David Oxtoby is the current President of the American Academy of Arts and <a href="https://www.amacad.org">Sciences</a>. In his annoucement of the new class he says:</p>
<blockquote><p><b> </b> <em></p>
<p>
The very first class of members elected to the Academy in 1781 included Benjamin Franklin and George Washington, and today I&#8217;m pleased to announce the new members elected to the American Academy of Arts and Sciences this year.<br />
</em>
</p></blockquote>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/do/" rel="attachment wp-att-21500"><img data-attachment-id="21500" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/do/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?fit=216%2C233&amp;ssl=1" data-orig-size="216,233" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="do" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?fit=216%2C233&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?fit=216%2C233&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?resize=144%2C158&#038;ssl=1" alt="" width="144" height="158" class="aligncenter wp-image-21500" data-recalc-dims="1" /></a></p>
<p><p>
The new computer science electees are listed <a href="https://www.amacad.org/new-members-2023">here</a> and include several others we know well and whose work we have covered. We list Kavraki again in case this list is taken as &#8220;the&#8221; list.</p>
<ul>
<p><li>
Michael Franklin <a href="https://cs.uchicago.edu/people/michael-franklin/">MF</a>, University of Chicago </p>
<p><li>
Xuedong Huang <a href="https://www.microsoft.com/en-us/research/people/xdh/">XH</a>, Microsoft Corporation</p>
<p><li>
Piotr Indyk <a href="https://people.csail.mit.edu/indyk/">PI</a>, Massachusetts Institute of Technology</p>
<p><li>
Lydia Kavraki <a href="https://www.cs.rice.edu/~kavraki/">LK</a>, Rice University</p>
<p><li>
Marta Kwiatkowska <a href="https://www.trinity.ox.ac.uk/people/marta-kwiatkowska">MK</a>, University of Oxford (international honorary member)</p>
<p><li>
Maja Mataric <a href="https://viterbi.usc.edu/directory/faculty/Mataric/Maja">MM</a>, University of Southern California Viterbi School of Engineering</p>
<p><li>
Kathryn McKinley <a href="https://thenewstack.io/google-cloud-engineer-kathryn-s-mckinley-on-leadership-mentoring-garbage-collection-and-rust/">KM</a>, Google LLC</p>
<p><li>
Gordon Plotkin (IHM) <a href="https://www.research.ed.ac.uk/en/persons/gordon-plotkin">GP</a>, University of Edinburgh</p>
<p><li>
Moti Yung <a href="https://www.researchgate.net/profile/Moti-Yung">MY</a>, Google LLC</p>
</ul>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Our congratulations again to all those just elected. </p>
<p><P><br />
[Words &#8220;for Information Technology&#8221; from previous name of the Ken Kennedy Institute deleted from intro]</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-22T15:22:28Z">Saturday, April 22 2023, 15:22</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, April 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10106'>No Where to Go But High: A Perspective on High Dimensional Expanders</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Roy Gotlib, Tali Kaufman</p><p>"No Where to go but in" is a well known statement of Osho. Osho meant to say
that the answers to all our questions should be obtained by looking into
ourselves. In a paraphrase to Osho's statement we say "No Where to go but
high". This meant to demonstrate that for various seemingly unrelated topics
and questions the only way to get significant progress is via the prism of a
new philosophy (new field) called high dimensional expansion. In this note we
give an introduction \footnote{This introduction reflects the authors'
interests and by no mean claim to represent the field in a through way} to the
high dimensional expansion philosophy, and how it has been useful recently in
obtaining progress in various questions in seemingly unrelated fields.
</p>
<p>This exposition is dedicated to the memory of my mother, Sarah Kaufman, who
was always trying to understand the reason why things behave in a certain way.
It is also dedicated to the memory of my father Eliezer Kaufman.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gotlib_R/0/1/0/all/0/1">Roy Gotlib</a>, <a href="http://arxiv.org/find/math/1/au:+Kaufman_T/0/1/0/all/0/1">Tali Kaufman</a></p><p>"No Where to go but in" is a well known statement of Osho. Osho meant to say
that the answers to all our questions should be obtained by looking into
ourselves. In a paraphrase to Osho's statement we say "No Where to go but
high". This meant to demonstrate that for various seemingly unrelated topics
and questions the only way to get significant progress is via the prism of a
new philosophy (new field) called high dimensional expansion. In this note we
give an introduction \footnote{This introduction reflects the authors'
interests and by no mean claim to represent the field in a through way} to the
high dimensional expansion philosophy, and how it has been useful recently in
obtaining progress in various questions in seemingly unrelated fields.
</p>
<p>This exposition is dedicated to the memory of my mother, Sarah Kaufman, who
was always trying to understand the reason why things behave in a certain way.
It is also dedicated to the memory of my father Eliezer Kaufman.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09990'>Reconfiguration of 3D Pivoting Modular Robots</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hugo A. Akitaya, Frederick Stock</p><p>We study a new model of 3-dimensional modular self-reconfigurable robots
Rhombic Dodecahedral (RD). By extending results on the 2D analog of this model
we characterize the free space requirements for a pivoting move and investigate
the $\textit{reconfiguration problem}$, that is, given two configurations $s$
and $t$ is there a sequence of moves that transforms $s$ into $t$? We show
reconfiguration is PSPACE-hard for RD modules in a restricted pivoting model.
In a more general model, we show that RD configurations are not universally
reconfigurable despite the fact that their 2D analog is [Akitaya et al., SoCG
2021]. Additionally, we present a new class of RD configurations that we call
$\textit{super-rigid}$. Such a configuration remains rigid even as a subset of
any larger configuration, which does not exist in the 2D setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Akitaya_H/0/1/0/all/0/1">Hugo A. Akitaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Stock_F/0/1/0/all/0/1">Frederick Stock</a></p><p>We study a new model of 3-dimensional modular self-reconfigurable robots
Rhombic Dodecahedral (RD). By extending results on the 2D analog of this model
we characterize the free space requirements for a pivoting move and investigate
the $\textit{reconfiguration problem}$, that is, given two configurations $s$
and $t$ is there a sequence of moves that transforms $s$ into $t$? We show
reconfiguration is PSPACE-hard for RD modules in a restricted pivoting model.
In a more general model, we show that RD configurations are not universally
reconfigurable despite the fact that their 2D analog is [Akitaya et al., SoCG
2021]. Additionally, we present a new class of RD configurations that we call
$\textit{super-rigid}$. Such a configuration remains rigid even as a subset of
any larger configuration, which does not exist in the 2D setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10028'>Minimizing the Size of the Uncertainty Regions for Centers of Moving Entities</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: William Evans, Seyed Ali Tabatabaee</p><p>In this paper, we study the problems of computing the 1-center, centroid, and
1-median of objects moving with bounded speed in Euclidean space. We can
acquire the exact location of only a constant number of objects (usually one)
per unit time, but for every other object, its set of potential locations,
called the object's uncertainty region, grows subject only to the speed limit.
As a result, the center of the objects may be at several possible locations,
called the center's uncertainty region. For each of these center problems, we
design query strategies to minimize the size of the center's uncertainty region
and compare its performance to an optimal query strategy that knows the
trajectories of the objects, but must still query to reduce their uncertainty.
For the static case of the 1-center problem in R^1, we show an algorithm that
queries four objects per unit time and works as well as the optimal algorithm
with one query per unit time. For the general case of the 1-center problem in
R^1, the centroid problem in R^d, and the 1-median problem in R^1, we prove
that the Round-robin scheduling algorithm is the best possible competitive
algorithm. For the center of mass problem in R^d, we provide an O(log
n)-competitive algorithm. In addition, for the general case of the 1-center
problem in R^d (d &gt;= 2), we argue that no algorithm can guarantee a bounded
competitive ratio against the optimal algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Evans_W/0/1/0/all/0/1">William Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabatabaee_S/0/1/0/all/0/1">Seyed Ali Tabatabaee</a></p><p>In this paper, we study the problems of computing the 1-center, centroid, and
1-median of objects moving with bounded speed in Euclidean space. We can
acquire the exact location of only a constant number of objects (usually one)
per unit time, but for every other object, its set of potential locations,
called the object's uncertainty region, grows subject only to the speed limit.
As a result, the center of the objects may be at several possible locations,
called the center's uncertainty region. For each of these center problems, we
design query strategies to minimize the size of the center's uncertainty region
and compare its performance to an optimal query strategy that knows the
trajectories of the objects, but must still query to reduce their uncertainty.
For the static case of the 1-center problem in R^1, we show an algorithm that
queries four objects per unit time and works as well as the optimal algorithm
with one query per unit time. For the general case of the 1-center problem in
R^1, the centroid problem in R^d, and the 1-median problem in R^1, we prove
that the Round-robin scheduling algorithm is the best possible competitive
algorithm. For the center of mass problem in R^d, we provide an O(log
n)-competitive algorithm. In addition, for the general case of the 1-center
problem in R^d (d &gt;= 2), we argue that no algorithm can guarantee a bounded
competitive ratio against the optimal algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10078'>High-Performance and Flexible Parallel Algorithms for Semisort and Related Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaojun Dong, Yunshu Wu, Zhongqi Wang, Laxman Dhulipala, Yan Gu, Yihan Sun</p><p>Semisort is a fundamental algorithmic primitive widely used in the design and
analysis of efficient parallel algorithms. It takes input as an array of
records and a function extracting a \emph{key} per record, and reorders them so
that records with equal keys are contiguous. Since many applications only
require collecting equal values, but not fully sorting the input, semisort is
broadly applicable, e.g., in string algorithms, graph analytics, and geometry
processing, among many other domains. However, despite dozens of recent papers
that use semisort in their theoretical analysis and the existence of an
asymptotically optimal parallel semisort algorithm, most implementations of
these parallel algorithms choose to implement semisort by using comparison or
integer sorting in practice, due to potential performance issues in existing
semisort implementations.
</p>
<p>In this paper, we revisit the semisort problem, with the goal of achieving a
high-performance parallel semisort implementation with a flexible interface.
Our approach can easily extend to two related problems, \emph{histogram} and
\emph{collect-reduce}. Our algorithms achieve strong speedups in practice, and
importantly, outperform state-of-the-art parallel sorting and semisorting
methods for almost all settings we tested, with varying input sizes,
distribution, and key types. We also test two important applications with
real-world data, and show that our algorithms improve the performance over
existing approaches. We believe that many other parallel algorithm
implementations can be accelerated using our results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaojun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yunshu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1">Laxman Dhulipala</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yihan Sun</a></p><p>Semisort is a fundamental algorithmic primitive widely used in the design and
analysis of efficient parallel algorithms. It takes input as an array of
records and a function extracting a \emph{key} per record, and reorders them so
that records with equal keys are contiguous. Since many applications only
require collecting equal values, but not fully sorting the input, semisort is
broadly applicable, e.g., in string algorithms, graph analytics, and geometry
processing, among many other domains. However, despite dozens of recent papers
that use semisort in their theoretical analysis and the existence of an
asymptotically optimal parallel semisort algorithm, most implementations of
these parallel algorithms choose to implement semisort by using comparison or
integer sorting in practice, due to potential performance issues in existing
semisort implementations.
</p>
<p>In this paper, we revisit the semisort problem, with the goal of achieving a
high-performance parallel semisort implementation with a flexible interface.
Our approach can easily extend to two related problems, \emph{histogram} and
\emph{collect-reduce}. Our algorithms achieve strong speedups in practice, and
importantly, outperform state-of-the-art parallel sorting and semisorting
methods for almost all settings we tested, with varying input sizes,
distribution, and key types. We also test two important applications with
real-world data, and show that our algorithms improve the performance over
existing approaches. We believe that many other parallel algorithm
implementations can be accelerated using our results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10350'>Polylog-Competitive Algorithms for Dynamic Balanced Graph Partitioning for Ring Demands</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Harald R&#xe4;cke, Stefan Schmid, Ruslan Zabrodin</p><p>The performance of many large-scale and data-intensive distributed systems
critically depends on the capacity of the interconnecting network. This paper
is motivated by the vision of self-adjusting infrastructures whose resources
can be adjusted according to the workload they currently serve, in a
demand-aware manner. Such dynamic adjustments can be exploited to improve
network utilization and hence performance, by dynamically moving frequently
interacting communication partners closer, e.g., collocating them in the same
server or datacenter rack.
</p>
<p>In particular, we revisit the online balanced graph partitioning problem
which captures the fundamental tradeoff between the benefits and costs of
dynamically collocating communication partners. The demand is modelled as a
sequence $\sigma$ (revealed in an online manner) of communication requests
between $n$ processes, each of which is running on one of the $\ell$ servers.
Each server has capacity $k=n/\ell$, hence, the processes have to be scheduled
in a balanced manner across the servers. A request incurs cost $1$, if the
requested processes are located on different servers, otherwise the cost is 0.
A process can be migrated to a different server at cost $1$.
</p>
<p>This paper presents the first online algorithm for online balanced graph
partitioning achieving a polylogarithmic competitive ratio for the fundamental
case of ring communication patterns. Specifically, our main contribution is a
$O(\log^3 n)$-competitive randomized online algorithm for this problem. We
further present a randomized online algorithm which is $O(\log^2
n)$-competitive when compared to a static optimal solution. Our two results
rely on different algorithms and techniques and hence are of independent
interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Racke_H/0/1/0/all/0/1">Harald R&#xe4;cke</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Zabrodin_R/0/1/0/all/0/1">Ruslan Zabrodin</a></p><p>The performance of many large-scale and data-intensive distributed systems
critically depends on the capacity of the interconnecting network. This paper
is motivated by the vision of self-adjusting infrastructures whose resources
can be adjusted according to the workload they currently serve, in a
demand-aware manner. Such dynamic adjustments can be exploited to improve
network utilization and hence performance, by dynamically moving frequently
interacting communication partners closer, e.g., collocating them in the same
server or datacenter rack.
</p>
<p>In particular, we revisit the online balanced graph partitioning problem
which captures the fundamental tradeoff between the benefits and costs of
dynamically collocating communication partners. The demand is modelled as a
sequence $\sigma$ (revealed in an online manner) of communication requests
between $n$ processes, each of which is running on one of the $\ell$ servers.
Each server has capacity $k=n/\ell$, hence, the processes have to be scheduled
in a balanced manner across the servers. A request incurs cost $1$, if the
requested processes are located on different servers, otherwise the cost is 0.
A process can be migrated to a different server at cost $1$.
</p>
<p>This paper presents the first online algorithm for online balanced graph
partitioning achieving a polylogarithmic competitive ratio for the fundamental
case of ring communication patterns. Specifically, our main contribution is a
$O(\log^3 n)$-competitive randomized online algorithm for this problem. We
further present a randomized online algorithm which is $O(\log^2
n)$-competitive when compared to a static optimal solution. Our two results
rely on different algorithms and techniques and hence are of independent
interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10414'>How the Move Acceptance Hyper-Heuristic Copes With Local Optima: Drastic Differences Between Jumps and Cliffs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benjamin Doerr, Arthur Dremaux, Johannes Lutzeyer, Aur&#xe9;lien Stumpf</p><p>In recent work, Lissovoi, Oliveto, and Warwicker (Artificial Intelligence
(2023)) proved that the Move Acceptance Hyper-Heuristic (MAHH) leaves the local
optimum of the multimodal cliff benchmark with remarkable efficiency. With its
$O(n^3)$ runtime, for almost all cliff widths $d,$ the MAHH massively
outperforms the $\Theta(n^d)$ runtime of simple elitist evolutionary algorithms
(EAs). For the most prominent multimodal benchmark, the jump functions, the
given runtime estimates of $O(n^{2m} m^{-\Theta(m)})$ and
$\Omega(2^{\Omega(m)})$, for gap size $m \ge 2$, are far apart and the real
performance of MAHH is still an open question.
</p>
<p>In this work, we resolve this question. We prove that for any choice of the
MAHH selection parameter~$p$, the expected runtime of the MAHH on a jump
function with gap size $m = o(n^{1/2})$ is at least $\Omega(n^{2m-1} /
(2m-1)!)$. This renders the MAHH much slower than simple elitist evolutionary
algorithms with their typical $O(n^m)$ runtime.
</p>
<p>We also show that the MAHH with the global bit-wise mutation operator instead
of the local one-bit operator optimizes jump functions in time $O(\min\{m
n^m,\frac{n^{2m-1}}{m!\Omega(m)^{m-2}}\})$, essentially the minimum of the
optimization times of the $(1+1)$ EA and the MAHH. This suggests that combining
several ways to cope with local optima can be a fruitful approach.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1">Benjamin Doerr</a>, <a href="http://arxiv.org/find/cs/1/au:+Dremaux_A/0/1/0/all/0/1">Arthur Dremaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Lutzeyer_J/0/1/0/all/0/1">Johannes Lutzeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpf_A/0/1/0/all/0/1">Aur&#xe9;lien Stumpf</a></p><p>In recent work, Lissovoi, Oliveto, and Warwicker (Artificial Intelligence
(2023)) proved that the Move Acceptance Hyper-Heuristic (MAHH) leaves the local
optimum of the multimodal cliff benchmark with remarkable efficiency. With its
$O(n^3)$ runtime, for almost all cliff widths $d,$ the MAHH massively
outperforms the $\Theta(n^d)$ runtime of simple elitist evolutionary algorithms
(EAs). For the most prominent multimodal benchmark, the jump functions, the
given runtime estimates of $O(n^{2m} m^{-\Theta(m)})$ and
$\Omega(2^{\Omega(m)})$, for gap size $m \ge 2$, are far apart and the real
performance of MAHH is still an open question.
</p>
<p>In this work, we resolve this question. We prove that for any choice of the
MAHH selection parameter~$p$, the expected runtime of the MAHH on a jump
function with gap size $m = o(n^{1/2})$ is at least $\Omega(n^{2m-1} /
(2m-1)!)$. This renders the MAHH much slower than simple elitist evolutionary
algorithms with their typical $O(n^m)$ runtime.
</p>
<p>We also show that the MAHH with the global bit-wise mutation operator instead
of the local one-bit operator optimizes jump functions in time $O(\min\{m
n^m,\frac{n^{2m-1}}{m!\Omega(m)^{m-2}}\})$, essentially the minimum of the
optimization times of the $(1+1)$ EA and the MAHH. This suggests that combining
several ways to cope with local optima can be a fruitful approach.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10524'>Learning Narrow One-Hidden-Layer ReLU Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sitan Chen, Zehao Dou, Surbhi Goel, Adam R Klivans, Raghu Meka</p><p>We consider the well-studied problem of learning a linear combination of $k$
ReLU activations with respect to a Gaussian distribution on inputs in $d$
dimensions. We give the first polynomial-time algorithm that succeeds whenever
$k$ is a constant. All prior polynomial-time learners require additional
assumptions on the network, such as positive combining coefficients or the
matrix of hidden weight vectors being well-conditioned.
</p>
<p>Our approach is based on analyzing random contractions of higher-order moment
tensors. We use a multi-scale analysis to argue that sufficiently close neurons
can be collapsed together, sidestepping the conditioning issues present in
prior work. This allows us to design an iterative procedure to discover
individual neurons.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sitan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zehao Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1">Surbhi Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1">Adam R Klivans</a>, <a href="http://arxiv.org/find/cs/1/au:+Meka_R/0/1/0/all/0/1">Raghu Meka</a></p><p>We consider the well-studied problem of learning a linear combination of $k$
ReLU activations with respect to a Gaussian distribution on inputs in $d$
dimensions. We give the first polynomial-time algorithm that succeeds whenever
$k$ is a constant. All prior polynomial-time learners require additional
assumptions on the network, such as positive combining coefficients or the
matrix of hidden weight vectors being well-conditioned.
</p>
<p>Our approach is based on analyzing random contractions of higher-order moment
tensors. We use a multi-scale analysis to argue that sufficiently close neurons
can be collapsed together, sidestepping the conditioning issues present in
prior work. This allows us to design an iterative procedure to discover
individual neurons.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, April 20
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/055'>TR23-055 |  On Approximability of Satisfiable $k$-CSPs: II | 

	Amey Bhangale, 

	Subhash Khot, 

	Dor Minzer</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Let $\Sigma$ be an alphabet and $\mu$ be a distribution on $\Sigma^k$ for some $k \geq 2$. Let $\alpha &gt; 0$ be the minimum probability of a tuple in the support of $\mu$ (denoted by $supp(\mu)$). Here, the support of $\mu$ is the set of all tuples in $\Sigma^k$ that have a positive probability mass under $\mu$. We treat the parameters $\Sigma, k, \mu, \alpha$ as fixed and constant.

We say that the distribution $\mu$ has a  linear embedding if there exist an Abelian group $G$ (with the identity element $0_G$) and mappings $\sigma_i : \Sigma \rightarrow G$, $1 \leq i \leq k$, such that  at least one of the mappings is non-constant and for every $(a_1, a_2, \ldots, a_k)\in supp(\mu)$, $\sum_{i=1}^k \sigma_i(a_i) = 0_G$. In [Bhangale-Khot-Minzer, STOC 2022], the authors asked the following analytical question.

Let $f_i: \Sigma^n\rightarrow [-1,1]$ be bounded functions, such that at least one of the functions $f_i$ essentially has degree at least $d$, meaning that the Fourier mass of $f_i$ on terms of degree less than $d$ is negligible, say at most $\delta$. In particular, $|\mathbb{E}[f_i]| \leq \delta$. The Fourier representation is w.r.t. the marginal of $\mu$ on the $i^{th}$ co-ordinate, denoted $(\Sigma, \mu_i)$. If $\mu$ has no linear embedding (over any Abelian group), then is it necessarily the case that

$$|\mathbb{E}_{(x_1, x_2, \ldots, x_k)\sim \mu^{\otimes n}}[f_1(x_1)f_2(x_2)\cdots f_k(x_k)]   = o_{d, \delta}(1),$$

where the right hand side $\to 0$ as the degree $d \to \infty$  and $\delta \to 0$?


In this paper, we answer this analytical question fully and in the affirmative for $k=3$. We also show the following two applications of the result.

1. The first application is related to hardness of approximation. Using the reduction from [Bhangale-Khot-Minzer, STOC 2022], we show that for every $3$-ary predicate $P:\Sigma^3 \to \{0,1\}$ such that $P$ has no linear embedding, an SDP integrality gap instance of a $P$-CSP instance with gap $(1,s)$ can be translated into a dictatorship test with completeness $1$ and soundness $s+o(1)$, under certain additional conditions on the instance.

2. The second application is related to additive combinatorics. We show that if the distribution $\mu$ on $\Sigma^3$ has no linear embedding, marginals of $\mu$ are uniform on $\Sigma$, and $(a,a,a)\in supp(\mu)$ for every $a\in \Sigma$, then every large enough subset of $\Sigma^n$ contains a triple $(x_1, x_2,x_3)$ from $\mu^{\otimes n}$ (and in fact a significant density of such triples).
        
        </div>

        <div class='tr-article-summary'>
        
          
          Let $\Sigma$ be an alphabet and $\mu$ be a distribution on $\Sigma^k$ for some $k \geq 2$. Let $\alpha &gt; 0$ be the minimum probability of a tuple in the support of $\mu$ (denoted by $supp(\mu)$). Here, the support of $\mu$ is the set of all tuples in $\Sigma^k$ that have a positive probability mass under $\mu$. We treat the parameters $\Sigma, k, \mu, \alpha$ as fixed and constant.

We say that the distribution $\mu$ has a  linear embedding if there exist an Abelian group $G$ (with the identity element $0_G$) and mappings $\sigma_i : \Sigma \rightarrow G$, $1 \leq i \leq k$, such that  at least one of the mappings is non-constant and for every $(a_1, a_2, \ldots, a_k)\in supp(\mu)$, $\sum_{i=1}^k \sigma_i(a_i) = 0_G$. In [Bhangale-Khot-Minzer, STOC 2022], the authors asked the following analytical question.

Let $f_i: \Sigma^n\rightarrow [-1,1]$ be bounded functions, such that at least one of the functions $f_i$ essentially has degree at least $d$, meaning that the Fourier mass of $f_i$ on terms of degree less than $d$ is negligible, say at most $\delta$. In particular, $|\mathbb{E}[f_i]| \leq \delta$. The Fourier representation is w.r.t. the marginal of $\mu$ on the $i^{th}$ co-ordinate, denoted $(\Sigma, \mu_i)$. If $\mu$ has no linear embedding (over any Abelian group), then is it necessarily the case that

$$|\mathbb{E}_{(x_1, x_2, \ldots, x_k)\sim \mu^{\otimes n}}[f_1(x_1)f_2(x_2)\cdots f_k(x_k)]   = o_{d, \delta}(1),$$

where the right hand side $\to 0$ as the degree $d \to \infty$  and $\delta \to 0$?


In this paper, we answer this analytical question fully and in the affirmative for $k=3$. We also show the following two applications of the result.

1. The first application is related to hardness of approximation. Using the reduction from [Bhangale-Khot-Minzer, STOC 2022], we show that for every $3$-ary predicate $P:\Sigma^3 \to \{0,1\}$ such that $P$ has no linear embedding, an SDP integrality gap instance of a $P$-CSP instance with gap $(1,s)$ can be translated into a dictatorship test with completeness $1$ and soundness $s+o(1)$, under certain additional conditions on the instance.

2. The second application is related to additive combinatorics. We show that if the distribution $\mu$ on $\Sigma^3$ has no linear embedding, marginals of $\mu$ are uniform on $\Sigma$, and $(a,a,a)\in supp(\mu)$ for every $a\in \Sigma$, then every large enough subset of $\Sigma^n$ contains a triple $(x_1, x_2,x_3)$ from $\mu^{\otimes n}$ (and in fact a significant density of such triples).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T22:00:35Z">Thursday, April 20 2023, 22:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/054'>TR23-054 |  On Approximability of Satisfiable $k$-CSPs: III | 

	Amey Bhangale, 

	Subhash Khot, 

	Dor Minzer</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this paper we study functions on the Boolean hypercube that have the property that after applying certain random restrictions, the restricted function is correlated to a linear function with non-negligible probability. If the given function is correlated with a linear function then this property clearly holds. Furthermore, the property also holds for low-degree functions as low-degree functions become a constant function under a random restriction with a non-negligible probability. We show that this essentially is the only possible reason.  More specifically, we show that the function must be correlated to a product of a linear function and a low-degree function. One of the main motivations of studying this question comes from the recent work of the authors [Bhangale, Khot and Minzer, STOC 2021] towards understanding approximability of satisfiable Constraint Satisfaction Problems.

Towards proving our structural theorem, we analyze a $2$-query direct product test for the table $F: {[n]\choose qn} \rightarrow \{0,1\}^{qn}$ where $q\in (0,1)$. We show that, for every constant $\varepsilon&gt;0$, if the test passes with probability $\varepsilon&gt;0$, then there is a global function such that for at least $\delta(\varepsilon)$ fraction of sets, the global function agrees with the given table on {\em all except $\alpha(\varepsilon)$ many locations}. The novelty of this result lies in the fact that $\alpha(\varepsilon)$ is independent of the set sizes. Prior to our work, such a conclusion (in fact, a stronger conclusion with $\alpha = 0$) was shown in [Dinur-Filmus-Harsha, SODA 2019] albeit when the test accepts with probability $1-\varepsilon$ for a small constant $\varepsilon&gt;0$. The setting of parameters in our direct product tests is fundamentally different compared to [Dinur-Goldenberg, FOCS 2008], [Impagliazzo-Kabanets-Wigderson, SIAM Journal of Computing 2012], [Dinur-Steurer, CCC 2014], [Dinur-Filmus-Harsha, SODA 2019]  and hence our analysis involves new techniques, including the use of the small-set expansion property of graphs defined on multi-slices. Such expansion property was recently shown in [Braverman-Khot-Lifshitz-Minzer, FOCS 2022].

As one application of our structural result, we give a $4$-query linearity test under the $p$-biased distribution. More specifically, for any $p\in (\frac{1}{3},\frac{2}{3})$, we give a test that queries a given function $f: \{0,1\}^n \rightarrow \{0,1\}$ at $4$ locations, where the marginal distribution of each query is $\mu_p^{\otimes n}$. The test has perfect completeness and soundness $\frac{1}{2}+\varepsilon$ -- in other words, for every constant $\varepsilon&gt;0$,  if the test passes with probability at least $\frac{1}{2}+\varepsilon$, then the function $f$ is correlated to a linear function under the $\mu_p^{\otimes n}$ measure. This qualitatively improves the results on the linearity testing under the $p$-biased distribution from the previous work [Kopparty-Saraf, APPROX/RANDOM 2009] and [Dinur-Filmus-Harsha, SODA 2019] in which the authors studied the test with soundness $1-\varepsilon$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In this paper we study functions on the Boolean hypercube that have the property that after applying certain random restrictions, the restricted function is correlated to a linear function with non-negligible probability. If the given function is correlated with a linear function then this property clearly holds. Furthermore, the property also holds for low-degree functions as low-degree functions become a constant function under a random restriction with a non-negligible probability. We show that this essentially is the only possible reason.  More specifically, we show that the function must be correlated to a product of a linear function and a low-degree function. One of the main motivations of studying this question comes from the recent work of the authors [Bhangale, Khot and Minzer, STOC 2021] towards understanding approximability of satisfiable Constraint Satisfaction Problems.

Towards proving our structural theorem, we analyze a $2$-query direct product test for the table $F: {[n]\choose qn} \rightarrow \{0,1\}^{qn}$ where $q\in (0,1)$. We show that, for every constant $\varepsilon&gt;0$, if the test passes with probability $\varepsilon&gt;0$, then there is a global function such that for at least $\delta(\varepsilon)$ fraction of sets, the global function agrees with the given table on {\em all except $\alpha(\varepsilon)$ many locations}. The novelty of this result lies in the fact that $\alpha(\varepsilon)$ is independent of the set sizes. Prior to our work, such a conclusion (in fact, a stronger conclusion with $\alpha = 0$) was shown in [Dinur-Filmus-Harsha, SODA 2019] albeit when the test accepts with probability $1-\varepsilon$ for a small constant $\varepsilon&gt;0$. The setting of parameters in our direct product tests is fundamentally different compared to [Dinur-Goldenberg, FOCS 2008], [Impagliazzo-Kabanets-Wigderson, SIAM Journal of Computing 2012], [Dinur-Steurer, CCC 2014], [Dinur-Filmus-Harsha, SODA 2019]  and hence our analysis involves new techniques, including the use of the small-set expansion property of graphs defined on multi-slices. Such expansion property was recently shown in [Braverman-Khot-Lifshitz-Minzer, FOCS 2022].

As one application of our structural result, we give a $4$-query linearity test under the $p$-biased distribution. More specifically, for any $p\in (\frac{1}{3},\frac{2}{3})$, we give a test that queries a given function $f: \{0,1\}^n \rightarrow \{0,1\}$ at $4$ locations, where the marginal distribution of each query is $\mu_p^{\otimes n}$. The test has perfect completeness and soundness $\frac{1}{2}+\varepsilon$ -- in other words, for every constant $\varepsilon&gt;0$,  if the test passes with probability at least $\frac{1}{2}+\varepsilon$, then the function $f$ is correlated to a linear function under the $\mu_p^{\otimes n}$ measure. This qualitatively improves the results on the linearity testing under the $p$-biased distribution from the previous work [Kopparty-Saraf, APPROX/RANDOM 2009] and [Dinur-Filmus-Harsha, SODA 2019] in which the authors studied the test with soundness $1-\varepsilon$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T22:00:22Z">Thursday, April 20 2023, 22:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/health-tech.html'>Health Tech</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p></p>♦<br>On Tuesday, at the behest of an alumnus, I spent the afternoon at HIMSS, a large health tech conference being held at the big convention center in Chicago. When I think of Health Tech, I imagine fancy medical devices, but most of the exhibitors were focused on software solutions.<p></p><p>Cybersecurity had the biggest theme area, no surprise given the devasting role ransomware has had on some hospital chains. The second largest theme area focused on Interoperability. Just a few years ago, the vast majority of medical data is transferred via fax. A few companies, like Epic Systems, dominate the electronic health records space and don't share nicely. There's a relatively new standard,&nbsp;FHIR, for transferring medical data, making it easily accessible via APIs while keeping it secure. Hopefully, we can finally kill off the fax machines in doctors offices. Patient Engagement was the other big theme area.</p><p>Of course the big discussion topics are about how AI will change health care. For example, the advances in electronic records have led to doctors spending far too much time entering data instead of seeing patients. AI could make data entry quick, easier or perhaps even unnecessary. Also AI could help provide functionality for triage and initial diagnoses, helping to extend the capabilities in a staff-limited environment and help bring down health-care costs. Many of the exhibited software systems boasted about using AI but it won't be until next year's meeting that we see the true integration of large-language models into health care technology.</p><p>Many of the challenges of technology in health care carry over to higher education. We don't generally use faxes, but why do we send transcripts by PDFs? Health and student data share similar privacy and security challenges, why can't we develop a FHIR-like system for higher education? Cybersecurity and Patient&nbsp;Student Engagement challenges loom large for universities as well.&nbsp;</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p></p><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhyGNMicDXyUD2rOs44Tlkus5rR0BF-8qwueFzOJQdXm6L_eaGZ3V9blhL9X1Viqg01o_gl-YkkgkE7wwPWfbJlN9q0HJU8RpEJIw6iVauLUFPD-c_iK0645ZzXrpgVAuDHASeM1X7zFcBn3YQyHIPJrRKsPIw6Rj0VYGzzY4yZbmRwQ9rwIQ/s4080/PXL_20230418_180451901.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="3072" data-original-width="4080" height="301" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhyGNMicDXyUD2rOs44Tlkus5rR0BF-8qwueFzOJQdXm6L_eaGZ3V9blhL9X1Viqg01o_gl-YkkgkE7wwPWfbJlN9q0HJU8RpEJIw6iVauLUFPD-c_iK0645ZzXrpgVAuDHASeM1X7zFcBn3YQyHIPJrRKsPIw6Rj0VYGzzY4yZbmRwQ9rwIQ/w400-h301/PXL_20230418_180451901.jpg" width="400" /></a></div><br />On Tuesday, at the behest of an alumnus, I spent the afternoon at <a href="https://www.himss.org/global-conference">HIMSS</a>, a large health tech conference being held at the big convention center in Chicago. When I think of Health Tech, I imagine fancy medical devices, but most of the exhibitors were focused on software solutions.<p></p><p>Cybersecurity had the biggest theme area, no surprise given the devasting role ransomware has had on some hospital chains. The second largest theme area focused on Interoperability. Just a few years ago, the vast majority of medical data is transferred via fax. A few companies, like Epic Systems, dominate the electronic health records space and don't share nicely. There's a relatively new standard,&nbsp;<a href="https://en.wikipedia.org/wiki/Fast_Healthcare_Interoperability_Resources">FHIR</a>, for transferring medical data, making it easily accessible via APIs while keeping it secure. Hopefully, we can finally kill off the fax machines in doctors offices. Patient Engagement was the other big theme area.</p><p>Of course the big discussion topics are about how AI will change health care. For example, the advances in electronic records have led to doctors spending far too much time entering data instead of seeing patients. AI could make data entry quick, easier or perhaps even unnecessary. Also AI could help provide functionality for triage and initial diagnoses, helping to extend the capabilities in a staff-limited environment and help bring down health-care costs. Many of the exhibited software systems boasted about using AI but it won't be until next year's meeting that we see the true integration of large-language models into health care technology.</p><p>Many of the challenges of technology in health care carry over to higher education. We don't generally use faxes, but why do we send transcripts by PDFs? Health and student data share similar privacy and security challenges, why can't we develop a FHIR-like system for higher education? Cybersecurity and <strike>Patient</strike>&nbsp;Student Engagement challenges loom large for universities as well.&nbsp;</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T21:30:00Z">Thursday, April 20 2023, 21:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/053'>TR23-053 |  Proof Simulation via Round-based Strategy Extraction for QBF | 

	Leroy Chew</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The proof complexity of Quantified Boolean Formulas (QBF) relates to both QBF solving and OBF certification. One method to p-simulate a QBF proof system is by formalising the soundness of its strategy extraction in propositional logic. In this work we illustrate how to use extended QBF Frege to simulate LD-Q(Drrs)-Res, a proof system that combines conflict driven clause learning with dependency schemes, using such a method.
The round-based technique is the most common way to show a QBF proof system has strategy extraction, originally shown for Q-resolution and later used for LD-Q-Resolution, LQU-Resolution, expansion based systems and dependency-scheme based systems. Many of these proof systems were already shown to be simulated by extended QBF Frege, but simulation had to use a specialised local strategy extraction technique. Here we simulate the remaining systems, by formalising the soundness of LD-Q(Drrs)-Res&#39;s round-based strategy extraction in propositional logic. This is a positive result for certification, and further suggests the feasibility of using Extended QU-Resolution or QRAT to certify QCDCL solvers.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The proof complexity of Quantified Boolean Formulas (QBF) relates to both QBF solving and OBF certification. One method to p-simulate a QBF proof system is by formalising the soundness of its strategy extraction in propositional logic. In this work we illustrate how to use extended QBF Frege to simulate LD-Q(Drrs)-Res, a proof system that combines conflict driven clause learning with dependency schemes, using such a method.
The round-based technique is the most common way to show a QBF proof system has strategy extraction, originally shown for Q-resolution and later used for LD-Q-Resolution, LQU-Resolution, expansion based systems and dependency-scheme based systems. Many of these proof systems were already shown to be simulated by extended QBF Frege, but simulation had to use a specialised local strategy extraction technique. Here we simulate the remaining systems, by formalising the soundness of LD-Q(Drrs)-Res&#39;s round-based strategy extraction in propositional logic. This is a positive result for certification, and further suggests the feasibility of using Extended QU-Resolution or QRAT to certify QCDCL solvers.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T05:02:11Z">Thursday, April 20 2023, 05:02</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/052'>TR23-052 |  Limits of CDCL Learning via Merge Resolution | 

	Marc Vinyals, 

	Chunxiao Li, 

	Noah Fleming, 

	Antonina Kolokolova, 

	Vijay Ganesh</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In their seminal work, Atserias et al. and independently Pipatsrisawat and Darwiche in 2009 showed that CDCL solvers can simulate resolution proofs with polynomial overhead. However, previous work does not address the tightness of the simulation, i.e., the question of how large this overhead needs to be. In this paper, we address this question by focusing on an important property of proofs generated by CDCL solvers that employ standard learning schemes, namely that the derivation of a learned clause has at least one inference where a literal appears in both premises (aka, a merge literal). Specifically, we show that proofs of this kind can simulate resolution proofs with at most a linear overhead, but there also exist formulas where such overhead is necessary or, more precisely, that there exist formulas with resolution proofs of linear length that require quadratic CDCL proofs.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In their seminal work, Atserias et al. and independently Pipatsrisawat and Darwiche in 2009 showed that CDCL solvers can simulate resolution proofs with polynomial overhead. However, previous work does not address the tightness of the simulation, i.e., the question of how large this overhead needs to be. In this paper, we address this question by focusing on an important property of proofs generated by CDCL solvers that employ standard learning schemes, namely that the derivation of a learned clause has at least one inference where a literal appears in both premises (aka, a merge literal). Specifically, we show that proofs of this kind can simulate resolution proofs with at most a linear overhead, but there also exist formulas where such overhead is necessary or, more precisely, that there exist formulas with resolution proofs of linear length that require quadratic CDCL proofs.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T04:59:40Z">Thursday, April 20 2023, 04:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/051'>TR23-051 |  QCDCL vs QBF Resolution: Further Insights | 

	Benjamin Böhm, 

	Olaf Beyersdorff</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We continue the investigation on the relations of QCDCL and QBF resolution systems. In particular, we introduce QCDCL versions that tightly characterise QU-Resolution and (a slight variant of) long-distance Q-Resolution. We show that most QCDCL variants - parameterised by different policies for decisions, unit propagations and reductions --  lead to incomparable systems for almost all choices of these policies.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We continue the investigation on the relations of QCDCL and QBF resolution systems. In particular, we introduce QCDCL versions that tightly characterise QU-Resolution and (a slight variant of) long-distance Q-Resolution. We show that most QCDCL variants - parameterised by different policies for decisions, unit propagations and reductions --  lead to incomparable systems for almost all choices of these policies.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T04:57:52Z">Thursday, April 20 2023, 04:57</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09422'>Limits of CDCL Learning via Merge Resolution</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marc Vinyals, Chunxiao Li, Noah Fleming, Antonina Kolokolova, Vijay Ganesh</p><p>In their seminal work, Atserias et al. and independently Pipatsrisawat and
Darwiche in 2009 showed that CDCL solvers can simulate resolution proofs with
polynomial overhead. However, previous work does not address the tightness of
the simulation, i.e., the question of how large this overhead needs to be. In
this paper, we address this question by focusing on an important property of
proofs generated by CDCL solvers that employ standard learning schemes, namely
that the derivation of a learned clause has at least one inference where a
literal appears in both premises (aka, a merge literal). Specifically, we show
that proofs of this kind can simulate resolution proofs with at most a linear
overhead, but there also exist formulas where such overhead is necessary or,
more precisely, that there exist formulas with resolution proofs of linear
length that require quadratic CDCL proofs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Vinyals_M/0/1/0/all/0/1">Marc Vinyals</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunxiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleming_N/0/1/0/all/0/1">Noah Fleming</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolokolova_A/0/1/0/all/0/1">Antonina Kolokolova</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganesh_V/0/1/0/all/0/1">Vijay Ganesh</a></p><p>In their seminal work, Atserias et al. and independently Pipatsrisawat and
Darwiche in 2009 showed that CDCL solvers can simulate resolution proofs with
polynomial overhead. However, previous work does not address the tightness of
the simulation, i.e., the question of how large this overhead needs to be. In
this paper, we address this question by focusing on an important property of
proofs generated by CDCL solvers that employ standard learning schemes, namely
that the derivation of a learned clause has at least one inference where a
literal appears in both premises (aka, a merge literal). Specifically, we show
that proofs of this kind can simulate resolution proofs with at most a linear
overhead, but there also exist formulas where such overhead is necessary or,
more precisely, that there exist formulas with resolution proofs of linear
length that require quadratic CDCL proofs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09216'>Higher-dimensional subdiagram matching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Amar Hadzihasanovic, Diana Kessler</p><p>Higher-dimensional rewriting is founded on a duality of rewrite systems and
cell complexes, connecting computational mathematics to higher categories and
homotopy theory: the two sides of a rewrite rule are two halves of the boundary
of an (n+1)-cell, which are diagrams of n-cells. We study higher-dimensional
diagram rewriting as a mechanism of computation, focussing on the matching
problem for rewritable subdiagrams within the combinatorial framework of
diagrammatic sets. We provide an algorithm for subdiagram matching in arbitrary
dimensions, based on new results on layerings of diagrams, and derive upper
bounds on its time complexity. We show that these superpolynomial bounds can be
improved to polynomial bounds under certain acyclicity conditions, and that
these conditions hold in general for diagrams up to dimension 3. We discuss the
challenges that arise in dimension 4.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Hadzihasanovic_A/0/1/0/all/0/1">Amar Hadzihasanovic</a>, <a href="http://arxiv.org/find/math/1/au:+Kessler_D/0/1/0/all/0/1">Diana Kessler</a></p><p>Higher-dimensional rewriting is founded on a duality of rewrite systems and
cell complexes, connecting computational mathematics to higher categories and
homotopy theory: the two sides of a rewrite rule are two halves of the boundary
of an (n+1)-cell, which are diagrams of n-cells. We study higher-dimensional
diagram rewriting as a mechanism of computation, focussing on the matching
problem for rewritable subdiagrams within the combinatorial framework of
diagrammatic sets. We provide an algorithm for subdiagram matching in arbitrary
dimensions, based on new results on layerings of diagrams, and derive upper
bounds on its time complexity. We show that these superpolynomial bounds can be
improved to polynomial bounds under certain acyclicity conditions, and that
these conditions hold in general for diagrams up to dimension 3. We discuss the
challenges that arise in dimension 4.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09217'>New Subset Selection Algorithms for Low Rank Approximation: Offline and Online</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David P. Woodruff, Taisuke Yasuda</p><p>Subset selection for the rank $k$ approximation of an $n\times d$ matrix $A$
offers improvements in the interpretability of matrices, as well as a variety
of computational savings. This problem is well-understood when the error
measure is the Frobenius norm, with various tight algorithms known even in
challenging models such as the online model, where an algorithm must select the
column subset irrevocably when the columns arrive one by one. In contrast, for
other matrix losses, optimal trade-offs between the subset size and
approximation quality have not been settled, even in the offline setting. We
give a number of results towards closing these gaps.
</p>
<p>In the offline setting, we achieve nearly optimal bicriteria algorithms in
two settings. First, we remove a $\sqrt k$ factor from a result of [SWZ19] when
the loss function is any entrywise loss with an approximate triangle inequality
and at least linear growth. Our result is tight for the $\ell_1$ loss. We give
a similar improvement for entrywise $\ell_p$ losses for $p&gt;2$, improving a
previous distortion of $k^{1-1/p}$ to $k^{1/2-1/p}$. Our results come from a
technique which replaces the use of a well-conditioned basis with a slightly
larger spanning set for which any vector can be expressed as a linear
combination with small Euclidean norm. We show that this technique also gives
the first oblivious $\ell_p$ subspace embeddings for $1&lt;p&lt;2$ with $\tilde
O(d^{1/p})$ distortion, which is nearly optimal and closes a long line of work.
</p>
<p>In the online setting, we give the first online subset selection algorithm
for $\ell_p$ subspace approximation and entrywise $\ell_p$ low rank
approximation by implementing sensitivity sampling online, which is challenging
due to the sequential nature of sensitivity sampling. Our main technique is an
online algorithm for detecting when an approximately optimal subspace changes
substantially.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a>, <a href="http://arxiv.org/find/cs/1/au:+Yasuda_T/0/1/0/all/0/1">Taisuke Yasuda</a></p><p>Subset selection for the rank $k$ approximation of an $n\times d$ matrix $A$
offers improvements in the interpretability of matrices, as well as a variety
of computational savings. This problem is well-understood when the error
measure is the Frobenius norm, with various tight algorithms known even in
challenging models such as the online model, where an algorithm must select the
column subset irrevocably when the columns arrive one by one. In contrast, for
other matrix losses, optimal trade-offs between the subset size and
approximation quality have not been settled, even in the offline setting. We
give a number of results towards closing these gaps.
</p>
<p>In the offline setting, we achieve nearly optimal bicriteria algorithms in
two settings. First, we remove a $\sqrt k$ factor from a result of [SWZ19] when
the loss function is any entrywise loss with an approximate triangle inequality
and at least linear growth. Our result is tight for the $\ell_1$ loss. We give
a similar improvement for entrywise $\ell_p$ losses for $p&gt;2$, improving a
previous distortion of $k^{1-1/p}$ to $k^{1/2-1/p}$. Our results come from a
technique which replaces the use of a well-conditioned basis with a slightly
larger spanning set for which any vector can be expressed as a linear
combination with small Euclidean norm. We show that this technique also gives
the first oblivious $\ell_p$ subspace embeddings for $1&lt;p&lt;2$ with $\tilde
O(d^{1/p})$ distortion, which is nearly optimal and closes a long line of work.
</p>
<p>In the online setting, we give the first online subset selection algorithm
for $\ell_p$ subspace approximation and entrywise $\ell_p$ low rank
approximation by implementing sensitivity sampling online, which is challenging
due to the sequential nature of sensitivity sampling. Our main technique is an
online algorithm for detecting when an approximately optimal subspace changes
substantially.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09281'>Optimal Eigenvalue Approximation via Sketching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: William Swartworth, David P. Woodruff</p><p>Given a symmetric matrix $A$, we show from the simple sketch $GAG^T$, where
$G$ is a Gaussian matrix with $k = O(1/\epsilon^2)$ rows, that there is a
procedure for approximating all eigenvalues of $A$ simultaneously to within
$\epsilon \|A\|_F$ additive error with large probability. Unlike the work of
(Andoni, Nguyen, SODA, 2013), we do not require that $A$ is positive
semidefinite and therefore we can recover sign information about the spectrum
as well. Our result also significantly improves upon the sketching dimension of
recent work for this problem (Needell, Swartworth, Woodruff FOCS 2022), and in
fact gives optimal sketching dimension. Our proof develops new properties of
singular values of $GA$ for a $k \times n$ Gaussian matrix $G$ and an $n \times
n$ matrix $A$ which may be of independent interest. Additionally we achieve
tight bounds in terms of matrix-vector queries. Our sketch can be computed
using $O(1/\epsilon^2)$ matrix-vector multiplies, and by improving on lower
bounds for the so-called rank estimation problem, we show that this number is
optimal even for adaptive matrix-vector queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Swartworth_W/0/1/0/all/0/1">William Swartworth</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a></p><p>Given a symmetric matrix $A$, we show from the simple sketch $GAG^T$, where
$G$ is a Gaussian matrix with $k = O(1/\epsilon^2)$ rows, that there is a
procedure for approximating all eigenvalues of $A$ simultaneously to within
$\epsilon \|A\|_F$ additive error with large probability. Unlike the work of
(Andoni, Nguyen, SODA, 2013), we do not require that $A$ is positive
semidefinite and therefore we can recover sign information about the spectrum
as well. Our result also significantly improves upon the sketching dimension of
recent work for this problem (Needell, Swartworth, Woodruff FOCS 2022), and in
fact gives optimal sketching dimension. Our proof develops new properties of
singular values of $GA$ for a $k \times n$ Gaussian matrix $G$ and an $n \times
n$ matrix $A$ which may be of independent interest. Additionally we achieve
tight bounds in terms of matrix-vector queries. Our sketch can be computed
using $O(1/\epsilon^2)$ matrix-vector multiplies, and by improving on lower
bounds for the so-called rank estimation problem, we show that this number is
optimal even for adaptive matrix-vector queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09283'>Sliding Block Hashing (Slick) -- Basic Algorithmic Ideas</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hans-Peter Lehmann, Peter Sanders, Stefan Walzer</p><p>We present {\bf Sli}ding Blo{\bf ck} Hashing (Slick), a simple hash table
data structure that combines high performance with very good space efficiency.
This preliminary report outlines avenues for analysis and implementation that
we intend to pursue.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lehmann_H/0/1/0/all/0/1">Hans-Peter Lehmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanders_P/0/1/0/all/0/1">Peter Sanders</a>, <a href="http://arxiv.org/find/cs/1/au:+Walzer_S/0/1/0/all/0/1">Stefan Walzer</a></p><p>We present {\bf Sli}ding Blo{\bf ck} Hashing (Slick), a simple hash table
data structure that combines high performance with very good space efficiency.
This preliminary report outlines avenues for analysis and implementation that
we intend to pursue.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09321'>A New Deterministic Algorithm for Fully Dynamic All-Pairs Shortest Paths</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julia Chuzhoy, Ruimin Zhang</p><p>We study the fully dynamic All-Pairs Shortest Paths (APSP) problem in
undirected edge-weighted graphs. Given an $n$-vertex graph $G$ with
non-negative edge lengths, that undergoes an online sequence of edge insertions
and deletions, the goal is to support approximate distance queries and
shortest-path queries. We provide a deterministic algorithm for this problem,
that, for a given precision parameter $\epsilon$, achieves approximation factor
$(\log\log n)^{2^{O(1/\epsilon^3)}}$, and has amortized update time
$O(n^{\epsilon}\log L)$ per operation, where $L$ is the ratio of longest to
shortest edge length. Query time for distance-query is
$O(2^{O(1/\epsilon)}\cdot \log n\cdot \log\log L)$, and query time for
shortest-path query is $O(|E(P)|+2^{O(1/\epsilon)}\cdot \log n\cdot \log\log
L)$, where $P$ is the path that the algorithm returns. To the best of our
knowledge, even allowing any $o(n)$-approximation factor, no adaptive-update
algorithms with better than $\Theta(m)$ amortized update time and better than
$\Theta(n)$ query time were known prior to this work. We also note that our
guarantees are stronger than the best current guarantees for APSP in
decremental graphs in the adaptive-adversary setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chuzhoy_J/0/1/0/all/0/1">Julia Chuzhoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruimin Zhang</a></p><p>We study the fully dynamic All-Pairs Shortest Paths (APSP) problem in
undirected edge-weighted graphs. Given an $n$-vertex graph $G$ with
non-negative edge lengths, that undergoes an online sequence of edge insertions
and deletions, the goal is to support approximate distance queries and
shortest-path queries. We provide a deterministic algorithm for this problem,
that, for a given precision parameter $\epsilon$, achieves approximation factor
$(\log\log n)^{2^{O(1/\epsilon^3)}}$, and has amortized update time
$O(n^{\epsilon}\log L)$ per operation, where $L$ is the ratio of longest to
shortest edge length. Query time for distance-query is
$O(2^{O(1/\epsilon)}\cdot \log n\cdot \log\log L)$, and query time for
shortest-path query is $O(|E(P)|+2^{O(1/\epsilon)}\cdot \log n\cdot \log\log
L)$, where $P$ is the path that the algorithm returns. To the best of our
knowledge, even allowing any $o(n)$-approximation factor, no adaptive-update
algorithms with better than $\Theta(m)$ amortized update time and better than
$\Theta(n)$ query time were known prior to this work. We also note that our
guarantees are stronger than the best current guarantees for APSP in
decremental graphs in the adaptive-adversary setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09331'>Provably-Efficient and Internally-Deterministic Parallel Union-Find</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Fedorov, Diba Hashemi, Giorgi Nadiradze, Dan Alistarh</p><p>Determining the degree of inherent parallelism in classical sequential
algorithms and leveraging it for fast parallel execution is a key topic in
parallel computing, and detailed analyses are known for a wide range of
classical algorithms. In this paper, we perform the first such analysis for the
fundamental Union-Find problem, in which we are given a graph as a sequence of
edges, and must maintain its connectivity structure under edge additions. We
prove that classic sequential algorithms for this problem are
well-parallelizable under reasonable assumptions, addressing a conjecture by
[Blelloch, 2017]. More precisely, we show via a new potential argument that,
under uniform random edge ordering, parallel union-find operations are unlikely
to interfere: $T$ concurrent threads processing the graph in parallel will
encounter memory contention $O(T^2 \cdot \log |V| \cdot \log |E|)$ times in
expectation, where $|E|$ and $|V|$ are the number of edges and nodes in the
graph, respectively. We leverage this result to design a new parallel
Union-Find algorithm that is both internally deterministic, i.e., its results
are guaranteed to match those of a sequential execution, but also
work-efficient and scalable, as long as the number of threads $T$ is
$O(|E|^{\frac{1}{3} - \varepsilon})$, for an arbitrarily small constant
$\varepsilon &gt; 0$, which holds for most large real-world graphs. We present
lower bounds which show that our analysis is close to optimal, and experimental
results suggesting that the performance cost of internal determinism is
limited.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fedorov_A/0/1/0/all/0/1">Alexander Fedorov</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_D/0/1/0/all/0/1">Diba Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadiradze_G/0/1/0/all/0/1">Giorgi Nadiradze</a>, <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a></p><p>Determining the degree of inherent parallelism in classical sequential
algorithms and leveraging it for fast parallel execution is a key topic in
parallel computing, and detailed analyses are known for a wide range of
classical algorithms. In this paper, we perform the first such analysis for the
fundamental Union-Find problem, in which we are given a graph as a sequence of
edges, and must maintain its connectivity structure under edge additions. We
prove that classic sequential algorithms for this problem are
well-parallelizable under reasonable assumptions, addressing a conjecture by
[Blelloch, 2017]. More precisely, we show via a new potential argument that,
under uniform random edge ordering, parallel union-find operations are unlikely
to interfere: $T$ concurrent threads processing the graph in parallel will
encounter memory contention $O(T^2 \cdot \log |V| \cdot \log |E|)$ times in
expectation, where $|E|$ and $|V|$ are the number of edges and nodes in the
graph, respectively. We leverage this result to design a new parallel
Union-Find algorithm that is both internally deterministic, i.e., its results
are guaranteed to match those of a sequential execution, but also
work-efficient and scalable, as long as the number of threads $T$ is
$O(|E|^{\frac{1}{3} - \varepsilon})$, for an arbitrarily small constant
$\varepsilon &gt; 0$, which holds for most large real-world graphs. We present
lower bounds which show that our analysis is close to optimal, and experimental
results suggesting that the performance cost of internal determinism is
limited.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
