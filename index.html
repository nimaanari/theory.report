<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>
  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel='stylesheet' type='text/css' href='css/font-awesome.css'>
  <link rel='stylesheet' type='text/css' href='css/blank.css'>
</head>
<body>
  <div id='navwrap'>
    <div id='nav'>
      <p>
        Last Update
      </p>
      <p class='small'>
        
          <time class='timeago' datetime="2022-09-28T17:56:22Z">Wednesday, September 28 2022, 17:56</time>
        
      </p>

      <p>Feeds</p>
      <ul class='subscriptions small' >
      
        <li>
          <a href='http://arxiv.org/rss/cs.CC'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.CG'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.DS'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
          
        </li>
      
        <li>
          <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
          
        </li>
      
        <li>
          <a href='https://adamsheffer.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
          
        </li>
      
        <li>
          <a href='https://adamdsmith.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
          
        </li>
      
        <li>
          <a href='https://polylogblog.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
          
        </li>
      
        <li>
          <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
          
        </li>
      
        <li>
          <a href='http://www.argmin.net/feed.xml'><img src='i/feed.png'></a>
          <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
          
        </li>
      
        <li>
          <a href='http://bit-player.org/feed/atom/'><img src='i/feed.png'></a>
          <a href='http://bit-player.org'>bit-player</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-jobs.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-jobs.org'>CCI: jobs</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-events.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-events.org'>CS Theory Events</a>
          
        </li>
      
        <li>
          <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='https://11011110.github.io/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='https://11011110.github.io/blog/'>David Eppstein</a>
          
        </li>
      
        <li>
          <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='i/feed.png'></a>
          <a href='https://daveagp.wordpress.com'>David Pritchard</a>
          
        </li>
      
        <li>
          <a href='https://decentdescent.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://decentdescent.org/'>Decent Descent</a>
          
        </li>
      
        <li>
          <a href='https://decentralizedthoughts.github.io/feed'><img src='i/feed.png'></a>
          <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
          
        </li>
      
        <li>
          <a href='https://differentialprivacy.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
          
        </li>
      
        <li>
          <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='i/feed.png'></a>
          <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
          
        </li>
      
        <li>
          <a href='https://emanueleviola.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
          
        </li>
      
        <li>
          <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='i/feed.png'></a>
          <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
          
        </li>
      
        <li>
          <a href='https://dstheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
          
        </li>
      
        <li>
          <a href='https://francisbach.com/feed/'><img src='i/feed.png'></a>
          <a href='https://francisbach.com'>Francis Bach</a>
          
        </li>
      
        <li>
          <a href='https://gilkalai.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
          
        </li>
      
        <li>
          <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
          
        </li>
      
        <li>
          <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='i/feed.png'></a>
          <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
          
        </li>
      
        <li>
          <a href='https://gradientscience.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://gradientscience.org/'>Gradient Science</a>
          
        </li>
      
        <li>
          <a href='http://grigory.us/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
          
        </li>
      
        <li>
          <a href='https://tcsmath.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
          
        </li>
      
        <li>
          <a href='https://kamathematics.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
          
        </li>
      
        <li>
          <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
          
        </li>
      
        <li>
          <a href='https://lucatrevisan.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
          
        </li>
      
        <li>
          <a href='https://mittheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
          
        </li>
      
        <li>
          <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
          
        </li>
      
        <li>
          <a href='http://blog.mrtz.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
          
        </li>
      
        <li>
          <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
          
        </li>
      
        <li>
          <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
          
        </li>
      
        <li>
          <a href='http://www.solipsistslog.com/feed/'><img src='i/feed.png'></a>
          <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
          
        </li>
      
        <li>
          <a href='http://www.offconvex.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://offconvex.github.io/'>Off the Convex Path</a>
          
        </li>
      
        <li>
          <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
          
        </li>
      
        <li>
          <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
          
        </li>
      
        <li>
          <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='i/feed.png'></a>
          <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
          
        </li>
      
        <li>
          <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
          
        </li>
      
        <li>
          <a href='https://scottaaronson.blog/?feed=atom'><img src='i/feed.png'></a>
          <a href='https://scottaaronson.blog'>Scott Aaronson</a>
          
        </li>
      
        <li>
          <a href='https://blog.simons.berkeley.edu/feed/'><img src='i/feed.png'></a>
          <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
          
        </li>
      
        <li>
          <a href='https://tcsplus.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
          
        </li>
      
        <li>
          <a href='https://toc4fairness.org/feed/'><img src='i/feed.png'></a>
          <a href='https://toc4fairness.org'>TOC for Fairness</a>
          
        </li>
      
        <li>
          <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='i/feed.png'></a>
          <a href='http://blog.geomblog.org/'>The Geomblog</a>
          
        </li>
      
        <li>
          <a href='https://www.let-all.com/blog/feed/'><img src='i/feed.png'></a>
          <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
          
        </li>
      
        <li>
          <a href='https://theorydish.blog/feed/'><img src='i/feed.png'></a>
          <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
          
        </li>
      
        <li>
          <a href='https://thmatters.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://thmatters.wordpress.com'>Theory Matters</a>
          
        </li>
      
        <li>
          <a href='https://mycqstate.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
          
        </li>
      
        <li>
          <a href='https://agtb.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
          
        </li>
      
        <li>
          <a href='https://windowsontheory.org/feed/'><img src='i/feed.png'></a>
          <a href='https://windowsontheory.org'>Windows on Theory</a>
          
        </li>
      
      </ul>

      <p class='small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
      <p class='small'>Subscribe to the <a href="atom.xml">Atom feed</a> or <a href="rss20.xml">RSS feed</a> to stay up to date.</p>
      <p class='small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
      <p class='small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
      <p class='small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
    </div>
  </div>

  <div id='opts'>
    <div style='width: 100%; text-align: right;'>
    <img src='i/view-headlines.png' id='show-headlines' title='Show Headlines Only' width='24' height='24'>
    <img src='i/view-snippets.png' id='show-snippets' title='Show Snippets' width='24' height='24'>
    <img src='i/view-standard.png' id='show-fulltext' title='Show Full Text' width='24' height='24'>
    </div>
  </div>

  <h1>
    Theory of Computing Report
  </h1>

  <div id="articles">
    
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Wednesday, September 28
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/28/phd-and-postdoc-at-irif-apply-by-november-1-2022/'>PhD and postdoc at IRIF (apply by November 1, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The Algorithms &#38; Complexity group at IRIF (CNRS, Université Paris-Cité) in Paris offers multiple PhD and postdoc positions on the theory of quantum computing. The group has expertise in quantum algorithms and quantum complexity theory, with permanent members S. Apers, I. Kerenidis, S. Laplante and F. Magniez. Soft deadline: November 1st, 2022. Website: irif.fr/en/equipes/algocomp/ Email: [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The Algorithms &amp; Complexity group at IRIF (CNRS, Université Paris-Cité) in Paris offers multiple PhD and postdoc positions on the theory of quantum computing. The group has expertise in quantum algorithms and quantum complexity theory, with permanent members S. Apers, I. Kerenidis, S. Laplante and F. Magniez.</p>
<p>Soft deadline: November 1st, 2022.</p>
<p>Website: irif.fr/en/equipes/algocomp/<br />
Email: apers@irif.fr</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T10:12:03Z">Wednesday, September 28 2022, 10:12</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13148'>Strategyproofness-Exposing Mechanism Descriptions</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Yannai A. Gonczarowski, Ori Heffetz, Clayton Thomas</p><p>A menu description defines a mechanism to player $i$ in two steps. Step (1)
uses the reports of other players to describe $i$'s menu: the set of $i$'s
potential outcomes. Step (2) uses $i$'s report to select $i$'s favorite outcome
from her menu. Can menu descriptions better expose strategyproofness, without
sacrificing simplicity? We propose a new, simple menu description of Deferred
Acceptance. We prove that -- in contrast with other common matching mechanisms
-- this menu description must differ substantially from the corresponding
traditional description. We demonstrate, with a lab experiment on two simple
mechanisms, the promise and challenges of menu descriptions.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/econ/1/au:+Gonczarowski_Y/0/1/0/all/0/1">Yannai A. Gonczarowski</a>, <a href="http://arxiv.org/find/econ/1/au:+Heffetz_O/0/1/0/all/0/1">Ori Heffetz</a>, <a href="http://arxiv.org/find/econ/1/au:+Thomas_C/0/1/0/all/0/1">Clayton Thomas</a></p><p>A menu description defines a mechanism to player $i$ in two steps. Step (1)
uses the reports of other players to describe $i$'s menu: the set of $i$'s
potential outcomes. Step (2) uses $i$'s report to select $i$'s favorite outcome
from her menu. Can menu descriptions better expose strategyproofness, without
sacrificing simplicity? We propose a new, simple menu description of Deferred
Acceptance. We prove that -- in contrast with other common matching mechanisms
-- this menu description must differ substantially from the corresponding
traditional description. We demonstrate, with a lab experiment on two simple
mechanisms, the promise and challenges of menu descriptions.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13404'>Polynomial time computable functions over the reals characterized using discrete ordinary differential equations</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Manon Blanc, Olivier Bournez</p><p>The class of functions from the integers to the integers computable in
polynomial time has been characterized recently using discrete ordinary
differential equations (ODE), also known as finite differences. In the
framework of ordinary differential equations, this is very natural to try to
extend the approach to classes of functions over the reals, and not only over
the integers. Recently, an extension of previous characterization was obtained
for functions from the integers to the reals, but the method used in the proof,
based on the existence of a continuous function from the integers to a suitable
discrete set of reals, cannot extend to functions from the reals to the reals,
as such a function cannot exist for clear topological reasons. In this article,
we prove that this is indeed possible to provide an elegant and simple
algebraic characterization of functions from the reals to the reals: we provide
a characterization of such functions as the smallest class of functions that
contains some basic functions, and that is closed by composition, linear length
ODEs, and a natural effective limit schema. This is obtained using an
alternative proof technique based on the construction of specific suitable
functions defined recursively, and a barycentric method. Furthermore, we also
extend previous characterizations in several directions: First, we prove that
there is no need of multiplication. We prove a normal form theorem, with a nice
side effect related to formal neural networks. Indeed, given some fixed error
and some polynomial time t(n), our settings produce effectively some neural
network that computes the function over its domain with the given precision,
for any t(n)-polynomial time computable function f .
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blanc_M/0/1/0/all/0/1">Manon Blanc</a>, <a href="http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1">Olivier Bournez</a></p><p>The class of functions from the integers to the integers computable in
polynomial time has been characterized recently using discrete ordinary
differential equations (ODE), also known as finite differences. In the
framework of ordinary differential equations, this is very natural to try to
extend the approach to classes of functions over the reals, and not only over
the integers. Recently, an extension of previous characterization was obtained
for functions from the integers to the reals, but the method used in the proof,
based on the existence of a continuous function from the integers to a suitable
discrete set of reals, cannot extend to functions from the reals to the reals,
as such a function cannot exist for clear topological reasons. In this article,
we prove that this is indeed possible to provide an elegant and simple
algebraic characterization of functions from the reals to the reals: we provide
a characterization of such functions as the smallest class of functions that
contains some basic functions, and that is closed by composition, linear length
ODEs, and a natural effective limit schema. This is obtained using an
alternative proof technique based on the construction of specific suitable
functions defined recursively, and a barycentric method. Furthermore, we also
extend previous characterizations in several directions: First, we prove that
there is no need of multiplication. We prove a normal form theorem, with a nice
side effect related to formal neural networks. Indeed, given some fixed error
and some polynomial time t(n), our settings produce effectively some neural
network that computes the function over its domain with the given precision,
for any t(n)-polynomial time computable function f .
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13024'>Improved and Generalized Algorithms for Burning a Planar Point Set</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Prashant Gokhale, J. Mark Keil, Debajyoti Mondal</p><p>Given a set $P$ of points in the plane, a point burning process is a discrete
time process to burn all the points of $P$ where fires must be initiated at the
given points. Specifically, the point burning process starts with a single
burnt point from $P$, and at each subsequent step, burns all the points in the
plane that are within one unit distance from the currently burnt points, as
well as one other unburnt point of $P$ (if exists). The point burning number of
$P$ is the smallest number of steps required to burn all the points of $P$. If
we allow the fire to be initiated anywhere, then the burning process is called
an anywhere burning process, and the corresponding burning number is called
anywhere burning number. Computing the point and anywhere burning number is
known to be NP-hard. In this paper we show that both these problems admit PTAS
in one dimension. We then show that in two dimensions, point burning and
anywhere burning are $(1.96296+\varepsilon)$ and $(1.92188+\varepsilon)$
approximable, respectively, for every $\varepsilon&gt;0$, which improves the
previously known $(2+\varepsilon)$ factor for these problems. We also observe
that a known result on set cover problem can be leveraged to obtain a
2-approximation for burning the maximum number of points in a given number of
steps. We show how the results generalize if we allow the points to have
different fire spreading rates. Finally, we prove that even if the burning
sources are given as input, finding a point burning sequence itself is NP-hard.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gokhale_P/0/1/0/all/0/1">Prashant Gokhale</a>, <a href="http://arxiv.org/find/cs/1/au:+Keil_J/0/1/0/all/0/1">J. Mark Keil</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1">Debajyoti Mondal</a></p><p>Given a set $P$ of points in the plane, a point burning process is a discrete
time process to burn all the points of $P$ where fires must be initiated at the
given points. Specifically, the point burning process starts with a single
burnt point from $P$, and at each subsequent step, burns all the points in the
plane that are within one unit distance from the currently burnt points, as
well as one other unburnt point of $P$ (if exists). The point burning number of
$P$ is the smallest number of steps required to burn all the points of $P$. If
we allow the fire to be initiated anywhere, then the burning process is called
an anywhere burning process, and the corresponding burning number is called
anywhere burning number. Computing the point and anywhere burning number is
known to be NP-hard. In this paper we show that both these problems admit PTAS
in one dimension. We then show that in two dimensions, point burning and
anywhere burning are $(1.96296+\varepsilon)$ and $(1.92188+\varepsilon)$
approximable, respectively, for every $\varepsilon&gt;0$, which improves the
previously known $(2+\varepsilon)$ factor for these problems. We also observe
that a known result on set cover problem can be leveraged to obtain a
2-approximation for burning the maximum number of points in a given number of
steps. We show how the results generalize if we allow the points to have
different fire spreading rates. Finally, we prove that even if the burning
sources are given as input, finding a point burning sequence itself is NP-hard.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13311'>Optimal Placement of Base Stations in Border Surveillance using Limited Capacity Drones</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: S. Bereg, J.M. D&#xed;az-B&#xe1;&#xf1;ez, M. Haghpanah, P. Horn, M.A. Lopez, N. Mar&#xed;n, A. Ram&#xed;rez-Vigueras, F. Rodr&#xed;guez, O. Sol&#xe9;-Pi, A. Stevens, J. Urrutia</p><p>Imagine an island modeled as a simple polygon $\P$ with $n$ vertices whose
coastline we wish to monitor. We consider the problem of building the minimum
number of refueling stations along the boundary of $\P$ in such a way that a
drone can follow a polygonal route enclosing the island without running out of
fuel. A drone can fly a maximum distance $d$ between consecutive stations and
is restricted to move either along the boundary of $\P$ or its exterior (i.e.,
over water). We present an algorithm that, given $\mathcal P$, finds the
locations for a set of refueling stations whose cardinality is at most the
optimal plus one. The time complexity of this algorithm is $O(n^2 + \frac{L}{d}
n)$, where $L$ is the length of $\mathcal P$. We also present an algorithm that
returns an additive $\epsilon$-approximation for the problem of minimizing the
fuel capacity required for the drones when we are allowed to place $k$ base
stations around the boundary of the island; this algorithm also finds the
locations of these refueling stations. Finally, we propose a practical
discretization heuristic which, under certain conditions, can be used to
certify optimality of the results.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bereg_S/0/1/0/all/0/1">S. Bereg</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1">J.M. D&#xed;az-B&#xe1;&#xf1;ez</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghpanah_M/0/1/0/all/0/1">M. Haghpanah</a>, <a href="http://arxiv.org/find/cs/1/au:+Horn_P/0/1/0/all/0/1">P. Horn</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_M/0/1/0/all/0/1">M.A. Lopez</a>, <a href="http://arxiv.org/find/cs/1/au:+Marin_N/0/1/0/all/0/1">N. Mar&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramirez_Vigueras_A/0/1/0/all/0/1">A. Ram&#xed;rez-Vigueras</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_F/0/1/0/all/0/1">F. Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Sole_Pi_O/0/1/0/all/0/1">O. Sol&#xe9;-Pi</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevens_A/0/1/0/all/0/1">A. Stevens</a>, <a href="http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1">J. Urrutia</a></p><p>Imagine an island modeled as a simple polygon $\P$ with $n$ vertices whose
coastline we wish to monitor. We consider the problem of building the minimum
number of refueling stations along the boundary of $\P$ in such a way that a
drone can follow a polygonal route enclosing the island without running out of
fuel. A drone can fly a maximum distance $d$ between consecutive stations and
is restricted to move either along the boundary of $\P$ or its exterior (i.e.,
over water). We present an algorithm that, given $\mathcal P$, finds the
locations for a set of refueling stations whose cardinality is at most the
optimal plus one. The time complexity of this algorithm is $O(n^2 + \frac{L}{d}
n)$, where $L$ is the length of $\mathcal P$. We also present an algorithm that
returns an additive $\epsilon$-approximation for the problem of minimizing the
fuel capacity required for the drones when we are allowed to place $k$ base
stations around the boundary of the island; this algorithm also finds the
locations of these refueling stations. Finally, we propose a practical
discretization heuristic which, under certain conditions, can be used to
certify optimality of the results.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13538'>Mathematics and Flamenco: An Unexpected Partnership</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jos&#xe9;-Miguel D&#xed;az-B&#xe1;&#xf1;ez</p><p>In this paper, we present a series of mathematical problems which throw
interesting lights on flamenco music. More specifically, these are problems in
discrete and computational mathematics suggested by an analytical (not
compositional) examination of flamenco ``cante'' (singing). As a consequence,
since the problems are taken from a culturally specific context, the examples
can make more effective mathematics education.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1">Jos&#xe9;-Miguel D&#xed;az-B&#xe1;&#xf1;ez</a></p><p>In this paper, we present a series of mathematical problems which throw
interesting lights on flamenco music. More specifically, these are problems in
discrete and computational mathematics suggested by an analytical (not
compositional) examination of flamenco ``cante'' (singing). As a consequence,
since the problems are taken from a culturally specific context, the examples
can make more effective mathematics education.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13028'>How to Sample From The Limiting Distribution of a Continuous-Time Quantum Walk</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Javad Doliskani</p><p>We introduce $\varepsilon$-projectors, using which we can sample from
limiting distributions of continuous-time quantum walks. The standard algorithm
for sampling from a distribution that is close to the limiting distribution of
a given quantum walk is to run the quantum walk for a time chosen uniformly at
random from a large interval, and measure the resulting quantum state. This
approach usually results in an exponential running time.
</p>
<p>We show that, using $\varepsilon$-projectors, we can sample exactly from the
limiting distribution. In the black-box setting, where we only have query
access to the adjacency matrix of the graph, our sampling algorithm runs in
time proportional to $\Delta^{-1}$, where $\Delta$ is the minimum spacing
between the distinct eigenvalues of the graph. In the non-black-box setting, we
give examples of graphs for which our algorithm runs exponentially faster than
the standard sampling algorithm.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Doliskani_J/0/1/0/all/0/1">Javad Doliskani</a></p><p>We introduce $\varepsilon$-projectors, using which we can sample from
limiting distributions of continuous-time quantum walks. The standard algorithm
for sampling from a distribution that is close to the limiting distribution of
a given quantum walk is to run the quantum walk for a time chosen uniformly at
random from a large interval, and measure the resulting quantum state. This
approach usually results in an exponential running time.
</p>
<p>We show that, using $\varepsilon$-projectors, we can sample exactly from the
limiting distribution. In the black-box setting, where we only have query
access to the adjacency matrix of the graph, our sampling algorithm runs in
time proportional to $\Delta^{-1}$, where $\Delta$ is the minimum spacing
between the distinct eigenvalues of the graph. In the non-black-box setting, we
give examples of graphs for which our algorithm runs exponentially faster than
the standard sampling algorithm.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13063'>Quantum-Inspired Perfect Matching under Vertex-Color Constraints</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Moshe Y. Vardi, Zhiwei Zhang</p><p>We propose and study the graph-theoretical problem PM-VC: perfect matching
under vertex-color constraints on graphs with bi-colored edges. PM-VC is of
special interest because of its motivation from quantum-state identification
and quantum-experiment design, as well as its rich expressiveness, i.e., PM-VC
subsumes many constrained matching problems naturally, such as exact perfect
matching. We give complexity and algorithmic results for PM-VC under two types
of vertex color constraints: 1) symmetric constraints (PM-VC-Sym) and 2)
decision-diagram constraints (PM-VC-DD).
</p>
<p>We prove that PM-VC-Sym is in RNC via a symbolic determinant algorithm, which
can be derandomized on planar graphs. Moreover, PM-VC-Sym can be expressed in
extended MSO, which encourages our design of an efficient dynamic programming
algorithm for PM-VC-Sym on bounded-treewidth graphs. For PM-VC-DD, we reveal
its NP-hardness by a graph-gadget technique. Our novel results for PM-VC
provide insights to both constrained matching and scalable quantum experiment
design.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1">Moshe Y. Vardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a></p><p>We propose and study the graph-theoretical problem PM-VC: perfect matching
under vertex-color constraints on graphs with bi-colored edges. PM-VC is of
special interest because of its motivation from quantum-state identification
and quantum-experiment design, as well as its rich expressiveness, i.e., PM-VC
subsumes many constrained matching problems naturally, such as exact perfect
matching. We give complexity and algorithmic results for PM-VC under two types
of vertex color constraints: 1) symmetric constraints (PM-VC-Sym) and 2)
decision-diagram constraints (PM-VC-DD).
</p>
<p>We prove that PM-VC-Sym is in RNC via a symbolic determinant algorithm, which
can be derandomized on planar graphs. Moreover, PM-VC-Sym can be expressed in
extended MSO, which encourages our design of an efficient dynamic programming
algorithm for PM-VC-Sym on bounded-treewidth graphs. For PM-VC-DD, we reveal
its NP-hardness by a graph-gadget technique. Our novel results for PM-VC
provide insights to both constrained matching and scalable quantum experiment
design.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13134'>An $O(3.82^k)$ Time FPT Algorithm for Convex Flip Distance</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Haohong Li, Ge Xia</p><p>Let ${\cal P}$ be a convex polygon in the plane, and let ${\cal T}$ be a
triangulation of ${\cal P}$. An edge $e$ in ${\cal T}$ is called a diagonal if
it is shared by two triangles in ${\cal T}$. A {\em flip} of a diagonal $e$ is
the operation of removing $e$ and adding the opposite diagonal of the resulting
quadrilateral to obtain a new triangulation of ${\cal P}$ from ${\cal T}$. The
{\em flip distance} between two triangulations of ${\cal P}$ is the minimum
number of flips needed to transform one triangulation into the other. The {\sc
Convex Flip Distance} problem asks if the flip distance between two given
triangulations of ${\cal P}$ is at most $k$, for some given parameter $k$.
</p>
<p>We present an FPT algorithm for the {\sc Convex Flip Distance} problem that
runs in time $O(3.82^{k})$ and uses polynomial space, where $k$ is the number
of flips. This algorithm significantly improves the previous best FPT
algorithms for the problem.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haohong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1">Ge Xia</a></p><p>Let ${\cal P}$ be a convex polygon in the plane, and let ${\cal T}$ be a
triangulation of ${\cal P}$. An edge $e$ in ${\cal T}$ is called a diagonal if
it is shared by two triangles in ${\cal T}$. A {\em flip} of a diagonal $e$ is
the operation of removing $e$ and adding the opposite diagonal of the resulting
quadrilateral to obtain a new triangulation of ${\cal P}$ from ${\cal T}$. The
{\em flip distance} between two triangulations of ${\cal P}$ is the minimum
number of flips needed to transform one triangulation into the other. The {\sc
Convex Flip Distance} problem asks if the flip distance between two given
triangulations of ${\cal P}$ is at most $k$, for some given parameter $k$.
</p>
<p>We present an FPT algorithm for the {\sc Convex Flip Distance} problem that
runs in time $O(3.82^{k})$ and uses polynomial space, where $k$ is the number
of flips. This algorithm significantly improves the previous best FPT
algorithms for the problem.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13175'>Partial and Simultaneous Transitive Orientations via Modular Decomposition</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Miriam M&#xfc;nch, Ignaz Rutter, Peter Stumpf</p><p>A natural generalization of the recognition problem for a geometric graph
class is the problem of extending a representation of a subgraph to a
representation of the whole graph. A related problem is to find representations
for multiple input graphs that coincide on subgraphs shared by the input
graphs. A common restriction is the sunflower case where the shared graph is
the same for each pair of input graphs. These problems translate to the setting
of comparability graphs where the representations correspond to transitive
orientations of their edges. We use modular decompositions to improve the
runtime for the orientation extension problem and the sunflower orientation
problem to linear time. We apply these results to improve the runtime for the
partial representation problem and the sunflower case of the simultaneous
representation problem for permutation graphs to linear time. We also give the
first efficient algorithms for these problems on circular permutation graphs.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Munch_M/0/1/0/all/0/1">Miriam M&#xfc;nch</a>, <a href="http://arxiv.org/find/cs/1/au:+Rutter_I/0/1/0/all/0/1">Ignaz Rutter</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpf_P/0/1/0/all/0/1">Peter Stumpf</a></p><p>A natural generalization of the recognition problem for a geometric graph
class is the problem of extending a representation of a subgraph to a
representation of the whole graph. A related problem is to find representations
for multiple input graphs that coincide on subgraphs shared by the input
graphs. A common restriction is the sunflower case where the shared graph is
the same for each pair of input graphs. These problems translate to the setting
of comparability graphs where the representations correspond to transitive
orientations of their edges. We use modular decompositions to improve the
runtime for the orientation extension problem and the sunflower orientation
problem to linear time. We apply these results to improve the runtime for the
partial representation problem and the sunflower case of the simultaneous
representation problem for permutation graphs to linear time. We also give the
first efficient algorithms for these problems on circular permutation graphs.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13355'>Algorithms for Large-scale Network Analysis and the NetworKit Toolkit</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Eugenio Angriman, Alexander van der Grinten, Michael Hamann, Henning Meyerhenke, Manuel Penschuck</p><p>The abundance of massive network data in a plethora of applications makes
scalable analysis algorithms and software tools necessary to generate knowledge
from such data in reasonable time. Addressing scalability as well as other
requirements such as good usability and a rich feature set, the open-source
software NetworKit has established itself as a popular tool for large-scale
network analysis. This chapter provides a brief overview of the contributions
to NetworKit made by the DFG Priority Programme SPP 1736 Algorithms for Big
Data. Algorithmic contributions in the areas of centrality computations,
community detection, and sparsification are in the focus, but we also mention
several other aspects -- such as current software engineering principles of the
project and ways to visualize network data within a NetworKit-based workflow.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Angriman_E/0/1/0/all/0/1">Eugenio Angriman</a>, <a href="http://arxiv.org/find/cs/1/au:+Grinten_A/0/1/0/all/0/1">Alexander van der Grinten</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamann_M/0/1/0/all/0/1">Michael Hamann</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyerhenke_H/0/1/0/all/0/1">Henning Meyerhenke</a>, <a href="http://arxiv.org/find/cs/1/au:+Penschuck_M/0/1/0/all/0/1">Manuel Penschuck</a></p><p>The abundance of massive network data in a plethora of applications makes
scalable analysis algorithms and software tools necessary to generate knowledge
from such data in reasonable time. Addressing scalability as well as other
requirements such as good usability and a rich feature set, the open-source
software NetworKit has established itself as a popular tool for large-scale
network analysis. This chapter provides a brief overview of the contributions
to NetworKit made by the DFG Priority Programme SPP 1736 Algorithms for Big
Data. Algorithmic contributions in the areas of centrality computations,
community detection, and sparsification are in the focus, but we also mention
several other aspects -- such as current software engineering principles of the
project and ways to visualize network data within a NetworKit-based workflow.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Tuesday, September 27
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://blog.simons.berkeley.edu/2022/09/the-blooming-of-the-c3-ltc-flowers/'>The Blooming of the \(c^3\) LTC Flowers</a></h3>
          <p class='item-feed'>from <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          by Prahladh Harsha The last year (2021–22) has seen some amazing new constructions of locally testable codes with constant rate and constant fractional distance and testable with a constant number of queries, sometimes referred to as \(c^3\) LTCs [DELLM22, PK22]. &#8230; Continue reading &#8594;<p>By Simons Institute Editor</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          by Prahladh Harsha The last year (2021–22) has seen some amazing new constructions of locally testable codes with constant rate and constant fractional distance and testable with a constant number of queries, sometimes referred to as \(c^3\) LTCs [DELLM22, PK22]. &#8230; <a href="https://blog.simons.berkeley.edu/2022/09/the-blooming-of-the-c3-ltc-flowers/">Continue reading <span class="meta-nav">&#8594;</span></a><p class="authors">By Simons Institute Editor</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T17:51:01Z">Tuesday, September 27 2022, 17:51</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/27/postdoc-in-quantum-algorithms-complexity-at-university-of-warwick-apply-by-october-18-2022/'>Postdoc in Quantum Algorithms & Complexity at University of Warwick (apply by October 18, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We seek to appoint a postdoc for 24 months starting in March 2023 or as soon as possible thereafter. The aim is to study property testing algorithms for quantum channels as part of a collaboration between CS &#38; Physics at Warwick, led by Animesh Datta and Tom Gur. For informal enquires, email your CV, explaining [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>We seek to appoint a postdoc for 24 months starting in March 2023 or as soon as possible thereafter. The aim is to study property testing algorithms for quantum channels as part of a collaboration between CS &amp; Physics at Warwick, led by Animesh Datta and Tom Gur.</p>
<p>For informal enquires, email your CV, explaining your suitability for the position.</p>
<p>Website: <a href="https://atsv7.wcn.co.uk/search_engine/jobs.cgi?owner=5062452&amp;ownertype=fair&amp;jcode=1888004&amp;vt_template=1457&amp;adminview=1">https://atsv7.wcn.co.uk/search_engine/jobs.cgi?owner=5062452&amp;ownertype=fair&amp;jcode=1888004&amp;vt_template=1457&amp;adminview=1</a><br />
Email: animesh.datta@warwick.ac.uk; tom.gur@warwick.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T15:22:22Z">Tuesday, September 27 2022, 15:22</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/137'>TR22-137 |  On blocky ranks of matrices | 

	Daniel Avraham , 

	Amir Yehudayoff</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          A matrix is blocky if it is a blowup of a permutation matrix. The blocky rank of a matrix M is the minimum number of blocky matrices that linearly span M. Hambardzumyan, Hatami and Hatami defined blocky rank and showed that it is connected to communication complexity and operator theory. We describe additional connections to circuit complexity and combinatorics, and we prove upper and lower bounds on blocky rank in various contexts.
        
        </div>

        <div class='item-content item-summary'>
        
          
          A matrix is blocky if it is a blowup of a permutation matrix. The blocky rank of a matrix M is the minimum number of blocky matrices that linearly span M. Hambardzumyan, Hatami and Hatami defined blocky rank and showed that it is connected to communication complexity and operator theory. We describe additional connections to circuit complexity and combinatorics, and we prove upper and lower bounds on blocky rank in various contexts.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T12:24:21Z">Tuesday, September 27 2022, 12:24</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://blog.computationalcomplexity.org/2022/09/is-complexity-of-vertex-cover-of-degree.html'>Is the complexity of approximating Vertex Cover of degree 3 open? (ADDED LATER-NO)</a></h3>
          <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>&nbsp;RECALL:</p><p>A max-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \ge (1-\epsilon)f(x).</p><p><br></p><p>A min-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \le (1+\epsilon)f(x).</p><p><br></p><p>(Note that the poly can depend on epsilon so it may be something like n^{1/epsilon}.)</p><p><br></p><p>MAX3SAT is, given a formula with \le 3 literals per clause, find an assignment</p><p>that maximized the number of clauses satisfied.</p><p><br></p><p>VCB-a is Vertex cover where graphs have degree \le a</p><p><br></p><p>The following are known:</p><p>0) MAX3SAT is in APX.</p><p>1) The PCP paper,&nbsp;here, showed that if MAX3SAT has a PTAS then P=NP.</p><p>2) Papadimitriou and Yannakakis (here)&nbsp; had showed much earlier that MAX3SAT \le VCB-4 with an approx preserving reduction.</p><p>3) From (1) and (2) we have that VCB-4 has a PTAS then P=NP. (VC is in APX by an easy 2-approx).</p><p>4) Clearly VCB-2 is in P.</p><p>The following seems to be open, though if you know otherwise pleae leave a comment:</p><p><br></p><p>Is VCB-3 a) in P? b) NPC? (ADDED LATER- NPC- See comments.)&nbsp;</p><p>Is the following true: if VCB-3 has a PTAS then P=NP. (ADDED LATER- NO PTAS-See Comments)</p><p><br></p><p>NOTE- all of the above is true for Ind Set-4 and Dom Set-4. So that leads to more open problems.</p><br><p>By gasarch</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>&nbsp;RECALL:</p><p>A max-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \ge (1-\epsilon)f(x).</p><p><br /></p><p>A min-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \le (1+\epsilon)f(x).</p><p><br /></p><p>(Note that the poly can depend on epsilon so it may be something like n^{1/epsilon}.)</p><p><br /></p><p>MAX3SAT is, given a formula with \le 3 literals per clause, find an assignment</p><p>that maximized the number of clauses satisfied.</p><p><br /></p><p>VCB-a is Vertex cover where graphs have degree \le a</p><p><br /></p><p>The following are known:</p><p>0) MAX3SAT is in APX.</p><p>1) The PCP paper,&nbsp;<a href="https://doi.org/10.1145/278298.278306">here</a>, showed that if MAX3SAT has a PTAS then P=NP.</p><p>2) Papadimitriou and Yannakakis (<a href="https://doi.org/10.1016/0022-0000(91)90023-X">here</a>)&nbsp; had showed much earlier that MAX3SAT \le VCB-4 with an approx preserving reduction.</p><p>3) From (1) and (2) we have that VCB-4 has a PTAS then P=NP. (VC is in APX by an easy 2-approx).</p><p>4) Clearly VCB-2 is in P.</p><p>The following seems to be open, though if you know otherwise pleae leave a comment:</p><p><br /></p><p>Is VCB-3 a) in P? b) NPC? (ADDED LATER- NPC- See comments.)&nbsp;</p><p>Is the following true: if VCB-3 has a PTAS then P=NP. (ADDED LATER- NO PTAS-See Comments)</p><p><br /></p><p>NOTE- all of the above is true for Ind Set-4 and Dom Set-4. So that leads to more open problems.</p><div><br /></div><p class="authors">By gasarch</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T02:02:00Z">Tuesday, September 27 2022, 02:02</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12168'>A characterization of functions over the integers computable in polynomial time using discrete differential equations</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Olivier Bournez, Arnaud Durand</p><p>This paper studies the expressive and computational power of discrete
Ordinary Differential Equations (ODEs), a.k.a. (Ordinary) Difference Equations.
It presents a new framework using these equations as a central tool for
computation and algorithm design. We present the general theory of discrete
ODEs for computation theory, we illustrate this with various examples of
algorithms, and we provide several implicit characterizations of complexity and
computability classes.
</p>
<p>The proposed framework presents an original point of view on complexity and
computation classes. It unifies several constructions that have been proposed
for characterizing these classes including classical approaches in implicit
complexity using restricted recursion schemes, as well as recent
characterizations of computability and complexity by classes of continuous
ordinary differential equations. It also helps understanding the relationships
between analog computations and classical discrete models of computation
theory.
</p>
<p>At a more technical point of view, this paper points out the fundamental role
of linear (discrete) ODEs and classical ODE tools such as changes of variables
to capture computability and complexity measures, or as a tool for programming
many algorithms.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1">Olivier Bournez</a>, <a href="http://arxiv.org/find/cs/1/au:+Durand_A/0/1/0/all/0/1">Arnaud Durand</a></p><p>This paper studies the expressive and computational power of discrete
Ordinary Differential Equations (ODEs), a.k.a. (Ordinary) Difference Equations.
It presents a new framework using these equations as a central tool for
computation and algorithm design. We present the general theory of discrete
ODEs for computation theory, we illustrate this with various examples of
algorithms, and we provide several implicit characterizations of complexity and
computability classes.
</p>
<p>The proposed framework presents an original point of view on complexity and
computation classes. It unifies several constructions that have been proposed
for characterizing these classes including classical approaches in implicit
complexity using restricted recursion schemes, as well as recent
characterizations of computability and complexity by classes of continuous
ordinary differential equations. It also helps understanding the relationships
between analog computations and classical discrete models of computation
theory.
</p>
<p>At a more technical point of view, this paper points out the fundamental role
of linear (discrete) ODEs and classical ODE tools such as changes of variables
to capture computability and complexity measures, or as a tool for programming
many algorithms.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11817'>An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Matthew Jones, Huy L&#xea; Nguyen, Thy Nguyen</p><p>Recently a multi-agent variant of the classical multi-armed bandit was
proposed to tackle fairness issues in online learning. Inspired by a long line
of work in social choice and economics, the goal is to optimize the Nash social
welfare instead of the total utility. Unfortunately previous algorithms either
are not efficient or achieve sub-optimal regret in terms of the number of
rounds $T$. We propose a new efficient algorithm with lower regret than even
previous inefficient ones. For $N$ agents, $K$ arms, and $T$ rounds, our
approach has a regret bound of $\tilde{O}(\sqrt{NKT} + NK)$. This is an
improvement to the previous approach, which has regret bound of $\tilde{O}(
\min(NK, \sqrt{N} K^{3/2})\sqrt{T})$. We also complement our efficient
algorithm with an inefficient approach with $\tilde{O}(\sqrt{KT} + N^2K)$
regret. The experimental findings confirm the effectiveness of our efficient
algorithm compared to the previous approaches.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1">Matthew Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huy L&#xea; Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thy Nguyen</a></p><p>Recently a multi-agent variant of the classical multi-armed bandit was
proposed to tackle fairness issues in online learning. Inspired by a long line
of work in social choice and economics, the goal is to optimize the Nash social
welfare instead of the total utility. Unfortunately previous algorithms either
are not efficient or achieve sub-optimal regret in terms of the number of
rounds $T$. We propose a new efficient algorithm with lower regret than even
previous inefficient ones. For $N$ agents, $K$ arms, and $T$ rounds, our
approach has a regret bound of $\tilde{O}(\sqrt{NKT} + NK)$. This is an
improvement to the previous approach, which has regret bound of $\tilde{O}(
\min(NK, \sqrt{N} K^{3/2})\sqrt{T})$. We also complement our efficient
algorithm with an inefficient approach with $\tilde{O}(\sqrt{KT} + N^2K)$
regret. The experimental findings confirm the effectiveness of our efficient
algorithm compared to the previous approaches.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11934'>The Online Knapsack Problem with Departures</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Bo Sun, Lin Yang, Mohammad Hajiesmaili, Adam Wierman, John C.S. Lui, Don Towsley, Danny H.K. Tsang</p><p>The online knapsack problem is a classic online resource allocation problem
in networking and operations research. Its basic version studies how to pack
online arriving items of different sizes and values into a capacity-limited
knapsack. In this paper, we study a general version that includes item
departures, while also considering multiple knapsacks and multi-dimensional
item sizes. We design a threshold-based online algorithm and prove that the
algorithm can achieve order-optimal competitive ratios. Beyond worst-case
performance guarantees, we also aim to achieve near-optimal average performance
under typical instances. Towards this goal, we propose a data-driven online
algorithm that learns within a policy-class that guarantees a worst-case
performance bound. In trace-driven experiments, we show that our data-driven
algorithm outperforms other benchmark algorithms in an application of online
knapsack to job scheduling for cloud computing.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Bo Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1">Mohammad Hajiesmaili</a>, <a href="http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1">Adam Wierman</a>, <a href="http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1">John C.S. Lui</a>, <a href="http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1">Don Towsley</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsang_D/0/1/0/all/0/1">Danny H.K. Tsang</a></p><p>The online knapsack problem is a classic online resource allocation problem
in networking and operations research. Its basic version studies how to pack
online arriving items of different sizes and values into a capacity-limited
knapsack. In this paper, we study a general version that includes item
departures, while also considering multiple knapsacks and multi-dimensional
item sizes. We design a threshold-based online algorithm and prove that the
algorithm can achieve order-optimal competitive ratios. Beyond worst-case
performance guarantees, we also aim to achieve near-optimal average performance
under typical instances. Towards this goal, we propose a data-driven online
algorithm that learns within a policy-class that guarantees a worst-case
performance bound. In trace-driven experiments, we show that our data-driven
algorithm outperforms other benchmark algorithms in an application of online
knapsack to job scheduling for cloud computing.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11936'>Online Admission Control and Rebalancing in Payment Channel Networks</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mahsa Bastankhah, Krishnendu Chatterjee, Mohammad Ali Maddah-Ali, Stefan Schmid, Jakub Svoboda, Michelle Yeo</p><p>Payment channel networks (PCNs) are a promising technology to improve the
scalability of cryptocurrencies. PCNs, however, face the challenge that the
frequent usage of certain routes may deplete channels in one direction, and
hence prevent further transactions. In order to reap the full potential of
PCNs, recharging and rebalancing mechanisms are required to provision channels,
as well as an admission control logic to decide which transactions to reject in
case capacity is insufficient. This paper presents a formal model of this
optimisation problem. In particular, we consider an online algorithms
perspective, where transactions arrive over time in an unpredictable manner.
Our main contributions are competitive online algorithms which come with
provable guarantees over time. We empirically evaluate our algorithms on
randomly generated transactions to compare the average performance of our
algorithms to our theoretical bounds. We also show how this model and approach
differs from related problems in classic communication networks.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bastankhah_M/0/1/0/all/0/1">Mahsa Bastankhah</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_K/0/1/0/all/0/1">Krishnendu Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddah_Ali_M/0/1/0/all/0/1">Mohammad Ali Maddah-Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Svoboda_J/0/1/0/all/0/1">Jakub Svoboda</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_M/0/1/0/all/0/1">Michelle Yeo</a></p><p>Payment channel networks (PCNs) are a promising technology to improve the
scalability of cryptocurrencies. PCNs, however, face the challenge that the
frequent usage of certain routes may deplete channels in one direction, and
hence prevent further transactions. In order to reap the full potential of
PCNs, recharging and rebalancing mechanisms are required to provision channels,
as well as an admission control logic to decide which transactions to reject in
case capacity is insufficient. This paper presents a formal model of this
optimisation problem. In particular, we consider an online algorithms
perspective, where transactions arrive over time in an unpredictable manner.
Our main contributions are competitive online algorithms which come with
provable guarantees over time. We empirically evaluate our algorithms on
randomly generated transactions to compare the average performance of our
algorithms to our theoretical bounds. We also show how this model and approach
differs from related problems in classic communication networks.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12013'>Non-monotonic Resource Utilization in the Bandits with Knapsacks Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Raunak Kumar, Robert Kleinberg</p><p>Bandits with knapsacks (BwK) is an influential model of sequential
decision-making under uncertainty that incorporates resource consumption
constraints. In each round, the decision-maker observes an outcome consisting
of a reward and a vector of nonnegative resource consumptions, and the budget
of each resource is decremented by its consumption. In this paper we introduce
a natural generalization of the stochastic BwK problem that allows
non-monotonic resource utilization. In each round, the decision-maker observes
an outcome consisting of a reward and a vector of resource drifts that can be
positive, negative or zero, and the budget of each resource is incremented by
its drift. Our main result is a Markov decision process (MDP) policy that has
constant regret against a linear programming (LP) relaxation when the
decision-maker knows the true outcome distributions. We build upon this to
develop a learning algorithm that has logarithmic regret against the same LP
relaxation when the decision-maker does not know the true outcome
distributions. We also present a reduction from BwK to our model that shows our
regret bound matches existing results.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Raunak Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_R/0/1/0/all/0/1">Robert Kleinberg</a></p><p>Bandits with knapsacks (BwK) is an influential model of sequential
decision-making under uncertainty that incorporates resource consumption
constraints. In each round, the decision-maker observes an outcome consisting
of a reward and a vector of nonnegative resource consumptions, and the budget
of each resource is decremented by its consumption. In this paper we introduce
a natural generalization of the stochastic BwK problem that allows
non-monotonic resource utilization. In each round, the decision-maker observes
an outcome consisting of a reward and a vector of resource drifts that can be
positive, negative or zero, and the budget of each resource is incremented by
its drift. Our main result is a Markov decision process (MDP) policy that has
constant regret against a linear programming (LP) relaxation when the
decision-maker knows the true outcome distributions. We build upon this to
develop a learning algorithm that has logarithmic regret against the same LP
relaxation when the decision-maker does not know the true outcome
distributions. We also present a reduction from BwK to our model that shows our
regret bound matches existing results.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12021'>Improving the Bounds of the Online Dynamic Power Management Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Ya-Chun Liang, Kazuo Iwama, Chung-Shou Liao</p><p>We investigate the {\em power-down mechanism} which decides when a machine
transitions between states such that the total energy consumption,
characterized by execution cost, idle cost and switching cost, is minimized. In
contrast to most of the previous studies on the offline model, we focus on the
online model in which a sequence of jobs with their release time, execution
time and deadline, arrive in an online fashion. More precisely, we exploit a
different switching on and off strategy and present an upper bound of 3, and
further show a lower bound of 2.1, in a dual-machine model, introduced by Chen
et al. in 2014 [STACS 2014: 226-238], both of which beat the currently best
result.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Ya-Chun Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwama_K/0/1/0/all/0/1">Kazuo Iwama</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1">Chung-Shou Liao</a></p><p>We investigate the {\em power-down mechanism} which decides when a machine
transitions between states such that the total energy consumption,
characterized by execution cost, idle cost and switching cost, is minimized. In
contrast to most of the previous studies on the offline model, we focus on the
online model in which a sequence of jobs with their release time, execution
time and deadline, arrive in an online fashion. More precisely, we exploit a
different switching on and off strategy and present an upper bound of 3, and
further show a lower bound of 2.1, in a dual-machine model, introduced by Chen
et al. in 2014 [STACS 2014: 226-238], both of which beat the currently best
result.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12023'>Twin-width V: linear minors, modular counting, and matrix multiplication</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: &#xc9;douard Bonnet, Ugo Giocanti, Patrice Ossona de Mendez, St&#xe9;phan Thomass&#xe9;</p><p>We continue developing the theory around the twin-width of totally ordered
binary structures, initiated in the previous paper of the series. We first
introduce the notion of parity and linear minors of a matrix, which consists of
iteratively replacing consecutive rows or consecutive columns with a linear
combination of them. We show that a matrix class has bounded twin-width if and
only if its linear-minor closure does not contain all matrices. We observe that
the fixed-parameter tractable algorithm for first-order model checking on
structures given with an $O(1)$-sequence (certificate of bounded twin-width)
and the fact that first-order transductions of bounded twin-width classes have
bounded twin-width, both established in Twin-width I, extend to first-order
logic with modular counting quantifiers. We make explicit a win-win argument
obtained as a by-product of Twin-width IV, and somewhat similar to
bidimensionality, that we call rank-bidimensionality. Armed with the
above-mentioned extension to modular counting, we show that the twin-width of
the product of two conformal matrices $A, B$ over a finite field is bounded by
a function of the twin-width of $A$, of $B$, and of the size of the field.
Furthermore, if $A$ and $B$ are $n \times n$ matrices of twin-width $d$ over
$\mathbb F_q$, we show that $AB$ can be computed in time $O_{d,q}(n^2 \log n)$.
We finally present an ad hoc algorithm to efficiently multiply two matrices of
bounded twin-width, with a single-exponential dependence in the twin-width
bound: If the inputs are given in a compact tree-like form, called
twin-decomposition (of width $d$), then two $n \times n$ matrices $A, B$ over
$\mathbb F_2$, a twin-decomposition of $AB$ with width $2^{d+o(d)}$ can be
computed in time $4^{d+o(d)}n$ (resp. $4^{d+o(d)}n^{1+\varepsilon}$), and
entries queried in doubly-logarithmic (resp. constant) time.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1">&#xc9;douard Bonnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Giocanti_U/0/1/0/all/0/1">Ugo Giocanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendez_P/0/1/0/all/0/1">Patrice Ossona de Mendez</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomasse_S/0/1/0/all/0/1">St&#xe9;phan Thomass&#xe9;</a></p><p>We continue developing the theory around the twin-width of totally ordered
binary structures, initiated in the previous paper of the series. We first
introduce the notion of parity and linear minors of a matrix, which consists of
iteratively replacing consecutive rows or consecutive columns with a linear
combination of them. We show that a matrix class has bounded twin-width if and
only if its linear-minor closure does not contain all matrices. We observe that
the fixed-parameter tractable algorithm for first-order model checking on
structures given with an $O(1)$-sequence (certificate of bounded twin-width)
and the fact that first-order transductions of bounded twin-width classes have
bounded twin-width, both established in Twin-width I, extend to first-order
logic with modular counting quantifiers. We make explicit a win-win argument
obtained as a by-product of Twin-width IV, and somewhat similar to
bidimensionality, that we call rank-bidimensionality. Armed with the
above-mentioned extension to modular counting, we show that the twin-width of
the product of two conformal matrices $A, B$ over a finite field is bounded by
a function of the twin-width of $A$, of $B$, and of the size of the field.
Furthermore, if $A$ and $B$ are $n \times n$ matrices of twin-width $d$ over
$\mathbb F_q$, we show that $AB$ can be computed in time $O_{d,q}(n^2 \log n)$.
We finally present an ad hoc algorithm to efficiently multiply two matrices of
bounded twin-width, with a single-exponential dependence in the twin-width
bound: If the inputs are given in a compact tree-like form, called
twin-decomposition (of width $d$), then two $n \times n$ matrices $A, B$ over
$\mathbb F_2$, a twin-decomposition of $AB$ with width $2^{d+o(d)}$ can be
computed in time $4^{d+o(d)}n$ (resp. $4^{d+o(d)}n^{1+\varepsilon}$), and
entries queried in doubly-logarithmic (resp. constant) time.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12062'>Compressing bipartite graphs with a dual reordering scheme</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Maximilien Danisch, Ioannis Panagiotas, Lionel Tabourier</p><p>In order to manage massive graphs in practice, it is often necessary to
resort to graph compression, which aims at reducing the memory used when
storing and processing the graph. Efficient compression methods have been
proposed in the literature, especially for web graphs. In most cases, they are
combined with a vertex reordering pre-processing step which significantly
improves the compression rate. However, these techniques are not as efficient
when considering other kinds of graphs. In this paper, we focus on the class of
bipartite graphs and adapt the vertex reordering phase to their specific
structure by proposing a dual reordering scheme. By reordering each group of
vertices in the purpose of minimizing a specific score, we show that we can
reach better compression rates. We also suggest that this approach can be
further refined to make the node orderings more adapted to the compression
phase that follows the ordering phase.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Danisch_M/0/1/0/all/0/1">Maximilien Danisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Panagiotas_I/0/1/0/all/0/1">Ioannis Panagiotas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabourier_L/0/1/0/all/0/1">Lionel Tabourier</a></p><p>In order to manage massive graphs in practice, it is often necessary to
resort to graph compression, which aims at reducing the memory used when
storing and processing the graph. Efficient compression methods have been
proposed in the literature, especially for web graphs. In most cases, they are
combined with a vertex reordering pre-processing step which significantly
improves the compression rate. However, these techniques are not as efficient
when considering other kinds of graphs. In this paper, we focus on the class of
bipartite graphs and adapt the vertex reordering phase to their specific
structure by proposing a dual reordering scheme. By reordering each group of
vertices in the purpose of minimizing a specific score, we show that we can
reach better compression rates. We also suggest that this approach can be
further refined to make the node orderings more adapted to the compression
phase that follows the ordering phase.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12273'>Augmentation based Approximation Algorithms for Flexible Network Design</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Chandra Chekuri, Rhea Jain</p><p>Adjiashvili introduced network design in a non-uniform fault model: the edge
set of a given graph is partitioned into safe and unsafe edges. A vertex pair
$(s,t)$ is $(p,q)$-flex-connected if $s$ and $t$ have $p$ edge-connectivity
even after the removal of any $q$ unsafe edges. Given a graph $G$, the goal is
to choose a min-cost subgraph $H$ of $G$ that has desired flex-connectivity for
a given set of vertex pairs. This model generalizes the well-studied
edge-connectivity based network design, however, even special cases are
provably much harder to approximate.
</p>
<p>The approximability of network design in this model has been mainly studied
for two settings of interest: (i) single pair setting under the names FTP and
FTF (fault tolerant path and fault tolerant flow), (ii) spanning setting under
the name FGC (flexible graph connectivity). There have been several positive
results in these papers. However, despite similarity to the well-known network
design problems, this new model has been challenging to design approximation
algorithms for, especially when $p,q \ge 2$. We obtain two results that advance
our understanding of algorithm design in this model.
</p>
<p>1. We obtain a $5$-approximation for the $(2,2)$-flex-connectivity for a
single pair $(s,t)$. Previously no non-trivial approximation was known for this
setting.
</p>
<p>2. We obtain $O(p)$ approximation for $(p,2)$ and $(p,3)$-FGC for any $p \ge
1$, and for $(p,4)$-FGC for any even $p$. We obtain an $O(q)$-approximation for
$(2,q)$-FGC for any $q \ge 1$. Previously only a $O(q \log n)$-approximation
was known for these settings.
</p>
<p>Our results are obtained via the augmentation framework where we identify a
structured way to use the well-known $2$-approximation for covering uncrossable
families of cuts. Our analysis also proves corresponding integrality gap bounds
on an LP relaxation that we formulate.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chekuri_C/0/1/0/all/0/1">Chandra Chekuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1">Rhea Jain</a></p><p>Adjiashvili introduced network design in a non-uniform fault model: the edge
set of a given graph is partitioned into safe and unsafe edges. A vertex pair
$(s,t)$ is $(p,q)$-flex-connected if $s$ and $t$ have $p$ edge-connectivity
even after the removal of any $q$ unsafe edges. Given a graph $G$, the goal is
to choose a min-cost subgraph $H$ of $G$ that has desired flex-connectivity for
a given set of vertex pairs. This model generalizes the well-studied
edge-connectivity based network design, however, even special cases are
provably much harder to approximate.
</p>
<p>The approximability of network design in this model has been mainly studied
for two settings of interest: (i) single pair setting under the names FTP and
FTF (fault tolerant path and fault tolerant flow), (ii) spanning setting under
the name FGC (flexible graph connectivity). There have been several positive
results in these papers. However, despite similarity to the well-known network
design problems, this new model has been challenging to design approximation
algorithms for, especially when $p,q \ge 2$. We obtain two results that advance
our understanding of algorithm design in this model.
</p>
<p>1. We obtain a $5$-approximation for the $(2,2)$-flex-connectivity for a
single pair $(s,t)$. Previously no non-trivial approximation was known for this
setting.
</p>
<p>2. We obtain $O(p)$ approximation for $(p,2)$ and $(p,3)$-FGC for any $p \ge
1$, and for $(p,4)$-FGC for any even $p$. We obtain an $O(q)$-approximation for
$(2,q)$-FGC for any $q \ge 1$. Previously only a $O(q \log n)$-approximation
was known for these settings.
</p>
<p>Our results are obtained via the augmentation framework where we identify a
structured way to use the well-known $2$-approximation for covering uncrossable
families of cuts. Our analysis also proves corresponding integrality gap bounds
on an LP relaxation that we formulate.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12301'>Constant-delay enumeration for SLP-compressed documents</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mart&#xed;n Mu&#xf1;oz, Cristian Riveros</p><p>We study the problem of enumerating results from a query over a compressed
document. The model we use for compression are straight-line programs (SLPs),
which are defined by a context-free grammar that produces a single string. For
our queries we use a model called Annotated Automata, an extension of regular
automata that allows annotations on letters. This model extends the notion of
Regular Spanners as it allows arbitrarily long outputs. Our main result is an
algorithm which evaluates such a query by enumerating all results with
output-linear delay after a preprocessing phase which takes linear time on the
size of the SLP, and cubic time over the size of the automaton. This is an
improvement over Schmid and Schweikardt's result, which, with the same
preprocessing time, enumerates with a delay which is logarithmic on the size of
the uncompressed document. We achieve this through a persistent data structure
named Enumerable Compact Sets with Shifts which guarantees output-linear delay
under certain restrictions. These results imply constant-delay enumeration
algorithms in the context of regular spanners. Further, we use an extension of
annotated automata which utilizes succinctly encoded annotations to save an
exponential factor from previous results that dealt with constant-delay
enumeration over vset automata. Lastly, we extend our results in the same
fashion Schmid and Schweikardt did to allow complex document editing while
maintaining the constant-delay guarantee.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Munoz_M/0/1/0/all/0/1">Mart&#xed;n Mu&#xf1;oz</a>, <a href="http://arxiv.org/find/cs/1/au:+Riveros_C/0/1/0/all/0/1">Cristian Riveros</a></p><p>We study the problem of enumerating results from a query over a compressed
document. The model we use for compression are straight-line programs (SLPs),
which are defined by a context-free grammar that produces a single string. For
our queries we use a model called Annotated Automata, an extension of regular
automata that allows annotations on letters. This model extends the notion of
Regular Spanners as it allows arbitrarily long outputs. Our main result is an
algorithm which evaluates such a query by enumerating all results with
output-linear delay after a preprocessing phase which takes linear time on the
size of the SLP, and cubic time over the size of the automaton. This is an
improvement over Schmid and Schweikardt's result, which, with the same
preprocessing time, enumerates with a delay which is logarithmic on the size of
the uncompressed document. We achieve this through a persistent data structure
named Enumerable Compact Sets with Shifts which guarantees output-linear delay
under certain restrictions. These results imply constant-delay enumeration
algorithms in the context of regular spanners. Further, we use an extension of
annotated automata which utilizes succinctly encoded annotations to save an
exponential factor from previous results that dealt with constant-delay
enumeration over vset automata. Lastly, we extend our results in the same
fashion Schmid and Schweikardt did to allow complex document editing while
maintaining the constant-delay guarantee.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12313'>Random graph matching at Otter's threshold via counting chandeliers</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Cheng Mao, Yihong Wu, Jiaming Xu, Sophie H. Yu</p><p>We propose an efficient algorithm for graph matching based on similarity
scores constructed from counting a certain family of weighted trees rooted at
each vertex. For two Erd\H{o}s-R\'enyi graphs $\mathcal{G}(n,q)$ whose edges
are correlated through a latent vertex correspondence, we show that this
algorithm correctly matches all but a vanishing fraction of the vertices with
high probability, provided that $nq\to\infty$ and the edge correlation
coefficient $\rho$ satisfies $\rho^2&gt;\alpha \approx 0.338$, where $\alpha$ is
Otter's tree-counting constant. Moreover, this almost exact matching can be
made exact under an extra condition that is information-theoretically
necessary. This is the first polynomial-time graph matching algorithm that
succeeds at an explicit constant correlation and applies to both sparse and
dense graphs. In comparison, previous methods either require $\rho=1-o(1)$ or
are restricted to sparse graphs.
</p>
<p>The crux of the algorithm is a carefully curated family of rooted trees
called chandeliers, which allows effective extraction of the graph correlation
from the counts of the same tree while suppressing the undesirable correlation
between those of different trees.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1">Cheng Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yihong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiaming Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Sophie H. Yu</a></p><p>We propose an efficient algorithm for graph matching based on similarity
scores constructed from counting a certain family of weighted trees rooted at
each vertex. For two Erd\H{o}s-R\'enyi graphs $\mathcal{G}(n,q)$ whose edges
are correlated through a latent vertex correspondence, we show that this
algorithm correctly matches all but a vanishing fraction of the vertices with
high probability, provided that $nq\to\infty$ and the edge correlation
coefficient $\rho$ satisfies $\rho^2&gt;\alpha \approx 0.338$, where $\alpha$ is
Otter's tree-counting constant. Moreover, this almost exact matching can be
made exact under an extra condition that is information-theoretically
necessary. This is the first polynomial-time graph matching algorithm that
succeeds at an explicit constant correlation and applies to both sparse and
dense graphs. In comparison, previous methods either require $\rho=1-o(1)$ or
are restricted to sparse graphs.
</p>
<p>The crux of the algorithm is a carefully curated family of rooted trees
called chandeliers, which allows effective extraction of the graph correlation
from the counts of the same tree while suppressing the undesirable correlation
between those of different trees.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12314'>Package Delivery Using Drones with Restricted Movement Areas</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Thomas Erlebach, Kelin Luo, Frits C.R. Spieksma</p><p>For the problem of delivering a package from a source node to a destination
node in a graph using a set of drones, we study the setting where the movements
of each drone are restricted to a certain subgraph of the given graph. We
consider the objectives of minimizing the delivery time (problem DDT) and of
minimizing the total energy consumption (problem DDC). For general graphs, we
show a strong inapproximability result and a matching approximation algorithm
for DDT as well as NP-hardness and a 2-approximation algorithm for DDC. For the
special case of a path, we show that DDT is NP-hard if the drones have
different speeds. For trees, we give optimal algorithms under the assumption
that all drones have the same speed or the same energy consumption rate. The
results for trees extend to arbitrary graphs if the subgraph of each drone is
isometric.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Erlebach_T/0/1/0/all/0/1">Thomas Erlebach</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1">Kelin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Spieksma_F/0/1/0/all/0/1">Frits C.R. Spieksma</a></p><p>For the problem of delivering a package from a source node to a destination
node in a graph using a set of drones, we study the setting where the movements
of each drone are restricted to a certain subgraph of the given graph. We
consider the objectives of minimizing the delivery time (problem DDT) and of
minimizing the total energy consumption (problem DDC). For general graphs, we
show a strong inapproximability result and a matching approximation algorithm
for DDT as well as NP-hardness and a 2-approximation algorithm for DDC. For the
special case of a path, we show that DDT is NP-hard if the drones have
different speeds. For trees, we give optimal algorithms under the assumption
that all drones have the same speed or the same energy consumption rate. The
results for trees extend to arbitrary graphs if the subgraph of each drone is
isometric.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12315'>Tree decompositions with bounded independence number: beyond independent sets</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Martin Milani&#x10d;, Pawe&#x142; Rz&#x105;&#x17c;ewski</p><p>We continue the study of graph classes in which the treewidth can only be
large due to the presence of a large clique, and, more specifically, of graph
classes with bounded tree-independence number. In [Dallard, Milani\v{c}, and
\v{S}torgel, Treewidth versus clique number. {II}. Tree-independence number,
2022], it was shown that the Maximum Weight Independent Packing problem, which
is a common generalization of the Independent Set and Induced Matching
problems, can be solved in polynomial time provided that the input graph is
given along with a tree decomposition with bounded independence number. We
provide further examples of algorithmic problems that can be solved in
polynomial time under this assumption. This includes, for all even positive
integers $d$, the problem of packing subgraphs at distance at least $d$
(generalizing the Maximum Weight Independent Packing problem) and the problem
of finding a large induced sparse subgraph satisfying an arbitrary but fixed
property expressible in counting monadic second-order logic. As part of our
approach, we generalize some classical results on powers of chordal graphs to
the context of general graphs and their tree-independence numbers.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Milanic_M/0/1/0/all/0/1">Martin Milani&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Rzazewski_P/0/1/0/all/0/1">Pawe&#x142; Rz&#x105;&#x17c;ewski</a></p><p>We continue the study of graph classes in which the treewidth can only be
large due to the presence of a large clique, and, more specifically, of graph
classes with bounded tree-independence number. In [Dallard, Milani\v{c}, and
\v{S}torgel, Treewidth versus clique number. {II}. Tree-independence number,
2022], it was shown that the Maximum Weight Independent Packing problem, which
is a common generalization of the Independent Set and Induced Matching
problems, can be solved in polynomial time provided that the input graph is
given along with a tree decomposition with bounded independence number. We
provide further examples of algorithmic problems that can be solved in
polynomial time under this assumption. This includes, for all even positive
integers $d$, the problem of packing subgraphs at distance at least $d$
(generalizing the Maximum Weight Independent Packing problem) and the problem
of finding a large induced sparse subgraph satisfying an arbitrary but fixed
property expressible in counting monadic second-order logic. As part of our
approach, we generalize some classical results on powers of chordal graphs to
the context of general graphs and their tree-independence numbers.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12332'>On the Optimal Linear Contraction Order for Tree Tensor Networks</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mihail Stoian</p><p>Tensor networks are nowadays the backbone of classical simulations of quantum
many-body systems and quantum circuits. Most tensor methods rely on the fact
that we can eventually contract the tensor network to obtain the final result.
While the contraction operation itself is trivial, its execution time is highly
dependent on the order in which the contractions are performed. To this end,
one tries to find beforehand an optimal order in which the contractions should
be performed. However, there is a drawback: the general problem of finding the
optimal contraction order is NP-complete. Therefore, one must settle for a
mixture of exponential algorithms for small problems, e.g., $n \leq 20$, and
otherwise hope for good contraction orders. For this reason, previous research
has focused on the latter part, trying to find better heuristics.
</p>
<p>In this work, we take a more conservative approach and show that tree tensor
networks accept optimal linear contraction orders. Beyond the optimality
results, we adapt two join ordering techniques that can build on our work to
guarantee near-optimal orders for arbitrary tensor networks.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Stoian_M/0/1/0/all/0/1">Mihail Stoian</a></p><p>Tensor networks are nowadays the backbone of classical simulations of quantum
many-body systems and quantum circuits. Most tensor methods rely on the fact
that we can eventually contract the tensor network to obtain the final result.
While the contraction operation itself is trivial, its execution time is highly
dependent on the order in which the contractions are performed. To this end,
one tries to find beforehand an optimal order in which the contractions should
be performed. However, there is a drawback: the general problem of finding the
optimal contraction order is NP-complete. Therefore, one must settle for a
mixture of exponential algorithms for small problems, e.g., $n \leq 20$, and
otherwise hope for good contraction orders. For this reason, previous research
has focused on the latter part, trying to find better heuristics.
</p>
<p>In this work, we take a more conservative approach and show that tree tensor
networks accept optimal linear contraction orders. Beyond the optimality
results, we adapt two join ordering techniques that can build on our work to
guarantee near-optimal orders for arbitrary tensor networks.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Monday, September 26
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11505'>The complexity of unsupervised learning of lexicographic preferences</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: H&#xe9;l&#xe8;ne Fargier (IRIT-ADRIA, ANITI), Pierre-Fran&#xe7;ois Gimenez (CIDRE), J&#xe9;r&#xf4;me Mengin (IRIT-ADRIA, ANITI), Bao Ngoc Le Nguyen (INSA Toulouse)</p><p>This paper considers the task of learning users' preferences on a
combinatorial set of alternatives, as generally used by online configurators,
for example. In many settings, only a set of selected alternatives during past
interactions is available to the learner. Fargier et al. [2018] propose an
approach to learn, in such a setting, a model of the users' preferences that
ranks previously chosen alternatives as high as possible; and an algorithm to
learn, in this setting, a particular model of preferences: lexicographic
preferences trees (LP-trees). In this paper, we study complexity-theoretical
problems related to this approach. We give an upper bound on the sample
complexity of learning an LP-tree, which is logarithmic in the number of
attributes. We also prove that computing the LP tree that minimises the
empirical risk can be done in polynomial time when restricted to the class of
linear LP-trees.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fargier_H/0/1/0/all/0/1">H&#xe9;l&#xe8;ne Fargier</a> (IRIT-ADRIA, ANITI), <a href="http://arxiv.org/find/cs/1/au:+Gimenez_P/0/1/0/all/0/1">Pierre-Fran&#xe7;ois Gimenez</a> (CIDRE), <a href="http://arxiv.org/find/cs/1/au:+Mengin_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Mengin</a> (IRIT-ADRIA, ANITI), <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Bao Ngoc Le Nguyen</a> (INSA Toulouse)</p><p>This paper considers the task of learning users' preferences on a
combinatorial set of alternatives, as generally used by online configurators,
for example. In many settings, only a set of selected alternatives during past
interactions is available to the learner. Fargier et al. [2018] propose an
approach to learn, in such a setting, a model of the users' preferences that
ranks previously chosen alternatives as high as possible; and an algorithm to
learn, in this setting, a particular model of preferences: lexicographic
preferences trees (LP-trees). In this paper, we study complexity-theoretical
problems related to this approach. We give an upper bound on the sample
complexity of learning an LP-tree, which is logarithmic in the number of
attributes. We also prove that computing the LP tree that minimises the
empirical risk can be done in polynomial time when restricted to the class of
linear LP-trees.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11650'>An Algebraic-Geometry Approach to Prime Factorization</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Alberto Montina, Stefan Wolf</p><p>New algorithms for prime factorization that outperform the existing ones or
take advantage of particular properties of the prime factors can have a
practical impact on present implementations of cryptographic algorithms that
rely on the complexity of factorization. Currently used keys are chosen on the
basis of the present algorithmic knowledge and, thus, can potentially be
subject to future breaches. For this reason, it is worth to investigate new
approaches which have the potentiality of giving a computational advantage. The
problem has also relevance in quantum computation, as an efficient quantum
algorithm for prime factorization already exists. Thus, better classical
asymptotic complexity can provide a better understanding of the advantages
offered by quantum computers. In this paper, we reduce the factorization
problem to the search of points of parametrizable varieties, in particular
curves, over finite fields. The varieties are required to have an arbitrarily
large number of intersection points with some hypersurface over the base field.
For a subexponential or poly- nomial factoring complexity, the number of
parameters have to scale sublinearly in the space dimension n and the
complexity of computing a point given the parameters has to be subexponential
or polynomial, respectively. We outline a procedure for building these
varieties, which is illustrated with two constructions. In one case, we show
that there are varieties whose points can be evaluated efficiently given a
number of parameters not greater than n/2. In the other case, the bound is
dropped to n/3. Incidentally, the first construction resembles a kind of
retro-causal model. Retro-causality is considered one possible explanation of
quantum weirdness.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Montina_A/0/1/0/all/0/1">Alberto Montina</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_S/0/1/0/all/0/1">Stefan Wolf</a></p><p>New algorithms for prime factorization that outperform the existing ones or
take advantage of particular properties of the prime factors can have a
practical impact on present implementations of cryptographic algorithms that
rely on the complexity of factorization. Currently used keys are chosen on the
basis of the present algorithmic knowledge and, thus, can potentially be
subject to future breaches. For this reason, it is worth to investigate new
approaches which have the potentiality of giving a computational advantage. The
problem has also relevance in quantum computation, as an efficient quantum
algorithm for prime factorization already exists. Thus, better classical
asymptotic complexity can provide a better understanding of the advantages
offered by quantum computers. In this paper, we reduce the factorization
problem to the search of points of parametrizable varieties, in particular
curves, over finite fields. The varieties are required to have an arbitrarily
large number of intersection points with some hypersurface over the base field.
For a subexponential or poly- nomial factoring complexity, the number of
parameters have to scale sublinearly in the space dimension n and the
complexity of computing a point given the parameters has to be subexponential
or polynomial, respectively. We outline a procedure for building these
varieties, which is illustrated with two constructions. In one case, we show
that there are varieties whose points can be evaluated efficiently given a
number of parameters not greater than n/2. In the other case, the bound is
dropped to n/3. Incidentally, the first construction resembles a kind of
retro-causal model. Retro-causality is considered one possible explanation of
quantum weirdness.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11260'>Piercing Diametral Disks Induced by Edges of Maximum Spanning Tree</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: A. Karim Abu-Affash, Paz Carmi, Meytal Maman</p><p>Let $P$ be a set of points in the plane and let $T$ be a maximum-weight
spanning tree of $P$. For an edge $(p,q)$, let $D_{pq}$ be the diametral disk
induced by $(p,q)$, i.e., the disk having the segment $\overline{pq}$ as its
diameter. Let $\cal{D_T}$ be the set of the diametral disks induced by the
edges of $T$. In this paper, we show that one point is sufficient to pierce all
the disks in $\cal{D_T}$, thus, the set $\cal{D_T}$ is Helly. Actually, we show
that the center of the smallest enclosing circle of $P$ is contained in all the
disks of $\cal{D_T}$, and thus the piercing point can be computed in linear
time.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Abu_Affash_A/0/1/0/all/0/1">A. Karim Abu-Affash</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmi_P/0/1/0/all/0/1">Paz Carmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maman_M/0/1/0/all/0/1">Meytal Maman</a></p><p>Let $P$ be a set of points in the plane and let $T$ be a maximum-weight
spanning tree of $P$. For an edge $(p,q)$, let $D_{pq}$ be the diametral disk
induced by $(p,q)$, i.e., the disk having the segment $\overline{pq}$ as its
diameter. Let $\cal{D_T}$ be the set of the diametral disks induced by the
edges of $T$. In this paper, we show that one point is sufficient to pierce all
the disks in $\cal{D_T}$, thus, the set $\cal{D_T}$ is Helly. Actually, we show
that the center of the smallest enclosing circle of $P$ is contained in all the
disks of $\cal{D_T}$, and thus the piercing point can be computed in linear
time.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11606'>An extension to VORO++ for multithreaded computation of Voronoi cells</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jiayin Lu, Emanuel A. Lazar, Chris H. Rycroft</p><p>VORO++ is a software library written in C++ for computing the Voronoi
tessellation, a technique in computational geometry that is widely used for
analyzing systems of particles. VORO++ was released in 2009 and is based on
computing the Voronoi cell for each particle individually. Here, we take
advantage of modern computer hardware, and extend the original serial version
to allow for multithreaded computation of Voronoi cells via the OpenMP
application programming interface. We test the performance of the code, and
demonstrate that we can achieve parallel efficiencies greater than 95% in many
cases. The multithreaded extension follows standard OpenMP programming
paradigms, allowing it to be incorporated into other programs. We provide an
example of this using the VoroTop software library, performing a multithreaded
Voronoi cell topology analysis of up to 102.4 million particles.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/physics/1/au:+Lu_J/0/1/0/all/0/1">Jiayin Lu</a>, <a href="http://arxiv.org/find/physics/1/au:+Lazar_E/0/1/0/all/0/1">Emanuel A. Lazar</a>, <a href="http://arxiv.org/find/physics/1/au:+Rycroft_C/0/1/0/all/0/1">Chris H. Rycroft</a></p><p>VORO++ is a software library written in C++ for computing the Voronoi
tessellation, a technique in computational geometry that is widely used for
analyzing systems of particles. VORO++ was released in 2009 and is based on
computing the Voronoi cell for each particle individually. Here, we take
advantage of modern computer hardware, and extend the original serial version
to allow for multithreaded computation of Voronoi cells via the OpenMP
application programming interface. We test the performance of the code, and
demonstrate that we can achieve parallel efficiencies greater than 95% in many
cases. The multithreaded extension follows standard OpenMP programming
paradigms, allowing it to be incorporated into other programs. We provide an
example of this using the VoroTop software library, performing a multithreaded
Voronoi cell topology analysis of up to 102.4 million particles.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11452'>From String Detection to Orthogonal Vector Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Yunhao Wang, Tianyuan Zheng, Lior Horesh</p><p>Considering Grover's Search Algorithm (GSA) with the standard diffuser stage
applied, we revisit the $3$-qubit unique String Detection Problem (SDP) and
extend the algorithm to $4$-qubit SDP with multiple winners. We then
investigate unstructured search problems with non-uniform distributions and
define the Orthogonal Vector Problem (OVP) under quantum settings. Although no
numerically stable results is reached under the original GSA framework, we
provide intuition behind our implementation and further observations on OVP. We
further perform a special case analysis under the modified GSA framework which
aims to stabilize the final measurement under arbitrary initial distribution.
Based on the result of the analysis, we generalize the initial condition under
which neither the original framework nor the modification works. Instead of
utilizing GSA, we also propose a short-depth circuit that can calculate the
orthogonal pair for a given vector represented as a binary string with constant
runtime.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Wang_Y/0/1/0/all/0/1">Yunhao Wang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zheng_T/0/1/0/all/0/1">Tianyuan Zheng</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Horesh_L/0/1/0/all/0/1">Lior Horesh</a></p><p>Considering Grover's Search Algorithm (GSA) with the standard diffuser stage
applied, we revisit the $3$-qubit unique String Detection Problem (SDP) and
extend the algorithm to $4$-qubit SDP with multiple winners. We then
investigate unstructured search problems with non-uniform distributions and
define the Orthogonal Vector Problem (OVP) under quantum settings. Although no
numerically stable results is reached under the original GSA framework, we
provide intuition behind our implementation and further observations on OVP. We
further perform a special case analysis under the modified GSA framework which
aims to stabilize the final measurement under arbitrary initial distribution.
Based on the result of the analysis, we generalize the initial condition under
which neither the original framework nor the modification works. Instead of
utilizing GSA, we also propose a short-depth circuit that can calculate the
orthogonal pair for a given vector represented as a binary string with constant
runtime.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11651'>Local Distributed Rounding: Generalized to MIS, Matching, Set Cover, and Beyond</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Salwa Faour, Mohsen Ghaffari, Christoph Grunau, Fabian Kuhn, V&#xe1;clav Rozho&#x148;</p><p>We develop a general deterministic distributed method for locally rounding
fractional solutions of graph problems for which the analysis can be broken
down into analyzing pairs of vertices. Roughly speaking, the method can
transform fractional/probabilistic label assignments of the vertices into
integral/deterministic label assignments for the vertices, while approximately
preserving a potential function that is a linear combination of functions, each
of which depends on at most two vertices (subject to some conditions usually
satisfied in pairwise analyses). The method unifies and significantly
generalizes prior work on deterministic local rounding techniques [Ghaffari,
Kuhn FOCS'21; Harris FOCS'19; Fischer, Ghaffari, Kuhn FOCS'17; Fischer DISC'17]
to obtain polylogarithmic-time deterministic distributed solutions for
combinatorial graph problems. Our general rounding result enables us to locally
and efficiently derandomize a range of distributed algorithms for local graph
problems, including maximal independent set (MIS), maximum-weight independent
set approximation, and minimum-cost set cover approximation. As a highlight, we
in particular obtain a deterministic $O(\log^2\Delta\cdot\log n)$-round
algorithm for computing an MIS in the LOCAL model and an almost as efficient
$O(\log^2\Delta\cdot\log\log\Delta\cdot\log n)$-round deterministic MIS
algorithm in the CONGEST model. As a result, the best known deterministic
distributed time complexity of the four most widely studied distributed
symmetry breaking problems (MIS, maximal matching, $(\Delta+1)$-vertex
coloring, and $(2\Delta-1)$-edge coloring) is now $O(\log^2\Delta\cdot\log n)$.
Our new MIS algorithm is also the first direct polylogarithmic-time
deterministic distributed MIS algorithm, which is not based on network
decomposition.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Faour_S/0/1/0/all/0/1">Salwa Faour</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1">Christoph Grunau</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhn_F/0/1/0/all/0/1">Fabian Kuhn</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozhon_V/0/1/0/all/0/1">V&#xe1;clav Rozho&#x148;</a></p><p>We develop a general deterministic distributed method for locally rounding
fractional solutions of graph problems for which the analysis can be broken
down into analyzing pairs of vertices. Roughly speaking, the method can
transform fractional/probabilistic label assignments of the vertices into
integral/deterministic label assignments for the vertices, while approximately
preserving a potential function that is a linear combination of functions, each
of which depends on at most two vertices (subject to some conditions usually
satisfied in pairwise analyses). The method unifies and significantly
generalizes prior work on deterministic local rounding techniques [Ghaffari,
Kuhn FOCS'21; Harris FOCS'19; Fischer, Ghaffari, Kuhn FOCS'17; Fischer DISC'17]
to obtain polylogarithmic-time deterministic distributed solutions for
combinatorial graph problems. Our general rounding result enables us to locally
and efficiently derandomize a range of distributed algorithms for local graph
problems, including maximal independent set (MIS), maximum-weight independent
set approximation, and minimum-cost set cover approximation. As a highlight, we
in particular obtain a deterministic $O(\log^2\Delta\cdot\log n)$-round
algorithm for computing an MIS in the LOCAL model and an almost as efficient
$O(\log^2\Delta\cdot\log\log\Delta\cdot\log n)$-round deterministic MIS
algorithm in the CONGEST model. As a result, the best known deterministic
distributed time complexity of the four most widely studied distributed
symmetry breaking problems (MIS, maximal matching, $(\Delta+1)$-vertex
coloring, and $(2\Delta-1)$-edge coloring) is now $O(\log^2\Delta\cdot\log n)$.
Our new MIS algorithm is also the first direct polylogarithmic-time
deterministic distributed MIS algorithm, which is not based on network
decomposition.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11669'>Improved Distributed Network Decomposition, Hitting Sets, and Spanners, via Derandomization</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mohsen Ghaffari, Christoph Grunau, Bernhard Haeupler, Saeed Ilchi, V&#xe1;clav Rozho&#x148;</p><p>This paper presents significantly improved deterministic algorithms for some
of the key problems in the area of distributed graph algorithms, including
network decomposition, hitting sets, and spanners. As the main ingredient in
these results, we develop novel randomized distributed algorithms that we can
analyze using only pairwise independence, and we can thus derandomize
efficiently. As our most prominent end-result, we obtain a deterministic
construction for $O(\log n)$-color $O(\log n \cdot \log\log\log n)$-strong
diameter network decomposition in $\tilde{O}(\log^3 n)$ rounds. This is the
first construction that achieves almost $\log n$ in both parameters, and it
improves on a recent line of exciting progress on deterministic distributed
network decompositions [Rozho\v{n}, Ghaffari STOC'20; Ghaffari, Grunau,
Rozho\v{n} SODA'21; Chang, Ghaffari PODC'21; Elkin, Haeupler, Rozho\v{n},
Grunau FOCS'22].
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1">Christoph Grunau</a>, <a href="http://arxiv.org/find/cs/1/au:+Haeupler_B/0/1/0/all/0/1">Bernhard Haeupler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilchi_S/0/1/0/all/0/1">Saeed Ilchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozhon_V/0/1/0/all/0/1">V&#xe1;clav Rozho&#x148;</a></p><p>This paper presents significantly improved deterministic algorithms for some
of the key problems in the area of distributed graph algorithms, including
network decomposition, hitting sets, and spanners. As the main ingredient in
these results, we develop novel randomized distributed algorithms that we can
analyze using only pairwise independence, and we can thus derandomize
efficiently. As our most prominent end-result, we obtain a deterministic
construction for $O(\log n)$-color $O(\log n \cdot \log\log\log n)$-strong
diameter network decomposition in $\tilde{O}(\log^3 n)$ rounds. This is the
first construction that achieves almost $\log n$ in both parameters, and it
improves on a recent line of exciting progress on deterministic distributed
network decompositions [Rozho\v{n}, Ghaffari STOC'20; Ghaffari, Grunau,
Rozho\v{n} SODA'21; Chang, Ghaffari PODC'21; Elkin, Haeupler, Rozho\v{n},
Grunau FOCS'22].
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Sunday, September 25
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://emanueleviola.wordpress.com/2022/09/25/getting-started-with-opengl-and-c/'>Getting started with OpenGL and C++</a></h3>
          <p class='item-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Below is a template that shows a fractal plant that you can modify with the keys z,w,s. Getting this to work was not straightforward, but the idea is that now you can just have fun and start your videogame. The code is not meant to be optimized at all, but simple. It&#8217;s pretty much self-explanatory, [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Below is a template that shows a fractal plant that you can modify with the keys z,w,s.  Getting this to work was not straightforward, but the idea is that now you can just have fun and start your videogame.  The code is not meant to be optimized at all, but simple.  It&#8217;s pretty much self-explanatory, basically you can just replace the call to drawFrac in display to show whatever you want, and you handle key strokes in the idle function.  I only tested it on Linux.</p>



<figure class="wp-block-image size-large"><a href="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png"><img data-attachment-id="1080" data-permalink="https://emanueleviola.wordpress.com/2022/09/25/getting-started-with-opengl-and-c/screenshot-from-2022-09-25-19-37-42/" data-orig-file="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png" data-orig-size="1369,873" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-from-2022-09-25-19-37-42" data-image-description="" data-image-caption="" data-medium-file="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=300" data-large-file="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=640" src="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=1024" alt="" class="wp-image-1080" srcset="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=1024 1024w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=150 150w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=300 300w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=768 768w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png 1369w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure>



<pre class="wp-block-code"><code>/*
This is a template to get started with OpenGL (which needs to be installed)
To compile: g++ GLtemplate.c++ -o GLtemplate -lglut -lGLU -lGL
To run: ./GLtemplate

It shows a fractal plant that you can modify with the keys z,w,s

*/

#include &lt;GL/glut.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;

GLfloat userAngle = M_PI/2, userLength = 0.5;

//Keyboard code.  keyStates&#091;x] is true if x is pressed.

bool keyStates&#091;256];     //Key state values

void keyPressed (unsigned char key, int x, int y) { keyStates&#091;key] = true;  }
void keyUp      (unsigned char key, int x, int y) { keyStates&#091;key] = false; }

void idle() {
  if (keyStates&#091;'z']) {userAngle += 0.01;}
  if (keyStates&#091;'w']) {userLength += 0.01;}
  if (keyStates&#091;'s']) {userLength -= 0.01; if (userLength &lt; 0) userLength = 0;}
}

/* Draws a plant from x,y with first piece length l, and angle a
The window has coordinates from (-1,-1) to (1,1).  The center is 0,0.
*/

void drawFrac(GLfloat x,GLfloat y,GLfloat l, GLfloat a) {
  if ( l &lt; 0.001 )
    return;

  glColor3f(0, l*30, 0);
  glLineWidth(l*10);  //Must be before glBegin(GL_LINES)

  glBegin(GL_LINES);

  glVertex2d(x,y);
  glVertex2d(x+cos(a)*l,y+sin(a)*l);

  glEnd();

  drawFrac(x+cos(a)*l*0.3,y+sin(a)*l*0.3,l*0.3,a+M_PI/4);
  drawFrac(x+cos(a)*l*0.6,y+sin(a)*l*0.6,l*0.4,a-M_PI/4);

  drawFrac(x+cos(a)*l,y+sin(a)*l,l*0.5,a+M_PI/4);
  drawFrac(x+cos(a)*l,y+sin(a)*l,l*0.5,a-M_PI/4);
}

//This is the function that draws everything on the screen
void display() {
  glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); //Clear screen

  /* Draw whatever you need here */
  drawFrac(0,0,userLength,userAngle);

  glutSwapBuffers();
  glutPostRedisplay();
}

int main(int argc, char** argv)
{
    glutInit(&amp;argc, argv);
    glutInitDisplayMode(GLUT_SINGLE);
    glutInitWindowSize(1000, 1000);
    glutInitWindowPosition(0,0);
    glutCreateWindow("GLtemplate");
    glutDisplayFunc(display);
    glutIdleFunc(idle);
    glutKeyboardUpFunc(keyUp);
    glutKeyboardFunc(keyPressed);

    glutMainLoop();
    return 0;
}
</code></pre>
<p class="authors">By Manu</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-25T23:45:43Z">Sunday, September 25 2022, 23:45</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/136'>TR22-136 |  Rounds vs Communication Tradeoffs for Maximal Independent Sets | 

	Sepehr Assadi, 

	Gillat Kol, 

	Zhijun Zhang</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We consider the problem of finding a maximal independent set (MIS) in the shared blackboard communication model with vertex-partitioned inputs. There are $n$ players corresponding to vertices of an undirected graph, and each player sees the edges incident on its vertex -- this way, each edge is known by both its endpoints and is thus shared by two players. The players communicate in simultaneous rounds by posting their messages on a shared blackboard visible to all players, with the goal of computing an MIS of the graph. While the MIS problem is well studied in other distributed models, and while shared blackboard is, perhaps, the simplest broadcast model, lower bounds for our problem were only known against one-round protocols.

We present a lower bound on the round-communication tradeoff for computing an MIS in this model. Specifically, we show that when $r$ rounds of interaction are allowed, at least one player needs to communicate $\Omega(n^{1/20^{r+1}})$ bits. In particular, with logarithmic bandwidth, finding an MIS requires $\Omega(\log\log{n})$ rounds. This lower bound can be compared with the algorithm of Ghaffari, Gouleakis, Konrad, Mitrovi ?c, and Rubinfeld [PODC 2018] that solves MIS in $O(\log\log{n})$ rounds but with a logarithmic bandwidth for an average player. Additionally, our lower bound further extends to the closely related problem of maximal bipartite matching.

The presence of edge-sharing gives the algorithms in our model a surprising power and numerous algorithmic results exploiting this power are known. For a similar reason, proving lower bounds in this model is much more challenging, as this sharing in the players&#39; inputs prohibits the use of standard number-in-hand communication complexity arguments. Thus, to prove our results, we devise a new round elimination framework, which we call partial-input embedding, that may also be useful in future work for proving round-sensitive lower bounds in the presence of shared inputs.

Finally, we discuss several implications of our results to multi-round (adaptive) distributed sketching algorithms, broadcast congested clique, and to the welfare maximization problem in two-sided matching markets.
        
        </div>

        <div class='item-content item-summary'>
        
          
          We consider the problem of finding a maximal independent set (MIS) in the shared blackboard communication model with vertex-partitioned inputs. There are $n$ players corresponding to vertices of an undirected graph, and each player sees the edges incident on its vertex -- this way, each edge is known by both its endpoints and is thus shared by two players. The players communicate in simultaneous rounds by posting their messages on a shared blackboard visible to all players, with the goal of computing an MIS of the graph. While the MIS problem is well studied in other distributed models, and while shared blackboard is, perhaps, the simplest broadcast model, lower bounds for our problem were only known against one-round protocols.

We present a lower bound on the round-communication tradeoff for computing an MIS in this model. Specifically, we show that when $r$ rounds of interaction are allowed, at least one player needs to communicate $\Omega(n^{1/20^{r+1}})$ bits. In particular, with logarithmic bandwidth, finding an MIS requires $\Omega(\log\log{n})$ rounds. This lower bound can be compared with the algorithm of Ghaffari, Gouleakis, Konrad, Mitrovi ?c, and Rubinfeld [PODC 2018] that solves MIS in $O(\log\log{n})$ rounds but with a logarithmic bandwidth for an average player. Additionally, our lower bound further extends to the closely related problem of maximal bipartite matching.

The presence of edge-sharing gives the algorithms in our model a surprising power and numerous algorithmic results exploiting this power are known. For a similar reason, proving lower bounds in this model is much more challenging, as this sharing in the players&#39; inputs prohibits the use of standard number-in-hand communication complexity arguments. Thus, to prove our results, we devise a new round elimination framework, which we call partial-input embedding, that may also be useful in future work for proving round-sensitive lower bounds in the presence of shared inputs.

Finally, we discuss several implications of our results to multi-round (adaptive) distributed sketching algorithms, broadcast congested clique, and to the welfare maximization problem in two-sided matching markets.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-25T06:24:48Z">Sunday, September 25 2022, 06:24</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/135'>TR22-135 |  Decision Tree Complexity versus Block Sensitivity and Degree | 

	Swagato Sanyal, 

	Supartha Poddar, 

	Rahul Chugh</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Relations between the decision tree complexity and various other complexity measures of Boolean functions is a thriving topic of research in computational complexity. While decision tree complexity is long known to be polynomially related with many other measures, the optimal exponents of many of these relations are not known. It is known that decision tree complexity is bounded above by the cube of block sensitivity, and the cube of polynomial degree. However, the widest separation between decision tree complexity and each of block sensitivity and degree that is witnessed by known Boolean functions is quadratic.

Proving quadratic relations between these measures would resolve several open questions in decision tree complexity. For example, we get a tight relation between decision tree complexity and square of randomized decision tree complexity and a tight relation between zero-error randomized decision tree complexity and square of fractional block sensitivity, resolving an open question raised by Aaronson. In this work, we investigate the tightness of the existing cubic upper bounds. 

We improve the cubic upper bounds for many interesting classes of Boolean functions. We show that for graph properties and for functions with a constant number of alternations, both of the cubic upper bounds can be improved to quadratic. We define a class of Boolean functions, which we call the zebra functions, that comprises Boolean functions where each monotone path from $0^n$ to $1^n$ has an equal number of alternations. This class contains the symmetric and monotone functions as its subclasses. We show that for any zebra function, decision tree complexity is at most the square of block sensitivity, and certificate complexity is at most the square of degree. 

Finally, we show using a lifting theorem of communication complexity by G{\&quot;{o}}{\&quot;{o}}s, Pitassi and Watson that the task of proving an improved upper bound on the decision tree complexity for all functions is in a sense equivalent to the potentially easier task of proving a similar upper bound on communication complexity for each bi-partition of the input variables, for all functions. In particular, this implies that to bound the decision tree complexity it suffices to bound smaller measures like parity decision tree complexity, subcube decision tree complexity and decision tree rank, that are defined in terms of models that can be efficiently simulated by communication protocols.
        
        </div>

        <div class='item-content item-summary'>
        
          
          Relations between the decision tree complexity and various other complexity measures of Boolean functions is a thriving topic of research in computational complexity. While decision tree complexity is long known to be polynomially related with many other measures, the optimal exponents of many of these relations are not known. It is known that decision tree complexity is bounded above by the cube of block sensitivity, and the cube of polynomial degree. However, the widest separation between decision tree complexity and each of block sensitivity and degree that is witnessed by known Boolean functions is quadratic.

Proving quadratic relations between these measures would resolve several open questions in decision tree complexity. For example, we get a tight relation between decision tree complexity and square of randomized decision tree complexity and a tight relation between zero-error randomized decision tree complexity and square of fractional block sensitivity, resolving an open question raised by Aaronson. In this work, we investigate the tightness of the existing cubic upper bounds. 

We improve the cubic upper bounds for many interesting classes of Boolean functions. We show that for graph properties and for functions with a constant number of alternations, both of the cubic upper bounds can be improved to quadratic. We define a class of Boolean functions, which we call the zebra functions, that comprises Boolean functions where each monotone path from $0^n$ to $1^n$ has an equal number of alternations. This class contains the symmetric and monotone functions as its subclasses. We show that for any zebra function, decision tree complexity is at most the square of block sensitivity, and certificate complexity is at most the square of degree. 

Finally, we show using a lifting theorem of communication complexity by G{\&quot;{o}}{\&quot;{o}}s, Pitassi and Watson that the task of proving an improved upper bound on the decision tree complexity for all functions is in a sense equivalent to the potentially easier task of proving a similar upper bound on communication complexity for each bi-partition of the input variables, for all functions. In particular, this implies that to bound the decision tree complexity it suffices to bound smaller measures like parity decision tree complexity, subcube decision tree complexity and decision tree rank, that are defined in terms of models that can be efficiently simulated by communication protocols.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-25T06:22:55Z">Sunday, September 25 2022, 06:22</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/134'>TR22-134 |  Some Games on Turing Machines and Power from Random Strings | 

	Alexey Milovanov, 

	Greg McLellan</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Denote by $R$ the set of strings with high Kolmogorov complexity. In [E. Allender, H. Buhrman, M. Kouck\&#39;y, D. van Melkebeek, and D. Ronneburger.
Power from random strings.
\emph{SIAM Journal on Computing}, 35:1467--1493, 2006.] the idea of using $R$ as an oracle for resource-bounded computation models was presented. This idea was later developed in several others papers.
We prove new lower bounds for $Q^R_{tt}$ and $Q^R_{sa}$:
- Oblivious-NP is subset of $Q^R_{tt}$;
- Oblivious-MA is subset of $Q^R_{sa}$.

Here $Q$ means quazi-polynomial-time; ``sa&#39;&#39; means sub-adaptive
reduction - a new type of reduction that we introduce. This type of reduction is not weaker than truth-table reduction and is not stronger than Turing reduction.

Also we prove upper bounds for BBP^R_{tt} and P^R_{sa} following [E. Allender, L. Friedman, and W. Gasarch. Limits on the computational power of random
strings.]:

P^R_{sa} is subset of EXP
BBP^R_{tt} is subset of AEXP(poly).

Here AEXP(poly) is the class of languages decidable in exponential time by an alternating Turing machine that switches from an existential to a universal state or vice versa at most polynomial times.


Finally we analyze some games that originate in [E. Allender, L. Friedman, and W. Gasarch. Limits on the computational power of random
strings.]. We prove completeness of these games. These results show that methods in this can not prove better upper bounds for P^R, NP^R and P^R_{tt} than known.
        
        </div>

        <div class='item-content item-summary'>
        
          
          Denote by $R$ the set of strings with high Kolmogorov complexity. In [E. Allender, H. Buhrman, M. Kouck\&#39;y, D. van Melkebeek, and D. Ronneburger.
Power from random strings.
\emph{SIAM Journal on Computing}, 35:1467--1493, 2006.] the idea of using $R$ as an oracle for resource-bounded computation models was presented. This idea was later developed in several others papers.
We prove new lower bounds for $Q^R_{tt}$ and $Q^R_{sa}$:
- Oblivious-NP is subset of $Q^R_{tt}$;
- Oblivious-MA is subset of $Q^R_{sa}$.

Here $Q$ means quazi-polynomial-time; ``sa&#39;&#39; means sub-adaptive
reduction - a new type of reduction that we introduce. This type of reduction is not weaker than truth-table reduction and is not stronger than Turing reduction.

Also we prove upper bounds for BBP^R_{tt} and P^R_{sa} following [E. Allender, L. Friedman, and W. Gasarch. Limits on the computational power of random
strings.]:

P^R_{sa} is subset of EXP
BBP^R_{tt} is subset of AEXP(poly).

Here AEXP(poly) is the class of languages decidable in exponential time by an alternating Turing machine that switches from an existential to a universal state or vice versa at most polynomial times.


Finally we analyze some games that originate in [E. Allender, L. Friedman, and W. Gasarch. Limits on the computational power of random
strings.]. We prove completeness of these games. These results show that methods in this can not prove better upper bounds for P^R, NP^R and P^R_{tt} than known.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-25T06:21:39Z">Sunday, September 25 2022, 06:21</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Friday, September 23
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/23/open-rank-professor-of-computer-science-at-pomona-college-apply-by-october-15-2022/'>Open-Rank Professor of Computer Science at Pomona College (apply by October 15, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Pomona College seeks applications for two Open-Rank (assistant, associate, or full) Professor of Computer Science positions, to begin on July 1, 2023. All subfields of computer science will be considered. Candidates should have a broad background in computer science, be excellent teachers, have an active research program, and be excited about directing undergraduate research. Website: [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Pomona College seeks applications for two Open-Rank (assistant, associate, or full) Professor of Computer Science positions, to begin on July 1, 2023. All subfields of computer science will be considered. Candidates should have a broad background in computer science, be excellent teachers, have an active research program, and be excited about directing undergraduate research.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/22190">https://academicjobsonline.org/ajo/jobs/22190</a><br />
Email: cssearch@pomona.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-23T17:09:49Z">Friday, September 23 2022, 17:09</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11202'>Solving the General Case of Rank-3 Maker-Breaker Games in Polynomial Time</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Lear Bahack</p><p>A rank-3 Maker-Breaker game is played on a hypergraph in which all hyperedges
are sets of at most 3 vertices. The two players of the game, called Maker and
Breaker, move alternately. On his turn, maker chooses a vertex to be withdrawn
from all hyperedges, while Breaker on her turn chooses a vertex and delete all
the hyperedges containing that vertex. Maker wins when by the end of his turn
some hyperedge is completely covered, i.e. the last remaining vertex of that
hyperedge is withdrawn. Breaker wins when by the end of her turn, all
hyperedges have been deleted.
</p>
<p>Solving a Maker-Breaker game is the computational problem of choosing an
optimal move, or equivalently, deciding which player has a winning strategy in
a configuration. The complexity of solving two degenerate cases of rank-3 games
has been proven before to be polynomial. In this paper, we show that the
general case of rank-3 Maker-Breaker games is also solvable in polynomial time.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bahack_L/0/1/0/all/0/1">Lear Bahack</a></p><p>A rank-3 Maker-Breaker game is played on a hypergraph in which all hyperedges
are sets of at most 3 vertices. The two players of the game, called Maker and
Breaker, move alternately. On his turn, maker chooses a vertex to be withdrawn
from all hyperedges, while Breaker on her turn chooses a vertex and delete all
the hyperedges containing that vertex. Maker wins when by the end of his turn
some hyperedge is completely covered, i.e. the last remaining vertex of that
hyperedge is withdrawn. Breaker wins when by the end of her turn, all
hyperedges have been deleted.
</p>
<p>Solving a Maker-Breaker game is the computational problem of choosing an
optimal move, or equivalently, deciding which player has a winning strategy in
a configuration. The complexity of solving two degenerate cases of rank-3 games
has been proven before to be polynomial. In this paper, we show that the
general case of rank-3 Maker-Breaker games is also solvable in polynomial time.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-23T00:30:00Z">Friday, September 23 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11216'>Hyperstable Sets with Voting and Algorithmic Hardness Applications</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Steven Heilman</p><p>The noise stability of a Euclidean set $A$ with correlation $\rho$ is the
probability that $(X,Y)\in A\times A$, where $X,Y$ are standard Gaussian random
vectors with correlation $\rho\in(0,1)$. It is well-known that a Euclidean set
of fixed Gaussian volume that maximizes noise stability must be a half space.
</p>
<p>For a partition of Euclidean space into $m&gt;2$ parts each of Gaussian measure
$1/m$, it is still unknown what sets maximize the sum of their noise
stabilities. In this work, we classify partitions maximizing noise stability
that are also critical points for the derivative of noise stability with
respect to $\rho$. We call a partition satisfying these conditions hyperstable.
Uner the assumption that a maximizing partition is hyperstable, we prove:
</p>
<p>* a (conditional) version of the Plurality is Stablest Conjecture for $3$ or
$4$ candidates.
</p>
<p>* a (conditional) sharp Unique Games Hardness result for MAX-m-CUT for $m=3$
or $4$
</p>
<p>* a (conditional) version of the Propeller Conjecture of Khot and Naor for
$4$ sets.
</p>
<p>We also show that a symmetric set that is hyperstable must be star-shaped.
</p>
<p>For partitions of Euclidean space into $m&gt;2$ parts of fixed (but perhaps
unequal) Gaussian measure, the hyperstable property can only be satisfied when
all of the parts have Gaussian measure $1/m$. So, as our main contribution, we
have identified a possible strategy for proving the full Plurality is Stablest
Conjecture and the full sharp hardness for MAX-m-CUT: to prove both statements,
it suffices to show that sets maximizing noise stability are hyperstable. This
last point is crucial since any proof of the Plurality is Stablest Conjecture
must use a property that is special to partitions of sets into equal measures,
since the conjecture is false in the unequal measure case.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Heilman_S/0/1/0/all/0/1">Steven Heilman</a></p><p>The noise stability of a Euclidean set $A$ with correlation $\rho$ is the
probability that $(X,Y)\in A\times A$, where $X,Y$ are standard Gaussian random
vectors with correlation $\rho\in(0,1)$. It is well-known that a Euclidean set
of fixed Gaussian volume that maximizes noise stability must be a half space.
</p>
<p>For a partition of Euclidean space into $m&gt;2$ parts each of Gaussian measure
$1/m$, it is still unknown what sets maximize the sum of their noise
stabilities. In this work, we classify partitions maximizing noise stability
that are also critical points for the derivative of noise stability with
respect to $\rho$. We call a partition satisfying these conditions hyperstable.
Uner the assumption that a maximizing partition is hyperstable, we prove:
</p>
<p>* a (conditional) version of the Plurality is Stablest Conjecture for $3$ or
$4$ candidates.
</p>
<p>* a (conditional) sharp Unique Games Hardness result for MAX-m-CUT for $m=3$
or $4$
</p>
<p>* a (conditional) version of the Propeller Conjecture of Khot and Naor for
$4$ sets.
</p>
<p>We also show that a symmetric set that is hyperstable must be star-shaped.
</p>
<p>For partitions of Euclidean space into $m&gt;2$ parts of fixed (but perhaps
unequal) Gaussian measure, the hyperstable property can only be satisfied when
all of the parts have Gaussian measure $1/m$. So, as our main contribution, we
have identified a possible strategy for proving the full Plurality is Stablest
Conjecture and the full sharp hardness for MAX-m-CUT: to prove both statements,
it suffices to show that sets maximizing noise stability are hyperstable. This
last point is crucial since any proof of the Plurality is Stablest Conjecture
must use a property that is special to partitions of sets into equal measures,
since the conjecture is false in the unequal measure case.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-23T00:30:00Z">Friday, September 23 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10743'>Output Mode Switching for Parallel Five-bar Manipulators Using a Graph-based Path Planner</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Parker B. Edwards, Aravind Baskar, Caroline Hills, Mark Plecnik, Jonathan D. Hauenstein</p><p>The configuration manifolds of parallel manipulators exhibit more
nonlinearity than serial manipulators. Qualitatively, they can be seen to
possess extra folds. By projecting such manifolds onto spaces of engineering
relevance, such as an output workspace or an input actuator space, these folds
cast edges that exhibit nonsmooth behavior. For example, inside the global
workspace bounds of a five-bar linkage appear several local workspace bounds
that only constrain certain output modes of the mechanism. The presence of such
boundaries, which manifest in both input and output projections, serve as a
source of confusion when these projections are studied exclusively instead of
the configuration manifold itself. Particularly, the design of nonsymmetric
parallel manipulators has been confounded by the presence of exotic projections
in their input and output spaces. In this paper, we represent the configuration
space with a radius graph, then weight each edge by solving an optimization
problem using homotopy continuation to quantify transmission quality. We then
employ a graph path planner to approximate geodesics between configuration
points that avoid regions of low transmission quality. Our methodology
automatically generates paths capable of transitioning between non-neighboring
output modes, a motion which involves osculating multiple workspace boundaries
(local, global, or both). We apply our technique to two nonsymmetric five-bar
examples that demonstrate how transmission properties and other characteristics
of the workspace can be selected by switching output modes.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Edwards_P/0/1/0/all/0/1">Parker B. Edwards</a>, <a href="http://arxiv.org/find/cs/1/au:+Baskar_A/0/1/0/all/0/1">Aravind Baskar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hills_C/0/1/0/all/0/1">Caroline Hills</a>, <a href="http://arxiv.org/find/cs/1/au:+Plecnik_M/0/1/0/all/0/1">Mark Plecnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauenstein_J/0/1/0/all/0/1">Jonathan D. Hauenstein</a></p><p>The configuration manifolds of parallel manipulators exhibit more
nonlinearity than serial manipulators. Qualitatively, they can be seen to
possess extra folds. By projecting such manifolds onto spaces of engineering
relevance, such as an output workspace or an input actuator space, these folds
cast edges that exhibit nonsmooth behavior. For example, inside the global
workspace bounds of a five-bar linkage appear several local workspace bounds
that only constrain certain output modes of the mechanism. The presence of such
boundaries, which manifest in both input and output projections, serve as a
source of confusion when these projections are studied exclusively instead of
the configuration manifold itself. Particularly, the design of nonsymmetric
parallel manipulators has been confounded by the presence of exotic projections
in their input and output spaces. In this paper, we represent the configuration
space with a radius graph, then weight each edge by solving an optimization
problem using homotopy continuation to quantify transmission quality. We then
employ a graph path planner to approximate geodesics between configuration
points that avoid regions of low transmission quality. Our methodology
automatically generates paths capable of transitioning between non-neighboring
output modes, a motion which involves osculating multiple workspace boundaries
(local, global, or both). We apply our technique to two nonsymmetric five-bar
examples that demonstrate how transmission properties and other characteristics
of the workspace can be selected by switching output modes.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-23T00:30:00Z">Friday, September 23 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10970'>Maths, Computation and Flamenco: overview and challenges</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jos&#xe9;-Miguel D&#xed;az-B&#xe1;&#xf1;ez, Nadine Kroher</p><p>Flamenco is a rich performance-oriented art music genre from Southern Spain
which attracts a growing community of aficionados around the globe. Due to its
improvisational and expressive nature, its unique musical characteristics, and
the fact that the genre is largely undocumented, flamenco poses a number of
interesting mathematical and computational challenges. Most existing approaches
in Musical Information Retrieval (MIR) were developed in the context of popular
or classical music and do often not generalize well to non-Western music
traditions, in particular when the underlying music theoretical assumptions do
not hold for these genres. Over the recent decade, a number of computational
problems related to the automatic analysis of flamenco music have been defined
and several methods addressing a variety of musical aspects have been proposed.
This paper provides an overview of the challenges which arise in the context of
computational analysis of flamenco music and outlines an overview of existing
approaches.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1">Jos&#xe9;-Miguel D&#xed;az-B&#xe1;&#xf1;ez</a>, <a href="http://arxiv.org/find/cs/1/au:+Kroher_N/0/1/0/all/0/1">Nadine Kroher</a></p><p>Flamenco is a rich performance-oriented art music genre from Southern Spain
which attracts a growing community of aficionados around the globe. Due to its
improvisational and expressive nature, its unique musical characteristics, and
the fact that the genre is largely undocumented, flamenco poses a number of
interesting mathematical and computational challenges. Most existing approaches
in Musical Information Retrieval (MIR) were developed in the context of popular
or classical music and do often not generalize well to non-Western music
traditions, in particular when the underlying music theoretical assumptions do
not hold for these genres. Over the recent decade, a number of computational
problems related to the automatic analysis of flamenco music have been defined
and several methods addressing a variety of musical aspects have been proposed.
This paper provides an overview of the challenges which arise in the context of
computational analysis of flamenco music and outlines an overview of existing
approaches.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-23T00:30:00Z">Friday, September 23 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11177'>Uniform Reliability for Unbounded Homomorphism-Closed Graph Queries</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Antoine Amarilli</p><p>We study the uniform query reliability problem, which asks, for a fixed
Boolean query Q, given an instance I, how many subinstances of I satisfy Q.
Equivalently, this is a restricted case of Boolean query evaluation on
tuple-independent probabilistic databases where all facts must have probability
1/2. We focus on graph signatures, and on queries closed under homomorphisms.
We show that for any such query that is unbounded, i.e., not equivalent to a
union of conjunctive queries, the uniform reliability problem is #P-hard. This
recaptures the hardness, e.g., of s-t connectedness, which counts how many
subgraphs of an input graph have a path between a source and a sink.
</p>
<p>This new hardness result on uniform reliability strengthens our earlier
hardness result on probabilistic query evaluation for unbounded
homomorphism-closed queries (ICDT'20). Indeed, our earlier proof crucially used
facts with probability 1, so it did not apply to the unweighted case. The new
proof presented in this paper avoids this; it uses our recent hardness result
on uniform reliability for non-hierarchical conjunctive queries without
self-joins (ICDT'21), along with new techniques.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Amarilli_A/0/1/0/all/0/1">Antoine Amarilli</a></p><p>We study the uniform query reliability problem, which asks, for a fixed
Boolean query Q, given an instance I, how many subinstances of I satisfy Q.
Equivalently, this is a restricted case of Boolean query evaluation on
tuple-independent probabilistic databases where all facts must have probability
1/2. We focus on graph signatures, and on queries closed under homomorphisms.
We show that for any such query that is unbounded, i.e., not equivalent to a
union of conjunctive queries, the uniform reliability problem is #P-hard. This
recaptures the hardness, e.g., of s-t connectedness, which counts how many
subgraphs of an input graph have a path between a source and a sink.
</p>
<p>This new hardness result on uniform reliability strengthens our earlier
hardness result on probabilistic query evaluation for unbounded
homomorphism-closed queries (ICDT'20). Indeed, our earlier proof crucially used
facts with probability 1, so it did not apply to the unweighted case. The new
proof presented in this paper avoids this; it uses our recent hardness result
on uniform reliability for non-hierarchical conjunctive queries without
self-joins (ICDT'21), along with new techniques.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-23T00:30:00Z">Friday, September 23 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11028'>Efficiently Reconfiguring a Connected Swarm of Labeled Robots</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: S&#xe1;ndor P. Fekete, Peter Kramer, Christian Rieck, Christian Scheffer, Arne Schmidt</p><p>When considering motion planning for a swarm of $n$ labeled robots, we need
to rearrange a given start configuration into a desired target configuration
via a sequence of parallel, continuous, collision-free robot motions. The
objective is to reach the new configuration in a minimum amount of time; an
important constraint is to keep the swarm connected at all times. Problems of
this type have been considered before, with recent notable results achieving
constant stretch for not necessarily connected reconfiguration: If mapping the
start configuration to the target configuration requires a maximum Manhattan
distance of $d$, the total duration of an overall schedule can be bounded to
$\mathcal{O}(d)$, which is optimal up to constant factors. However, constant
stretch could only be achieved if disconnected reconfiguration is allowed, or
for scaled configurations (which arise by increasing all dimensions of a given
object by the same multiplicative factor) of unlabeled robots.
</p>
<p>We resolve these major open problems by (1) establishing a lower bound of
$\Omega(\sqrt{n})$ for connected, labeled reconfiguration and, most
importantly, by (2) proving that for scaled arrangements, constant stretch for
connected reconfiguration can be achieved. In addition, we show that (3) it is
NP-hard to decide whether a makespan of 2 can be achieved, while it is possible
to check in polynomial time whether a makespan of 1 can be achieved.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fekete_S/0/1/0/all/0/1">S&#xe1;ndor P. Fekete</a>, <a href="http://arxiv.org/find/cs/1/au:+Kramer_P/0/1/0/all/0/1">Peter Kramer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieck_C/0/1/0/all/0/1">Christian Rieck</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheffer_C/0/1/0/all/0/1">Christian Scheffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_A/0/1/0/all/0/1">Arne Schmidt</a></p><p>When considering motion planning for a swarm of $n$ labeled robots, we need
to rearrange a given start configuration into a desired target configuration
via a sequence of parallel, continuous, collision-free robot motions. The
objective is to reach the new configuration in a minimum amount of time; an
important constraint is to keep the swarm connected at all times. Problems of
this type have been considered before, with recent notable results achieving
constant stretch for not necessarily connected reconfiguration: If mapping the
start configuration to the target configuration requires a maximum Manhattan
distance of $d$, the total duration of an overall schedule can be bounded to
$\mathcal{O}(d)$, which is optimal up to constant factors. However, constant
stretch could only be achieved if disconnected reconfiguration is allowed, or
for scaled configurations (which arise by increasing all dimensions of a given
object by the same multiplicative factor) of unlabeled robots.
</p>
<p>We resolve these major open problems by (1) establishing a lower bound of
$\Omega(\sqrt{n})$ for connected, labeled reconfiguration and, most
importantly, by (2) proving that for scaled arrangements, constant stretch for
connected reconfiguration can be achieved. In addition, we show that (3) it is
NP-hard to decide whether a makespan of 2 can be achieved, while it is possible
to check in polynomial time whether a makespan of 1 can be achieved.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-23T00:30:00Z">Friday, September 23 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10614'>Learning-Augmented Algorithms for Online Linear and Semidefinite Programming</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Elena Grigorescu, Young-San Lin, Sandeep Silwal, Maoyuan Song, Samson Zhou</p><p>Semidefinite programming (SDP) is a unifying framework that generalizes both
linear programming and quadratically-constrained quadratic programming, while
also yielding efficient solvers, both in theory and in practice. However, there
exist known impossibility results for approximating the optimal solution when
constraints for covering SDPs arrive in an online fashion. In this paper, we
study online covering linear and semidefinite programs in which the algorithm
is augmented with advice from a possibly erroneous predictor. We show that if
the predictor is accurate, we can efficiently bypass these impossibility
results and achieve a constant-factor approximation to the optimal solution,
i.e., consistency. On the other hand, if the predictor is inaccurate, under
some technical conditions, we achieve results that match both the classical
optimal upper bounds and the tight lower bounds up to constant factors, i.e.,
robustness.
</p>
<p>More broadly, we introduce a framework that extends both (1) the online set
cover problem augmented with machine-learning predictors, studied by Bamas,
Maggiori, and Svensson (NeurIPS 2020), and (2) the online covering SDP problem,
initiated by Elad, Kale, and Naor (ICALP 2016). Specifically, we obtain general
online learning-augmented algorithms for covering linear programs with
fractional advice and constraints, and initiate the study of learning-augmented
algorithms for covering SDP problems.
</p>
<p>Our techniques are based on the primal-dual framework of Buchbinder and Naor
(Mathematics of Operations Research, 34, 2009) and can be further adjusted to
handle constraints where the variables lie in a bounded region, i.e., box
constraints.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grigorescu_E/0/1/0/all/0/1">Elena Grigorescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Young-San Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1">Sandeep Silwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Maoyuan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Samson Zhou</a></p><p>Semidefinite programming (SDP) is a unifying framework that generalizes both
linear programming and quadratically-constrained quadratic programming, while
also yielding efficient solvers, both in theory and in practice. However, there
exist known impossibility results for approximating the optimal solution when
constraints for covering SDPs arrive in an online fashion. In this paper, we
study online covering linear and semidefinite programs in which the algorithm
is augmented with advice from a possibly erroneous predictor. We show that if
the predictor is accurate, we can efficiently bypass these impossibility
results and achieve a constant-factor approximation to the optimal solution,
i.e., consistency. On the other hand, if the predictor is inaccurate, under
some technical conditions, we achieve results that match both the classical
optimal upper bounds and the tight lower bounds up to constant factors, i.e.,
robustness.
</p>
<p>More broadly, we introduce a framework that extends both (1) the online set
cover problem augmented with machine-learning predictors, studied by Bamas,
Maggiori, and Svensson (NeurIPS 2020), and (2) the online covering SDP problem,
initiated by Elad, Kale, and Naor (ICALP 2016). Specifically, we obtain general
online learning-augmented algorithms for covering linear programs with
fractional advice and constraints, and initiate the study of learning-augmented
algorithms for covering SDP problems.
</p>
<p>Our techniques are based on the primal-dual framework of Buchbinder and Naor
(Mathematics of Operations Research, 34, 2009) and can be further adjusted to
handle constraints where the variables lie in a bounded region, i.e., box
constraints.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-23T00:30:00Z">Friday, September 23 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10685'>A cubic algorithm for computing the Hermite normal form of a nonsingular integer matrix</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Stavros Birmpilis, George Labahn, Arne Storjohann</p><p>A Las Vegas randomized algorithm is given to compute the Hermite normal form
of a nonsingular integer matrix $A$ of dimension $n$. The algorithm uses
quadratic integer multiplication and cubic matrix multiplication and has
running time bounded by $O(n^3 (\log n + \log ||A||)^2(\log n)^2)$ bit
operations, where $||A||= \max_{ij} |A_{ij}|$ denotes the largest entry of $A$
in absolute value. A variant of the algorithm that uses pseudo-linear integer
multiplication is given that has running time $(n^3 \log ||A||)^{1+o(1)}$ bit
operations, where the exponent $"+o(1)"$ captures additional factors $c_1 (\log
n)^{c_2} (\log \log ||A||)^{c_3}$ for positive real constants $c_1,c_2,c_3$.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Birmpilis_S/0/1/0/all/0/1">Stavros Birmpilis</a>, <a href="http://arxiv.org/find/cs/1/au:+Labahn_G/0/1/0/all/0/1">George Labahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Storjohann_A/0/1/0/all/0/1">Arne Storjohann</a></p><p>A Las Vegas randomized algorithm is given to compute the Hermite normal form
of a nonsingular integer matrix $A$ of dimension $n$. The algorithm uses
quadratic integer multiplication and cubic matrix multiplication and has
running time bounded by $O(n^3 (\log n + \log ||A||)^2(\log n)^2)$ bit
operations, where $||A||= \max_{ij} |A_{ij}|$ denotes the largest entry of $A$
in absolute value. A variant of the algorithm that uses pseudo-linear integer
multiplication is given that has running time $(n^3 \log ||A||)^{1+o(1)}$ bit
operations, where the exponent $"+o(1)"$ captures additional factors $c_1 (\log
n)^{c_2} (\log \log ||A||)^{c_3}$ for positive real constants $c_1,c_2,c_3$.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-23T00:30:00Z">Friday, September 23 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.10805'>Popular Edges with Critical Nodes</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Kushagra Chatterjee, Prajakta Nimbhorkar</p><p>In the popular edge problem, the input is a bipartite graph $G = (A \cup
B,E)$ where $A$ and $B$ denote a set of men and a set of women respectively,
and each vertex in $A\cup B$ has a strict preference ordering over its
neighbours. A matching $M$ in $G$ is said to be {\em popular} if there is no
other matching $M'$ such that the number of vertices that prefer $M'$ to $M$ is
more than the number of vertices that prefer $M$ to $M'$. The goal is to
determine, whether a given edge $e$ belongs to some popular matching in $G$. A
polynomial-time algorithm for this problem appears in \cite{CK18}. We consider
the popular edge problem when some men or women are prioritized or critical. A
matching that matches all the critical nodes is termed as a feasible matching.
It follows from \cite{Kavitha14,Kavitha21,NNRS21,NN17} that, when $G$ admits a
feasible matching, there always exists a matching that is popular among all
feasible matchings. We give a polynomial-time algorithm for the popular edge
problem in the presence of critical men or women. We also show that an
analogous result does not hold in the many-to-one setting, which is known as
the Hospital-Residents Problem in literature, even when there are no critical
nodes.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_K/0/1/0/all/0/1">Kushagra Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Nimbhorkar_P/0/1/0/all/0/1">Prajakta Nimbhorkar</a></p><p>In the popular edge problem, the input is a bipartite graph $G = (A \cup
B,E)$ where $A$ and $B$ denote a set of men and a set of women respectively,
and each vertex in $A\cup B$ has a strict preference ordering over its
neighbours. A matching $M$ in $G$ is said to be {\em popular} if there is no
other matching $M'$ such that the number of vertices that prefer $M'$ to $M$ is
more than the number of vertices that prefer $M$ to $M'$. The goal is to
determine, whether a given edge $e$ belongs to some popular matching in $G$. A
polynomial-time algorithm for this problem appears in \cite{CK18}. We consider
the popular edge problem when some men or women are prioritized or critical. A
matching that matches all the critical nodes is termed as a feasible matching.
It follows from \cite{Kavitha14,Kavitha21,NNRS21,NN17} that, when $G$ admits a
feasible matching, there always exists a matching that is popular among all
feasible matchings. We give a polynomial-time algorithm for the popular edge
problem in the presence of critical men or women. We also show that an
analogous result does not hold in the many-to-one setting, which is known as
the Hospital-Residents Problem in literature, even when there are no critical
nodes.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-23T00:30:00Z">Friday, September 23 2022, 00:30</time>
        </div>
      </div>
    </article>
  
  </div>

  <script src='js/jquery-2.0.3.min.js'></script>
  <script src="js/jquery.timeago.js" type="text/javascript"></script>
  <script>
    jQuery(document).ready(function() {
      jQuery("time.timeago").timeago();
    });
  </script>
  <script src='js/blank.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
