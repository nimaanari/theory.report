<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-05-23T19:30:35Z">Tuesday, May 23 2023, 19:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, May 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/'>Early Theory</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          &#8220;Everything is interesting&#8221; Susan Graham is a Distinguished Professor of Electrical Engineering and Computer Science Emerita at the University of California, Berkeley. I have known Graham for decades&#8212;and am happy to report she is still active. She was a member of the President&#8217;s Council of Advisors on Science and Technology (PCAST) during the Obama Administration. [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>&#8220;Everything is interesting&#8221;</em><br />
<font color="#000000"></p>
<p>
Susan Graham is a Distinguished Professor of Electrical Engineering and Computer Science Emerita at the University of California, Berkeley. I have known Graham for decades&#8212;and am happy to report she is still active. </p>
<p>
She was a <a href="https://obamawhitehouse.archives.gov/administration/eop/ostp/pcast/about/members">member</a> of the President&#8217;s Council of Advisors on Science and Technology (PCAST) during the Obama Administration. She served alongside Bill Press of Austin, who is <a href="https://obamawhitehouse.archives.gov/administration/eop/ostp/pcast/about/members">still</a> on PCAST&#8212;alongside Terry Tao among names we know. </p>
<p>
Graham has maintained involvements in the performing arts. She is an <a href="https://calperformances.org/about/trustees/">Officer</a> on the Board of Trustees of <a href="https://calperformances.org/">Cal Performances</a>. She also served on the Board of Overseers of the Curtis Institute of Music in Philadelphia until they reorganized in 2016. She has also had a long association with Harvard, She was referring to committee memberships when she was <a href="https://www.harvardmagazine.com/2011/09/and-then-there-were-10">quoted</a> for the subtitle above, but her words &#8220;everything is interesting&#8221; apply more widely in our field.</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/sg-2/" rel="attachment wp-att-21640"><img data-attachment-id="21640" data-permalink="https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/sg-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?fit=200%2C200&amp;ssl=1" data-orig-size="200,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sg" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?fit=200%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?fit=200%2C200&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?resize=200%2C200&#038;ssl=1" alt="" width="200" height="200" class="aligncenter size-full wp-image-21640" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?w=200&amp;ssl=1 200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 200px) 100vw, 200px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Her Work </H2></p>
<p><p>
Graham has done seminal research in compiler code generation and optimization. She was elected a member of the National Academy of Engineering in 1993 for contributions to the theory and practice of compiler construction and for leadership in the computer science community. And was awarded the 2009 IEEE John von Neumann Medal for &#8220;contributions to programming language design and implementation and for exemplary service to the discipline of computer science.&#8221;</p>
<p>
The nexus with programming languages was arguably <em>the</em> initial focus of computer science theory in the years before 1965, when Juris Hartmanis and Richard Stearns founded computational complexity on Turing machines. See the <a href="https://cs.brown.edu/people/jsavage/papers/09_ch5.pdf">history</a> penned by John Savage, Alan Selman, and Carl Smith for a neat summary. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/jsascs/" rel="attachment wp-att-21641"><img data-attachment-id="21641" data-permalink="https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/jsascs/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?fit=546%2C191&amp;ssl=1" data-orig-size="546,191" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="JSASCS" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?fit=300%2C105&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?fit=546%2C191&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?resize=362%2C128&#038;ssl=1" alt="" width="362" height="128" class="aligncenter wp-image-21641" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?w=546&amp;ssl=1 546w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?resize=300%2C105&amp;ssl=1 300w" sizes="(max-width: 362px) 100vw, 362px" data-recalc-dims="1" /></a></p>
<p><P><br />
They point out:</p>
<blockquote><p><b> </b> <em> After the early recognition of the relevance of the theory of formal languages to the practice of compiler construction, theoretical computer science became a cornerstone of virtually every computer science undergraduate degree program. </em>
</p></blockquote>
<p><p>
Susan&#8217;s first <a href="https://ieeexplore.ieee.org/document/4569647">paper</a> appeared at the conference now named FOCS in 1970. It was titled, &#8220;Extended Precedence Languages, Bounded Right Context Languages, and Deterministic Languages.&#8221; Rather than invent a new complexity class, as even ChatGPT picked up on our common vice <a href="https://rjlipton.wpcomstaging.com/2023/04/01/the-chatgpt-conundrum/">recently</a>, she more economically collapsed some classes together. </p>
<p>
The combination of &#8220;theoretical and practical interest&#8221; as mentioned in her paper carried through to much other work in programming languages and their implementations, software tools and development environments, and needs of high-performance computing. Her work with students on the Berkeley Unix project led to their <a href="https://docs-archive.freebsd.org/44doc/psd/18.gprof/paper.pdf">paper</a> on the program profiling tool <a href="https://en.wikipedia.org/wiki/Gprof">gprof</a>. This is considered one of the classic papers from the Programming Language Design and Implementation (PLDI) conferences.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Graham is terrific. I only hope that she is able to help us better understand theory of all types. </p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T02:48:30Z">Tuesday, May 23 2023, 02:48</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.12097'>Nearly Optimal Algorithms for Testing and Learning Quantum Junta Channels</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zongbo Bao, Penghui Yao</p><p>We consider the problems of testing and learning quantum $k$-junta channels,
which are $n$-qubit to $n$-qubit quantum channels acting non-trivially on at
most $k$ out of $n$ qubits and leaving the rest of qubits unchanged. We show
the following.
</p>
<p>1. An $\widetilde{O}\left(\sqrt{k}\right)$-query algorithm to distinguish
whether the given channel is $k$-junta channel or is far from any $k$-junta
channels, and a lower bound $\Omega\left(\sqrt{k}\right)$ on the number of
queries;
</p>
<p>2. An $\widetilde{O}\left(4^k\right)$-query algorithm to learn a $k$-junta
channel, and a lower bound $\Omega\left(4^k/k\right)$ on the number of queries.
</p>
<p>This answers an open problem raised by Chen et al. (2023). In order to settle
these problems, we develop a Fourier analysis framework over the space of
superoperators and prove several fundamental properties, which extends the
Fourier analysis over the space of operators introduced in Montanaro and
Osborne (2010).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Bao_Z/0/1/0/all/0/1">Zongbo Bao</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yao_P/0/1/0/all/0/1">Penghui Yao</a></p><p>We consider the problems of testing and learning quantum $k$-junta channels,
which are $n$-qubit to $n$-qubit quantum channels acting non-trivially on at
most $k$ out of $n$ qubits and leaving the rest of qubits unchanged. We show
the following.
</p>
<p>1. An $\widetilde{O}\left(\sqrt{k}\right)$-query algorithm to distinguish
whether the given channel is $k$-junta channel or is far from any $k$-junta
channels, and a lower bound $\Omega\left(\sqrt{k}\right)$ on the number of
queries;
</p>
<p>2. An $\widetilde{O}\left(4^k\right)$-query algorithm to learn a $k$-junta
channel, and a lower bound $\Omega\left(4^k/k\right)$ on the number of queries.
</p>
<p>This answers an open problem raised by Chen et al. (2023). In order to settle
these problems, we develop a Fourier analysis framework over the space of
superoperators and prove several fundamental properties, which extends the
Fourier analysis over the space of operators introduced in Montanaro and
Osborne (2010).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T00:30:00Z">Tuesday, May 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.12176'>On the approximability and energy-flow modeling of the electric vehicle sharing problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Welverton R. Silva, F&#xe1;bio L. Usberti, Rafael C. S. Schouery</p><p>The electric vehicle sharing problem (EVSP) arises from the planning and
operation of one-way electric car-sharing systems. It aims to maximize the
total rental time of a fleet of electric vehicles while ensuring that all the
demands of the customer are fulfilled. In this paper, we expand the knowledge
on the complexity of the EVSP by showing that it is NP-hard to approximate it
to within a factor of $n^{1-\epsilon}$ in polynomial time, for any $\epsilon &gt;
0$, where $n$ denotes the number of customers, unless P = NP. In addition, we
also show that the problem does not have a monotone structure, which can be
detrimental to the development of heuristics employing constructive strategies.
Moreover, we propose a novel approach for the modeling of the EVSP based on
energy flows in the network. Based on the new model, we propose a relax-and-fix
strategy and an exact algorithm that uses a warm-start solution obtained from
our heuristic approach. We report computational results comparing our
formulation with the best-performing formulation in the literature. The results
show that our formulation outperforms the previous one concerning the number of
optimal solutions obtained, optimality gaps, and computational times.
Previously, $32.7\%$ of the instances remained unsolved (within a time limit of
one hour) by the best-performing formulation in the literature, while our
formulation obtained optimal solutions for all instances. To stress our
approaches, two more challenging new sets of instances were generated, for
which we were able to solve $49.5\%$ of the instances, with an average
optimality gap of $2.91\%$ for those not solved optimally.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Silva_W/0/1/0/all/0/1">Welverton R. Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Usberti_F/0/1/0/all/0/1">F&#xe1;bio L. Usberti</a>, <a href="http://arxiv.org/find/cs/1/au:+Schouery_R/0/1/0/all/0/1">Rafael C. S. Schouery</a></p><p>The electric vehicle sharing problem (EVSP) arises from the planning and
operation of one-way electric car-sharing systems. It aims to maximize the
total rental time of a fleet of electric vehicles while ensuring that all the
demands of the customer are fulfilled. In this paper, we expand the knowledge
on the complexity of the EVSP by showing that it is NP-hard to approximate it
to within a factor of $n^{1-\epsilon}$ in polynomial time, for any $\epsilon &gt;
0$, where $n$ denotes the number of customers, unless P = NP. In addition, we
also show that the problem does not have a monotone structure, which can be
detrimental to the development of heuristics employing constructive strategies.
Moreover, we propose a novel approach for the modeling of the EVSP based on
energy flows in the network. Based on the new model, we propose a relax-and-fix
strategy and an exact algorithm that uses a warm-start solution obtained from
our heuristic approach. We report computational results comparing our
formulation with the best-performing formulation in the literature. The results
show that our formulation outperforms the previous one concerning the number of
optimal solutions obtained, optimality gaps, and computational times.
Previously, $32.7\%$ of the instances remained unsolved (within a time limit of
one hour) by the best-performing formulation in the literature, while our
formulation obtained optimal solutions for all instances. To stress our
approaches, two more challenging new sets of instances were generated, for
which we were able to solve $49.5\%$ of the instances, with an average
optimality gap of $2.91\%$ for those not solved optimally.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T00:30:00Z">Tuesday, May 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11942'>OPTWIN: Drift identification with optimal sub-windows</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mauro Dalle Lucca Tosi, Martin Theobald</p><p>Online Learning (OL) is a field of research that is increasingly gaining
attention both in academia and industry. One of the main challenges of OL is
the inherent presence of concept drifts, which are commonly defined as
unforeseeable changes in the statistical properties of an incoming data stream
over time. The detection of concept drifts typically involves analyzing the
error rates produced by an underlying OL algorithm in order to identify if a
concept drift occurred or not, such that the OL algorithm can adapt
accordingly. Current concept-drift detectors perform very well, i.e., with low
false negative rates, but they still tend to exhibit high false positive rates
in the concept-drift detection. This may impact the performance of the learner
and result in an undue amount of computational resources spent on retraining a
model that actually still performs within its expected range. In this paper, we
propose OPTWIN, our "OPTimal WINdow" concept drift detector. OPTWIN uses a
sliding window of events over an incoming data stream to track the errors of an
OL algorithm. The novelty of OPTWIN is to consider both the means and the
variances of the error rates produced by a learner in order to split the
sliding window into two provably optimal sub-windows, such that the split
occurs at the earliest event at which a statistically significant difference
according to either the $t$- or the $f$-tests occurred. We assessed OPTWIN over
the MOA framework, using ADWIN, DDM, EDDM, STEPD and ECDD as baselines over 7
synthetic and real-world datasets, and in the presence of both sudden and
gradual concept drifts. In our experiments, we show that OPTWIN surpasses the
F1-score of the baselines in a statistically significant manner while
maintaining a lower detection delay and saving up to 21% of time spent on
retraining the models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tosi_M/0/1/0/all/0/1">Mauro Dalle Lucca Tosi</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobald_M/0/1/0/all/0/1">Martin Theobald</a></p><p>Online Learning (OL) is a field of research that is increasingly gaining
attention both in academia and industry. One of the main challenges of OL is
the inherent presence of concept drifts, which are commonly defined as
unforeseeable changes in the statistical properties of an incoming data stream
over time. The detection of concept drifts typically involves analyzing the
error rates produced by an underlying OL algorithm in order to identify if a
concept drift occurred or not, such that the OL algorithm can adapt
accordingly. Current concept-drift detectors perform very well, i.e., with low
false negative rates, but they still tend to exhibit high false positive rates
in the concept-drift detection. This may impact the performance of the learner
and result in an undue amount of computational resources spent on retraining a
model that actually still performs within its expected range. In this paper, we
propose OPTWIN, our "OPTimal WINdow" concept drift detector. OPTWIN uses a
sliding window of events over an incoming data stream to track the errors of an
OL algorithm. The novelty of OPTWIN is to consider both the means and the
variances of the error rates produced by a learner in order to split the
sliding window into two provably optimal sub-windows, such that the split
occurs at the earliest event at which a statistically significant difference
according to either the $t$- or the $f$-tests occurred. We assessed OPTWIN over
the MOA framework, using ADWIN, DDM, EDDM, STEPD and ECDD as baselines over 7
synthetic and real-world datasets, and in the presence of both sudden and
gradual concept drifts. In our experiments, we show that OPTWIN surpasses the
F1-score of the baselines in a statistically significant manner while
maintaining a lower detection delay and saving up to 21% of time spent on
retraining the models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T00:30:00Z">Tuesday, May 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.12023'>Stretch-width</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: &#xc9;douard Bonnet, Julien Duron</p><p>We introduce a new parameter, called stretch-width, that we show sits
strictly between clique-width and twin-width. Unlike the reduced parameters
[BKW '22], planar graphs and polynomial subdivisions do not have bounded
stretch-width. This leaves open the possibility of efficient algorithms for a
broad fragment of problems within Monadic Second-Order (MSO) logic on graphs of
bounded stretch-width. In this direction, we prove that graphs of bounded
maximum degree and bounded stretch-width have at most logarithmic treewidth. As
a consequence, in classes of bounded stretch-width, Maximum Independent Set can
be solved in subexponential time $2^{O(n^{4/5} \log n)}$ on $n$-vertex graphs,
and, if further the maximum degree is bounded, Existential Counting Modal Logic
[Pilipczuk '11] can be model-checked in polynomial time. We also give a
polynomial-time $O(\text{OPT}^2)$-approximation for the stretch-width of
symmetric $0,1$-matrices or ordered graphs. Somewhat unexpectedly, we prove
that exponential subdivisions of bounded-degree graphs have bounded
stretch-width. This allows to complement the logarithmic upper bound of
treewidth with a matching lower bound. We leave as open the existence of an
efficient approximation algorithm for the stretch-width of unordered graphs, if
the exponential subdivisions of all graphs have bounded stretch-width, and if
graphs of bounded stretch-width have logarithmic clique-width (or rank-width).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1">&#xc9;douard Bonnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Duron_J/0/1/0/all/0/1">Julien Duron</a></p><p>We introduce a new parameter, called stretch-width, that we show sits
strictly between clique-width and twin-width. Unlike the reduced parameters
[BKW '22], planar graphs and polynomial subdivisions do not have bounded
stretch-width. This leaves open the possibility of efficient algorithms for a
broad fragment of problems within Monadic Second-Order (MSO) logic on graphs of
bounded stretch-width. In this direction, we prove that graphs of bounded
maximum degree and bounded stretch-width have at most logarithmic treewidth. As
a consequence, in classes of bounded stretch-width, Maximum Independent Set can
be solved in subexponential time $2^{O(n^{4/5} \log n)}$ on $n$-vertex graphs,
and, if further the maximum degree is bounded, Existential Counting Modal Logic
[Pilipczuk '11] can be model-checked in polynomial time. We also give a
polynomial-time $O(\text{OPT}^2)$-approximation for the stretch-width of
symmetric $0,1$-matrices or ordered graphs. Somewhat unexpectedly, we prove
that exponential subdivisions of bounded-degree graphs have bounded
stretch-width. This allows to complement the logarithmic upper bound of
treewidth with a matching lower bound. We leave as open the existence of an
efficient approximation algorithm for the stretch-width of unordered graphs, if
the exponential subdivisions of all graphs have bounded stretch-width, and if
graphs of bounded stretch-width have logarithmic clique-width (or rank-width).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T00:30:00Z">Tuesday, May 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.12119'>Distortion in metric matching with ordinal preferences</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nima Anari, Moses Charikar, Prasanna Ramakrishnan</p><p>Suppose that we have $n$ agents and $n$ items which lie in a shared metric
space. We would like to match the agents to items such that the total distance
from agents to their matched items is as small as possible. However, instead of
having direct access to distances in the metric, we only have each agent's
ranking of the items in order of distance. Given this limited information, what
is the minimum possible worst-case approximation ratio (known as the
distortion) that a matching mechanism can guarantee?
</p>
<p>Previous work by Caragiannis et al. proved that the (deterministic) Serial
Dictatorship mechanism has distortion at most $2^n - 1$. We improve this by
providing a simple deterministic mechanism that has distortion $O(n^2)$. We
also provide the first nontrivial lower bound on this problem, showing that any
matching mechanism (deterministic or randomized) must have worst-case
distortion $\Omega(\log n)$.
</p>
<p>In addition to these new bounds, we show that a large class of truthful
mechanisms derived from Deferred Acceptance all have worst-case distortion at
least $2^n - 1$, and we find an intriguing connection between thin matchings
(analogous to the well-known thin trees conjecture) and the distortion gap
between deterministic and randomized mechanisms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Anari_N/0/1/0/all/0/1">Nima Anari</a>, <a href="http://arxiv.org/find/cs/1/au:+Charikar_M/0/1/0/all/0/1">Moses Charikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_P/0/1/0/all/0/1">Prasanna Ramakrishnan</a></p><p>Suppose that we have $n$ agents and $n$ items which lie in a shared metric
space. We would like to match the agents to items such that the total distance
from agents to their matched items is as small as possible. However, instead of
having direct access to distances in the metric, we only have each agent's
ranking of the items in order of distance. Given this limited information, what
is the minimum possible worst-case approximation ratio (known as the
distortion) that a matching mechanism can guarantee?
</p>
<p>Previous work by Caragiannis et al. proved that the (deterministic) Serial
Dictatorship mechanism has distortion at most $2^n - 1$. We improve this by
providing a simple deterministic mechanism that has distortion $O(n^2)$. We
also provide the first nontrivial lower bound on this problem, showing that any
matching mechanism (deterministic or randomized) must have worst-case
distortion $\Omega(\log n)$.
</p>
<p>In addition to these new bounds, we show that a large class of truthful
mechanisms derived from Deferred Acceptance all have worst-case distortion at
least $2^n - 1$, and we find an intriguing connection between thin matchings
(analogous to the well-known thin trees conjecture) and the distortion gap
between deterministic and randomized mechanisms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T00:30:00Z">Tuesday, May 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, May 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11276'>Perspective on complexity measures targetting read-once branching programs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yaqiao Li, Pierre McKenzie</p><p>A model of computation for which reasonable yet still incomplete lower bounds
are known is the read-once branching program. Here variants of complexity
measures successful in the study of read-once branching programs are defined
and studied. Some new or simpler proofs of known bounds are uncovered.
Branching program resources and the new measures are compared extensively. The
new variants are developed in part in the hope of tackling read-k branching
programs for the tree evaluation problem studied in Cook et al. Other
computation problems are studied as well. In particular, a common view of a
function studied by Gal and a function studied by Bollig and Wegener leads to
the general combinatorics of blocking sets. Technical combinatorial results of
independent interest are obtained. New leads towards further progress are
discussed. An exponential lower bound for non-deterministic read-k branching
programs for the GEN function is also derived, independently from the new
measures.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yaqiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+McKenzie_P/0/1/0/all/0/1">Pierre McKenzie</a></p><p>A model of computation for which reasonable yet still incomplete lower bounds
are known is the read-once branching program. Here variants of complexity
measures successful in the study of read-once branching programs are defined
and studied. Some new or simpler proofs of known bounds are uncovered.
Branching program resources and the new measures are compared extensively. The
new variants are developed in part in the hope of tackling read-k branching
programs for the tree evaluation problem studied in Cook et al. Other
computation problems are studied as well. In particular, a common view of a
function studied by Gal and a function studied by Bollig and Wegener leads to
the general combinatorics of blocking sets. Technical combinatorial results of
independent interest are obtained. New leads towards further progress are
discussed. An exponential lower bound for non-deterministic read-k branching
programs for the GEN function is also derived, independently from the new
measures.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11813'>Making $\textsf{IP}=\textsf{PSPACE}$ Practical: Efficient Interactive Protocols for BDD Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eszter Couillard, Philipp Czerner, Javier Esparza, Rupak Majumdar</p><p>We show that interactive protocols between a prover and a verifier, a
well-known tool of complexity theory, can be used in practice to certify the
correctness of automated reasoning tools.
</p>
<p>Theoretically, interactive protocols exist for all $\textsf{PSPACE}$
problems. The verifier of a protocol checks the prover's answer to a problem
instance in polynomial time, with polynomially many bits of communication, and
with exponentially small probability of error. (The prover may need exponential
time.) Existing interactive protocols are not used in practice because their
provers use naive algorithms, inefficient even for small instances, that are
incompatible with practical implementations of automated reasoning.
</p>
<p>We bridge the gap between theory and practice by means of a novel interactive
protocol whose prover uses BDDs. We consider the problem of counting the number
of assignments to a QBF instance ($\#\textrm{CP}$), which has a natural
BDD-based algorithm. We give an interactive protocol for $\#\textrm{CP}$ whose
prover is implemented on top of an extended BDD library. The prover has only a
linear overhead in computation time over the natural algorithm.
</p>
<p>We have implemented our protocol in $\textsf{blic}$, a certifying tool for
$\#\textrm{CP}$. Experiments on standard QBF benchmarks show that \blic\ is
competitive with state-of-the-art QBF-solvers. The run time of the verifier is
negligible. While loss of absolute certainty can be concerning, the error
probability in our experiments is at most $10^{-10}$ and reduces to $10^{-10k}$
by repeating the verification $k$ times.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Couillard_E/0/1/0/all/0/1">Eszter Couillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Czerner_P/0/1/0/all/0/1">Philipp Czerner</a>, <a href="http://arxiv.org/find/cs/1/au:+Esparza_J/0/1/0/all/0/1">Javier Esparza</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumdar_R/0/1/0/all/0/1">Rupak Majumdar</a></p><p>We show that interactive protocols between a prover and a verifier, a
well-known tool of complexity theory, can be used in practice to certify the
correctness of automated reasoning tools.
</p>
<p>Theoretically, interactive protocols exist for all $\textsf{PSPACE}$
problems. The verifier of a protocol checks the prover's answer to a problem
instance in polynomial time, with polynomially many bits of communication, and
with exponentially small probability of error. (The prover may need exponential
time.) Existing interactive protocols are not used in practice because their
provers use naive algorithms, inefficient even for small instances, that are
incompatible with practical implementations of automated reasoning.
</p>
<p>We bridge the gap between theory and practice by means of a novel interactive
protocol whose prover uses BDDs. We consider the problem of counting the number
of assignments to a QBF instance ($\#\textrm{CP}$), which has a natural
BDD-based algorithm. We give an interactive protocol for $\#\textrm{CP}$ whose
prover is implemented on top of an extended BDD library. The prover has only a
linear overhead in computation time over the natural algorithm.
</p>
<p>We have implemented our protocol in $\textsf{blic}$, a certifying tool for
$\#\textrm{CP}$. Experiments on standard QBF benchmarks show that \blic\ is
competitive with state-of-the-art QBF-solvers. The run time of the verifier is
negligible. While loss of absolute certainty can be concerning, the error
probability in our experiments is at most $10^{-10}$ and reduces to $10^{-10k}$
by repeating the verification $k$ times.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11833'>Complexity of Neural Network Training and ETR: Extensions with Effectively Continuous Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Teemu Hankala, Miika Hannula, Juha Kontinen, Jonni Virtema</p><p>We study the complexity of the problem of training neural networks defined
via various activation functions. The training problem is known to be
existsR-complete with respect to linear activation functions and the ReLU
activation function. We consider the complexity of the problem with respect to
the sigmoid activation function and other effectively continuous functions. We
show that these training problems are polynomial-time many-one bireducible to
the existential theory of the reals extended with the corresponding activation
functions. In particular, we establish that the sigmoid activation function
leads to the existential theory of the reals with the exponential function. It
is thus open, and equivalent with the decidability of the existential theory of
the reals with the exponential function, whether training neural networks using
the sigmoid activation function is algorithmically solvable. In contrast, we
obtain that the training problem is undecidable if sinusoidal activation
functions are considered. Finally, we obtain general upper bounds for the
complexity of the training problem in the form of low levels of the
arithmetical hierarchy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hankala_T/0/1/0/all/0/1">Teemu Hankala</a>, <a href="http://arxiv.org/find/cs/1/au:+Hannula_M/0/1/0/all/0/1">Miika Hannula</a>, <a href="http://arxiv.org/find/cs/1/au:+Kontinen_J/0/1/0/all/0/1">Juha Kontinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Virtema_J/0/1/0/all/0/1">Jonni Virtema</a></p><p>We study the complexity of the problem of training neural networks defined
via various activation functions. The training problem is known to be
existsR-complete with respect to linear activation functions and the ReLU
activation function. We consider the complexity of the problem with respect to
the sigmoid activation function and other effectively continuous functions. We
show that these training problems are polynomial-time many-one bireducible to
the existential theory of the reals extended with the corresponding activation
functions. In particular, we establish that the sigmoid activation function
leads to the existential theory of the reals with the exponential function. It
is thus open, and equivalent with the decidability of the existential theory of
the reals with the exponential function, whether training neural networks using
the sigmoid activation function is algorithmically solvable. In contrast, we
obtain that the training problem is undecidable if sinusoidal activation
functions are considered. Finally, we obtain general upper bounds for the
complexity of the training problem in the form of low levels of the
arithmetical hierarchy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11312'>Engineering an algorithm for constructing low-stretch geometric graphs with near-greedy average-degrees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: FNU Shariful, Justin Weathers, Anirban Ghosh, Giri Narasimhan</p><p>We design and engineer Fast-Sparse-Spanner, a simple and practical (fast and
memory-efficient) algorithm for constructing sparse low stretch-factor
geometric graphs on large pointsets in the plane. To our knowledge, this is the
first practical algorithm to construct fast low stretch-factor graphs on large
pointsets with average-degrees (hence, the number of edges) competitive with
that of greedy-spanners, the sparsest known class of Euclidean geometric
spanners.
</p>
<p>To evaluate our implementation in terms of computation speed, memory usage,
and quality of output, we performed extensive experiments with synthetic and
real-world pointsets, and by comparing it to our closest competitor Bucketing,
the fastest known greedy-spanner algorithm for pointsets in the plane, devised
by Alewijnse et al. (Algorithmica, 2017). We always found that
Fast-Sparse-Spanner generated near-greedy t-spanners while being fast and
memory-efficient. Our experiment with constructing a 1.1-spanner on a large
synthetic pointset with 128K points uniformly distributed within a square shows
more than a 41-fold speedup with roughly a third of the memory usage of that of
Bucketing, but with only a 3% increase in the average-degree of the resulting
graph. In terms of diameter, the graphs generated by Fast-Sparse-Spanner beat
greedy-spanners in most cases (have substantially lower diameter) while
maintaining near-greedy average-degree.
</p>
<p>As a byproduct of our research, we design and engineer Fast-Stretch-Factor, a
practical parallelizable algorithm that can measure the stretch-factor of any
graph generated by Fast-Sparse-Spanner. Our experiments show that it is much
faster than the naive Dijkstra-based stretch-factor measurement algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Shariful_F/0/1/0/all/0/1">FNU Shariful</a>, <a href="http://arxiv.org/find/cs/1/au:+Weathers_J/0/1/0/all/0/1">Justin Weathers</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Anirban Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_G/0/1/0/all/0/1">Giri Narasimhan</a></p><p>We design and engineer Fast-Sparse-Spanner, a simple and practical (fast and
memory-efficient) algorithm for constructing sparse low stretch-factor
geometric graphs on large pointsets in the plane. To our knowledge, this is the
first practical algorithm to construct fast low stretch-factor graphs on large
pointsets with average-degrees (hence, the number of edges) competitive with
that of greedy-spanners, the sparsest known class of Euclidean geometric
spanners.
</p>
<p>To evaluate our implementation in terms of computation speed, memory usage,
and quality of output, we performed extensive experiments with synthetic and
real-world pointsets, and by comparing it to our closest competitor Bucketing,
the fastest known greedy-spanner algorithm for pointsets in the plane, devised
by Alewijnse et al. (Algorithmica, 2017). We always found that
Fast-Sparse-Spanner generated near-greedy t-spanners while being fast and
memory-efficient. Our experiment with constructing a 1.1-spanner on a large
synthetic pointset with 128K points uniformly distributed within a square shows
more than a 41-fold speedup with roughly a third of the memory usage of that of
Bucketing, but with only a 3% increase in the average-degree of the resulting
graph. In terms of diameter, the graphs generated by Fast-Sparse-Spanner beat
greedy-spanners in most cases (have substantially lower diameter) while
maintaining near-greedy average-degree.
</p>
<p>As a byproduct of our research, we design and engineer Fast-Stretch-Factor, a
practical parallelizable algorithm that can measure the stretch-factor of any
graph generated by Fast-Sparse-Spanner. Our experiments show that it is much
faster than the naive Dijkstra-based stretch-factor measurement algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11552'>Advancing Front Mapping</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marco Livesu</p><p>We present Advancing Front Mapping (AFM), a provably robust algorithm for the
computation of surface mappings to simple base domains. Given an input mesh and
a convex or star-shaped target domain, AFM installs a (possibly refined)
version of the input connectivity into the target shape, generating a
piece-wise linear mapping between them. The algorithm is inspired by the
advancing front meshing paradigm, which is revisited to operate on two
embeddings at once, thus becoming a tool for compatible mesh generation. AFM
extends the capabilities of existing robust approaches, such as Tutte or
Progressive Embedding, by providing the same theoretical guarantees of
injectivity and at the same time introducing two key advantages: support for a
broader set of target domains (star-shaped polygons) and local mesh refinement,
which is used to automatically open the space of solutions in case a valid
mapping to the target domain does not exist. AFM relies solely on two
topological operators (triangle split and flip) and on the computation of
segment intersections, thus permitting to compute provably injective mappings
without solving any numerical problem. This makes the algorithm predictable and
easy to implement, debug and deploy. We validated the capabilities of AFM by
testing it on 36K input cases, showing that its theoretical guarantees nicely
transition to a robust and practical implementation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Livesu_M/0/1/0/all/0/1">Marco Livesu</a></p><p>We present Advancing Front Mapping (AFM), a provably robust algorithm for the
computation of surface mappings to simple base domains. Given an input mesh and
a convex or star-shaped target domain, AFM installs a (possibly refined)
version of the input connectivity into the target shape, generating a
piece-wise linear mapping between them. The algorithm is inspired by the
advancing front meshing paradigm, which is revisited to operate on two
embeddings at once, thus becoming a tool for compatible mesh generation. AFM
extends the capabilities of existing robust approaches, such as Tutte or
Progressive Embedding, by providing the same theoretical guarantees of
injectivity and at the same time introducing two key advantages: support for a
broader set of target domains (star-shaped polygons) and local mesh refinement,
which is used to automatically open the space of solutions in case a valid
mapping to the target domain does not exist. AFM relies solely on two
topological operators (triangle split and flip) and on the computation of
segment intersections, thus permitting to compute provably injective mappings
without solving any numerical problem. This makes the algorithm predictable and
easy to implement, debug and deploy. We validated the capabilities of AFM by
testing it on 36K input cases, showing that its theoretical guarantees nicely
transition to a robust and practical implementation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11286'>Improved and Partially-Tight Lower Bounds for Message-Passing Implementations of Multiplicity Queues</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anh Tran, Edward Talmage</p><p>A multiplicity queue is a concurrently-defined data type which relaxes the
conditions of a linearizable FIFO queue to allow concurrent Dequeue instances
to return the same value. It would seem that this should allow faster
implementations, as processes should not need to wait as long to learn about
concurrent operations at remote processes and previous work has shown that
multiplicity queues are computationally less complex than the unrelaxed
version. Intriguingly, recent work has shown that there is, in fact, not much
speedup possible versus an unrelaxed queue implementation. Seeking to
understand this difference between intuition and real behavior, we extend that
work, increasing the lower bound for uniform algorithms. Further, we outline a
path forward toward building proofs for even higher lower bounds, allowing us
to hypothesize that the worst-case time to Dequeue approaches maximum message
delay, which is similar to the time required for an unrelaxed Dequeue. We also
give an upper bound for a special case to show that our bounds are tight at
that point. To achieve our lower bounds, we use extended shifting arguments,
which have been rarely used but allow larger lower bounds than traditional
shifting arguments. We use these in series of inductive indistinguishability
proofs which allow us to extend our proofs beyond the usual limitations of
shifting arguments. This proof structure is an interesting contribution
independently of the main result, as developing new lower bound proof
techniques may have many uses in future work.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tran_A/0/1/0/all/0/1">Anh Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Talmage_E/0/1/0/all/0/1">Edward Talmage</a></p><p>A multiplicity queue is a concurrently-defined data type which relaxes the
conditions of a linearizable FIFO queue to allow concurrent Dequeue instances
to return the same value. It would seem that this should allow faster
implementations, as processes should not need to wait as long to learn about
concurrent operations at remote processes and previous work has shown that
multiplicity queues are computationally less complex than the unrelaxed
version. Intriguingly, recent work has shown that there is, in fact, not much
speedup possible versus an unrelaxed queue implementation. Seeking to
understand this difference between intuition and real behavior, we extend that
work, increasing the lower bound for uniform algorithms. Further, we outline a
path forward toward building proofs for even higher lower bounds, allowing us
to hypothesize that the worst-case time to Dequeue approaches maximum message
delay, which is similar to the time required for an unrelaxed Dequeue. We also
give an upper bound for a special case to show that our bounds are tight at
that point. To achieve our lower bounds, we use extended shifting arguments,
which have been rarely used but allow larger lower bounds than traditional
shifting arguments. We use these in series of inductive indistinguishability
proofs which allow us to extend our proofs beyond the usual limitations of
shifting arguments. This proof structure is an interesting contribution
independently of the main result, as developing new lower bound proof
techniques may have many uses in future work.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11352'>Efficient quantum linear solver algorithm with detailed running costs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David Jennings, Matteo Lostaglio, Sam Pallister, Andrew T Sornborger, Yi&#x11f;it Suba&#x15f;&#x131;</p><p>As we progress towards physical implementation of quantum algorithms it is
vital to determine the explicit resource costs needed to run them. Solving
linear systems of equations is a fundamental problem with a wide variety of
applications across many fields of science, and there is increasing effort to
develop quantum linear solver algorithms. Here we introduce a quantum linear
solver algorithm combining ideas from adiabatic quantum computing with
filtering techniques based on quantum signal processing. We give a closed
formula for the non-asymptotic query complexity $Q$ -- the exact number of
calls to a block-encoding of the linear system matrix -- as a function of
condition number $\kappa$, error tolerance $\epsilon$ and block-encoding
scaling factor $\alpha$. Our protocol reduces the cost of quantum linear
solvers over state-of-the-art close to an order of magnitude for early
implementations. The asymptotic scaling is $O(\kappa \log(\kappa/\epsilon))$,
slightly looser than the $O(\kappa \log(1/\epsilon))$ scaling of the
asymptotically optimal algorithm of Costa et al. However, our algorithm
outperforms the latter for all condition numbers up to $\kappa \approx
10^{32}$, at which point $Q$ is comparably large, and both algorithms are
anyway practically unfeasible. The present optimized analysis is both
problem-agnostic and architecture-agnostic, and hence can be deployed in any
quantum algorithm that uses linear solvers as a subroutine.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Jennings_D/0/1/0/all/0/1">David Jennings</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Lostaglio_M/0/1/0/all/0/1">Matteo Lostaglio</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pallister_S/0/1/0/all/0/1">Sam Pallister</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sornborger_A/0/1/0/all/0/1">Andrew T Sornborger</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Subasi_Y/0/1/0/all/0/1">Yi&#x11f;it Suba&#x15f;&#x131;</a></p><p>As we progress towards physical implementation of quantum algorithms it is
vital to determine the explicit resource costs needed to run them. Solving
linear systems of equations is a fundamental problem with a wide variety of
applications across many fields of science, and there is increasing effort to
develop quantum linear solver algorithms. Here we introduce a quantum linear
solver algorithm combining ideas from adiabatic quantum computing with
filtering techniques based on quantum signal processing. We give a closed
formula for the non-asymptotic query complexity $Q$ -- the exact number of
calls to a block-encoding of the linear system matrix -- as a function of
condition number $\kappa$, error tolerance $\epsilon$ and block-encoding
scaling factor $\alpha$. Our protocol reduces the cost of quantum linear
solvers over state-of-the-art close to an order of magnitude for early
implementations. The asymptotic scaling is $O(\kappa \log(\kappa/\epsilon))$,
slightly looser than the $O(\kappa \log(1/\epsilon))$ scaling of the
asymptotically optimal algorithm of Costa et al. However, our algorithm
outperforms the latter for all condition numbers up to $\kappa \approx
10^{32}$, at which point $Q$ is comparably large, and both algorithms are
anyway practically unfeasible. The present optimized analysis is both
problem-agnostic and architecture-agnostic, and hence can be deployed in any
quantum algorithm that uses linear solvers as a subroutine.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11580'>Approximate Distance Sensitivity Oracles in Subquadratic Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davide Bil&#xf2;, Shiri Chechik, Keerti Choudhary, Sarel Cohen, Tobias Friedrich, Simon Krogmann, Martin Schirneck</p><p>An $f$-edge fault-tolerant distance sensitive oracle ($f$-DSO) with stretch
$\sigma \ge 1$ is a data structure that preprocesses a given undirected,
unweighted graph $G$ with $n$ vertices and $m$ edges, and a positive integer
$f$. When queried with a pair of vertices $s, t$ and a set $F$ of at most $f$
edges, it returns a $\sigma$-approximation of the $s$-$t$-distance in $G-F$. We
study $f$-DSOs that take subquadratic space. Thorup and Zwick [JACM 2015]
showed that this is only possible for $\sigma \ge 3$. We present, for any
constant $f \ge 1$ and $\alpha \in (0, \frac{1}{2})$, and any $\varepsilon &gt;
0$, an $f$-DSO with stretch $ 3 + \varepsilon$ that takes
$\widetilde{O}(n^{2-\frac{\alpha}{f+1}}/\varepsilon) \cdot O(\log
n/\varepsilon)^{f+1}$ space and has an $O(n^\alpha/\varepsilon^2)$ query time.
We also give an improved construction for graphs with diameter at most $D$. For
any constant $k$, we devise an $f$-DSO with stretch $2k-1$ that takes
$O(D^{f+o(1)} n^{1+1/k})$ space and has $\widetilde{O}(D^{o(1)})$ query time,
with a preprocessing time of $O(D^{f+o(1)} mn^{1/k})$. Chechik, Cohen, Fiat,
and Kaplan [SODA 2017] presented an $f$-DSO with stretch $1{+}\varepsilon$ and
preprocessing time $O_\varepsilon(n^{5+o(1)})$, albeit with a super-quadratic
space requirement. We show how to reduce their preprocessing time to
$O_{\varepsilon}(mn^{2+o(1)})$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bilo_D/0/1/0/all/0/1">Davide Bil&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_S/0/1/0/all/0/1">Shiri Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_K/0/1/0/all/0/1">Keerti Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Sarel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrich_T/0/1/0/all/0/1">Tobias Friedrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Krogmann_S/0/1/0/all/0/1">Simon Krogmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schirneck_M/0/1/0/all/0/1">Martin Schirneck</a></p><p>An $f$-edge fault-tolerant distance sensitive oracle ($f$-DSO) with stretch
$\sigma \ge 1$ is a data structure that preprocesses a given undirected,
unweighted graph $G$ with $n$ vertices and $m$ edges, and a positive integer
$f$. When queried with a pair of vertices $s, t$ and a set $F$ of at most $f$
edges, it returns a $\sigma$-approximation of the $s$-$t$-distance in $G-F$. We
study $f$-DSOs that take subquadratic space. Thorup and Zwick [JACM 2015]
showed that this is only possible for $\sigma \ge 3$. We present, for any
constant $f \ge 1$ and $\alpha \in (0, \frac{1}{2})$, and any $\varepsilon &gt;
0$, an $f$-DSO with stretch $ 3 + \varepsilon$ that takes
$\widetilde{O}(n^{2-\frac{\alpha}{f+1}}/\varepsilon) \cdot O(\log
n/\varepsilon)^{f+1}$ space and has an $O(n^\alpha/\varepsilon^2)$ query time.
We also give an improved construction for graphs with diameter at most $D$. For
any constant $k$, we devise an $f$-DSO with stretch $2k-1$ that takes
$O(D^{f+o(1)} n^{1+1/k})$ space and has $\widetilde{O}(D^{o(1)})$ query time,
with a preprocessing time of $O(D^{f+o(1)} mn^{1/k})$. Chechik, Cohen, Fiat,
and Kaplan [SODA 2017] presented an $f$-DSO with stretch $1{+}\varepsilon$ and
preprocessing time $O_\varepsilon(n^{5+o(1)})$, albeit with a super-quadratic
space requirement. We show how to reduce their preprocessing time to
$O_{\varepsilon}(mn^{2+o(1)})$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11639'>Distributed MIS with Low Energy and Time Complexities</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Ghaffari, Julian Portmann</p><p>We present randomized distributed algorithms for the maximal independent set
problem (MIS) that, while keeping the time complexity nearly matching the best
known, reduce the energy complexity substantially. These algorithms work in the
standard CONGEST model of distributed message passing with $O(\log n)$ bit
messages. The time complexity measures the number of rounds in the algorithm.
The energy complexity measures the number of rounds each node is awake; during
other rounds, the node sleeps and cannot perform any computation or
communications.
</p>
<p>Our first algorithm has an energy complexity of $O(\log\log n)$ and a time
complexity of $O(\log^2 n)$. Our second algorithm is faster but slightly less
energy-efficient: it achieves an energy complexity of $O(\log^2 \log n)$ and a
time complexity of $O(\log n \cdot \log\log n \cdot \log^* n)$. Thus, this
algorithm nearly matches the $O(\log n)$ time complexity of the
state-of-the-art MIS algorithms while significantly reducing their energy
complexity from $O(\log n)$ to $O(\log^2 \log n)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Portmann_J/0/1/0/all/0/1">Julian Portmann</a></p><p>We present randomized distributed algorithms for the maximal independent set
problem (MIS) that, while keeping the time complexity nearly matching the best
known, reduce the energy complexity substantially. These algorithms work in the
standard CONGEST model of distributed message passing with $O(\log n)$ bit
messages. The time complexity measures the number of rounds in the algorithm.
The energy complexity measures the number of rounds each node is awake; during
other rounds, the node sleeps and cannot perform any computation or
communications.
</p>
<p>Our first algorithm has an energy complexity of $O(\log\log n)$ and a time
complexity of $O(\log^2 n)$. Our second algorithm is faster but slightly less
energy-efficient: it achieves an energy complexity of $O(\log^2 \log n)$ and a
time complexity of $O(\log n \cdot \log\log n \cdot \log^* n)$. Thus, this
algorithm nearly matches the $O(\log n)$ time complexity of the
state-of-the-art MIS algorithms while significantly reducing their energy
complexity from $O(\log n)$ to $O(\log^2 \log n)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11644'>Deterministic Fault-Tolerant Distributed Computing in Linear Time and Communication</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bogdan S. Chlebus, Dariusz R. Kowalski, Jan Olkowski</p><p>We develop deterministic algorithms for the problems of consensus, gossiping
and checkpointing with nodes prone to failing. Distributed systems are modeled
as synchronous complete networks. Failures are represented either as crashes or
authenticated Byzantine faults. The algorithmic goal is to have both linear
running time and linear amount of communication for as large an upper bound $t$
on the number of faults as possible, with respect to the number of nodes~$n$.
For crash failures, these bounds of optimality are $t=\mathcal{O}(\frac{n}{\log
n})$ for consensus and $t=\mathcal{O}(\frac{n}{\log^2 n})$ for gossiping and
checkpointing, while the running time for each algorithm is $\Theta(t+\log n)$.
For the authenticated Byzantine model of failures, we show how to accomplish
both linear running time and communication for $t=\mathcal{O}(\sqrt{n})$. We
show how to implement the algorithms in the single-port model, in which a node
may choose only one other node to send/receive a message to/from in a round,
such as to preserve the range of running time and communication optimality. We
prove lower bounds to show the optimality of some performance bounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chlebus_B/0/1/0/all/0/1">Bogdan S. Chlebus</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowalski_D/0/1/0/all/0/1">Dariusz R. Kowalski</a>, <a href="http://arxiv.org/find/cs/1/au:+Olkowski_J/0/1/0/all/0/1">Jan Olkowski</a></p><p>We develop deterministic algorithms for the problems of consensus, gossiping
and checkpointing with nodes prone to failing. Distributed systems are modeled
as synchronous complete networks. Failures are represented either as crashes or
authenticated Byzantine faults. The algorithmic goal is to have both linear
running time and linear amount of communication for as large an upper bound $t$
on the number of faults as possible, with respect to the number of nodes~$n$.
For crash failures, these bounds of optimality are $t=\mathcal{O}(\frac{n}{\log
n})$ for consensus and $t=\mathcal{O}(\frac{n}{\log^2 n})$ for gossiping and
checkpointing, while the running time for each algorithm is $\Theta(t+\log n)$.
For the authenticated Byzantine model of failures, we show how to accomplish
both linear running time and communication for $t=\mathcal{O}(\sqrt{n})$. We
show how to implement the algorithms in the single-port model, in which a node
may choose only one other node to send/receive a message to/from in a round,
such as to preserve the range of running time and communication optimality. We
prove lower bounds to show the optimality of some performance bounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11765'>Tester-Learners for Halfspaces: Universal Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aravind Gollakota, Adam R. Klivans, Konstantinos Stavropoulos, Arsen Vasilyan</p><p>We give the first tester-learner for halfspaces that succeeds universally
over a wide class of structured distributions. Our universal tester-learner
runs in fully polynomial time and has the following guarantee: the learner
achieves error $O(\mathrm{opt}) + \epsilon$ on any labeled distribution that
the tester accepts, and moreover, the tester accepts whenever the marginal is
any distribution that satisfies a Poincar\'e inequality. In contrast to prior
work on testable learning, our tester is not tailored to any single target
distribution but rather succeeds for an entire target class of distributions.
The class of Poincar\'e distributions includes all strongly log-concave
distributions, and, assuming the Kannan--L\'{o}vasz--Simonovits (KLS)
conjecture, includes all log-concave distributions. In the special case where
the label noise is known to be Massart, our tester-learner achieves error
$\mathrm{opt} + \epsilon$ while accepting all log-concave distributions
unconditionally (without assuming KLS). Our tests rely on checking
hypercontractivity of the unknown distribution using a sum-of-squares (SOS)
program, and crucially make use of the fact that Poincar\'e distributions are
certifiably hypercontractive in the SOS framework.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gollakota_A/0/1/0/all/0/1">Aravind Gollakota</a>, <a href="http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1">Adam R. Klivans</a>, <a href="http://arxiv.org/find/cs/1/au:+Stavropoulos_K/0/1/0/all/0/1">Konstantinos Stavropoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasilyan_A/0/1/0/all/0/1">Arsen Vasilyan</a></p><p>We give the first tester-learner for halfspaces that succeeds universally
over a wide class of structured distributions. Our universal tester-learner
runs in fully polynomial time and has the following guarantee: the learner
achieves error $O(\mathrm{opt}) + \epsilon$ on any labeled distribution that
the tester accepts, and moreover, the tester accepts whenever the marginal is
any distribution that satisfies a Poincar\'e inequality. In contrast to prior
work on testable learning, our tester is not tailored to any single target
distribution but rather succeeds for an entire target class of distributions.
The class of Poincar\'e distributions includes all strongly log-concave
distributions, and, assuming the Kannan--L\'{o}vasz--Simonovits (KLS)
conjecture, includes all log-concave distributions. In the special case where
the label noise is known to be Massart, our tester-learner achieves error
$\mathrm{opt} + \epsilon$ while accepting all log-concave distributions
unconditionally (without assuming KLS). Our tests rely on checking
hypercontractivity of the unknown distribution using a sum-of-squares (SOS)
program, and crucially make use of the fact that Poincar\'e distributions are
certifiably hypercontractive in the SOS framework.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, May 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/05/logic-and-lack-of-logic-of-anti-vaxers.html'>Logic and lack of Logic of Anti Vaxers</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>I wrote the&nbsp; post below the dotted line a long time ago but never got around to posting it. Now that&nbsp;</p><p><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; WHO says COVID emergency is over.</p><p>(When I first saw I misread it as a question:&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Who says COVID emergency is over?&nbsp;</p><p>)&nbsp;</p><p>I decided to post it (with one update that has an ADDED LATER on it).&nbsp;</p><p>If you didn't know , WHO is World Health Organization. Actually, that is true whether or not you know it.</p><p>------------------------------------------------------------------------------------</p><p>Some of the reasons anti-vaxers give are better than others. Some are consistent, some are not.&nbsp;</p><p>We list some of them and invite the comments to list more. Our point is- which ones have something interesting to say?&nbsp;</p><p><br>I am PRO VAX but I often seek out intelligent opposing views on any of my opinions. Did I find any here? I leave that as an exercise for the reader.&nbsp;</p><p><br></p><p>Reasons anti-vaxxers give or could give.&nbsp;</p><p>a)&nbsp;FREEDOM!&nbsp;That's not quite a reason. I am reminded of asking a neighbor why he flies a confederate flag and he said</p><p>FREEDOM!</p><p>I was hoping he would say either</p><p>To honor my great grandfather who died for the south in the civil war.</p><p>or</p><p>Because I don't like black people.</p><p>or</p><p>To honor those many people, black and white, who died in the civil war fighting for the south.&nbsp;</p><p>or</p><p>SOMETHING with content to it.&nbsp;<br><br></p><p>Any of those answered would tell me something could be discussed. Just the word FREEDOM does not.&nbsp;</p><p>b)&nbsp;Bill Gates put microchips in the vaccine so he can keep track of where you are. Why? Bill Gates and Mark Zuckerberg can ALREADY keep track of where you are. I do wonder if this is a common anti-vax viewpoint or if its VERY RARE and the media plays it up to make anti-vaxers look stupid. Same with the notion that the vaccine makes you magnetic (that sounds cool!)</p><p>c) I&nbsp;want to wait and see its effects since it was rushed out. That might have made sense&nbsp; X months ago, but by now its very well established.</p><p>d)&nbsp;I haven't gotten around to it yet.&nbsp;These are a very good target for the mandates or at least to be talked into doing it. It may be more fun to talk about the radical anti-vaxers; however, if the&nbsp;haven't gotten&nbsp;around to it&nbsp;group all got vaccinated we would be closer to herd immunity.</p><p>e) I've got COVID so I am immune. This is true for Y months (I am not sure what Y is); however, the person I know who told me this had COVID about 3 years ago.&nbsp;&nbsp;But at least its an attempt at an argument.&nbsp;</p><p>f)&nbsp;The medical community has been bad to (i) me, (ii) my people, (iii) some other people that I care&nbsp;about hence I do not trust them.&nbsp;The premise is actually true, so this is an attempt at an intelligent argument.&nbsp;</p><p>g)&nbsp;Big Pharma&nbsp;is making a mint on this and ripping us off.&nbsp;This is a view of, not the extreme left but the fringe left. Robert Kennedy is a big voice here, see&nbsp;here. On a right-wing relatives' urging I listened to an hour-long interview with him. Mostly a rambling incoherent argument. Much of it was anti-business which got no pushback from the usually-pro-business republican's. Are there any mainstream democrats who are anti-vax? I do not think so. Also, is it true that Big Pharma is is making a mint? Ripping us off? Ripping someone off? This could be an interesting question if asked more coherently. But its not a good reason to be anti-vax.&nbsp;</p><p>h) Trump said it was a hoax to get him out of office. Taking a vaccine now would be to admit its not a hoax. Such people should take Karl Popper's view of science: Conjecture that, as Ted Cruz said, if Biden wins then COVID will go away since it was a hoax made up to get Biden to win. If Biden wins and COVID does not go away then you must reject your conjecture. (ADDED LATER: Odd point- Trump has sometimes said, though not lately, that people should get the Vax that HE invented. If we called it a Trumpzine then would people take it? As of now Trump and DeathSantos are trying to anti-vax each other.)&nbsp;</p><p>i) The first few days after you take it it hurts and you feel tired or get chills or other reactions. This is actually true, though one has to balance that against getting COVID.</p><p>j) The Ford Administration really messed up on the Swine Flu so why trust the government now? This is true- The Ford Admin DID mess up. Oddly enough, I have never (or perhaps rarely) heard this as a reason. This puzzles me- Why claim Bill Gates microchip stuff (which is absurd) or Vax causes autism (debunked)&nbsp; and&nbsp; NOT use arguments are are more reasonable?</p><p>k) Vaccines cause autism. That study was debunked a long time ago, but it still lives on.</p><p>l) Kamala Harris said she was hesitant since it was rushed.&nbsp; I've only heard this one as Republicans&nbsp; try to blame her for Vaccine Hesitancy. The problem with that argument is that you are claiming that the anti-vaxers, who are mostly republicans, are listening to Kamala Harris for advice.</p><p>l)&nbsp;If many people get Vaxed and COVID goes away then Biden will look good, and we can't have that.</p><p>m) COVID was invented by the Chinese to cripple us. Uh- even if true (which it is not, though the leaked lab hypothesis might be) that's a reason to TAKE it to thwart their plans. For that matter, Trump could have been Trumpian and PRO-MASK and&nbsp; PRO-VAX by blaming the Chinese and George Soros and the Deep State and Biden and Obama and of course Hillary,&nbsp; but using this to say WEAR THE MASK! TAKE THE VAX! to DEFEAT these ENEMIES who want to destroy America. Would that have worked to slow the spread of COVID? If so then would he have won re-election?&nbsp;</p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I wrote the&nbsp; post below the dotted line a long time ago but never got around to posting it. Now that&nbsp;</p><p><br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; WHO says COVID emergency is over.</p><p>(When I first saw I misread it as a question:&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Who says COVID emergency is over?&nbsp;</p><p>)&nbsp;</p><p>I decided to post it (with one update that has an ADDED LATER on it).&nbsp;</p><p>If you didn't know , WHO is World Health Organization. Actually, that is true whether or not you know it.</p><p>------------------------------------------------------------------------------------</p><p>Some of the reasons anti-vaxers give are better than others. Some are consistent, some are not.&nbsp;</p><p>We list some of them and invite the comments to list more. Our point is- which ones have something interesting to say?&nbsp;</p><p><br />I am PRO VAX but I often seek out intelligent opposing views on any of my opinions. Did I find any here? I leave that as an exercise for the reader.&nbsp;</p><p><br /></p><p>Reasons anti-vaxxers give or could give.&nbsp;</p><p>a)&nbsp;<i>FREEDOM!&nbsp;</i>That's not quite a reason. I am reminded of asking a neighbor why he flies a confederate flag and he said</p><p>FREEDOM!</p><p>I was hoping he would say either</p><p>To honor my great grandfather who died for the south in the civil war.</p><p>or</p><p>Because I don't like black people.</p><p>or</p><p>To honor those many people, black and white, who died in the civil war fighting for the south.&nbsp;</p><p>or</p><p>SOMETHING with content to it.&nbsp;<br /><br /></p><p>Any of those answered would tell me something could be discussed. Just the word FREEDOM does not.&nbsp;</p><p>b)&nbsp;<i>Bill Gates put microchips in the vaccine so he can keep track of where you are</i>. Why? Bill Gates and Mark Zuckerberg can ALREADY keep track of where you are. I do wonder if this is a common anti-vax viewpoint or if its VERY RARE and the media plays it up to make anti-vaxers look stupid. Same with the notion that the vaccine makes you magnetic (that sounds cool!)</p><p>c) I<i>&nbsp;want to wait and see its effects since it was rushed out</i>. That might have made sense&nbsp; X months ago, but by now its very well established.</p><p>d)&nbsp;<i>I haven't gotten around to it yet.</i>&nbsp;These are a very good target for the mandates or at least to be talked into doing it. It may be more fun to talk about the radical anti-vaxers; however, if the&nbsp;<i>haven't gotten</i>&nbsp;<i>around to it&nbsp;</i>group all got vaccinated we would be closer to herd immunity.</p><p>e) I<i>'ve got COVID so I am immune. </i>This is true for Y months (I am not sure what Y is); however, the person I know who told me this had COVID about 3 years ago.&nbsp;&nbsp;But at least its an attempt at an argument.&nbsp;</p><p>f)&nbsp;<i>The medical community has been bad to (i) me, (ii) my people, (iii) some other people that I care</i>&nbsp;<i>about hence I do not trust them.&nbsp;</i>The premise is actually true, so this is an attempt at an intelligent argument.&nbsp;</p><p>g)&nbsp;<i>Big Pharma&nbsp;is making a mint on this and ripping us off.</i>&nbsp;This is a view of, not the extreme left but the fringe left. Robert Kennedy is a big voice here, see&nbsp;<a href="https://www.mcgill.ca/oss/article/covid-19-health-pseudoscience/anti-vaccine-propaganda-robert-f-kennedy-jr">here</a>. On a right-wing relatives' urging I listened to an hour-long interview with him. Mostly a rambling incoherent argument. Much of it was anti-business which got no pushback from the usually-pro-business republican's. Are there any mainstream democrats who are anti-vax? I do not think so. Also, is it true that Big Pharma is is making a mint? Ripping us off? Ripping someone off? This could be an interesting question if asked more coherently. But its not a good reason to be anti-vax.&nbsp;</p><p>h) Trump said it was a hoax to get him out of office. Taking a vaccine now would be to admit its not a hoax. Such people should take Karl Popper's view of science: Conjecture that, as Ted Cruz said, if Biden wins then COVID will go away since it was a hoax made up to get Biden to win. If Biden wins and COVID does not go away then you must reject your conjecture. (ADDED LATER: Odd point- Trump has sometimes said, though not lately, that people should get the Vax that HE invented. If we called it a Trumpzine then would people take it? As of now Trump and DeathSantos are trying to anti-vax each other.)&nbsp;</p><p>i) The first few days after you take it it hurts and you feel tired or get chills or other reactions. This is actually true, though one has to balance that against getting COVID.</p><p>j) The Ford Administration really messed up on the Swine Flu so why trust the government now? This is true- The Ford Admin DID mess up. Oddly enough, I have never (or perhaps rarely) heard this as a reason. This puzzles me- Why claim Bill Gates microchip stuff (which is absurd) or Vax causes autism (debunked)&nbsp; and&nbsp; NOT use arguments are are more reasonable?</p><p>k) Vaccines cause autism. That study was debunked a long time ago, but it still lives on.</p><p>l) Kamala Harris said she was hesitant since it was rushed.&nbsp; I've only heard this one as Republicans&nbsp; try to blame her for Vaccine Hesitancy. The problem with that argument is that you are claiming that the anti-vaxers, who are mostly republicans, are listening to Kamala Harris for advice.</p><p>l)&nbsp;If many people get Vaxed and COVID goes away then Biden will look good, and we can't have that.</p><p>m) COVID was invented by the Chinese to cripple us. Uh- even if true (which it is not, though the leaked lab hypothesis might be) that's a reason to TAKE it to thwart their plans. For that matter, Trump could have been Trumpian and PRO-MASK and&nbsp; PRO-VAX by blaming the Chinese and George Soros and the Deep State and Biden and Obama and of course Hillary,&nbsp; but using this to say WEAR THE MASK! TAKE THE VAX! to DEFEAT these ENEMIES who want to destroy America. Would that have worked to slow the spread of COVID? If so then would he have won re-election?&nbsp;</p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-21T12:25:00Z">Sunday, May 21 2023, 12:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/075'>TR23-075 |  Border Complexity of Symbolic Determinant under Rank One Restriction | 

	Abhranil Chatterjee, 

	Sumanta Ghosh, 

	Rohit Gurjar, 

	Roshan  Raj</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          VBP is the class of polynomial families that can be computed by the determinant of a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where the size of each $A_i$ is polynomial in the number of variables (equivalently, computable by polynomial-sized algebraic branching programs (ABP)). A major open problem in geometric complexity theory (GCT) is to determine whether VBP is closed under approximation. The power of approximation is well understood for some restricted models of computation, e.g., the class of depth-two circuits, read-once oblivious ABPs (ROABP), monotone ABPs, depth-three circuits of bounded top fan-in, and width-two ABPs. The former three classes are known to be closed under approximation [Bl&quot;{a}ser, Ikenmeyer, Mahajan, Pandey, and Saurabh (2020)], whereas the approximative closure of the last one captures the whole class of polynomial families computable by polynomial-sized formulas [Bringmann, Ikenmeyer, and Zuiddam (2017)].

In this work, we consider the subclass of VBP computed by the determinant of a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where for each $1\leq i \leq n$, $A_i$ is of rank one. It has been studied extensively [Edmonds(1968), Edmonds(1979)] and efficient identity testing algorithms are known [Lov&quot;{a}sz (1989), Gurjar and Thierauf (2020)]. We show that this class is closed under approximation. In the language of algebraic geometry,
we show that the set obtained by taking coordinatewise products of pairs of points from (the Pl\&quot;{u}cker embedding of) a Grassmannian variety is closed.
        
        </div>

        <div class='tr-article-summary'>
        
          
          VBP is the class of polynomial families that can be computed by the determinant of a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where the size of each $A_i$ is polynomial in the number of variables (equivalently, computable by polynomial-sized algebraic branching programs (ABP)). A major open problem in geometric complexity theory (GCT) is to determine whether VBP is closed under approximation. The power of approximation is well understood for some restricted models of computation, e.g., the class of depth-two circuits, read-once oblivious ABPs (ROABP), monotone ABPs, depth-three circuits of bounded top fan-in, and width-two ABPs. The former three classes are known to be closed under approximation [Bl&quot;{a}ser, Ikenmeyer, Mahajan, Pandey, and Saurabh (2020)], whereas the approximative closure of the last one captures the whole class of polynomial families computable by polynomial-sized formulas [Bringmann, Ikenmeyer, and Zuiddam (2017)].

In this work, we consider the subclass of VBP computed by the determinant of a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where for each $1\leq i \leq n$, $A_i$ is of rank one. It has been studied extensively [Edmonds(1968), Edmonds(1979)] and efficient identity testing algorithms are known [Lov&quot;{a}sz (1989), Gurjar and Thierauf (2020)]. We show that this class is closed under approximation. In the language of algebraic geometry,
we show that the set obtained by taking coordinatewise products of pairs of points from (the Pl\&quot;{u}cker embedding of) a Grassmannian variety is closed.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-21T06:59:02Z">Sunday, May 21 2023, 06:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/074'>TR23-074 |  Radical Sylvester-Gallai Theorem for Tuples of Quadratics | 

	Abhibhav Garg, 

	Rafael Mendes de Oliveira, 

	Shir Peleg, 

	Akash Sengupta</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We prove a higher codimensional radical Sylvester-Gallai type theorem for quadratic polynomials, simultaneously generalizing [Han65, Shp20]. Hansen&#39;s theorem is a high-dimensional version of the classical Sylvester-Gallai theorem in which the incidence condition is given by high-dimensional flats instead of lines. We generalize Hansen&#39;s theorem to the setting of quadratic forms in a polynomial ring, where the incidence condition is given by radical membership in a high-codimensional ideal. Our main theorem is also a generalization of the quadratic Sylvester--Gallai Theorem of [Shp20].

Our work is the first to prove a radical Sylvester--Gallai type theorem for arbitrary  codimension $k\geq 2$, whereas previous works [Shp20,PS20,PS21,OS22] considered the case of codimension $2$ ideals. Our techniques combine algebraic geometric and combinatorial arguments. A key ingredient is a structural result for ideals generated by a constant number of quadratics, showing that such ideals must be radical whenever the quadratic forms are far apart. Using the wide algebras defined in [OS22], combined with results about integral ring extensions and dimension theory, we develop new techniques for studying such ideals generated by quadratic forms. One advantage of our approach is that it does not need the finer classification theorems for codimension $2$ complete intersection of quadratics proved in [Shp20, GOS22].
        
        </div>

        <div class='tr-article-summary'>
        
          
          We prove a higher codimensional radical Sylvester-Gallai type theorem for quadratic polynomials, simultaneously generalizing [Han65, Shp20]. Hansen&#39;s theorem is a high-dimensional version of the classical Sylvester-Gallai theorem in which the incidence condition is given by high-dimensional flats instead of lines. We generalize Hansen&#39;s theorem to the setting of quadratic forms in a polynomial ring, where the incidence condition is given by radical membership in a high-codimensional ideal. Our main theorem is also a generalization of the quadratic Sylvester--Gallai Theorem of [Shp20].

Our work is the first to prove a radical Sylvester--Gallai type theorem for arbitrary  codimension $k\geq 2$, whereas previous works [Shp20,PS20,PS21,OS22] considered the case of codimension $2$ ideals. Our techniques combine algebraic geometric and combinatorial arguments. A key ingredient is a structural result for ideals generated by a constant number of quadratics, showing that such ideals must be radical whenever the quadratic forms are far apart. Using the wide algebras defined in [OS22], combined with results about integral ring extensions and dimension theory, we develop new techniques for studying such ideals generated by quadratic forms. One advantage of our approach is that it does not need the finer classification theorems for codimension $2$ complete intersection of quadratics proved in [Shp20, GOS22].
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-21T06:54:34Z">Sunday, May 21 2023, 06:54</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/073'>TR23-073 |  Reducing Tarski to Unique Tarski (in the Black-box Model) | 

	Xi Chen, 

	Yuhao Li, 

	Mihalis Yannakakis</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study the problem of finding a Tarski fixed point over the $k$-dimensional grid $[n]^k$. We give a black-box reduction from the Tarski problem to the same problem with an additional promise that the input function has a unique fixed point. It implies that the Tarski problem and the unique Tarski problem have exactly the same query complexity. Our reduction is based on a novel notion of partial-information functions which we use to fool algorithms for the unique Tarski problem as if they were working on a monotone function with a unique fixed point.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study the problem of finding a Tarski fixed point over the $k$-dimensional grid $[n]^k$. We give a black-box reduction from the Tarski problem to the same problem with an additional promise that the input function has a unique fixed point. It implies that the Tarski problem and the unique Tarski problem have exactly the same query complexity. Our reduction is based on a novel notion of partial-information functions which we use to fool algorithms for the unique Tarski problem as if they were working on a monotone function with a unique fixed point.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-21T02:59:43Z">Sunday, May 21 2023, 02:59</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, May 19
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/'>GPT as an âIntelligence Forklift.â</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          [See my&#160;post with Edelman on AI takeover and&#160;Aaronson on AI scenarios. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on Windows on Theory.] &#160;One challenge for considering the implications of âartificial intelligence,â especially of the âgeneralâ variety, is that we donât have a consensus definition of intelligence. The&#160;Oxford Companion &#8230; Continue reading GPT as an &#8220;Intelligence Forklift.&#8221;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><em>[See my&nbsp;</em><a href="https://www.lesswrong.com/posts/zB3ukZJqt3pQDw9jz/ai-will-change-the-world-but-won-t-take-it-over-by-playing-3"><em><u>post with Edelman on AI takeover</u></em></a><em> and&nbsp;</em><a href="https://scottaaronson.blog/?p=7266"><em><u>Aaronson on AI scenarios</u></em></a><em>. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on </em><a href="https://windowsontheory.org/"><em>Windows on Theory</em></a><em>.]</em></p>



<p>&nbsp;<br>One challenge for considering the implications of âartificial intelligence,â especially of the âgeneralâ variety, is that we donât have a consensus definition of intelligence. The&nbsp;<a href="https://www.amazon.com/Oxford-Companion-Mind-Companions/dp/0198662246"><u>Oxford Companion to the Mind</u></a> states that âthere seem to be almost as many definitions of intelligence as experts asked to define it.â&nbsp; Indeed,&nbsp; in a recent discussion,&nbsp;<a href="https://www.lepoint.fr/sciences-nature/yuval-harari-sapiens-versus-yann-le-cun-meta-on-artificial-intelligence-11-05-2023-2519782_1924.php#11"><u>Yann LeCun and Yuval Noah Harari</u></a> offered two different definitions. However, it seems many people agree that:</p>



<ol>
<li>Whatever intelligence is, more computational power or cognitive capacity (e.g., a more complex or larger neural network, a species with a larger brain)&nbsp; leads to more of it.&nbsp;</li>



<li>Whatever intelligence is, the more of it one has, the more one can impact one&#8217;s environment.&nbsp;</li>
</ol>



<p>1 and 2 together can already lead to growing concerns now that we are building artificial systems that every year are more powerful than the last.&nbsp;<a href="https://www.lesswrong.com/posts/3Jpchgy53D2gB5qdk/my-childhood-role-model"><u>Yudkowski</u></a> presents potential progress on intelligence with something like the following chart (taken from&nbsp;<a href="https://intelligenceexplosion.com/2011/plenty-of-room-above-us/"><u>Muehlhauser</u></a>):</p>



<figure class="wp-block-image"><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/cfee2d12a17cf70d8bfdc038070a679c423c7061ed67439f.png" alt="" /></figure>



<p><br>Given that recent progress on AI was achieved by scaling ever larger amounts of computation and data, we might expect a cartoon that looks more like the following:</p>



<p><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/abf19d90ec5756ee84d74f5a21312ef7a7eb1fb11c8029f4.png" style="width: 600px"></p>



<p><em>(Donât take this cartoon or numbers too seriously. It is obtained by superimposing a hypothetical 1000T param model on the figure fromÂ </em><a href="https://chomsky.info/20140826/"><em><u>Bolhuis, Tattersall, Chomsky and Berwick</u></em></a><em>. 100T connections in Homo sapiens brain is aÂ </em><a href="https://www.scientificamerican.com/article/100-trillion-connections/"><em><u>rough estimate</u></em></a><em>.Â  Axes implicitly assumeÂ </em><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8463089/"><em><u>synaptic density</u></em></a><em> scales with volume.)</em></p>



<p><br>Whether the first or the second cartoon is more accurate, the idea of constructing intelligence that surpasses ours to an increasing degree and on a growing number of dimensions is understandably unsettling to many people. (Especially given that none of the other species of the genus&nbsp;<em>Homo</em> in the chart above survived.)&nbsp; This post is&nbsp;<em>not</em> to say that we should not worry about this. Instead I suggest a different metaphor for how we could think of future powerful models.<br>&nbsp;</p>



<h2 class="wp-block-heading">Whose intelligence is it?</h2>



<p>In our own speciesâ evolution, as we have become more intelligent, we have become more able to act as&nbsp;<em>agents</em> that do not follow pre-ordained goals but rather choose our own. So we might imagine that there is some monotone âagency vs. intelligenceâ curve along the following:</p>



<figure class="wp-block-image"><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/8617e5cafd5f4c3a19ca6e894a8b921c6b503a7b39b313f0.png" alt="" /></figure>



<p>&nbsp;<em>(Once again, donât take the cartoon too seriously; whether it is a step function, sigmoid-like, or some other monotone curve can be debatable and also depends on what one&#8217;s definitions of âagencyâ and âintelligenceâ are.)</em></p>



<p><br>But perhaps intelligence does not have to go hand-in-hand with agency. Consider the property of&nbsp;<strong>physical strength</strong>. Like intelligence, this is a capability that an individual can use to shape their environment. I am (much) weaker than&nbsp;<a href="https://en.wikipedia.org/wiki/Olga_Liashchuk"><u>Olga Liashchuk</u></a>, who can lift a 300kg Yoke and walk 24 meters with it in under 20 seconds.&nbsp; However, if I were to drive a forklift, the combination of me and the forklift would be stronger than her. Thus, if we measure strength in functional terms (what we can&nbsp;<em>do</em> with it) instead of by artificial competitions, it makes sense to consider strength as a&nbsp;<strong>property of a system rather than an individual</strong>. Strength can be aggregated to combine several systems into a stronger one or split up to use different parts of the capacity for different tasks.</p>



<p><br>Is there an&nbsp;<strong>âintelligence forkliftâ</strong>? It is hard to imagine a system that is more intelligent than humans but lacks agency. More accurately, up until recently, it would have been hard to imagine such a system. However, with generative pretrained transformers (GPTs), we have systems that have the potential to be just that. Even though recent GPTs undergo some adaptation and fine-tuning, the vast majority of the computational resources invested into GPTs is used to make them solve the task of finding a continuation of a sequence given its prefix.&nbsp;</p>



<p><br>We can phrase many general problems as special cases of the task above. (Indeed, with multimodal models, such tasks include essentially any problem that can be asked and answered using any type of digital representation.) Hence as GPT-n becomes better at this task, it is arguably becoming arbitrarily intelligent. However, it is still not an agent but rather a generic problem-solver. In that sense,&nbsp;<strong>GPTs can best be modeled as intelligence forklifts</strong>.</p>



<figure class="wp-block-image is-resized"><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/9131b5cd330416a57ba14408cb461b4a2a3da0e89d8f224b.png" alt="" width="714" height="312" /></figure>



<p>By âintelligence forkliftâ I mean that such a model can augment an agent with arbitrary intelligence to complete the goals the agent seeks. The agent may be human, but it can also be an AI itself. For example, it might be obtained using fine-tuning, reinforcement learning, or prompt-engineering on GPT. (So, while GPT is not an agent, it can âplay one on TVâ if asked to do so in its prompt.) Therefore, the above does not mean that we should not be concerned about an artificial highly intelligent agent. However, if the vast majority of an agentâs intelligence is derived from the non-agentic âforkliftâ (which can be used by many other agents as well), then a&nbsp;<strong>multipolar scenario of many agents of competing objectives</strong> is more likely than a unipolar one of a single dominating actor. The multipolar scenario might not be safer, but it is different.<br>&nbsp;</p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T21:16:17Z">Friday, May 19 2023, 21:16</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7321'>Book Review: &#8220;Quantum Supremacy&#8221; by Michio Kaku (tl;dr DO NOT BUY)</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          When I was a teenager, I enjoyed reading Hyperspace, an early popularization of string theory by the theoretical physicist Michio Kaku. I&#8217;m sure I&#8217;d have plenty of criticisms if I reread it today, but at the time, I liked it a lot. In the decades since, Kaku has widened his ambit to, well, pretty much [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>When I was a teenager, I enjoyed reading <em><a href="https://www.amazon.com/Hyperspace-Scientific-Parallel-Universes-Dimension/dp/0385477058">Hyperspace</a></em>, an early popularization of string theory by the theoretical physicist Michio Kaku.  I&#8217;m sure I&#8217;d have plenty of criticisms if I reread it today, but at the time, I liked it a lot.  In the decades since, Kaku has widened his ambit to, well, pretty much everything, regularly churning out popular books with subtitles like &#8220;How Science Will Revolutionize the 21st Century&#8221; and &#8220;How Science Will Shape Human Destiny and Our Daily Lives.&#8221;  He&#8217;s also appeared on countless TV specials, in many cases to argue that UFOs likely contain extraterrestrial visitors.</p>



<p>Now Kaku has a new bestseller about quantum computing, creatively entitled <em><a href="https://www.amazon.com/Quantum-Supremacy-Computer-Revolution-Everything/dp/0385548362">Quantum Supremacy</a></em>.  He even <a href="https://ogjre.com/episode/1980-michio-kaku">appeared on Joe Rogan</a> a couple weeks ago to promote the book, surely reaching an orders-of-magnitude larger audience than I have in two decades of trying to explain quantum computing to non-experts.  (Incidentally, to those who&#8217;ve asked why Joe Rogan hasn&#8217;t invited <em>me</em> on his show to explain quantum computing: I guess you now have an answer of sorts!)</p>



<p>In the spirit, perhaps, of the TikTokkers who eat live cockroaches or whatever to satisfy their viewers, I decided to oblige loyal <em>Shtetl-Optimized</em> fans by buying <em>Quantum Supremacy</em> and reading it.  So I can now state with confidence: beating out a crowded field, this is <strong>the worst book about quantum computing,</strong> for some definition of the word &#8220;about,&#8221; that I&#8217;ve ever encountered.</p>



<p>Admittedly, it&#8217;s not obvious why I&#8217;m reviewing the book here at all.  Among people who&#8217;ve heard of this blog, I expect that approximately zero would be tempted to buy Kaku&#8217;s book, at least if they flipped through a few random pages and saw the &#8230; <em>level of care</em> that went into them.  Conversely, the book&#8217;s target readers have probably never visited a blog like this one and never will.  So what&#8217;s the use of this post?</p>



<p>Well, as the accidental #1 quantum computing blogger on the planet, I feel a sort of grim obligation here.  Who knows, maybe this post will show up in the first page of Google results for Kaku&#8217;s book, and it will manage to rescue two or three people from the kindergarten of lies.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Where to begin?  Should we just go through <em>the first chapter</em> with a red pen?  OK then: on the very first page, Kaku writes,</p>



<blockquote class="wp-block-quote">
<p>Google revealed that their Sycamore quantum computer could solve a mathematical problem in 200 seconds that would take 10,000 years on the world&#8217;s fastest supercomputer.</p>
</blockquote>



<p>No, the &#8220;10,000 years&#8221; estimate was <a href="https://scottaaronson.blog/?p=4372">quickly falsified</a>, as anyone following the subject knows.  I&#8217;d be the first to stress that the situation is complicated; compared to the best currently-known classical algorithms, some quantum advantage remains for the Random Circuit Sampling task, depending on how you measure it.  But to repeat the &#8220;10,000 years&#8221; figure at this point, with no qualifications, is actively misleading.</p>



<p>Turning to the second page:</p>



<blockquote class="wp-block-quote">
<p>[Quantum computers] are a new type of computer that can tackle problems that digital computers can never solve, even with an infinite amount of time.  For example, digital computers can never accurately calculate how atoms combine to create crucial chemical reactions, especially those that make life possible.  Digital computers can only compute on digital tape, consisting of a series of 0s and 1s, which are too crude to describe the delicate waves of electrons dancing deep inside a molecule.  For example, when tediously computing the paths taken by a mouse in a maze, a digital computer has to painfully analyze each possible path, one after the other.  A quantum computer, however, <em>simultaneously</em> analyzes all possible paths at the same time, with lightning speed.</p>
</blockquote>



<p>OK, so here Kaku has already perpetuated two of the most basic, forehead-banging errors about what quantum computers can do.  In truth, anything that a QC can calculate, a classical computer can calculate as well, <em>given exponentially more time</em>: for example, by representing the entire wavefunction, all 2<sup>n</sup> amplitudes, to whatever accuracy is needed.  That&#8217;s why it was understood from the very beginning that quantum computers can&#8217;t change what&#8217;s computable, but only how <em>efficiently</em> things can be computed.</p>



<p>And then there&#8217;s the Misconception of Misconceptions, about how a QC &#8220;analyzes all possible paths at the same time&#8221;&#8212;with no recognition anywhere of the central difficulty, the thing that makes a QC enormously <em>weaker</em> than an exponentially parallel classical computer, but is also the new and interesting part, namely that you only get to see a <em>single, random outcome</em> when you measure, with its probability given by the Born rule.  That&#8217;s the error so common that I warn against it right below the title of my blog.</p>



<blockquote class="wp-block-quote">
<p>[Q]uantum computers are so powerful that, in principle, they could break all known cybercodes.</p>
</blockquote>



<p>Nope, that&#8217;s strongly believed to be false, just like the analogous statement for <em>classical</em> computers.  Despite its obvious relevance for business and policy types, the entire field of <a href="https://en.wikipedia.org/wiki/Post-quantum_cryptography">post-quantum cryptography</a>&#8212;including the <a href="https://en.wikipedia.org/wiki/Lattice-based_cryptography">lattice-based public-key cryptosystems</a> that have by now survived 20+ years of efforts to find a quantum algorithm to break them&#8212;receives just a single vague mention, on pages 84-85.  The possibility of cryptography surviving quantum computers is quickly dismissed because &#8220;these new trapdoor functions are not easy to implement.&#8221;  (But they <em><a href="https://cloud.google.com/blog/products/identity-security/why-google-now-uses-post-quantum-cryptography-for-internal-comms">have</a></em> been implemented.)</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>There&#8217;s no attempt, anywhere in this book, to explain how any quantum algorithm actually works, let alone is there a word anywhere about the <em>limitations</em> of quantum algorithms.  And yet there&#8217;s still enough said to be wrong.  On page 84, shortly after confusing the concept of a <a href="https://en.wikipedia.org/wiki/One-way_function">one-way function</a> with that of a <a href="https://en.wikipedia.org/wiki/Trapdoor_function">trapdoor function</a>, Kaku writes:</p>



<blockquote class="wp-block-quote">
<p>Let N represent the number we wish to factorize.  For an ordinary digital computer, the amount of time it takes to factorize a number grows exponentially, like t ~ e<sup>N</sup>, times some unimportant factors.</p>
</blockquote>



<p>This is a double howler: first, trial division takes only ~âN time; Kaku has confused N itself with its <em>number of digits</em>, ~log<sub>2</sub>N.  Second, he seems unaware that much better classical factoring algorithms, like the <a href="https://en.wikipedia.org/wiki/General_number_field_sieve">Number Field Sieve</a>, have been known for decades, even though those algorithms play a central role in codebreaking and in any discussion of where the quantum/classical crossover might happen.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Honestly, though, the errors aren&#8217;t the worst of it.  The majority of the book is not even <em>worth</em> hunting for errors in, because fundamentally, it&#8217;s <em>filler</em>.</p>



<p>First there&#8217;s page after page breathlessly quoting prestigious-sounding people and organizations&#8212;Google&#8217;s Sundar Pichai, various government agencies, some report by Deloitte&#8212;about just how revolutionary they think quantum computing will be.  Then there are capsule hagiographies of Babbage and Lovelace, GÃ¶del and Turing, Planck and Einstein, Feynman and Everett.</p>



<p>And then the bulk of the book is actually about stuff <em>with no direct relation to quantum computing at all</em>&#8212;the origin of life, climate change, energy generation, cancer, curing aging, etc.&#8212;except with ungrounded speculations tacked onto the end of each chapter about how quantum computers will someday revolutionize all of this.  Personally, I&#8217;d say that</p>



<ol>
<li>Quantum simulation speeding up progress in biochemistry, high-temperature superconductivity, and the like is at least <em>plausible</em>&#8212;though very far from guaranteed, since one has to beat the cleverest classical approaches that can be designed for the same problems (a point that Kaku nowhere grapples with).</li>



<li>The stuff involving optimization, machine learning, and the like is almost entirely wishful thinking.</li>



<li>Not once in the book has Kaku even <em>mentioned</em> the intellectual tools (e.g., looking at actual quantum algorithms like Groverâs algorithm or phase estimation, and their performance on various tasks) that would be needed to distinguish 1 from 2.</li>
</ol>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>In his acknowledgments section, Kaku simply lists a bunch of famous scientists he&#8217;s met in his life&#8212;Feynman, Witten, Hawking, Penrose, Brian Greene, Lisa Randall, Neil deGrasse Tyson.  Not a single living quantum computing researcher is acknowledged, not one.</p>



<p>Recently, I&#8217;d been cautiously optimistic that, after decades of overblown headlines about &#8220;trying all answers in parallel,&#8221; &#8220;cracking all known codes,&#8221; etc., the standard for quantum computing popularization was slowly creeping upward.  Maybe I was just bowled over by <a href="https://www.youtube.com/watch?v=-UrdExQW0cs">this recent YouTube video</a> (&#8220;How Quantum Computers Break the Internet&#8230; Starting Now&#8221;), which despite its clickbait title and its slick presentation, miraculously gets essentially everything right, shaming the hypesters by demonstrating just how much better it&#8217;s possible to do.</p>



<p>Kaku&#8217;s slapdash &#8220;book,&#8221; and the publicity campaign around it, represents a noxious step backwards.  The wonder of it, to me, is Kaku holds a PhD in theoretical physics.  And yet the average English major who&#8217;s written a &#8220;what&#8217;s the deal with quantum computing?&#8221; article for some obscure link aggregator site has done a more careful and honest job than Kaku has.  That&#8217;s setting the bar about a millimeter off the floor.  I think the difference is, at least the English major knows that they&#8217;re supposed to <em>call</em> an expert or two, when writing about an enormously complicated subject of which they&#8217;re completely ignorant.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Update:</mark></strong> Iâve now been immersed in the AI safety field for one year, let I wouldnât consider myself <em>nearly</em> ready to write a book on the subject.  My knowledge of related parts of CS, my year studying AI in grad school, and my having created the subject of computational learning theory of quantum states would all be relevant but totally insufficient.  And AI safety, for all its importance, has less than quantum computing does in the way of difficult-to-understand concepts and results that basically everyone in the field agrees about.  And if I <em>did</em> someday write such a book, Iâd be pretty terrified of getting stuff wrong, and would have multiple expert colleagues read drafts.</p>



<p>In case this wasnât clear enough from my post, Kaku appears to have had zero prior engagement with quantum computing, <strong>and also </strong>to have consulted zero relevant experts who couldâve fixed his misconceptions.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T10:15:56Z">Friday, May 19 2023, 10:15</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10749'>On the Computational Complexity of Generalized Common Shape Puzzles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mutsunori Banbara, Shin-ichi Minato, Hirotaka Ono, Ryuhei Uehara</p><p>In this study, we investigate the computational complexity of some variants
of generalized puzzles. We are provided with two sets S_1 and S_2 of
polyominoes. The first puzzle asks us to form the same shape using polyominoes
in S_1 and S_2. We demonstrate that this is polynomial-time solvable if S_1 and
S_2 have constant numbers of polyominoes, and it is strongly NP-complete in
general. The second puzzle allows us to make copies of the pieces in S_1 and
S_2. That is, a polyomino in S_1 can be used multiple times to form a shape.
This is a generalized version of the classical puzzle known as the common
multiple shape puzzle. For two polyominoes P and Q, the common multiple shape
is a shape that can be formed by many copies of P and many copies of Q. We show
that the second puzzle is undecidable in general. The undecidability is
demonstrated by a reduction from a new type of undecidable puzzle based on
tiling. Nevertheless, certain concrete instances of the common multiple shape
can be solved in a practical time. We present a method for determining the
common multiple shape for provided tuples of polyominoes and outline concrete
results, which improve on the previously known results in puzzle society.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Banbara_M/0/1/0/all/0/1">Mutsunori Banbara</a>, <a href="http://arxiv.org/find/cs/1/au:+Minato_S/0/1/0/all/0/1">Shin-ichi Minato</a>, <a href="http://arxiv.org/find/cs/1/au:+Ono_H/0/1/0/all/0/1">Hirotaka Ono</a>, <a href="http://arxiv.org/find/cs/1/au:+Uehara_R/0/1/0/all/0/1">Ryuhei Uehara</a></p><p>In this study, we investigate the computational complexity of some variants
of generalized puzzles. We are provided with two sets S_1 and S_2 of
polyominoes. The first puzzle asks us to form the same shape using polyominoes
in S_1 and S_2. We demonstrate that this is polynomial-time solvable if S_1 and
S_2 have constant numbers of polyominoes, and it is strongly NP-complete in
general. The second puzzle allows us to make copies of the pieces in S_1 and
S_2. That is, a polyomino in S_1 can be used multiple times to form a shape.
This is a generalized version of the classical puzzle known as the common
multiple shape puzzle. For two polyominoes P and Q, the common multiple shape
is a shape that can be formed by many copies of P and many copies of Q. We show
that the second puzzle is undecidable in general. The undecidability is
demonstrated by a reduction from a new type of undecidable puzzle based on
tiling. Nevertheless, certain concrete instances of the common multiple shape
can be solved in a practical time. We present a method for determining the
common multiple shape for provided tuples of polyominoes and outline concrete
results, which improve on the previously known results in puzzle society.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10922'>On $k$-means for segments and polylines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sergio Cabello, Panos Giannopoulos</p><p>We study the problem of $k$-means clustering in the space of straight-line
segments in $\mathbb{R}^{2}$ under the Hausdorff distance. For this problem, we
give a $(1+\epsilon)$-approximation algorithm that, for an input of $n$
segments, for any fixed $k$, and with constant success probability, runs in
time $O(n+ \epsilon^{-O(k)} + \epsilon^{-O(k)}\cdot \log^{O(k)}
(\epsilon^{-1}))$. The algorithm has two main ingredients. Firstly, we express
the $k$-means objective in our metric space as a sum of algebraic functions and
use the optimization technique of Vigneron~\cite{Vigneron14} to approximate its
minimum. Secondly, we reduce the input size by computing a small size coreset
using the sensitivity-based sampling framework by Feldman and
Langberg~\cite{Feldman11, Feldman2020}. Our results can be extended to
polylines of constant complexity with a running time of $O(n+
\epsilon^{-O(k)})$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cabello_S/0/1/0/all/0/1">Sergio Cabello</a>, <a href="http://arxiv.org/find/cs/1/au:+Giannopoulos_P/0/1/0/all/0/1">Panos Giannopoulos</a></p><p>We study the problem of $k$-means clustering in the space of straight-line
segments in $\mathbb{R}^{2}$ under the Hausdorff distance. For this problem, we
give a $(1+\epsilon)$-approximation algorithm that, for an input of $n$
segments, for any fixed $k$, and with constant success probability, runs in
time $O(n+ \epsilon^{-O(k)} + \epsilon^{-O(k)}\cdot \log^{O(k)}
(\epsilon^{-1}))$. The algorithm has two main ingredients. Firstly, we express
the $k$-means objective in our metric space as a sum of algebraic functions and
use the optimization technique of Vigneron~\cite{Vigneron14} to approximate its
minimum. Secondly, we reduce the input size by computing a small size coreset
using the sensitivity-based sampling framework by Feldman and
Langberg~\cite{Feldman11, Feldman2020}. Our results can be extended to
polylines of constant complexity with a running time of $O(n+
\epsilon^{-O(k)})$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10575'>The Complexity of Diagonalization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nikhil Srivastava</p><p>We survey recent progress on efficient algorithms for approximately
diagonalizing a square complex matrix in the models of rational (variable
precision) and finite (floating point) arithmetic. This question has been
studied across several research communities for decades, but many mysteries
remain. We present several open problems which we hope will be of broad
interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Srivastava_N/0/1/0/all/0/1">Nikhil Srivastava</a></p><p>We survey recent progress on efficient algorithms for approximately
diagonalizing a square complex matrix in the models of rational (variable
precision) and finite (floating point) arithmetic. This question has been
studied across several research communities for decades, but many mysteries
remain. We present several open problems which we hope will be of broad
interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11053'>(Noisy) Gap Cycle Counting Strikes Back: Random Order Streaming Lower Bounds for Connected Components and Beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sepehr Assadi, Janani Sundaresan</p><p>We continue the study of the communication complexity of gap cycle counting
problems. These problems have been introduced by Verbin and Yu [SODA 2011] and
have found numerous applications in proving streaming lower bounds. In the
noisy gap cycle counting problem (NGC), there is a small integer $k \geq 1$ and
an $n$-vertex graph consisted of vertex-disjoint union of either $k$-cycles or
$2k$-cycles, plus $O(n/k)$ disjoint paths of length $k-1$ in both cases
(``noise''). The edges of this graph are partitioned between Alice and Bob
whose goal is to decide which case the graph belongs to with minimal
communication from Alice to Bob.
</p>
<p>We study the robust communication complexity -- `a la Chakrabarti, Cormode,
and McGregor [STOC 2008] -- of NGC, namely, when edges are partitioned randomly
between the players. This is in contrast to all prior work on gap cycle
counting problems in adversarial partitions. While NGC can be solved trivially
with zero communication when $k &lt; \log{n}$, we prove that when $k$ is a
constant factor larger than $\log{n}$, the robust (one-way) communication
complexity of NGC is $\Omega(n)$ bits.
</p>
<p>As a corollary of this result, we can prove several new graph streaming lower
bounds for random order streams. In particular, we show that any streaming
algorithm that for every $\varepsilon &gt; 0$ estimates the number of connected
components of a graph presented in a random order stream to within an
$\varepsilon \cdot n$ additive factor requires $2^{\Omega(1/\varepsilon)}$
space, settling a conjecture of Peng and Sohler [SODA 2018]. We further discuss
new implications of our lower bounds to other problems such as estimating size
of maximum matchings and independent sets on planar graphs, random walks, as
well as to stochastic streams.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Assadi_S/0/1/0/all/0/1">Sepehr Assadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaresan_J/0/1/0/all/0/1">Janani Sundaresan</a></p><p>We continue the study of the communication complexity of gap cycle counting
problems. These problems have been introduced by Verbin and Yu [SODA 2011] and
have found numerous applications in proving streaming lower bounds. In the
noisy gap cycle counting problem (NGC), there is a small integer $k \geq 1$ and
an $n$-vertex graph consisted of vertex-disjoint union of either $k$-cycles or
$2k$-cycles, plus $O(n/k)$ disjoint paths of length $k-1$ in both cases
(``noise''). The edges of this graph are partitioned between Alice and Bob
whose goal is to decide which case the graph belongs to with minimal
communication from Alice to Bob.
</p>
<p>We study the robust communication complexity -- `a la Chakrabarti, Cormode,
and McGregor [STOC 2008] -- of NGC, namely, when edges are partitioned randomly
between the players. This is in contrast to all prior work on gap cycle
counting problems in adversarial partitions. While NGC can be solved trivially
with zero communication when $k &lt; \log{n}$, we prove that when $k$ is a
constant factor larger than $\log{n}$, the robust (one-way) communication
complexity of NGC is $\Omega(n)$ bits.
</p>
<p>As a corollary of this result, we can prove several new graph streaming lower
bounds for random order streams. In particular, we show that any streaming
algorithm that for every $\varepsilon &gt; 0$ estimates the number of connected
components of a graph presented in a random order stream to within an
$\varepsilon \cdot n$ additive factor requires $2^{\Omega(1/\varepsilon)}$
space, settling a conjecture of Peng and Sohler [SODA 2018]. We further discuss
new implications of our lower bounds to other problems such as estimating size
of maximum matchings and independent sets on planar graphs, random walks, as
well as to stochastic streams.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10536'>Online List Labeling with Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel McCauley, Benjamin Moseley, Aidin Niaparast, Shikha Singh</p><p>A growing line of work shows how learned predictions can be used to break
through worst-case barriers to improve the running time of an algorithm.
However, incorporating predictions into data structures with strong theoretical
guarantees remains underdeveloped. This paper takes a step in this direction by
showing that predictions can be leveraged in the fundamental online list
labeling problem. In the problem, n items arrive over time and must be stored
in sorted order in an array of size Theta(n). The array slot of an element is
its label and the goal is to maintain sorted order while minimizing the total
number of elements moved (i.e., relabeled). We design a new list labeling data
structure and bound its performance in two models. In the worst-case
learning-augmented model, we give guarantees in terms of the error in the
predictions. Our data structure provides strong guarantees: it is optimal for
any prediction error and guarantees the best-known worst-case bound even when
the predictions are entirely erroneous. We also consider a stochastic error
model and bound the performance in terms of the expectation and variance of the
error. Finally, the theoretical results are demonstrated empirically. In
particular, we show that our data structure has strong performance on real
temporal data sets where predictions are constructed from elements that arrived
in the past, as is typically done in a practical use case.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+McCauley_S/0/1/0/all/0/1">Samuel McCauley</a>, <a href="http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1">Benjamin Moseley</a>, <a href="http://arxiv.org/find/cs/1/au:+Niaparast_A/0/1/0/all/0/1">Aidin Niaparast</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Shikha Singh</a></p><p>A growing line of work shows how learned predictions can be used to break
through worst-case barriers to improve the running time of an algorithm.
However, incorporating predictions into data structures with strong theoretical
guarantees remains underdeveloped. This paper takes a step in this direction by
showing that predictions can be leveraged in the fundamental online list
labeling problem. In the problem, n items arrive over time and must be stored
in sorted order in an array of size Theta(n). The array slot of an element is
its label and the goal is to maintain sorted order while minimizing the total
number of elements moved (i.e., relabeled). We design a new list labeling data
structure and bound its performance in two models. In the worst-case
learning-augmented model, we give guarantees in terms of the error in the
predictions. Our data structure provides strong guarantees: it is optimal for
any prediction error and guarantees the best-known worst-case bound even when
the predictions are entirely erroneous. We also consider a stochastic error
model and bound the performance in terms of the expectation and variance of the
error. Finally, the theoretical results are demonstrated empirically. In
particular, we show that our data structure has strong performance on real
temporal data sets where predictions are constructed from elements that arrived
in the past, as is typically done in a practical use case.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10618'>Fault-Tolerant Consensus in Quantum Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: MohammadTaghi Hajiaghayi, Dariusz R. Kowalski, Jan Olkowski</p><p>Fault-tolerant consensus is about reaching agreement on some of the input
values in a limited time by non-faulty autonomous processes, despite of
failures of processes or communication medium. This problem is particularly
challenging and costly against an adaptive adversary with full information.
Bar-Joseph and Ben-Or (PODC'98) were the first who proved an absolute lower
bound $\Omega(\sqrt{n/\log n})$ on expected time complexity of consensus in any
classic (i.e., randomized or deterministic) message-passing network with $n$
processes succeeding with probability $1$ against such a strong adaptive
adversary crashing processes. Seminal work of Ben-Or and Hassidim (STOC'05)
broke the $\Omega(\sqrt{n/\log n})$ barrier for consensus in classic
(deterministic and randomized) networks by employing quantum computing. They
showed an (expected) constant-time quantum algorithm for a linear number of
crashes $t&lt;n/3$. In this paper, we improve upon that seminal work by reducing
the number of quantum and communication bits to an arbitrarily small
polynomial, and even more, to a polylogarithmic number -- though, the latter in
the cost of a slightly larger polylogarithmic time (still exponentially smaller
than the time lower bound $\Omega(\sqrt{n/\log n})$ for classic computation).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1">MohammadTaghi Hajiaghayi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowalski_D/0/1/0/all/0/1">Dariusz R. Kowalski</a>, <a href="http://arxiv.org/find/cs/1/au:+Olkowski_J/0/1/0/all/0/1">Jan Olkowski</a></p><p>Fault-tolerant consensus is about reaching agreement on some of the input
values in a limited time by non-faulty autonomous processes, despite of
failures of processes or communication medium. This problem is particularly
challenging and costly against an adaptive adversary with full information.
Bar-Joseph and Ben-Or (PODC'98) were the first who proved an absolute lower
bound $\Omega(\sqrt{n/\log n})$ on expected time complexity of consensus in any
classic (i.e., randomized or deterministic) message-passing network with $n$
processes succeeding with probability $1$ against such a strong adaptive
adversary crashing processes. Seminal work of Ben-Or and Hassidim (STOC'05)
broke the $\Omega(\sqrt{n/\log n})$ barrier for consensus in classic
(deterministic and randomized) networks by employing quantum computing. They
showed an (expected) constant-time quantum algorithm for a linear number of
crashes $t&lt;n/3$. In this paper, we improve upon that seminal work by reducing
the number of quantum and communication bits to an arbitrarily small
polynomial, and even more, to a polylogarithmic number -- though, the latter in
the cost of a slightly larger polylogarithmic time (still exponentially smaller
than the time lower bound $\Omega(\sqrt{n/\log n})$ for classic computation).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10744'>Online Resource Allocation in Episodic Markov Decision Processes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Duksang Lee, Dabeen Lee</p><p>This paper studies a long-term resource allocation problem over multiple
periods where each period requires a multi-stage decision-making process. We
formulate the problem as an online resource allocation problem in an episodic
finite-horizon Markov decision process with unknown non-stationary transitions
and stochastic non-stationary reward and resource consumption functions for
each episode. We provide an equivalent online linear programming reformulation
based on occupancy measures, for which we develop an online mirror descent
algorithm. Our online dual mirror descent algorithm for resource allocation
deals with uncertainties and errors in estimating the true feasible set, which
is of independent interest. We prove that under stochastic reward and resource
consumption functions, the expected regret of the online mirror descent
algorithm is bounded by $O(\rho^{-1}{H^{3/2}}S\sqrt{AT})$ where $\rho\in(0,1)$
is the budget parameter, $H$ is the length of the horizon, $S$ and $A$ are the
numbers of states and actions, and $T$ is the number of episodes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Duksang Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dabeen Lee</a></p><p>This paper studies a long-term resource allocation problem over multiple
periods where each period requires a multi-stage decision-making process. We
formulate the problem as an online resource allocation problem in an episodic
finite-horizon Markov decision process with unknown non-stationary transitions
and stochastic non-stationary reward and resource consumption functions for
each episode. We provide an equivalent online linear programming reformulation
based on occupancy measures, for which we develop an online mirror descent
algorithm. Our online dual mirror descent algorithm for resource allocation
deals with uncertainties and errors in estimating the true feasible set, which
is of independent interest. We prove that under stochastic reward and resource
consumption functions, the expected regret of the online mirror descent
algorithm is bounded by $O(\rho^{-1}{H^{3/2}}S\sqrt{AT})$ where $\rho\in(0,1)$
is the budget parameter, $H$ is the length of the horizon, $S$ and $A$ are the
numbers of states and actions, and $T$ is the number of episodes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10935'>Submodularity Gaps for Selected Network Design and Matching Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Martin B&#xf6;hm, Jaros&#x142;aw Byrka, Mateusz Lewandowski, Jan Marcinkowski</p><p>Submodularity in combinatorial optimization has been a topic of many studies
and various algorithmic techniques exploiting submodularity of a studied
problem have been proposed. It is therefore natural to ask, in cases where the
cost function of the studied problem is not submodular, whether it is possible
to approximate this cost function with a proxy submodular function.
</p>
<p>We answer this question in the negative for two major problems in metric
optimization, namely Steiner Tree and Uncapacitated Facility Location. We do so
by proving super-constant lower bounds on the submodularity gap for these
problems, which are in contrast to the known constant factor cost sharing
schemes known for them. Technically, our lower bounds build on strong lower
bounds for the online variants of these two problems. Nevertheless, online
lower bounds do not always imply submodularity lower bounds. We show that the
problem Maximum Bipartite Matching does not exhibit any submodularity gap,
despite its online variant being only (1 - 1/e)-competitive in the randomized
setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bohm_M/0/1/0/all/0/1">Martin B&#xf6;hm</a>, <a href="http://arxiv.org/find/cs/1/au:+Byrka_J/0/1/0/all/0/1">Jaros&#x142;aw Byrka</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewandowski_M/0/1/0/all/0/1">Mateusz Lewandowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcinkowski_J/0/1/0/all/0/1">Jan Marcinkowski</a></p><p>Submodularity in combinatorial optimization has been a topic of many studies
and various algorithmic techniques exploiting submodularity of a studied
problem have been proposed. It is therefore natural to ask, in cases where the
cost function of the studied problem is not submodular, whether it is possible
to approximate this cost function with a proxy submodular function.
</p>
<p>We answer this question in the negative for two major problems in metric
optimization, namely Steiner Tree and Uncapacitated Facility Location. We do so
by proving super-constant lower bounds on the submodularity gap for these
problems, which are in contrast to the known constant factor cost sharing
schemes known for them. Technically, our lower bounds build on strong lower
bounds for the online variants of these two problems. Nevertheless, online
lower bounds do not always imply submodularity lower bounds. We show that the
problem Maximum Bipartite Matching does not exhibit any submodularity gap,
despite its online variant being only (1 - 1/e)-competitive in the randomized
setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11046'>Difference of Submodular Minimization via DC Programming</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marwa El Halabi, George Orfanides, Tim Hoheisel</p><p>Minimizing the difference of two submodular (DS) functions is a problem that
naturally occurs in various machine learning problems. Although it is well
known that a DS problem can be equivalently formulated as the minimization of
the difference of two convex (DC) functions, existing algorithms do not fully
exploit this connection. A classical algorithm for DC problems is called the DC
algorithm (DCA). We introduce variants of DCA and its complete form (CDCA) that
we apply to the DC program corresponding to DS minimization. We extend existing
convergence properties of DCA, and connect them to convergence properties on
the DS problem. Our results on DCA match the theoretical guarantees satisfied
by existing DS algorithms, while providing a more complete characterization of
convergence properties. In the case of CDCA, we obtain a stronger local
minimality guarantee. Our numerical results show that our proposed algorithms
outperform existing baselines on two applications: speech corpus selection and
feature selection.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Halabi_M/0/1/0/all/0/1">Marwa El Halabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Orfanides_G/0/1/0/all/0/1">George Orfanides</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoheisel_T/0/1/0/all/0/1">Tim Hoheisel</a></p><p>Minimizing the difference of two submodular (DS) functions is a problem that
naturally occurs in various machine learning problems. Although it is well
known that a DS problem can be equivalently formulated as the minimization of
the difference of two convex (DC) functions, existing algorithms do not fully
exploit this connection. A classical algorithm for DC problems is called the DC
algorithm (DCA). We introduce variants of DCA and its complete form (CDCA) that
we apply to the DC program corresponding to DS minimization. We extend existing
convergence properties of DCA, and connect them to convergence properties on
the DS problem. Our results on DCA match the theoretical guarantees satisfied
by existing DS algorithms, while providing a more complete characterization of
convergence properties. In the case of CDCA, we obtain a stronger local
minimality guarantee. Our numerical results show that our proposed algorithms
outperform existing baselines on two applications: speech corpus selection and
feature selection.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, May 18
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/05/community-guidelines-that-ignore-history.html'>Community Guidelines that Ignore History</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Last week I got the following email from Blogger:</p><blockquote><p>As you may know, our Community Guidelines (blogger.com/go/contentpolicy) describe the boundaries for what we allow-- and don't allow-- on Blogger. Your post titled "Mysteries of the Seventies" was flagged to us for review. This post was put behind a warning for readers because it contains sensitive content; the post is visible at&nbsp;blog.computationalcomplexity.org/2005/06/mysteries-of-seventies.html. Your blog readers must acknowledge the warning before being able to read the post/blog.</p></blockquote><p>So let me describe what happened carefully so this post doesn't also get flagged. First a history lesson. In 1972, five men were arrested for breaking into the Democratic National Committee (DNC) headquarters at the Watergate complex in Washington, D.C. They were found with bugging devices and cameras, attempting to wiretap the DNC offices. One of them had ties to&nbsp;the Committee to Re-Elect the President (CREEP), which supported Richard Nixon's re-election campaign.</p><p>Two Washington Post reporters,&nbsp;Bob Woodward and Carl Bernstein, broke the story of the coverup that would eventually lead to Nixon's resignation in 1974. I highly recommend both the book and the film All the President's Men&nbsp;about their investigation.&nbsp;Woodward and Bernstein got help from a then anonymous source. The identity of the source was subject to huge speculation and remained a mystery for three decades. In 2005&nbsp;Mark Felt, associate director of the FBI, outed himself as the source.</p><p>After the announcement I wrote a short post&nbsp;(would have been a tweet today) mentioning that while we learned the solution of one mystery from the 1970s, another remained.</p><p>So why was this post flagged as sensitive eighteen years later? Because I used the pseudonym the Washington Post reporters gave to Mark Felt, a name take from a popular adult movie at the time.&nbsp;</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Last week I got the following email from Blogger:</p><blockquote><p>As you may know, our Community Guidelines (<a href="https://blogger.com/go/contentpolicy">https://blogger.com/go/contentpolicy</a>) describe the boundaries for what we allow-- and don't allow-- on Blogger. Your post titled "Mysteries of the Seventies" was flagged to us for review. This post was put behind a warning for readers because it contains sensitive content; the post is visible at&nbsp;<a href="http://blog.computationalcomplexity.org/2005/06/mysteries-of-seventies.html">http://blog.computationalcomplexity.org/2005/06/mysteries-of-seventies.html</a>. Your blog readers must acknowledge the warning before being able to read the post/blog.</p></blockquote><p>So let me describe what happened carefully so this post doesn't also get flagged. First a history lesson. In 1972, five men were arrested for breaking into the Democratic National Committee (DNC) headquarters at the Watergate complex in Washington, D.C. They were found with bugging devices and cameras, attempting to wiretap the DNC offices. One of them had ties to&nbsp;the Committee to Re-Elect the President (CREEP), which supported Richard Nixon's re-election campaign.</p><p>Two Washington Post reporters,&nbsp;Bob Woodward and Carl Bernstein, broke the story of the coverup that would eventually lead to Nixon's resignation in 1974. I highly recommend both the <a href="https://amzn.to/4561z5n">book</a> and the <a href="https://www.imdb.com/title/tt0074119/">film</a> <i>All the President's Men</i>&nbsp;about their investigation.<b style="font-style: italic;">&nbsp;</b>Woodward and Bernstein got help from a then anonymous source. The identity of the source was subject to huge speculation and remained a mystery for three decades. In 2005&nbsp;<a href="https://en.wikipedia.org/wiki/Mark_Felt">Mark Felt</a>, associate director of the FBI, outed himself as the source.</p><p>After the announcement I wrote <a href="https://blog.computationalcomplexity.org/2005/06/mysteries-of-seventies.html">a short post</a>&nbsp;(would have been a tweet today) mentioning that while we learned the solution of one mystery from the 1970s, <a href="https://www.claymath.org/millennium-problems/p-vs-np-problem">another</a> remained.</p><p>So why was this post flagged as sensitive eighteen years later? Because I used the pseudonym the Washington Post reporters gave to Mark Felt, a name take from a popular adult movie at the time.&nbsp;</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T12:54:00Z">Thursday, May 18 2023, 12:54</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/072'>TR23-072 |  Range Avoidance, Remote Point, and Hard Partial Truth Tables via Satisfying-Pairs Algorithms | 

	Yeyuan Chen, 

	Yizhi Huang, 

	Jiatu Li, 

	Hanlin Ren</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The *range avoidance problem*, denoted as $\mathcal{C}$-$\rm Avoid$, asks to find a non-output of a given $\mathcal{C}$-circuit $C:\{0,1\}^n\to\{0,1\}^\ell$ with stretch $\ell&gt;n$. This problem has recently received much attention in complexity theory for its connections with circuit lower bounds and other explicit construction problems. Inspired by the Algorithmic Method for circuit lower bounds, Ren, Santhanam, and Wang (FOCS&#39;22) established a framework to design $\rm FP^{NP}$ algorithms for $\mathcal{C}$-$\rm Avoid$ via *slightly non-trivial* data structures related to $\mathcal{C}$. However, a major drawback of their approach is the lack of unconditional results even for $\mathcal{C}={\rm AC}^0$.
	
In this work, we present the first unconditional $\rm FP^{NP}$ algorithm for ${\rm ACC}^0$-$\rm Avoid$. Indeed, we obtain $\rm FP^{NP}$ algorithms for the following stronger problems:
$\bullet$ (${\rm ACC}^0$-$\rm RemotePoint$). Given $C:\{0,1\}^n\to\{0,1\}^\ell$ for some $\ell={\rm quasipoly}(n)$ such that each output bit of $C$ is computed by a ${\rm quasipoly}(n)$-size ${\rm AC}^0[m]$ circuit, we can find some $y\in\{0,1\}^\ell$ in $\rm FP^{NP}$ such that for every $x\in\{0, 1\}^n$, the relative Hamming distance between $y$ and $C(x)$ is at least $1/2-1/{\rm poly}(n)$. This problem is the ``average-case&#39;&#39; analogue of ${\rm ACC}^0$-$\rm Avoid$.
$\bullet$ (${\rm ACC}^0$-$\rm AvgPartialHard$). Given $x_1,\dots,x_\ell\in\{0,1\}^n$ for some $\ell={\rm quasipoly}(n)$, we can compute $\ell$ bits $y_1,\dots,y_\ell\in\{0,1\}$ in $\rm FP^{NP}$ such that for every $2^{\log^c(n)}$-size ${\rm ACC}^0$ circuit $C$, $\Pr_i[C(x_i)\ne y_i]\ge 1/2-1/{\rm poly}(n)$, where $c=O(1)$. This problem generalises the strong average-case circuit lower bounds against ${\rm ACC}^0$ in a different way. 
Our algorithms can be seen as natural generalisations of the best known almost-everywhere average-case lower bounds against ${\rm ACC}^0$ circuits by Chen, Lyu, and Williams (FOCS&#39;20). Note that both problems above have been studied prior to our work, and no $\rm FP^{NP}$ algorithm was known even for weak circuit classes such as ${\rm GF}(2)$-linear circuits and DNF formulas. 

Our results follow from a strengthened algorithmic method: slightly non-trivial algorithms for the *Satisfying-Pairs* problem for $\mathcal{C}$ implies $\rm FP^{NP}$ algorithms for $\mathcal{C}$-$\rm Avoid$ (as well as $\mathcal{C}$-$\rm RemotePoint$ and $\mathcal{C}$-$\rm AvgPartialHard$). Here, given $\mathcal{C}$-circuits $\{C_i\}$ and inputs $\{x_j\}$, the $\mathcal{C}$-Satisfying-Pairs problem asks to (approximately) count the number of pairs $(i,j)$ such that $C_i(x_j)=1$.
	
A technical contribution of this work is a construction of a *short, smooth, and rectangular PCP of Proximity* that combines two previous PCP constructions, which may be of independent interest. It serves as a key tool that allows us to generalise the framework for $\rm Avoid$ to the average-case scenarios.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The *range avoidance problem*, denoted as $\mathcal{C}$-$\rm Avoid$, asks to find a non-output of a given $\mathcal{C}$-circuit $C:\{0,1\}^n\to\{0,1\}^\ell$ with stretch $\ell&gt;n$. This problem has recently received much attention in complexity theory for its connections with circuit lower bounds and other explicit construction problems. Inspired by the Algorithmic Method for circuit lower bounds, Ren, Santhanam, and Wang (FOCS&#39;22) established a framework to design $\rm FP^{NP}$ algorithms for $\mathcal{C}$-$\rm Avoid$ via *slightly non-trivial* data structures related to $\mathcal{C}$. However, a major drawback of their approach is the lack of unconditional results even for $\mathcal{C}={\rm AC}^0$.
	
In this work, we present the first unconditional $\rm FP^{NP}$ algorithm for ${\rm ACC}^0$-$\rm Avoid$. Indeed, we obtain $\rm FP^{NP}$ algorithms for the following stronger problems:
$\bullet$ (${\rm ACC}^0$-$\rm RemotePoint$). Given $C:\{0,1\}^n\to\{0,1\}^\ell$ for some $\ell={\rm quasipoly}(n)$ such that each output bit of $C$ is computed by a ${\rm quasipoly}(n)$-size ${\rm AC}^0[m]$ circuit, we can find some $y\in\{0,1\}^\ell$ in $\rm FP^{NP}$ such that for every $x\in\{0, 1\}^n$, the relative Hamming distance between $y$ and $C(x)$ is at least $1/2-1/{\rm poly}(n)$. This problem is the ``average-case&#39;&#39; analogue of ${\rm ACC}^0$-$\rm Avoid$.
$\bullet$ (${\rm ACC}^0$-$\rm AvgPartialHard$). Given $x_1,\dots,x_\ell\in\{0,1\}^n$ for some $\ell={\rm quasipoly}(n)$, we can compute $\ell$ bits $y_1,\dots,y_\ell\in\{0,1\}$ in $\rm FP^{NP}$ such that for every $2^{\log^c(n)}$-size ${\rm ACC}^0$ circuit $C$, $\Pr_i[C(x_i)\ne y_i]\ge 1/2-1/{\rm poly}(n)$, where $c=O(1)$. This problem generalises the strong average-case circuit lower bounds against ${\rm ACC}^0$ in a different way. 
Our algorithms can be seen as natural generalisations of the best known almost-everywhere average-case lower bounds against ${\rm ACC}^0$ circuits by Chen, Lyu, and Williams (FOCS&#39;20). Note that both problems above have been studied prior to our work, and no $\rm FP^{NP}$ algorithm was known even for weak circuit classes such as ${\rm GF}(2)$-linear circuits and DNF formulas. 

Our results follow from a strengthened algorithmic method: slightly non-trivial algorithms for the *Satisfying-Pairs* problem for $\mathcal{C}$ implies $\rm FP^{NP}$ algorithms for $\mathcal{C}$-$\rm Avoid$ (as well as $\mathcal{C}$-$\rm RemotePoint$ and $\mathcal{C}$-$\rm AvgPartialHard$). Here, given $\mathcal{C}$-circuits $\{C_i\}$ and inputs $\{x_j\}$, the $\mathcal{C}$-Satisfying-Pairs problem asks to (approximately) count the number of pairs $(i,j)$ such that $C_i(x_j)=1$.
	
A technical contribution of this work is a construction of a *short, smooth, and rectangular PCP of Proximity* that combines two previous PCP constructions, which may be of independent interest. It serves as a key tool that allows us to generalise the framework for $\rm Avoid$ to the average-case scenarios.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T12:12:41Z">Thursday, May 18 2023, 12:12</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-events.org/2023/05/18/fodsi-summer-school-on-the-foundations-of-data-science/'>FODSI Summer School on the Foundations of Data Science.</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-events.org'>CS Theory Events</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          June 27-28, 2023 Bryn Mawr College fodsi.us/ssbm.html The Foundations of Data Science Institute (FODSI) is organizing a summer school on the foundations of data science. This school will be held at the Bryn Mawr College campus, near Philadelphia. It is aimed at advanced undergraduate students and beginning graduate students in fields related to the foundations &#8230; Continue reading FODSI Summer School on the Foundations of Data&#160;Science.<p>By shacharlovett</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          June 27-28, 2023 Bryn Mawr College https://fodsi.us/ssbm.html The Foundations of Data Science Institute (FODSI) is organizing a summer school on the foundations of data science. This school will be held at the Bryn Mawr College campus, near Philadelphia. It is aimed at advanced undergraduate students and beginning graduate students in fields related to the foundations &#8230; <a href="https://cstheory-events.org/2023/05/18/fodsi-summer-school-on-the-foundations-of-data-science/" class="more-link">Continue reading <span class="screen-reader-text">FODSI Summer School on the Foundations of Data&#160;Science.</span></a><p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T04:58:12Z">Thursday, May 18 2023, 04:58</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09973'>Border Complexity of Symbolic Determinant under Rank One Restriction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Abhranil Chatterjee, Sumanta Ghosh, Rohit Gurjar, Roshan Raj</p><p>VBP is the class of polynomial families that can be computed by the
determinant of a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where
the size of each $A_i$ is polynomial in the number of variables (equivalently,
computable by polynomial-sized algebraic branching programs (ABP)). A major
open problem in geometric complexity theory (GCT) is to determine whether VBP
is closed under approximation. The power of approximation is well understood
for some restricted models of computation, e.g., the class of depth-two
circuits, read-once oblivious ABPs (ROABP), monotone ABPs, depth-three circuits
of bounded top fan-in, and width-two ABPs. The former three classes are known
to be closed under approximation [Bl"{a}ser, Ikenmeyer, Mahajan, Pandey, and
Saurabh (2020)], whereas the approximative closure of the last one captures the
whole class of polynomial families computable by polynomial-sized formulas
[Bringmann, Ikenmeyer, and Zuiddam (2017)].
</p>
<p>In this work, we consider the subclass of VBP computed by the determinant of
a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where for each $1\leq
i \leq n$, $A_i$ is of rank one. It has been studied extensively
[Edmonds(1968), Edmonds(1979)] and efficient identity testing algorithms are
known [Lov"{a}sz (1989), Gurjar and Thierauf (2020)]. We show that this class
is closed under approximation. In the language of algebraic geometry, we show
that the set obtained by taking coordinatewise products of pairs of points from
(the Pl\"{u}cker embedding of) a Grassmannian variety is closed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1">Abhranil Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Sumanta Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurjar_R/0/1/0/all/0/1">Rohit Gurjar</a>, <a href="http://arxiv.org/find/cs/1/au:+Raj_R/0/1/0/all/0/1">Roshan Raj</a></p><p>VBP is the class of polynomial families that can be computed by the
determinant of a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where
the size of each $A_i$ is polynomial in the number of variables (equivalently,
computable by polynomial-sized algebraic branching programs (ABP)). A major
open problem in geometric complexity theory (GCT) is to determine whether VBP
is closed under approximation. The power of approximation is well understood
for some restricted models of computation, e.g., the class of depth-two
circuits, read-once oblivious ABPs (ROABP), monotone ABPs, depth-three circuits
of bounded top fan-in, and width-two ABPs. The former three classes are known
to be closed under approximation [Bl"{a}ser, Ikenmeyer, Mahajan, Pandey, and
Saurabh (2020)], whereas the approximative closure of the last one captures the
whole class of polynomial families computable by polynomial-sized formulas
[Bringmann, Ikenmeyer, and Zuiddam (2017)].
</p>
<p>In this work, we consider the subclass of VBP computed by the determinant of
a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where for each $1\leq
i \leq n$, $A_i$ is of rank one. It has been studied extensively
[Edmonds(1968), Edmonds(1979)] and efficient identity testing algorithms are
known [Lov"{a}sz (1989), Gurjar and Thierauf (2020)]. We show that this class
is closed under approximation. In the language of algebraic geometry, we show
that the set obtained by taking coordinatewise products of pairs of points from
(the Pl\"{u}cker embedding of) a Grassmannian variety is closed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09984'>The Noncommutative Edmonds' Problem Re-visited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Abhranil Chatterjee, Partha Mukhopadhyay</p><p>Let $T$ be a matrix whose entries are linear forms over the noncommutative
variables $x_1, x_2, \ldots, x_n$. The noncommutative Edmonds' problem
(NSINGULAR) aims to determine whether $T$ is invertible in the free skew field
generated by $x_1,x_2,\ldots,x_n$. Currently, there are three different
deterministic polynomial-time algorithms to solve this problem: using operator
scaling [Garg, Gurvits, Oliveira, and Wigserdon (2016)], algebraic methods
[Ivanyos, Qiao, and Subrahmanyam (2018)], and convex optimization [Hamada and
Hirai (2021)].
</p>
<p>In this paper, we present a simpler algorithm for the NSINGULAR problem.
While our algorithmic template is similar to the one in Ivanyos et. al.(2018),
it significantly differs in its implementation of the rank increment step.
Instead of computing the limit of a second Wong sequence, we reduce the problem
to the polynomial identity testing (PIT) of noncommutative algebraic branching
programs (ABPs).
</p>
<p>This enables us to bound the bit-complexity of the algorithm over
$\mathbb{Q}$ without requiring special care. Moreover, the rank increment step
can be implemented in quasipolynomial-time even without an explicit description
of the coefficient matrices in $T$. This is possible by exploiting the
connection with the black-box PIT of noncommutative ABPs [Forbes and Shpilka
(2013)].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1">Abhranil Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukhopadhyay_P/0/1/0/all/0/1">Partha Mukhopadhyay</a></p><p>Let $T$ be a matrix whose entries are linear forms over the noncommutative
variables $x_1, x_2, \ldots, x_n$. The noncommutative Edmonds' problem
(NSINGULAR) aims to determine whether $T$ is invertible in the free skew field
generated by $x_1,x_2,\ldots,x_n$. Currently, there are three different
deterministic polynomial-time algorithms to solve this problem: using operator
scaling [Garg, Gurvits, Oliveira, and Wigserdon (2016)], algebraic methods
[Ivanyos, Qiao, and Subrahmanyam (2018)], and convex optimization [Hamada and
Hirai (2021)].
</p>
<p>In this paper, we present a simpler algorithm for the NSINGULAR problem.
While our algorithmic template is similar to the one in Ivanyos et. al.(2018),
it significantly differs in its implementation of the rank increment step.
Instead of computing the limit of a second Wong sequence, we reduce the problem
to the polynomial identity testing (PIT) of noncommutative algebraic branching
programs (ABPs).
</p>
<p>This enables us to bound the bit-complexity of the algorithm over
$\mathbb{Q}$ without requiring special care. Moreover, the rank increment step
can be implemented in quasipolynomial-time even without an explicit description
of the coefficient matrices in $T$. This is possible by exploiting the
connection with the black-box PIT of noncommutative ABPs [Forbes and Shpilka
(2013)].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09995'>Algorithmic Decorrelation and Planted Clique in Dependent Random Graphs: The Case of Extra Triangles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guy Bresler, Chenghao Guo, Yury Polyanskiy</p><p>We aim to understand the extent to which the noise distribution in a planted
signal-plus-noise problem impacts its computational complexity. To that end, we
consider the planted clique and planted dense subgraph problems, but in a
different ambient graph. Instead of Erd\H{o}s-R\'enyi $G(n,p)$, which has
independent edges, we take the ambient graph to be the \emph{random graph with
triangles} (RGT) obtained by adding triangles to $G(n,p)$. We show that the RGT
can be efficiently mapped to the corresponding $G(n,p)$, and moreover, that the
planted clique (or dense subgraph) is approximately preserved under this
mapping. This constitutes the first average-case reduction transforming
dependent noise to independent noise. Together with the easier direction of
mapping the ambient graph from Erd\H{o}s-R\'enyi to RGT, our results yield a
strong equivalence between models. In order to prove our results, we develop a
new general framework for reasoning about the validity of average-case
reductions based on \emph{low sensitivity to perturbations}.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Bresler_G/0/1/0/all/0/1">Guy Bresler</a>, <a href="http://arxiv.org/find/math/1/au:+Guo_C/0/1/0/all/0/1">Chenghao Guo</a>, <a href="http://arxiv.org/find/math/1/au:+Polyanskiy_Y/0/1/0/all/0/1">Yury Polyanskiy</a></p><p>We aim to understand the extent to which the noise distribution in a planted
signal-plus-noise problem impacts its computational complexity. To that end, we
consider the planted clique and planted dense subgraph problems, but in a
different ambient graph. Instead of Erd\H{o}s-R\'enyi $G(n,p)$, which has
independent edges, we take the ambient graph to be the \emph{random graph with
triangles} (RGT) obtained by adding triangles to $G(n,p)$. We show that the RGT
can be efficiently mapped to the corresponding $G(n,p)$, and moreover, that the
planted clique (or dense subgraph) is approximately preserved under this
mapping. This constitutes the first average-case reduction transforming
dependent noise to independent noise. Together with the easier direction of
mapping the ambient graph from Erd\H{o}s-R\'enyi to RGT, our results yield a
strong equivalence between models. In order to prove our results, we develop a
new general framework for reasoning about the validity of average-case
reductions based on \emph{low sensitivity to perturbations}.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10277'>Lower bounds on the Approximate Stabilizer Rank: A Probabilistic Approach</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Saeed Mehraban, Mehrdad Tahmasbi</p><p>The approximate stabilizer rank of a quantum state is the minimum number of
terms in any approximate decomposition of that state into stabilizer states.
Bravyi and Gosset showed that the approximate stabilizer rank of a so-called
"magic" state like $|T\rangle^{\otimes n}$, up to polynomial factors, is an
upper bound on the number of classical operations required to simulate an
arbitrary quantum circuit with Clifford gates and $n$ number of $T$ gates. As a
result, an exponential lower bound on this quantity seems inevitable. Despite
this intuition, several attempts using various techniques could not lead to a
better than a linear lower bound on the "exact" rank of $|T\rangle^{\otimes
n}$, meaning the minimal size of a decomposition that exactly produces the
state. However, an "approximate" rank is more realistically related to the cost
of simulating quantum circuits because exact rank is not robust to errors;
there are quantum states with exponentially large exact ranks but constant
approximate ranks even with arbitrarily small approximation parameters. No
lower bound better than $\tilde \Omega(\sqrt n)$ has been known for the
approximate rank. In this paper, we improve this lower bound to $\tilde \Omega
(n)$ for a wide range of the approximation parameters. Our approach is based on
a strong lower bound on the approximate rank of a quantum state sampled from
the Haar measure and a step-by-step analysis of the approximate rank of a
magic-state teleportation protocol to sample from the Haar measure.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Mehraban_S/0/1/0/all/0/1">Saeed Mehraban</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tahmasbi_M/0/1/0/all/0/1">Mehrdad Tahmasbi</a></p><p>The approximate stabilizer rank of a quantum state is the minimum number of
terms in any approximate decomposition of that state into stabilizer states.
Bravyi and Gosset showed that the approximate stabilizer rank of a so-called
"magic" state like $|T\rangle^{\otimes n}$, up to polynomial factors, is an
upper bound on the number of classical operations required to simulate an
arbitrary quantum circuit with Clifford gates and $n$ number of $T$ gates. As a
result, an exponential lower bound on this quantity seems inevitable. Despite
this intuition, several attempts using various techniques could not lead to a
better than a linear lower bound on the "exact" rank of $|T\rangle^{\otimes
n}$, meaning the minimal size of a decomposition that exactly produces the
state. However, an "approximate" rank is more realistically related to the cost
of simulating quantum circuits because exact rank is not robust to errors;
there are quantum states with exponentially large exact ranks but constant
approximate ranks even with arbitrarily small approximation parameters. No
lower bound better than $\tilde \Omega(\sqrt n)$ has been known for the
approximate rank. In this paper, we improve this lower bound to $\tilde \Omega
(n)$ for a wide range of the approximation parameters. Our approach is based on
a strong lower bound on the approximate rank of a quantum state sampled from
the Haar measure and a step-by-step analysis of the approximate rank of a
magic-state teleportation protocol to sample from the Haar measure.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10334'>Principal-Agent Boolean Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David Hyland, Julian Gutierrez, Michael Wooldridge</p><p>We introduce and study a computational version of the principal-agent problem
-- a classic problem in Economics that arises when a principal desires to
contract an agent to carry out some task, but has incomplete information about
the agent or their subsequent actions. The key challenge in this setting is for
the principal to design a contract for the agent such that the agent's
preferences are then aligned with those of the principal. We study this problem
using a variation of Boolean games, where multiple players each choose
valuations for Boolean variables under their control, seeking the satisfaction
of a personal goal, given as a Boolean logic formula. In our setting, the
principal can only observe some subset of these variables, and the principal
chooses a contract which rewards players on the basis of the assignments they
make for the variables that are observable to the principal. The principal's
challenge is to design a contract so that, firstly, the principal's goal is
achieved in some or all Nash equilibrium choices, and secondly, that the
principal is able to verify that their goal is satisfied. In this paper, we
formally define this problem and completely characterise the computational
complexity of the most relevant decision problems associated with it.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hyland_D/0/1/0/all/0/1">David Hyland</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_J/0/1/0/all/0/1">Julian Gutierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Wooldridge_M/0/1/0/all/0/1">Michael Wooldridge</a></p><p>We introduce and study a computational version of the principal-agent problem
-- a classic problem in Economics that arises when a principal desires to
contract an agent to carry out some task, but has incomplete information about
the agent or their subsequent actions. The key challenge in this setting is for
the principal to design a contract for the agent such that the agent's
preferences are then aligned with those of the principal. We study this problem
using a variation of Boolean games, where multiple players each choose
valuations for Boolean variables under their control, seeking the satisfaction
of a personal goal, given as a Boolean logic formula. In our setting, the
principal can only observe some subset of these variables, and the principal
chooses a contract which rewards players on the basis of the assignments they
make for the variables that are observable to the principal. The principal's
challenge is to design a contract so that, firstly, the principal's goal is
achieved in some or all Nash equilibrium choices, and secondly, that the
principal is able to verify that their goal is satisfied. In this paper, we
formally define this problem and completely characterise the computational
complexity of the most relevant decision problems associated with it.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09778'>Shortest Path to Boundary for Self-Intersecting Meshes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: He Chen, Elie Diaz, Cem Yuksel</p><p>We introduce a method for efficiently computing the exact shortest path to
the boundary of a mesh from a given internal point in the presence of
self-intersections. We provide a formal definition of shortest boundary paths
for self-intersecting objects and present a robust algorithm for computing the
actual shortest boundary path. The resulting method offers an effective
solution for collision and self-collision handling while simulating deformable
volumetric objects, using fast simulation techniques that provide no guarantees
on collision resolution. Our evaluation includes complex self-collision
scenarios with a large number of active contacts, showing that our method can
successfully handle them by introducing a relatively minor computational
overhead.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">He Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_E/0/1/0/all/0/1">Elie Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuksel_C/0/1/0/all/0/1">Cem Yuksel</a></p><p>We introduce a method for efficiently computing the exact shortest path to
the boundary of a mesh from a given internal point in the presence of
self-intersections. We provide a formal definition of shortest boundary paths
for self-intersecting objects and present a robust algorithm for computing the
actual shortest boundary path. The resulting method offers an effective
solution for collision and self-collision handling while simulating deformable
volumetric objects, using fast simulation techniques that provide no guarantees
on collision resolution. Our evaluation includes complex self-collision
scenarios with a large number of active contacts, showing that our method can
successfully handle them by introducing a relatively minor computational
overhead.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09925'>A Scalable Method for Readable Tree Layouts</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kathryn Gray, Mingwei Li, Reyan Ahmed, Md. Khaledur Rahman, Ariful Azad, Stephen Kobourov, Katy B&#xf6;rner</p><p>Large tree structures are ubiquitous and real-world relational datasets often
have information associated with nodes (e.g., labels or other attributes) and
edges (e.g., weights or distances) that need to be communicated to the viewers.
Yet, scalable, easy to read tree layouts are difficult to achieve. We consider
tree layouts to be readable if they meet some basic requirements: node labels
should not overlap, edges should not cross, edge lengths should be preserved,
and the output should be compact. There are many algorithms for drawing trees,
although very few take node labels or edge lengths into account, and none
optimizes all requirements above. With this in mind, we propose a new scalable
method for readable tree layouts. The algorithm guarantees that the layout has
no edge crossings and no label overlaps, and optimizes one of the remaining
aspects: desired edge lengths and compactness. We evaluate the performance of
the new algorithm by comparison with related earlier approaches using several
real-world datasets, ranging from a few thousand nodes to hundreds of thousands
of nodes. Tree layout algorithms can be used to visualize large general graphs,
by extracting a hierarchy of progressively larger trees. We illustrate this
functionality by presenting several map-like visualizations generated by the
new tree layout algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gray_K/0/1/0/all/0/1">Kathryn Gray</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mingwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_R/0/1/0/all/0/1">Reyan Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Md. Khaledur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Azad_A/0/1/0/all/0/1">Ariful Azad</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobourov_S/0/1/0/all/0/1">Stephen Kobourov</a>, <a href="http://arxiv.org/find/cs/1/au:+Borner_K/0/1/0/all/0/1">Katy B&#xf6;rner</a></p><p>Large tree structures are ubiquitous and real-world relational datasets often
have information associated with nodes (e.g., labels or other attributes) and
edges (e.g., weights or distances) that need to be communicated to the viewers.
Yet, scalable, easy to read tree layouts are difficult to achieve. We consider
tree layouts to be readable if they meet some basic requirements: node labels
should not overlap, edges should not cross, edge lengths should be preserved,
and the output should be compact. There are many algorithms for drawing trees,
although very few take node labels or edge lengths into account, and none
optimizes all requirements above. With this in mind, we propose a new scalable
method for readable tree layouts. The algorithm guarantees that the layout has
no edge crossings and no label overlaps, and optimizes one of the remaining
aspects: desired edge lengths and compactness. We evaluate the performance of
the new algorithm by comparison with related earlier approaches using several
real-world datasets, ranging from a few thousand nodes to hundreds of thousands
of nodes. Tree layout algorithms can be used to visualize large general graphs,
by extracting a hierarchy of progressively larger trees. We illustrate this
functionality by presenting several map-like visualizations generated by the
new tree layout algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10023'>An Efficient Solution Space Exploring and Descent Method for Packing Equal Spheres in a Sphere</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jianrong Zhou, Shuo Ren, Kun He, Yanli Liu, Chu-Min Li</p><p>The problem of packing equal spheres in a spherical container is a classic
global optimization problem, which has attracted enormous studies in academia
and found various applications in industry. This problem is computationally
challenging, and many efforts focus on small-scale instances with the number of
spherical items less than 200 in the literature. In this work, we propose an
efficient local search heuristic algorithm named solution space exploring and
descent for solving this problem, which can quantify the solution's quality to
determine the number of exploring actions and quickly discover a high-quality
solution. Besides, we propose an adaptive neighbor object maintenance method to
speed up the convergence of the continuous optimization process and reduce the
time consumption. Computational experiments on a large number of benchmark
instances with $5 \leq n \leq 400$ spherical items show that our algorithm
significantly outperforms the state-of-the-art algorithm. In particular, it
improves the 274 best-known results and matches the 84 best-known results out
of the 396 well-known benchmark instances.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jianrong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Shuo Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yanli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chu-Min Li</a></p><p>The problem of packing equal spheres in a spherical container is a classic
global optimization problem, which has attracted enormous studies in academia
and found various applications in industry. This problem is computationally
challenging, and many efforts focus on small-scale instances with the number of
spherical items less than 200 in the literature. In this work, we propose an
efficient local search heuristic algorithm named solution space exploring and
descent for solving this problem, which can quantify the solution's quality to
determine the number of exploring actions and quickly discover a high-quality
solution. Besides, we propose an adaptive neighbor object maintenance method to
speed up the convergence of the continuous optimization process and reduce the
time consumption. Computational experiments on a large number of benchmark
instances with $5 \leq n \leq 400$ spherical items show that our algorithm
significantly outperforms the state-of-the-art algorithm. In particular, it
improves the 274 best-known results and matches the 84 best-known results out
of the 396 well-known benchmark instances.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10341'>Convex Cover and Hidden Set in Funnel Polygons</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Reilly Browne</p><p>We present linear-time algorithms for both maximum hidden set and minimum
convex cover in funnel polygons. These algorithms show that funnel polygons are
"homestead" polygons, i.e. polygons for which the hidden set number and the
convex cover number coincide. We extend the algorithm to apply to maximum
hidden vertex set and use the result to give a 2-approximation for all three
problems in pseudotriangles.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Browne_R/0/1/0/all/0/1">Reilly Browne</a></p><p>We present linear-time algorithms for both maximum hidden set and minimum
convex cover in funnel polygons. These algorithms show that funnel polygons are
"homestead" polygons, i.e. polygons for which the hidden set number and the
convex cover number coincide. We extend the algorithm to apply to maximum
hidden vertex set and use the result to give a 2-approximation for all three
problems in pseudotriangles.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10389'>Cache-Oblivious Parallel Convex Hull in the Binary Forking Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Reilly Browne, Rezaul Chowdhury, Shih-Yu Tsai, Yimin Zhu</p><p>We present two cache-oblivious sorting-based convex hull algorithms in the
Binary Forking Model. The first is an algorithm for a presorted set of points
which achieves $O(n)$ work, $O(\log n)$ span, and $O(n/B)$ serial cache
complexity, where $B$ is the cache line size. These are all optimal worst-case
bounds for cache-oblivious algorithms in the Binary Forking Model. The second
adapts Cole and Ramachandran's cache-oblivious sorting algorithm, matching its
properties including achieving $O(n \log n)$ work, $O(\log n \log \log n)$
span, and $O(n/B \log_M n)$ serial cache complexity. Here $M$ is the size of
the private cache.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Browne_R/0/1/0/all/0/1">Reilly Browne</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_R/0/1/0/all/0/1">Rezaul Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_S/0/1/0/all/0/1">Shih-Yu Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yimin Zhu</a></p><p>We present two cache-oblivious sorting-based convex hull algorithms in the
Binary Forking Model. The first is an algorithm for a presorted set of points
which achieves $O(n)$ work, $O(\log n)$ span, and $O(n/B)$ serial cache
complexity, where $B$ is the cache line size. These are all optimal worst-case
bounds for cache-oblivious algorithms in the Binary Forking Model. The second
adapts Cole and Ramachandran's cache-oblivious sorting algorithm, matching its
properties including achieving $O(n \log n)$ work, $O(\log n \log \log n)$
span, and $O(n/B \log_M n)$ serial cache complexity. Here $M$ is the size of
the private cache.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09668'>Mean Estimation Under Heterogeneous Privacy: Some Privacy Can Be Free</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Syomantak Chaudhuri, Thomas A. Courtade</p><p>Differential Privacy (DP) is a well-established framework to quantify privacy
loss incurred by any algorithm. Traditional DP formulations impose a uniform
privacy requirement for all users, which is often inconsistent with real-world
scenarios in which users dictate their privacy preferences individually. This
work considers the problem of mean estimation under heterogeneous DP
constraints, where each user can impose their own distinct privacy level. The
algorithm we propose is shown to be minimax optimal when there are two groups
of users with distinct privacy levels. Our results elicit an interesting
saturation phenomenon that occurs as one group's privacy level is relaxed,
while the other group's privacy level remains constant. Namely, after a certain
point, further relaxing the privacy requirement of the former group does not
improve the performance of the minimax optimal mean estimator. Thus, the
central server can offer a certain degree of privacy without any sacrifice in
performance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1">Syomantak Chaudhuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Courtade_T/0/1/0/all/0/1">Thomas A. Courtade</a></p><p>Differential Privacy (DP) is a well-established framework to quantify privacy
loss incurred by any algorithm. Traditional DP formulations impose a uniform
privacy requirement for all users, which is often inconsistent with real-world
scenarios in which users dictate their privacy preferences individually. This
work considers the problem of mean estimation under heterogeneous DP
constraints, where each user can impose their own distinct privacy level. The
algorithm we propose is shown to be minimax optimal when there are two groups
of users with distinct privacy levels. Our results elicit an interesting
saturation phenomenon that occurs as one group's privacy level is relaxed,
while the other group's privacy level remains constant. Namely, after a certain
point, further relaxing the privacy requirement of the former group does not
improve the performance of the minimax optimal mean estimator. Thus, the
central server can offer a certain degree of privacy without any sacrifice in
performance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.09752'>Finding Maximal Exact Matches in Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicola Rizzo, Manuel C&#xe1;ceres, Veli M&#xe4;kinen</p><p>We study the problem of finding maximal exact matches (MEMs) between a query
string $Q$ and a labeled graph $G$. MEMs are an important class of seeds, often
used in seed-chain-extend type of practical alignment methods because of their
strong connections to classical metrics. A principled way to speed up chaining
is to limit the number of MEMs by considering only MEMs of length at least
$\kappa$ ($\kappa$-MEMs). However, on arbitrary input graphs, the problem of
finding MEMs cannot be solved in truly sub-quadratic time under SETH (Equi et
al., ICALP 2019) even on acyclic graphs. In this paper we show an $O(n\cdot L
\cdot d^{L-1} + m + M_{\kappa,L})$-time algorithm finding all $\kappa$-MEMs
between $Q$ and $G$ spanning exactly $L$ nodes in $G$, where $n$ is the total
length of node labels, $d$ is the maximum degree of a node in $G$, $m = |Q|$,
and $M_{\kappa,L}$ is the number of output MEMs. We use this algorithm to
develop a $\kappa$-MEM finding solution on indexable Elastic Founder Graphs
(Equi et al., Algorithmica 2022) running in time $O(nH^2 + m + M_\kappa)$,
where $H$ is the maximum number of nodes in a block, and $M_\kappa$ is the
total number of $\kappa$-MEMs. Our results generalize to the analysis of
multiple query strings (MEMs between $G$ and any of the strings). Additionally,
we provide some preliminary experimental results showing that the number of
graph MEMs is orders of magnitude smaller than the number of string MEMs of the
corresponding concatenated collection.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rizzo_N/0/1/0/all/0/1">Nicola Rizzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Caceres_M/0/1/0/all/0/1">Manuel C&#xe1;ceres</a>, <a href="http://arxiv.org/find/cs/1/au:+Makinen_V/0/1/0/all/0/1">Veli M&#xe4;kinen</a></p><p>We study the problem of finding maximal exact matches (MEMs) between a query
string $Q$ and a labeled graph $G$. MEMs are an important class of seeds, often
used in seed-chain-extend type of practical alignment methods because of their
strong connections to classical metrics. A principled way to speed up chaining
is to limit the number of MEMs by considering only MEMs of length at least
$\kappa$ ($\kappa$-MEMs). However, on arbitrary input graphs, the problem of
finding MEMs cannot be solved in truly sub-quadratic time under SETH (Equi et
al., ICALP 2019) even on acyclic graphs. In this paper we show an $O(n\cdot L
\cdot d^{L-1} + m + M_{\kappa,L})$-time algorithm finding all $\kappa$-MEMs
between $Q$ and $G$ spanning exactly $L$ nodes in $G$, where $n$ is the total
length of node labels, $d$ is the maximum degree of a node in $G$, $m = |Q|$,
and $M_{\kappa,L}$ is the number of output MEMs. We use this algorithm to
develop a $\kappa$-MEM finding solution on indexable Elastic Founder Graphs
(Equi et al., Algorithmica 2022) running in time $O(nH^2 + m + M_\kappa)$,
where $H$ is the maximum number of nodes in a block, and $M_\kappa$ is the
total number of $\kappa$-MEMs. Our results generalize to the analysis of
multiple query strings (MEMs between $G$ and any of the strings). Additionally,
we provide some preliminary experimental results showing that the number of
graph MEMs is orders of magnitude smaller than the number of string MEMs of the
corresponding concatenated collection.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10108'>List 3-Coloring on Comb-Convex and Caterpillar-Convex Bipartite Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Banu Baklan &#x15e;en, &#xd6;znur Ya&#x15f;ar Diner, Thomas Erlebach</p><p>Given a graph $G=(V, E)$ and a list of available colors $L(v)$ for each
vertex $v\in V$, where $L(v) \subseteq \{1, 2, \ldots, k\}$, List $k$-Coloring
refers to the problem of assigning colors to the vertices of $G$ so that each
vertex receives a color from its own list and no two neighboring vertices
receive the same color. The decision version of the problem List $3$-Coloring
is NP-complete even for bipartite graphs, and its complexity on comb-convex
bipartite graphs has been an open problem. We give a polynomial-time algorithm
to solve List $3$-Coloring for caterpillar-convex bipartite graphs, a
superclass of comb-convex bipartite graphs. We also give a polynomial-time
recognition algorithm for the class of caterpillar-convex bipartite graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sen_B/0/1/0/all/0/1">Banu Baklan &#x15e;en</a>, <a href="http://arxiv.org/find/cs/1/au:+Diner_O/0/1/0/all/0/1">&#xd6;znur Ya&#x15f;ar Diner</a>, <a href="http://arxiv.org/find/cs/1/au:+Erlebach_T/0/1/0/all/0/1">Thomas Erlebach</a></p><p>Given a graph $G=(V, E)$ and a list of available colors $L(v)$ for each
vertex $v\in V$, where $L(v) \subseteq \{1, 2, \ldots, k\}$, List $k$-Coloring
refers to the problem of assigning colors to the vertices of $G$ so that each
vertex receives a color from its own list and no two neighboring vertices
receive the same color. The decision version of the problem List $3$-Coloring
is NP-complete even for bipartite graphs, and its complexity on comb-convex
bipartite graphs has been an open problem. We give a polynomial-time algorithm
to solve List $3$-Coloring for caterpillar-convex bipartite graphs, a
superclass of comb-convex bipartite graphs. We also give a polynomial-time
recognition algorithm for the class of caterpillar-convex bipartite graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10292'>Linear Query Approximation Algorithms for Non-monotone Submodular Maximization under Knapsack Constraint</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Canh V. Pham, Tan D. Tran, Dung T.K. Ha, My T. Thai</p><p>This work, for the first time, introduces two constant factor approximation
algorithms with linear query complexity for non-monotone submodular
maximization over a ground set of size $n$ subject to a knapsack constraint,
$\mathsf{DLA}$ and $\mathsf{RLA}$. $\mathsf{DLA}$ is a deterministic algorithm
that provides an approximation factor of $6+\epsilon$ while $\mathsf{RLA}$ is a
randomized algorithm with an approximation factor of $4+\epsilon$. Both run in
$O(n \log(1/\epsilon)/\epsilon)$ query complexity. The key idea to obtain a
constant approximation ratio with linear query lies in: (1) dividing the ground
set into two appropriate subsets to find the near-optimal solution over these
subsets with linear queries, and (2) combining a threshold greedy with
properties of two disjoint sets or a random selection process to improve
solution quality. In addition to the theoretical analysis, we have evaluated
our proposed solutions with three applications: Revenue Maximization, Image
Summarization, and Maximum Weighted Cut, showing that our algorithms not only
return comparative results to state-of-the-art algorithms but also require
significantly fewer queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pham_C/0/1/0/all/0/1">Canh V. Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1">Tan D. Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ha_D/0/1/0/all/0/1">Dung T.K. Ha</a>, <a href="http://arxiv.org/find/cs/1/au:+Thai_M/0/1/0/all/0/1">My T. Thai</a></p><p>This work, for the first time, introduces two constant factor approximation
algorithms with linear query complexity for non-monotone submodular
maximization over a ground set of size $n$ subject to a knapsack constraint,
$\mathsf{DLA}$ and $\mathsf{RLA}$. $\mathsf{DLA}$ is a deterministic algorithm
that provides an approximation factor of $6+\epsilon$ while $\mathsf{RLA}$ is a
randomized algorithm with an approximation factor of $4+\epsilon$. Both run in
$O(n \log(1/\epsilon)/\epsilon)$ query complexity. The key idea to obtain a
constant approximation ratio with linear query lies in: (1) dividing the ground
set into two appropriate subsets to find the near-optimal solution over these
subsets with linear queries, and (2) combining a threshold greedy with
properties of two disjoint sets or a random selection process to improve
solution quality. In addition to the theoretical analysis, we have evaluated
our proposed solutions with three applications: Revenue Maximization, Image
Summarization, and Maximum Weighted Cut, showing that our algorithms not only
return comparative results to state-of-the-art algorithms but also require
significantly fewer queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-18T00:30:00Z">Thursday, May 18 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, May 17
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/05/17/permutation-supersequences-shortest.html'>Permutation supersequences and shortest paths</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          You may have heard of permutation superpatterns and superpermutations, but have you heard of permutation supersequences? They turn out to be closely related to how quickly we can find shortest paths in graphs with negative edge weights using the BellmanâFord algorithm.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>You may have heard of <a href="https://en.wikipedia.org/wiki/Superpattern">permutation superpatterns</a> and <a href="https://en.wikipedia.org/wiki/Superpermutation">superpermutations</a>, but have you heard of permutation supersequences? They turn out to be closely related to how quickly we can find shortest paths in graphs with negative edge weights using the <a href="https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm">BellmanâFord algorithm</a>.</p>

<p>Superpatterns, superpermutations, and supersequences are all sequences of symbols that somehow contain each permutation of their symbols. But they use different definitions of âcontainâ, causing them to have different lengths. For supersequences, the goal is to have every permutation as a subsequence: its symbols must appear in the same order, but can be widely spaced. One way to create a supersequence of \(n\) symbols, but not the best way, is to repeat all of them \(n\) times: 1234123412341234. You can do a little better by alternating ascending and descending order, saving one symbol per repetition: 1234321234321. But this is still not optimal. According to Oliver Tan in âSkip letters for short supersequence of all permutationsâ (<em>Disc. Math.</em> 2022, <a href="https://doi.org/10.1016/j.disc.2022.113070">doi:10.1016/j.disc.2022.113070</a>), calculating the exact length of the shortest supersequence of \(n\) symbols, as a function <span style="white-space:nowrap">of \(n\),</span> is still an open problem. Tan finds sequences of <span style="white-space:nowrap">length \(n^2-\tfrac52n+O(n^{2/3})\),</span> and cites a bound of Kleitman and Kwiatkowski showing that they must have <span style="white-space:nowrap">length \(n^2-O(n^{7/4})\).</span> So we have pretty accurate bounds on how short they can be: <span style="white-space:nowrap">near \(n^2\).</span></p>

<p>Now letâs continue to look at sequences and subsequences, but change up what they have to contain. Any permutation has \(n-1\) consecutive pairs of symbols. I want to find a sequence of pairs that for each permutation contains its \(n-1\) pairs, in their correct order. For instance, a four-symbol pair sequence should contain the three pairs 12, 23, and 34, in that order, coming from the permutation 1234, and it should also contain the other 23 triples of pairs coming from the other 23 permutations of the four symbols.</p>

<p>Why? Because thatâs what some versions of the BellmanâFord algorithm do! Suppose we want to find shortest paths from some starting vertex \(v_0\) to all other vertices in a complete directed graph. We can initialize tentative distances \(D[i]\) for all other vertices <span style="white-space:nowrap">\(v_i\), \(i&gt;0\)</span> to be the lengths of the single edges from \(v_0\) to those vertices, and then repeatedly <em>relax</em> a pair \((i,j)\) by <span style="white-space:nowrap">setting \(D[j]=\min\{D[j],D[i]+\operatorname{len}(v_i,v_j)\}\).</span> If we relax all of the consecutive pairs of vertices along a shortest path, in order, this will cause the tentative distance for the endpoint of the path to equal its correct shortest path distance.</p>

<p>So one way to get a correct shortest path algorithm is simply to choose a supersequence of the consecutive pairs of all permutations, and update the tentative distances in this order. You might notice that such an algorithm doesnât pay any attention to the results of its calculation; it just performs its pairwise calculations for the entire supersequence, in a set order. Iâll call an algorithm like this, that chooses its update steps ahead of time instead of taking account of what has happened so far, <em>non-adaptive</em>. As a sequential algorithm, it would be better to be a little smarter, and use past information to guide future steps, but non-adaptive versions of BellmanâFord turn out to be widely used in contexts where there is no centralized control, such as <a href="https://en.wikipedia.org/wiki/Distance-vector_routing_protocol">distance vector routing</a> on the internet.</p>

<p>So to figure out how efficient BellmanâFord can be, we need to figure out how short these pair supersequences can be. Frustratingly, I donât know very tight bounds for this problem. I can at least find out the exponent of the leading term in the length of these sequences (itâs cubic), but its constant factor eludes me.</p>

<p>As an upper bound, we can look at what various versions of the BellmanâFord algorithm actually do. The simplest choice is just to repeat all pairs of indexes, \(n-1\) times: for four symbols (graphs with five vertices, but not counting the start), repeat 12â13â14â21â23â24â31â32â34â41â42â43 three times. For \(n\) symbols, this would require a total of \(\bigl(1-o(1)\bigr)n^3\) pairs. A technique of Yen improves this by listing the ascending pairs in ascending order and then the descending pairs in descending order: 12â13â14â23â24â34â43â42â32â41â31â21. Such a sequence can cover the pairs from any run of ascending symbols followed by any run of descending symbols: for instance, it would by itself cover the pairs from the permutations 1234, 1243, 1342, 1432, 2341, 2431, 3421, and 4321, which each consist of one ascending and one descending run. In general, you only need to repeat this ascending-descending pair sequence \(\lceil n/2\rceil\) times to cover all ascending and descending runs, giving pair supersequences of <span style="white-space:nowrap">length \(\bigl(\tfrac12-o(1)\bigr)n^3\).</span> And if youâre willing to tolerate a randomized algorithm that is correct only with high probability instead of with certainty, <a href="/blog/2011/04/11/randomized-bellmanford.html">a paper of mine with Michael Bannister from 2012</a> randomly permutes the symbols before using Yenâs ascending-descending method to achieve <span style="white-space:nowrap">length \(\bigl(\tfrac13+o(1)\bigr)n^3\).</span></p>

<p>My newest preprint, âLower bounds for non-adaptive shortest path relaxationâ (<a href="https://arxiv.org/abs/2305.09230">arXiv:2305.09230</a>, to appear at WADS), as the title suggests, looks at the lower bound side of the same problem. It shows that deterministically chosen sequences of pairs must have length at least \(\bigl(\tfrac16-o(1)\bigr)n^3\) and that random sequences (correct with high probability) must have length at least \(\bigl(\tfrac1{12}-o(1)\bigr)n^3\). It also contains analogous bounds for graphs that are not complete. However, these lower bounds are still far from the upper bounds. They are not even close enough to tell me whether randomized BellmanâFord is really better than deterministic BellmanâFord (in this non-adaptive setting) or whether a better deterministic pair sequence would beat the random one from my 2012 paper.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/110384942112779003">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-17T09:11:00Z">Wednesday, May 17 2023, 09:11</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
