<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-05-26T20:30:42Z">Friday, May 26 2023, 20:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, May 26
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/05/26/tcs-talk-wednesday-may-31-paul-golz-harvard-university/'>TCS+ talk: Wednesday, May 31 — Paul Gölz, Harvard University</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, May 31th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Paul Gölz from Harvard University will speak about &#8220;News from Algorithmic Democracy: Proportional Representation for Preferences and Demographics&#8221; (abstract below). You can reserve a spot as an individual [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, May 31th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Paul Gölz</strong> from Harvard University will speak about &#8220;<em>News from Algorithmic Democracy: Proportional Representation for Preferences and Demographics</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: How do you fill a knapsack with city projects to fund, in a way that aligns with voters’ preferences? And how do you choose a committee that represents the population’s makeup in terms of gender, age, etc.? Both questions are central to experiments with new forms of democracy in practice, and both have spurred an exploration for the right algorithms in computational social choice. In this talk, I will survey advances along these thrusts: proposed algorithms, guarantees offered and sought after, as well as technical challenges and connections.</p></blockquote>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-26T06:40:08Z">Friday, May 26 2023, 06:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.15861'>On the Weisfeiler-Leman dimension of permutation graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jin Guo, Alexander L. Gavrilyuk, Ilia Ponomarenko</p><p>It is proved that the Weisfeiler-Leman dimension of the class of permutation
graphs is at most 18. Previously it was only known that this dimension is
finite (Gru{\ss}ien, 2017).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Guo_J/0/1/0/all/0/1">Jin Guo</a>, <a href="http://arxiv.org/find/math/1/au:+Gavrilyuk_A/0/1/0/all/0/1">Alexander L. Gavrilyuk</a>, <a href="http://arxiv.org/find/math/1/au:+Ponomarenko_I/0/1/0/all/0/1">Ilia Ponomarenko</a></p><p>It is proved that the Weisfeiler-Leman dimension of the class of permutation
graphs is at most 18. Previously it was only known that this dimension is
finite (Gru{\ss}ien, 2017).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-26T00:30:00Z">Friday, May 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.15917'>A Fast Algorithm for Consistency Checking Partially Ordered Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Leif Eriksson, Victor Lagerkvist</p><p>Partially ordered models of time occur naturally in applications where agents
or processes cannot perfectly communicate with each other, and can be traced
back to the seminal work of Lamport. In this paper we consider the problem of
deciding if a (likely incomplete) description of a system of events is
consistent, the network consistency problem for the point algebra of partially
ordered time (POT). While the classical complexity of this problem has been
fully settled, comparably little is known of the fine-grained complexity of POT
except that it can be solved in $O^*((0.368n)^n)$ time by enumerating ordered
partitions. We construct a much faster algorithm with a run-time bounded by
$O^*((0.26n)^n)$. This is achieved by a sophisticated enumeration of structures
similar to total orders, which are then greedily expanded toward a solution.
While similar ideas have been explored earlier for related problems it turns
out that the analysis for POT is non-trivial and requires significant new
ideas.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Eriksson_L/0/1/0/all/0/1">Leif Eriksson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lagerkvist_V/0/1/0/all/0/1">Victor Lagerkvist</a></p><p>Partially ordered models of time occur naturally in applications where agents
or processes cannot perfectly communicate with each other, and can be traced
back to the seminal work of Lamport. In this paper we consider the problem of
deciding if a (likely incomplete) description of a system of events is
consistent, the network consistency problem for the point algebra of partially
ordered time (POT). While the classical complexity of this problem has been
fully settled, comparably little is known of the fine-grained complexity of POT
except that it can be solved in $O^*((0.368n)^n)$ time by enumerating ordered
partitions. We construct a much faster algorithm with a run-time bounded by
$O^*((0.26n)^n)$. This is achieved by a sophisticated enumeration of structures
similar to total orders, which are then greedily expanded toward a solution.
While similar ideas have been explored earlier for related problems it turns
out that the analysis for POT is non-trivial and requires significant new
ideas.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-26T00:30:00Z">Friday, May 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.15950'>Improved Algorithms for Allen's Interval Algebra by Dynamic Programming with Sublinear Partitioning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Leif Eriksson, Victor Lagerkvist</p><p>Allen's interval algebra is one of the most well-known calculi in qualitative
temporal reasoning with numerous applications in artificial intelligence.
Recently, there has been a surge of improvements in the fine-grained complexity
of NP-hard reasoning tasks, improving the running time from the naive
$2^{O(n^2)}$ to $O^*((1.0615n)^{n})$, with even faster algorithms for unit
intervals a bounded number of overlapping intervals (the $O^*(\cdot)$ notation
suppresses polynomial factors). Despite these improvements the best known lower
bound is still only $2^{o(n)}$ (under the exponential-time hypothesis) and
major improvements in either direction seemingly require fundamental advances
in computational complexity. In this paper we propose a novel framework for
solving NP-hard qualitative reasoning problems which we refer to as dynamic
programming with sublinear partitioning. Using this technique we obtain a major
improvement of $O^*((\frac{cn}{\log{n}})^{n})$ for Allen's interval algebra. To
demonstrate that the technique is applicable to more domains we apply it to a
problem in qualitative spatial reasoning, the cardinal direction point algebra,
and solve it in $O^*((\frac{cn}{\log{n}})^{2n/3})$ time. Hence, not only do we
significantly advance the state-of-the-art for NP-hard qualitative reasoning
problems, but obtain a novel algorithmic technique that is likely applicable to
many problems where $2^{O(n)}$ time algorithms are unlikely.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Eriksson_L/0/1/0/all/0/1">Leif Eriksson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lagerkvist_V/0/1/0/all/0/1">Victor Lagerkvist</a></p><p>Allen's interval algebra is one of the most well-known calculi in qualitative
temporal reasoning with numerous applications in artificial intelligence.
Recently, there has been a surge of improvements in the fine-grained complexity
of NP-hard reasoning tasks, improving the running time from the naive
$2^{O(n^2)}$ to $O^*((1.0615n)^{n})$, with even faster algorithms for unit
intervals a bounded number of overlapping intervals (the $O^*(\cdot)$ notation
suppresses polynomial factors). Despite these improvements the best known lower
bound is still only $2^{o(n)}$ (under the exponential-time hypothesis) and
major improvements in either direction seemingly require fundamental advances
in computational complexity. In this paper we propose a novel framework for
solving NP-hard qualitative reasoning problems which we refer to as dynamic
programming with sublinear partitioning. Using this technique we obtain a major
improvement of $O^*((\frac{cn}{\log{n}})^{n})$ for Allen's interval algebra. To
demonstrate that the technique is applicable to more domains we apply it to a
problem in qualitative spatial reasoning, the cardinal direction point algebra,
and solve it in $O^*((\frac{cn}{\log{n}})^{2n/3})$ time. Hence, not only do we
significantly advance the state-of-the-art for NP-hard qualitative reasoning
problems, but obtain a novel algorithmic technique that is likely applicable to
many problems where $2^{O(n)}$ time algorithms are unlikely.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-26T00:30:00Z">Friday, May 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.15721'>An exponential bound for simultaneous embeddings of planar graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ritesh Goenka, Pardis Semnani, Chi Hoi Yip</p><p>We show that there are $O(n \cdot 4^{n/11})$ planar graphs on $n$ vertices
which do not admit a simultaneous straight-line embedding on any $n$-point set
in the plane. In particular, this improves the best known bound $O(n!)$
significantly.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Goenka_R/0/1/0/all/0/1">Ritesh Goenka</a>, <a href="http://arxiv.org/find/math/1/au:+Semnani_P/0/1/0/all/0/1">Pardis Semnani</a>, <a href="http://arxiv.org/find/math/1/au:+Yip_C/0/1/0/all/0/1">Chi Hoi Yip</a></p><p>We show that there are $O(n \cdot 4^{n/11})$ planar graphs on $n$ vertices
which do not admit a simultaneous straight-line embedding on any $n$-point set
in the plane. In particular, this improves the best known bound $O(n!)$
significantly.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-26T00:30:00Z">Friday, May 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.15804'>Smoothed Complexity of SWAP in Local Graph Partitioning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xi Chen, Chenghao Guo, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Mihalis Yannakakis</p><p>We give the first quasipolynomial upper bound $\phi n^{\text{polylog}(n)}$
for the smoothed complexity of the SWAP algorithm for local Graph Partitioning
(also known as Bisection Width), where $n$ is the number of nodes in the graph
and $\phi$ is a parameter that measures the magnitude of perturbations applied
on its edge weights. More generally, we show that the same quasipolynomial
upper bound holds for the smoothed complexity of the 2-FLIP algorithm for any
binary Maximum Constraint Satisfaction Problem, including local Max-Cut, for
which similar bounds were only known for $1$-FLIP. Our results are based on an
analysis of cycles formed in long sequences of double flips, showing that it is
unlikely for every move in a long sequence to incur a positive but small
improvement in the cut weight.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Chenghao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlatakis_Gkaragkounis_E/0/1/0/all/0/1">Emmanouil-Vasileios Vlatakis-Gkaragkounis</a>, <a href="http://arxiv.org/find/cs/1/au:+Yannakakis_M/0/1/0/all/0/1">Mihalis Yannakakis</a></p><p>We give the first quasipolynomial upper bound $\phi n^{\text{polylog}(n)}$
for the smoothed complexity of the SWAP algorithm for local Graph Partitioning
(also known as Bisection Width), where $n$ is the number of nodes in the graph
and $\phi$ is a parameter that measures the magnitude of perturbations applied
on its edge weights. More generally, we show that the same quasipolynomial
upper bound holds for the smoothed complexity of the 2-FLIP algorithm for any
binary Maximum Constraint Satisfaction Problem, including local Max-Cut, for
which similar bounds were only known for $1$-FLIP. Our results are based on an
analysis of cycles formed in long sequences of double flips, showing that it is
unlikely for every move in a long sequence to incur a positive but small
improvement in the cut weight.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-26T00:30:00Z">Friday, May 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.15452'>Adaptive Data Analysis in a Balanced Adversarial Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kobbi Nissim, Uri Stemmer, Eliad Tsfadia</p><p>In adaptive data analysis, a mechanism gets $n$ i.i.d. samples from an
unknown distribution $D$, and is required to provide accurate estimations to a
sequence of adaptively chosen statistical queries with respect to $D$. Hardt
and Ullman (FOCS 2014) and Steinke and Ullman (COLT 2015) showed that in
general, it is computationally hard to answer more than $\Theta(n^2)$ adaptive
queries, assuming the existence of one-way functions.
</p>
<p>However, these negative results strongly rely on an adversarial model that
significantly advantages the adversarial analyst over the mechanism, as the
analyst, who chooses the adaptive queries, also chooses the underlying
distribution $D$. This imbalance raises questions with respect to the
applicability of the obtained hardness results -- an analyst who has complete
knowledge of the underlying distribution $D$ would have little need, if at all,
to issue statistical queries to a mechanism which only holds a finite number of
samples from $D$.
</p>
<p>We consider more restricted adversaries, called \emph{balanced}, where each
such adversary consists of two separated algorithms: The \emph{sampler} who is
the entity that chooses the distribution and provides the samples to the
mechanism, and the \emph{analyst} who chooses the adaptive queries, but does
not have a prior knowledge of the underlying distribution. We improve the
quality of previous lower bounds by revisiting them using an efficient
\emph{balanced} adversary, under standard public-key cryptography assumptions.
We show that these stronger hardness assumptions are unavoidable in the sense
that any computationally bounded \emph{balanced} adversary that has the
structure of all known attacks, implies the existence of public-key
cryptography.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nissim_K/0/1/0/all/0/1">Kobbi Nissim</a>, <a href="http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1">Uri Stemmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsfadia_E/0/1/0/all/0/1">Eliad Tsfadia</a></p><p>In adaptive data analysis, a mechanism gets $n$ i.i.d. samples from an
unknown distribution $D$, and is required to provide accurate estimations to a
sequence of adaptively chosen statistical queries with respect to $D$. Hardt
and Ullman (FOCS 2014) and Steinke and Ullman (COLT 2015) showed that in
general, it is computationally hard to answer more than $\Theta(n^2)$ adaptive
queries, assuming the existence of one-way functions.
</p>
<p>However, these negative results strongly rely on an adversarial model that
significantly advantages the adversarial analyst over the mechanism, as the
analyst, who chooses the adaptive queries, also chooses the underlying
distribution $D$. This imbalance raises questions with respect to the
applicability of the obtained hardness results -- an analyst who has complete
knowledge of the underlying distribution $D$ would have little need, if at all,
to issue statistical queries to a mechanism which only holds a finite number of
samples from $D$.
</p>
<p>We consider more restricted adversaries, called \emph{balanced}, where each
such adversary consists of two separated algorithms: The \emph{sampler} who is
the entity that chooses the distribution and provides the samples to the
mechanism, and the \emph{analyst} who chooses the adaptive queries, but does
not have a prior knowledge of the underlying distribution. We improve the
quality of previous lower bounds by revisiting them using an efficient
\emph{balanced} adversary, under standard public-key cryptography assumptions.
We show that these stronger hardness assumptions are unavoidable in the sense
that any computationally bounded \emph{balanced} adversary that has the
structure of all known attacks, implies the existence of public-key
cryptography.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-26T00:30:00Z">Friday, May 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.15566'>Trading Prophets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jos&#xe9; Correa, Andr&#xe9;s Cristi, Paul D&#xfc;tting, Mohammad Hajiaghayi, Jan Olkowski, Kevin Schewior</p><p>In this work we initiate the study of buy-and-sell prophet inequalities. We
start by considering what is arguably the most fundamental setting. In this
setting the online algorithm observes a sequence of prices one after the other.
At each time step, the online algorithm can decide to buy and pay the current
price if it does not hold the item already; or it can decide to sell and
collect the current price as a reward if it holds the item.
</p>
<p>We show that for i.i.d. prices a single-threshold online algorithm achieves
at least $1/2$ of the expected profit of the optimal offline algorithm and we
prove that this is optimal. For non-i.i.d. prices in random order, where prices
are no longer independent, we give a single-threshold online algorithm that
achieves at least a $1/16$ fraction of the expected profit of the optimal
offline algorithm. We also show that for this setting no online algorithm can
yield a better than $1/3$ approximation, and thus establish a formal separation
from the i.i.d. case. On the other hand, we present a threshold-based online
algorithm for this setting that yields a $1/2-o(1)$ approximation. For
non-i.i.d. prices no approximation is possible.
</p>
<p>We use the results for these base cases to solve a variety of more complex
settings. For instance, we show a $1/2-o(1)$ approximation for settings where
prices are affiliated and the online algorithm has only access to a single
sample. We also extend our upper and lower bounds for the single item case to
$k$ items, and thus in particular show that it is impossible to achieve
$1-o(1)$ approximations. For the budgeted version, where fractions of an item
can be bought, and gains can be reinvested, we show a constant-factor
approximation to the optimal offline algorithm's growth rate. In a setting with
$k$ item types and price streams, we achieve a $\Omega(1/k)$ approximation for
the unit-capacity case, which is optimal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Correa_J/0/1/0/all/0/1">Jos&#xe9; Correa</a>, <a href="http://arxiv.org/find/cs/1/au:+Cristi_A/0/1/0/all/0/1">Andr&#xe9;s Cristi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutting_P/0/1/0/all/0/1">Paul D&#xfc;tting</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1">Mohammad Hajiaghayi</a>, <a href="http://arxiv.org/find/cs/1/au:+Olkowski_J/0/1/0/all/0/1">Jan Olkowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Schewior_K/0/1/0/all/0/1">Kevin Schewior</a></p><p>In this work we initiate the study of buy-and-sell prophet inequalities. We
start by considering what is arguably the most fundamental setting. In this
setting the online algorithm observes a sequence of prices one after the other.
At each time step, the online algorithm can decide to buy and pay the current
price if it does not hold the item already; or it can decide to sell and
collect the current price as a reward if it holds the item.
</p>
<p>We show that for i.i.d. prices a single-threshold online algorithm achieves
at least $1/2$ of the expected profit of the optimal offline algorithm and we
prove that this is optimal. For non-i.i.d. prices in random order, where prices
are no longer independent, we give a single-threshold online algorithm that
achieves at least a $1/16$ fraction of the expected profit of the optimal
offline algorithm. We also show that for this setting no online algorithm can
yield a better than $1/3$ approximation, and thus establish a formal separation
from the i.i.d. case. On the other hand, we present a threshold-based online
algorithm for this setting that yields a $1/2-o(1)$ approximation. For
non-i.i.d. prices no approximation is possible.
</p>
<p>We use the results for these base cases to solve a variety of more complex
settings. For instance, we show a $1/2-o(1)$ approximation for settings where
prices are affiliated and the online algorithm has only access to a single
sample. We also extend our upper and lower bounds for the single item case to
$k$ items, and thus in particular show that it is impossible to achieve
$1-o(1)$ approximations. For the budgeted version, where fractions of an item
can be bought, and gains can be reinvested, we show a constant-factor
approximation to the optimal offline algorithm's growth rate. In a setting with
$k$ item types and price streams, we achieve a $\Omega(1/k)$ approximation for
the unit-capacity case, which is optimal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-26T00:30:00Z">Friday, May 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.15738'>Maximum Weight Independent Set in Graphs with no Long Claws in Quasi-Polynomial Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Peter Gartland, Daniel Lokshtanov, Tom&#xe1;&#x161; Masa&#x159;&#xed;k, Marcin Pilipczuk, Micha&#x142; Pilipczuk, Pawe&#x142; Rz&#x105;&#x17c;ewski</p><p>We show that the \textsc{Maximum Weight Independent Set} problem
(\textsc{MWIS}) can be solved in quasi-polynomial time on $H$-free graphs
(graphs excluding a fixed graph $H$ as an induced subgraph) for every $H$ whose
every connected component is a path or a subdivided claw (i.e., a tree with at
most three leaves). This completes the dichotomy of the complexity of
\textsc{MWIS} in $\mathcal{F}$-free graphs for any finite set $\mathcal{F}$ of
graphs into NP-hard cases and cases solvable in quasi-polynomial time, and
corroborates the conjecture that the cases not known to be NP-hard are actually
polynomial-time solvable.
</p>
<p>The key graph-theoretic ingredient in our result is as follows. Fix an
integer $t \geq 1$. Let $S_{t,t,t}$ be the graph created from three paths on
$t$ edges by identifying one endpoint of each path into a single vertex. We
show that, given a graph $G$, one can in polynomial time find either an induced
$S_{t,t,t}$ in $G$, or a balanced separator consisting of $\Oh(\log |V(G)|)$
vertex neighborhoods in $G$, or an extended strip decomposition of $G$ (a
decomposition almost as useful for recursion for \textsc{MWIS} as a partition
into connected components) with each particle of weight multiplicatively
smaller than the weight of $G$. This is a strengthening of a result of Majewski
et al.\ [ICALP~2022] which provided such an extended strip decomposition only
after the deletion of $\Oh(\log |V(G)|)$ vertex neighborhoods. To reach the
final result, we employ an involved branching strategy that relies on the
structural lemma presented above.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gartland_P/0/1/0/all/0/1">Peter Gartland</a>, <a href="http://arxiv.org/find/cs/1/au:+Lokshtanov_D/0/1/0/all/0/1">Daniel Lokshtanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Masarik_T/0/1/0/all/0/1">Tom&#xe1;&#x161; Masa&#x159;&#xed;k</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Marcin Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Micha&#x142; Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Rzazewski_P/0/1/0/all/0/1">Pawe&#x142; Rz&#x105;&#x17c;ewski</a></p><p>We show that the \textsc{Maximum Weight Independent Set} problem
(\textsc{MWIS}) can be solved in quasi-polynomial time on $H$-free graphs
(graphs excluding a fixed graph $H$ as an induced subgraph) for every $H$ whose
every connected component is a path or a subdivided claw (i.e., a tree with at
most three leaves). This completes the dichotomy of the complexity of
\textsc{MWIS} in $\mathcal{F}$-free graphs for any finite set $\mathcal{F}$ of
graphs into NP-hard cases and cases solvable in quasi-polynomial time, and
corroborates the conjecture that the cases not known to be NP-hard are actually
polynomial-time solvable.
</p>
<p>The key graph-theoretic ingredient in our result is as follows. Fix an
integer $t \geq 1$. Let $S_{t,t,t}$ be the graph created from three paths on
$t$ edges by identifying one endpoint of each path into a single vertex. We
show that, given a graph $G$, one can in polynomial time find either an induced
$S_{t,t,t}$ in $G$, or a balanced separator consisting of $\Oh(\log |V(G)|)$
vertex neighborhoods in $G$, or an extended strip decomposition of $G$ (a
decomposition almost as useful for recursion for \textsc{MWIS} as a partition
into connected components) with each particle of weight multiplicatively
smaller than the weight of $G$. This is a strengthening of a result of Majewski
et al.\ [ICALP~2022] which provided such an extended strip decomposition only
after the deletion of $\Oh(\log |V(G)|)$ vertex neighborhoods. To reach the
final result, we employ an involved branching strategy that relies on the
structural lemma presented above.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-26T00:30:00Z">Friday, May 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.15790'>Maximizing Neutrality in News Ordering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rishi Advani (1), Paolo Papotti (2), Abolfazl Asudeh (1) ((1) University of Illinois Chicago, (2) EURECOM)</p><p>The detection of fake news has received increasing attention over the past
few years, but there are more subtle ways of deceiving one's audience. In
addition to the content of news stories, their presentation can also be made
misleading or biased. In this work, we study the impact of the ordering of news
stories on audience perception. We introduce the problems of detecting
cherry-picked news orderings and maximizing neutrality in news orderings. We
prove hardness results and present several algorithms for approximately solving
these problems. Furthermore, we provide extensive experimental results and
present evidence of potential cherry-picking in the real world.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Advani_R/0/1/0/all/0/1">Rishi Advani</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Papotti_P/0/1/0/all/0/1">Paolo Papotti</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Asudeh_A/0/1/0/all/0/1">Abolfazl Asudeh</a> (1) ((1) University of Illinois Chicago, (2) EURECOM)</p><p>The detection of fake news has received increasing attention over the past
few years, but there are more subtle ways of deceiving one's audience. In
addition to the content of news stories, their presentation can also be made
misleading or biased. In this work, we study the impact of the ordering of news
stories on audience perception. We introduce the problems of detecting
cherry-picked news orderings and maximizing neutrality in news orderings. We
prove hardness results and present several algorithms for approximately solving
these problems. Furthermore, we provide extensive experimental results and
present evidence of potential cherry-picking in the real world.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-26T00:30:00Z">Friday, May 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, May 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://adamsheffer.wordpress.com/2023/05/25/a-guide-for-students-presenting-their-first-talk/'>A Guide for Students Presenting their First Talk</a></h3>
        <p class='tr-article-feed'>from <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I wrote a guide for undergraduate students who prepare to present their first math talk, for participants of the Polymath Jr Program and the NYC Discrete Math REU. I wanted to also share the guide here for two reasons: Click here for the pdf file. To the many friends who helped preparing this, THANK YOU! [&#8230;]<p>By Adam Sheffer</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          I wrote a guide for undergraduate students who prepare to present their first math talk, for participants of the Polymath Jr Program and the NYC Discrete Math REU. I wanted to also share the guide here for two reasons: Click here for the pdf file. To the many friends who helped preparing this, THANK YOU! [&#8230;]<p class="authors">By Adam Sheffer</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-25T23:25:23Z">Thursday, May 25 2023, 23:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/05/finding-primes-pseudodeterministically.html'>Finding Primes Pseudodeterministically</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>In 2003, Agrawal, Kayal and Saxena showed that primality testing is in P, i.e., you could test for primes without using any randomness.</p><p>What if you want to find a prime? Specifically given a number m in binary, can you find a prime p &gt; m in time polynomial in the length of m. In 2009 I&nbsp;posted&nbsp;about a polymath project to find a deterministic algorithm for finding primes and the problem remains open today.&nbsp;</p><p>Likely you could just try m+1,m+2, ... until you find a prime but whether that is bounded by a polynomial number of steps is a big open question in number theory. You can choose random numbers between m and 2m and find one in expected polytime given the prime number theorem. This algorithm will likely output a different prime every time you run it.</p><p>There's a new paper by&nbsp;Lijie Chen, Zhenjian Lu, Igor Carboni Oliveira, Hanlin Ren and Rahul Santhanam that solves this problem pseudodeterministically for infinitely many inputs. This is a randomized polynomial-time algorithm B that for infinitely many n, there is a specific prime p between 2n and 2n+1 such that B(1n) outputs p with high probability. With high probability you will get the same prime every time you run the algorithm!</p><p>The proof uses a win-win kind of argument, if a certain algorithm fails to work you can use that to derandomize. Making that argument work requires bootstrapping on variants of previous pseudorandom generator and hitting sets constructions.&nbsp;</p><p>Almost surely there is a deterministic polytime algorithm for finding primes. But for now the new result of Chen et al. is a nice stop in that direction.&nbsp;</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In 2003, Agrawal, Kayal and Saxena showed that primality testing is in P, i.e., you could test for primes without using any randomness.</p><p>What if you want to find a prime? Specifically given a number m in binary, can you find a prime p &gt; m in time polynomial in the length of m. In 2009 I&nbsp;<a href="https://blog.computationalcomplexity.org/2009/08/finding-primes.html">posted</a>&nbsp;about a polymath project to find a deterministic algorithm for finding primes and the problem remains open today.&nbsp;</p><p>Likely you could just try m+1,m+2, ... until you find a prime but whether that is bounded by a polynomial number of steps is a big open question in number theory. You can choose random numbers between m and 2m and find one in expected polytime given the <a href="https://en.wikipedia.org/wiki/Prime_number_theorem">prime number theorem</a>. This algorithm will likely output a different prime every time you run it.</p><p>There's a <a href="https://eccc.weizmann.ac.il/report/2023/076/">new paper</a> by&nbsp;Lijie Chen, Zhenjian Lu, Igor Carboni Oliveira, Hanlin Ren and Rahul Santhanam that solves this problem pseudodeterministically for infinitely many inputs. This is a randomized polynomial-time algorithm B that for infinitely many n, there is a specific prime p between 2<sup>n</sup> and 2<sup>n+1</sup> such that B(1<sup>n</sup>) outputs p with high probability. With high probability you will get the same prime every time you run the algorithm!</p><p>The proof uses a win-win kind of argument, if a certain algorithm fails to work you can use that to derandomize. Making that argument work requires bootstrapping on variants of previous pseudorandom generator and hitting sets constructions.&nbsp;</p><p>Almost surely there is a deterministic polytime algorithm for finding primes. But for now the new result of Chen et al. is a nice stop in that direction.&nbsp;</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-25T13:17:00Z">Thursday, May 25 2023, 13:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/'>Test your intuition 52: Can you predict the ratios of ones?</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Here is a problem I heard from Zachary Chase and Yuval Peres. Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice&#8217;s task is to choose, at a certain &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Here is a problem I heard from Zachary Chase and Yuval Peres. Bob choses a sequences of zeroes and ones of length <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N" class="latex" />. The bits are presented to Alice one by one. Alice&#8217;s task is to choose, at a certain time of her choice, some number <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> (smaller than the number of unseen bits) and to predict the fraction of ones in the next <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> bits. Alice wins if her prediction deviates by at most 0.01 from the correct ratio.</p>
<h3>Test your intuition 52: Assuming that <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N" class="latex" /> is sufficiently large, is it possible for Alice to achieve this task with probability greater than 0.99?</h3>
<p><span style="color: #0000ff">Clarification: we assume Bob’s sequence is fixed, and the randomness is over a probabilistic strategy chosen by Alice.</span></p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-25T08:33:58Z">Thursday, May 25 2023, 08:33</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.14632'>Supermodular Rank: Set Function Decomposition and Optimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rishi Sonthalia, Anna Seigal, Guido Montufar</p><p>We define the supermodular rank of a function on a lattice. This is the
smallest number of terms needed to decompose it into a sum of supermodular
functions. The supermodular summands are defined with respect to different
partial orders. We characterize the maximum possible value of the supermodular
rank and describe the functions with fixed supermodular rank. We analogously
define the submodular rank. We use submodular decompositions to optimize set
functions. Given a bound on the submodular rank of a set function, we formulate
an algorithm that splits an optimization problem into submodular subproblems.
We show that this method improves the approximation ratio guarantees of several
algorithms for monotone set function maximization and ratio of set functions
minimization, at a computation overhead that depends on the submodular rank.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Sonthalia_R/0/1/0/all/0/1">Rishi Sonthalia</a>, <a href="http://arxiv.org/find/math/1/au:+Seigal_A/0/1/0/all/0/1">Anna Seigal</a>, <a href="http://arxiv.org/find/math/1/au:+Montufar_G/0/1/0/all/0/1">Guido Montufar</a></p><p>We define the supermodular rank of a function on a lattice. This is the
smallest number of terms needed to decompose it into a sum of supermodular
functions. The supermodular summands are defined with respect to different
partial orders. We characterize the maximum possible value of the supermodular
rank and describe the functions with fixed supermodular rank. We analogously
define the submodular rank. We use submodular decompositions to optimize set
functions. Given a bound on the submodular rank of a set function, we formulate
an algorithm that splits an optimization problem into submodular subproblems.
We show that this method improves the approximation ratio guarantees of several
algorithms for monotone set function maximization and ratio of set functions
minimization, at a computation overhead that depends on the submodular rank.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-25T00:30:00Z">Thursday, May 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.14461'>Engineering Rank/Select Data Structures for Big-Alphabet Strings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Diego Arroyuelo, Gabriel Carmona, H&#xe9;ctor Larra&#xf1;aga, Francisco Riveros, Erick Sep&#xfa;lveda</p><p>Big-alphabet strings are common in several scenarios such as information
retrieval and natural-language processing. The efficient storage and processing
of such strings usually introduces several challenges that are not witnessed in
smaller-alphabets strings. This paper studies the efficient implementation of
one of the most effective approaches for dealing with big-alphabet strings,
namely the \emph{alphabet-partitioning} approach. The main contribution is a
compressed data structure that supports the fundamental operations rank and
select efficiently. We show experimental results that indicate that our
implementation outperforms the current realizations of the
alphabet-partitioning approach. In particular, the time for operation select
can be improved by about 80%, using only 11% more space than current
alphabet-partitioning schemes. We also show the impact of our data structure on
several applications, like the intersection of inverted lists (where
improvements of up to 60% are achieved, using only 2% of extra space), the
representation of run-length compressed strings, and the
distributed-computation processing of rank and select operations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Arroyuelo_D/0/1/0/all/0/1">Diego Arroyuelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmona_G/0/1/0/all/0/1">Gabriel Carmona</a>, <a href="http://arxiv.org/find/cs/1/au:+Larranaga_H/0/1/0/all/0/1">H&#xe9;ctor Larra&#xf1;aga</a>, <a href="http://arxiv.org/find/cs/1/au:+Riveros_F/0/1/0/all/0/1">Francisco Riveros</a>, <a href="http://arxiv.org/find/cs/1/au:+Sepulveda_E/0/1/0/all/0/1">Erick Sep&#xfa;lveda</a></p><p>Big-alphabet strings are common in several scenarios such as information
retrieval and natural-language processing. The efficient storage and processing
of such strings usually introduces several challenges that are not witnessed in
smaller-alphabets strings. This paper studies the efficient implementation of
one of the most effective approaches for dealing with big-alphabet strings,
namely the \emph{alphabet-partitioning} approach. The main contribution is a
compressed data structure that supports the fundamental operations rank and
select efficiently. We show experimental results that indicate that our
implementation outperforms the current realizations of the
alphabet-partitioning approach. In particular, the time for operation select
can be improved by about 80%, using only 11% more space than current
alphabet-partitioning schemes. We also show the impact of our data structure on
several applications, like the intersection of inverted lists (where
improvements of up to 60% are achieved, using only 2% of extra space), the
representation of run-length compressed strings, and the
distributed-computation processing of rank and select operations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-25T00:30:00Z">Thursday, May 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.14756'>Deterministic Algorithmic Approaches to Solve Generalised Wordle</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aditya Lahiri, Naigam Shah, Shivaank Agarwal, Vignesh Nandakumar</p><p>Wordle is a single-player word-based game where the objective is to guess the
5-letter word in a maximum of 6 tries. The game was released to the public in
October 2021 and has since gained popularity with people competing against each
other to maintain daily streaks and guess the word in a minimum number of
tries. There have been works using probabilistic and reinforcement learning
based approaches to solve the game. Our work aims to formulate and analyze
deterministic algorithms that can solve the game and minimize the number of
turns required to guess the word and do so for any generalized setting of the
game. As a simplifying assumption, for our analysis of all the algorithms we
present, we assume that all letters will be unique in any word which is part of
our vocabulary. We propose two algorithms to play Wordle - one a greedy based
approach, and other based on Cliques. The Greedy approach is applicable for
both hard and easy modes of Wordle, while the Clique formation based approach
only works on the Easy mode. We present our analysis on both approaches one by
one, next.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lahiri_A/0/1/0/all/0/1">Aditya Lahiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Naigam Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Shivaank Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nandakumar_V/0/1/0/all/0/1">Vignesh Nandakumar</a></p><p>Wordle is a single-player word-based game where the objective is to guess the
5-letter word in a maximum of 6 tries. The game was released to the public in
October 2021 and has since gained popularity with people competing against each
other to maintain daily streaks and guess the word in a minimum number of
tries. There have been works using probabilistic and reinforcement learning
based approaches to solve the game. Our work aims to formulate and analyze
deterministic algorithms that can solve the game and minimize the number of
turns required to guess the word and do so for any generalized setting of the
game. As a simplifying assumption, for our analysis of all the algorithms we
present, we assume that all letters will be unique in any word which is part of
our vocabulary. We propose two algorithms to play Wordle - one a greedy based
approach, and other based on Cliques. The Greedy approach is applicable for
both hard and easy modes of Wordle, while the Clique formation based approach
only works on the Easy mode. We present our analysis on both approaches one by
one, next.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-25T00:30:00Z">Thursday, May 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://grigory.github.io/blog/theory-jobs-2023/'>Theory Jobs 2023</a></h3>
        <p class='tr-article-feed'>from <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Here is a link to a crowdsourced spreadsheet created to collect information about theory hires this year. 
Rules for the spreadsheet have been copied from previous years and all edits to the document are anonymized. Please, feel free to contact me directly or post a comment if you have any suggestions about the rules.</p>
<ul>
 <li>You are welcome to add yourself, or people your department has hired. </li>
 <li>Separate sheets for faculty, industry and postdocs/visitors. </li>
 <li>Hires should be connected to theoretical computer science, broadly defined.</li>
 <li>Only add jobs that you are absolutely sure have been offered and accepted. This is not the place for speculation and rumors. Please, be particularly careful when adding senior hires (people who already have an academic or industrial job) -- end dates of their current positions might be still in the future. </li>
</ul>


  <p>Theory Jobs 2023 was originally published by Grigory Yaroslavtsev at The Big Data Theory on May 25, 2023.</p><p>By Grigory Yaroslavtsev</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="https://docs.google.com/spreadsheets/d/1-_IMSqElpovmhKsOZTAZ92L3FHJTLmnmvqJSOXsSI-8/edit?usp=sharing">Here is a link</a> to a crowdsourced spreadsheet created to collect information about theory hires this year. 
Rules for the spreadsheet have been copied from previous years and all edits to the document are anonymized. Please, feel free to contact me directly or post a comment if you have any suggestions about the rules.</p>
<ul>
 <li>You are welcome to add yourself, or people your department has hired. </li>
 <li>Separate sheets for faculty, industry and postdocs/visitors. </li>
 <li>Hires should be connected to theoretical computer science, broadly defined.</li>
 <li>Only add jobs that you are <b>absolutely sure have been offered and accepted</b>. This is not the place for speculation and rumors. Please, be particularly careful when adding senior hires (people who already have an academic or industrial job) -- end dates of their current positions might be still in the future. </li>
</ul>


  <p><a href="http://grigory.github.io/blog/theory-jobs-2023/">Theory Jobs 2023</a> was originally published by Grigory Yaroslavtsev at <a href="http://grigory.github.io/blog">The Big Data Theory</a> on May 25, 2023.</p><p class="authors">By Grigory Yaroslavtsev</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-25T00:00:00Z">Thursday, May 25 2023, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, May 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/05/24/congratulations-dr-frishberg.html'>Congratulations, Dr. Frishberg!</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          My student Daniel Frishberg successfully passed his dissertation defense today!
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>My student <a href="https://www.ics.uci.edu/~dfrishbe/">Daniel Frishberg</a> successfully passed his dissertation defense today!</p>

<p>I’ve written here already about several of our joint papers:</p>
<ul>
  <li>“<a href="/blog/2019/02/21/mutual-nearest-neighbors.html">New applications of nearest-neighbor chains: Euclidean TSP and motorcycle graphs</a>” (with Mamano, Efrat, Goodrich, Kobourov, Matias, and Polishchuk, <a href="https://doi.org/10.4230/LIPIcs.ISAAC.2019.51">ISAAC 2019</a>)</li>
  <li>“<a href="/blog/2019/01/29/simplifying-task-milestone.html">Simplifying activity-on-edge graphs</a> (with Havvaei, <a href="https://doi.org/10.4230/LIPIcs.SWAT.2020.24">SWAT 2020</a>)</li>
  <li>“<a href="/blog/2020/05/03/hanoi-vs-sierpinski.html">On the treewidth of Hanoi graphs</a>” (with Maxwell, <a href="https://doi.org/10.4230/LIPIcs.FUN.2021.13">FUN 2020</a> and <a href="https://doi.org/10.1016/j.tcs.2021.12.014"><em>Theor. Comput. Sci.</em> 2022</a>)</li>
  <li>“<a href="/blog/2021/07/10/angles-arc-triangles.html">Angles of arc-polygons and Lombardi drawings of cacti</a>” (with Osegueda, <a href="https://projects.cs.dal.ca/cccg2021/wordpress/wp-content/uploads/2021/08/CCCG2021.pdf">CCCG 2021</a> and <a href="https://doi.org/10.1016/j.comgeo.2023.101982"><em>Comp. Geom. Theory &amp; Applications</em> 2023</a>)</li>
  <li>“<a href="/blog/2022/07/21/flipping-until-lost.html">Improved mixing for the convex polygon triangulation flip walk</a>” (ICALP 2023, to appear)</li>
  <li>“<a href="/blog/2021/11/14/random-independent-sets.html">Rapid mixing of the hardcore Glauber dynamics and other Markov chains in bounded-treewidth graphs</a>” (not yet published)</li>
</ul>

<p>Several more are on the way but not yet announced. As is typical for our students, the earlier ones involved more of my intervention, the last two were mostly Daniel’s work, and I’m not even likely to be a coauthor on the upcoming ones: the pattern we want to see developing in a new doctorate. The dissertation incorporates the last two of the papers listed above. Most of our students combine three papers to form a dissertation, and the Hanoi graph work would have fit thematically, but just with the two Daniel included it already had plenty of material.</p>

<p>The ICALP reviewers told us that we’ve been underselling one of the results in that paper, on the expansion of the associahedron, so I thought I’d elaborate on that a little more here. An <a href="https://en.wikipedia.org/wiki/Associahedron">associahedron</a> is a graph whose vertices represent triangulations of a convex polygon (or binary search trees on a given set of keys) and whose edges represent “flips” that remove and replace one diagonal in a triangulation (or that perform a single binary tree rotation). There’s a lot we don’t know about associahedra still, including how to calculate shortest paths (“flip distance”) between vertices efficiently.</p>

<p style="text-align:center"><img src="/blog/assets/2006/fg6.png" alt="Flip graph of a hexagon" /></p>

<p>The version of expansion we’re using is <a href="https://en.wikipedia.org/wiki/Expander_graph">edge expansion</a>,</p>

\[\min_{X\subset V(G)}\frac{\vert\partial X\vert}{\min(\vert X\vert,\vert V(G)\setminus X\vert)},\]

<p>where \(\partial X\) represents the set of edges having one endpoint in \(X\). There are many other graphs of local moves in state spaces that, like the associahedron, can also be given the structure of the vertices and edges of a convex polytope, and in many such cases these have constant expansion. In fact, Milena Mihail and Umesh Vazirani conjectured some time prior to 1992 that every polytope whose vertex coordinates are all 0 or 1 has expansion at least one (for this history see e.g. Kaibel, “On the Expansion of
Graphs of 0/1-Polytopes”, <a href="https://arxiv.org/abs/math/0112146">arXiv:math/0112146</a>), and it was a big breakthrough in 2018 when <a href="https://gilkalai.wordpress.com/2018/12/12/nima-anari-kuikui-liu-shayan-oveis-gharan-and-cynthia-vinzant-solved-the-mihail-vazirani-conjecture/">Nima Anari, Kuikui Liu, Shayan Oveis Gharan, and Cynthia Vinzant proved it for flip graphs of matroids</a> (<a href="https://arxiv.org/abs/1811.01816">arXiv:1811.01816</a>). The associahedra are not 0-1 polytopes, but one can still ask what their expansion is. The ICALP paper gets within a logarithmic factor of the right answer: it proves that the expansion is \(\Omega\bigl(1/(\sqrt n\log n)\bigr)\) and \(O(1/\sqrt n)\). The lower bound is the part that fits into the machinery of Daniel’s thesis, but it is the upper bound that the referees told us we were underselling. It is the first time we have seen that the expansion of the associahedron is smaller than a constant.</p>

<p>To prove this upper bound (in appendix C of <a href="https://arxiv.org/abs/2207.09972">arXiv:2207.09972</a>), we merely have to find a partition of the space of all triangulations into two subsets with few edges connecting them. This partition is defined very simply, as follows:</p>

<ul>
  <li>For each triangulation, look at the triangle containing the center point of the polygon.</li>
  <li>This triangle has three sides. Define their “length” combinatorially, as the number of polygon sides they cut off. Thus, the three lengths sum to \(n\), and the shortest is at most \(n/3\).</li>
  <li>Put a triangulation into one side of the partition when its central triangle has a very short side, of length less than \(n/6\), and into the other side of the partition otherwise.</li>
</ul>

<p>There are always three flips that move one of the vertices of the central triangle, unless the short side is only one edge long. But short motions of these vertices are likelier than long ones, enough so to keep the expansion small. The details involve doing some sums with Catalan numbers.</p>

<p>The next step for Daniel will be to start an assistant professor position at Cal Poly in San Luis Obispo in the fall.</p>

<p>Congratulations, Daniel!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/110427368041366794">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-24T21:06:00Z">Wednesday, May 24 2023, 21:06</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/076'>TR23-076 |  Polynomial-Time Pseudodeterministic Construction of Primes | 

	Lijie Chen, 

	Zhenjian Lu, 

	Igor Carboni Oliveira, 

	Hanlin Ren, 

	Rahul Santhanam</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A randomized algorithm for a search problem is *pseudodeterministic* if it produces a fixed canonical solution to the search problem with high probability. In their seminal work on the topic, Gat and Goldwasser posed as their main open problem whether prime numbers can be pseudodeterministically constructed in polynomial time. 

We provide a positive solution to this question in the infinitely-often regime. In more detail, we give an *unconditional* polynomial-time randomized algorithm $B$ such that, for infinitely many values of $n$, $B(1^n)$ outputs a canonical $n$-bit prime $p_n$ with high probability. More generally, we prove that for every dense property $Q$ of strings that can be decided in polynomial time, there is an infinitely-often pseudodeterministic polynomial-time construction of strings satisfying $Q$. This improves upon a subexponential-time construction of Oliveira and Santhanam.  

Our construction uses several new ideas, including a novel bootstrapping technique for pseudodeterministic constructions, and a quantitative optimization of the uniform hardness-randomness framework of Chen and Tell, using a variant of the Shaltiel--Umans generator.
        
        </div>

        <div class='tr-article-summary'>
        
          
          A randomized algorithm for a search problem is *pseudodeterministic* if it produces a fixed canonical solution to the search problem with high probability. In their seminal work on the topic, Gat and Goldwasser posed as their main open problem whether prime numbers can be pseudodeterministically constructed in polynomial time. 

We provide a positive solution to this question in the infinitely-often regime. In more detail, we give an *unconditional* polynomial-time randomized algorithm $B$ such that, for infinitely many values of $n$, $B(1^n)$ outputs a canonical $n$-bit prime $p_n$ with high probability. More generally, we prove that for every dense property $Q$ of strings that can be decided in polynomial time, there is an infinitely-often pseudodeterministic polynomial-time construction of strings satisfying $Q$. This improves upon a subexponential-time construction of Oliveira and Santhanam.  

Our construction uses several new ideas, including a novel bootstrapping technique for pseudodeterministic constructions, and a quantitative optimization of the uniform hardness-randomness framework of Chen and Tell, using a variant of the Shaltiel--Umans generator.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-24T13:56:30Z">Wednesday, May 24 2023, 13:56</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.13807'>On the number of tangencies among 1-intersecting curves</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eyal Ackerman, Bal&#xe1;zs Keszegh</p><p>Let $\cal C$ be a set of curves in the plane such that no three curves in
$\cal C$ intersect at a single point and every pair of curves in $\cal C$
intersect at exactly one point which is either a crossing or a touching point.
According to a conjecture of J\'anos Pach the number of pairs of curves in
$\cal C$ that touch each other is $O(|{\cal C}|)$. We prove this conjecture for
$x$-monotone curves.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Ackerman_E/0/1/0/all/0/1">Eyal Ackerman</a>, <a href="http://arxiv.org/find/math/1/au:+Keszegh_B/0/1/0/all/0/1">Bal&#xe1;zs Keszegh</a></p><p>Let $\cal C$ be a set of curves in the plane such that no three curves in
$\cal C$ intersect at a single point and every pair of curves in $\cal C$
intersect at exactly one point which is either a crossing or a touching point.
According to a conjecture of J\'anos Pach the number of pairs of curves in
$\cal C$ that touch each other is $O(|{\cal C}|)$. We prove this conjecture for
$x$-monotone curves.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-24T00:30:00Z">Wednesday, May 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.13402'>Error-Tolerant Exact Query Learning of Finite Set Partitions with Same-Cluster Oracle</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adela Frances DePavia, Olga Medrano Mart&#xed;n del Campo, Erasmo Tani</p><p>This paper initiates the study of active learning for exact recovery of
partitions exclusively through access to a same-cluster oracle in the presence
of bounded adversarial error. We first highlight a novel connection between
learning partitions and correlation clustering. Then we use this connection to
build a R\'enyi-Ulam style analytical framework for this problem, and prove
upper and lower bounds on its worst-case query complexity. Further, we bound
the expected performance of a relevant randomized algorithm. Finally, we study
the relationship between adaptivity and query complexity for this problem and
related variants.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+DePavia_A/0/1/0/all/0/1">Adela Frances DePavia</a>, <a href="http://arxiv.org/find/cs/1/au:+Campo_O/0/1/0/all/0/1">Olga Medrano Mart&#xed;n del Campo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tani_E/0/1/0/all/0/1">Erasmo Tani</a></p><p>This paper initiates the study of active learning for exact recovery of
partitions exclusively through access to a same-cluster oracle in the presence
of bounded adversarial error. We first highlight a novel connection between
learning partitions and correlation clustering. Then we use this connection to
build a R\'enyi-Ulam style analytical framework for this problem, and prove
upper and lower bounds on its worst-case query complexity. Further, we bound
the expected performance of a relevant randomized algorithm. Finally, we study
the relationship between adaptivity and query complexity for this problem and
related variants.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-24T00:30:00Z">Wednesday, May 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.13440'>Differentially Private Medians and Interior Points for Non-Pathological Data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Maryam Aliakbarpour, Rose Silver, Thomas Steinke, Jonathan Ullman</p><p>We construct differentially private estimators with low sample complexity
that estimate the median of an arbitrary distribution over $\mathbb{R}$
satisfying very mild moment conditions. Our result stands in contrast to the
surprising negative result of Bun et al. (FOCS 2015) that showed there is no
differentially private estimator with any finite sample complexity that returns
any non-trivial approximation to the median of an arbitrary distribution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aliakbarpour_M/0/1/0/all/0/1">Maryam Aliakbarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Silver_R/0/1/0/all/0/1">Rose Silver</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1">Thomas Steinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullman_J/0/1/0/all/0/1">Jonathan Ullman</a></p><p>We construct differentially private estimators with low sample complexity
that estimate the median of an arbitrary distribution over $\mathbb{R}$
satisfying very mild moment conditions. Our result stands in contrast to the
surprising negative result of Bun et al. (FOCS 2015) that showed there is no
differentially private estimator with any finite sample complexity that returns
any non-trivial approximation to the median of an arbitrary distribution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-24T00:30:00Z">Wednesday, May 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.13459'>The First Proven Performance Guarantees for the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) on a Combinatorial Optimization Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sacha Cerf, Benjamin Doerr, Benjamin Hebras, Yakob Kahane, Simon Wietheger</p><p>The Non-dominated Sorting Genetic Algorithm-II (NSGA-II) is one of the most
prominent algorithms to solve multi-objective optimization problems. Recently,
the first mathematical runtime guarantees have been obtained for this
algorithm, however only for synthetic benchmark problems.
</p>
<p>In this work, we give the first proven performance guarantees for a classic
optimization problem, the NP-complete bi-objective minimum spanning tree
problem. More specifically, we show that the NSGA-II with population size $N
\ge 4((n-1) w_{\max} + 1)$ computes all extremal points of the Pareto front in
an expected number of $O(m^2 n w_{\max} \log(n w_{\max}))$ iterations, where
$n$ is the number of vertices, $m$ the number of edges, and $w_{\max}$ is the
maximum edge weight in the problem instance. This result confirms, via
mathematical means, the good performance of the NSGA-II observed empirically.
It also shows that mathematical analyses of this algorithm are not only
possible for synthetic benchmark problems, but also for more complex
combinatorial optimization problems.
</p>
<p>As a side result, we also obtain a new analysis of the performance of the
global SEMO algorithm on the bi-objective minimum spanning tree problem, which
improves the previous best result by a factor of $|F|$, the number of extremal
points of the Pareto front, a set that can be as large as $n w_{\max}$. The
main reason for this improvement is our observation that both multi-objective
evolutionary algorithms find the different extremal points in parallel rather
than sequentially, as assumed in the previous proofs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cerf_S/0/1/0/all/0/1">Sacha Cerf</a>, <a href="http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1">Benjamin Doerr</a>, <a href="http://arxiv.org/find/cs/1/au:+Hebras_B/0/1/0/all/0/1">Benjamin Hebras</a>, <a href="http://arxiv.org/find/cs/1/au:+Kahane_Y/0/1/0/all/0/1">Yakob Kahane</a>, <a href="http://arxiv.org/find/cs/1/au:+Wietheger_S/0/1/0/all/0/1">Simon Wietheger</a></p><p>The Non-dominated Sorting Genetic Algorithm-II (NSGA-II) is one of the most
prominent algorithms to solve multi-objective optimization problems. Recently,
the first mathematical runtime guarantees have been obtained for this
algorithm, however only for synthetic benchmark problems.
</p>
<p>In this work, we give the first proven performance guarantees for a classic
optimization problem, the NP-complete bi-objective minimum spanning tree
problem. More specifically, we show that the NSGA-II with population size $N
\ge 4((n-1) w_{\max} + 1)$ computes all extremal points of the Pareto front in
an expected number of $O(m^2 n w_{\max} \log(n w_{\max}))$ iterations, where
$n$ is the number of vertices, $m$ the number of edges, and $w_{\max}$ is the
maximum edge weight in the problem instance. This result confirms, via
mathematical means, the good performance of the NSGA-II observed empirically.
It also shows that mathematical analyses of this algorithm are not only
possible for synthetic benchmark problems, but also for more complex
combinatorial optimization problems.
</p>
<p>As a side result, we also obtain a new analysis of the performance of the
global SEMO algorithm on the bi-objective minimum spanning tree problem, which
improves the previous best result by a factor of $|F|$, the number of extremal
points of the Pareto front, a set that can be as large as $n w_{\max}$. The
main reason for this improvement is our observation that both multi-objective
evolutionary algorithms find the different extremal points in parallel rather
than sequentially, as assumed in the previous proofs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-24T00:30:00Z">Wednesday, May 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.13560'>Single-Pass Pivot Algorithm for Correlation Clustering. Keep it simple!</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sayak Chakrabarty, Konstantin Makarychev</p><p>We show that a simple single-pass semi-streaming variant of the Pivot
algorithm for Correlation Clustering gives a (3 + {\epsilon})-approximation
using O(n/{\epsilon}) words of memory. This is a slight improvement over the
recent results of Cambus, Kuhn, Lindy, Pai, and Uitto, who gave a (3 +
{\epsilon})-approximation using O(n log n) words of memory, and Behnezhad,
Charikar, Ma, and Tan, who gave a 5-approximation using O(n) words of memory.
One of the main contributions of this paper is that both the algorithm and its
analysis are very simple, and also the algorithm is easy to implement.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chakrabarty_S/0/1/0/all/0/1">Sayak Chakrabarty</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_K/0/1/0/all/0/1">Konstantin Makarychev</a></p><p>We show that a simple single-pass semi-streaming variant of the Pivot
algorithm for Correlation Clustering gives a (3 + {\epsilon})-approximation
using O(n/{\epsilon}) words of memory. This is a slight improvement over the
recent results of Cambus, Kuhn, Lindy, Pai, and Uitto, who gave a (3 +
{\epsilon})-approximation using O(n log n) words of memory, and Behnezhad,
Charikar, Ma, and Tan, who gave a 5-approximation using O(n) words of memory.
One of the main contributions of this paper is that both the algorithm and its
analysis are very simple, and also the algorithm is easy to implement.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-24T00:30:00Z">Wednesday, May 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.13889'>Parameterized Complexity Classification for Interval Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Konrad K. Dabrowski, Peter Jonsson, Sebastian Ordyniak, George Osipov, Marcin Pilipczuk, Roohani Sharma</p><p>Constraint satisfaction problems form a nicely behaved class of problems that
lends itself to complexity classification results. From the point of view of
parameterized complexity, a natural task is to classify the parameterized
complexity of MinCSP problems parameterized by the number of unsatisfied
constraints. In other words, we ask whether we can delete at most $k$
constraints, where $k$ is the parameter, to get a satisfiable instance. In this
work, we take a step towards classifying the parameterized complexity for an
important infinite-domain CSP: Allen's interval algebra (IA). This CSP has
closed intervals with rational endpoints as domain values and employs a set $A$
of 13 basic comparison relations such as ``precedes'' or ``during'' for
relating intervals. IA is a highly influential and well-studied formalism
within AI and qualitative reasoning that has numerous applications in, for
instance, planning, natural language processing and molecular biology. We
provide an FPT vs. W[1]-hard dichotomy for MinCSP$(\Gamma)$ for all $\Gamma
\subseteq A$. IA is sometimes extended with unions of the relations in $A$ or
first-order definable relations over $A$, but extending our results to these
cases would require first solving the parameterized complexity of Directed
Symmetric Multicut, which is a notorious open problem. Already in this limited
setting, we uncover connections to new variants of graph cut and separation
problems. This includes hardness proofs for simultaneous cuts or feedback arc
set problems in directed graphs, as well as new tractable cases with algorithms
based on the recently introduced flow augmentation technique. Given the
intractability of MinCSP$(A)$ in general, we then consider (parameterized)
approximation algorithms and present a factor-$2$ fpt-approximation algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dabrowski_K/0/1/0/all/0/1">Konrad K. Dabrowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Jonsson_P/0/1/0/all/0/1">Peter Jonsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ordyniak_S/0/1/0/all/0/1">Sebastian Ordyniak</a>, <a href="http://arxiv.org/find/cs/1/au:+Osipov_G/0/1/0/all/0/1">George Osipov</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilipczuk_M/0/1/0/all/0/1">Marcin Pilipczuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Roohani Sharma</a></p><p>Constraint satisfaction problems form a nicely behaved class of problems that
lends itself to complexity classification results. From the point of view of
parameterized complexity, a natural task is to classify the parameterized
complexity of MinCSP problems parameterized by the number of unsatisfied
constraints. In other words, we ask whether we can delete at most $k$
constraints, where $k$ is the parameter, to get a satisfiable instance. In this
work, we take a step towards classifying the parameterized complexity for an
important infinite-domain CSP: Allen's interval algebra (IA). This CSP has
closed intervals with rational endpoints as domain values and employs a set $A$
of 13 basic comparison relations such as ``precedes'' or ``during'' for
relating intervals. IA is a highly influential and well-studied formalism
within AI and qualitative reasoning that has numerous applications in, for
instance, planning, natural language processing and molecular biology. We
provide an FPT vs. W[1]-hard dichotomy for MinCSP$(\Gamma)$ for all $\Gamma
\subseteq A$. IA is sometimes extended with unions of the relations in $A$ or
first-order definable relations over $A$, but extending our results to these
cases would require first solving the parameterized complexity of Directed
Symmetric Multicut, which is a notorious open problem. Already in this limited
setting, we uncover connections to new variants of graph cut and separation
problems. This includes hardness proofs for simultaneous cuts or feedback arc
set problems in directed graphs, as well as new tractable cases with algorithms
based on the recently introduced flow augmentation technique. Given the
intractability of MinCSP$(A)$ in general, we then consider (parameterized)
approximation algorithms and present a factor-$2$ fpt-approximation algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-24T00:30:00Z">Wednesday, May 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, May 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/'>Early Theory</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          &#8220;Everything is interesting&#8221; Susan Graham is a Distinguished Professor of Electrical Engineering and Computer Science Emerita at the University of California, Berkeley. I have known Graham for decades&#8212;and am happy to report she is still active. She was a member of the President&#8217;s Council of Advisors on Science and Technology (PCAST) during the Obama Administration. [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>&#8220;Everything is interesting&#8221;</em><br />
<font color="#000000"></p>
<p>
Susan Graham is a Distinguished Professor of Electrical Engineering and Computer Science Emerita at the University of California, Berkeley. I have known Graham for decades&#8212;and am happy to report she is still active. </p>
<p>
She was a <a href="https://obamawhitehouse.archives.gov/administration/eop/ostp/pcast/about/members">member</a> of the President&#8217;s Council of Advisors on Science and Technology (PCAST) during the Obama Administration. She served alongside Bill Press of Austin, who is <a href="https://obamawhitehouse.archives.gov/administration/eop/ostp/pcast/about/members">still</a> on PCAST&#8212;alongside Terry Tao among names we know. </p>
<p>
Graham has maintained involvements in the performing arts. She is an <a href="https://calperformances.org/about/trustees/">Officer</a> on the Board of Trustees of <a href="https://calperformances.org/">Cal Performances</a>. She also served on the Board of Overseers of the Curtis Institute of Music in Philadelphia until they reorganized in 2016. She has also had a long association with Harvard, She was referring to committee memberships when she was <a href="https://www.harvardmagazine.com/2011/09/and-then-there-were-10">quoted</a> for the subtitle above, but her words &#8220;everything is interesting&#8221; apply more widely in our field.</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/sg-2/" rel="attachment wp-att-21640"><img data-attachment-id="21640" data-permalink="https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/sg-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?fit=200%2C200&amp;ssl=1" data-orig-size="200,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sg" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?fit=200%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?fit=200%2C200&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?resize=200%2C200&#038;ssl=1" alt="" width="200" height="200" class="aligncenter size-full wp-image-21640" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?w=200&amp;ssl=1 200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/sg.jpeg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 200px) 100vw, 200px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Her Work </H2></p>
<p><p>
Graham has done seminal research in compiler code generation and optimization. She was elected a member of the National Academy of Engineering in 1993 for contributions to the theory and practice of compiler construction and for leadership in the computer science community. And was awarded the 2009 IEEE John von Neumann Medal for &#8220;contributions to programming language design and implementation and for exemplary service to the discipline of computer science.&#8221;</p>
<p>
The nexus with programming languages was arguably <em>the</em> initial focus of computer science theory in the years before 1965, when Juris Hartmanis and Richard Stearns founded computational complexity on Turing machines. See the <a href="https://cs.brown.edu/people/jsavage/papers/09_ch5.pdf">history</a> penned by John Savage, Alan Selman, and Carl Smith for a neat summary. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/jsascs/" rel="attachment wp-att-21641"><img data-attachment-id="21641" data-permalink="https://rjlipton.wpcomstaging.com/2023/05/22/early-theory/jsascs/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?fit=546%2C191&amp;ssl=1" data-orig-size="546,191" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="JSASCS" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?fit=300%2C105&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?fit=546%2C191&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?resize=362%2C128&#038;ssl=1" alt="" width="362" height="128" class="aligncenter wp-image-21641" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?w=546&amp;ssl=1 546w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/05/JSASCS.png?resize=300%2C105&amp;ssl=1 300w" sizes="(max-width: 362px) 100vw, 362px" data-recalc-dims="1" /></a></p>
<p><P><br />
They point out:</p>
<blockquote><p><b> </b> <em> After the early recognition of the relevance of the theory of formal languages to the practice of compiler construction, theoretical computer science became a cornerstone of virtually every computer science undergraduate degree program. </em>
</p></blockquote>
<p><p>
Susan&#8217;s first <a href="https://ieeexplore.ieee.org/document/4569647">paper</a> appeared at the conference now named FOCS in 1970. It was titled, &#8220;Extended Precedence Languages, Bounded Right Context Languages, and Deterministic Languages.&#8221; Rather than invent a new complexity class, as even ChatGPT picked up on our common vice <a href="https://rjlipton.wpcomstaging.com/2023/04/01/the-chatgpt-conundrum/">recently</a>, she more economically collapsed some classes together. </p>
<p>
The combination of &#8220;theoretical and practical interest&#8221; as mentioned in her paper carried through to much other work in programming languages and their implementations, software tools and development environments, and needs of high-performance computing. Her work with students on the Berkeley Unix project led to their <a href="https://docs-archive.freebsd.org/44doc/psd/18.gprof/paper.pdf">paper</a> on the program profiling tool <a href="https://en.wikipedia.org/wiki/Gprof">gprof</a>. This is considered one of the classic papers from the Programming Language Design and Implementation (PLDI) conferences.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Graham is terrific. I only hope that she is able to help us better understand theory of all types. </p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T02:48:30Z">Tuesday, May 23 2023, 02:48</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.12097'>Nearly Optimal Algorithms for Testing and Learning Quantum Junta Channels</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zongbo Bao, Penghui Yao</p><p>We consider the problems of testing and learning quantum $k$-junta channels,
which are $n$-qubit to $n$-qubit quantum channels acting non-trivially on at
most $k$ out of $n$ qubits and leaving the rest of qubits unchanged. We show
the following.
</p>
<p>1. An $\widetilde{O}\left(\sqrt{k}\right)$-query algorithm to distinguish
whether the given channel is $k$-junta channel or is far from any $k$-junta
channels, and a lower bound $\Omega\left(\sqrt{k}\right)$ on the number of
queries;
</p>
<p>2. An $\widetilde{O}\left(4^k\right)$-query algorithm to learn a $k$-junta
channel, and a lower bound $\Omega\left(4^k/k\right)$ on the number of queries.
</p>
<p>This answers an open problem raised by Chen et al. (2023). In order to settle
these problems, we develop a Fourier analysis framework over the space of
superoperators and prove several fundamental properties, which extends the
Fourier analysis over the space of operators introduced in Montanaro and
Osborne (2010).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Bao_Z/0/1/0/all/0/1">Zongbo Bao</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yao_P/0/1/0/all/0/1">Penghui Yao</a></p><p>We consider the problems of testing and learning quantum $k$-junta channels,
which are $n$-qubit to $n$-qubit quantum channels acting non-trivially on at
most $k$ out of $n$ qubits and leaving the rest of qubits unchanged. We show
the following.
</p>
<p>1. An $\widetilde{O}\left(\sqrt{k}\right)$-query algorithm to distinguish
whether the given channel is $k$-junta channel or is far from any $k$-junta
channels, and a lower bound $\Omega\left(\sqrt{k}\right)$ on the number of
queries;
</p>
<p>2. An $\widetilde{O}\left(4^k\right)$-query algorithm to learn a $k$-junta
channel, and a lower bound $\Omega\left(4^k/k\right)$ on the number of queries.
</p>
<p>This answers an open problem raised by Chen et al. (2023). In order to settle
these problems, we develop a Fourier analysis framework over the space of
superoperators and prove several fundamental properties, which extends the
Fourier analysis over the space of operators introduced in Montanaro and
Osborne (2010).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T00:30:00Z">Tuesday, May 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.12176'>On the approximability and energy-flow modeling of the electric vehicle sharing problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Welverton R. Silva, F&#xe1;bio L. Usberti, Rafael C. S. Schouery</p><p>The electric vehicle sharing problem (EVSP) arises from the planning and
operation of one-way electric car-sharing systems. It aims to maximize the
total rental time of a fleet of electric vehicles while ensuring that all the
demands of the customer are fulfilled. In this paper, we expand the knowledge
on the complexity of the EVSP by showing that it is NP-hard to approximate it
to within a factor of $n^{1-\epsilon}$ in polynomial time, for any $\epsilon &gt;
0$, where $n$ denotes the number of customers, unless P = NP. In addition, we
also show that the problem does not have a monotone structure, which can be
detrimental to the development of heuristics employing constructive strategies.
Moreover, we propose a novel approach for the modeling of the EVSP based on
energy flows in the network. Based on the new model, we propose a relax-and-fix
strategy and an exact algorithm that uses a warm-start solution obtained from
our heuristic approach. We report computational results comparing our
formulation with the best-performing formulation in the literature. The results
show that our formulation outperforms the previous one concerning the number of
optimal solutions obtained, optimality gaps, and computational times.
Previously, $32.7\%$ of the instances remained unsolved (within a time limit of
one hour) by the best-performing formulation in the literature, while our
formulation obtained optimal solutions for all instances. To stress our
approaches, two more challenging new sets of instances were generated, for
which we were able to solve $49.5\%$ of the instances, with an average
optimality gap of $2.91\%$ for those not solved optimally.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Silva_W/0/1/0/all/0/1">Welverton R. Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Usberti_F/0/1/0/all/0/1">F&#xe1;bio L. Usberti</a>, <a href="http://arxiv.org/find/cs/1/au:+Schouery_R/0/1/0/all/0/1">Rafael C. S. Schouery</a></p><p>The electric vehicle sharing problem (EVSP) arises from the planning and
operation of one-way electric car-sharing systems. It aims to maximize the
total rental time of a fleet of electric vehicles while ensuring that all the
demands of the customer are fulfilled. In this paper, we expand the knowledge
on the complexity of the EVSP by showing that it is NP-hard to approximate it
to within a factor of $n^{1-\epsilon}$ in polynomial time, for any $\epsilon &gt;
0$, where $n$ denotes the number of customers, unless P = NP. In addition, we
also show that the problem does not have a monotone structure, which can be
detrimental to the development of heuristics employing constructive strategies.
Moreover, we propose a novel approach for the modeling of the EVSP based on
energy flows in the network. Based on the new model, we propose a relax-and-fix
strategy and an exact algorithm that uses a warm-start solution obtained from
our heuristic approach. We report computational results comparing our
formulation with the best-performing formulation in the literature. The results
show that our formulation outperforms the previous one concerning the number of
optimal solutions obtained, optimality gaps, and computational times.
Previously, $32.7\%$ of the instances remained unsolved (within a time limit of
one hour) by the best-performing formulation in the literature, while our
formulation obtained optimal solutions for all instances. To stress our
approaches, two more challenging new sets of instances were generated, for
which we were able to solve $49.5\%$ of the instances, with an average
optimality gap of $2.91\%$ for those not solved optimally.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T00:30:00Z">Tuesday, May 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11942'>OPTWIN: Drift identification with optimal sub-windows</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mauro Dalle Lucca Tosi, Martin Theobald</p><p>Online Learning (OL) is a field of research that is increasingly gaining
attention both in academia and industry. One of the main challenges of OL is
the inherent presence of concept drifts, which are commonly defined as
unforeseeable changes in the statistical properties of an incoming data stream
over time. The detection of concept drifts typically involves analyzing the
error rates produced by an underlying OL algorithm in order to identify if a
concept drift occurred or not, such that the OL algorithm can adapt
accordingly. Current concept-drift detectors perform very well, i.e., with low
false negative rates, but they still tend to exhibit high false positive rates
in the concept-drift detection. This may impact the performance of the learner
and result in an undue amount of computational resources spent on retraining a
model that actually still performs within its expected range. In this paper, we
propose OPTWIN, our "OPTimal WINdow" concept drift detector. OPTWIN uses a
sliding window of events over an incoming data stream to track the errors of an
OL algorithm. The novelty of OPTWIN is to consider both the means and the
variances of the error rates produced by a learner in order to split the
sliding window into two provably optimal sub-windows, such that the split
occurs at the earliest event at which a statistically significant difference
according to either the $t$- or the $f$-tests occurred. We assessed OPTWIN over
the MOA framework, using ADWIN, DDM, EDDM, STEPD and ECDD as baselines over 7
synthetic and real-world datasets, and in the presence of both sudden and
gradual concept drifts. In our experiments, we show that OPTWIN surpasses the
F1-score of the baselines in a statistically significant manner while
maintaining a lower detection delay and saving up to 21% of time spent on
retraining the models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tosi_M/0/1/0/all/0/1">Mauro Dalle Lucca Tosi</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobald_M/0/1/0/all/0/1">Martin Theobald</a></p><p>Online Learning (OL) is a field of research that is increasingly gaining
attention both in academia and industry. One of the main challenges of OL is
the inherent presence of concept drifts, which are commonly defined as
unforeseeable changes in the statistical properties of an incoming data stream
over time. The detection of concept drifts typically involves analyzing the
error rates produced by an underlying OL algorithm in order to identify if a
concept drift occurred or not, such that the OL algorithm can adapt
accordingly. Current concept-drift detectors perform very well, i.e., with low
false negative rates, but they still tend to exhibit high false positive rates
in the concept-drift detection. This may impact the performance of the learner
and result in an undue amount of computational resources spent on retraining a
model that actually still performs within its expected range. In this paper, we
propose OPTWIN, our "OPTimal WINdow" concept drift detector. OPTWIN uses a
sliding window of events over an incoming data stream to track the errors of an
OL algorithm. The novelty of OPTWIN is to consider both the means and the
variances of the error rates produced by a learner in order to split the
sliding window into two provably optimal sub-windows, such that the split
occurs at the earliest event at which a statistically significant difference
according to either the $t$- or the $f$-tests occurred. We assessed OPTWIN over
the MOA framework, using ADWIN, DDM, EDDM, STEPD and ECDD as baselines over 7
synthetic and real-world datasets, and in the presence of both sudden and
gradual concept drifts. In our experiments, we show that OPTWIN surpasses the
F1-score of the baselines in a statistically significant manner while
maintaining a lower detection delay and saving up to 21% of time spent on
retraining the models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T00:30:00Z">Tuesday, May 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.12023'>Stretch-width</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: &#xc9;douard Bonnet, Julien Duron</p><p>We introduce a new parameter, called stretch-width, that we show sits
strictly between clique-width and twin-width. Unlike the reduced parameters
[BKW '22], planar graphs and polynomial subdivisions do not have bounded
stretch-width. This leaves open the possibility of efficient algorithms for a
broad fragment of problems within Monadic Second-Order (MSO) logic on graphs of
bounded stretch-width. In this direction, we prove that graphs of bounded
maximum degree and bounded stretch-width have at most logarithmic treewidth. As
a consequence, in classes of bounded stretch-width, Maximum Independent Set can
be solved in subexponential time $2^{O(n^{4/5} \log n)}$ on $n$-vertex graphs,
and, if further the maximum degree is bounded, Existential Counting Modal Logic
[Pilipczuk '11] can be model-checked in polynomial time. We also give a
polynomial-time $O(\text{OPT}^2)$-approximation for the stretch-width of
symmetric $0,1$-matrices or ordered graphs. Somewhat unexpectedly, we prove
that exponential subdivisions of bounded-degree graphs have bounded
stretch-width. This allows to complement the logarithmic upper bound of
treewidth with a matching lower bound. We leave as open the existence of an
efficient approximation algorithm for the stretch-width of unordered graphs, if
the exponential subdivisions of all graphs have bounded stretch-width, and if
graphs of bounded stretch-width have logarithmic clique-width (or rank-width).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1">&#xc9;douard Bonnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Duron_J/0/1/0/all/0/1">Julien Duron</a></p><p>We introduce a new parameter, called stretch-width, that we show sits
strictly between clique-width and twin-width. Unlike the reduced parameters
[BKW '22], planar graphs and polynomial subdivisions do not have bounded
stretch-width. This leaves open the possibility of efficient algorithms for a
broad fragment of problems within Monadic Second-Order (MSO) logic on graphs of
bounded stretch-width. In this direction, we prove that graphs of bounded
maximum degree and bounded stretch-width have at most logarithmic treewidth. As
a consequence, in classes of bounded stretch-width, Maximum Independent Set can
be solved in subexponential time $2^{O(n^{4/5} \log n)}$ on $n$-vertex graphs,
and, if further the maximum degree is bounded, Existential Counting Modal Logic
[Pilipczuk '11] can be model-checked in polynomial time. We also give a
polynomial-time $O(\text{OPT}^2)$-approximation for the stretch-width of
symmetric $0,1$-matrices or ordered graphs. Somewhat unexpectedly, we prove
that exponential subdivisions of bounded-degree graphs have bounded
stretch-width. This allows to complement the logarithmic upper bound of
treewidth with a matching lower bound. We leave as open the existence of an
efficient approximation algorithm for the stretch-width of unordered graphs, if
the exponential subdivisions of all graphs have bounded stretch-width, and if
graphs of bounded stretch-width have logarithmic clique-width (or rank-width).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T00:30:00Z">Tuesday, May 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.12119'>Distortion in metric matching with ordinal preferences</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nima Anari, Moses Charikar, Prasanna Ramakrishnan</p><p>Suppose that we have $n$ agents and $n$ items which lie in a shared metric
space. We would like to match the agents to items such that the total distance
from agents to their matched items is as small as possible. However, instead of
having direct access to distances in the metric, we only have each agent's
ranking of the items in order of distance. Given this limited information, what
is the minimum possible worst-case approximation ratio (known as the
distortion) that a matching mechanism can guarantee?
</p>
<p>Previous work by Caragiannis et al. proved that the (deterministic) Serial
Dictatorship mechanism has distortion at most $2^n - 1$. We improve this by
providing a simple deterministic mechanism that has distortion $O(n^2)$. We
also provide the first nontrivial lower bound on this problem, showing that any
matching mechanism (deterministic or randomized) must have worst-case
distortion $\Omega(\log n)$.
</p>
<p>In addition to these new bounds, we show that a large class of truthful
mechanisms derived from Deferred Acceptance all have worst-case distortion at
least $2^n - 1$, and we find an intriguing connection between thin matchings
(analogous to the well-known thin trees conjecture) and the distortion gap
between deterministic and randomized mechanisms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Anari_N/0/1/0/all/0/1">Nima Anari</a>, <a href="http://arxiv.org/find/cs/1/au:+Charikar_M/0/1/0/all/0/1">Moses Charikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_P/0/1/0/all/0/1">Prasanna Ramakrishnan</a></p><p>Suppose that we have $n$ agents and $n$ items which lie in a shared metric
space. We would like to match the agents to items such that the total distance
from agents to their matched items is as small as possible. However, instead of
having direct access to distances in the metric, we only have each agent's
ranking of the items in order of distance. Given this limited information, what
is the minimum possible worst-case approximation ratio (known as the
distortion) that a matching mechanism can guarantee?
</p>
<p>Previous work by Caragiannis et al. proved that the (deterministic) Serial
Dictatorship mechanism has distortion at most $2^n - 1$. We improve this by
providing a simple deterministic mechanism that has distortion $O(n^2)$. We
also provide the first nontrivial lower bound on this problem, showing that any
matching mechanism (deterministic or randomized) must have worst-case
distortion $\Omega(\log n)$.
</p>
<p>In addition to these new bounds, we show that a large class of truthful
mechanisms derived from Deferred Acceptance all have worst-case distortion at
least $2^n - 1$, and we find an intriguing connection between thin matchings
(analogous to the well-known thin trees conjecture) and the distortion gap
between deterministic and randomized mechanisms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-23T00:30:00Z">Tuesday, May 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, May 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11276'>Perspective on complexity measures targetting read-once branching programs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yaqiao Li, Pierre McKenzie</p><p>A model of computation for which reasonable yet still incomplete lower bounds
are known is the read-once branching program. Here variants of complexity
measures successful in the study of read-once branching programs are defined
and studied. Some new or simpler proofs of known bounds are uncovered.
Branching program resources and the new measures are compared extensively. The
new variants are developed in part in the hope of tackling read-k branching
programs for the tree evaluation problem studied in Cook et al. Other
computation problems are studied as well. In particular, a common view of a
function studied by Gal and a function studied by Bollig and Wegener leads to
the general combinatorics of blocking sets. Technical combinatorial results of
independent interest are obtained. New leads towards further progress are
discussed. An exponential lower bound for non-deterministic read-k branching
programs for the GEN function is also derived, independently from the new
measures.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yaqiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+McKenzie_P/0/1/0/all/0/1">Pierre McKenzie</a></p><p>A model of computation for which reasonable yet still incomplete lower bounds
are known is the read-once branching program. Here variants of complexity
measures successful in the study of read-once branching programs are defined
and studied. Some new or simpler proofs of known bounds are uncovered.
Branching program resources and the new measures are compared extensively. The
new variants are developed in part in the hope of tackling read-k branching
programs for the tree evaluation problem studied in Cook et al. Other
computation problems are studied as well. In particular, a common view of a
function studied by Gal and a function studied by Bollig and Wegener leads to
the general combinatorics of blocking sets. Technical combinatorial results of
independent interest are obtained. New leads towards further progress are
discussed. An exponential lower bound for non-deterministic read-k branching
programs for the GEN function is also derived, independently from the new
measures.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11813'>Making $\textsf{IP}=\textsf{PSPACE}$ Practical: Efficient Interactive Protocols for BDD Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eszter Couillard, Philipp Czerner, Javier Esparza, Rupak Majumdar</p><p>We show that interactive protocols between a prover and a verifier, a
well-known tool of complexity theory, can be used in practice to certify the
correctness of automated reasoning tools.
</p>
<p>Theoretically, interactive protocols exist for all $\textsf{PSPACE}$
problems. The verifier of a protocol checks the prover's answer to a problem
instance in polynomial time, with polynomially many bits of communication, and
with exponentially small probability of error. (The prover may need exponential
time.) Existing interactive protocols are not used in practice because their
provers use naive algorithms, inefficient even for small instances, that are
incompatible with practical implementations of automated reasoning.
</p>
<p>We bridge the gap between theory and practice by means of a novel interactive
protocol whose prover uses BDDs. We consider the problem of counting the number
of assignments to a QBF instance ($\#\textrm{CP}$), which has a natural
BDD-based algorithm. We give an interactive protocol for $\#\textrm{CP}$ whose
prover is implemented on top of an extended BDD library. The prover has only a
linear overhead in computation time over the natural algorithm.
</p>
<p>We have implemented our protocol in $\textsf{blic}$, a certifying tool for
$\#\textrm{CP}$. Experiments on standard QBF benchmarks show that \blic\ is
competitive with state-of-the-art QBF-solvers. The run time of the verifier is
negligible. While loss of absolute certainty can be concerning, the error
probability in our experiments is at most $10^{-10}$ and reduces to $10^{-10k}$
by repeating the verification $k$ times.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Couillard_E/0/1/0/all/0/1">Eszter Couillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Czerner_P/0/1/0/all/0/1">Philipp Czerner</a>, <a href="http://arxiv.org/find/cs/1/au:+Esparza_J/0/1/0/all/0/1">Javier Esparza</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumdar_R/0/1/0/all/0/1">Rupak Majumdar</a></p><p>We show that interactive protocols between a prover and a verifier, a
well-known tool of complexity theory, can be used in practice to certify the
correctness of automated reasoning tools.
</p>
<p>Theoretically, interactive protocols exist for all $\textsf{PSPACE}$
problems. The verifier of a protocol checks the prover's answer to a problem
instance in polynomial time, with polynomially many bits of communication, and
with exponentially small probability of error. (The prover may need exponential
time.) Existing interactive protocols are not used in practice because their
provers use naive algorithms, inefficient even for small instances, that are
incompatible with practical implementations of automated reasoning.
</p>
<p>We bridge the gap between theory and practice by means of a novel interactive
protocol whose prover uses BDDs. We consider the problem of counting the number
of assignments to a QBF instance ($\#\textrm{CP}$), which has a natural
BDD-based algorithm. We give an interactive protocol for $\#\textrm{CP}$ whose
prover is implemented on top of an extended BDD library. The prover has only a
linear overhead in computation time over the natural algorithm.
</p>
<p>We have implemented our protocol in $\textsf{blic}$, a certifying tool for
$\#\textrm{CP}$. Experiments on standard QBF benchmarks show that \blic\ is
competitive with state-of-the-art QBF-solvers. The run time of the verifier is
negligible. While loss of absolute certainty can be concerning, the error
probability in our experiments is at most $10^{-10}$ and reduces to $10^{-10k}$
by repeating the verification $k$ times.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11833'>Complexity of Neural Network Training and ETR: Extensions with Effectively Continuous Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Teemu Hankala, Miika Hannula, Juha Kontinen, Jonni Virtema</p><p>We study the complexity of the problem of training neural networks defined
via various activation functions. The training problem is known to be
existsR-complete with respect to linear activation functions and the ReLU
activation function. We consider the complexity of the problem with respect to
the sigmoid activation function and other effectively continuous functions. We
show that these training problems are polynomial-time many-one bireducible to
the existential theory of the reals extended with the corresponding activation
functions. In particular, we establish that the sigmoid activation function
leads to the existential theory of the reals with the exponential function. It
is thus open, and equivalent with the decidability of the existential theory of
the reals with the exponential function, whether training neural networks using
the sigmoid activation function is algorithmically solvable. In contrast, we
obtain that the training problem is undecidable if sinusoidal activation
functions are considered. Finally, we obtain general upper bounds for the
complexity of the training problem in the form of low levels of the
arithmetical hierarchy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hankala_T/0/1/0/all/0/1">Teemu Hankala</a>, <a href="http://arxiv.org/find/cs/1/au:+Hannula_M/0/1/0/all/0/1">Miika Hannula</a>, <a href="http://arxiv.org/find/cs/1/au:+Kontinen_J/0/1/0/all/0/1">Juha Kontinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Virtema_J/0/1/0/all/0/1">Jonni Virtema</a></p><p>We study the complexity of the problem of training neural networks defined
via various activation functions. The training problem is known to be
existsR-complete with respect to linear activation functions and the ReLU
activation function. We consider the complexity of the problem with respect to
the sigmoid activation function and other effectively continuous functions. We
show that these training problems are polynomial-time many-one bireducible to
the existential theory of the reals extended with the corresponding activation
functions. In particular, we establish that the sigmoid activation function
leads to the existential theory of the reals with the exponential function. It
is thus open, and equivalent with the decidability of the existential theory of
the reals with the exponential function, whether training neural networks using
the sigmoid activation function is algorithmically solvable. In contrast, we
obtain that the training problem is undecidable if sinusoidal activation
functions are considered. Finally, we obtain general upper bounds for the
complexity of the training problem in the form of low levels of the
arithmetical hierarchy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11312'>Engineering an algorithm for constructing low-stretch geometric graphs with near-greedy average-degrees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: FNU Shariful, Justin Weathers, Anirban Ghosh, Giri Narasimhan</p><p>We design and engineer Fast-Sparse-Spanner, a simple and practical (fast and
memory-efficient) algorithm for constructing sparse low stretch-factor
geometric graphs on large pointsets in the plane. To our knowledge, this is the
first practical algorithm to construct fast low stretch-factor graphs on large
pointsets with average-degrees (hence, the number of edges) competitive with
that of greedy-spanners, the sparsest known class of Euclidean geometric
spanners.
</p>
<p>To evaluate our implementation in terms of computation speed, memory usage,
and quality of output, we performed extensive experiments with synthetic and
real-world pointsets, and by comparing it to our closest competitor Bucketing,
the fastest known greedy-spanner algorithm for pointsets in the plane, devised
by Alewijnse et al. (Algorithmica, 2017). We always found that
Fast-Sparse-Spanner generated near-greedy t-spanners while being fast and
memory-efficient. Our experiment with constructing a 1.1-spanner on a large
synthetic pointset with 128K points uniformly distributed within a square shows
more than a 41-fold speedup with roughly a third of the memory usage of that of
Bucketing, but with only a 3% increase in the average-degree of the resulting
graph. In terms of diameter, the graphs generated by Fast-Sparse-Spanner beat
greedy-spanners in most cases (have substantially lower diameter) while
maintaining near-greedy average-degree.
</p>
<p>As a byproduct of our research, we design and engineer Fast-Stretch-Factor, a
practical parallelizable algorithm that can measure the stretch-factor of any
graph generated by Fast-Sparse-Spanner. Our experiments show that it is much
faster than the naive Dijkstra-based stretch-factor measurement algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Shariful_F/0/1/0/all/0/1">FNU Shariful</a>, <a href="http://arxiv.org/find/cs/1/au:+Weathers_J/0/1/0/all/0/1">Justin Weathers</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Anirban Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_G/0/1/0/all/0/1">Giri Narasimhan</a></p><p>We design and engineer Fast-Sparse-Spanner, a simple and practical (fast and
memory-efficient) algorithm for constructing sparse low stretch-factor
geometric graphs on large pointsets in the plane. To our knowledge, this is the
first practical algorithm to construct fast low stretch-factor graphs on large
pointsets with average-degrees (hence, the number of edges) competitive with
that of greedy-spanners, the sparsest known class of Euclidean geometric
spanners.
</p>
<p>To evaluate our implementation in terms of computation speed, memory usage,
and quality of output, we performed extensive experiments with synthetic and
real-world pointsets, and by comparing it to our closest competitor Bucketing,
the fastest known greedy-spanner algorithm for pointsets in the plane, devised
by Alewijnse et al. (Algorithmica, 2017). We always found that
Fast-Sparse-Spanner generated near-greedy t-spanners while being fast and
memory-efficient. Our experiment with constructing a 1.1-spanner on a large
synthetic pointset with 128K points uniformly distributed within a square shows
more than a 41-fold speedup with roughly a third of the memory usage of that of
Bucketing, but with only a 3% increase in the average-degree of the resulting
graph. In terms of diameter, the graphs generated by Fast-Sparse-Spanner beat
greedy-spanners in most cases (have substantially lower diameter) while
maintaining near-greedy average-degree.
</p>
<p>As a byproduct of our research, we design and engineer Fast-Stretch-Factor, a
practical parallelizable algorithm that can measure the stretch-factor of any
graph generated by Fast-Sparse-Spanner. Our experiments show that it is much
faster than the naive Dijkstra-based stretch-factor measurement algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11552'>Advancing Front Mapping</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marco Livesu</p><p>We present Advancing Front Mapping (AFM), a provably robust algorithm for the
computation of surface mappings to simple base domains. Given an input mesh and
a convex or star-shaped target domain, AFM installs a (possibly refined)
version of the input connectivity into the target shape, generating a
piece-wise linear mapping between them. The algorithm is inspired by the
advancing front meshing paradigm, which is revisited to operate on two
embeddings at once, thus becoming a tool for compatible mesh generation. AFM
extends the capabilities of existing robust approaches, such as Tutte or
Progressive Embedding, by providing the same theoretical guarantees of
injectivity and at the same time introducing two key advantages: support for a
broader set of target domains (star-shaped polygons) and local mesh refinement,
which is used to automatically open the space of solutions in case a valid
mapping to the target domain does not exist. AFM relies solely on two
topological operators (triangle split and flip) and on the computation of
segment intersections, thus permitting to compute provably injective mappings
without solving any numerical problem. This makes the algorithm predictable and
easy to implement, debug and deploy. We validated the capabilities of AFM by
testing it on 36K input cases, showing that its theoretical guarantees nicely
transition to a robust and practical implementation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Livesu_M/0/1/0/all/0/1">Marco Livesu</a></p><p>We present Advancing Front Mapping (AFM), a provably robust algorithm for the
computation of surface mappings to simple base domains. Given an input mesh and
a convex or star-shaped target domain, AFM installs a (possibly refined)
version of the input connectivity into the target shape, generating a
piece-wise linear mapping between them. The algorithm is inspired by the
advancing front meshing paradigm, which is revisited to operate on two
embeddings at once, thus becoming a tool for compatible mesh generation. AFM
extends the capabilities of existing robust approaches, such as Tutte or
Progressive Embedding, by providing the same theoretical guarantees of
injectivity and at the same time introducing two key advantages: support for a
broader set of target domains (star-shaped polygons) and local mesh refinement,
which is used to automatically open the space of solutions in case a valid
mapping to the target domain does not exist. AFM relies solely on two
topological operators (triangle split and flip) and on the computation of
segment intersections, thus permitting to compute provably injective mappings
without solving any numerical problem. This makes the algorithm predictable and
easy to implement, debug and deploy. We validated the capabilities of AFM by
testing it on 36K input cases, showing that its theoretical guarantees nicely
transition to a robust and practical implementation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11286'>Improved and Partially-Tight Lower Bounds for Message-Passing Implementations of Multiplicity Queues</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anh Tran, Edward Talmage</p><p>A multiplicity queue is a concurrently-defined data type which relaxes the
conditions of a linearizable FIFO queue to allow concurrent Dequeue instances
to return the same value. It would seem that this should allow faster
implementations, as processes should not need to wait as long to learn about
concurrent operations at remote processes and previous work has shown that
multiplicity queues are computationally less complex than the unrelaxed
version. Intriguingly, recent work has shown that there is, in fact, not much
speedup possible versus an unrelaxed queue implementation. Seeking to
understand this difference between intuition and real behavior, we extend that
work, increasing the lower bound for uniform algorithms. Further, we outline a
path forward toward building proofs for even higher lower bounds, allowing us
to hypothesize that the worst-case time to Dequeue approaches maximum message
delay, which is similar to the time required for an unrelaxed Dequeue. We also
give an upper bound for a special case to show that our bounds are tight at
that point. To achieve our lower bounds, we use extended shifting arguments,
which have been rarely used but allow larger lower bounds than traditional
shifting arguments. We use these in series of inductive indistinguishability
proofs which allow us to extend our proofs beyond the usual limitations of
shifting arguments. This proof structure is an interesting contribution
independently of the main result, as developing new lower bound proof
techniques may have many uses in future work.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tran_A/0/1/0/all/0/1">Anh Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Talmage_E/0/1/0/all/0/1">Edward Talmage</a></p><p>A multiplicity queue is a concurrently-defined data type which relaxes the
conditions of a linearizable FIFO queue to allow concurrent Dequeue instances
to return the same value. It would seem that this should allow faster
implementations, as processes should not need to wait as long to learn about
concurrent operations at remote processes and previous work has shown that
multiplicity queues are computationally less complex than the unrelaxed
version. Intriguingly, recent work has shown that there is, in fact, not much
speedup possible versus an unrelaxed queue implementation. Seeking to
understand this difference between intuition and real behavior, we extend that
work, increasing the lower bound for uniform algorithms. Further, we outline a
path forward toward building proofs for even higher lower bounds, allowing us
to hypothesize that the worst-case time to Dequeue approaches maximum message
delay, which is similar to the time required for an unrelaxed Dequeue. We also
give an upper bound for a special case to show that our bounds are tight at
that point. To achieve our lower bounds, we use extended shifting arguments,
which have been rarely used but allow larger lower bounds than traditional
shifting arguments. We use these in series of inductive indistinguishability
proofs which allow us to extend our proofs beyond the usual limitations of
shifting arguments. This proof structure is an interesting contribution
independently of the main result, as developing new lower bound proof
techniques may have many uses in future work.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11352'>Efficient quantum linear solver algorithm with detailed running costs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David Jennings, Matteo Lostaglio, Sam Pallister, Andrew T Sornborger, Yi&#x11f;it Suba&#x15f;&#x131;</p><p>As we progress towards physical implementation of quantum algorithms it is
vital to determine the explicit resource costs needed to run them. Solving
linear systems of equations is a fundamental problem with a wide variety of
applications across many fields of science, and there is increasing effort to
develop quantum linear solver algorithms. Here we introduce a quantum linear
solver algorithm combining ideas from adiabatic quantum computing with
filtering techniques based on quantum signal processing. We give a closed
formula for the non-asymptotic query complexity $Q$ -- the exact number of
calls to a block-encoding of the linear system matrix -- as a function of
condition number $\kappa$, error tolerance $\epsilon$ and block-encoding
scaling factor $\alpha$. Our protocol reduces the cost of quantum linear
solvers over state-of-the-art close to an order of magnitude for early
implementations. The asymptotic scaling is $O(\kappa \log(\kappa/\epsilon))$,
slightly looser than the $O(\kappa \log(1/\epsilon))$ scaling of the
asymptotically optimal algorithm of Costa et al. However, our algorithm
outperforms the latter for all condition numbers up to $\kappa \approx
10^{32}$, at which point $Q$ is comparably large, and both algorithms are
anyway practically unfeasible. The present optimized analysis is both
problem-agnostic and architecture-agnostic, and hence can be deployed in any
quantum algorithm that uses linear solvers as a subroutine.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Jennings_D/0/1/0/all/0/1">David Jennings</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Lostaglio_M/0/1/0/all/0/1">Matteo Lostaglio</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pallister_S/0/1/0/all/0/1">Sam Pallister</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sornborger_A/0/1/0/all/0/1">Andrew T Sornborger</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Subasi_Y/0/1/0/all/0/1">Yi&#x11f;it Suba&#x15f;&#x131;</a></p><p>As we progress towards physical implementation of quantum algorithms it is
vital to determine the explicit resource costs needed to run them. Solving
linear systems of equations is a fundamental problem with a wide variety of
applications across many fields of science, and there is increasing effort to
develop quantum linear solver algorithms. Here we introduce a quantum linear
solver algorithm combining ideas from adiabatic quantum computing with
filtering techniques based on quantum signal processing. We give a closed
formula for the non-asymptotic query complexity $Q$ -- the exact number of
calls to a block-encoding of the linear system matrix -- as a function of
condition number $\kappa$, error tolerance $\epsilon$ and block-encoding
scaling factor $\alpha$. Our protocol reduces the cost of quantum linear
solvers over state-of-the-art close to an order of magnitude for early
implementations. The asymptotic scaling is $O(\kappa \log(\kappa/\epsilon))$,
slightly looser than the $O(\kappa \log(1/\epsilon))$ scaling of the
asymptotically optimal algorithm of Costa et al. However, our algorithm
outperforms the latter for all condition numbers up to $\kappa \approx
10^{32}$, at which point $Q$ is comparably large, and both algorithms are
anyway practically unfeasible. The present optimized analysis is both
problem-agnostic and architecture-agnostic, and hence can be deployed in any
quantum algorithm that uses linear solvers as a subroutine.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11580'>Approximate Distance Sensitivity Oracles in Subquadratic Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davide Bil&#xf2;, Shiri Chechik, Keerti Choudhary, Sarel Cohen, Tobias Friedrich, Simon Krogmann, Martin Schirneck</p><p>An $f$-edge fault-tolerant distance sensitive oracle ($f$-DSO) with stretch
$\sigma \ge 1$ is a data structure that preprocesses a given undirected,
unweighted graph $G$ with $n$ vertices and $m$ edges, and a positive integer
$f$. When queried with a pair of vertices $s, t$ and a set $F$ of at most $f$
edges, it returns a $\sigma$-approximation of the $s$-$t$-distance in $G-F$. We
study $f$-DSOs that take subquadratic space. Thorup and Zwick [JACM 2015]
showed that this is only possible for $\sigma \ge 3$. We present, for any
constant $f \ge 1$ and $\alpha \in (0, \frac{1}{2})$, and any $\varepsilon &gt;
0$, an $f$-DSO with stretch $ 3 + \varepsilon$ that takes
$\widetilde{O}(n^{2-\frac{\alpha}{f+1}}/\varepsilon) \cdot O(\log
n/\varepsilon)^{f+1}$ space and has an $O(n^\alpha/\varepsilon^2)$ query time.
We also give an improved construction for graphs with diameter at most $D$. For
any constant $k$, we devise an $f$-DSO with stretch $2k-1$ that takes
$O(D^{f+o(1)} n^{1+1/k})$ space and has $\widetilde{O}(D^{o(1)})$ query time,
with a preprocessing time of $O(D^{f+o(1)} mn^{1/k})$. Chechik, Cohen, Fiat,
and Kaplan [SODA 2017] presented an $f$-DSO with stretch $1{+}\varepsilon$ and
preprocessing time $O_\varepsilon(n^{5+o(1)})$, albeit with a super-quadratic
space requirement. We show how to reduce their preprocessing time to
$O_{\varepsilon}(mn^{2+o(1)})$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bilo_D/0/1/0/all/0/1">Davide Bil&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_S/0/1/0/all/0/1">Shiri Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_K/0/1/0/all/0/1">Keerti Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Sarel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrich_T/0/1/0/all/0/1">Tobias Friedrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Krogmann_S/0/1/0/all/0/1">Simon Krogmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schirneck_M/0/1/0/all/0/1">Martin Schirneck</a></p><p>An $f$-edge fault-tolerant distance sensitive oracle ($f$-DSO) with stretch
$\sigma \ge 1$ is a data structure that preprocesses a given undirected,
unweighted graph $G$ with $n$ vertices and $m$ edges, and a positive integer
$f$. When queried with a pair of vertices $s, t$ and a set $F$ of at most $f$
edges, it returns a $\sigma$-approximation of the $s$-$t$-distance in $G-F$. We
study $f$-DSOs that take subquadratic space. Thorup and Zwick [JACM 2015]
showed that this is only possible for $\sigma \ge 3$. We present, for any
constant $f \ge 1$ and $\alpha \in (0, \frac{1}{2})$, and any $\varepsilon &gt;
0$, an $f$-DSO with stretch $ 3 + \varepsilon$ that takes
$\widetilde{O}(n^{2-\frac{\alpha}{f+1}}/\varepsilon) \cdot O(\log
n/\varepsilon)^{f+1}$ space and has an $O(n^\alpha/\varepsilon^2)$ query time.
We also give an improved construction for graphs with diameter at most $D$. For
any constant $k$, we devise an $f$-DSO with stretch $2k-1$ that takes
$O(D^{f+o(1)} n^{1+1/k})$ space and has $\widetilde{O}(D^{o(1)})$ query time,
with a preprocessing time of $O(D^{f+o(1)} mn^{1/k})$. Chechik, Cohen, Fiat,
and Kaplan [SODA 2017] presented an $f$-DSO with stretch $1{+}\varepsilon$ and
preprocessing time $O_\varepsilon(n^{5+o(1)})$, albeit with a super-quadratic
space requirement. We show how to reduce their preprocessing time to
$O_{\varepsilon}(mn^{2+o(1)})$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11639'>Distributed MIS with Low Energy and Time Complexities</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Ghaffari, Julian Portmann</p><p>We present randomized distributed algorithms for the maximal independent set
problem (MIS) that, while keeping the time complexity nearly matching the best
known, reduce the energy complexity substantially. These algorithms work in the
standard CONGEST model of distributed message passing with $O(\log n)$ bit
messages. The time complexity measures the number of rounds in the algorithm.
The energy complexity measures the number of rounds each node is awake; during
other rounds, the node sleeps and cannot perform any computation or
communications.
</p>
<p>Our first algorithm has an energy complexity of $O(\log\log n)$ and a time
complexity of $O(\log^2 n)$. Our second algorithm is faster but slightly less
energy-efficient: it achieves an energy complexity of $O(\log^2 \log n)$ and a
time complexity of $O(\log n \cdot \log\log n \cdot \log^* n)$. Thus, this
algorithm nearly matches the $O(\log n)$ time complexity of the
state-of-the-art MIS algorithms while significantly reducing their energy
complexity from $O(\log n)$ to $O(\log^2 \log n)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Portmann_J/0/1/0/all/0/1">Julian Portmann</a></p><p>We present randomized distributed algorithms for the maximal independent set
problem (MIS) that, while keeping the time complexity nearly matching the best
known, reduce the energy complexity substantially. These algorithms work in the
standard CONGEST model of distributed message passing with $O(\log n)$ bit
messages. The time complexity measures the number of rounds in the algorithm.
The energy complexity measures the number of rounds each node is awake; during
other rounds, the node sleeps and cannot perform any computation or
communications.
</p>
<p>Our first algorithm has an energy complexity of $O(\log\log n)$ and a time
complexity of $O(\log^2 n)$. Our second algorithm is faster but slightly less
energy-efficient: it achieves an energy complexity of $O(\log^2 \log n)$ and a
time complexity of $O(\log n \cdot \log\log n \cdot \log^* n)$. Thus, this
algorithm nearly matches the $O(\log n)$ time complexity of the
state-of-the-art MIS algorithms while significantly reducing their energy
complexity from $O(\log n)$ to $O(\log^2 \log n)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11644'>Deterministic Fault-Tolerant Distributed Computing in Linear Time and Communication</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bogdan S. Chlebus, Dariusz R. Kowalski, Jan Olkowski</p><p>We develop deterministic algorithms for the problems of consensus, gossiping
and checkpointing with nodes prone to failing. Distributed systems are modeled
as synchronous complete networks. Failures are represented either as crashes or
authenticated Byzantine faults. The algorithmic goal is to have both linear
running time and linear amount of communication for as large an upper bound $t$
on the number of faults as possible, with respect to the number of nodes~$n$.
For crash failures, these bounds of optimality are $t=\mathcal{O}(\frac{n}{\log
n})$ for consensus and $t=\mathcal{O}(\frac{n}{\log^2 n})$ for gossiping and
checkpointing, while the running time for each algorithm is $\Theta(t+\log n)$.
For the authenticated Byzantine model of failures, we show how to accomplish
both linear running time and communication for $t=\mathcal{O}(\sqrt{n})$. We
show how to implement the algorithms in the single-port model, in which a node
may choose only one other node to send/receive a message to/from in a round,
such as to preserve the range of running time and communication optimality. We
prove lower bounds to show the optimality of some performance bounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chlebus_B/0/1/0/all/0/1">Bogdan S. Chlebus</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowalski_D/0/1/0/all/0/1">Dariusz R. Kowalski</a>, <a href="http://arxiv.org/find/cs/1/au:+Olkowski_J/0/1/0/all/0/1">Jan Olkowski</a></p><p>We develop deterministic algorithms for the problems of consensus, gossiping
and checkpointing with nodes prone to failing. Distributed systems are modeled
as synchronous complete networks. Failures are represented either as crashes or
authenticated Byzantine faults. The algorithmic goal is to have both linear
running time and linear amount of communication for as large an upper bound $t$
on the number of faults as possible, with respect to the number of nodes~$n$.
For crash failures, these bounds of optimality are $t=\mathcal{O}(\frac{n}{\log
n})$ for consensus and $t=\mathcal{O}(\frac{n}{\log^2 n})$ for gossiping and
checkpointing, while the running time for each algorithm is $\Theta(t+\log n)$.
For the authenticated Byzantine model of failures, we show how to accomplish
both linear running time and communication for $t=\mathcal{O}(\sqrt{n})$. We
show how to implement the algorithms in the single-port model, in which a node
may choose only one other node to send/receive a message to/from in a round,
such as to preserve the range of running time and communication optimality. We
prove lower bounds to show the optimality of some performance bounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.11765'>Tester-Learners for Halfspaces: Universal Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aravind Gollakota, Adam R. Klivans, Konstantinos Stavropoulos, Arsen Vasilyan</p><p>We give the first tester-learner for halfspaces that succeeds universally
over a wide class of structured distributions. Our universal tester-learner
runs in fully polynomial time and has the following guarantee: the learner
achieves error $O(\mathrm{opt}) + \epsilon$ on any labeled distribution that
the tester accepts, and moreover, the tester accepts whenever the marginal is
any distribution that satisfies a Poincar\'e inequality. In contrast to prior
work on testable learning, our tester is not tailored to any single target
distribution but rather succeeds for an entire target class of distributions.
The class of Poincar\'e distributions includes all strongly log-concave
distributions, and, assuming the Kannan--L\'{o}vasz--Simonovits (KLS)
conjecture, includes all log-concave distributions. In the special case where
the label noise is known to be Massart, our tester-learner achieves error
$\mathrm{opt} + \epsilon$ while accepting all log-concave distributions
unconditionally (without assuming KLS). Our tests rely on checking
hypercontractivity of the unknown distribution using a sum-of-squares (SOS)
program, and crucially make use of the fact that Poincar\'e distributions are
certifiably hypercontractive in the SOS framework.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gollakota_A/0/1/0/all/0/1">Aravind Gollakota</a>, <a href="http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1">Adam R. Klivans</a>, <a href="http://arxiv.org/find/cs/1/au:+Stavropoulos_K/0/1/0/all/0/1">Konstantinos Stavropoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasilyan_A/0/1/0/all/0/1">Arsen Vasilyan</a></p><p>We give the first tester-learner for halfspaces that succeeds universally
over a wide class of structured distributions. Our universal tester-learner
runs in fully polynomial time and has the following guarantee: the learner
achieves error $O(\mathrm{opt}) + \epsilon$ on any labeled distribution that
the tester accepts, and moreover, the tester accepts whenever the marginal is
any distribution that satisfies a Poincar\'e inequality. In contrast to prior
work on testable learning, our tester is not tailored to any single target
distribution but rather succeeds for an entire target class of distributions.
The class of Poincar\'e distributions includes all strongly log-concave
distributions, and, assuming the Kannan--L\'{o}vasz--Simonovits (KLS)
conjecture, includes all log-concave distributions. In the special case where
the label noise is known to be Massart, our tester-learner achieves error
$\mathrm{opt} + \epsilon$ while accepting all log-concave distributions
unconditionally (without assuming KLS). Our tests rely on checking
hypercontractivity of the unknown distribution using a sum-of-squares (SOS)
program, and crucially make use of the fact that Poincar\'e distributions are
certifiably hypercontractive in the SOS framework.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-22T00:30:00Z">Monday, May 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, May 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/05/logic-and-lack-of-logic-of-anti-vaxers.html'>Logic and lack of Logic of Anti Vaxers</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>I wrote the&nbsp; post below the dotted line a long time ago but never got around to posting it. Now that&nbsp;</p><p><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; WHO says COVID emergency is over.</p><p>(When I first saw I misread it as a question:&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Who says COVID emergency is over?&nbsp;</p><p>)&nbsp;</p><p>I decided to post it (with one update that has an ADDED LATER on it).&nbsp;</p><p>If you didn't know , WHO is World Health Organization. Actually, that is true whether or not you know it.</p><p>------------------------------------------------------------------------------------</p><p>Some of the reasons anti-vaxers give are better than others. Some are consistent, some are not.&nbsp;</p><p>We list some of them and invite the comments to list more. Our point is- which ones have something interesting to say?&nbsp;</p><p><br>I am PRO VAX but I often seek out intelligent opposing views on any of my opinions. Did I find any here? I leave that as an exercise for the reader.&nbsp;</p><p><br></p><p>Reasons anti-vaxxers give or could give.&nbsp;</p><p>a)&nbsp;FREEDOM!&nbsp;That's not quite a reason. I am reminded of asking a neighbor why he flies a confederate flag and he said</p><p>FREEDOM!</p><p>I was hoping he would say either</p><p>To honor my great grandfather who died for the south in the civil war.</p><p>or</p><p>Because I don't like black people.</p><p>or</p><p>To honor those many people, black and white, who died in the civil war fighting for the south.&nbsp;</p><p>or</p><p>SOMETHING with content to it.&nbsp;<br><br></p><p>Any of those answered would tell me something could be discussed. Just the word FREEDOM does not.&nbsp;</p><p>b)&nbsp;Bill Gates put microchips in the vaccine so he can keep track of where you are. Why? Bill Gates and Mark Zuckerberg can ALREADY keep track of where you are. I do wonder if this is a common anti-vax viewpoint or if its VERY RARE and the media plays it up to make anti-vaxers look stupid. Same with the notion that the vaccine makes you magnetic (that sounds cool!)</p><p>c) I&nbsp;want to wait and see its effects since it was rushed out. That might have made sense&nbsp; X months ago, but by now its very well established.</p><p>d)&nbsp;I haven't gotten around to it yet.&nbsp;These are a very good target for the mandates or at least to be talked into doing it. It may be more fun to talk about the radical anti-vaxers; however, if the&nbsp;haven't gotten&nbsp;around to it&nbsp;group all got vaccinated we would be closer to herd immunity.</p><p>e) I've got COVID so I am immune. This is true for Y months (I am not sure what Y is); however, the person I know who told me this had COVID about 3 years ago.&nbsp;&nbsp;But at least its an attempt at an argument.&nbsp;</p><p>f)&nbsp;The medical community has been bad to (i) me, (ii) my people, (iii) some other people that I care&nbsp;about hence I do not trust them.&nbsp;The premise is actually true, so this is an attempt at an intelligent argument.&nbsp;</p><p>g)&nbsp;Big Pharma&nbsp;is making a mint on this and ripping us off.&nbsp;This is a view of, not the extreme left but the fringe left. Robert Kennedy is a big voice here, see&nbsp;here. On a right-wing relatives' urging I listened to an hour-long interview with him. Mostly a rambling incoherent argument. Much of it was anti-business which got no pushback from the usually-pro-business republican's. Are there any mainstream democrats who are anti-vax? I do not think so. Also, is it true that Big Pharma is is making a mint? Ripping us off? Ripping someone off? This could be an interesting question if asked more coherently. But its not a good reason to be anti-vax.&nbsp;</p><p>h) Trump said it was a hoax to get him out of office. Taking a vaccine now would be to admit its not a hoax. Such people should take Karl Popper's view of science: Conjecture that, as Ted Cruz said, if Biden wins then COVID will go away since it was a hoax made up to get Biden to win. If Biden wins and COVID does not go away then you must reject your conjecture. (ADDED LATER: Odd point- Trump has sometimes said, though not lately, that people should get the Vax that HE invented. If we called it a Trumpzine then would people take it? As of now Trump and DeathSantos are trying to anti-vax each other.)&nbsp;</p><p>i) The first few days after you take it it hurts and you feel tired or get chills or other reactions. This is actually true, though one has to balance that against getting COVID.</p><p>j) The Ford Administration really messed up on the Swine Flu so why trust the government now? This is true- The Ford Admin DID mess up. Oddly enough, I have never (or perhaps rarely) heard this as a reason. This puzzles me- Why claim Bill Gates microchip stuff (which is absurd) or Vax causes autism (debunked)&nbsp; and&nbsp; NOT use arguments are are more reasonable?</p><p>k) Vaccines cause autism. That study was debunked a long time ago, but it still lives on.</p><p>l) Kamala Harris said she was hesitant since it was rushed.&nbsp; I've only heard this one as Republicans&nbsp; try to blame her for Vaccine Hesitancy. The problem with that argument is that you are claiming that the anti-vaxers, who are mostly republicans, are listening to Kamala Harris for advice.</p><p>l)&nbsp;If many people get Vaxed and COVID goes away then Biden will look good, and we can't have that.</p><p>m) COVID was invented by the Chinese to cripple us. Uh- even if true (which it is not, though the leaked lab hypothesis might be) that's a reason to TAKE it to thwart their plans. For that matter, Trump could have been Trumpian and PRO-MASK and&nbsp; PRO-VAX by blaming the Chinese and George Soros and the Deep State and Biden and Obama and of course Hillary,&nbsp; but using this to say WEAR THE MASK! TAKE THE VAX! to DEFEAT these ENEMIES who want to destroy America. Would that have worked to slow the spread of COVID? If so then would he have won re-election?&nbsp;</p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I wrote the&nbsp; post below the dotted line a long time ago but never got around to posting it. Now that&nbsp;</p><p><br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; WHO says COVID emergency is over.</p><p>(When I first saw I misread it as a question:&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Who says COVID emergency is over?&nbsp;</p><p>)&nbsp;</p><p>I decided to post it (with one update that has an ADDED LATER on it).&nbsp;</p><p>If you didn't know , WHO is World Health Organization. Actually, that is true whether or not you know it.</p><p>------------------------------------------------------------------------------------</p><p>Some of the reasons anti-vaxers give are better than others. Some are consistent, some are not.&nbsp;</p><p>We list some of them and invite the comments to list more. Our point is- which ones have something interesting to say?&nbsp;</p><p><br />I am PRO VAX but I often seek out intelligent opposing views on any of my opinions. Did I find any here? I leave that as an exercise for the reader.&nbsp;</p><p><br /></p><p>Reasons anti-vaxxers give or could give.&nbsp;</p><p>a)&nbsp;<i>FREEDOM!&nbsp;</i>That's not quite a reason. I am reminded of asking a neighbor why he flies a confederate flag and he said</p><p>FREEDOM!</p><p>I was hoping he would say either</p><p>To honor my great grandfather who died for the south in the civil war.</p><p>or</p><p>Because I don't like black people.</p><p>or</p><p>To honor those many people, black and white, who died in the civil war fighting for the south.&nbsp;</p><p>or</p><p>SOMETHING with content to it.&nbsp;<br /><br /></p><p>Any of those answered would tell me something could be discussed. Just the word FREEDOM does not.&nbsp;</p><p>b)&nbsp;<i>Bill Gates put microchips in the vaccine so he can keep track of where you are</i>. Why? Bill Gates and Mark Zuckerberg can ALREADY keep track of where you are. I do wonder if this is a common anti-vax viewpoint or if its VERY RARE and the media plays it up to make anti-vaxers look stupid. Same with the notion that the vaccine makes you magnetic (that sounds cool!)</p><p>c) I<i>&nbsp;want to wait and see its effects since it was rushed out</i>. That might have made sense&nbsp; X months ago, but by now its very well established.</p><p>d)&nbsp;<i>I haven't gotten around to it yet.</i>&nbsp;These are a very good target for the mandates or at least to be talked into doing it. It may be more fun to talk about the radical anti-vaxers; however, if the&nbsp;<i>haven't gotten</i>&nbsp;<i>around to it&nbsp;</i>group all got vaccinated we would be closer to herd immunity.</p><p>e) I<i>'ve got COVID so I am immune. </i>This is true for Y months (I am not sure what Y is); however, the person I know who told me this had COVID about 3 years ago.&nbsp;&nbsp;But at least its an attempt at an argument.&nbsp;</p><p>f)&nbsp;<i>The medical community has been bad to (i) me, (ii) my people, (iii) some other people that I care</i>&nbsp;<i>about hence I do not trust them.&nbsp;</i>The premise is actually true, so this is an attempt at an intelligent argument.&nbsp;</p><p>g)&nbsp;<i>Big Pharma&nbsp;is making a mint on this and ripping us off.</i>&nbsp;This is a view of, not the extreme left but the fringe left. Robert Kennedy is a big voice here, see&nbsp;<a href="https://www.mcgill.ca/oss/article/covid-19-health-pseudoscience/anti-vaccine-propaganda-robert-f-kennedy-jr">here</a>. On a right-wing relatives' urging I listened to an hour-long interview with him. Mostly a rambling incoherent argument. Much of it was anti-business which got no pushback from the usually-pro-business republican's. Are there any mainstream democrats who are anti-vax? I do not think so. Also, is it true that Big Pharma is is making a mint? Ripping us off? Ripping someone off? This could be an interesting question if asked more coherently. But its not a good reason to be anti-vax.&nbsp;</p><p>h) Trump said it was a hoax to get him out of office. Taking a vaccine now would be to admit its not a hoax. Such people should take Karl Popper's view of science: Conjecture that, as Ted Cruz said, if Biden wins then COVID will go away since it was a hoax made up to get Biden to win. If Biden wins and COVID does not go away then you must reject your conjecture. (ADDED LATER: Odd point- Trump has sometimes said, though not lately, that people should get the Vax that HE invented. If we called it a Trumpzine then would people take it? As of now Trump and DeathSantos are trying to anti-vax each other.)&nbsp;</p><p>i) The first few days after you take it it hurts and you feel tired or get chills or other reactions. This is actually true, though one has to balance that against getting COVID.</p><p>j) The Ford Administration really messed up on the Swine Flu so why trust the government now? This is true- The Ford Admin DID mess up. Oddly enough, I have never (or perhaps rarely) heard this as a reason. This puzzles me- Why claim Bill Gates microchip stuff (which is absurd) or Vax causes autism (debunked)&nbsp; and&nbsp; NOT use arguments are are more reasonable?</p><p>k) Vaccines cause autism. That study was debunked a long time ago, but it still lives on.</p><p>l) Kamala Harris said she was hesitant since it was rushed.&nbsp; I've only heard this one as Republicans&nbsp; try to blame her for Vaccine Hesitancy. The problem with that argument is that you are claiming that the anti-vaxers, who are mostly republicans, are listening to Kamala Harris for advice.</p><p>l)&nbsp;If many people get Vaxed and COVID goes away then Biden will look good, and we can't have that.</p><p>m) COVID was invented by the Chinese to cripple us. Uh- even if true (which it is not, though the leaked lab hypothesis might be) that's a reason to TAKE it to thwart their plans. For that matter, Trump could have been Trumpian and PRO-MASK and&nbsp; PRO-VAX by blaming the Chinese and George Soros and the Deep State and Biden and Obama and of course Hillary,&nbsp; but using this to say WEAR THE MASK! TAKE THE VAX! to DEFEAT these ENEMIES who want to destroy America. Would that have worked to slow the spread of COVID? If so then would he have won re-election?&nbsp;</p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-21T12:25:00Z">Sunday, May 21 2023, 12:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/075'>TR23-075 |  Border Complexity of Symbolic Determinant under Rank One Restriction | 

	Abhranil Chatterjee, 

	Sumanta Ghosh, 

	Rohit Gurjar, 

	Roshan  Raj</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          VBP is the class of polynomial families that can be computed by the determinant of a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where the size of each $A_i$ is polynomial in the number of variables (equivalently, computable by polynomial-sized algebraic branching programs (ABP)). A major open problem in geometric complexity theory (GCT) is to determine whether VBP is closed under approximation. The power of approximation is well understood for some restricted models of computation, e.g., the class of depth-two circuits, read-once oblivious ABPs (ROABP), monotone ABPs, depth-three circuits of bounded top fan-in, and width-two ABPs. The former three classes are known to be closed under approximation [Bl&quot;{a}ser, Ikenmeyer, Mahajan, Pandey, and Saurabh (2020)], whereas the approximative closure of the last one captures the whole class of polynomial families computable by polynomial-sized formulas [Bringmann, Ikenmeyer, and Zuiddam (2017)].

In this work, we consider the subclass of VBP computed by the determinant of a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where for each $1\leq i \leq n$, $A_i$ is of rank one. It has been studied extensively [Edmonds(1968), Edmonds(1979)] and efficient identity testing algorithms are known [Lov&quot;{a}sz (1989), Gurjar and Thierauf (2020)]. We show that this class is closed under approximation. In the language of algebraic geometry,
we show that the set obtained by taking coordinatewise products of pairs of points from (the Pl\&quot;{u}cker embedding of) a Grassmannian variety is closed.
        
        </div>

        <div class='tr-article-summary'>
        
          
          VBP is the class of polynomial families that can be computed by the determinant of a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where the size of each $A_i$ is polynomial in the number of variables (equivalently, computable by polynomial-sized algebraic branching programs (ABP)). A major open problem in geometric complexity theory (GCT) is to determine whether VBP is closed under approximation. The power of approximation is well understood for some restricted models of computation, e.g., the class of depth-two circuits, read-once oblivious ABPs (ROABP), monotone ABPs, depth-three circuits of bounded top fan-in, and width-two ABPs. The former three classes are known to be closed under approximation [Bl&quot;{a}ser, Ikenmeyer, Mahajan, Pandey, and Saurabh (2020)], whereas the approximative closure of the last one captures the whole class of polynomial families computable by polynomial-sized formulas [Bringmann, Ikenmeyer, and Zuiddam (2017)].

In this work, we consider the subclass of VBP computed by the determinant of a symbolic matrix of the form $A_0 + \sum_{i=1}^n A_ix_i$ where for each $1\leq i \leq n$, $A_i$ is of rank one. It has been studied extensively [Edmonds(1968), Edmonds(1979)] and efficient identity testing algorithms are known [Lov&quot;{a}sz (1989), Gurjar and Thierauf (2020)]. We show that this class is closed under approximation. In the language of algebraic geometry,
we show that the set obtained by taking coordinatewise products of pairs of points from (the Pl\&quot;{u}cker embedding of) a Grassmannian variety is closed.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-21T06:59:02Z">Sunday, May 21 2023, 06:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/074'>TR23-074 |  Radical Sylvester-Gallai Theorem for Tuples of Quadratics | 

	Abhibhav Garg, 

	Rafael Mendes de Oliveira, 

	Shir Peleg, 

	Akash Sengupta</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We prove a higher codimensional radical Sylvester-Gallai type theorem for quadratic polynomials, simultaneously generalizing [Han65, Shp20]. Hansen&#39;s theorem is a high-dimensional version of the classical Sylvester-Gallai theorem in which the incidence condition is given by high-dimensional flats instead of lines. We generalize Hansen&#39;s theorem to the setting of quadratic forms in a polynomial ring, where the incidence condition is given by radical membership in a high-codimensional ideal. Our main theorem is also a generalization of the quadratic Sylvester--Gallai Theorem of [Shp20].

Our work is the first to prove a radical Sylvester--Gallai type theorem for arbitrary  codimension $k\geq 2$, whereas previous works [Shp20,PS20,PS21,OS22] considered the case of codimension $2$ ideals. Our techniques combine algebraic geometric and combinatorial arguments. A key ingredient is a structural result for ideals generated by a constant number of quadratics, showing that such ideals must be radical whenever the quadratic forms are far apart. Using the wide algebras defined in [OS22], combined with results about integral ring extensions and dimension theory, we develop new techniques for studying such ideals generated by quadratic forms. One advantage of our approach is that it does not need the finer classification theorems for codimension $2$ complete intersection of quadratics proved in [Shp20, GOS22].
        
        </div>

        <div class='tr-article-summary'>
        
          
          We prove a higher codimensional radical Sylvester-Gallai type theorem for quadratic polynomials, simultaneously generalizing [Han65, Shp20]. Hansen&#39;s theorem is a high-dimensional version of the classical Sylvester-Gallai theorem in which the incidence condition is given by high-dimensional flats instead of lines. We generalize Hansen&#39;s theorem to the setting of quadratic forms in a polynomial ring, where the incidence condition is given by radical membership in a high-codimensional ideal. Our main theorem is also a generalization of the quadratic Sylvester--Gallai Theorem of [Shp20].

Our work is the first to prove a radical Sylvester--Gallai type theorem for arbitrary  codimension $k\geq 2$, whereas previous works [Shp20,PS20,PS21,OS22] considered the case of codimension $2$ ideals. Our techniques combine algebraic geometric and combinatorial arguments. A key ingredient is a structural result for ideals generated by a constant number of quadratics, showing that such ideals must be radical whenever the quadratic forms are far apart. Using the wide algebras defined in [OS22], combined with results about integral ring extensions and dimension theory, we develop new techniques for studying such ideals generated by quadratic forms. One advantage of our approach is that it does not need the finer classification theorems for codimension $2$ complete intersection of quadratics proved in [Shp20, GOS22].
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-21T06:54:34Z">Sunday, May 21 2023, 06:54</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/073'>TR23-073 |  Reducing Tarski to Unique Tarski (in the Black-box Model) | 

	Xi Chen, 

	Yuhao Li, 

	Mihalis Yannakakis</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study the problem of finding a Tarski fixed point over the $k$-dimensional grid $[n]^k$. We give a black-box reduction from the Tarski problem to the same problem with an additional promise that the input function has a unique fixed point. It implies that the Tarski problem and the unique Tarski problem have exactly the same query complexity. Our reduction is based on a novel notion of partial-information functions which we use to fool algorithms for the unique Tarski problem as if they were working on a monotone function with a unique fixed point.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study the problem of finding a Tarski fixed point over the $k$-dimensional grid $[n]^k$. We give a black-box reduction from the Tarski problem to the same problem with an additional promise that the input function has a unique fixed point. It implies that the Tarski problem and the unique Tarski problem have exactly the same query complexity. Our reduction is based on a novel notion of partial-information functions which we use to fool algorithms for the unique Tarski problem as if they were working on a monotone function with a unique fixed point.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-21T02:59:43Z">Sunday, May 21 2023, 02:59</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, May 19
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/'>GPT as an “Intelligence Forklift.”</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          [See my&#160;post with Edelman on AI takeover and&#160;Aaronson on AI scenarios. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on Windows on Theory.] &#160;One challenge for considering the implications of “artificial intelligence,” especially of the “general” variety, is that we don’t have a consensus definition of intelligence. The&#160;Oxford Companion &#8230; Continue reading GPT as an &#8220;Intelligence Forklift.&#8221;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><em>[See my&nbsp;</em><a href="https://www.lesswrong.com/posts/zB3ukZJqt3pQDw9jz/ai-will-change-the-world-but-won-t-take-it-over-by-playing-3"><em><u>post with Edelman on AI takeover</u></em></a><em> and&nbsp;</em><a href="https://scottaaronson.blog/?p=7266"><em><u>Aaronson on AI scenarios</u></em></a><em>. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on </em><a href="https://windowsontheory.org/"><em>Windows on Theory</em></a><em>.]</em></p>



<p>&nbsp;<br>One challenge for considering the implications of “artificial intelligence,” especially of the “general” variety, is that we don’t have a consensus definition of intelligence. The&nbsp;<a href="https://www.amazon.com/Oxford-Companion-Mind-Companions/dp/0198662246"><u>Oxford Companion to the Mind</u></a> states that “there seem to be almost as many definitions of intelligence as experts asked to define it.”&nbsp; Indeed,&nbsp; in a recent discussion,&nbsp;<a href="https://www.lepoint.fr/sciences-nature/yuval-harari-sapiens-versus-yann-le-cun-meta-on-artificial-intelligence-11-05-2023-2519782_1924.php#11"><u>Yann LeCun and Yuval Noah Harari</u></a> offered two different definitions. However, it seems many people agree that:</p>



<ol>
<li>Whatever intelligence is, more computational power or cognitive capacity (e.g., a more complex or larger neural network, a species with a larger brain)&nbsp; leads to more of it.&nbsp;</li>



<li>Whatever intelligence is, the more of it one has, the more one can impact one&#8217;s environment.&nbsp;</li>
</ol>



<p>1 and 2 together can already lead to growing concerns now that we are building artificial systems that every year are more powerful than the last.&nbsp;<a href="https://www.lesswrong.com/posts/3Jpchgy53D2gB5qdk/my-childhood-role-model"><u>Yudkowski</u></a> presents potential progress on intelligence with something like the following chart (taken from&nbsp;<a href="https://intelligenceexplosion.com/2011/plenty-of-room-above-us/"><u>Muehlhauser</u></a>):</p>



<figure class="wp-block-image"><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/cfee2d12a17cf70d8bfdc038070a679c423c7061ed67439f.png" alt="" /></figure>



<p><br>Given that recent progress on AI was achieved by scaling ever larger amounts of computation and data, we might expect a cartoon that looks more like the following:</p>



<p><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/abf19d90ec5756ee84d74f5a21312ef7a7eb1fb11c8029f4.png" style="width: 600px"></p>



<p><em>(Don’t take this cartoon or numbers too seriously. It is obtained by superimposing a hypothetical 1000T param model on the figure from </em><a href="https://chomsky.info/20140826/"><em><u>Bolhuis, Tattersall, Chomsky and Berwick</u></em></a><em>. 100T connections in Homo sapiens brain is a </em><a href="https://www.scientificamerican.com/article/100-trillion-connections/"><em><u>rough estimate</u></em></a><em>.  Axes implicitly assume </em><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8463089/"><em><u>synaptic density</u></em></a><em> scales with volume.)</em></p>



<p><br>Whether the first or the second cartoon is more accurate, the idea of constructing intelligence that surpasses ours to an increasing degree and on a growing number of dimensions is understandably unsettling to many people. (Especially given that none of the other species of the genus&nbsp;<em>Homo</em> in the chart above survived.)&nbsp; This post is&nbsp;<em>not</em> to say that we should not worry about this. Instead I suggest a different metaphor for how we could think of future powerful models.<br>&nbsp;</p>



<h2 class="wp-block-heading">Whose intelligence is it?</h2>



<p>In our own species’ evolution, as we have become more intelligent, we have become more able to act as&nbsp;<em>agents</em> that do not follow pre-ordained goals but rather choose our own. So we might imagine that there is some monotone “agency vs. intelligence” curve along the following:</p>



<figure class="wp-block-image"><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/8617e5cafd5f4c3a19ca6e894a8b921c6b503a7b39b313f0.png" alt="" /></figure>



<p>&nbsp;<em>(Once again, don’t take the cartoon too seriously; whether it is a step function, sigmoid-like, or some other monotone curve can be debatable and also depends on what one&#8217;s definitions of “agency” and “intelligence” are.)</em></p>



<p><br>But perhaps intelligence does not have to go hand-in-hand with agency. Consider the property of&nbsp;<strong>physical strength</strong>. Like intelligence, this is a capability that an individual can use to shape their environment. I am (much) weaker than&nbsp;<a href="https://en.wikipedia.org/wiki/Olga_Liashchuk"><u>Olga Liashchuk</u></a>, who can lift a 300kg Yoke and walk 24 meters with it in under 20 seconds.&nbsp; However, if I were to drive a forklift, the combination of me and the forklift would be stronger than her. Thus, if we measure strength in functional terms (what we can&nbsp;<em>do</em> with it) instead of by artificial competitions, it makes sense to consider strength as a&nbsp;<strong>property of a system rather than an individual</strong>. Strength can be aggregated to combine several systems into a stronger one or split up to use different parts of the capacity for different tasks.</p>



<p><br>Is there an&nbsp;<strong>“intelligence forklift”</strong>? It is hard to imagine a system that is more intelligent than humans but lacks agency. More accurately, up until recently, it would have been hard to imagine such a system. However, with generative pretrained transformers (GPTs), we have systems that have the potential to be just that. Even though recent GPTs undergo some adaptation and fine-tuning, the vast majority of the computational resources invested into GPTs is used to make them solve the task of finding a continuation of a sequence given its prefix.&nbsp;</p>



<p><br>We can phrase many general problems as special cases of the task above. (Indeed, with multimodal models, such tasks include essentially any problem that can be asked and answered using any type of digital representation.) Hence as GPT-n becomes better at this task, it is arguably becoming arbitrarily intelligent. However, it is still not an agent but rather a generic problem-solver. In that sense,&nbsp;<strong>GPTs can best be modeled as intelligence forklifts</strong>.</p>



<figure class="wp-block-image is-resized"><img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/9131b5cd330416a57ba14408cb461b4a2a3da0e89d8f224b.png" alt="" width="714" height="312" /></figure>



<p>By “intelligence forklift” I mean that such a model can augment an agent with arbitrary intelligence to complete the goals the agent seeks. The agent may be human, but it can also be an AI itself. For example, it might be obtained using fine-tuning, reinforcement learning, or prompt-engineering on GPT. (So, while GPT is not an agent, it can “play one on TV” if asked to do so in its prompt.) Therefore, the above does not mean that we should not be concerned about an artificial highly intelligent agent. However, if the vast majority of an agent’s intelligence is derived from the non-agentic “forklift” (which can be used by many other agents as well), then a&nbsp;<strong>multipolar scenario of many agents of competing objectives</strong> is more likely than a unipolar one of a single dominating actor. The multipolar scenario might not be safer, but it is different.<br>&nbsp;</p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T21:16:17Z">Friday, May 19 2023, 21:16</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7321'>Book Review: &#8220;Quantum Supremacy&#8221; by Michio Kaku (tl;dr DO NOT BUY)</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          When I was a teenager, I enjoyed reading Hyperspace, an early popularization of string theory by the theoretical physicist Michio Kaku. I&#8217;m sure I&#8217;d have plenty of criticisms if I reread it today, but at the time, I liked it a lot. In the decades since, Kaku has widened his ambit to, well, pretty much [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>When I was a teenager, I enjoyed reading <em><a href="https://www.amazon.com/Hyperspace-Scientific-Parallel-Universes-Dimension/dp/0385477058">Hyperspace</a></em>, an early popularization of string theory by the theoretical physicist Michio Kaku.  I&#8217;m sure I&#8217;d have plenty of criticisms if I reread it today, but at the time, I liked it a lot.  In the decades since, Kaku has widened his ambit to, well, pretty much everything, regularly churning out popular books with subtitles like &#8220;How Science Will Revolutionize the 21st Century&#8221; and &#8220;How Science Will Shape Human Destiny and Our Daily Lives.&#8221;  He&#8217;s also appeared on countless TV specials, in many cases to argue that UFOs likely contain extraterrestrial visitors.</p>



<p>Now Kaku has a new bestseller about quantum computing, creatively entitled <em><a href="https://www.amazon.com/Quantum-Supremacy-Computer-Revolution-Everything/dp/0385548362">Quantum Supremacy</a></em>.  He even <a href="https://ogjre.com/episode/1980-michio-kaku">appeared on Joe Rogan</a> a couple weeks ago to promote the book, surely reaching an orders-of-magnitude larger audience than I have in two decades of trying to explain quantum computing to non-experts.  (Incidentally, to those who&#8217;ve asked why Joe Rogan hasn&#8217;t invited <em>me</em> on his show to explain quantum computing: I guess you now have an answer of sorts!)</p>



<p>In the spirit, perhaps, of the TikTokkers who eat live cockroaches or whatever to satisfy their viewers, I decided to oblige loyal <em>Shtetl-Optimized</em> fans by buying <em>Quantum Supremacy</em> and reading it.  So I can now state with confidence: beating out a crowded field, this is <strong>the worst book about quantum computing,</strong> for some definition of the word &#8220;about,&#8221; that I&#8217;ve ever encountered.</p>



<p>Admittedly, it&#8217;s not obvious why I&#8217;m reviewing the book here at all.  Among people who&#8217;ve heard of this blog, I expect that approximately zero would be tempted to buy Kaku&#8217;s book, at least if they flipped through a few random pages and saw the &#8230; <em>level of care</em> that went into them.  Conversely, the book&#8217;s target readers have probably never visited a blog like this one and never will.  So what&#8217;s the use of this post?</p>



<p>Well, as the accidental #1 quantum computing blogger on the planet, I feel a sort of grim obligation here.  Who knows, maybe this post will show up in the first page of Google results for Kaku&#8217;s book, and it will manage to rescue two or three people from the kindergarten of lies.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Where to begin?  Should we just go through <em>the first chapter</em> with a red pen?  OK then: on the very first page, Kaku writes,</p>



<blockquote class="wp-block-quote">
<p>Google revealed that their Sycamore quantum computer could solve a mathematical problem in 200 seconds that would take 10,000 years on the world&#8217;s fastest supercomputer.</p>
</blockquote>



<p>No, the &#8220;10,000 years&#8221; estimate was <a href="https://scottaaronson.blog/?p=4372">quickly falsified</a>, as anyone following the subject knows.  I&#8217;d be the first to stress that the situation is complicated; compared to the best currently-known classical algorithms, some quantum advantage remains for the Random Circuit Sampling task, depending on how you measure it.  But to repeat the &#8220;10,000 years&#8221; figure at this point, with no qualifications, is actively misleading.</p>



<p>Turning to the second page:</p>



<blockquote class="wp-block-quote">
<p>[Quantum computers] are a new type of computer that can tackle problems that digital computers can never solve, even with an infinite amount of time.  For example, digital computers can never accurately calculate how atoms combine to create crucial chemical reactions, especially those that make life possible.  Digital computers can only compute on digital tape, consisting of a series of 0s and 1s, which are too crude to describe the delicate waves of electrons dancing deep inside a molecule.  For example, when tediously computing the paths taken by a mouse in a maze, a digital computer has to painfully analyze each possible path, one after the other.  A quantum computer, however, <em>simultaneously</em> analyzes all possible paths at the same time, with lightning speed.</p>
</blockquote>



<p>OK, so here Kaku has already perpetuated two of the most basic, forehead-banging errors about what quantum computers can do.  In truth, anything that a QC can calculate, a classical computer can calculate as well, <em>given exponentially more time</em>: for example, by representing the entire wavefunction, all 2<sup>n</sup> amplitudes, to whatever accuracy is needed.  That&#8217;s why it was understood from the very beginning that quantum computers can&#8217;t change what&#8217;s computable, but only how <em>efficiently</em> things can be computed.</p>



<p>And then there&#8217;s the Misconception of Misconceptions, about how a QC &#8220;analyzes all possible paths at the same time&#8221;&#8212;with no recognition anywhere of the central difficulty, the thing that makes a QC enormously <em>weaker</em> than an exponentially parallel classical computer, but is also the new and interesting part, namely that you only get to see a <em>single, random outcome</em> when you measure, with its probability given by the Born rule.  That&#8217;s the error so common that I warn against it right below the title of my blog.</p>



<blockquote class="wp-block-quote">
<p>[Q]uantum computers are so powerful that, in principle, they could break all known cybercodes.</p>
</blockquote>



<p>Nope, that&#8217;s strongly believed to be false, just like the analogous statement for <em>classical</em> computers.  Despite its obvious relevance for business and policy types, the entire field of <a href="https://en.wikipedia.org/wiki/Post-quantum_cryptography">post-quantum cryptography</a>&#8212;including the <a href="https://en.wikipedia.org/wiki/Lattice-based_cryptography">lattice-based public-key cryptosystems</a> that have by now survived 20+ years of efforts to find a quantum algorithm to break them&#8212;receives just a single vague mention, on pages 84-85.  The possibility of cryptography surviving quantum computers is quickly dismissed because &#8220;these new trapdoor functions are not easy to implement.&#8221;  (But they <em><a href="https://cloud.google.com/blog/products/identity-security/why-google-now-uses-post-quantum-cryptography-for-internal-comms">have</a></em> been implemented.)</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>There&#8217;s no attempt, anywhere in this book, to explain how any quantum algorithm actually works, let alone is there a word anywhere about the <em>limitations</em> of quantum algorithms.  And yet there&#8217;s still enough said to be wrong.  On page 84, shortly after confusing the concept of a <a href="https://en.wikipedia.org/wiki/One-way_function">one-way function</a> with that of a <a href="https://en.wikipedia.org/wiki/Trapdoor_function">trapdoor function</a>, Kaku writes:</p>



<blockquote class="wp-block-quote">
<p>Let N represent the number we wish to factorize.  For an ordinary digital computer, the amount of time it takes to factorize a number grows exponentially, like t ~ e<sup>N</sup>, times some unimportant factors.</p>
</blockquote>



<p>This is a double howler: first, trial division takes only ~√N time; Kaku has confused N itself with its <em>number of digits</em>, ~log<sub>2</sub>N.  Second, he seems unaware that much better classical factoring algorithms, like the <a href="https://en.wikipedia.org/wiki/General_number_field_sieve">Number Field Sieve</a>, have been known for decades, even though those algorithms play a central role in codebreaking and in any discussion of where the quantum/classical crossover might happen.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Honestly, though, the errors aren&#8217;t the worst of it.  The majority of the book is not even <em>worth</em> hunting for errors in, because fundamentally, it&#8217;s <em>filler</em>.</p>



<p>First there&#8217;s page after page breathlessly quoting prestigious-sounding people and organizations&#8212;Google&#8217;s Sundar Pichai, various government agencies, some report by Deloitte&#8212;about just how revolutionary they think quantum computing will be.  Then there are capsule hagiographies of Babbage and Lovelace, Gödel and Turing, Planck and Einstein, Feynman and Everett.</p>



<p>And then the bulk of the book is actually about stuff <em>with no direct relation to quantum computing at all</em>&#8212;the origin of life, climate change, energy generation, cancer, curing aging, etc.&#8212;except with ungrounded speculations tacked onto the end of each chapter about how quantum computers will someday revolutionize all of this.  Personally, I&#8217;d say that</p>



<ol>
<li>Quantum simulation speeding up progress in biochemistry, high-temperature superconductivity, and the like is at least <em>plausible</em>&#8212;though very far from guaranteed, since one has to beat the cleverest classical approaches that can be designed for the same problems (a point that Kaku nowhere grapples with).</li>



<li>The stuff involving optimization, machine learning, and the like is almost entirely wishful thinking.</li>



<li>Not once in the book has Kaku even <em>mentioned</em> the intellectual tools (e.g., looking at actual quantum algorithms like Grover’s algorithm or phase estimation, and their performance on various tasks) that would be needed to distinguish 1 from 2.</li>
</ol>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>In his acknowledgments section, Kaku simply lists a bunch of famous scientists he&#8217;s met in his life&#8212;Feynman, Witten, Hawking, Penrose, Brian Greene, Lisa Randall, Neil deGrasse Tyson.  Not a single living quantum computing researcher is acknowledged, not one.</p>



<p>Recently, I&#8217;d been cautiously optimistic that, after decades of overblown headlines about &#8220;trying all answers in parallel,&#8221; &#8220;cracking all known codes,&#8221; etc., the standard for quantum computing popularization was slowly creeping upward.  Maybe I was just bowled over by <a href="https://www.youtube.com/watch?v=-UrdExQW0cs">this recent YouTube video</a> (&#8220;How Quantum Computers Break the Internet&#8230; Starting Now&#8221;), which despite its clickbait title and its slick presentation, miraculously gets essentially everything right, shaming the hypesters by demonstrating just how much better it&#8217;s possible to do.</p>



<p>Kaku&#8217;s slapdash &#8220;book,&#8221; and the publicity campaign around it, represents a noxious step backwards.  The wonder of it, to me, is Kaku holds a PhD in theoretical physics.  And yet the average English major who&#8217;s written a &#8220;what&#8217;s the deal with quantum computing?&#8221; article for some obscure link aggregator site has done a more careful and honest job than Kaku has.  That&#8217;s setting the bar about a millimeter off the floor.  I think the difference is, at least the English major knows that they&#8217;re supposed to <em>call</em> an expert or two, when writing about an enormously complicated subject of which they&#8217;re completely ignorant.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Update:</mark></strong> I’ve now been immersed in the AI safety field for one year, let I wouldn’t consider myself <em>nearly</em> ready to write a book on the subject.  My knowledge of related parts of CS, my year studying AI in grad school, and my having created the subject of computational learning theory of quantum states would all be relevant but totally insufficient.  And AI safety, for all its importance, has less than quantum computing does in the way of difficult-to-understand concepts and results that basically everyone in the field agrees about.  And if I <em>did</em> someday write such a book, I’d be pretty terrified of getting stuff wrong, and would have multiple expert colleagues read drafts.</p>



<p>In case this wasn’t clear enough from my post, Kaku appears to have had zero prior engagement with quantum computing, <strong>and also </strong>to have consulted zero relevant experts who could’ve fixed his misconceptions.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T10:15:56Z">Friday, May 19 2023, 10:15</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10749'>On the Computational Complexity of Generalized Common Shape Puzzles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mutsunori Banbara, Shin-ichi Minato, Hirotaka Ono, Ryuhei Uehara</p><p>In this study, we investigate the computational complexity of some variants
of generalized puzzles. We are provided with two sets S_1 and S_2 of
polyominoes. The first puzzle asks us to form the same shape using polyominoes
in S_1 and S_2. We demonstrate that this is polynomial-time solvable if S_1 and
S_2 have constant numbers of polyominoes, and it is strongly NP-complete in
general. The second puzzle allows us to make copies of the pieces in S_1 and
S_2. That is, a polyomino in S_1 can be used multiple times to form a shape.
This is a generalized version of the classical puzzle known as the common
multiple shape puzzle. For two polyominoes P and Q, the common multiple shape
is a shape that can be formed by many copies of P and many copies of Q. We show
that the second puzzle is undecidable in general. The undecidability is
demonstrated by a reduction from a new type of undecidable puzzle based on
tiling. Nevertheless, certain concrete instances of the common multiple shape
can be solved in a practical time. We present a method for determining the
common multiple shape for provided tuples of polyominoes and outline concrete
results, which improve on the previously known results in puzzle society.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Banbara_M/0/1/0/all/0/1">Mutsunori Banbara</a>, <a href="http://arxiv.org/find/cs/1/au:+Minato_S/0/1/0/all/0/1">Shin-ichi Minato</a>, <a href="http://arxiv.org/find/cs/1/au:+Ono_H/0/1/0/all/0/1">Hirotaka Ono</a>, <a href="http://arxiv.org/find/cs/1/au:+Uehara_R/0/1/0/all/0/1">Ryuhei Uehara</a></p><p>In this study, we investigate the computational complexity of some variants
of generalized puzzles. We are provided with two sets S_1 and S_2 of
polyominoes. The first puzzle asks us to form the same shape using polyominoes
in S_1 and S_2. We demonstrate that this is polynomial-time solvable if S_1 and
S_2 have constant numbers of polyominoes, and it is strongly NP-complete in
general. The second puzzle allows us to make copies of the pieces in S_1 and
S_2. That is, a polyomino in S_1 can be used multiple times to form a shape.
This is a generalized version of the classical puzzle known as the common
multiple shape puzzle. For two polyominoes P and Q, the common multiple shape
is a shape that can be formed by many copies of P and many copies of Q. We show
that the second puzzle is undecidable in general. The undecidability is
demonstrated by a reduction from a new type of undecidable puzzle based on
tiling. Nevertheless, certain concrete instances of the common multiple shape
can be solved in a practical time. We present a method for determining the
common multiple shape for provided tuples of polyominoes and outline concrete
results, which improve on the previously known results in puzzle society.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.10922'>On $k$-means for segments and polylines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sergio Cabello, Panos Giannopoulos</p><p>We study the problem of $k$-means clustering in the space of straight-line
segments in $\mathbb{R}^{2}$ under the Hausdorff distance. For this problem, we
give a $(1+\epsilon)$-approximation algorithm that, for an input of $n$
segments, for any fixed $k$, and with constant success probability, runs in
time $O(n+ \epsilon^{-O(k)} + \epsilon^{-O(k)}\cdot \log^{O(k)}
(\epsilon^{-1}))$. The algorithm has two main ingredients. Firstly, we express
the $k$-means objective in our metric space as a sum of algebraic functions and
use the optimization technique of Vigneron~\cite{Vigneron14} to approximate its
minimum. Secondly, we reduce the input size by computing a small size coreset
using the sensitivity-based sampling framework by Feldman and
Langberg~\cite{Feldman11, Feldman2020}. Our results can be extended to
polylines of constant complexity with a running time of $O(n+
\epsilon^{-O(k)})$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cabello_S/0/1/0/all/0/1">Sergio Cabello</a>, <a href="http://arxiv.org/find/cs/1/au:+Giannopoulos_P/0/1/0/all/0/1">Panos Giannopoulos</a></p><p>We study the problem of $k$-means clustering in the space of straight-line
segments in $\mathbb{R}^{2}$ under the Hausdorff distance. For this problem, we
give a $(1+\epsilon)$-approximation algorithm that, for an input of $n$
segments, for any fixed $k$, and with constant success probability, runs in
time $O(n+ \epsilon^{-O(k)} + \epsilon^{-O(k)}\cdot \log^{O(k)}
(\epsilon^{-1}))$. The algorithm has two main ingredients. Firstly, we express
the $k$-means objective in our metric space as a sum of algebraic functions and
use the optimization technique of Vigneron~\cite{Vigneron14} to approximate its
minimum. Secondly, we reduce the input size by computing a small size coreset
using the sensitivity-based sampling framework by Feldman and
Langberg~\cite{Feldman11, Feldman2020}. Our results can be extended to
polylines of constant complexity with a running time of $O(n+
\epsilon^{-O(k)})$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-19T00:30:00Z">Friday, May 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
