<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-03-11T09:30:23Z">Saturday, March 11 2023, 09:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, March 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://dstheory.wordpress.com/2023/03/10/thursday-mar-16th-2023-vladimir-braverman-from-rice-university/'>Thursday, Mar 16th, 2023 — Vladimir Braverman from Rice University</a></h3>
        <p class='tr-article-feed'>from <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next Foundations of Data Science virtual talk series on recent advances in adversarially robust streaming will take place on Thursday, March 16th at 1:00 PM Pacific Time (16:00 Eastern Time, 22:00 Central European Time, 21:00 UTC). Vladimir Braverman from Rice University will talk about “Adversarial Robustness of Streaming Algorithms through Importance Sampling”. Details ofContinue reading "Thursday, Mar 16th, 2023 — Vladimir Braverman from Rice&#160;University"
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="has-text-align-justify">The next <a rel="noreferrer noopener" href="https://sites.google.com/view/dstheory/home" target="_blank">Foundations of Data Science</a> virtual talk series on recent advances in <em>adversarially robust streaming</em> will take place on <strong>Thursday, March 16th</strong> at<strong> 1:00 PM Pacific Time</strong> (16:00 Eastern Time, 22:00 Central European Time, 21:00 UTC). <a href="https://profiles.rice.edu/faculty/vladimir-braverman">Vladimir Braverman</a> from<strong> Rice University</strong> will talk about <em>“Adversarial Robustness of Streaming Algorithms through Importance Sampling”</em>.</p>



<p><a href="https://sites.google.com/view/dstheory">Details of the talk (Zoom link) are available here.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>: Robustness against adversarial attacks has recently been at the forefront of algorithmic design for machine learning tasks. In the adversarial streaming model, an adversary gives an algorithm a sequence of adaptively chosen updates u1, &#8230; ,un as a data stream. The goal of the algorithm is to compute or approximate some predetermined function for every prefix of the adversarial stream, but the adversary may generate future updates based on previous outputs of the algorithm. In particular, the adversary may gradually learn the random bits internally used by an algorithm to manipulate dependencies in the input. This is especially problematic as many important problems in the streaming model require randomized algorithms, as they are known to not admit any deterministic algorithms that use sublinear space. In this paper, we introduce adversarially robust streaming algorithms for central machine learning and algorithmic tasks, such as regression and clustering, as well as their more general counterparts, subspace embedding, low-rank approximation, and coreset construction. For regression and other numerical linear algebra related tasks, we consider the row arrival streaming model. Our results are based on a simple, but powerful, observation that many importance sampling-based algorithms give rise to adversarial robustness which is in contrast to sketching based algorithms, which are very prevalent in the streaming literature but suffer from adversarial attacks. In addition, we show that the well-known merge and reduce paradigm in streaming is adversarially robust. Since the merge and reduce paradigm allows coreset constructions in the streaming setting, we thus obtain robust algorithms for k-means, k-median, k-center, Bregman clustering, projective clustering, principal component analysis (PCA) and non-negative matrix factorization. To the best of our knowledge, these are the first adversarially robust results for these problems yet require no new algorithmic implementations. Finally, we empirically confirm the robustness of our algorithms on various adversarial attacks and demonstrate that by contrast, some common existing algorithms are not robust.</p>



<p>This is a joint work with Avinatan Hassidim, Yossi Matias, Mariano Schain, Sandeep Silwal, Samson Zhou. This result has appeared in NeurIPS 2021.</p>



<p>&nbsp;The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p>
<p class="authors">By dstheory</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T22:17:33Z">Friday, March 10 2023, 22:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/'>Subspace Designs, Unit and Distinct Distances, and Piercing Standard Boxes.</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A lot of things are happening and let me briefly report on three major advancements in combinatorics. Peter Keevash, Ashwin Sah and Mehtaab Sawhney proved the existence of subspace designs with any given parameters, provided that the dimension of the &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A lot of things are happening and let me briefly report on three major advancements in combinatorics.</p>
<ol>
<li>Peter Keevash, Ashwin Sah and Mehtaab Sawhney proved the existence of subspace designs with any given parameters, provided that the dimension of the underlying space is sufficiently large in terms of the other parameters of the design and satisfies the obvious necessary divisibility conditions.  Here is the link to the paper: <a href="https://arxiv.org/abs/2212.00870">The existence of subspace designs</a>.</li>
<li>Noga Alon, Matija Bucić, and Lisa Sauermann made an important advance on the study of unit distances and distinct distances in arbitrary normed space. Here is a link to the paper: <a href="https://arxiv.org/abs/2302.09058">Unit and distinct distances in typical norms.</a> The unit distance and distinct distances problems for Euclidean geometry are old and famous and there was also a lot of attention for the question of what happens for these problems if one considers normed spaces other than the Euclidean plane. Alon, Bucić, and Sauermann give an essentially tight answer to both questions for almost all norms on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /> , in a certain Baire categoric sense.</li>
<li>István Tomon&#8217;s paper: <a href="https://arxiv.org/abs/2209.09887">Lower bounds for piercing and coloring boxes</a>. Here is Tomon&#8217;s abstract from his recent Copenhagen-Jerusalem seminar: Configurations of axis-parallel boxes in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /> are extensively studied in combinatorial and computational geometry. Despite their innocent appearance, there are many old problems involving their structure that are still not well understood. I will talk about a construction, which addresses several of these problems, and shows that configurations of boxes may be more complex than people conjectured.</li>
</ol>
<h3>Subspace designs and q-analogs</h3>
<p>We talked about subspace designs in <a href="https://gilkalai.wordpress.com/2016/11/23/amazing-stefan-glock-daniela-kuhn-allan-lo-deryk-osthus-give-a-new-proof-for-keevashs-theorem-and-more-news-on-designs/">this post</a>  and in particular about the 2016 paper of Michael  Braun, Tuvi Etzion , Patric R. J. Östergard , Alexander Vardy,  and Alferd Wasserman. While preparing this post I learned the sad news that Alexander Vardy, a prominent coding theorist,  passed away a year ago at the early age of 58.</p>
<p>The theme of finding <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" />-analogs to combinatorial results and problems is important both in enumerative and algebraic combinatorics and in extremal combinatorics and it will be interesting to discuss it in some future post and while preparing for that I recalled the famous <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" />&#8211;<a href="https://en.wikipedia.org/wiki/Dyson_conjecture">Dyson conjecture</a> that was settled by Zeilberger and Bressoud in 1995. I learned that by now there are simpler proofs:  &#8220;A shorter proof, using formal Laurent series, was given in 2004 by Ira Gessel and Guoce Xin, and an even shorter proof, using a quantitative form, due to Karasev and Petrov, and independently to Lason, of Noga Alon&#8217;s Combinatorial Nullstellensatz, was given in 2012 by Gyula Karolyi and Zoltan Lorant Nagy. The latter method was extended, in 2013, by <a href="http://www.math.rutgers.edu/~zeilberg/mamarim/mamarimhtml/qdyson.html">Shalosh B. Ekhad and Doron Zeilberger</a> to derive explicit expressions of any specific coefficient.&#8221; (Wikipedia.)</p>
<h3>Unit and distinct distances</h3>
<p>Here is the abstract of the paper by Alon, Bucić, and Sauermann:</p>
<blockquote><p><em>Erdős&#8217; unit distance problem and Erdős&#8217; distinct distances problem are among the most classical and well-known open problems in all of discrete mathematics. They ask for the maximum number of unit distances, or the minimum number of distinct distances, respectively, determined by $latex <span id="MathJax-Element-1-Frame" class="MathJax"><span id="MathJax-Span-1" class="math"><span id="MathJax-Span-2" class="mrow"><span id="MathJax-Span-3" class="mi">n$</span></span></span></span> points in the Euclidean plane. The question of what happens in these problems if one considers normed spaces other than the Euclidean plane has been raised in the 1980s by Ulam and Erdős and attracted a lot of attention over the years. We give an essentially tight answer to both questions for almost all norms on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" />, in a certain Baire categoric sense.</em></p>
<p><em>For the unit distance problem we prove that for almost all norms ||.|| on <span id="MathJax-Element-3-Frame" class="MathJax"><span id="MathJax-Span-11" class="math"><span id="MathJax-Span-12" class="mrow"><span id="MathJax-Span-13" class="msubsup"><span id="MathJax-Span-14" class="texatom"><span id="MathJax-Span-15" class="mrow"><span id="MathJax-Span-16" class="mi"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /></span></span></span></span></span></span></span>, any set of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> points defines at most <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+d+%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+d+%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+d+%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;frac{1}{2} d &#92;cdot n &#92;log_2 n" class="latex" /> unit distances according to ||.||. We also show that this is essentially tight, by proving that for every norm ||.|| on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" />, for any large <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, we can find $latex <span id="MathJax-Element-8-Frame" class="MathJax"><span id="MathJax-Span-44" class="math"><span id="MathJax-Span-45" class="mrow"><span id="MathJax-Span-46" class="mi">n$</span></span></span></span> points defining at least <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D%28d-1-o%281%29%29%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D%28d-1-o%281%29%29%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D%28d-1-o%281%29%29%5Ccdot+n+%5Clog_2+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;frac{1}{2}(d-1-o(1))&#92;cdot n &#92;log_2 n" class="latex" /> unit distances according to ||.||.</em></p>
<p><em>For the distinct distances problem, we prove that for almost all norms ||.|| on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /> any set of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> <span id="MathJax-Element-11-Frame" class="MathJax"><span id="MathJax-Span-76" class="math"><span id="MathJax-Span-77" class="mrow"><span id="MathJax-Span-78" class="mi"></span></span></span></span> points defines at least $latex <span id="MathJax-Element-12-Frame" class="MathJax"><span id="MathJax-Span-79" class="math"><span id="MathJax-Span-80" class="mrow"><span id="MathJax-Span-81" class="mo">(</span><span id="MathJax-Span-82" class="mn">1</span><span id="MathJax-Span-83" class="mo">−</span><span id="MathJax-Span-84" class="mi">o</span><span id="MathJax-Span-85" class="mo">(</span><span id="MathJax-Span-86" class="mn">1</span><span id="MathJax-Span-87" class="mo">)</span><span id="MathJax-Span-88" class="mo">)</span><span id="MathJax-Span-89" class="mi">n$</span></span></span></span> distinct distances according to ||.||. This is clearly tight up to the $latex <span id="MathJax-Element-13-Frame" class="MathJax"><span id="MathJax-Span-90" class="math"><span id="MathJax-Span-91" class="mrow"><span id="MathJax-Span-92" class="mi">o</span><span id="MathJax-Span-93" class="mo">(</span><span id="MathJax-Span-94" class="mn">1</span><span id="MathJax-Span-95" class="mo">)$</span></span></span></span> term.</em></p>
<p><em>Our results settle, in a strong and somewhat surprising form, problems and conjectures of Brass, of Matoušek, and of Brass-Moser-Pach. The proofs combine combinatorial and geometric ideas with tools from Linear Algebra, Topology and Algebraic Geometry.</em></p></blockquote>
<p>We discussed the unit distances and distinct distances in many posts over here, and they are also related to problems around Borsuk&#8217;s problem (see also my survey paper <a href="https://arxiv.org/abs/1505.04952">Some old and new problems in combinatorial geometry I: Around <span class="search-hit mathjax">Borsuk&#8217;s</span> problem</a>).</p>
<h3>Standard boxes</h3>
<p>Here is the abstract of Tomon&#8217;s paper.<br />
<img data-attachment-id="23978" data-permalink="https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/tomon/" data-orig-file="https://gilkalai.files.wordpress.com/2023/03/tomon.png" data-orig-size="663,481" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Tomon" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=640" class="alignnone size-full wp-image-23978" src="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=640" alt="Tomon" srcset="https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=640 640w, https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=150 150w, https://gilkalai.files.wordpress.com/2023/03/tomon.png?w=300 300w, https://gilkalai.files.wordpress.com/2023/03/tomon.png 663w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p>We discussed the intersection pattern of (standard) boxes on several occasions such as <a href="https://gilkalai.wordpress.com/2014/07/03/my-mathematical-dialogue-with-jurgen-eckhoff/">this post</a> about Jurgen Eckhoff.</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T11:28:42Z">Friday, March 10 2023, 11:28</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04859'>Agnostic PAC Learning of k-juntas Using L2-Polynomial Regression</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Heidari, Wojciech Szpankowski</p><p>Many conventional learning algorithms rely on loss functions other than the
natural 0-1 loss for computational efficiency and theoretical tractability.
Among them are approaches based on absolute loss (L1 regression) and square
loss (L2 regression). The first is proved to be an \textit{agnostic} PAC
learner for various important concept classes such as \textit{juntas}, and
\textit{half-spaces}. On the other hand, the second is preferable because of
its computational efficiency, which is linear in the sample size. However, PAC
learnability is still unknown as guarantees have been proved only under
distributional restrictions. The question of whether L2 regression is an
agnostic PAC learner for 0-1 loss has been open since 1993 and yet has to be
answered.
</p>
<p>This paper resolves this problem for the junta class on the Boolean cube --
proving agnostic PAC learning of k-juntas using L2 polynomial regression.
Moreover, we present a new PAC learning algorithm based on the Boolean Fourier
expansion with lower computational complexity. Fourier-based algorithms, such
as Linial et al. (1993), have been used under distributional restrictions, such
as uniform distribution. We show that with an appropriate change, one can apply
those algorithms in agnostic settings without any distributional assumption. We
prove our results by connecting the PAC learning with 0-1 loss to the minimum
mean square estimation (MMSE) problem. We derive an elegant upper bound on the
0-1 loss in terms of the MMSE error and show that the sign of the MMSE is a PAC
learner for any concept class containing it.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Heidari_M/0/1/0/all/0/1">Mohsen Heidari</a>, <a href="http://arxiv.org/find/cs/1/au:+Szpankowski_W/0/1/0/all/0/1">Wojciech Szpankowski</a></p><p>Many conventional learning algorithms rely on loss functions other than the
natural 0-1 loss for computational efficiency and theoretical tractability.
Among them are approaches based on absolute loss (L1 regression) and square
loss (L2 regression). The first is proved to be an \textit{agnostic} PAC
learner for various important concept classes such as \textit{juntas}, and
\textit{half-spaces}. On the other hand, the second is preferable because of
its computational efficiency, which is linear in the sample size. However, PAC
learnability is still unknown as guarantees have been proved only under
distributional restrictions. The question of whether L2 regression is an
agnostic PAC learner for 0-1 loss has been open since 1993 and yet has to be
answered.
</p>
<p>This paper resolves this problem for the junta class on the Boolean cube --
proving agnostic PAC learning of k-juntas using L2 polynomial regression.
Moreover, we present a new PAC learning algorithm based on the Boolean Fourier
expansion with lower computational complexity. Fourier-based algorithms, such
as Linial et al. (1993), have been used under distributional restrictions, such
as uniform distribution. We show that with an appropriate change, one can apply
those algorithms in agnostic settings without any distributional assumption. We
prove our results by connecting the PAC learning with 0-1 loss to the minimum
mean square estimation (MMSE) problem. We derive an elegant upper bound on the
0-1 loss in terms of the MMSE error and show that the sign of the MMSE is a PAC
learner for any concept class containing it.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05136'>A New Heuristic for Rectilinear Crossing Minimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fran&#xe7;ois Dor&#xe9;, Enrico Formenti</p><p>A new heuristic for rectilinear crossing minimization is proposed. It is
based on the idea of iteratively repositioning nodes after a first initial
graph drawing. The new position of a node is computed by casting rays from the
node towards graph edges. Each ray receives a mark and the one with the best
mark determines the new position. The heuristic has interesting performances
when compared to the best competitors which can be found in classical graph
drawing libraries like OGDF.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dore_F/0/1/0/all/0/1">Fran&#xe7;ois Dor&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Formenti_E/0/1/0/all/0/1">Enrico Formenti</a></p><p>A new heuristic for rectilinear crossing minimization is proposed. It is
based on the idea of iteratively repositioning nodes after a first initial
graph drawing. The new position of a node is computed by casting rays from the
node towards graph edges. Each ray receives a mark and the one with the best
mark determines the new position. The heuristic has interesting performances
when compared to the best competitors which can be found in classical graph
drawing libraries like OGDF.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05044'>Range Avoidance for Constant-Depth Circuits: Hardness and Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Karthik Gajulapalli, Alexander Golovnev, Satyajeet Nagargoje, Sidhant Saraogi</p><p>Range Avoidance (AVOID) is a total search problem where, given a Boolean
circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a
$y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$,
$NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends
on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami,
Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of
high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs,
and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing
conditional hardness of the $NC^0_4$-AVOID problem. On the other hand,
$NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about
the complexity of $NC^0_3$-AVOID open. We give the first reduction of an
explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a
polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case
of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and,
thus, a super-linear lower bound on the size of log-depth circuits. We also
give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems
for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required
larger stretch, $m \geq n^{k-1}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gajulapalli_K/0/1/0/all/0/1">Karthik Gajulapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Golovnev_A/0/1/0/all/0/1">Alexander Golovnev</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagargoje_S/0/1/0/all/0/1">Satyajeet Nagargoje</a>, <a href="http://arxiv.org/find/cs/1/au:+Saraogi_S/0/1/0/all/0/1">Sidhant Saraogi</a></p><p>Range Avoidance (AVOID) is a total search problem where, given a Boolean
circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a
$y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$,
$NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends
on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami,
Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of
high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs,
and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing
conditional hardness of the $NC^0_4$-AVOID problem. On the other hand,
$NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about
the complexity of $NC^0_3$-AVOID open. We give the first reduction of an
explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a
polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case
of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and,
thus, a super-linear lower bound on the size of log-depth circuits. We also
give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems
for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required
larger stretch, $m \geq n^{k-1}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04845'>Smoothed Analysis of Sequential Probability Assignment</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alankrita Bhatt, Nika Haghtalab, Abhishek Shetty</p><p>We initiate the study of smoothed analysis for the sequential probability
assignment problem with contexts. We study information-theoretically optimal
minmax rates as well as a framework for algorithmic reduction involving the
maximum likelihood estimator oracle. Our approach establishes a general-purpose
reduction from minimax rates for sequential probability assignment for smoothed
adversaries to minimax rates for transductive learning. This leads to optimal
(logarithmic) fast rates for parametric classes and classes with finite VC
dimension. On the algorithmic front, we develop an algorithm that efficiently
taps into the MLE oracle, for general classes of functions. We show that under
general conditions this algorithmic approach yields sublinear regret.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhatt_A/0/1/0/all/0/1">Alankrita Bhatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghtalab_N/0/1/0/all/0/1">Nika Haghtalab</a>, <a href="http://arxiv.org/find/cs/1/au:+Shetty_A/0/1/0/all/0/1">Abhishek Shetty</a></p><p>We initiate the study of smoothed analysis for the sequential probability
assignment problem with contexts. We study information-theoretically optimal
minmax rates as well as a framework for algorithmic reduction involving the
maximum likelihood estimator oracle. Our approach establishes a general-purpose
reduction from minimax rates for sequential probability assignment for smoothed
adversaries to minimax rates for transductive learning. This leads to optimal
(logarithmic) fast rates for parametric classes and classes with finite VC
dimension. On the algorithmic front, we develop an algorithm that efficiently
taps into the MLE oracle, for general classes of functions. We show that under
general conditions this algorithmic approach yields sublinear regret.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04934'>Parallel Strong Connectivity Based on Faster Reachability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Letong Wang, Xiaojun Dong, Yan Gu, Yihan Sun</p><p>Computing strongly connected components (SCC) is a fundamental problems in
graph processing. As today's real-world graphs are getting larger and larger,
parallel SCC is increasingly important. SCC is challenging in the parallel
setting and is particularly hard on large-diameter graphs. Many existing
parallel SCC implementations can be even slower than Tarjan's sequential
algorithm on large-diameter graphs.
</p>
<p>To tackle this challenge, we propose an efficient parallel SCC implementation
using a new parallel reachability algorithm. Our solution is based on a novel
idea referred to as vertical granularity control (VGC). It breaks the
synchronization barriers to increase parallelism and hide scheduling overhead.
To use VGC in our SCC algorithm, we also design an efficient data structure
called the \emph{parallel hash bag}. It uses parallel dynamic resizing to avoid
redundant work in maintaining frontiers (vertices processed in a round).
</p>
<p>We implement the parallel SCC algorithm by Blelloch et al.\ (J.\ ACM, 2020)
using our new parallel reachability algorithm. We compare our implementation to
the state-of-the-art systems, including GBBS, iSpan, Multi-step, and our highly
optimized Tarjan's (sequential) algorithm, on 18 graphs, including social, web,
$k$-NN, and lattice graphs. On a machine with 96 cores, our implementation is
the fastest on 16 out of 18 graphs. On average (geometric means) over all
graphs, our SCC is 6.0$\times$ faster than the best previous parallel code
(GBBS), 12.8$\times$ faster than Tarjan's sequential algorithms, and
2.7$\times$ faster than the \emph{best existing implementation on each graph}.
</p>
<p>We believe that our techniques are of independent interest. We also apply our
parallel hash bag and VGC scheme to other graph problems, including
connectivity and least-element lists (LE-lists).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Letong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaojun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yihan Sun</a></p><p>Computing strongly connected components (SCC) is a fundamental problems in
graph processing. As today's real-world graphs are getting larger and larger,
parallel SCC is increasingly important. SCC is challenging in the parallel
setting and is particularly hard on large-diameter graphs. Many existing
parallel SCC implementations can be even slower than Tarjan's sequential
algorithm on large-diameter graphs.
</p>
<p>To tackle this challenge, we propose an efficient parallel SCC implementation
using a new parallel reachability algorithm. Our solution is based on a novel
idea referred to as vertical granularity control (VGC). It breaks the
synchronization barriers to increase parallelism and hide scheduling overhead.
To use VGC in our SCC algorithm, we also design an efficient data structure
called the \emph{parallel hash bag}. It uses parallel dynamic resizing to avoid
redundant work in maintaining frontiers (vertices processed in a round).
</p>
<p>We implement the parallel SCC algorithm by Blelloch et al.\ (J.\ ACM, 2020)
using our new parallel reachability algorithm. We compare our implementation to
the state-of-the-art systems, including GBBS, iSpan, Multi-step, and our highly
optimized Tarjan's (sequential) algorithm, on 18 graphs, including social, web,
$k$-NN, and lattice graphs. On a machine with 96 cores, our implementation is
the fastest on 16 out of 18 graphs. On average (geometric means) over all
graphs, our SCC is 6.0$\times$ faster than the best previous parallel code
(GBBS), 12.8$\times$ faster than Tarjan's sequential algorithms, and
2.7$\times$ faster than the \emph{best existing implementation on each graph}.
</p>
<p>We believe that our techniques are of independent interest. We also apply our
parallel hash bag and VGC scheme to other graph problems, including
connectivity and least-element lists (LE-lists).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04945'>A Survey of Quantum Alternatives to Randomized Algorithms: Monte Carlo Integration and Beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Philip Intallura, Georgios Korpas, Sudeepto Chakraborty, Vyacheslav Kungurtsev, Jakub Marecek</p><p>Monte Carlo sampling is a powerful toolbox of algorithmic techniques widely
used for a number of applications wherein some noisy quantity, or summary
statistic thereof, is sought to be estimated. In this paper, we survey the
literature for implementing Monte Carlo procedures using quantum circuits,
focusing on the potential to obtain a quantum advantage in the computational
speed of these procedures. We revisit the quantum algorithms that could replace
classical Monte Carlo and then consider both the existing quantum algorithms
and the potential quantum realizations that include adaptive enhancements as
alternatives to the classical procedure.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Intallura_P/0/1/0/all/0/1">Philip Intallura</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Korpas_G/0/1/0/all/0/1">Georgios Korpas</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chakraborty_S/0/1/0/all/0/1">Sudeepto Chakraborty</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kungurtsev_V/0/1/0/all/0/1">Vyacheslav Kungurtsev</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Marecek_J/0/1/0/all/0/1">Jakub Marecek</a></p><p>Monte Carlo sampling is a powerful toolbox of algorithmic techniques widely
used for a number of applications wherein some noisy quantity, or summary
statistic thereof, is sought to be estimated. In this paper, we survey the
literature for implementing Monte Carlo procedures using quantum circuits,
focusing on the potential to obtain a quantum advantage in the computational
speed of these procedures. We revisit the quantum algorithms that could replace
classical Monte Carlo and then consider both the existing quantum algorithms
and the potential quantum realizations that include adaptive enhancements as
alternatives to the classical procedure.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05012'>Spatio-Temporal Trajectory Similarity Measures: A Comprehensive Survey and Quantitative Study</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Danlei Hu, Lu Chen, Hanxi Fang, Ziquan Fang, Tianyi Li, Yunjun Gao</p><p>Spatio-temporal trajectory analytics is at the core of smart mobility
solutions, which offers unprecedented information for diversified applications
such as urban planning, infrastructure development, and vehicular networks.
Trajectory similarity measure, which aims to evaluate the distance between two
trajectories, is a fundamental functionality of trajectory analytics. In this
paper, we propose a comprehensive survey that investigates all the most common
and representative spatio-temporal trajectory measures. First, we provide an
overview of spatio-temporal trajectory measures in terms of three hierarchical
perspectives: Non-learning vs. Learning, Free Space vs. Road Network, and
Standalone vs. Distributed. Next, we present an evaluation benchmark by
designing five real-world transformation scenarios. Based on this benchmark,
extensive experiments are conducted to study the effectiveness,
robustness,nefficiency, and scalability of each measure, which offers
guidelines for trajectory measure selection among multiple techniques and
applications such as trajectory data mining, deep learning, and distributed
processing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Danlei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1">Hanxi Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Ziquan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yunjun Gao</a></p><p>Spatio-temporal trajectory analytics is at the core of smart mobility
solutions, which offers unprecedented information for diversified applications
such as urban planning, infrastructure development, and vehicular networks.
Trajectory similarity measure, which aims to evaluate the distance between two
trajectories, is a fundamental functionality of trajectory analytics. In this
paper, we propose a comprehensive survey that investigates all the most common
and representative spatio-temporal trajectory measures. First, we provide an
overview of spatio-temporal trajectory measures in terms of three hierarchical
perspectives: Non-learning vs. Learning, Free Space vs. Road Network, and
Standalone vs. Distributed. Next, we present an evaluation benchmark by
designing five real-world transformation scenarios. Based on this benchmark,
extensive experiments are conducted to study the effectiveness,
robustness,nefficiency, and scalability of each measure, which offers
guidelines for trajectory measure selection among multiple techniques and
applications such as trajectory data mining, deep learning, and distributed
processing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05067'>Robust optimization with belief functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marc Goerigk, Romain Guillaume, Adam Kasperski, Pawe&#x142; Zieli&#x144;ski</p><p>In this paper, an optimization problem with uncertain objective function
coefficients is considered. The uncertainty is specified by providing a
discrete scenario set, containing possible realizations of the objective
function coefficients. The concept of belief function in the traditional and
possibilistic setting is applied to define a set of admissible probability
distributions over the scenario set. The generalized Hurwicz criterion is then
used to compute a solution. In this paper, the complexity of the resulting
problem is explored. Some exact and approximation methods of solving it are
proposed.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goerigk_M/0/1/0/all/0/1">Marc Goerigk</a>, <a href="http://arxiv.org/find/cs/1/au:+Guillaume_R/0/1/0/all/0/1">Romain Guillaume</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasperski_A/0/1/0/all/0/1">Adam Kasperski</a>, <a href="http://arxiv.org/find/cs/1/au:+Zielinski_P/0/1/0/all/0/1">Pawe&#x142; Zieli&#x144;ski</a></p><p>In this paper, an optimization problem with uncertain objective function
coefficients is considered. The uncertainty is specified by providing a
discrete scenario set, containing possible realizations of the objective
function coefficients. The concept of belief function in the traditional and
possibilistic setting is applied to define a set of admissible probability
distributions over the scenario set. The generalized Hurwicz criterion is then
used to compute a solution. In this paper, the complexity of the resulting
problem is explored. Some exact and approximation methods of solving it are
proposed.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05250'>Distributed Half-Integral Matching and Beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sameep Dahal, Jukka Suomela</p><p>By prior work, it is known that any distributed graph algorithm that finds a
maximal matching requires $\Omega(\log^* n)$ communication rounds, while it is
possible to find a maximal fractional matching in $O(1)$ rounds in
bounded-degree graphs. However, all prior $O(1)$-round algorithms for maximal
fractional matching use arbitrarily fine-grained fractional values. In
particular, none of them is able to find a half-integral solution, using only
values from $\{0, \frac12, 1\}$. We show that the use of fine-grained
fractional values is necessary, and moreover we give a complete
characterization on exactly how small values are needed: if we consider maximal
fractional matching in graphs of maximum degree $\Delta = 2d$, and any
distributed graph algorithm with round complexity $T(\Delta)$ that only depends
on $\Delta$ and is independent of $n$, we show that the algorithm has to use
fractional values with a denominator at least $2^d$. We give a new algorithm
that shows that this is also sufficient.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dahal_S/0/1/0/all/0/1">Sameep Dahal</a>, <a href="http://arxiv.org/find/cs/1/au:+Suomela_J/0/1/0/all/0/1">Jukka Suomela</a></p><p>By prior work, it is known that any distributed graph algorithm that finds a
maximal matching requires $\Omega(\log^* n)$ communication rounds, while it is
possible to find a maximal fractional matching in $O(1)$ rounds in
bounded-degree graphs. However, all prior $O(1)$-round algorithms for maximal
fractional matching use arbitrarily fine-grained fractional values. In
particular, none of them is able to find a half-integral solution, using only
values from $\{0, \frac12, 1\}$. We show that the use of fine-grained
fractional values is necessary, and moreover we give a complete
characterization on exactly how small values are needed: if we consider maximal
fractional matching in graphs of maximum degree $\Delta = 2d$, and any
distributed graph algorithm with round complexity $T(\Delta)$ that only depends
on $\Delta$ and is independent of $n$, we show that the algorithm has to use
fractional values with a denominator at least $2^d$. We give a new algorithm
that shows that this is also sufficient.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05327'>Direct Access for Answers to Conjunctive Queries with Aggregation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Idan Eldar, Nofar Carmeli, Benny Kimelfeld</p><p>We study the fine-grained complexity of conjunctive queries with grouping and
aggregation. For some common aggregate functions (e.g., min, max, count, sum),
such a query can be phrased as an ordinary conjunctive query over a database
annotated with a suitable commutative semiring. Specifically, we investigate
the ability to evaluate such queries by constructing in log-linear time a data
structure that provides logarithmic-time direct access to the answers ordered
by a given lexicographic order. This task is nontrivial since the number of
answers might be larger than log-linear in the size of the input, and so, the
data structure needs to provide a compact representation of the space of
answers.
</p>
<p>In the absence of aggregation and annotation, past research provides a
sufficient tractability condition on queries and orders. For queries without
self-joins, this condition is not just sufficient, but also necessary (under
conventional lower-bound assumptions in fine-grained complexity). We show that
all past results continue to hold for annotated databases, assuming that the
annotation itself is not part of the lexicographic order. On the other hand, we
show infeasibility for the case of count-distinct that does not have any
efficient representation as a commutative semiring. We then investigate the
ability to include the aggregate and annotation outcome in the lexicographic
order. Among the hardness results, standing out as tractable is the case of a
semiring with an idempotent addition, such as those of min and max. Notably,
this case captures also count-distinct over a logarithmic-size domain.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Eldar_I/0/1/0/all/0/1">Idan Eldar</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmeli_N/0/1/0/all/0/1">Nofar Carmeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Kimelfeld_B/0/1/0/all/0/1">Benny Kimelfeld</a></p><p>We study the fine-grained complexity of conjunctive queries with grouping and
aggregation. For some common aggregate functions (e.g., min, max, count, sum),
such a query can be phrased as an ordinary conjunctive query over a database
annotated with a suitable commutative semiring. Specifically, we investigate
the ability to evaluate such queries by constructing in log-linear time a data
structure that provides logarithmic-time direct access to the answers ordered
by a given lexicographic order. This task is nontrivial since the number of
answers might be larger than log-linear in the size of the input, and so, the
data structure needs to provide a compact representation of the space of
answers.
</p>
<p>In the absence of aggregation and annotation, past research provides a
sufficient tractability condition on queries and orders. For queries without
self-joins, this condition is not just sufficient, but also necessary (under
conventional lower-bound assumptions in fine-grained complexity). We show that
all past results continue to hold for annotated databases, assuming that the
annotation itself is not part of the lexicographic order. On the other hand, we
show infeasibility for the case of count-distinct that does not have any
efficient representation as a commutative semiring. We then investigate the
ability to include the aggregate and annotation outcome in the lexicographic
order. Among the hardness results, standing out as tractable is the case of a
semiring with an idempotent addition, such as those of min and max. Notably,
this case captures also count-distinct over a logarithmic-size domain.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05336'>Elastic Founder Graphs Improved and Enhanced</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nicola Rizzo, Massimo Equi, Tuukka Norri, Veli M&#xe4;kinen</p><p>Indexing labeled graphs for pattern matching is a central challenge of
pangenomics. Equi et al. (Algorithmica, 2022) developed the Elastic Founder
Graph ($\mathsf{EFG}$) representing an alignment of $m$ sequences of length
$n$, drawn from alphabet $\Sigma$ plus the special gap character: the paths
spell the original sequences or their recombination. By enforcing the
semi-repeat-free property, the $\mathsf{EFG}$ admits a polynomial-space index
for linear-time pattern matching, breaking through the conditional lower bounds
on indexing labeled graphs (Equi et al., SOFSEM 2021). In this work we improve
the space of the $\mathsf{EFG}$ index answering pattern matching queries in
linear time, from linear in the length of all strings spelled by three
consecutive node labels, to linear in the size of the edge labels. Then, we
develop linear-time construction algorithms optimizing for different metrics:
we improve the existing linearithmic construction algorithms to $O(mn)$, by
solving the novel exclusive ancestor set problem on trees; we propose, for the
simplified gapless setting, an $O(mn)$-time solution minimizing the maximum
block height, that we generalize by substituting block height with prefix-aware
height. Finally, to show the versatility of the framework, we develop a
BWT-based $\mathsf{EFG}$ index and study how to encode and perform document
listing queries on a set of paths of the graphs, reporting which paths present
a given pattern as a substring. We propose the $\mathsf{EFG}$ framework as an
improved and enhanced version of the framework for the gapless setting, along
with construction methods that are valid in any setting concerned with the
segmentation of aligned sequences.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rizzo_N/0/1/0/all/0/1">Nicola Rizzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Equi_M/0/1/0/all/0/1">Massimo Equi</a>, <a href="http://arxiv.org/find/cs/1/au:+Norri_T/0/1/0/all/0/1">Tuukka Norri</a>, <a href="http://arxiv.org/find/cs/1/au:+Makinen_V/0/1/0/all/0/1">Veli M&#xe4;kinen</a></p><p>Indexing labeled graphs for pattern matching is a central challenge of
pangenomics. Equi et al. (Algorithmica, 2022) developed the Elastic Founder
Graph ($\mathsf{EFG}$) representing an alignment of $m$ sequences of length
$n$, drawn from alphabet $\Sigma$ plus the special gap character: the paths
spell the original sequences or their recombination. By enforcing the
semi-repeat-free property, the $\mathsf{EFG}$ admits a polynomial-space index
for linear-time pattern matching, breaking through the conditional lower bounds
on indexing labeled graphs (Equi et al., SOFSEM 2021). In this work we improve
the space of the $\mathsf{EFG}$ index answering pattern matching queries in
linear time, from linear in the length of all strings spelled by three
consecutive node labels, to linear in the size of the edge labels. Then, we
develop linear-time construction algorithms optimizing for different metrics:
we improve the existing linearithmic construction algorithms to $O(mn)$, by
solving the novel exclusive ancestor set problem on trees; we propose, for the
simplified gapless setting, an $O(mn)$-time solution minimizing the maximum
block height, that we generalize by substituting block height with prefix-aware
height. Finally, to show the versatility of the framework, we develop a
BWT-based $\mathsf{EFG}$ index and study how to encode and perform document
listing queries on a set of paths of the graphs, reporting which paths present
a given pattern as a substring. We propose the $\mathsf{EFG}$ framework as an
improved and enhanced version of the framework for the gapless setting, along
with construction methods that are valid in any setting concerned with the
segmentation of aligned sequences.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.05408'>Fast algorithms for Vizing's theorem on bounded degree graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anton Bernshteyn, Abhishek Dhawan</p><p>Vizing's theorem states that every graph $G$ of maximum degree $\Delta$ can
be properly edge-colored using $\Delta + 1$ colors. The fastest currently known
$(\Delta+1)$-edge-coloring algorithm for general graphs is due to Sinnamon and
runs in time $O(m\sqrt{n})$, where $n = |V(G)|$ and $m =|E(G)|$. Using the
bound $m \leq \Delta n/2$, the running time of Sinnamon's algorithm can be
expressed as $O(\Delta n^{3/2})$. In the regime when $\Delta$ is considerably
smaller than $n$ (for instance, when $\Delta$ is a constant), this can be
improved, as Gabow, Nishizeki, Kariv, Leven, and Terada designed an algorithm
with running time $O(\Delta m \log n) = O(\Delta^2 n \log n)$. Here we give an
algorithm whose running time is only linear in $n$ (which is obviously best
possible) and polynomial in $\Delta$. We also develop new algorithms for
$(\Delta+1)$-edge-coloring in the $\mathsf{LOCAL}$ model of distributed
computation. Namely, we design a deterministic $\mathsf{LOCAL}$ algorithm with
running time $\mathsf{poly}(\Delta, \log\log n) \log^5 n$ and a randomized
$\mathsf{LOCAL}$ algorithm with running time $\mathsf{poly}(\Delta) \log^2 n$.
The key new ingredient in our algorithms is a novel application of the entropy
compression method.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bernshteyn_A/0/1/0/all/0/1">Anton Bernshteyn</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhawan_A/0/1/0/all/0/1">Abhishek Dhawan</a></p><p>Vizing's theorem states that every graph $G$ of maximum degree $\Delta$ can
be properly edge-colored using $\Delta + 1$ colors. The fastest currently known
$(\Delta+1)$-edge-coloring algorithm for general graphs is due to Sinnamon and
runs in time $O(m\sqrt{n})$, where $n = |V(G)|$ and $m =|E(G)|$. Using the
bound $m \leq \Delta n/2$, the running time of Sinnamon's algorithm can be
expressed as $O(\Delta n^{3/2})$. In the regime when $\Delta$ is considerably
smaller than $n$ (for instance, when $\Delta$ is a constant), this can be
improved, as Gabow, Nishizeki, Kariv, Leven, and Terada designed an algorithm
with running time $O(\Delta m \log n) = O(\Delta^2 n \log n)$. Here we give an
algorithm whose running time is only linear in $n$ (which is obviously best
possible) and polynomial in $\Delta$. We also develop new algorithms for
$(\Delta+1)$-edge-coloring in the $\mathsf{LOCAL}$ model of distributed
computation. Namely, we design a deterministic $\mathsf{LOCAL}$ algorithm with
running time $\mathsf{poly}(\Delta, \log\log n) \log^5 n$ and a randomized
$\mathsf{LOCAL}$ algorithm with running time $\mathsf{poly}(\Delta) \log^2 n$.
The key new ingredient in our algorithms is a novel application of the entropy
compression method.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-10T01:30:00Z">Friday, March 10 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, March 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://processalgebra.blogspot.com/2023/03/ten-fully-funded-phd-positions-in.html'>Ten fully-funded PhD positions in Computer Science at the Gran Sasso Science Institute</a></h3>
        <p class='tr-article-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>The Computer Science group at the GSSI has ten fully-funded PhD positions. See the call for applications for details. The deadline for applications is 30 May 2023. <br></p><p>The Computer Science group at the GSSI provides an excellent environment for PhD students and its group has been ranked as "excellent" by a recent national research assessment exercise. In my, admittedly biased, opinion, it is one of the places to be for research in Computer Science in Italy. </p><p>Spread the news! <br></p><p>&nbsp;<br></p><p>By Luca Aceto</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Computer Science group at the GSSI has ten fully-funded PhD positions. See the <a href="https://www.gssi.it/albo-ufficiale-online-gssi/item/download/4164_c550280ade939db61570a29ef700f63e" target="_blank">call for applications</a> for details. The deadline for applications is 30 May 2023. <br /></p><p>The <a href="https://sites.google.com/gssi.it/csgssi" target="_blank">Computer Science group at the GSSI</a> provides an excellent environment for PhD students and its group has been ranked as <a href="https://processalgebra.blogspot.com/2022/12/computer-science-and-mathematics-at.html" target="_blank">"excellent"</a> by a recent national research assessment exercise. In my, admittedly biased, opinion, it is one of the places to be for research in Computer Science in Italy. </p><p>Spread the news! <br /></p><p>&nbsp;<br /></p><p class="authors">By Luca Aceto</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T13:49:00Z">Thursday, March 09 2023, 13:49</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7094'>The False Promise of Chomskyism</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Important Update (March 10): On deeper reflection, I probably don&#8217;t need to spend emotional energy refuting people like Chomsky, who believe that Large Language Models are just a laughable fad rather than a step-change in how humans can and will use technology, any more than I would&#8217;ve needed to spend it refuting those who said [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Important Update (March 10):</mark></strong> On deeper reflection, I probably don&#8217;t <em>need</em> to spend emotional energy refuting people like Chomsky, who believe that Large Language Models are just a laughable fad rather than a step-change in how humans can and will use technology, any more than I would&#8217;ve needed to spend it refuting those who said the same about the World Wide Web in 1993.  Yes, they&#8217;re wrong, and yes, despite being wrong they&#8217;re self-certain, hostile, and smug, and yes I can see this, and yes it angers me.  But the world is going to make the argument for me.  And if not the world, <a href="https://twitter.com/SebastienBubeck/status/1634009568341622784/photo/1">Bing already does a perfectly serviceable job</a> at refuting Chomsky&#8217;s points (h/t Sebastien Bubeck via Boaz Barak).</p>



<p>Meanwhile, out there in reality, <a href="https://southpark.cc.com/episodes/8byci4/south-park-deep-learning-season-26-ep-4?fbclid=IwAR0hxxqhxF3jsMu7EZvGqJYmFruseZTNL_7W_8i_Y7dfhDYhmMoc9KOYWco">last night&#8217;s <em>South Park</em> episode</a> does a <em>much</em> better job than most academic thinkpieces at exploring how ordinary people are going to respond (and have already responded) to the availability of ChatGPT.  It will <em>not</em>, to put it mildly, be with sneering Chomskyan disdain, whether the effects on the world are for good or ill or (most likely) both.  Among other things&#8212;I don&#8217;t want to give away too much!&#8212;this episode prominently features a soothsayer accompanied by a bird that caws whenever it detects GPT-generated text.  Now why didn&#8217;t I think of that in preference to cryptographic watermarking??</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>I was asked to respond to the <em>New York Times</em> opinion piece entitled <a href="https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html">The False Promise of ChatGPT</a>, by Noam Chomsky along with Ian Roberts and Jeffrey Watumull (who once took my class at MIT).  I&#8217;ll be busy all day at the Harvard CS department, where I&#8217;m <a href="https://events.seas.harvard.edu/event/how_much_information_is_in_a_quantum_state">giving a quantum talk</a> this afternoon. <strong>[Added: Several commenters complained that they found this sentence &#8220;condescending,&#8221; but I&#8217;m not sure what exactly they wanted me to say&#8212;that I was visiting some school in Cambridge, MA, two T stops from the school where Chomsky works and I used to work?]</strong></p>



<p>But for now:</p>



<p>In this piece Chomsky, the intellectual godfather god of an effort that failed for 60 years to build machines that can converse in ordinary language, condemns the effort that succeeded.  <strong>[Added: Please, <em>please</em> stop writing that I must be an ignoramus since I don&#8217;t even know that Chomsky has never worked on AI.  I know perfectly well that he hasn&#8217;t, and meant only that he&#8217;s regarded as the highest authority <em>by</em> the anti-statistical, &#8220;don&#8217;t-look-through-the-telescope&#8221; AI faction, the ones views he himself fully endorses in his attack-piece.  If you don&#8217;t know the relevant history, <a href="https://norvig.com/chomsky.html">read Norvig</a>.]</strong></p>



<p>Chomsky condemns ChatGPT for four reasons:</p>



<ol>
<li>because it could, in principle, misinterpret sentences that could also be sentence fragments, like &#8220;John is too stubborn to talk to&#8221; (bizarrely, he never checks whether it <em>does</em> misinterpret it&#8212;I just tried it this morning and it seems to decide correctly based on context whether it&#8217;s a sentence or a sentence fragment, much like I would!);</li>



<li>because it doesn’t learn the way humans do (personally, I think ChatGPT and other large language models have <em>massively</em> illuminated at least one component of the human language faculty, what you could call its <a href="https://en.wikipedia.org/wiki/Predictive_coding">predictive coding</a> component, though clearly not all of it);</li>



<li>because it could learn false facts or grammatical systems if fed false training data (how could it be otherwise?); and</li>



<li>most of all because it’s “amoral,” refusing to take a stand on potentially controversial issues (he gives an example involving the ethics of terraforming Mars).</li>
</ol>



<p>This last, of course, is a <em>choice</em>, imposed by OpenAI using reinforcement learning.  The reason for it is simply that ChatGPT is a consumer product.  The same people who condemn it for not taking controversial stands would condemn it much more loudly if it did — just like the same people who condemn it for wrong answers and explanations, would condemn it equally for right ones (Chomsky promises as much in the essay).</p>



<p>I submit that, like the Jesuit astronomers declining to look through Galileo’s telescope, what Chomsky and his followers are ultimately angry at is reality itself, for having the temerity to offer something up that they didn’t predict and that doesn’t fit their worldview.</p>



<p>[<em>Note for people who might be visiting this blog for the first time:</em> I&#8217;m a CS professor at UT Austin, on leave for one year to work at OpenAI on the theoretical foundations of AI safety.  I accepted OpenAI&#8217;s offer in part because I already held the views here, or something close to them; and given that I could see how large language models were poised to change the world for good and ill, I wanted to be part of the effort to help prevent their misuse.  No one at OpenAI asked me to write this or saw it beforehand, and I don&#8217;t even know to what extent they agree with it.]</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T12:01:55Z">Thursday, March 09 2023, 12:01</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/021'>TR23-021 |  Range Avoidance for Constant-Depth Circuits: Hardness and Algorithms | 

	Sidhant Saraogi, 

	Alexander Golovnev, 

	Satyajeet Nagargoje, 

	Karthik Gajulapalli</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Range Avoidance (AVOID) is a total search problem where, given a Boolean circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a $y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$, $NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami, Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs, and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing conditional hardness of the $NC^0_4$-AVOID problem. On the other hand, $NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about the complexity of $NC^0_3$-AVOID open.

We give the first reduction of an explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and, thus, a super-linear lower bound on the size of log-depth circuits.

We also give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required larger stretch, $m \geq n^{k-1}$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Range Avoidance (AVOID) is a total search problem where, given a Boolean circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a $y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$, $NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami, Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs, and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing conditional hardness of the $NC^0_4$-AVOID problem. On the other hand, $NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about the complexity of $NC^0_3$-AVOID open.

We give the first reduction of an explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and, thus, a super-linear lower bound on the size of log-depth circuits.

We also give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required larger stretch, $m \geq n^{k-1}$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T09:26:46Z">Thursday, March 09 2023, 09:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04298'>Classical vs Quantum Advice under Classically-Accessible Oracle</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xingjian Li, Qipeng Liu, Angelos Pelecanos, Takashi Yamakawa</p><p>It is a long-standing open question to construct a classical oracle relative
to which BQP/qpoly $\neq$ BQP/poly or QMA $\neq$ QCMA. In this paper, we
construct classically-accessible classical oracles relative to which BQP/qpoly
$\neq$ BQP/poly. Here, classically-accessible classical oracles are oracles
that can be accessed only classically even for quantum algorithms. Based on a
similar technique, we also show an alternative proof for separation of QMA and
QCMA relative to a distributional quantumly-accessible classical oracles, which
was recently shown by Natarajan and Nirkhe.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Li_X/0/1/0/all/0/1">Xingjian Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Liu_Q/0/1/0/all/0/1">Qipeng Liu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pelecanos_A/0/1/0/all/0/1">Angelos Pelecanos</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yamakawa_T/0/1/0/all/0/1">Takashi Yamakawa</a></p><p>It is a long-standing open question to construct a classical oracle relative
to which BQP/qpoly $\neq$ BQP/poly or QMA $\neq$ QCMA. In this paper, we
construct classically-accessible classical oracles relative to which BQP/qpoly
$\neq$ BQP/poly. Here, classically-accessible classical oracles are oracles
that can be accessed only classically even for quantum algorithms. Based on a
similar technique, we also show an alternative proof for separation of QMA and
QCMA relative to a distributional quantumly-accessible classical oracles, which
was recently shown by Natarajan and Nirkhe.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04613'>The Descriptive Complexity of Graph Neural Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Martin Grohe</p><p>We analyse the power of graph neural networks (GNNs) in terms of Boolean
circuit complexity and descriptive complexity.
</p>
<p>We prove that the graph queries that can be computed by a polynomial-size
bounded-depth family of GNNs are exactly those definable in the guarded
fragment GFO+C of first-order logic with counting and with built-in relations.
This puts GNNs in the circuit complexity class TC^0. Remarkably, the GNN
families may use arbitrary real weights and a wide class of activation
functions that includes the standard ReLU, logistic "sigmoid", and hyperbolic
tangent functions. If the GNNs are allowed to use random initialisation and
global readout (both standard features of GNNs widely used in practice), they
can compute exactly the same queries as bounded depth Boolean circuits with
threshold gates, that is, exactly the queries in TC^0. Moreover, we show that
queries computable by a single GNN with piecewise linear activations and
rational weights are definable in GFO+C without built-in relations. Therefore,
they are contained in uniform TC^0.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1">Martin Grohe</a></p><p>We analyse the power of graph neural networks (GNNs) in terms of Boolean
circuit complexity and descriptive complexity.
</p>
<p>We prove that the graph queries that can be computed by a polynomial-size
bounded-depth family of GNNs are exactly those definable in the guarded
fragment GFO+C of first-order logic with counting and with built-in relations.
This puts GNNs in the circuit complexity class TC^0. Remarkably, the GNN
families may use arbitrary real weights and a wide class of activation
functions that includes the standard ReLU, logistic "sigmoid", and hyperbolic
tangent functions. If the GNNs are allowed to use random initialisation and
global readout (both standard features of GNNs widely used in practice), they
can compute exactly the same queries as bounded depth Boolean circuits with
threshold gates, that is, exactly the queries in TC^0. Moreover, we show that
queries computable by a single GNN with piecewise linear activations and
rational weights are definable in GFO+C without built-in relations. Therefore,
they are contained in uniform TC^0.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04350'>Improved Bounds for Covering Paths and Trees in the Plane</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ahmad Biniaz</p><p>A covering path for a planar point set is a path drawn in the plane with
straight-line edges such that every point lies at a vertex or on an edge of the
path. A covering tree is defined analogously. Let $\pi(n)$ be the minimum
number such that every set of $n$ points in the plane can be covered by a
noncrossing path with at most $\pi(n)$ edges. Let $\tau(n)$ be the analogous
number for noncrossing covering trees. Dumitrescu, Gerbner, Keszegh, and T\'oth
(Discrete &amp; Computational Geometry, 2014) established the following
inequalities: \[\frac{5n}{9} - O(1) &lt; \pi(n) &lt;
\left(1-\frac{1}{601080391}\right)n, \quad\text{and} \quad\frac{9n}{17} - O(1)
&lt; \tau(n)\leqslant \left\lfloor\frac{5n}{6}\right\rfloor.\] We report the
following improved upper bounds: \[\pi(n)\leqslant
\left(1-\frac{1}{22}\right)n, \quad\text{and}\quad \tau(n)\leqslant
\left\lceil\frac{4n}{5}\right\rceil.\]
</p>
<p>In the same context we study rainbow polygons. For a set of colored points in
the plane, a perfect rainbow polygon is a simple polygon that contains exactly
one point of each color in its interior or on its boundary. Let $\rho(k)$ be
the minimum number such that every $k$-colored point set in the plane admits a
perfect rainbow polygon of size $\rho(k)$. Flores-Pe\~naloza, Kano,
Mart\'inez-Sandoval, Orden, Tejel, T\'oth, Urrutia, and Vogtenhuber (Discrete
Mathematics, 2021) proved that $20k/19 - O(1) &lt;\rho(k) &lt; 10k/7 + O(1).$ We
report the improved upper bound $\rho(k)&lt; 7k/5 + O(1)$.
</p>
<p>To obtain the improved bounds we present simple $O(n\log n)$-time algorithms
that achieve paths, trees, and polygons with our desired number of edges.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Biniaz_A/0/1/0/all/0/1">Ahmad Biniaz</a></p><p>A covering path for a planar point set is a path drawn in the plane with
straight-line edges such that every point lies at a vertex or on an edge of the
path. A covering tree is defined analogously. Let $\pi(n)$ be the minimum
number such that every set of $n$ points in the plane can be covered by a
noncrossing path with at most $\pi(n)$ edges. Let $\tau(n)$ be the analogous
number for noncrossing covering trees. Dumitrescu, Gerbner, Keszegh, and T\'oth
(Discrete &amp; Computational Geometry, 2014) established the following
inequalities: \[\frac{5n}{9} - O(1) &lt; \pi(n) &lt;
\left(1-\frac{1}{601080391}\right)n, \quad\text{and} \quad\frac{9n}{17} - O(1)
&lt; \tau(n)\leqslant \left\lfloor\frac{5n}{6}\right\rfloor.\] We report the
following improved upper bounds: \[\pi(n)\leqslant
\left(1-\frac{1}{22}\right)n, \quad\text{and}\quad \tau(n)\leqslant
\left\lceil\frac{4n}{5}\right\rceil.\]
</p>
<p>In the same context we study rainbow polygons. For a set of colored points in
the plane, a perfect rainbow polygon is a simple polygon that contains exactly
one point of each color in its interior or on its boundary. Let $\rho(k)$ be
the minimum number such that every $k$-colored point set in the plane admits a
perfect rainbow polygon of size $\rho(k)$. Flores-Pe\~naloza, Kano,
Mart\'inez-Sandoval, Orden, Tejel, T\'oth, Urrutia, and Vogtenhuber (Discrete
Mathematics, 2021) proved that $20k/19 - O(1) &lt;\rho(k) &lt; 10k/7 + O(1).$ We
report the improved upper bound $\rho(k)&lt; 7k/5 + O(1)$.
</p>
<p>To obtain the improved bounds we present simple $O(n\log n)$-time algorithms
that achieve paths, trees, and polygons with our desired number of edges.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04722'>B-Treaps Revised: Write Efficient Randomized Block Search Trees with High Load</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Roodabeh Safavi, Martin P. Seybold</p><p>Uniquely represented data structures represent each logical state with a
unique storage state. We study the problem of maintaining a dynamic set of $n$
keys from a totally ordered universe in this context.
</p>
<p>We introduce a two-layer data structure called
$(\alpha,\varepsilon)$-Randomized Block Search Tree (RBST) that is uniquely
represented and suitable for external memory. Though RBSTs naturally generalize
the well-known binary Treaps, several new ideas are needed to analyze the {\em
expected} search, update, and storage, efficiency in terms of block-reads,
block-writes, and blocks stored. We prove that searches have
$O(\varepsilon^{-1} + \log_\alpha n)$ block-reads, that $(\alpha,
\varepsilon)$-RBSTs have an asymptotic load-factor of at least
$(1-\varepsilon)$ for every $\varepsilon \in (0,1/2]$, and that dynamic updates
perform $O(\varepsilon^{-1} + \log_\alpha(n)/\alpha)$ block-writes, i.e.
$O(1/\varepsilon)$ writes if $\alpha=\Omega(\frac{\log n}{\log \log n} )$. Thus
$(\alpha, \varepsilon)$-RBSTs provide improved search, storage-, and
write-efficiency bounds in regard to the known, uniquely represented B-Treap
[Golovin; ICALP'09].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Safavi_R/0/1/0/all/0/1">Roodabeh Safavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Seybold_M/0/1/0/all/0/1">Martin P. Seybold</a></p><p>Uniquely represented data structures represent each logical state with a
unique storage state. We study the problem of maintaining a dynamic set of $n$
keys from a totally ordered universe in this context.
</p>
<p>We introduce a two-layer data structure called
$(\alpha,\varepsilon)$-Randomized Block Search Tree (RBST) that is uniquely
represented and suitable for external memory. Though RBSTs naturally generalize
the well-known binary Treaps, several new ideas are needed to analyze the {\em
expected} search, update, and storage, efficiency in terms of block-reads,
block-writes, and blocks stored. We prove that searches have
$O(\varepsilon^{-1} + \log_\alpha n)$ block-reads, that $(\alpha,
\varepsilon)$-RBSTs have an asymptotic load-factor of at least
$(1-\varepsilon)$ for every $\varepsilon \in (0,1/2]$, and that dynamic updates
perform $O(\varepsilon^{-1} + \log_\alpha(n)/\alpha)$ block-writes, i.e.
$O(1/\varepsilon)$ writes if $\alpha=\Omega(\frac{\log n}{\log \log n} )$. Thus
$(\alpha, \varepsilon)$-RBSTs provide improved search, storage-, and
write-efficiency bounds in regard to the known, uniquely represented B-Treap
[Golovin; ICALP'09].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04199'>Diversity Embeddings and the Hypergraph Sparsest Cut</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam D. Jozefiak, F. Bruce Shepherd</p><p>Good approximations have been attained for the sparsest cut problem by
rounding solutions to convex relaxations via low-distortion metric embeddings.
Recently, Bryant and Tupper showed that this approach extends to the hypergraph
setting by formulating a linear program whose solutions are so-called
diversities which are rounded via diversity embeddings into $\ell_1$.
Diversities are a generalization of metric spaces in which the nonnegative
function is defined on all subsets as opposed to only on pairs of elements.
</p>
<p>We show that this approach yields a polytime $O(\log{n})$-approximation when
either the supply or demands are given by a graph. This result improves upon
Plotkin et al.'s $O(\log{(kn)}\log{n})$-approximation, where $k$ is the number
of demands, for the setting where the supply is given by a graph and the
demands are given by a hypergraph. Additionally, we provide a polytime
$O(\min{\{r_G,r_H\}}\log{r_H}\log{n})$-approximation for when the supply and
demands are given by hypergraphs whose hyperedges are bounded in cardinality by
$r_G$ and $r_H$ respectively.
</p>
<p>To establish these results we provide an $O(\log{n})$-distortion $\ell_1$
embedding for the class of diversities known as diameter diversities. This
improves upon Bryant and Tupper's $O(\log\^2{n})$-distortion embedding. The
smallest known distortion with which an arbitrary diversity can be embedded
into $\ell_1$ is $O(n)$. We show that for any $\epsilon &gt; 0$ and any $p&gt;0$,
there is a family of diversities which cannot be embedded into $\ell_1$ in
polynomial time with distortion smaller than $O(n^{1-\epsilon})$ based on
querying the diversities on sets of cardinality at most $O(\log^p{n})$, unless
$P=NP$. This disproves (an algorithmic refinement of) Bryant and Tupper's
conjecture that there exists an $O(\sqrt{n})$-distortion $\ell_1$ embedding
based off a diversity's induced metric.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jozefiak_A/0/1/0/all/0/1">Adam D. Jozefiak</a>, <a href="http://arxiv.org/find/cs/1/au:+Shepherd_F/0/1/0/all/0/1">F. Bruce Shepherd</a></p><p>Good approximations have been attained for the sparsest cut problem by
rounding solutions to convex relaxations via low-distortion metric embeddings.
Recently, Bryant and Tupper showed that this approach extends to the hypergraph
setting by formulating a linear program whose solutions are so-called
diversities which are rounded via diversity embeddings into $\ell_1$.
Diversities are a generalization of metric spaces in which the nonnegative
function is defined on all subsets as opposed to only on pairs of elements.
</p>
<p>We show that this approach yields a polytime $O(\log{n})$-approximation when
either the supply or demands are given by a graph. This result improves upon
Plotkin et al.'s $O(\log{(kn)}\log{n})$-approximation, where $k$ is the number
of demands, for the setting where the supply is given by a graph and the
demands are given by a hypergraph. Additionally, we provide a polytime
$O(\min{\{r_G,r_H\}}\log{r_H}\log{n})$-approximation for when the supply and
demands are given by hypergraphs whose hyperedges are bounded in cardinality by
$r_G$ and $r_H$ respectively.
</p>
<p>To establish these results we provide an $O(\log{n})$-distortion $\ell_1$
embedding for the class of diversities known as diameter diversities. This
improves upon Bryant and Tupper's $O(\log\^2{n})$-distortion embedding. The
smallest known distortion with which an arbitrary diversity can be embedded
into $\ell_1$ is $O(n)$. We show that for any $\epsilon &gt; 0$ and any $p&gt;0$,
there is a family of diversities which cannot be embedded into $\ell_1$ in
polynomial time with distortion smaller than $O(n^{1-\epsilon})$ based on
querying the diversities on sets of cardinality at most $O(\log^p{n})$, unless
$P=NP$. This disproves (an algorithmic refinement of) Bryant and Tupper's
conjecture that there exists an $O(\sqrt{n})$-distortion $\ell_1$ embedding
based off a diversity's induced metric.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04205'>Investigating the complexity of the double distance problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marilia D. V. Braga, Leonie R. Brockmann, Katharina Klerx, Jens Stoye</p><p>Two genomes over the same set of gene families form a canonical pair when
each of them has exactly one gene from each family. Different distances of
canonical genomes can be derived from a structure called breakpoint graph,
which represents the relation between the two given genomes as a collection of
cycles of even length and paths. Then, the breakpoint distance is equal to n -
(c_2 + p_0/2), where n is the number of genes, c_2 is the number of cycles of
length 2 and p_0 is the number of paths of length 0. Similarly, when the
considered rearrangements are those modeled by the double-cut-and-join (DCJ)
operation, the rearrangement distance is n - (c + p_e/2), where c is the total
number of cycles and p_e is the total number of even paths.
</p>
<p>The distance formulation is a basic unit for several other combinatorial
problems related to genome evolution and ancestral reconstruction, such as
median or double distance. Interestingly, both median and double distance
problems can be solved in polynomial time for the breakpoint distance, while
they are NP-hard for the rearrangement distance. One way of exploring the
complexity space between these two extremes is to consider the {\sigma}_k
distance, defined to be n - [c_2 + c_4 + ... + c_k + (p_0 + p_2 + ... +p_k)/2],
and increasingly investigate the complexities of median and double distance for
the {\sigma}_4 distance, then the {\sigma}_6 distance, and so on. While for the
median much effort was done in our and in other research groups but no progress
was obtained even for the {\sigma}_4 distance, for solving the double distance
under {\sigma}_4 and {\sigma}_6 distances we could devise linear time
algorithms, which we present here.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Braga_M/0/1/0/all/0/1">Marilia D. V. Braga</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockmann_L/0/1/0/all/0/1">Leonie R. Brockmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Klerx_K/0/1/0/all/0/1">Katharina Klerx</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoye_J/0/1/0/all/0/1">Jens Stoye</a></p><p>Two genomes over the same set of gene families form a canonical pair when
each of them has exactly one gene from each family. Different distances of
canonical genomes can be derived from a structure called breakpoint graph,
which represents the relation between the two given genomes as a collection of
cycles of even length and paths. Then, the breakpoint distance is equal to n -
(c_2 + p_0/2), where n is the number of genes, c_2 is the number of cycles of
length 2 and p_0 is the number of paths of length 0. Similarly, when the
considered rearrangements are those modeled by the double-cut-and-join (DCJ)
operation, the rearrangement distance is n - (c + p_e/2), where c is the total
number of cycles and p_e is the total number of even paths.
</p>
<p>The distance formulation is a basic unit for several other combinatorial
problems related to genome evolution and ancestral reconstruction, such as
median or double distance. Interestingly, both median and double distance
problems can be solved in polynomial time for the breakpoint distance, while
they are NP-hard for the rearrangement distance. One way of exploring the
complexity space between these two extremes is to consider the {\sigma}_k
distance, defined to be n - [c_2 + c_4 + ... + c_k + (p_0 + p_2 + ... +p_k)/2],
and increasingly investigate the complexities of median and double distance for
the {\sigma}_4 distance, then the {\sigma}_6 distance, and so on. While for the
median much effort was done in our and in other research groups but no progress
was obtained even for the {\sigma}_4 distance, for solving the double distance
under {\sigma}_4 and {\sigma}_6 distances we could devise linear time
algorithms, which we present here.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04288'>Polynomial Time and Private Learning of Unbounded Gaussian Mixture Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jamil Arbas, Hassan Ashtiani, Christopher Liaw</p><p>We study the problem of privately estimating the parameters of
$d$-dimensional Gaussian Mixture Models (GMMs) with $k$ components. For this,
we develop a technique to reduce the problem to its non-private counterpart.
This allows us to privatize existing non-private algorithms in a blackbox
manner, while incurring only a small overhead in the sample complexity and
running time. As the main application of our framework, we develop an
$(\varepsilon, \delta)$-differentially private algorithm to learn GMMs using
the non-private algorithm of Moitra and Valiant [MV10] as a blackbox.
Consequently, this gives the first sample complexity upper bound and first
polynomial time algorithm for privately learning GMMs without any boundedness
assumptions on the parameters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Arbas_J/0/1/0/all/0/1">Jamil Arbas</a>, <a href="http://arxiv.org/find/stat/1/au:+Ashtiani_H/0/1/0/all/0/1">Hassan Ashtiani</a>, <a href="http://arxiv.org/find/stat/1/au:+Liaw_C/0/1/0/all/0/1">Christopher Liaw</a></p><p>We study the problem of privately estimating the parameters of
$d$-dimensional Gaussian Mixture Models (GMMs) with $k$ components. For this,
we develop a technique to reduce the problem to its non-private counterpart.
This allows us to privatize existing non-private algorithms in a blackbox
manner, while incurring only a small overhead in the sample complexity and
running time. As the main application of our framework, we develop an
$(\varepsilon, \delta)$-differentially private algorithm to learn GMMs using
the non-private algorithm of Moitra and Valiant [MV10] as a blackbox.
Consequently, this gives the first sample complexity upper bound and first
polynomial time algorithm for privately learning GMMs without any boundedness
assumptions on the parameters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04301'>Optimal Sparse Recovery with Decision Stumps</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kiarash Banihashem, MohammadTaghi Hajiaghayi, Max Springer</p><p>Decision trees are widely used for their low computational cost, good
predictive performance, and ability to assess the importance of features.
Though often used in practice for feature selection, the theoretical guarantees
of these methods are not well understood. We here obtain a tight finite sample
bound for the feature selection problem in linear regression using single-depth
decision trees. We examine the statistical properties of these "decision
stumps" for the recovery of the $s$ active features from $p$ total features,
where $s \ll p$. Our analysis provides tight sample performance guarantees on
high-dimensional sparse systems which align with the finite sample bound of
$O(s \log p)$ as obtained by Lasso, improving upon previous bounds for both the
median and optimal splitting criteria. Our results extend to the non-linear
regime as well as arbitrary sub-Gaussian distributions, demonstrating that tree
based methods attain strong feature selection properties under a wide variety
of settings and further shedding light on the success of these methods in
practice. As a byproduct of our analysis, we show that we can provably
guarantee recovery even when the number of active features $s$ is unknown. We
further validate our theoretical results and proof methodology using
computational experiments.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Banihashem_K/0/1/0/all/0/1">Kiarash Banihashem</a>, <a href="http://arxiv.org/find/stat/1/au:+Hajiaghayi_M/0/1/0/all/0/1">MohammadTaghi Hajiaghayi</a>, <a href="http://arxiv.org/find/stat/1/au:+Springer_M/0/1/0/all/0/1">Max Springer</a></p><p>Decision trees are widely used for their low computational cost, good
predictive performance, and ability to assess the importance of features.
Though often used in practice for feature selection, the theoretical guarantees
of these methods are not well understood. We here obtain a tight finite sample
bound for the feature selection problem in linear regression using single-depth
decision trees. We examine the statistical properties of these "decision
stumps" for the recovery of the $s$ active features from $p$ total features,
where $s \ll p$. Our analysis provides tight sample performance guarantees on
high-dimensional sparse systems which align with the finite sample bound of
$O(s \log p)$ as obtained by Lasso, improving upon previous bounds for both the
median and optimal splitting criteria. Our results extend to the non-linear
regime as well as arbitrary sub-Gaussian distributions, demonstrating that tree
based methods attain strong feature selection properties under a wide variety
of settings and further shedding light on the success of these methods in
practice. As a byproduct of our analysis, we show that we can provably
guarantee recovery even when the number of active features $s$ is unknown. We
further validate our theoretical results and proof methodology using
computational experiments.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04478'>Change a Bit to save Bytes: Compression for Floating Point Time-Series Data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Francesco Taurone, Daniel E. Lucani, Marcell Feh&#xe9;r, Qi Zhang</p><p>The number of IoT devices is expected to continue its dramatic growth in the
coming years and, with it, a growth in the amount of data to be transmitted,
processed and stored. Compression techniques that support analytics directly on
the compressed data could pave the way for systems to scale efficiently to
these growing demands. This paper proposes two novel methods for preprocessing
a stream of floating point data to improve the compression capabilities of
various IoT data compressors. In particular, these techniques are shown to be
helpful with recent compressors that allow for random access and analytics
while maintaining good compression. Our techniques improve compression with
reductions up to 80% when allowing for at most 1% of recovery error.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Taurone_F/0/1/0/all/0/1">Francesco Taurone</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucani_D/0/1/0/all/0/1">Daniel E. Lucani</a>, <a href="http://arxiv.org/find/cs/1/au:+Feher_M/0/1/0/all/0/1">Marcell Feh&#xe9;r</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a></p><p>The number of IoT devices is expected to continue its dramatic growth in the
coming years and, with it, a growth in the amount of data to be transmitted,
processed and stored. Compression techniques that support analytics directly on
the compressed data could pave the way for systems to scale efficiently to
these growing demands. This paper proposes two novel methods for preprocessing
a stream of floating point data to improve the compression capabilities of
various IoT data compressors. In particular, these techniques are shown to be
helpful with recent compressors that allow for random access and analytics
while maintaining good compression. Our techniques improve compression with
reductions up to 80% when allowing for at most 1% of recovery error.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04555'>Streaming Kernel PCA Algorithm With Small Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yichuan Deng, Zhao Song, Zifan Wang, Han Zhang</p><p>Principal Component Analysis (PCA) is a widely used technique in machine
learning, data analysis and signal processing. With the increase in the size
and complexity of datasets, it has become important to develop low-space usage
algorithms for PCA. Streaming PCA has gained significant attention in recent
years, as it can handle large datasets efficiently. The kernel method, which is
commonly used in learning algorithms such as Support Vector Machines (SVMs),
has also been applied in PCA algorithms.
</p>
<p>We propose a streaming algorithm for Kernel PCA problems based on the
traditional scheme by Oja. Our algorithm addresses the challenge of reducing
the memory usage of PCA while maintaining its accuracy. We analyze the
performance of our algorithm by studying the conditions under which it
succeeds. Specifically, we show that, when the spectral ratio $R :=
\lambda_1/\lambda_2$ of the target covariance matrix is lower bounded by $C
\cdot \log n\cdot \log d$, the streaming PCA can be solved with $O(d)$ space
cost.
</p>
<p>Our proposed algorithm has several advantages over existing methods. First,
it is a streaming algorithm that can handle large datasets efficiently. Second,
it employs the kernel method, which allows it to capture complex nonlinear
relationships among data points. Third, it has a low-space usage, making it
suitable for applications where memory is limited.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yichuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a></p><p>Principal Component Analysis (PCA) is a widely used technique in machine
learning, data analysis and signal processing. With the increase in the size
and complexity of datasets, it has become important to develop low-space usage
algorithms for PCA. Streaming PCA has gained significant attention in recent
years, as it can handle large datasets efficiently. The kernel method, which is
commonly used in learning algorithms such as Support Vector Machines (SVMs),
has also been applied in PCA algorithms.
</p>
<p>We propose a streaming algorithm for Kernel PCA problems based on the
traditional scheme by Oja. Our algorithm addresses the challenge of reducing
the memory usage of PCA while maintaining its accuracy. We analyze the
performance of our algorithm by studying the conditions under which it
succeeds. Specifically, we show that, when the spectral ratio $R :=
\lambda_1/\lambda_2$ of the target covariance matrix is lower bounded by $C
\cdot \log n\cdot \log d$, the streaming PCA can be solved with $O(d)$ space
cost.
</p>
<p>Our proposed algorithm has several advantages over existing methods. First,
it is a streaming algorithm that can handle large datasets efficiently. Second,
it employs the kernel method, which allows it to capture complex nonlinear
relationships among data points. Third, it has a low-space usage, making it
suitable for applications where memory is limited.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04771'>Interior-point methods on manifolds: theory and applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Harold Nieuwboer, Michael Walter</p><p>Interior-point methods offer a highly versatile framework for convex
optimization that is effective in theory and practice. A key notion in their
theory is that of a self-concordant barrier. We give a suitable generalization
of self-concordance to Riemannian manifolds and show that it gives the same
structural results and guarantees as in the Euclidean setting, in particular
local quadratic convergence of Newton's method. We then analyze a short-step
path-following method for optimizing compatible objectives over a convex domain
for which one has a self-concordant barrier, and obtain the standard complexity
guarantees as in the Euclidean setting. We show that on the positive-definite
matrices and other symmetric spaces, the squared distance to a point is a
self-concordant function. Our work is motivated by recent progress on scaling
problems and non-commutative optimization, and we show that these fit into our
framework, yielding algorithms with state-of-the-art complexity guarantees.
Furthermore, we show how to apply our methods to computing geometric medians on
spaces with constant negative curvature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Nieuwboer_H/0/1/0/all/0/1">Harold Nieuwboer</a>, <a href="http://arxiv.org/find/math/1/au:+Walter_M/0/1/0/all/0/1">Michael Walter</a></p><p>Interior-point methods offer a highly versatile framework for convex
optimization that is effective in theory and practice. A key notion in their
theory is that of a self-concordant barrier. We give a suitable generalization
of self-concordance to Riemannian manifolds and show that it gives the same
structural results and guarantees as in the Euclidean setting, in particular
local quadratic convergence of Newton's method. We then analyze a short-step
path-following method for optimizing compatible objectives over a convex domain
for which one has a self-concordant barrier, and obtain the standard complexity
guarantees as in the Euclidean setting. We show that on the positive-definite
matrices and other symmetric spaces, the squared distance to a point is a
self-concordant function. Our work is motivated by recent progress on scaling
problems and non-commutative optimization, and we show that these fit into our
framework, yielding algorithms with state-of-the-art complexity guarantees.
Furthermore, we show how to apply our methods to computing geometric medians on
spaces with constant negative curvature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, March 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/03/08/more-mathematics-books.html'>More mathematics books by women</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          For the last several years, I’ve been celebrating International Women’s Day by posting lists of mathematics books written or coauthored by women: 2020, 2021, 2022. Here’s another set. The links go to Wikipedia articles on the books, where you can find more information about them collated from their published reviews. The level and selection is, as usual, random, based mainly on whether the book’s topic caught my interest and it had enough published reviews to justify a Wikipedia article.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>For the last several years, I’ve been celebrating International Women’s Day by posting lists of mathematics books written or coauthored by women: <a href="/blog/2020/03/08/mathematics-books-women.html">2020</a>, <a href="/blog/2021/03/08/more-mathematics-books.html">2021</a>, <a href="/blog/2022/03/08/mathematics-books-by-women.html">2022</a>. Here’s another set. The links go to Wikipedia articles on the books, where you can find more information about them collated from their published reviews. The level and selection is, as usual, random, based mainly on whether the book’s topic caught my interest and it had enough published reviews to justify a Wikipedia article.</p>

<ul>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Geometry_of_an_Art">The Geometry of an Art: The History of the Mathematical Theory of Perspective from Alberti to Monge</a></em> (2007), Kirsti Andersen. The development of the mathematics of perspective and descriptive geometry, and its applications by European artists, from the 15th to 18th centuries.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Extrinsic_Geometric_Flows">Extrinsic Geometric Flows</a></em> (2020), Ben Andrews, Bennett Chow, Christine Guenther, and Mat Langford. A geometric flow is a way of continuously moving a curve, surface, or other shape, with the speed and direction of motion depending on its shape. It is “extrinsic” when the flow depends on a higher-dimensional space in which the moving object is embedded, rather than just on the intrinsic geometry of the object itself. This is a graduate textbook on the subject.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Spatial_Mathematics:_Theory_and_Practice_through_Mapping">Spatial Mathematics: Theory and Practice through Mapping</a></em> (2013), Sandra Arlinghaus and Joseph Kerski. The mathematical background behind geodesy and spatial visualization in geographic information systems.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Problem_Solving_Through_Recreational_Mathematics">Problem Solving Through Recreational Mathematics</a></em> (1980), Bonnie Averbach and Orin Chein. Despite the title this is an undergraduate textbook, for general education courses aimed at non-mathematics students. Its premise is that the use of fun “recreational” problems can help motivate these students to learn mathematical problem-solving techniques.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Geometric_and_Topological_Inference">Geometric and Topological Inference</a></em> (2018), Jean-Daniel Boissonnat, Frédéric Chazal, and Mariette Yvinec. Computational geometry meets machine learning.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Independence_Theory_in_Combinatorics">Independence Theory in Combinatorics: An Introductory Account with Applications to Graphs and Transversals</a></em> (1980), Victor Bryant and Hazel Perfect. An undergraduate text on matroid theory, with a particular focus on graph-theoretic applications of matroids.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Beyond_Infinity_(mathematics_book)">Beyond Infinity: An Expedition to the Outer Limits of Mathematics</a></em> (2017), Eugenia Cheng. A general-audience book looking at the many ways mathematics has approached the infinite.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Symmetries_of_Things">The Symmetries of Things</a></em> (2008), John Horton Conway, Heidi Burgiel, and Chaim Goodman-Strauss. A bit annoying for its frequent use of neologism and revisionist history, but packed with detail about discrete symmetries of geometric objects.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/A_Biography_of_Maria_Gaetana_Agnesi">A Biography of Maria Gaetana Agnesi</a></em> (2008), Antonella Cupillari. This mainly consists of a translation of Antonio Francesco Frisi’s Italian-language biography of Agnesi, augmented with many pages of notes and with translations of some of Agnesi’s mathematical works.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Finding_Ellipses">Finding Ellipses: What Blaschke Products, Poncelet’s Theorem, and the Numerical Range Know about Each Other</a></em> (2019), Ulrich Daepp, Pamela Gorkin, Andrew Shaffer, and Karl Voss. An undergraduate-level exposition of some deep connections between functional analysis (analytic functions with specified zeros), geometry (polygons simultaneously inscribed in and circumscribing conics), and linear algebra (convex sets containing the eigenvalues of a matrix).</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Introduction_to_Lattices_and_Order">Introduction to Lattices and Order</a></em> (1990, 2002), Brian A. Davey and Hilary Priestley. A graduate textbook on order theory, also noteworthy for its tips on how to use LaTeX to make order-theoretic mathematical diagrams.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Geometry_of_the_Octonions">The Geometry of the Octonions</a></em> (2015), Tevian Dray and Corinne Manogue. Beyond the real numbers, complex numbers, and quaternions, the next step is the octonions, a division algebra but not a ring. This book surveys this topic at an advanced undergraduate level.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Cube_Made_Interesting">The Cube Made Interesting</a></em> (1960, 1964), Aniela Ehrenfeucht. Aimed at high school students, and originally written in Polish, on the rotational symmetries of a cube, its colorings, and on the ability to pass a cube through a hole in an equal-sized cube (“Prince Rupert’s cube”), illustrated with red-blue anaglyphic 3d visualizations.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Erd%C5%91s_Distance_Problem">The Erdős Distance Problem</a></em> (2011), Julia Garibaldi, Alex Iosevich, and Steven Senger, an advanced undergraduate monograph on the problem of arranging points to make as few distinct distances as possible, unfortunately made mostly obsolete soon after its publication by the polynomial method of Larry Guth and Nets Katz.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Lumen_Naturae">Lumen Naturae: Visions of the Abstract in Art and Mathematics</a></em> (2020), Matilde Marcolli. On inspirations and analogies connecting modern art, mathematics, and mathematical physics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Black_Mathematicians_and_Their_Works">Black Mathematicians and Their Works</a></em> (1980), Virginia Newell, Joella Gipson, L. Waldo Rich, and Beauregard Stubblefield. Brief biographies of 62 black mathematicians, and reprints of 26 of their papers on mathematics and mathematics education, maybe the only book of its kind.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/From_Zero_to_Infinity">From Zero to Infinity: What Makes Numbers Interesting</a></em> (1955, …, 2006), Constance Reid. A classic of general-audience mathematics exposition, on different kinds of numbers and topics in number theory.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Math_on_Trial">Math on Trial: How Numbers Get Used and Abused in the Courtroom</a></em> (2013), Leila Schneps and Coralie Colmez. A collection of case studies on mathematical fallacies occurring in famous court cases, aimed at a general audience.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Curvature_of_Space_and_Time,_with_an_Introduction_to_Geometric_Analysis">Curvature of Space and Time, with an Introduction to Geometric Analysis</a></em> (2020), Iva Stavrov. An undergraduate textbook on differential geometry and its applications in the theory of relativity.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_History_of_Mathematics:_A_Very_Short_Introduction">The History of Mathematics: A Very Short Introduction</a></em> (2012), Jackie Stedall. This is less an overview of the history of mathematics itself (maybe too big a topic for a short book) and more an overview of the philosophy of the history of mathematics, as demonstrated through several case studies.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Ad_Quadratum:_The_Practical_Application_of_Geometry_in_Medieval_Architecture">Ad Quadratum: The Practical Application of Geometry in Medieval Architecture</a></em> (2002), Nancy Y. Wu. An edited volume of papers on geometry in medieval architecture, mostly of Gothic cathedrals.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Do_Not_Erase:_Mathematicians_and_their_Chalkboards">Do Not Erase: Mathematicians and their Chalkboards</a></em> (2021), Jessica Wynne. A photo-essay pairing photographs of mathematician’s chalkboards with reflections on their contents by the mathematicians. I listed this in last year’s collection of books for which I could not find enough reviews, but in this case I subsequently did find them.</p>
  </li>
</ul>

<p>(<a href="https://mathstodon.xyz/@11011110/109990803163597638">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T17:40:00Z">Wednesday, March 08 2023, 17:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/03/08/three-assistant-associate-professor-positions-in-security-at-the-vu-amsterdam-at-vrije-universiteit-amsterdam-apply-by-april-13-2023/'>Three assistant/associate professor positions in security at the VU Amsterdam at Vrije Universiteit Amsterdam (apply by April 13, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Department of Computer Science at the Vrije Universiteit Amsterdam offers three open positions for assistant/associate professor in the area of security, related to theory, vulnerability, and AI. Website: werkenbij.vu.nl/vacatures Email: w.j.fokkink@vu.nl
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Department of Computer Science at the Vrije Universiteit Amsterdam offers three open positions for assistant/associate professor in the area of security, related to theory, vulnerability, and AI.</p>
<p>Website: <a href="https://werkenbij.vu.nl/vacatures">https://werkenbij.vu.nl/vacatures</a><br />
Email: w.j.fokkink@vu.nl</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T17:29:12Z">Wednesday, March 08 2023, 17:29</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/03/08/interview-about-this-blog-in-the-bulletin-of-the-eatcs/'>Interview about this blog in the Bulletin of the EATCS</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Luca Trevisan recently interviewed me for the Bulletin of the EATCS (see link for the full issue, including an interview with Alexandra Silva, and technical columns by Naama Ben-David, Ryan Williams, and Yuri Gurevich). With Luca&#8217;s permission, I am cross-posting it here. (I added some hyperlinks to relevant documents.) Q. Boaz, thanks for taking the &#8230; Continue reading Interview about this blog in the Bulletin of the&#160;EATCS
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="https://lucatrevisan.github.io/">Luca Trevisan</a> recently interviewed me for the <a href="https://eatcs.org/images/bulletin/beatcs139.pdf">Bulletin of the EATCS</a> (see link for the full issue, including an interview with Alexandra Silva, and technical columns by Naama Ben-David, Ryan Williams, and Yuri Gurevich). With Luca&#8217;s permission, I am cross-posting it here.  (I added some hyperlinks to relevant documents.)</p>



<p><strong>Q. Boaz, thanks for taking the time to talk about your blog to our readers. When did you start to blog, and what motivated you to start?</strong></p>



<p>In 2012, Omer Reingold <a href="https://windowsontheory.org/about/">started a group blog</a> for the amazing theoretical computer scientists of the Microsoft Research Silicon Valley lab, and called it &#8220;Windows on Theory&#8221;. As a fellow MSR researcher, Omer invited me to join the blog a few months later. Joining a group blog seemed to me like an attractive proposition, since I didn&#8217;t think I will have something interesting to say on a very regular basis.</p>



<p>I liked the idea of explaining technical topics on a blog post, the way you might sketch them on a whiteboard to a colleague. Compared to a survey, where you have to cross all your t&#8217;s and dot all your i&#8217;s, and get all references straight, a blog post can be a good way to convey the heart of the matter without doing as much work.<br>Indeed throughout the years, I&#8217;ve been inspired by several blog posts by you, Luca. <a href="https://lucatrevisan.wordpress.com/">Your blog</a> is a great example of how to explain technical topics in an informal manner.</p>



<p><strong>Q. Thank you so much for that! You have very broad interests in theoretical computer science, and you blog about a great variety of topics. Have there been instances where writing posts or discussing in the comment section has clarified ideas or led to a conjecture or otherwise helped with your research?</strong></p>



<p>I do think that my thinking on several questions, including <a href="https://windowsontheory.org/2013/10/07/structure-vs-combinatorics-in-computational-complexity/">structure vs. combinatorics</a><a href="https://windowsontheory.org/2017/10/30/the-different-forms-of-quantum-computing-skepticism/">, quantum skepticism</a>, <a href="https://windowsontheory.org/2022/06/20/the-uneasy-relationship-between-deep-learning-and-classical-statistics/">theory of deep learning</a>, and more, have been shaped by both the process of writing essays and the discussion in comments or outside the blog that ensues. It is a different form of thinking than the typical scientific paper, and often when you sit down to write, it forces you to clarify your thoughts. This is similar to how often the best way to learn a topic is to teach it.</p>



<p><strong>Q. I have followed on your blog, your course on methods from theoretical physics, and your posts on the <a href="https://windowsontheory.org/2022/06/20/the-uneasy-relationship-between-deep-learning-and-classical-statistics/">foundations of machine learning</a> and AI, and I know you have worked on a <a href="https://introtcs.org/">new approach</a> to teach computability and complexity. What kind of TCS do you think we should teach to CS undergraduates who are interested in AI?</strong></p>



<p>It&#8217;s interesting because I think traditionally, the critique of courses in theoretical CS was that we are teaching all this math, while students are going to be software developers, and they just need to know how to write a website. Now it turns out that we didn&#8217;t teach enough math, and to participate in the AI revolution, students need to know their gradients and Hessians. It&#8217;s also the case that Neural networks are really just arithmetic circuits (and backpropagation has been rediscovered several times, including by <a href="https://core.ac.uk/download/pdf/82480031.pdf">Baur and Strassen</a> in 1982, where they used it for circuit lower bounds).</p>



<p>So I think the tools we teach as theoretical computer scientists are as relevant as ever. I did try to modernize my <a href="https://cs121.boazbarak.org/">course</a>, focusing on circuits, which are relevant not just for AI but also for the foundations of both cryptography and quantum computing. I also talk much more about randomness in computation. This means that some other materials, such as automata, need to be reduced or cut, but I think it&#8217;s a good tradeoff.</p>



<p><strong>Q. On a related note, what do you think that a future satisfactory theory of AI might look like?</strong></p>



<p>As theoretical computer scientists, we are used to being way ahead of practice. For example, people are only starting now to implement the ideas of zero-knowledge and probabilistically-checkable proofs that were put forward by theorists in the 80s and 90s. Dwork and Naor suggested the &#8220;proof of work&#8221; protocol used by Bitcoin in 1992. (They were also ahead of the curve in another way: proposing to combat &#8220;junk email&#8221; before most people had access to email and the term &#8220;spam email&#8221; was even coined.)</p>



<p>In deep learning, we are in a different setting: practice is ahead of theory, and people are implementing systems that they themselves don&#8217;t understand. In that sense, these systems behave more like artifacts that are discovered (or evolved) than like ones that are designed. This forces us to use a different form of theory, and one that relies more heavily on experiments to figure out what are even the right questions to ask.</p>



<p>So, we are not in our usual mode where there are easy-to-state but hard-to-prove conjectures, and our goal is to sit down with pen and paper and to prove them. But for me, theoretical computer science was never about the mode of operation but about the mission of understanding computation. So if understanding deep learning means that I needed to re-learn how to code, and rack up large bills for GPU computation, then so be it.</p>



<p><strong>Q. Can you tell us a bit about the plans for changes in California math education and about your involvement in that debate?</strong></p>



<p>Some colleagues in California have alerted me to a <a href="https://windowsontheory.org/2021/12/03/an-alarming-trend-in-k-12-math-education/">proposed change</a> to the way K-12 math is taught there and that this change is part of a national movement. Part of this is the typical tension that always exists between teaching mathematical topics that are foundational (and often a bit more challenging) vs. &#8220;practical math&#8221;.<br>This is something that I mentioned also in the discussion regarding university teaching.</p>



<p>In the context of high school, the new version of &#8220;practical math&#8221; is no longer accounting but <a href="https://www.educationnext.org/rethinking-math-education-educators-differ-curriculum-methods-forum/">&#8220;data science&#8221;</a>. There is also a twist in which it is claimed that somehow data science is more &#8220;equitable&#8221;, which is something I find offensive, as it tacitly assumes that people from certain groups are inherently incapable of accessing mathematical topics such as algebra and calculus. From my experience in teaching, both at university settings and in Ethiopia and Jamaica, nothing could be further from the truth</p>



<p>Now I am all for teaching students a course in some data literacy, including facility with spreadsheets and understanding the various ways that people can &#8220;lie with statistics&#8221;. It&#8217;s just not a replacement for math courses.</p>



<p>The truth is that, like at the university level, students need more math these days than ever before. By far the largest growth in job opportunities has been in quantitative fields.<br>When data science is offered as an <em>alternative</em> to math, as opposed to complementing them, it basically serves as an &#8220;off ramp&#8221; that shuts students out of these fields, including, ironically, from careers in data science itself.</p>



<p><strong>Q. In general, what are your thoughts about the role of public intellectuals that theoretical computer scientists could fill, and what are public debates where you would like to see more voices coming from our community?</strong></p>



<p>In our field, we often have the experience of being humiliated by either discovering that our conjecture was wrong or being unable to prove it. I think this is not a bad experience to have had for public intellectuals, and so I would hope that theoretical computer scientists speak up more in the public sphere.</p>



<p>Areas including immigration, science funding, open access to publications, and mathematical education are clearly central to our mission to advance science, but I think we can talk about more topics as well. For example, I recently signed an open letter protesting the Israeli government&#8217;s efforts to weaken the judicial branch and the basic laws on human rights. Scientific progress relies on the ability to collaborate, so free speech and human rights are topics that we should talk about as well.</p>



<p><strong>I would like to ask you to pick one or a couple of your favorite posts, and tell us about it/them/</strong></p>



<p>My first blog post was an <a href="https://windowsontheory.org/2012/05/01/the-swiss-army-knife-of-cryptography">exposition</a> of Fully Homomorphic Encryption with Zvika Brakerski. I like that post because we didn&#8217;t just repeat what&#8217;s in the papers but used the flexibility of the blog format to focus on optimizing simplicity and intuition as opposed to precision and computational efficiency. I think people have found it useful over the years. Another blog post I am proud of is my post on <a href="https://windowsontheory.org/2017/08/16/men-in-computer-science/">&#8220;Men in Computer Science&#8221;</a>. I mostly made obvious points in that post, but heard from several women that they appreciated it.</p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T14:13:20Z">Wednesday, March 08 2023, 14:13</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2023/03/news-for-february-2023/'>News for February 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Despite being a short month, February 2023 has witnessed a significant amount of activity under the sublinear &#8220;regime&#8221;. Let us know if we have missed anything! Dynamic \((1 + \epsilon)\)-Approximate Matching Size in Truly Sublinear Update Time by Sayan Bhattacharya, Peter Kiss, and Thatchaphol Saranurak (arXiv). This work throws light on connections between the dynamic [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Despite being a short month, February 2023 has witnessed a significant amount of activity under the sublinear &#8220;regime&#8221;. Let us know if we have missed anything!</p>



<p><strong>Dynamic \((1 + \epsilon)\)-Approximate Matching Size in Truly Sublinear Update Time</strong> by Sayan Bhattacharya, Peter Kiss, and Thatchaphol Saranurak (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.05030" target="_blank">arXiv</a>). This work throws light on connections between the dynamic and query models of computation and uses them for making advances on approximating the size of a maximum cardinality matching (MCM) in a general graph. In particular, as the main technical ingredient in obtaining an improved dynamic algorithm for maintaining an approximation to the size of MCM, the authors provide a \(\pm \epsilon n\) approximation algorithm for estimating the size of MCM in a general \(n\)-vertex graph by making \(n^{2 &#8211; \Omega_{\epsilon}(1)}\) adjacency queries. Prior to this result, the state of the art (Behnezhad, Roghani &amp; Rubinstein; STOC&#8217;23) was a \(n^{2 &#8211; \Omega(1)}\)-query algorithm for the same problem with a multiplicative approximation guarantee of \(1.5\) and an additive guarantee of \(o(n)\). </p>



<p><strong>Uniformity Testing over Hypergrids with Subcube Conditioning</strong> by Xi Chen and Cassandra Marcussen (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.09013" target="_blank">arXiv</a>). As the name indicates, the paper studies the fundamental problem of testing uniformity of distributions supported over hypergrids \([m]^n\). The tester that they present make \(O(\text{poly}(m)\sqrt{n}/\epsilon^2)\) queries to a conditional subcube sampling oracle, which, when given a subcube of \([m]^n\), returns a point sampled from the distribution conditioned on the point belonging to the subcube. The result is a generalization of the uniformity tester for distributions supported over the \(n\)-dimensional hypercube (Canonne, Chen, Kamath, Levi and Waingarten; SODA &#8217;21). </p>



<p><strong>Easy Testability for Posets</strong> by Panna Timea Fekete and Gabor Kun (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.11390" target="_blank">arXiv</a>). This paper deals with testing properties of directed graphs in the adjacency matrix model. The main characters of the story are posets, or directed acyclic graphs (DAGs) that are transitively closed. Given a family \(\mathcal{F}\) of finite posets, let \(\mathcal{P}_\mathcal{F}\) denote the set of all finite posets that do not contain any element of \(\mathcal{F}\) as a subposet. The main result of the paper is an \(\epsilon\)-tester with query complexity \(\text{poly}(1/\epsilon)\) for \(\mathcal{P}_\mathcal{F}\). The authors obtain this result by proving a removal lemma for posets. The result is placed in the larger context of understanding what properties of graphs can be tested with query complexity that has a polynomial dependence on \(1/\epsilon\) in the adjacency matrix model. </p>



<p><strong>Compressibility-Aware Quantum Algorithms</strong> on Strings by Daniel Gibney and Sharma V. Thankachan (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.07235" target="_blank">arXiv</a>). Lastly, we have a paper on quantum string algorithms that run in sublinear time. In short, the authors present quantum algorithms with optimal running times for computing the Lempel-Ziv (LZ) encoding and Burrows Wheeler Transform (BWT) of highly compressible strings. A main consequence of these results is a faster quantum algorithm for computing the longest common subsequence (LCS) of two strings when the concatenation of the strings is highly compressible. It is to be noted that sublinear-time algorithms do not exist for these problems in the classical model of computation. More details follow. <br><br>Factoring a string into disjoint substrings (factors) in an specific manner is the main step in the LZ compression algorithm. The smaller the number of factors, the more compressible the string is.  This paper gives a quantum algorithm for the problem of computing the LZ factorization of a string in time \(\tilde{O}(\sqrt{nz})\), where \(z\) is the number of factors in the string. They also show that their algorithm is optimal. Using this algorithm, they obtain a fast algorithm for computing the BWT of an input string, as well as an algorithm running in time \(\tilde{O}(\sqrt{nz})\) to compute the LCS of two strings, where \(n\) is the length and \(z\) is the number of factors in the concatenation of the two strings. When \(z\) is \(o(n^{1/3})\), this algorithm gives an improvement over the previous best quantum algorithm running in time \(\tilde{O}(n^{2/3})\).</p>
<p class="authors">By Nithin Varma</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T06:59:54Z">Wednesday, March 08 2023, 06:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03645'>Filter Pruning based on Information Capacity and Independence</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaolong Tang, Tianheng Hu, Yufeng Shi</p><p>Filter pruning has been widely used in the compression and acceleration of
convolutional neural networks (CNNs). However, most existing methods are still
challenged by heavy compute cost and biased filter selection. Moreover, most
designs for filter evaluation miss interpretability due to the lack of
appropriate theoretical guidance. In this paper, we propose a novel filter
pruning method which evaluates filters in a interpretable, multi-persepective
and data-free manner. We introduce information capacity, a metric that
represents the amount of information contained in a filter. Based on the
interpretability and validity of information entropy, we propose to use that as
a quantitative index of information quantity. Besides, we experimently show
that the obvious correlation between the entropy of the feature map and the
corresponding filter, so as to propose an interpretable, data-driven scheme to
measure the information capacity of the filter. Further, we introduce
information independence, another metric that represents the correlation among
differrent filters. Consequently, the least impotant filters, which have less
information capacity and less information independence, will be pruned. We
evaluate our method on two benchmarks using multiple representative CNN
architectures, including VGG-16 and ResNet. On CIFAR-10, we reduce 71.9% of
floating-point operations (FLOPs) and 69.4% of parameters for ResNet-110 with
0.28% accuracy increase. On ILSVRC-2012, we reduce 76.6% of floating-point
operations (FLOPs) and 68.6% of parameters for ResNet-50 with only 2.80%
accuracy decrease, which outperforms the state-of-the-arts.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaolong Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1">Tianheng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yufeng Shi</a></p><p>Filter pruning has been widely used in the compression and acceleration of
convolutional neural networks (CNNs). However, most existing methods are still
challenged by heavy compute cost and biased filter selection. Moreover, most
designs for filter evaluation miss interpretability due to the lack of
appropriate theoretical guidance. In this paper, we propose a novel filter
pruning method which evaluates filters in a interpretable, multi-persepective
and data-free manner. We introduce information capacity, a metric that
represents the amount of information contained in a filter. Based on the
interpretability and validity of information entropy, we propose to use that as
a quantitative index of information quantity. Besides, we experimently show
that the obvious correlation between the entropy of the feature map and the
corresponding filter, so as to propose an interpretable, data-driven scheme to
measure the information capacity of the filter. Further, we introduce
information independence, another metric that represents the correlation among
differrent filters. Consequently, the least impotant filters, which have less
information capacity and less information independence, will be pruned. We
evaluate our method on two benchmarks using multiple representative CNN
architectures, including VGG-16 and ResNet. On CIFAR-10, we reduce 71.9% of
floating-point operations (FLOPs) and 69.4% of parameters for ResNet-110 with
0.28% accuracy increase. On ILSVRC-2012, we reduce 76.6% of floating-point
operations (FLOPs) and 68.6% of parameters for ResNet-50 with only 2.80%
accuracy decrease, which outperforms the state-of-the-arts.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03921'>Approximate degree lower bounds for oracle identification problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mark Bun, Nadezhda Voronova</p><p>The approximate degree of a Boolean function is the minimum degree of real
polynomial that approximates it pointwise. For any Boolean function, its
approximate degree serves as a lower bound on its quantum query complexity, and
generically lifts to a quantum communication lower bound for a related
function.
</p>
<p>We introduce a framework for proving approximate degree lower bounds for
certain oracle identification problems, where the goal is to recover a hidden
binary string $x \in \{0, 1\}^n$ given possibly non-standard oracle access to
it. We apply this framework to the ordered search and hidden string problems,
proving nearly tight approximate degree lower bounds of $\Omega(n/\log^2 n)$
for each.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bun_M/0/1/0/all/0/1">Mark Bun</a>, <a href="http://arxiv.org/find/cs/1/au:+Voronova_N/0/1/0/all/0/1">Nadezhda Voronova</a></p><p>The approximate degree of a Boolean function is the minimum degree of real
polynomial that approximates it pointwise. For any Boolean function, its
approximate degree serves as a lower bound on its quantum query complexity, and
generically lifts to a quantum communication lower bound for a related
function.
</p>
<p>We introduce a framework for proving approximate degree lower bounds for
certain oracle identification problems, where the goal is to recover a hidden
binary string $x \in \{0, 1\}^n$ given possibly non-standard oracle access to
it. We apply this framework to the ordered search and hidden string problems,
proving nearly tight approximate degree lower bounds of $\Omega(n/\log^2 n)$
for each.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03958'>The Linear Correlation of $P$ and $NP$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bojin Zheng, Weiwu Wang</p><p>$P \overset{\text{?}}{=} NP$ or $P\ vs\ NP$ is the core problem in
computational complexity theory. In this paper, we proposed a definition of
linear correlation of derived matrix and system, and discussed the linear
correlation of $P$ and $NP$. We draw a conclusion that $P$ is linearly
dependent and there exists $NP$ which is is linearly independent and take a
3SAT instance which belongs to $NP$ as the example , that is, $P \neq NP$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Bojin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiwu Wang</a></p><p>$P \overset{\text{?}}{=} NP$ or $P\ vs\ NP$ is the core problem in
computational complexity theory. In this paper, we proposed a definition of
linear correlation of derived matrix and system, and discussed the linear
correlation of $P$ and $NP$. We draw a conclusion that $P$ is linearly
dependent and there exists $NP$ which is is linearly independent and take a
3SAT instance which belongs to $NP$ as the example , that is, $P \neq NP$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03616'>Geometry-Aware Coverage Path Planning on Complex 3D Surfaces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Van-Thach Do, Quang-Cuong Pham</p><p>This paper presents a new approach to obtaining nearly complete coverage
paths (CP) with low overlapping on 3D general surfaces using mesh models given
or reconstructed from actual scenes. The CP is obtained by segmenting the mesh
model into a given number of clusters using constrained centroidal Voronoi
tessellation (CCVT) and finding the shortest path from cluster centroids using
the geodesic metric efficiently. We introduce a new cost function to
harmoniously achieve uniform areas of the obtained clusters and a restriction
on the variation of triangle normals during the construction of CCVTs. The
obtained clusters can be used to construct high-quality viewpoints (VP) for
visual coverage tasks. Here, we utilize the planned VPs as cleaning
configurations to perform residual powder removal in additive manufacturing
using manipulator robots. The self-occlusion of VPs and ensuring collision-free
robot configurations are addressed by integrating a proposed optimization-based
strategy to find a set of candidate rays for each VP into the motion planning
phase. CP planning benchmarks and physical experiments are conducted to
demonstrate the effectiveness of the proposed approach. We show that our
approach can compute the CPs and VPs of various mesh models with a massive
number of triangles within a reasonable time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Do_V/0/1/0/all/0/1">Van-Thach Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1">Quang-Cuong Pham</a></p><p>This paper presents a new approach to obtaining nearly complete coverage
paths (CP) with low overlapping on 3D general surfaces using mesh models given
or reconstructed from actual scenes. The CP is obtained by segmenting the mesh
model into a given number of clusters using constrained centroidal Voronoi
tessellation (CCVT) and finding the shortest path from cluster centroids using
the geodesic metric efficiently. We introduce a new cost function to
harmoniously achieve uniform areas of the obtained clusters and a restriction
on the variation of triangle normals during the construction of CCVTs. The
obtained clusters can be used to construct high-quality viewpoints (VP) for
visual coverage tasks. Here, we utilize the planned VPs as cleaning
configurations to perform residual powder removal in additive manufacturing
using manipulator robots. The self-occlusion of VPs and ensuring collision-free
robot configurations are addressed by integrating a proposed optimization-based
strategy to find a set of candidate rays for each VP into the motion planning
phase. CP planning benchmarks and physical experiments are conducted to
demonstrate the effectiveness of the proposed approach. We show that our
approach can compute the CPs and VPs of various mesh models with a massive
number of triangles within a reasonable time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04014'>Hausdorff and Gromov-Hausdorff stable subsets of the medial axis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andr&#xe9; Lieutier, Mathijs Wintraecken</p><p>In this paper we introduce a pruning of the medial axis called the
$(\lambda,\alpha)$-medial axis ($\textrm{ax}_\lambda^\alpha $). We prove that
the $(\lambda,\alpha)$-medial axis of a set $K$ is stable in a Gromov-Hausdorff
sense under weak assumptions. More formally we prove that if $K$ and $K'$ are
close in the Hausdorff ($d_H$) sense then the $(\lambda,\alpha)$-medial axes of
$K$ and $K'$ are close as metric spaces, that is the Gromov-Hausdorff distance
($d_{GH}$) between the two is $\frac{1}{4}$-H{\"o}lder in the sense that
$d_{GH} (\textrm{ax}_\lambda^\alpha (K),\textrm{ax}_\lambda^\alpha (K'))
\lesssim d_H(K,K')^{1/4}$. The Hausdorff distance between the two medial axes
is also bounded, by $d_{H} (\textrm{ax}_\lambda^\alpha
(K),\textrm{ax}_\lambda^\alpha (K')) \lesssim d_H(K,K')^{1/2}$. These
quantified stability results provide guarantees for practical computations of
medial axes from approximations. Moreover, they provide key ingredients for
studying the computability of the medial axis in the context of computable
analysis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lieutier_A/0/1/0/all/0/1">Andr&#xe9; Lieutier</a>, <a href="http://arxiv.org/find/cs/1/au:+Wintraecken_M/0/1/0/all/0/1">Mathijs Wintraecken</a></p><p>In this paper we introduce a pruning of the medial axis called the
$(\lambda,\alpha)$-medial axis ($\textrm{ax}_\lambda^\alpha $). We prove that
the $(\lambda,\alpha)$-medial axis of a set $K$ is stable in a Gromov-Hausdorff
sense under weak assumptions. More formally we prove that if $K$ and $K'$ are
close in the Hausdorff ($d_H$) sense then the $(\lambda,\alpha)$-medial axes of
$K$ and $K'$ are close as metric spaces, that is the Gromov-Hausdorff distance
($d_{GH}$) between the two is $\frac{1}{4}$-H{\"o}lder in the sense that
$d_{GH} (\textrm{ax}_\lambda^\alpha (K),\textrm{ax}_\lambda^\alpha (K'))
\lesssim d_H(K,K')^{1/4}$. The Hausdorff distance between the two medial axes
is also bounded, by $d_{H} (\textrm{ax}_\lambda^\alpha
(K),\textrm{ax}_\lambda^\alpha (K')) \lesssim d_H(K,K')^{1/2}$. These
quantified stability results provide guarantees for practical computations of
medial axes from approximations. Moreover, they provide key ingredients for
studying the computability of the medial axis in the context of computable
analysis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04079'>An extension theorem for signotopes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Helena Bergold, Stefan Felsner, Manfred Scheucher</p><p>In 1926, Levi showed that, for every pseudoline arrangement $\mathcal{A}$ and
two points in the plane, $\mathcal{A}$ can be extended by a pseudoline which
contains the two prescribed points. Later extendability was studied for
arrangements of pseudohyperplanes in higher dimensions. While the extendability
of an arrangement of proper hyperplanes in $\mathbb{R}^d$ with a hyperplane
containing $d$ prescribed points is trivial, Richter-Gebert found an
arrangement of pseudoplanes in $\mathbb{R}^3$ which cannot be extended with a
pseudoplane containing two particular prescribed points. In this article, we
investigate the extendability of signotopes, which are a combinatorial
structure encoding a rich subclass of pseudohyperplane arrangements. Our main
result is that signotopes of odd rank are extendable in the sense that for two
prescribed crossing points we can add an element containing them. Moreover, we
conjecture that in all even ranks $r \geq 4$ there exist signotopes which are
not extendable for two prescribed points. Our conjecture is supported by
examples in ranks 4, 6, 8, 10, and 12 that were found with a SAT based
approach.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Bergold_H/0/1/0/all/0/1">Helena Bergold</a>, <a href="http://arxiv.org/find/math/1/au:+Felsner_S/0/1/0/all/0/1">Stefan Felsner</a>, <a href="http://arxiv.org/find/math/1/au:+Scheucher_M/0/1/0/all/0/1">Manfred Scheucher</a></p><p>In 1926, Levi showed that, for every pseudoline arrangement $\mathcal{A}$ and
two points in the plane, $\mathcal{A}$ can be extended by a pseudoline which
contains the two prescribed points. Later extendability was studied for
arrangements of pseudohyperplanes in higher dimensions. While the extendability
of an arrangement of proper hyperplanes in $\mathbb{R}^d$ with a hyperplane
containing $d$ prescribed points is trivial, Richter-Gebert found an
arrangement of pseudoplanes in $\mathbb{R}^3$ which cannot be extended with a
pseudoplane containing two particular prescribed points. In this article, we
investigate the extendability of signotopes, which are a combinatorial
structure encoding a rich subclass of pseudohyperplane arrangements. Our main
result is that signotopes of odd rank are extendable in the sense that for two
prescribed crossing points we can add an element containing them. Moreover, we
conjecture that in all even ranks $r \geq 4$ there exist signotopes which are
not extendable for two prescribed points. Our conjecture is supported by
examples in ranks 4, 6, 8, 10, and 12 that were found with a SAT based
approach.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03617'>Computing Effective Resistances on Large Graphs Based on Approximate Inverse of Cholesky Factor</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhiqiang Liu, Wenjian Yu</p><p>Effective resistance, which originates from the field of circuits analysis,
is an important graph distance in spectral graph theory. It has found numerous
applications in various areas, such as graph data mining, spectral graph
sparsification, circuits simulation, etc. However, computing effective
resistances accurately can be intractable and we still lack efficient methods
for estimating effective resistances on large graphs. In this work, we propose
an efficient algorithm to compute effective resistances on general weighted
graphs, based on a sparse approximate inverse technique. Compared with a recent
competitor, the proposed algorithm shows several hundreds of speedups and also
one to two orders of magnitude improvement in the accuracy of results.
Incorporating the proposed algorithm with the graph sparsification based power
grid (PG) reduction framework, we develop a fast PG reduction method, which
achieves an average 6.4X speedup in the reduction time without loss of
reduction accuracy. In the applications of power grid transient analysis and DC
incremental analysis, the proposed method enables 1.7X and 2.5X speedup of
overall time compared to using the PG reduction based on accurate effective
resistances, without increase in the error of solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Liu_Z/0/1/0/all/0/1">Zhiqiang Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Yu_W/0/1/0/all/0/1">Wenjian Yu</a></p><p>Effective resistance, which originates from the field of circuits analysis,
is an important graph distance in spectral graph theory. It has found numerous
applications in various areas, such as graph data mining, spectral graph
sparsification, circuits simulation, etc. However, computing effective
resistances accurately can be intractable and we still lack efficient methods
for estimating effective resistances on large graphs. In this work, we propose
an efficient algorithm to compute effective resistances on general weighted
graphs, based on a sparse approximate inverse technique. Compared with a recent
competitor, the proposed algorithm shows several hundreds of speedups and also
one to two orders of magnitude improvement in the accuracy of results.
Incorporating the proposed algorithm with the graph sparsification based power
grid (PG) reduction framework, we develop a fast PG reduction method, which
achieves an average 6.4X speedup in the reduction time without loss of
reduction accuracy. In the applications of power grid transient analysis and DC
incremental analysis, the proposed method enables 1.7X and 2.5X speedup of
overall time compared to using the PG reduction based on accurate effective
resistances, without increase in the error of solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03705'>Fairness-aware Maximal Biclique Enumeration on Bipartite Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ziqi Yin, Qi Zhang, Wentao Zhang, Rong-Hua Li, Guoren Wang</p><p>Maximal biclique enumeration is a fundamental problem in bipartite graph data
analysis. Existing biclique enumeration methods mainly focus on non-attributed
bipartite graphs and also ignore the \emph{fairness} of graph attributes. In
this paper, we introduce the concept of fairness into the biclique model for
the first time and study the problem of fairness-aware biclique enumeration.
Specifically, we propose two fairness-aware biclique models, called
\nonesidebc~and \ntwosidebc~respectively. To efficiently enumerate all
{\nonesidebc}s, we first present two non-trivial pruning techniques, called
fair $\alpha$-$\beta$ core pruning and colorful fair $\alpha$-$\beta$ core
pruning, to reduce the graph size without losing accuracy. Then, we develop a
branch and bound algorithm, called \onesideFBCEM, to enumerate all single-side
fair bicliques on the reduced bipartite graph. To further improve the
efficiency, we propose an efficient branch and bound algorithm with a
carefully-designed combinatorial enumeration technique. Note that all of our
techniques can also be extended to enumerate all bi-side fair bicliques. We
also extend the two fairness-aware biclique models by constraining the ratio of
the number of vertices of each attribute to the total number of vertices and
present corresponding enumeration algorithms. Extensive experimental results on
five large real-world datasets demonstrate our methods' efficiency,
effectiveness, and scalability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Ziqi Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wentao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Rong-Hua Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoren Wang</a></p><p>Maximal biclique enumeration is a fundamental problem in bipartite graph data
analysis. Existing biclique enumeration methods mainly focus on non-attributed
bipartite graphs and also ignore the \emph{fairness} of graph attributes. In
this paper, we introduce the concept of fairness into the biclique model for
the first time and study the problem of fairness-aware biclique enumeration.
Specifically, we propose two fairness-aware biclique models, called
\nonesidebc~and \ntwosidebc~respectively. To efficiently enumerate all
{\nonesidebc}s, we first present two non-trivial pruning techniques, called
fair $\alpha$-$\beta$ core pruning and colorful fair $\alpha$-$\beta$ core
pruning, to reduce the graph size without losing accuracy. Then, we develop a
branch and bound algorithm, called \onesideFBCEM, to enumerate all single-side
fair bicliques on the reduced bipartite graph. To further improve the
efficiency, we propose an efficient branch and bound algorithm with a
carefully-designed combinatorial enumeration technique. Note that all of our
techniques can also be extended to enumerate all bi-side fair bicliques. We
also extend the two fairness-aware biclique models by constraining the ratio of
the number of vertices of each attribute to the total number of vertices and
present corresponding enumeration algorithms. Extensive experimental results on
five large real-world datasets demonstrate our methods' efficiency,
effectiveness, and scalability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03741'>Complete Log Concavity of Coverage-Like Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dorna Abdolazimi, Shayan Oveis Gharan</p><p>We introduce an expressive subclass of non-negative almost submodular set
functions, called strongly 2-coverage functions which include coverage and
(sums of) matroid rank functions, and prove that the homogenization of the
generating polynomial of any such function is completely log-concave, taking a
step towards characterizing the coefficients of (homogeneous) completely
log-concave polynomials. As a consequence we obtain that the "level sets" of
any such function form an ultra-log concave sequence.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Abdolazimi_D/0/1/0/all/0/1">Dorna Abdolazimi</a>, <a href="http://arxiv.org/find/math/1/au:+Gharan_S/0/1/0/all/0/1">Shayan Oveis Gharan</a></p><p>We introduce an expressive subclass of non-negative almost submodular set
functions, called strongly 2-coverage functions which include coverage and
(sums of) matroid rank functions, and prove that the homogenization of the
generating polynomial of any such function is completely log-concave, taking a
step towards characterizing the coefficients of (homogeneous) completely
log-concave polynomials. As a consequence we obtain that the "level sets" of
any such function form an ultra-log concave sequence.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03962'>Cops and Robbers on Multi-Layer Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jessica Enright, Kitty Meeks, William Pettersson, John Sylvester</p><p>We generalise the popular cops and robbers game to multi-layer graphs, where
each cop and the robber are restricted to a single layer (or set of edges). We
show that initial intuition about the best way to allocate cops to layers is
not always correct, and prove that the multi-layer cop number is neither
bounded from above nor below by any function of the cop numbers of the
individual layers. We determine that it is NP-hard to decide if k cops are
sufficient to catch the robber, even if all cop layers are trees. However, we
give a polynomial time algorithm to determine if k cops can win when the robber
layer is a tree. Additionally, we investigate a question of worst-case division
of a simple graph into layers: given a simple graph G, what is the maximum
number of cops required to catch a robber over all multi-layer graphs where
each edge of G is in at least one layer and all layers are connected? For
cliques, suitably dense random graphs, and graphs of bounded treewidth, we
determine this parameter up to multiplicative constants. Lastly we consider a
multi-layer variant of Meyniel's Conjecture, and show the existence of an
infinite family of graphs whose multi-layer cop number is bounded from below by
a constant times n / log n, where n is the number of vertices in the graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Enright_J/0/1/0/all/0/1">Jessica Enright</a>, <a href="http://arxiv.org/find/math/1/au:+Meeks_K/0/1/0/all/0/1">Kitty Meeks</a>, <a href="http://arxiv.org/find/math/1/au:+Pettersson_W/0/1/0/all/0/1">William Pettersson</a>, <a href="http://arxiv.org/find/math/1/au:+Sylvester_J/0/1/0/all/0/1">John Sylvester</a></p><p>We generalise the popular cops and robbers game to multi-layer graphs, where
each cop and the robber are restricted to a single layer (or set of edges). We
show that initial intuition about the best way to allocate cops to layers is
not always correct, and prove that the multi-layer cop number is neither
bounded from above nor below by any function of the cop numbers of the
individual layers. We determine that it is NP-hard to decide if k cops are
sufficient to catch the robber, even if all cop layers are trees. However, we
give a polynomial time algorithm to determine if k cops can win when the robber
layer is a tree. Additionally, we investigate a question of worst-case division
of a simple graph into layers: given a simple graph G, what is the maximum
number of cops required to catch a robber over all multi-layer graphs where
each edge of G is in at least one layer and all layers are connected? For
cliques, suitably dense random graphs, and graphs of bounded treewidth, we
determine this parameter up to multiplicative constants. Lastly we consider a
multi-layer variant of Meyniel's Conjecture, and show the existence of an
infinite family of graphs whose multi-layer cop number is bounded from below by
a constant times n / log n, where n is the number of vertices in the graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03964'>Force-Directed Graph Layouts Revisited: A New Force Based on the T-Distribution</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fahai Zhong, Mingliang Xue, Jian Zhang, Fan Zhang, Rui Ban, Oliver Deussen, Yunhai Wang</p><p>In this paper, we propose the t-FDP model, a force-directed placement method
based on a novel bounded short-range force (t-force) defined by Student's
t-distribution. Our formulation is flexible, exerts limited repulsive forces
for nearby nodes and can be adapted separately in its short- and long-range
effects. Using such forces in force-directed graph layouts yields better
neighborhood preservation than current methods, while maintaining low stress
errors. Our efficient implementation using a Fast Fourier Transform is one
order of magnitude faster than state-of-the-art methods and two orders faster
on the GPU, enabling us to perform parameter tuning by globally and locally
adjusting the t-force in real-time for complex graphs. We demonstrate the
quality of our approach by numerical evaluation against state-of-the-art
approaches and extensions for interactive exploration.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhong_F/0/1/0/all/0/1">Fahai Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1">Mingliang Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ban_R/0/1/0/all/0/1">Rui Ban</a>, <a href="http://arxiv.org/find/cs/1/au:+Deussen_O/0/1/0/all/0/1">Oliver Deussen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhai Wang</a></p><p>In this paper, we propose the t-FDP model, a force-directed placement method
based on a novel bounded short-range force (t-force) defined by Student's
t-distribution. Our formulation is flexible, exerts limited repulsive forces
for nearby nodes and can be adapted separately in its short- and long-range
effects. Using such forces in force-directed graph layouts yields better
neighborhood preservation than current methods, while maintaining low stress
errors. Our efficient implementation using a Fast Fourier Transform is one
order of magnitude faster than state-of-the-art methods and two orders faster
on the GPU, enabling us to perform parameter tuning by globally and locally
adjusting the t-force in real-time for complex graphs. We demonstrate the
quality of our approach by numerical evaluation against state-of-the-art
approaches and extensions for interactive exploration.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, March 07
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/03/07/greg-kuperberg-tel-aviv-university/'>Greg Kuperberg @ Tel Aviv University</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Greg Kuperberg is on a short visit in Israel and yesterday he gave a fantastic lecture on an improved bound for the Solovay-Kitaev theorem. Here is a videotaped lecture of Greg on the same topic in QIP2023. The Solovay-Kitaev theorem &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><img data-attachment-id="23940" data-permalink="https://gilkalai.wordpress.com/2023/03/07/greg-kuperberg-tel-aviv-university/zigzagolf/" data-orig-file="https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png" data-orig-size="382,418" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zigzagolf" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png?w=274" data-large-file="https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png?w=382" class="alignnone size-full wp-image-23940" src="https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png?w=640" alt="zigzagolf" srcset="https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png 382w, https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png?w=137 137w, https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png?w=274 274w" sizes="(max-width: 382px) 100vw, 382px"   /></p>
<p>Greg Kuperberg is on a short visit in Israel and yesterday he gave a fantastic lecture on an improved bound for the Solovay-Kitaev theorem. Here is a videotaped lecture of Greg on the same topic in QIP2023.</p>
<p><iframe class="youtube-player" width="640" height="360" src="https://www.youtube.com/embed/_quPWFo7YPc?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></p>
<p>The Solovay-Kitaev theorem from 1995 (in a stronger version by Kitaev-Shen-Viyalyi) asserts that</p>
<p><strong>Theorem:</strong>  If <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> is a finite subset of  <img src="https://s0.wp.com/latex.php?latex=G%3DSU%28d%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G%3DSU%28d%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G%3DSU%28d%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G=SU(d)" class="latex" /> that densely generates <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> with the property that <img src="https://s0.wp.com/latex.php?latex=A%3DA%5E%7B-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A%3DA%5E%7B-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%3DA%5E%7B-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A=A^{-1}" class="latex" />, then there is an efficient algorithm to <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon" class="latex" />-approximate every element <img src="https://s0.wp.com/latex.php?latex=g+%5Cin+G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g+%5Cin+G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g+%5Cin+G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g &#92;in G" class="latex" /> by a word <img src="https://s0.wp.com/latex.php?latex=w_A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w_A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w_A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w_A" class="latex" />  of length</p>
<p><img src="https://s0.wp.com/latex.php?latex=O%28%5Clog+%5Cfrac%7B1%7D%7B%5Cepsilon%7D%29%5E%7B%5Cgamma%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28%5Clog+%5Cfrac%7B1%7D%7B%5Cepsilon%7D%29%5E%7B%5Cgamma%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28%5Clog+%5Cfrac%7B1%7D%7B%5Cepsilon%7D%29%5E%7B%5Cgamma%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(&#92;log &#92;frac{1}{&#92;epsilon})^{&#92;gamma}," class="latex" /></p>
<p>where we can take <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3D+3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+%3D+3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+%3D+3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma = 3+&#92;delta" class="latex" />, for every <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdelta+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;delta &gt;0" class="latex" />.</p>
<p>Greg mentioned several improvements and related results shown over the years, and he addressed the question of improving <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" />. His result, which gave the first known improvement (using two separate ideas) takes <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" /> down from <img src="https://s0.wp.com/latex.php?latex=3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3+&#92;delta" class="latex" /> to 1.44042&#8230;</p>
<p>(I told Greg that the mathematicians&#8217; labor unions frown upon such drastic advances in a single paper.)</p>
<p>You can test your intuition for what 1.44042&#8230; stands for.</p>
<p><span id="more-23935"></span></p>
<p>1.44042 stands for <img src="https://s0.wp.com/latex.php?latex=%5Clog+_%5Cphi+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+_%5Cphi+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+_%5Cphi+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log _&#92;phi 2" class="latex" /> where golden <img src="https://s0.wp.com/latex.php?latex=%5Cphi%3D%5Cfrac+%7B1%2B%5Csqrt+5%7D%7B2%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi%3D%5Cfrac+%7B1%2B%5Csqrt+5%7D%7B2%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi%3D%5Cfrac+%7B1%2B%5Csqrt+5%7D%7B2%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi=&#92;frac {1+&#92;sqrt 5}{2}." class="latex" /></p>
<p>Solovay-Kitaev&#8217;s theorem and its extensions are related to questions about expansion and other properties of Cayley graphs of Lie groups, questions in additive number theory, and questions in group theory. One of the techniques that Greg has developed is referred to as zigzag Golf (see the picture above) and another technique that Greg applies is related to higher commutators and the Elkasapy-Thom theory.</p>
<p>After the lecture, a few of us had a very nice chat with Greg over lunch on various issues. Just before I left Greg told me about three experimental advances regarding quantum error correcting that he found exciting (and which he thought were potentially relevant to a long and intensive email discussion/debate that he and I have been having on the topic since 2005.) I will mention these examples and some related information in <a href="https://gilkalai.wordpress.com/2022/05/26/waging-war-on-quantum/#comment-94128">a comment</a> to <a href="http://(https://gilkalai.wordpress.com/2022/05/26/waging-war-on-quantum/">this post</a>. After more than a decade of a continuous, intensive debate and a few later bursts of additional fierce discussions (also on blogs and FB), Greg and I decided on a truce with a friendly exchange of ideas from time to time.</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T19:45:54Z">Tuesday, March 07 2023, 19:45</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/'>STACS 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Symposium on Theoretical Aspects of Computer Science&#8212;STACS&#8212;will take place from 7th March to 9th March 2023 in Universitat Hamburg, Hamburg, Germany. It starts right away&#8212;tomorrow. I cannot go to this one, but it has been a strong theory conference over the past. And I wish I could go to this one. Ken says the [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
The Symposium on Theoretical Aspects of Computer Science&#8212;STACS&#8212;will take place from 7th March to 9th March 2023 in Universitat Hamburg, Hamburg, Germany. It starts right away&#8212;tomorrow. </p>
<p>
I cannot go to this one, but it has been a strong theory conference over the past. And I wish I could go to this one. Ken says the same.  He recalls that the two of us connected in a big way at STACS 1994 in Caen, France.</p>
<p>
For the first time, <a href="https://www.conferences.uni-hamburg.de/event/272/page/153-home">STACS 2023</a> will consist of two tracks, A and B, to facilitate the work of the program committee(s). Track A is dedicated to algorithms and data structures, complexity and games. Track B will cover automata, logic, semantics and theory of programming.</p>
<p>
The conference is chaired by Petra Berenbrink and Mamadou Kant&eacute; for track A, Anuj Dawar and Patricia Bouyer-Decitre for track B.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/trackleadersab/" rel="attachment wp-att-21227"><img data-attachment-id="21227" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/trackleadersab/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?fit=228%2C334&amp;ssl=1" data-orig-size="228,334" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="TrackLeadersAB" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?fit=205%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?fit=228%2C334&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?resize=228%2C334&#038;ssl=1" alt="" width="228" height="334" class="aligncenter size-full wp-image-21227" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?w=228&amp;ssl=1 228w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?resize=205%2C300&amp;ssl=1 205w" sizes="(max-width: 228px) 100vw, 228px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Invited Speakers </H2></p>
<p><p>
There are three invited speakers. Here are their titles and talk descriptions:</p>
<p>
<b>Eva Rotenberg</b> (Technical University of Denmark): <b>Amortised Analysis of Dynamic Data Structures.</b></p>
<p>
In dynamic data structures, one is interested in efficiently facilitating queries to a data set, while being able to efficiently perform updates as the data set undergoes changes. Often, relaxing the efficiency measure to the amortised setting allows for simpler algorithms. A well-known example of a data structure with amortised guarantees is the splay tree by Sleator and Tarjan.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/er/" rel="attachment wp-att-21220"><img data-attachment-id="21220" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/er/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/er.jpeg?fit=201%2C251&amp;ssl=1" data-orig-size="201,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="er" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/er.jpeg?fit=201%2C251&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/er.jpeg?fit=201%2C251&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/er.jpeg?resize=201%2C251&#038;ssl=1" alt="" width="201" height="251" class="aligncenter size-full wp-image-21220" data-recalc-dims="1" /></a></p>
<p><P><br />
<b>Karoliina Lehtinen</b> (CNRS, Aix-Marseille Univercity, LIS, Marseille, France ): <b>A brief history of history-determinism.</b></p>
<p>
Most nondeterministic automata models are more expressive, or at least more succinct, than their deterministic counterparts; however, this comes at a cost, as deterministic automata tend to have better algorithmic properties. History-deterministic automata are an intermediate model that allows a restricted form of nondeterminism: all nondeterministic choices must be resolvable on-the-fly, with only the knowledge of the word prefix read so far&#8212;as opposed to general nondeterminism, which allows for guessing the future of the word. History-deterministic automata combine some of the algorithmic benefits of determinism with some of the increased power of nondeterminism, thus enjoying (some of) the best of both worlds. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/kl-2/" rel="attachment wp-att-21221"><img data-attachment-id="21221" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/kl-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/kl.jpeg?fit=211%2C239&amp;ssl=1" data-orig-size="211,239" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kl" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/kl.jpeg?fit=211%2C239&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/kl.jpeg?fit=211%2C239&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/kl.jpeg?resize=211%2C239&#038;ssl=1" alt="" width="211" height="239" class="aligncenter size-full wp-image-21221" data-recalc-dims="1" /></a></p>
<p><P><br />
<b>Moshe Vardi</b> (Rice University): <b>Logical Algorithmics: From Theory to Practice.</b></p>
<p>
The standard approach to algorithm development is to focus on a specific problem and develop for it a specific algorithm. Codd&#8217;s introduction of the relational model in 1970 included two fundamental ideas: </p>
<p>
(1) Relations provide a universal data representation formalism, and </p>
<p>
(2) Relational databases can be queried using first-order logic. </p>
<p>
Realizing these ideas required the development of a meta-algorithm, which takes a declarative query and executes it with respect to a database. In this talk, I will describe this approach, which I call Logical Algorithmics, in detail, and explore its profound ramification.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/mv/" rel="attachment wp-att-21222"><img data-attachment-id="21222" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/mv/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?fit=440%2C346&amp;ssl=1" data-orig-size="440,346" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mv" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?fit=300%2C236&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?fit=440%2C346&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?resize=220%2C173&#038;ssl=1" alt="" width="220" height="173" class="aligncenter wp-image-21222" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?w=440&amp;ssl=1 440w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?resize=300%2C236&amp;ssl=1 300w" sizes="(max-width: 220px) 100vw, 220px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Selected Papers </H2></p>
<p><p>
Here are a few of the accepted papers:</p>
<ul>
<p><li>
Edouard Bonnet, Ugo Giocanti, Patrice Ossona de Mendez and Stephan Thomasse. <a href="https://arxiv.org/abs/2209.12023">Twin-width V: linear minors, modular counting, and matrix multiplication</a>.</p>
<p><li>
Charles Paperman, Sylvain Salvati and Claire Soyez-Martin. <a href="https://hal.science/hal-03831752/file/main.pdf">An algebraic approach to vectorial programs</a>.</p>
<p><li>
Pascal Baumann, Roland Meyer and Georg Zetzsche. <a href="https://arxiv.org/abs/2301.11242">Regular Separability in Buchi Vector Addition Systems</a></p>
<p><li>
Monika Henzinger, Stefan Neumann, Harald Racke and Stefan Schmid. <a href="https://arxiv.org/abs/2301.01744">Dynamic Maintenance of Monotone Dynamic Programs and Applications</a>.</p>
<p><li>
Satyadev Nandakumar and Subin Pulari. <a href="https://arxiv.org/pdf/2208.06340.pdf">Real numbers equally compressible in every base</a>.</p>
</ul>
<p>
See this <a href="https://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16268">for all the papers</a>. That is a <b>complete list</b>. </p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
I highlighted the above papers for personal reasons&#8212;hmmm.</p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T04:25:19Z">Tuesday, March 07 2023, 04:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02301'>Locally universal C*-algebras with computable presentations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alec Fox, Isaac Goldbring, Bradd Hart</p><p>The Kirchberg Embedding Problem (KEP) asks if every C*-algebra embeds into an
ultrapower of the Cuntz algebra $\mathcal{O}_2$. In an effort to provide a
negative solution to the KEP and motivated by the recent refutation of the
Connes Embedding Problem, we establish two computability-theoretic consequences
of a positive solution to KEP. Both of our results follow from the a priori
weaker assumption that there exists a locally universal C*-algebra with a
computable presentation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Fox_A/0/1/0/all/0/1">Alec Fox</a>, <a href="http://arxiv.org/find/math/1/au:+Goldbring_I/0/1/0/all/0/1">Isaac Goldbring</a>, <a href="http://arxiv.org/find/math/1/au:+Hart_B/0/1/0/all/0/1">Bradd Hart</a></p><p>The Kirchberg Embedding Problem (KEP) asks if every C*-algebra embeds into an
ultrapower of the Cuntz algebra $\mathcal{O}_2$. In an effort to provide a
negative solution to the KEP and motivated by the recent refutation of the
Connes Embedding Problem, we establish two computability-theoretic consequences
of a positive solution to KEP. Both of our results follow from the a priori
weaker assumption that there exists a locally universal C*-algebra with a
computable presentation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02337'>Some results on Minimum Consistent Subsets of Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bubai Manna, Bodhayan Roy</p><p>For a graph G = (V,E) where each vertex is coloured by one of k colours,
consider a subset C of V such that for each vertex v in V\C, its set of nearest
neighbours in C contains at least one vertex of the same colour as v. Such a C
is called a consistent subset (CS). Computing a consistent subset of the
minimum size is called the Minimum Consistent Subset problem (MCS). MCS is
known to be NP-complete for planar graphs. We propose a polynomial-time
algorithm for finding a minimum consistent subset of a k-chromatic spider graph
when k is a constant. We also show MCS remains NP-complete on trees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Manna_B/0/1/0/all/0/1">Bubai Manna</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Bodhayan Roy</a></p><p>For a graph G = (V,E) where each vertex is coloured by one of k colours,
consider a subset C of V such that for each vertex v in V\C, its set of nearest
neighbours in C contains at least one vertex of the same colour as v. Such a C
is called a consistent subset (CS). Computing a consistent subset of the
minimum size is called the Minimum Consistent Subset problem (MCS). MCS is
known to be NP-complete for planar graphs. We propose a polynomial-time
algorithm for finding a minimum consistent subset of a k-chromatic spider graph
when k is a constant. We also show MCS remains NP-complete on trees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02283'>On Maximum Bipartite Matching with Separation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pasin Manurangsi, Erel Segal-Halevi, Warut Suksompong</p><p>Maximum bipartite matching is a fundamental algorithmic problem which can be
solved in polynomial time. We consider a natural variant in which there is a
separation constraint: the vertices on one side lie on a path or a grid, and
two vertices that are close to each other are not allowed to be matched
simultaneously. We show that the problem is hard to approximate even for paths,
and provide constant-factor approximation algorithms for both paths and grids.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1">Pasin Manurangsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Segal_Halevi_E/0/1/0/all/0/1">Erel Segal-Halevi</a>, <a href="http://arxiv.org/find/cs/1/au:+Suksompong_W/0/1/0/all/0/1">Warut Suksompong</a></p><p>Maximum bipartite matching is a fundamental algorithmic problem which can be
solved in polynomial time. We consider a natural variant in which there is a
separation constraint: the vertices on one side lie on a path or a grid, and
two vertices that are close to each other are not allowed to be matched
simultaneously. We show that the problem is hard to approximate even for paths,
and provide constant-factor approximation algorithms for both paths and grids.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02317'>Fast Option Pricing using Nonlinear Stencils</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zafar Ahmad, Rezaul Chowdhury, Rathish Das, Yushen Huang, Yimin Zhu</p><p>We study the binomial option pricing model and the Black-Scholes-Merton
pricing model. In the binomial option pricing model, we concentrate on two
widely-used call options: (1) European and (2) American. Under the
Black-Scholes-Merton model, we investigate pricing American put options. Our
contributions are two-fold: First, we transform the option pricing problems
into nonlinear stencil computation problems and present efficient algorithms to
solve them. Second, using our new FFT-based nonlinear stencil algorithms, we
improve the work and span asymptotically for the option pricing problems we
consider. In particular, we perform $O(T\log^2 T)$ work for both American call
and put option pricing, where $T$ is the number of time steps.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ahmad_Z/0/1/0/all/0/1">Zafar Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_R/0/1/0/all/0/1">Rezaul Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1">Rathish Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yushen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yimin Zhu</a></p><p>We study the binomial option pricing model and the Black-Scholes-Merton
pricing model. In the binomial option pricing model, we concentrate on two
widely-used call options: (1) European and (2) American. Under the
Black-Scholes-Merton model, we investigate pricing American put options. Our
contributions are two-fold: First, we transform the option pricing problems
into nonlinear stencil computation problems and present efficient algorithms to
solve them. Second, using our new FFT-based nonlinear stencil algorithms, we
improve the work and span asymptotically for the option pricing problems we
consider. In particular, we perform $O(T\log^2 T)$ work for both American call
and put option pricing, where $T$ is the number of time steps.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02390'>Efficient maximal cliques enumeration in weakly closed graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: George Manoussakis</p><p>We show that the algorithm presented in [J. Fox, T. Roughgarden, C.
Seshadhri, F. Wei, and N. Wein. Finding cliques in social networks: A new
distribution-free model. SIAM journal on computing, 49(2):448-464, 2020.] can
be modified to have enumeration time complexity $\alpha\mathcal{O} (npoly(c))$.
Here parameter $c$ is the weakly closure of the graph and $\alpha$ its number
of maximal cliques. This result improves on their complexity which was not
output sensitive and exponential in the closure of the graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Manoussakis_G/0/1/0/all/0/1">George Manoussakis</a></p><p>We show that the algorithm presented in [J. Fox, T. Roughgarden, C.
Seshadhri, F. Wei, and N. Wein. Finding cliques in social networks: A new
distribution-free model. SIAM journal on computing, 49(2):448-464, 2020.] can
be modified to have enumeration time complexity $\alpha\mathcal{O} (npoly(c))$.
Here parameter $c$ is the weakly closure of the graph and $\alpha$ its number
of maximal cliques. This result improves on their complexity which was not
output sensitive and exponential in the closure of the graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
