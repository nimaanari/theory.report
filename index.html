<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-03-03T13:35:09Z">Friday, March 03 2023, 13:35</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, March 03
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01016'>On the Consistency of Circuit Lower Bounds for Non-Deterministic Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Albert Atserias, Sam Buss, Moritz M&#xfc;ller</p><p>We prove the first unconditional consistency result for superpolynomial
circuit lower bounds with a relatively strong theory of bounded arithmetic.
Namely, we show that the theory V$^0_2$ is consistent with the conjecture that
NEXP $\not\subseteq$ P/poly, i.e., some problem that is solvable in
non-deterministic exponential time does not have polynomial size circuits. We
suggest this is the best currently available evidence for the truth of the
conjecture. The same techniques establish the same results with NEXP replaced
by the class of problems that are decidable in non-deterministic barely
superpolynomial time such as NTIME$(n^{O(\log\log\log n)})$. Additionally, we
establish a magnification result on the hardness of proving circuit lower
bounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Atserias_A/0/1/0/all/0/1">Albert Atserias</a>, <a href="http://arxiv.org/find/cs/1/au:+Buss_S/0/1/0/all/0/1">Sam Buss</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_M/0/1/0/all/0/1">Moritz M&#xfc;ller</a></p><p>We prove the first unconditional consistency result for superpolynomial
circuit lower bounds with a relatively strong theory of bounded arithmetic.
Namely, we show that the theory V$^0_2$ is consistent with the conjecture that
NEXP $\not\subseteq$ P/poly, i.e., some problem that is solvable in
non-deterministic exponential time does not have polynomial size circuits. We
suggest this is the best currently available evidence for the truth of the
conjecture. The same techniques establish the same results with NEXP replaced
by the class of problems that are decidable in non-deterministic barely
superpolynomial time such as NTIME$(n^{O(\log\log\log n)})$. Additionally, we
establish a magnification result on the hardness of proving circuit lower
bounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01411'>Algorithmic Randomness and Probabilistic Laws</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jeffrey A. Barrett, Eddy Keming Chen</p><p>We consider two ways one might use algorithmic randomness to characterize a
probabilistic law. The first is a generative chance* law. Such laws involve a
nonstandard notion of chance. The second is a probabilistic* constraining law.
Such laws impose relative frequency and randomness constraints that every
physically possible world must satisfy. While each notion has virtues, we argue
that the latter has advantages over the former. It supports a unified governing
account of non-Humean laws and provides independently motivated solutions to
issues in the Humean best-system account. On both notions, we have a much
tighter connection between probabilistic laws and their corresponding sets of
possible worlds. Certain histories permitted by traditional probabilistic laws
are ruled out as physically impossible. As a result, such laws avoid one
variety of empirical underdetermination, but the approach reveals other
varieties of underdetermination that are typically overlooked.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/physics/1/au:+Barrett_J/0/1/0/all/0/1">Jeffrey A. Barrett</a>, <a href="http://arxiv.org/find/physics/1/au:+Chen_E/0/1/0/all/0/1">Eddy Keming Chen</a></p><p>We consider two ways one might use algorithmic randomness to characterize a
probabilistic law. The first is a generative chance* law. Such laws involve a
nonstandard notion of chance. The second is a probabilistic* constraining law.
Such laws impose relative frequency and randomness constraints that every
physically possible world must satisfy. While each notion has virtues, we argue
that the latter has advantages over the former. It supports a unified governing
account of non-Humean laws and provides independently motivated solutions to
issues in the Humean best-system account. On both notions, we have a much
tighter connection between probabilistic laws and their corresponding sets of
possible worlds. Certain histories permitted by traditional probabilistic laws
are ruled out as physically impossible. As a result, such laws avoid one
variety of empirical underdetermination, but the approach reveals other
varieties of underdetermination that are typically overlooked.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01224'>Enumeration and Unimodular Equivalence of Empty Delta-Modular Simplices</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: D. Gribanov</p><p>Consider a class of simplices defined by systems $A x \leq b$ of linear
inequalities with $\Delta$-modular matrices. A matrix is called
$\Delta$-modular, if all its rank-order sub-determinants are bounded by
$\Delta$ in an absolute value. In our work we call a simplex $\Delta$-modular,
if it can be defined by a system $A x \leq b$ with a $\Delta$-modular matrix
$A$. And we call a simplex empty, if it contains no points with integer
coordinates. In literature, a simplex is called lattice-simplex, if all its
vertices have integer coordinates. And a lattice-simplex called empty, if it
contains no points with integer coordinates excluding its vertices.
</p>
<p>Recently, assuming that $\Delta$ is fixed, it was shown that the number of
$\Delta$-modular empty simplices modulo the unimodular equivalence relation is
bounded by a polynomial on dimension. We show that the analogous fact holds for
the class of $\Delta$-modular empty lattice-simplices. As the main result,
assuming again that the value of the parameter $\Delta$ is fixed, we show that
all unimodular equivalence classes of simplices of the both types can be
enumerated by a polynomial-time algorithm. As the secondary result, we show the
existence of a polynomial-time algorithm for the problem to check the
unimodular equivalence relation for a given pair of $\Delta$-modular, not
necessarily empty, simplices.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gribanov_D/0/1/0/all/0/1">D. Gribanov</a></p><p>Consider a class of simplices defined by systems $A x \leq b$ of linear
inequalities with $\Delta$-modular matrices. A matrix is called
$\Delta$-modular, if all its rank-order sub-determinants are bounded by
$\Delta$ in an absolute value. In our work we call a simplex $\Delta$-modular,
if it can be defined by a system $A x \leq b$ with a $\Delta$-modular matrix
$A$. And we call a simplex empty, if it contains no points with integer
coordinates. In literature, a simplex is called lattice-simplex, if all its
vertices have integer coordinates. And a lattice-simplex called empty, if it
contains no points with integer coordinates excluding its vertices.
</p>
<p>Recently, assuming that $\Delta$ is fixed, it was shown that the number of
$\Delta$-modular empty simplices modulo the unimodular equivalence relation is
bounded by a polynomial on dimension. We show that the analogous fact holds for
the class of $\Delta$-modular empty lattice-simplices. As the main result,
assuming again that the value of the parameter $\Delta$ is fixed, we show that
all unimodular equivalence classes of simplices of the both types can be
enumerated by a polynomial-time algorithm. As the secondary result, we show the
existence of a polynomial-time algorithm for the problem to check the
unimodular equivalence relation for a given pair of $\Delta$-modular, not
necessarily empty, simplices.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00878'>Interactive Exploration of the Temporal $\alpha$-Shape</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Felix Weitbrecht</p><p>An interesting subcomplex of the Delaunay triangulation are $\alpha$-shapes,
which give a more detailed representation of the shape of point sets than the
convex hull. We extend an algorithm which computes all Delaunay simplices over
all time windows to also compute the temporal $\alpha$-shape, which is a
description of all $\alpha$-shapes over all time windows and all values of
$\alpha$, in output-sensitive linear time. We present an interactive demo
application based on a fast query data structure. Experimental results show
that our algorithm is practical and can be used on real-world data sets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Weitbrecht_F/0/1/0/all/0/1">Felix Weitbrecht</a></p><p>An interesting subcomplex of the Delaunay triangulation are $\alpha$-shapes,
which give a more detailed representation of the shape of point sets than the
convex hull. We extend an algorithm which computes all Delaunay simplices over
all time windows to also compute the temporal $\alpha$-shape, which is a
description of all $\alpha$-shapes over all time windows and all values of
$\alpha$, in output-sensitive linear time. We present an interactive demo
application based on a fast query data structure. Experimental results show
that our algorithm is practical and can be used on real-world data sets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01096'>Geometric Spanning Trees Minimizing the Wiener Index</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: A. Karim Abu-Affash, Paz Carmi, Ori Luwisch, Joseph S. B. Mitchell</p><p>The Wiener index of a network, introduced by the chemist Harry Wiener, is the
sum of distances between all pairs of nodes in the network. This index,
originally used in chemical graph representations of the non-hydrogen atoms of
a molecule, is considered to be a fundamental and useful network descriptor. We
study the problem of constructing geometric networks on point sets in Euclidean
space that minimize the Wiener index: given a set $P$ of $n$ points in
$\mathbb{R}^d$, the goal is to construct a network, spanning $P$ and satisfying
certain constraints, that minimizes the Wiener index among the allowable class
of spanning networks.
</p>
<p>In this work, we focus mainly on spanning networks that are trees and we
focus on problems in the plane ($d=2$). We show that any spanning tree that
minimizes the Wiener index has non-crossing edges in the plane. Then, we use
this fact to devise an $O(n^4)$-time algorithm that constructs a spanning tree
of minimum Wiener index for points in convex position. We also prove that the
problem of computing a spanning tree on $P$ whose Wiener index is at most $W$,
while having total (Euclidean) weight at most $B$, is NP-hard.
</p>
<p>Computing a tree that minimizes the Wiener index has been studied in the area
of communication networks, where it is known as the optimum communication
spanning tree problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Abu_Affash_A/0/1/0/all/0/1">A. Karim Abu-Affash</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmi_P/0/1/0/all/0/1">Paz Carmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Luwisch_O/0/1/0/all/0/1">Ori Luwisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_J/0/1/0/all/0/1">Joseph S. B. Mitchell</a></p><p>The Wiener index of a network, introduced by the chemist Harry Wiener, is the
sum of distances between all pairs of nodes in the network. This index,
originally used in chemical graph representations of the non-hydrogen atoms of
a molecule, is considered to be a fundamental and useful network descriptor. We
study the problem of constructing geometric networks on point sets in Euclidean
space that minimize the Wiener index: given a set $P$ of $n$ points in
$\mathbb{R}^d$, the goal is to construct a network, spanning $P$ and satisfying
certain constraints, that minimizes the Wiener index among the allowable class
of spanning networks.
</p>
<p>In this work, we focus mainly on spanning networks that are trees and we
focus on problems in the plane ($d=2$). We show that any spanning tree that
minimizes the Wiener index has non-crossing edges in the plane. Then, we use
this fact to devise an $O(n^4)$-time algorithm that constructs a spanning tree
of minimum Wiener index for points in convex position. We also prove that the
problem of computing a spanning tree on $P$ whose Wiener index is at most $W$,
while having total (Euclidean) weight at most $B$, is NP-hard.
</p>
<p>Computing a tree that minimizes the Wiener index has been studied in the area
of communication networks, where it is known as the optimum communication
spanning tree problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01400'>Coresets for Clustering in Geometric Intersection Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sayan Bandyapadhyay, Fedor V. Fomin, Tanmay Inamdar</p><p>Designing coresets--small-space sketches of the data preserving cost of the
solutions within $(1\pm \epsilon)$-approximate factor--is an important research
direction in the study of center-based $k$-clustering problems, such as
$k$-means or $k$-median. Feldman and Langberg [STOC'11] have shown that for
$k$-clustering of $n$ points in general metrics, it is possible to obtain
coresets whose size depends logarithmically in $n$. Moreover, such a dependency
in $n$ is inevitable in general metrics. A significant amount of recent work in
the area is devoted to obtaining coresests whose sizes are independent of $n$
(i.e., ``small'' coresets) for special metrics, like $d$-dimensional Euclidean
spaces, doubling metrics, metrics of graphs of bounded treewidth, or those
excluding a fixed minor.
</p>
<p>In this paper, we provide the first constructions of small coresets for
$k$-clustering in the metrics induced by geometric intersection graphs, such as
Euclidean-weighted Unit Disk/Square Graphs. These constructions follow from a
general theorem that identifies two canonical properties of a graph metric
sufficient for obtaining small coresets. The proof of our theorem builds on the
recent work of Cohen-Addad, Saulpic, and Schwiegelshohn [STOC '21], which
ensures small-sized coresets conditioned on the existence of an interesting set
of centers, called ``centroid set''. The main technical contribution of our
work is the proof of the existence of such a small-sized centroid set for
graphs that satisfy the two canonical geometric properties. The new coreset
construction helps to design the first $(1+\epsilon)$-approximation for
center-based clustering problems in UDGs and USGs, that is fixed-parameter
tractable in $k$ and $\epsilon$ (FPT-AS).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bandyapadhyay_S/0/1/0/all/0/1">Sayan Bandyapadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1">Fedor V. Fomin</a>, <a href="http://arxiv.org/find/cs/1/au:+Inamdar_T/0/1/0/all/0/1">Tanmay Inamdar</a></p><p>Designing coresets--small-space sketches of the data preserving cost of the
solutions within $(1\pm \epsilon)$-approximate factor--is an important research
direction in the study of center-based $k$-clustering problems, such as
$k$-means or $k$-median. Feldman and Langberg [STOC'11] have shown that for
$k$-clustering of $n$ points in general metrics, it is possible to obtain
coresets whose size depends logarithmically in $n$. Moreover, such a dependency
in $n$ is inevitable in general metrics. A significant amount of recent work in
the area is devoted to obtaining coresests whose sizes are independent of $n$
(i.e., ``small'' coresets) for special metrics, like $d$-dimensional Euclidean
spaces, doubling metrics, metrics of graphs of bounded treewidth, or those
excluding a fixed minor.
</p>
<p>In this paper, we provide the first constructions of small coresets for
$k$-clustering in the metrics induced by geometric intersection graphs, such as
Euclidean-weighted Unit Disk/Square Graphs. These constructions follow from a
general theorem that identifies two canonical properties of a graph metric
sufficient for obtaining small coresets. The proof of our theorem builds on the
recent work of Cohen-Addad, Saulpic, and Schwiegelshohn [STOC '21], which
ensures small-sized coresets conditioned on the existence of an interesting set
of centers, called ``centroid set''. The main technical contribution of our
work is the proof of the existence of such a small-sized centroid set for
graphs that satisfy the two canonical geometric properties. The new coreset
construction helps to design the first $(1+\epsilon)$-approximation for
center-based clustering problems in UDGs and USGs, that is fixed-parameter
tractable in $k$ and $\epsilon$ (FPT-AS).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00791'>Scarf's algorithm and stable marriages</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuri Faenza, Chengyue He, Jay Sethuraman</p><p>Scarf's algorithm gives a pivoting procedure to find a special vertex -- a
dominating vertex -- in down-monotone polytopes. This paper studies the
behavior of Scarf's algorithm when employed to find stable matchings in
bipartite graphs. First, it proves that Scarf's algorithm can be implemented to
run in polynomial time, showing the first positive result on its runtime in
significant settings. Second, it shows an infinite family of instances where,
no matter the pivoting rule and runtime, Scarf's algorithm outputs a matching
from an exponentially small subset of all stable matchings, thus showing a
structural weakness of the approach.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Faenza_Y/0/1/0/all/0/1">Yuri Faenza</a>, <a href="http://arxiv.org/find/math/1/au:+He_C/0/1/0/all/0/1">Chengyue He</a>, <a href="http://arxiv.org/find/math/1/au:+Sethuraman_J/0/1/0/all/0/1">Jay Sethuraman</a></p><p>Scarf's algorithm gives a pivoting procedure to find a special vertex -- a
dominating vertex -- in down-monotone polytopes. This paper studies the
behavior of Scarf's algorithm when employed to find stable matchings in
bipartite graphs. First, it proves that Scarf's algorithm can be implemented to
run in polynomial time, showing the first positive result on its runtime in
significant settings. Second, it shows an infinite family of instances where,
no matter the pivoting rule and runtime, Scarf's algorithm outputs a matching
from an exponentially small subset of all stable matchings, thus showing a
structural weakness of the approach.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00811'>Parallel and Distributed Exact Single-Source Shortest Paths with Negative Edge Weights</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vikrant Ashvinkumar, Aaron Bernstein, Nairen Cao, Christoph Grunau, Bernhard Haeupler, Yonggang Jiang, Danupon Nanongkai, Hsin Hao Su</p><p>This paper presents parallel and distributed algorithms for single-source
shortest paths when edges can have negative weights (negative-weight SSSP). We
show a framework that reduces negative-weight SSSP in either setting to
$n^{o(1)}$ calls to any SSSP algorithm that works with a virtual source. More
specifically, for a graph with $m$ edges, $n$ vertices, undirected hop-diameter
$D$, and polynomially bounded integer edge weights, we show randomized
algorithms for negative-weight SSSP with (i) $W_{SSSP}(m,n)n^{o(1)}$ work and
$S_{SSSP}(m,n)n^{o(1)}$ span, given access to an SSSP algorithm with
$W_{SSSP}(m,n)$ work and $S_{SSSP}(m,n)$ span in the parallel model, (ii)
$T_{SSSP}(n,D)n^{o(1)}$, given access to an SSSP algorithm that takes
$T_{SSSP}(n,D)$ rounds in $\mathsf{CONGEST}$. This work builds off the recent
result of [Bernstein, Nanongkai, Wulff-Nilsen, FOCS'22], which gives a
near-linear time algorithm for negative-weight SSSP in the sequential setting.
</p>
<p>Using current state-of-the-art SSSP algorithms yields randomized algorithms
for negative-weight SSSP with (i) $m^{1+o(1)}$ work and $n^{1/2+o(1)}$ span in
the parallel model, (ii) $(n^{2/5}D^{2/5} + \sqrt{n} + D)n^{o(1)}$ rounds in
$\mathsf{CONGEST}$.
</p>
<p>Our main technical contribution is an efficient reduction for computing a
low-diameter decomposition (LDD) of directed graphs to computations of SSSP
with a virtual source. Efficiently computing an LDD has heretofore only been
known for undirected graphs in both the parallel and distributed models. The
LDD is a crucial step of the algorithm in [Bernstein, Nanongkai, Wulff-Nilsen,
FOCS'22], and we think that its applications to other problems in parallel and
distributed models are far from being exhausted.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ashvinkumar_V/0/1/0/all/0/1">Vikrant Ashvinkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernstein_A/0/1/0/all/0/1">Aaron Bernstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_N/0/1/0/all/0/1">Nairen Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1">Christoph Grunau</a>, <a href="http://arxiv.org/find/cs/1/au:+Haeupler_B/0/1/0/all/0/1">Bernhard Haeupler</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yonggang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nanongkai_D/0/1/0/all/0/1">Danupon Nanongkai</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hsin Hao Su</a></p><p>This paper presents parallel and distributed algorithms for single-source
shortest paths when edges can have negative weights (negative-weight SSSP). We
show a framework that reduces negative-weight SSSP in either setting to
$n^{o(1)}$ calls to any SSSP algorithm that works with a virtual source. More
specifically, for a graph with $m$ edges, $n$ vertices, undirected hop-diameter
$D$, and polynomially bounded integer edge weights, we show randomized
algorithms for negative-weight SSSP with (i) $W_{SSSP}(m,n)n^{o(1)}$ work and
$S_{SSSP}(m,n)n^{o(1)}$ span, given access to an SSSP algorithm with
$W_{SSSP}(m,n)$ work and $S_{SSSP}(m,n)$ span in the parallel model, (ii)
$T_{SSSP}(n,D)n^{o(1)}$, given access to an SSSP algorithm that takes
$T_{SSSP}(n,D)$ rounds in $\mathsf{CONGEST}$. This work builds off the recent
result of [Bernstein, Nanongkai, Wulff-Nilsen, FOCS'22], which gives a
near-linear time algorithm for negative-weight SSSP in the sequential setting.
</p>
<p>Using current state-of-the-art SSSP algorithms yields randomized algorithms
for negative-weight SSSP with (i) $m^{1+o(1)}$ work and $n^{1/2+o(1)}$ span in
the parallel model, (ii) $(n^{2/5}D^{2/5} + \sqrt{n} + D)n^{o(1)}$ rounds in
$\mathsf{CONGEST}$.
</p>
<p>Our main technical contribution is an efficient reduction for computing a
low-diameter decomposition (LDD) of directed graphs to computations of SSSP
with a virtual source. Efficiently computing an LDD has heretofore only been
known for undirected graphs in both the parallel and distributed models. The
LDD is a crucial step of the algorithm in [Bernstein, Nanongkai, Wulff-Nilsen,
FOCS'22], and we think that its applications to other problems in parallel and
distributed models are far from being exhausted.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00837'>Predictive Flows for Faster Ford-Fulkerson</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sami Davies, Benjamin Moseley, Sergei Vassilvitskii, Yuyan Wang</p><p>Recent work has shown that leveraging learned predictions can improve the
running time of algorithms for bipartite matching and similar combinatorial
problems. In this work, we build on this idea to improve the performance of the
widely used Ford-Fulkerson algorithm for computing maximum flows by seeding
Ford-Fulkerson with predicted flows. Our proposed method offers strong
theoretical performance in terms of the quality of the prediction. We then
consider image segmentation, a common use-case of flows in computer vision, and
complement our theoretical analysis with strong empirical results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Davies_S/0/1/0/all/0/1">Sami Davies</a>, <a href="http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1">Benjamin Moseley</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilvitskii_S/0/1/0/all/0/1">Sergei Vassilvitskii</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyan Wang</a></p><p>Recent work has shown that leveraging learned predictions can improve the
running time of algorithms for bipartite matching and similar combinatorial
problems. In this work, we build on this idea to improve the performance of the
widely used Ford-Fulkerson algorithm for computing maximum flows by seeding
Ford-Fulkerson with predicted flows. Our proposed method offers strong
theoretical performance in terms of the quality of the prediction. We then
consider image segmentation, a common use-case of flows in computer vision, and
complement our theoretical analysis with strong empirical results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01078'>Pandora's Problem with Combinatorial Cost</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ben Berger, Tomer Ezra, Michal Feldman, Federico Fusco</p><p>Pandora's problem is a fundamental model in economics that studies optimal
search strategies under costly inspection. In this paper we initiate the study
of Pandora's problem with combinatorial costs, capturing many real-life
scenarios where search cost is non-additive. Weitzman's celebrated algorithm
[1979] establishes the remarkable result that, for additive costs, the optimal
search strategy is non-adaptive and computationally feasible.
</p>
<p>We inquire to which extent this structural and computational simplicity
extends beyond additive cost functions. Our main result is that the class of
submodular cost functions admits an optimal strategy that follows a fixed,
non-adaptive order, thus preserving the structural simplicity of additive cost
functions. In contrast, for the more general class of subadditive (or even XOS)
cost functions, the optimal strategy may already need to determine the search
order adaptively. On the computational side, obtaining any approximation to the
optimal utility requires super polynomially many queries to the cost function,
even for a strict subclass of submodular cost functions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berger_B/0/1/0/all/0/1">Ben Berger</a>, <a href="http://arxiv.org/find/cs/1/au:+Ezra_T/0/1/0/all/0/1">Tomer Ezra</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldman_M/0/1/0/all/0/1">Michal Feldman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1">Federico Fusco</a></p><p>Pandora's problem is a fundamental model in economics that studies optimal
search strategies under costly inspection. In this paper we initiate the study
of Pandora's problem with combinatorial costs, capturing many real-life
scenarios where search cost is non-additive. Weitzman's celebrated algorithm
[1979] establishes the remarkable result that, for additive costs, the optimal
search strategy is non-adaptive and computationally feasible.
</p>
<p>We inquire to which extent this structural and computational simplicity
extends beyond additive cost functions. Our main result is that the class of
submodular cost functions admits an optimal strategy that follows a fixed,
non-adaptive order, thus preserving the structural simplicity of additive cost
functions. In contrast, for the more general class of subadditive (or even XOS)
cost functions, the optimal strategy may already need to determine the search
order adaptively. On the computational side, obtaining any approximation to the
optimal utility requires super polynomially many queries to the cost function,
even for a strict subclass of submodular cost functions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01188'>Quantum Channel Certification with Incoherent Strategies</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Omar Fawzi, Nicolas Flammarion, Aur&#xe9;lien Garivier, Aadil Oufkir</p><p>In the problem of quantum channel certification, we have black box access to
a quantum process and would like to decide if this process matches some
predefined specification or is $\varepsilon$-far from this specification. The
objective is to achieve this task while minimizing the number of times the
black box is used.
</p>
<p>Here, we focus on optimal incoherent strategies for two relevant extreme
cases of channel certification. The first one is when the predefined
specification is a unitary channel, e.g., a gate in a quantum circuit.
</p>
<p>In this case, we show that testing whether the black box is described by a
fixed unitary operator in dimension $d$ or $\varepsilon$-far from it in the
trace norm requires $\Theta(d/\varepsilon^2)$ uses of the black box. The second
setting we consider is when the predefined specification is a completely
depolarizing channel with input dimension $d_{\text{in}}$ and output dimension
$d_{\text{out}}$.
</p>
<p>In this case, we prove that, in the non-adaptive setting,
$\tilde{\Theta}(d_{\text{in}}^2d_{\text{out}}^{1.5}/\varepsilon^2)$ uses of the
channel are necessary and sufficient to verify whether it is equal to the
depolarizing channel or $\varepsilon$-far from it in the diamond norm.
</p>
<p>Finally, we prove a lower bound of
$\Omega(d_{\text{in}}^2d_{\text{out}}/\varepsilon^2)$ for this problem in the
adaptive setting. Note that the special case $d_{\text{in}} = 1$ corresponds to
the well-studied quantum state certification problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Fawzi_O/0/1/0/all/0/1">Omar Fawzi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Flammarion_N/0/1/0/all/0/1">Nicolas Flammarion</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Garivier_A/0/1/0/all/0/1">Aur&#xe9;lien Garivier</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Oufkir_A/0/1/0/all/0/1">Aadil Oufkir</a></p><p>In the problem of quantum channel certification, we have black box access to
a quantum process and would like to decide if this process matches some
predefined specification or is $\varepsilon$-far from this specification. The
objective is to achieve this task while minimizing the number of times the
black box is used.
</p>
<p>Here, we focus on optimal incoherent strategies for two relevant extreme
cases of channel certification. The first one is when the predefined
specification is a unitary channel, e.g., a gate in a quantum circuit.
</p>
<p>In this case, we show that testing whether the black box is described by a
fixed unitary operator in dimension $d$ or $\varepsilon$-far from it in the
trace norm requires $\Theta(d/\varepsilon^2)$ uses of the black box. The second
setting we consider is when the predefined specification is a completely
depolarizing channel with input dimension $d_{\text{in}}$ and output dimension
$d_{\text{out}}$.
</p>
<p>In this case, we prove that, in the non-adaptive setting,
$\tilde{\Theta}(d_{\text{in}}^2d_{\text{out}}^{1.5}/\varepsilon^2)$ uses of the
channel are necessary and sufficient to verify whether it is equal to the
depolarizing channel or $\varepsilon$-far from it in the diamond norm.
</p>
<p>Finally, we prove a lower bound of
$\Omega(d_{\text{in}}^2d_{\text{out}}/\varepsilon^2)$ for this problem in the
adaptive setting. Note that the special case $d_{\text{in}} = 1$ corresponds to
the well-studied quantum state certification problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01256'>Choosing Public Datasets for Private Machine Learning via Gradient Subspace Distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xin Gu, Gautam Kamath, Zhiwei Steven Wu</p><p>Differentially private stochastic gradient descent privatizes model training
by injecting noise into each iteration, where the noise magnitude increases
with the number of model parameters. Recent works suggest that we can reduce
the noise by leveraging public data for private machine learning, by projecting
gradients onto a subspace prescribed by the public data. However, given a
choice of public datasets, it is not a priori clear which one may be most
appropriate for the private task. We give an algorithm for selecting a public
dataset by measuring a low-dimensional subspace distance between gradients of
the public and private examples. We provide theoretical analysis demonstrating
that the excess risk scales with this subspace distance. This distance is easy
to compute and robust to modifications in the setting. Empirical evaluation
shows that trained model accuracy is monotone in this distance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Gu_X/0/1/0/all/0/1">Xin Gu</a>, <a href="http://arxiv.org/find/stat/1/au:+Kamath_G/0/1/0/all/0/1">Gautam Kamath</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_Z/0/1/0/all/0/1">Zhiwei Steven Wu</a></p><p>Differentially private stochastic gradient descent privatizes model training
by injecting noise into each iteration, where the noise magnitude increases
with the number of model parameters. Recent works suggest that we can reduce
the noise by leveraging public data for private machine learning, by projecting
gradients onto a subspace prescribed by the public data. However, given a
choice of public datasets, it is not a priori clear which one may be most
appropriate for the private task. We give an algorithm for selecting a public
dataset by measuring a low-dimensional subspace distance between gradients of
the public and private examples. We provide theoretical analysis demonstrating
that the excess risk scales with this subspace distance. This distance is easy
to compute and robust to modifications in the setting. Empirical evaluation
shows that trained model accuracy is monotone in this distance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01290'>Solving Distance-constrained Labeling Problems for Small Diameter Graphs via TSP</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tesshu Hanaka, Hirotaka Ono, Kosuke Sugiyama</p><p>In this paper, we give a simple polynomial-time reduction of {L(p)-Labeling}
on graphs with a small diameter to {Metric (Path) TSP}, which enables us to use
numerous results on {(Metric) TSP}. On the practical side, we can utilize
various high-performance heuristics for TSP, such as Concordo and LKH, to solve
our problem. On the theoretical side, we can see that the problem for any p
under this framework is 1.5-approximable, and it can be solved by the Held-Karp
algorithm in O(2^n n^2) time, where n is the number of vertices, and so on.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hanaka_T/0/1/0/all/0/1">Tesshu Hanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Ono_H/0/1/0/all/0/1">Hirotaka Ono</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_K/0/1/0/all/0/1">Kosuke Sugiyama</a></p><p>In this paper, we give a simple polynomial-time reduction of {L(p)-Labeling}
on graphs with a small diameter to {Metric (Path) TSP}, which enables us to use
numerous results on {(Metric) TSP}. On the practical side, we can utilize
various high-performance heuristics for TSP, such as Concordo and LKH, to solve
our problem. On the theoretical side, we can see that the problem for any p
under this framework is 1.5-approximable, and it can be solved by the Held-Karp
algorithm in O(2^n n^2) time, where n is the number of vertices, and so on.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01414'>Improved Algorithms for Monotone Moldable Job Scheduling using Compression and Convolution</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kilian Grage, Klaus Jansen, Felix Ohnesorge</p><p>In the moldable job scheduling problem one has to assign a set of $n$ jobs to
$m$ machines, in order to minimize the time it takes to process all jobs. Each
job is moldable, so it can be assigned not only to one but any number of the
equal machines. We assume that the work of each job is monotone and that jobs
can be placed non-contiguously. In this work we present a $(\frac 3 2 +
\epsilon)$-approximation algorithm with a worst-case runtime of ${O(n
\log^2(\frac 1 \epsilon + \frac {\log (\epsilon m)} \epsilon) +
\frac{n}{\epsilon} \log(\frac 1 \epsilon) {\log (\epsilon m)})}$ when $m\le
16n$. This is an improvement over the best known algorithm of the same quality
by a factor of $\frac 1 \epsilon$ and several logarithmic dependencies. We
complement this result with an improved FPTAS with running time $O(n
\log^2(\frac 1 \epsilon + \frac {\log (\epsilon m)} \epsilon))$ for instances
with many machines $m&gt; 8\frac n \epsilon$. This yields a $\frac 3
2$-approximation with runtime $O(n \log^2(\log m))$ when $m&gt;16n$.
</p>
<p>We achieve these results through one new core observation: In an
approximation setting one does not need to consider all $m$ possible allotments
for each job. We will show that we can reduce the number of relevant allotments
for each job from $m$ to $O(\frac 1 \epsilon + \frac {\log (\epsilon
m)}{\epsilon})$. Using this observation immediately yields the improved FPTAS.
For the other result we use a reduction to the knapsack problem first
introduced by Mouni\'e, Rapine and Trystram. We use the reduced number of
machines to give a new elaborate rounding scheme and define a modified version
of this this knapsack instance. This in turn allows for the application of a
convolution based algorithm by Axiotis and Tzamos. We further back our
theoretical results through a practical implementation and compare our
algorithm to the previously known best result.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grage_K/0/1/0/all/0/1">Kilian Grage</a>, <a href="http://arxiv.org/find/cs/1/au:+Jansen_K/0/1/0/all/0/1">Klaus Jansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohnesorge_F/0/1/0/all/0/1">Felix Ohnesorge</a></p><p>In the moldable job scheduling problem one has to assign a set of $n$ jobs to
$m$ machines, in order to minimize the time it takes to process all jobs. Each
job is moldable, so it can be assigned not only to one but any number of the
equal machines. We assume that the work of each job is monotone and that jobs
can be placed non-contiguously. In this work we present a $(\frac 3 2 +
\epsilon)$-approximation algorithm with a worst-case runtime of ${O(n
\log^2(\frac 1 \epsilon + \frac {\log (\epsilon m)} \epsilon) +
\frac{n}{\epsilon} \log(\frac 1 \epsilon) {\log (\epsilon m)})}$ when $m\le
16n$. This is an improvement over the best known algorithm of the same quality
by a factor of $\frac 1 \epsilon$ and several logarithmic dependencies. We
complement this result with an improved FPTAS with running time $O(n
\log^2(\frac 1 \epsilon + \frac {\log (\epsilon m)} \epsilon))$ for instances
with many machines $m&gt; 8\frac n \epsilon$. This yields a $\frac 3
2$-approximation with runtime $O(n \log^2(\log m))$ when $m&gt;16n$.
</p>
<p>We achieve these results through one new core observation: In an
approximation setting one does not need to consider all $m$ possible allotments
for each job. We will show that we can reduce the number of relevant allotments
for each job from $m$ to $O(\frac 1 \epsilon + \frac {\log (\epsilon
m)}{\epsilon})$. Using this observation immediately yields the improved FPTAS.
For the other result we use a reduction to the knapsack problem first
introduced by Mouni\'e, Rapine and Trystram. We use the reduced number of
machines to give a new elaborate rounding scheme and define a modified version
of this this knapsack instance. This in turn allows for the application of a
convolution based algorithm by Axiotis and Tzamos. We further back our
theoretical results through a practical implementation and compare our
algorithm to the previously known best result.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01417'>Distributed Deep Multilevel Graph Partitioning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Peter Sanders, Daniel Seemaier</p><p>We describe the engineering of the distributed-memory multilevel graph
partitioner dKaMinPar. It scales to (at least) 8192 cores while achieving
partitioning quality comparable to widely used sequential and shared-memory
graph partitioners. In comparison, previous distributed graph partitioners
scale only in more restricted scenarios and often induce a considerable quality
penalty compared to non-distributed partitioners. When partitioning into a
large number of blocks, they even produce infeasible solution that violate the
balancing constraint. dKaMinPar achieves its robustness by a scalable
distributed implementation of the deep-multilevel scheme for graph
partitioning. Crucially, this includes new algorithms for balancing during
refinement and coarsening.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sanders_P/0/1/0/all/0/1">Peter Sanders</a>, <a href="http://arxiv.org/find/cs/1/au:+Seemaier_D/0/1/0/all/0/1">Daniel Seemaier</a></p><p>We describe the engineering of the distributed-memory multilevel graph
partitioner dKaMinPar. It scales to (at least) 8192 cores while achieving
partitioning quality comparable to widely used sequential and shared-memory
graph partitioners. In comparison, previous distributed graph partitioners
scale only in more restricted scenarios and often induce a considerable quality
penalty compared to non-distributed partitioners. When partitioning into a
large number of blocks, they even produce infeasible solution that violate the
balancing constraint. dKaMinPar achieves its robustness by a scalable
distributed implementation of the deep-multilevel scheme for graph
partitioning. Crucially, this includes new algorithms for balancing during
refinement and coarsening.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01453'>Improved Space Bounds for Learning with Experts</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anders Aamand, Justin Y. Chen, Huy L&#xea; Nguyen, Sandeep Silwal</p><p>We give improved tradeoffs between space and regret for the online learning
with expert advice problem over $T$ days with $n$ experts. Given a space budget
of $n^{\delta}$ for $\delta \in (0,1)$, we provide an algorithm achieving
regret $\tilde{O}(n^2 T^{1/(1+\delta)})$, improving upon the regret bound
$\tilde{O}(n^2 T^{2/(2+\delta)})$ in the recent work of [PZ23]. The improvement
is particularly salient in the regime $\delta \rightarrow 1$ where the regret
of our algorithm approaches $\tilde{O}_n(\sqrt{T})$, matching the $T$
dependence in the standard online setting without space restrictions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aamand_A/0/1/0/all/0/1">Anders Aamand</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Justin Y. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huy L&#xea; Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1">Sandeep Silwal</a></p><p>We give improved tradeoffs between space and regret for the online learning
with expert advice problem over $T$ days with $n$ experts. Given a space budget
of $n^{\delta}$ for $\delta \in (0,1)$, we provide an algorithm achieving
regret $\tilde{O}(n^2 T^{1/(1+\delta)})$, improving upon the regret bound
$\tilde{O}(n^2 T^{2/(2+\delta)})$ in the recent work of [PZ23]. The improvement
is particularly salient in the regime $\delta \rightarrow 1$ where the regret
of our algorithm approaches $\tilde{O}_n(\sqrt{T})$, matching the $T$
dependence in the standard online setting without space restrictions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01478'>Faster exact and approximation algorithms for packing and covering matroids via push-relabel</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kent Quanrud</p><p>Matroids are a fundamental object of study in combinatorial optimization.
Three closely related and important problems involving matroids are maximizing
the size of the union of $k$ independent sets (that is, $k$-fold matroid
union), computing $k$ disjoint bases (a.k.a. matroid base packing), and
covering the elements by $k$ bases (a.k.a. matroid base covering). These
problems generalize naturally to integral and real-valued capacities on the
elements. This work develops faster exact and/or approximation problems for
these and some other closely related problems such as optimal reinforcement and
matroid membership. We obtain improved running times both for general matroids
in the independence oracle model and for the graphic matroid. The main thrust
of our improvements comes from developing a faster and unifying push-relabel
algorithm for the integer-capacitated versions of these problems, building on
previous work by Frank and Mikl\'os [FM12]. We then build on this algorithm in
two directions. First we develop a faster augmenting path subroutine for
$k$-fold matroid union that, when appended to an approximation version of the
push-relabel algorithm, gives a faster exact algorithm for some parameters of
$k$. In particular we obtain a subquadratic-query running time in the
uncapacitated setting for the three basic problems listed above. We also obtain
faster approximation algorithms for these problems with real-valued capacities
by reducing to small integral capacities via randomized rounding. To this end,
we develop a new randomized rounding technique for base covering problems in
matroids that may also be of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Quanrud_K/0/1/0/all/0/1">Kent Quanrud</a></p><p>Matroids are a fundamental object of study in combinatorial optimization.
Three closely related and important problems involving matroids are maximizing
the size of the union of $k$ independent sets (that is, $k$-fold matroid
union), computing $k$ disjoint bases (a.k.a. matroid base packing), and
covering the elements by $k$ bases (a.k.a. matroid base covering). These
problems generalize naturally to integral and real-valued capacities on the
elements. This work develops faster exact and/or approximation problems for
these and some other closely related problems such as optimal reinforcement and
matroid membership. We obtain improved running times both for general matroids
in the independence oracle model and for the graphic matroid. The main thrust
of our improvements comes from developing a faster and unifying push-relabel
algorithm for the integer-capacitated versions of these problems, building on
previous work by Frank and Mikl\'os [FM12]. We then build on this algorithm in
two directions. First we develop a faster augmenting path subroutine for
$k$-fold matroid union that, when appended to an approximation version of the
push-relabel algorithm, gives a faster exact algorithm for some parameters of
$k$. In particular we obtain a subquadratic-query running time in the
uncapacitated setting for the three basic problems listed above. We also obtain
faster approximation algorithms for these problems with real-valued capacities
by reducing to small integral capacities via randomized rounding. To this end,
we develop a new randomized rounding technique for base covering problems in
matroids that may also be of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-03T01:30:00Z">Friday, March 03 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, March 02
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/020'>TR23-020 |  Certified Randomness from Quantum Supremacy | 

	Scott Aaronson, 

	Shih-Han Hung</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We propose an application for near-term quantum devices: namely, generating cryptographically certified random bits, to use (for example) in proof-of-stake cryptocurrencies. Our protocol repurposes the existing &quot;quantum supremacy&quot; experiments, based on random circuit sampling, that Google and USTC have successfully carried out starting in 2019. We show that, whenever the outputs of these experiments pass the now-standard Linear Cross-Entropy Benchmark (LXEB), under plausible hardness assumptions they necessarily contain $\Omega(n)$ min-entropy, where $n$ is the number of qubits. To achieve a net gain in randomness, we use a small random seed to produce pseudorandom challenge circuits. In response to the challenge circuits, the quantum computer generates output strings that, after verification, can then be fed into a randomness extractor to produce certified nearly-uniform bits---thereby &quot;bootstrapping&quot; from pseudorandomness to genuine randomness. We prove our protocol sound in two senses: (i) under a hardness assumption called Long List Quantum Supremacy Verification, which we justify in the random oracle model, and (ii) unconditionally in the random oracle model against an eavesdropper who could share arbitrary entanglement with the device. (Note that our protocol&#39;s output is unpredictable even to a computationally unbounded adversary who can see the random oracle.) Currently, the central drawback of our protocol is the exponential cost of verification, which in practice will limit its implementation to at most $n\sim 60$ qubits, a regime where attacks are expensive but not impossible. Modulo that drawback, our protocol appears to be the only practical application of quantum computing that both requires a QC and is physically realizable today.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We propose an application for near-term quantum devices: namely, generating cryptographically certified random bits, to use (for example) in proof-of-stake cryptocurrencies. Our protocol repurposes the existing &quot;quantum supremacy&quot; experiments, based on random circuit sampling, that Google and USTC have successfully carried out starting in 2019. We show that, whenever the outputs of these experiments pass the now-standard Linear Cross-Entropy Benchmark (LXEB), under plausible hardness assumptions they necessarily contain $\Omega(n)$ min-entropy, where $n$ is the number of qubits. To achieve a net gain in randomness, we use a small random seed to produce pseudorandom challenge circuits. In response to the challenge circuits, the quantum computer generates output strings that, after verification, can then be fed into a randomness extractor to produce certified nearly-uniform bits---thereby &quot;bootstrapping&quot; from pseudorandomness to genuine randomness. We prove our protocol sound in two senses: (i) under a hardness assumption called Long List Quantum Supremacy Verification, which we justify in the random oracle model, and (ii) unconditionally in the random oracle model against an eavesdropper who could share arbitrary entanglement with the device. (Note that our protocol&#39;s output is unpredictable even to a computationally unbounded adversary who can see the random oracle.) Currently, the central drawback of our protocol is the exponential cost of verification, which in practice will limit its implementation to at most $n\sim 60$ qubits, a regime where attacks are expensive but not impossible. Modulo that drawback, our protocol appears to be the only practical application of quantum computing that both requires a QC and is physically realizable today.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T23:10:26Z">Thursday, March 02 2023, 23:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/019'>TR23-019 |  Theory of Unconditional Pseudorandom Generators | 

	Pooya Hatami, 

	William Hoza</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This is a survey of unconditional *pseudorandom generators* (PRGs). A PRG uses a short, truly random seed to generate a long, &quot;pseudorandom&quot; sequence of bits. To be more specific, for each restricted model of computation (e.g., bounded-depth circuits or read-once branching programs), we would like to design a PRG that &quot;fools&quot; the model, meaning that every function computable in the model behaves approximately the same when we plug in pseudorandom bits from the PRG as it does when we plug in truly random bits. In this survey, we discuss four major paradigms for designing PRGs:

- We present several PRGs based on $k$-wise uniform generators, small-bias generators, and simple combinations thereof, including proofs of Viola&#39;s theorem on fooling low-degree polynomials (Comput. Complexity 2009) and Braverman&#39;s theorem on fooling $\mathbf{AC}^0$ circuits (J. ACM 2010).

- We present several PRGs based on &quot;recycling&quot; random bits to take advantage of communication bottlenecks, such as the Impagliazzo-Nisan-Wigderson generator (STOC 1994).

- We present connections between PRGs and computational hardness, including the Nisan-Wigderson framework for converting a hard Boolean function into a PRG (J. Comput. Syst. Sci. 1994).

- We present PRG frameworks based on random restrictions, including the &quot;polarizing random walks&quot; framework (Chattopadhyay, Hatami, Hosseini, and Lovett, Theory Comput. 2019).

We explain how to use these paradigms to construct PRGs that work *unconditionally*, with no unproven mathematical assumptions. The PRG constructions use ingredients such as finite field arithmetic, expander graphs, and randomness extractors. The analyses use techniques such as Fourier analysis, sandwiching approximators, and simplification-under-restrictions lemmas.
        
        </div>

        <div class='tr-article-summary'>
        
          
          This is a survey of unconditional *pseudorandom generators* (PRGs). A PRG uses a short, truly random seed to generate a long, &quot;pseudorandom&quot; sequence of bits. To be more specific, for each restricted model of computation (e.g., bounded-depth circuits or read-once branching programs), we would like to design a PRG that &quot;fools&quot; the model, meaning that every function computable in the model behaves approximately the same when we plug in pseudorandom bits from the PRG as it does when we plug in truly random bits. In this survey, we discuss four major paradigms for designing PRGs:

- We present several PRGs based on $k$-wise uniform generators, small-bias generators, and simple combinations thereof, including proofs of Viola&#39;s theorem on fooling low-degree polynomials (Comput. Complexity 2009) and Braverman&#39;s theorem on fooling $\mathbf{AC}^0$ circuits (J. ACM 2010).

- We present several PRGs based on &quot;recycling&quot; random bits to take advantage of communication bottlenecks, such as the Impagliazzo-Nisan-Wigderson generator (STOC 1994).

- We present connections between PRGs and computational hardness, including the Nisan-Wigderson framework for converting a hard Boolean function into a PRG (J. Comput. Syst. Sci. 1994).

- We present PRG frameworks based on random restrictions, including the &quot;polarizing random walks&quot; framework (Chattopadhyay, Hatami, Hosseini, and Lovett, Theory Comput. 2019).

We explain how to use these paradigms to construct PRGs that work *unconditionally*, with no unproven mathematical assumptions. The PRG constructions use ingredients such as finite field arithmetic, expander graphs, and randomness extractors. The analyses use techniques such as Fourier analysis, sandwiching approximators, and simplification-under-restrictions lemmas.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T23:09:23Z">Thursday, March 02 2023, 23:09</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/03/goodbye-dilbert.html'>Goodbye Dilbert</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Scott Adams, creator of Dilbert, had a racist rant in a video he posted last week. As a result most newspapers that carried the comic strip are dropping Dilbert, including our local Chicago Tribune. I fully support these moves. Much as I believe in separating the art from the artist, it's different when the artist is living and profiting from their art.</p><p>So we need to say to Dilbert, making the end of an era. Dilbert started in 1989 as a strip that captured the absurdities of the work place in an anonymous tech company, predating movies like Office Space and shows like Better Off Ted and&nbsp;Silicon Valley. I used Dilbert strips (with permission) in my book, namely&nbsp;this strip to introduce Kolmogorov complexity and this strip to describe my research area. Just call me Dan.</p><p>Farewell to Dilbert, Dogbert, Wally, Alice, Asok, the pointy-haired boss and the rest. I won't miss Scott Adams, but I will miss his creations.</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Scott Adams, creator of Dilbert, had a racist rant in a video he posted last week. As a result <a href="https://www.wsj.com/articles/newspapers-drop-dilbert-after-cartoonist-calls-black-americans-hate-group-21348ce1?st=mcxbs51a70by7i3&amp;reflink=desktopwebshare_permalink">most newspapers that carried the comic strip are dropping Dilbert</a>, including our local Chicago Tribune. I fully support these moves. Much as I believe in separating the art from the artist, it's different when the artist is living and profiting from their art.</p><p>So we need to say to Dilbert, making the end of an era. Dilbert started in 1989 as a strip that captured the absurdities of the work place in an anonymous tech company, predating movies like <a href="https://www.imdb.com/title/tt0151804/">Office Space</a> and shows like <a href="https://www.imdb.com/title/tt1235547/">Better Off Ted</a> and&nbsp;<a href="https://www.imdb.com/title/tt2575988/">Silicon Valley</a>. I used Dilbert strips (with permission) in my book, namely&nbsp;<a href="https://dilbert.com/strip/2001-10-25">this strip</a> to introduce Kolmogorov complexity and <a href="https://dilbert.com/strip/1997-12-22">this strip</a> to describe my research area. Just call me Dan.</p><p>Farewell to Dilbert, Dogbert, Wally, Alice, Asok, the pointy-haired boss and the rest. I won't miss Scott Adams, but I will miss his creations.</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T13:19:00Z">Thursday, March 02 2023, 13:19</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/018'>TR23-018 |  Memory-Sample Lower Bounds for Learning with Classical-Quantum Hybrid Memory | 

	Qipeng Liu, 

	Ran Raz, 

	Wei Zhan</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In a work by Raz (J. ACM and FOCS 16), it was proved that any algorithm for parity learning on $n$ bits requires either $\Omega(n^2)$ bits of classical memory or an exponential number (in~$n$) of random samples. A line of recent works continued that research direction and showed that for a large collection of classical learning tasks, either super-linear classical memory size or super-polynomially many samples are needed. All these works consider learning algorithms as classical branching programs, which perform classical computation within bounded memory.

However, these results do not capture all physical computational models, remarkably, quantum computers and the use of quantum memory. It leaves the possibility that a small piece of quantum memory could significantly reduce the need for classical memory or samples and thus completely change the nature of the classical learning task. Despite the recent research on the necessity of quantum memory for intrinsic quantum learning problems like shadow tomography and purity testing, the role of quantum memory in classical learning tasks remains obscure. 

In this work, we study classical learning tasks in the presence of quantum memory. We prove that any quantum algorithm with both, classical memory and quantum memory, for parity learning on $n$ bits, requires either $\Omega(n^2)$ bits of classical memory or $\Omega(n)$ bits of quantum  memory or an exponential number of samples. In other words, the memory-sample lower bound for parity learning remains qualitatively the same, even if the learning algorithm can use, in addition to the classical memory, a quantum memory of size $c n$ (for some constant $c&gt;0$).

Our result is more general and applies to many other classical learning tasks. Following previous works, we represent by the matrix $M: A \times X \to \{-1,1\}$ the following learning task. An unknown $x$ is sampled uniformly at random from a concept class $X$, and a learning algorithm tries to uncover $x$ by seeing streaming of random samples $(a_i, b_i = M(a_i, x))$ where for every $i$, $a_i\in A$ is chosen uniformly at random. Assume that $k,\ell,r$ are integers such that any submatrix of $M$ of at least $2^{-k}\cdot|A|$ rows and at least $2^{-\ell}\cdot|X|$ columns, has a bias of at most $2^{-r}$. We prove that any algorithm with classical and quantum hybrid memory for the learning problem corresponding to $M$ needs either (1) $\Omega(k \cdot \ell)$ bits of classical memory, or (2) $\Omega(r)$ qubits of quantum memory, or (3) $2^{\Omega(r)}$ random samples, to achieve a success probability at least $2^{-O(r)}$. 

Our results refute the possibility that a small amount of quantum memory significantly reduces the size of classical memory needed for efficient learning on these problems. Our results also imply improved security of several existing cryptographical protocols in the bounded-storage model (protocols that are based on parity learning on $n$ bits), proving that security holds even in the presence of a quantum adversary with at most $c n^2$ bits of classical memory and $c n$ bits of quantum memory (for some constant $c&gt;0$).
        
        </div>

        <div class='tr-article-summary'>
        
          
          In a work by Raz (J. ACM and FOCS 16), it was proved that any algorithm for parity learning on $n$ bits requires either $\Omega(n^2)$ bits of classical memory or an exponential number (in~$n$) of random samples. A line of recent works continued that research direction and showed that for a large collection of classical learning tasks, either super-linear classical memory size or super-polynomially many samples are needed. All these works consider learning algorithms as classical branching programs, which perform classical computation within bounded memory.

However, these results do not capture all physical computational models, remarkably, quantum computers and the use of quantum memory. It leaves the possibility that a small piece of quantum memory could significantly reduce the need for classical memory or samples and thus completely change the nature of the classical learning task. Despite the recent research on the necessity of quantum memory for intrinsic quantum learning problems like shadow tomography and purity testing, the role of quantum memory in classical learning tasks remains obscure. 

In this work, we study classical learning tasks in the presence of quantum memory. We prove that any quantum algorithm with both, classical memory and quantum memory, for parity learning on $n$ bits, requires either $\Omega(n^2)$ bits of classical memory or $\Omega(n)$ bits of quantum  memory or an exponential number of samples. In other words, the memory-sample lower bound for parity learning remains qualitatively the same, even if the learning algorithm can use, in addition to the classical memory, a quantum memory of size $c n$ (for some constant $c&gt;0$).

Our result is more general and applies to many other classical learning tasks. Following previous works, we represent by the matrix $M: A \times X \to \{-1,1\}$ the following learning task. An unknown $x$ is sampled uniformly at random from a concept class $X$, and a learning algorithm tries to uncover $x$ by seeing streaming of random samples $(a_i, b_i = M(a_i, x))$ where for every $i$, $a_i\in A$ is chosen uniformly at random. Assume that $k,\ell,r$ are integers such that any submatrix of $M$ of at least $2^{-k}\cdot|A|$ rows and at least $2^{-\ell}\cdot|X|$ columns, has a bias of at most $2^{-r}$. We prove that any algorithm with classical and quantum hybrid memory for the learning problem corresponding to $M$ needs either (1) $\Omega(k \cdot \ell)$ bits of classical memory, or (2) $\Omega(r)$ qubits of quantum memory, or (3) $2^{\Omega(r)}$ random samples, to achieve a success probability at least $2^{-O(r)}$. 

Our results refute the possibility that a small amount of quantum memory significantly reduces the size of classical memory needed for efficient learning on these problems. Our results also imply improved security of several existing cryptographical protocols in the bounded-storage model (protocols that are based on parity learning on $n$ bits), proving that security holds even in the presence of a quantum adversary with at most $c n^2$ bits of classical memory and $c n$ bits of quantum memory (for some constant $c&gt;0$).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T04:17:11Z">Thursday, March 02 2023, 04:17</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, March 01
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/03/01/tcs-talk-wednesday-march-8-christos-tzamos-u-athens-uw-madison/'>TCS+ talk: Wednesday, March 8 — Christos Tzamos, U Athens/UW Madison</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, March 8th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Christos Tzamos from University of Athens/UW Madison will speak about &#8220;A Strongly Polynomial Algorithm for Approximate Forster Transforms and its Application to Halfspace Learning&#8221; (abstract below). You can [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, March 8th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Christos Tzamos</strong> from University of Athens/UW Madison will speak about &#8220;<em>A Strongly Polynomial Algorithm for Approximate Forster Transforms and its Application to Halfspace Learning</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: The Forster transform is a method of regularizing a dataset by placing it in radial isotropic position while maintaining some of its essential properties. Forster transforms have played a key role in a diverse range of settings spanning computer science and functional analysis. Prior work had given weakly polynomial time algorithms for computing Forster transforms, when they exist. Our main result is the first strongly polynomial time algorithm to compute an approximate Forster transform of a given dataset or certify that no such transformation exists. By leveraging our strongly polynomial Forster algorithm, we obtain the first strongly polynomial time algorithm for distribution-free PAC learning of halfspaces. This learning result is surprising because proper PAC learning of halfspaces is equivalent to linear programming. Our learning approach extends to give a strongly polynomial halfspace learner in the presence of random classification noise and, more generally, Massart noise.</p></blockquote>
<p>&#8220;</p>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T21:43:08Z">Wednesday, March 01 2023, 21:43</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/03/01/non-crossing-hamiltonian.html'>Non-crossing Hamiltonian paths and cycles in output-polynomial time</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          My paper “Non-crossing Hamiltonian paths and cycles in output-polynomial time”, to appear at SoCG, is now online as a preprint at arXiv:2303.00147. This is the full version; the SoCG version will need to be cut down by omitting proofs to reach the 500-line proceedings limit. It’s about polygonalization, the problem of finding all ways of connecting dots in the plane into a simple polygon (allowing connections that pass straight through a dot, but not allowing missing a dot altogether). The main results are that we can list all of these in time polynomial in the output size, and in polynomial time get an approximate count of them that is bounded above and below the true count by a polynomial of its value. Previously, the best we knew were that there were at most exponentially many polygonalizations and that we could list them in exponential time.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>My paper “Non-crossing Hamiltonian paths and cycles in output-polynomial time”, to appear at SoCG, is now online as a preprint at <a href="https://arxiv.org/abs/2303.00147">arXiv:2303.00147</a>. This is the full version; the SoCG version will need to be cut down by omitting proofs to reach the 500-line proceedings limit. It’s about <a href="https://en.wikipedia.org/wiki/Polygonalization">polygonalization</a>, the problem of finding all ways of connecting dots in the plane into a simple polygon (allowing connections that pass straight through a dot, but not allowing missing a dot altogether). The main results are that we can list all of these in time polynomial in the output size, and in polynomial time get an approximate count of them that is bounded above and below the true count by a polynomial of its value. Previously, the best we knew were that there were at most exponentially many polygonalizations and that we could list them in exponential time.</p>

<p>I think of this as being in the vein of recent conferences like the <a href="https://www.siam.org/conferences/cm/conference/sosa23">Symposium on Simplicity in Algorithms</a> or the new “simplicity track” of the <a href="http://esa-symposium.org/">European Symposium on Algorithms</a>: simple algorithms whose analysis isn’t. In fact, the algorithm in my paper isn’t even new. It’s the same one that was already used to achieve exponential time, in a paper “Algorithmic enumeration of surrounding polygons” by Katsuhisa Yamanaka, David Avis, Takashi Horiyama, Yoshio Okamoto, Ryuhei Uehara, and Tanami Yamauchi, published in 2021 in <em>Discrete Applied Mathematics</em> (<a href="https://doi.org/10.1016/j.dam.2020.03.034">doi:10.1016/j.dam.2020.03.03</a>).</p>

<p>If we want to list all structures, from an exponentally large family of structures, in time polynomial per structure, then I think there’s really only one idea and a lot of elaboration on that idea. The idea is: describe your structures as the vertices of a large state space, with some sort of local operation for moving from state to state; prove that this local operation suffices to connect all the states together; and then apply a graph exploration algorithm like depth-first search to find all of the states from some starting state. The trouble is, for polygonalizations, we don’t know a good local operation. The obvious candidates, local moves that replace two or three edges of a polygon by a different set of edges, <a href="/blog/2020/01/29/unflippable-polygon.html">were proven not to work</a> in a 2002 paper by Carmen Fernando, Michael Houle, and Ferran Hurtado (<a href="https://doi.org/10.1016%2FS0304-3975%2801%2900409-1">doi:10.1016/S0304-3975(01)00409-1</a>). Instead, Yamanaka et al. propose to list all of the members of a larger family of structures, and then filter out the ones that are really polygonalizations. These more general structures are the “surrounding polygons” of their paper’s title.</p>

<p>A surrounding polygon is just a simple polygon that uses some of the given dots as vertices and contains the rest. The example below is taken from the last section of my paper. There I show that point sets like the one in the illustration, with one concave chain of dots inside a triangle, have \((n-1)2^{n-4}\) polygonalizations but a polynomially-larger number of surrounding polygons proportional to \(n(1+\varphi)^n\). Here \(\varphi\) is the golden ratio; this is <a href="/blog/2020/01/12/counting-grid-polygonalizations.html">not the first occurrence of the golden ratio in counting polygonalizations</a>. A reviewer told me that these point sets are called “party-hat sets” or “ice-cream cone sets” but I’m not sure I believe it; I couldn’t find those names in a Google Scholar search.</p>

<p style="text-align:center"><img src="/blog/assets/2023/pseudotriangle.svg" alt="A set of points in the form of a triangle with a concave chain of points replacing one of its edges, and a surrounding polygon of the points. The points that are vertices of the polygon are colored blue, and the other points surrounded by the polygon are colored red." /></p>

<p>The simplest surrounding polygon of any input is just its <a href="https://en.wikipedia.org/wiki/Convex_hull">convex hull</a>. You can get from any surrounding polygon that is not the convex hull to a simpler one by “<a href="https://en.wikipedia.org/wiki/Two_ears_theorem">ear-cutting</a>”: find two consecutive edges of the polygon that form two sides of an empty triangle outside the polygon, and replace them by a single shortcut edge. The shortcutted vertex becomes surrounded, and the area of the polygon grows, so repeated ear-cutting can only stop at the convex hull, implying that all surrounding polygons are connected through the convex hull. If you choose carefully which ear to cut, you give all surrounding polygons the structure of a tree, and the algorithm of Yamanaka et al. amounts to depth-first search of this tree. You can then find the polygonalizations just by running this algorithm and outputting only the surrounding polygons that use all the dots, at some tree leaves.</p>

<p>The idea of my new paper is to analyze these structures in the style of my book, <a href="https://www.ics.uci.edu/~eppstein/forbidden/"><em>Forbidden Configurations in Discrete Geometry</em></a>, in terms of simple parameters of point sets that are monotonic (they don’t go down when you add more points) and that depend only on the order-type of the point set and not its exact coordinates. The question I set out to answer is: which point sets have only a very small number of polygonalizations, and which have many? I quickly identified two ways in which a point set could only have a small number:</p>

<ul>
  <li>
    <p>Most of its points could belong to a single line. If a set of \(n\) points has \(n-k\) points on a line, and only a much smaller number \(k\) of points elsewhere, then most of the edges would have to connect paths of consecutive points along the line, and there aren’t very many ways of doing that. This number \(k\) is one of the parameters studied in my book. Working out the details of this argument showed more specifically that the number of polygonalizations is \(n^{O(k)}\): there are only \(O(k)\) points of any polygonalization where something interesting happens, and only \(O(n)\) choices for what happens there.</p>
  </li>
  <li>
    <p>Most of its points could belong to the convex hull. If all points belong to the convex hull, then that is the only polygonalization. And if there are \(n-k\) points on the hull, and only a much smaller number \(k\) of points elsewhere, then the only points where something interesting happens are the \(O(k)\) points that are either not on the hull, or adjacent to a non-hull point. All the rest of their points have to be connected to their two hull neighbors. So again the number of polygonalizations is \(n^{O(k)}\). The parameter used here, the number of points interior to the hull, was not from my book, but maybe it should have been.</p>
  </li>
</ul>

<p>More strongly, upper bounds of the same form also apply to surrounding polygons. Allowing an interesting point to be skipped by the polygon doesn’t increase its number of choices much. Consecutive blocks of uninteresting points along a long line of points must either all be skipped or all be part of a surrounding polygon, again not increasing the number of choices by much. And a surrounding polygon cannot skip any point of the convex hull, because then it would not be surrounded. The part of the analysis that I found more difficult was proving that these are the only cases. If you have points that are mostly not on a line and mostly not on a hull, then there are exponentially many polygonalizations. And if you have one of the two situations with few polygonalizations described above, then the number of polygonalizations is accurately described by the upper bounds above. For details of these lower bounds, see the paper. The number of surrounding polygons can only be at least as large as the number of polygonalizations, because every polygonalization is a surrounding polygon.</p>

<p>Once that analysis was done, the algorithms for listing polygonalizations and for approximately counting them came for free. The lower bound and the upper bound on the number of polygonalizations have the same form as each other, so they give an accurate approximation without any more effort. And the bounds on the number of polygonalizations and on the number of surrounding polygons have the same form as each other, so the analysis of the algorithm for surrounding polygons (that it takes input-polynomial time per polygon) also shows that it generates all polygonalizations in output-polynomial time.</p>

<p>The “non-crossing Hamiltonian paths” of the new paper’s title are the same thing, but easier. The easier-to-generate structures are non-crossing paths, which you can form into a forest (rooted at the one-vertex paths) by a parent operation that removes the final edge of a path. And points in convex position still have many paths; the only point sets that have a small number of non-crossing Hamiltonian paths (or non-crossing paths) are the ones with most of the points on a single line.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/109951209389425592">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T17:51:00Z">Wednesday, March 01 2023, 17:51</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/03/01/soda-2023/'>SODA 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Traces of strings, plus ways of tracing accepted papers Anindya De was at Northwestern University and is now at the University of Pennsylvania&#8212;see here. He was advised by two of the top advisors ever there were: Luca Trevisan and Umesh Vazirani. Traces I recently ran across a great paper by Anindya titled Approximate Trace Reconstruction [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>Traces of strings, plus ways of tracing accepted papers</em><br />
<font color="#000000"></p>
<p>
Anindya De was at Northwestern University and is now at the University of Pennsylvania&#8212;see <a href="https://www.seas.upenn.edu/~anindyad/">here</a>. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/01/soda-2023/ad-2/" rel="attachment wp-att-21192"><img data-attachment-id="21192" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/01/soda-2023/ad-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?fit=400%2C400&amp;ssl=1" data-orig-size="400,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 5D Mark III&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1551052800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;200&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.00625&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ad" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?fit=400%2C400&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?resize=250%2C250&#038;ssl=1" alt="" width="250" height="250" class="aligncenter wp-image-21192" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?w=400&amp;ssl=1 400w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 250px) 100vw, 250px" data-recalc-dims="1" /></a></p>
<p>
He was advised by two of the top advisors ever there were: Luca Trevisan and Umesh Vazirani. </p>
<p>
<p><H2> Traces </H2></p>
<p><p>
I recently ran across a great paper by Anindya titled <a href="https://arxiv.org/abs/2211.03292">Approximate Trace Reconstruction from a Single Trace</a>. It is co-authored with Xi Chen (Columbia University), Chin Ho Lee (Harvard University), and Rocco Servedio and Sandip Sinha (Columbia University). Notice that we did not put an <a href="https://jewishstandard.timesofisrael.com/horse-mule-horse-mule/">Oxford comma</a> between Servedio and Sinha as they are both from Columbia. The paper appeared at <a href="https://www.siam.org/conferences/cm/program/accepted-papers/soda23-accepted-papers">SODA 2023</a> this January. </p>
<p>
Here are pointers to the almost 200 papers that were in the conference. I put this together before discovering the site <a href="https://www.conference-publishing.com/">conference-publishing.com</a>, which as mentioned in my STOC 2023 <a href="https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/">post</a> generates paper lists with links for a host of conferences. So I did all the following links myself. Do scroll past the list to the bottom to read a little more about traces which Ken and I put together.</p>
<ol>
<p><li>
<a href="https://arxiv.org/pdf/2204.09129.pdf">Small Shadows of Lattice Polytopes</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.05186">Fair allocation of a multiset of indivisible items</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.02277">Hierarchies of Minion Tests for PCSPs through Tensors</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.08293">Approximate Graph Colouring and Crystals</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.04455">The Price of Stability for First Price Auction</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.04549">Spencer&#8217;s theorem in nearly input-sparsity time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.11195">Spatial Mixing and the random-cluster dynamics on lattices</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch157">Nonlinear codes exceeding the Gilbert-Varshamov and Tsfasman-Vladut-Zink bounds</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.09391">A Near-Linear Time Sampler for the Ising Model with External Field</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.02655">Concentration of polynomial random matrices via Efron-Stein inequalities</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.15945">Quantum Speed-ups for String Synchronizing Sets, Longest Common Substring, and kmismatch Matching</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.11275">Halving by a Thousand Cuts or Punctures</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch50">On the number incidences when avoiding an induced biclique in geometric settings</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.00579">Subexponential mixing for partition chains on grid-like graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2103.02972">Weisfeilera Leman and Graph Spectra</a></p>
<p><li>
<a href="https://arxiv.org/abs/2203.09334">Stronger 3SUM-Indexing Lower Bounds</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.10556">Tight Bounds for Monotone Minimal Perfect Hashing</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.02732">Almost Consistent Systems of Linear Equations</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.05898">Testing and Learning Quantum Juntas Nearly Optimally</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch155">Testing Convex Truncation</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch55">Player-optimal Stable Regret for Bandit Learning in Matching Markets</a></p>
<p><li>
<a href="https://arxiv.org/abs/2103.03769">Competitive Information Design for Pandoras Box</a></p>
<p><li>
<a href="https://arxiv.org/abs/2106.12725">Breaking the O(n)-Barrier in the Construction of Compressed Suffix Arrays and Suffix Trees</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.14108">Short Synchronizing Words for Random Automata</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.00450">Packing cycles in planar and bounded-genus graphs</a></p>
<p><li>
<a href="https://web.eecs.umich.edu/~pettie/papers/LLL.pdf">Improved Distributed Algorithms for the Lovasz Local Lemma and Edge Coloring</a></p>
<p><li>
<a href="https://arxiv.org/abs/2112.07050">Optimal Fully Dynamic <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" />-Center Clustering for Adaptive and Oblivious Adversaries</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.13335">A logic-based algorithmic meta-theorem for mim-width</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.12800">Tiny Pointers</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07158">Streaming complexity of CSPs with randomly ordered constraints</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.04458">Computing Square Colorings on Bounded-Treewidth and Planar Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2203.00751">Near-Linear Time Approximations for Cut Problems via Fair Cuts</a></p>
<p><li>
<a href="https://deepai.org/publication/stronger-privacy-amplification-by-shuffling-for-renyi-and-approximate-differential-privacy">Stronger Privacy Amplification by Shuffling for R&eacute;nyi and Approximate Differential Privacy</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.13696">Minimizing Completion Times for Stochastic Jobs via Batched Free Times</a></p>
<p><li>
<a href="https://arxiv.org/abs/2106.02149">Optimal Pricing Schemes for an Impatient Buyer</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07974">Online Prediction in Sub-linear Space</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.03268">Fast Discrepancy Minimization with Hereditary Guarantees</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07363">Exact Flow Sparsification Requires Unbounded Size</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07809">Curve Simplification and Clustering under Frechet Distance</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08783">Almost Tight Bounds for Online Facility Location in the Random-Order Model</a></p>
<p><li>
<a href="https://arxiv.org/abs/2104.00406">The complete classification for quantified equality constraints</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.02170">Small subgraphs with large average degree</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.07544">Mean estimation when you have the source code; or, quantum Monte Carlo methods</a></p>
<p><li>
<a href="https://arxiv.org/abs/2212.03016">Online Min-Max Paging</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.08904">Gap-ETH-Tight Approximation Schemes for Red-Green-Blue Separation and BicoloredEuclidean Travelling Salesman Tours</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.02951">Map matching queries on realistic input graphs under the Frachet distance</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.07410">Private Query Release via the Johnson Lindenstrauss Transform</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.07571">Efficient decoding up to a constant fraction of the code length for asymptotically goodquantum codes</a> </p>
<p><li>
<a href="https://arxiv.org/abs/2202.01248">Passing the Limits of Pure Local Search for weighted k-Set Packing</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.11892">Improved Bounds for Sampling Solutions of Random CNF Formulas</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.03158">Pricing Query Complexity of Revenue Maximization</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07422">Flow-augmentation III: complexity dichotomy for Boolean CSPs parameterized by thenumber of unsatisfied constraints</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07425">Parameter tractability of Directed Multicut with three terminal pairs parameterizedby the size of the cutset: twin-width meets flow-augmentation</a> </p>
<p><li>
<a href="https://arxiv.org/abs/2012.06713">Approximate Trace Reconstruction from a Single Trace</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07519">Dynamic Algorithms for Packing-Covering LPs via Multiplicative Weight Updates</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.03469">Sharp threshold sequence and universality for Ising perceptron models</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.02519">Maintaining Expander Decompositions via Sparse Cuts</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.09341">Near Optimal Analysis of the Cube versus Cube Test</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.09341">Approximating Knapsack and Partition via Dense Subset Sums</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.13755">Online and Bandit Algorithms for Norms with Gradient-Stable Approximations</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.04868">On complex roots of the independence polynomial</a></p>
<p><li>
<a href="https://deepai.org/publication/simplex-range-searching-revisited-how-to-shave-logs-in-multi-level-data-structures">Simplex Range Searching Revisited: How to Shave Logs in Multi-Level Data Structures</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.04112">Improved Pattern-Avoidance Bounds for Greedy BSTs via Matrix Decomposition</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.06527">Moser-Tardos Algorithm: Beyond Shearer&#8217;s Bound</a></p>
<p><li>
<a href="https://arxiv.org/abs/2212.14847">Deterministic counting Lovasz local lemma beyond linear programming</a></p>
<p><li>
<a href="https://arxiv.org/abs/2205.05564">Conflict-free hypergraph matchings</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.12721">A Subquadratic <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%5Cepsilon%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n^&#92;epsilon}" class="latex" />-approximation for the Continuous Frachet Distance</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.08044">Interdependent Public Projects</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.04994">A Nearly Time-Optimal Distributed Approximation of Minimum Cost <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" />-Edge-Connected Spanning Subgraph</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07426">A tight quasi-polynomial bound for Global Label Min-Cut</a></p>
<p><li>
<a href="https://arxiv.org/abs/2205.07709">Polynomial formulations as a barrier for reduction-based hardness proofs</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch173">Faster Algorithm for Turn-based Stochastic Games with Bounded Treewidth</a></p>
<p><li>
<a href="https://arxiv.org/abs/2203.17144">Instability of backoff protocols with arbitrary arrival rates</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch158">On the orbit closure intersection problems for matrix tuples under conjugation and leftright actions</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.04377">Constant Approximating Parameterized k-SetCover is W[2]-hard</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08268?context=stat.ML">Online Lewis Weight Sampling</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.11328">Toeplitz Low-Rank Approximation with Sublinear Query Complexity</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.06874">Kernelization for Graph Packing Problems via Rainbow Matching</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.01143">Improved Integrality Gap in Max-Min Allocation: or Topology at the North Pole</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.06292">Generalized Unrelated Machine Scheduling Problem</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.04278">Tight Complexity Bounds for Counting Generalized Dominating Sets in Bounded-Treewidth Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2301.07537">An Improved Approximation for Maximum Weighted k-Set Packing</a></p>
<p><li>
<a href="https://arxiv.org/abs/2212.09348">Excluding Single-Crossing Matching Minors in Bipartite Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.15335">Byzantine Agreement with Optimal Resilience via Statistical Fraud Detection</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05345">Finding Triangles and Other Small Subgraphs in Geometric Intersection Graphs</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch188">Simple, deterministic, fast (but weak) approximations to edit distance and Dyck edit distance</a> </p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch132">From algorithms to connectivity and back: finding a giant component in random k-SAT</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.00594">Sparse graphs with bounded induced cycle packing number have logarithmic treewidth</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08311">Shrunk subspaces via operator Sinkhorn iteration</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.10398">Improved Approximation Algorithms for Unrelated Machines</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.01723">Model-Checking for First-Order Logic with Disjoint Paths Predicates in Proper MinorClosed Graph Classes</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.10556">A Distanced Matching Game, Decremental APSP in Expanders, and Faster DeterministicAlgorithms for Graph Cut Problems</a> </p>
<p><li>
<a href="https://arxiv.org/abs/2005.06156">Super-resolution and Robust Sparse Continuous Fourier Transform in Any Constant Dimension: Nearly Linear Time and Sample Complexity</a></p>
<p><li>
<a href="https://chaoxuprime.com/files/papers/sub4part.pdf">A Polynomial Time Algorithm for Finding a Minimum 4-Partition of a Submodular Function</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.05423">Positivity of the symmetric group characters is PH-hard</a></p>
<p><li>
<a href="https://arxiv.org/abs/1905.08841">Parallel Exact Shortest Paths in Almost Linear Work and Square Root Depth</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/10.1137/1.9781611977554.ch40">On the Integrality Gap of MFN Relaxation for the Capacitated Facility Location Problem</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch105">Weak Bisimulation Finiteness of Pushdown Systems With Deterministic Transitions-ExpTime-Complete</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.13057">Beating Greedy Matching in Sublinear Time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2203.11863">Integrality Gaps for Random Integer Programs via Discrepancy</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.10265">Improved Approximation for Two-Edge-Connectivity</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch117">Zigzagging through acyclic orientations of chordal graphs and hypergraphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.04797">Shortest Cycles With Monotone Submodular Costs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2107.07347">Traversing the FFT Computation Tree for Dimension-Independent Sparse FourierTransforms</a> </p>
<p><li>
<a href="https://arxiv.org/abs/2207.07449">Fixed-Parameter Tractability of Maximum Colored Path and Beyond</a></p>
<p><li>
<a href="https://arxiv.org/abs/2007.12257">A half-integral Erd&#337;s-P&oacute;sa theorem for directed odd cycles</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.13395">Improved Bi-point Rounding Algorithms and a Golden Barrier for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" />-Median</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.05659">Approximate Distance Oracles for Planar Graphs with Subpolynomial Error Dependency</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.02717">A Framework for Approximation Schemes on Disk Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.13281">Cubic Goldreich-Levin</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.04507">Closing the Gap Between Directed Hopsets and Shortcut Sets</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.09215">&#8220;Who is Next in Line?&#8221; On the Significance of Knowing the Arrival Order in Bayesian Online Settings</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05217">Smaller Low-Depth Circuits for Kronecker Powers</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.14759">Fast algorithms for solving the Hamilton Cycle problem with high probability</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05053">On Minimizing Tardy Processing Time, Max-Min Skewed Convolution, and TrianglarStructured ILPs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2302.02290">Maximal k-Edge-Connected Subgraphs in Weighted Graphs via Local Random Contraction</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.10850">A simple and sharper proof of the hypergraph Moore bound</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08643">A Sublinear-Time Quantum Algorithm for Approximating Partition Functions</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.13484">On Problems Related to Unbounded SubsetSum: A Unified Combinatorial Approach</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.03893">Query Complexity of the Metric Steiner Tree Problem</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.12601">Sublinear-Time Algorithms for Max Cut, Max E2Lin<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%28q%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{(q)}" class="latex" />, and Unique Label Cover on Expanders</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.06790">Near-Linear Sample Complexity for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BL_p%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{L_p}" class="latex" /> Polynomial Regression</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.07520">On (Random-order) Online Contention Resolution Schemes for the Matching Polytope of (Bipartite) Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.09964">Optimal Algorithms for Linear Algebra in the Current Matrix Multiplication Time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07946">Algebraic Algorithms for Fractional Linear Matroid Parity via Non-commutative Rank</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05006">Almost Tight Error Bounds on Differentially Private Continual Counting</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.09159">Secretary Problems: The Power of a Single Sample</a></p>
<p><li>
<a href="https://arxiv.org/abs/2112.06380">Robust Voting Rules from Algorithmic Robust Statistics</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch9">Faster and Unified Algorithms for Diameter Reducing Shortcuts and Minimum Chain Cover</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch85">Improved girth approximation in weighted undirected graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2112.03791">Online Sorting and Translational Packing of Convex Polygons</a></p>
<p><li>
<a href="https://arxiv.org/abs/2302.05951">Fully Dynamic Exact Edge Connectivity in Sublinear Time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.11072">Algorithmizing the Multiplicity Schwartz-Zippel Lemma</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07949">A Nearly Tight Analysis of Greedy k-means++</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07007?context=cs">A polynomial-time algorithm for 1/2-well-supported Nash equilibria in bimatrix games</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.10969">Bidder subset selection problem in auction design</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.09035">Massively Parallel Computation on Embedded Planar Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2301.09810">Balanced Allocations: The Power of Memory with Heterogeneous Bins</a></p>
<p><li>
<a href="https://arxiv.org/abs/2003.00545">Simple Mechanisms for Agents with Non-linear Utilities</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch59">The Power of Clairvoyance for Multi-Level Aggregation and Set Cover with Delay</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05769">Steiner Connectivity Augmentation and Splitting-off in Poly-logarithmic Maximum Flows</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05509">Discrepancy minimization via regularization</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch162">Equivalence Test for Read-Once Arithmetic Formulas</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.07534">Time-Space Tradeoffs for Element Distinctness and Set Intersection via Pseudorandomness</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.11651">Local Distributed Rounding: Generalized to MIS, Matching, Set Cover, and Beyond</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch143">Parameterized Approximation Scheme for Biclique-free Max k-Weight SAT and Max Coverage</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.11669">Improved Distributed Network Decomposition, Hitting Sets, and Spanners, via Derandomization</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.05150">Breaching the 2 LMP Approximation Barrier for Facility Location with Applications to kMedian</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.12441">Query Complexity of Inversion Minimization on Trees</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch4">Faster Deterministic Worst-Case Fully Dynamic All-Pairs Shortest Paths via Decremental Hop-Restricted Shortest Paths</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch189">Optimal Square Detection Over General Alphabets</a></p>
<p><li>
<a href="https://arxiv.org/abs/2203.16476">Differentially Private All-Pairs Shortest Path Distances: Improved Algorithms and Lower Bounds</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch96">Faster Computation of 3-Edge-Connected Components in Digraphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2201.10758">Sampling Equilibria: Fast No-Regret Learning in Structured Games</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.07327">Higher degree sum-of-squares relaxations robust against oblivious outliers</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.07606">Fast Distributed Brooks Theorem</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch119">Graph Classes With Few Minimal Separators. I. Finite Forbidden Subgraphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.03530">Optimal Deterministic Massively Parallel Connectivity on Forests</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.03151">Foundations of Transaction Fee Mechanism Design</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch119">Graph Classes With Few Minimal Separators. II. A Dichotomy</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.01945">Distributed Maximal Matching and Maximal Independent Set on Hypergraphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08800">Quantum tomography using state-preparation unitaries</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.01911">Almost-Linear Planted Cliques Elude the Metropolis Process</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.05450">Timeliness Through Telephones</a></p>
<p><li>
<a href="https://www.ccs.neu.edu/home/viola/papers/resilient.pdf">Efficient resilient functions</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07438">Dynamic Matching with Better-than-2 Approximation in Polylogarithmic Update Time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.03877">The Need for Seed (in the abstract Tile Assembly Model)</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08347">Private Convex Optimization in General Norms</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07607">Dynamic Algorithms for Maximum Matching Size</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.01254">Unique Games hardness of Quantum Max-Cut, and a conjectured vector-valued Borell&#8217;s inequality</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch23">A Nearly-tight Analysis of Multipass Pairing Heaps</a></p>
<p><li>
<a href="https://arxiv.org/abs/2108.04458">A Tight Analysis of Slim Heaps and Smooth Heaps</a></p>
<p><li>
<a href="https://arxiv.org/abs/2106.04863">Lossless Online Rounding for Online Bipartite Matching (Despite its Impossibility)</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07983?context=cs">Approximation Algorithms for Steiner Tree Augmentation Problems</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.08404">Low Degree Testing over the Reals</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05170">Streaming algorithms for the missing item finding problem</a></p>
<p><li>
<a href="https://cse.hkust.edu.hk/faculty/arya/pub/soda23.pdf">Economical Convex Coverings and Applications</a></p>
<p><li>
<a href="https://eccc.weizmann.ac.il/report/2022/146/">Interactive Coding with Small Memory</a></p>
<p><li>
<a href="https://arxiv.org/abs/2301.05682">Non-Stochastic CDF Estimation Using Threshold Queries</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch30">Elliptic Curve Fast Fourier Transform Part I : Low-degree extension in time O(n log n) over all finite fields</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch33">Single-Pass Streaming Algorithms for Correlation Clustering</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.01468">A New Approach to Estimating Effective Resistances and Counting Spanning Trees in Expander Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.06375">Superpolynomial Lower Bounds for Decision Tree Learning and Testing</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.07132">The <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_p%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;ell_p}" class="latex" />-Subspace Sketch Problem in Small Dimensions with Applications to Support Vector Machines</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.17515">Beating <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%281-1%2Fe%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{(1-1/e)}" class="latex" />-Approximation for Weighted Stochastic Matching</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch35">Towards Multi-Pass Streaming Lower Bounds for Optimal Approximation of Max-Cut</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.03341">Parameterized Algorithm for the Planar Disjoint Paths Problem: Exponential in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k^2}" class="latex" />, and Linear in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /></a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.02581">Learning Hierarchical Cluster Structure of Graphs in Sublinear Time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.09106">The Exact Bipartite Matching Polytope Has Exponential Extension Complexity</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.03161">4D Range Reporting in the Pointer Machine Model in Almost-Optimal Time</a></p>
</ol>
<p>
<p><H2> The Trace Result </H2></p>
<p><p>
The trace problem begins by sending a binary string <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> of length <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> through a <b>deletion channel</b> with parameter <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cin+%5B0%2C1%5D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;delta &#92;in [0,1]}" class="latex" />. Each bit <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x_i}" class="latex" /> entering the channel survives with probability <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B1+-+%5Cdelta%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{1 - &#92;delta}" class="latex" /> to be part of the output string <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" />. That is, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x_i}" class="latex" /> is deleted with probability <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;delta}" class="latex" />. The deletions are independent. For an unknown string <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />, the problem is:</p>
<blockquote><p><b> </b> <em> Given <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> strings <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By_1%2C%5Cdots%2Cy_k%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y_1,&#92;dots,y_k}" class="latex" /> produced by <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> runs of the channel on <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />, reconstruct <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> if possible. Else, calculate a binary string <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x&#039;}" class="latex" /> of length <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> that minimizes a distance metric <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bd%28x%2Cx%27%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{d(x,x&#039;)}" class="latex" />. The metric of choice is to maximize the length <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28x%2Cx%27%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;ell(x,x&#039;)}" class="latex" /> of the longest common subsequence (not necessarily contiguous) of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x&#039;}" class="latex" />, which corresponds to minimizing their edit distance. </em>
</p></blockquote>
<p><p>
As indicated by its title &#8220;Approximate Trace Reconstruction from a Single Trace,&#8221; the <a href="https://arxiv.org/abs/2211.03292">paper</a> tackles the extreme case <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k=1}" class="latex" />. Of course one cannot reconstruct <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> (unless no deletions occur so <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By+%3D+x%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y = x}" class="latex" />) so the game is to find <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x&#039;}" class="latex" /> that are most likely to have produced the lone observed <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" />. The scoring function takes the expectation of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28x%27%2Cx%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;ell(x&#039;,x)}" class="latex" /> over both the generation of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> from the true <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> and the run of the algorithm guessing <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x&#039;}" class="latex" /> from <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" />. There are two main questions:</p>
<ul>
<li>
How well does the algorithm perform&#8212;relative to theoretically optimal choices given <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" />&#8212;when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> itself is generated uniformly at random? </p>
<li>
How well does the algorithm perform when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> is generated adversarially? Note that <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> is still probabilistic, and the performance of both the theoretical optimal algorithm and their algorithm are evaluated based on the distribution of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> for the fixed (unseen) <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />.
</ul>
<p>
These questions are posed for small, medium, and large values of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;delta}" class="latex" />. When the deletion probability is close to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{1}" class="latex" />, the strings <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> are most often tiny. One would think they offer no help in coming close to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />. However, they do help efficient algorithms come close to the optimal policy for a worst-case chosen <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />. The paradoxical results of their paper, in their own words (but reversing their order), are: </p>
<ol>
<li>
In the average-case setting, having access to a single trace is provably not very useful: no algorithm, computationally efficient or otherwise, can achieve significantly higher accuracy given one trace that is <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bo%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{o(n)}" class="latex" /> bits long than it could with no traces. </p>
<li>
Having access to a single trace is already quite useful for worst-case trace reconstruction: an efficient algorithm can perform much more accurate reconstruction, given one trace that is even only a few bits long, than it could given no traces at all.
</ol>
<p>
The deep point is that when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> as well as <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> is random, seeing <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> gives little advantage to both the optimal strategy (which does not know <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />) and their algorithm. Whereas, when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> is fixed, the knowledge of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> is more valuable to the optimal strategy and separates it from the case of not seeing <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> at all. However, the profit given by even a short <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> is one that is apprehendable by a complexity-limited deterministic algorithm that sees only <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" />. That&#8217;s our attempt at an intuitive takeaway; as always we invite readers to consult the paper in detail.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Comparing my list of pointer to the papers from SODA, which was a bit of trouble to create by hand, to the STOC&#8217;23 <a href="https://www.conference-publishing.com/list.php?Event=STOC23">output</a> from the conference-publishing site, leads to a curious question:</p>
<blockquote><p><b> </b> <em> Do we scan lists of papers more by looking for subject words in their titles or looking for authors we know? </em>
</p></blockquote>
<p><p>
Well, I have not found SODA&#8217;23 on that website, where authors too would be given; for me, copying the authors would more than double the manual work.</p>
<p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T06:02:29Z">Wednesday, March 01 2023, 06:02</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, February 28
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/02/28/linkage-200k-edits.html'>Linkage for 200,000 edits to Wikipedia</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government (\(\mathbb{M}\)), including guidelines for equitable use of AI and automated systems through a new Blueprint for an AI Bill of Rights (that is, rights for people to be protected against unfair uses of AI, not rights for artificial intelligences).
        
        </div>

        <div class='tr-article-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/02/16/executive-order-on-further-advancing-racial-equity-and-support-for-underserved-communities-through-the-federal-government/">Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@sorelle@mastodon.social/109875326202971711">\(\mathbb{M}\)</a>),</span> including guidelines for equitable use of AI and automated systems through a new <a href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/">Blueprint for an AI Bill of Rights</a> (that is, rights for people to be protected against unfair uses of AI, not rights for artificial intelligences).</p>
  </li>
  <li>
    <p><a href="https://press.princeton.edu/ideas/why-prove-it">Why prove it?</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@highergeometer/109854745668334423">\(\mathbb{M}\)</a>,</span> <a href="https://www.math.columbia.edu/~woit/wordpress/?p=13288">via</a>). John Stillwell on human-written vs machine-checkable proofs, with reference to the abc conjecture.</p>
  </li>
  <li>
    <p><a href="https://www.ics.uci.edu/~eppstein/pix/ltcc/index.html">Low tide at Crystal Cove State Park</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109894403539276698">\(\mathbb{M}\)</a>).</span></p>

    <p style="text-align:center"><img src="https://www.ics.uci.edu/~eppstein/pix/ltcc/Seagrass2-m.jpg" alt="Low tide at Crystal Cove State Park, California" style="border-style:solid;border-color:black" /></p>
  </li>
  <li>
    <p>Another newly promoted Wikipedia Good Article: <a href="https://en.wikipedia.org/wiki/Polygonalization">Polygonalization</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109906715996859674">\(\mathbb{M}\)</a>),</span> about finding a polygon that uses all of a given set of points as vertices. The usual definitions allow it to go straight through some of the vertices, rather than always turning, though, and the illustration below shows why: for some point sets, including 3x3 grids, a polygon that turns everywhere might not exist.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/3x3_grid_polygonalizations.svg" alt="Eight ways of polygonalizing a 3x3 grid" /></p>
  </li>
  <li>
    <p><a href="https://terrytao.wordpress.com/2023/02/18/would-it-be-possible-to-create-a-tool-to-automatically-diagram-papers/">Would it be possible to create a tool to automatically diagram papers?</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@tao/109887019658810502">\(\mathbb{M}\)</a>),</span> by Terry Tao, inspired by the diagrams the proof-assistant people have been using to guide their work.</p>
  </li>
  <li>
    <p>People who indulge in the fringe belief in the reality of certain folklore beasts are sad that <a href="https://boingboing.net/2023/02/22/the-cryptid-complications-of-wikipedias-editing-policies.html">Wikipedia now focuses on the folklore of these beasts without going into much detail about the fringe belief in their reality</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109918360457067075">\(\mathbb{M}\)</a>).</span> (Based on a both-sides-ist <em>Slate</em> article that I’m not going to link.)</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=MDhT6-6Yr_I">Origami actuators</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@logicalelegance@mastodon.online/109920746034435458">\(\mathbb{M}\)</a>),</span> for simple repetitive motions of origami models, by attaching flat-printed electromagnets to them.</p>
  </li>
  <li>
    <p>Gasarch writes: <a href="https://blog.computationalcomplexity.org/2023/02/it-is-more-important-than-ever-to-teach.html">It is more important than ever to teach your students probability (even non-stem students)</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109935523877122235">\(\mathbb{M}\)</a>).</span> Why: because your university may be making deals promoting online gambling to the same students, as the linked copy of a New York Times article details.</p>
  </li>
  <li>
    <p><a href="https://xtools.wmflabs.org/ec/en.wikipedia.org/David_Eppstein">Sometime in the last month (not exactly sure when) I passed the milestone of 200,000 edits (all non-automated) to Wikipedia</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109941265893054592">\(\mathbb{M}\)</a>).</span> That’s…a lot of edits. Although, as of earlier in the month when it was below 200,000, it only places me at 260 on the <a href="https://en.wikipedia.org/w/index.php?title=Wikipedia:List_of_Wikipedians_by_number_of_edits&amp;oldid=1138516223">list of all-time prolific editors</a>. And a couple of the top ten are now blocked, so it’s not exactly always a place of pride.</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2023/02/zai-divecha-phase-shift/">Mesmerizing paper sculptures and animations by Zai Divecha convey the subtlety of change</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@colossal@mastodon.art/109937307601608046">\(\mathbb{M}\)</a>,</span> <a href="https://zaidivecha.com/">see also</a>). Basically a 3d papercraft zoetrope.</p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T17:40:00Z">Tuesday, February 28 2023, 17:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.simons.berkeley.edu/2023/02/theory-at-the-institute-and-beyond-february-2023/'>Theory at the Institute and Beyond, February 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          by Venkatesan Guruswami (Simons Institute) This semester at the Simons Institute, the Meta-Complexity program is buzzing along with intense activity in the form of multiple reading groups and a weekly seminar, on top of the usual three workshops and boot &#8230; Continue reading &#8594;<p>By Simons Institute Editor</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          by Venkatesan Guruswami (Simons Institute) This semester at the Simons Institute, the Meta-Complexity program is buzzing along with intense activity in the form of multiple reading groups and a weekly seminar, on top of the usual three workshops and boot &#8230; <a href="https://blog.simons.berkeley.edu/2023/02/theory-at-the-institute-and-beyond-february-2023/">Continue reading <span class="meta-nav">&#8594;</span></a><p class="authors">By Simons Institute Editor</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T17:00:08Z">Tuesday, February 28 2023, 17:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/'>Alef’s Corner: Democracy (Israel, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Democracy in Hebrew is דמוקרטיה represented by the letter &#8220;dalet&#8221; ד  
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p></p>


<h2><img loading="lazy" data-attachment-id="23916" data-permalink="https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/dem1/" data-orig-file="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg" data-orig-size="684,701" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Dem1" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=293" data-large-file="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=640" class="alignnone size-full wp-image-23916" src="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg" alt="Dem1" width="684" height="701" srcset="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg 684w, https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=146&amp;h=150 146w, https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=293&amp;h=300 293w" sizes="(max-width: 684px) 100vw, 684px" /><img loading="lazy" data-attachment-id="23918" data-permalink="https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/dem2/" data-orig-file="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg" data-orig-size="1000,1000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Dem2" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=640" class="alignnone size-full wp-image-23918" src="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg" alt="Dem2" width="1000" height="1000" srcset="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg 1000w, https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=150&amp;h=150 150w, https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=300&amp;h=300 300w, https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=768&amp;h=768 768w" sizes="(max-width: 1000px) 100vw, 1000px" /></h2>
<h2>Democracy in Hebrew is דמוקרטיה represented by the letter &#8220;dalet&#8221; <strong><span style="color: #ff0000">ד</span></strong></h2>
<p> </p><p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T16:27:04Z">Tuesday, February 28 2023, 16:27</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, February 27
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/i-wish-we-had-less-students-in-class.html'>I wish we had less students in a Class. Demographics says I may get my wish.</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;According to&nbsp;this&nbsp;article, in the near future LESS people will be going to college. There is even a name for this upcoming shift: The Enrollment Cliff. Why?</p><p>Is it Covid-related?&nbsp; Is it that College has gotten to expensive? To liberal? To much cancel culture?&nbsp; To many dead white males in the core? The core is to multicultural? Online learning is stealing our students?&nbsp;</p><p>No. The reason is actually very boring and does not serve anyone's political agenda. (thats not quite right).&nbsp; Or any agenda. And you can probably guess the cause from the title of this blog post.</p><p>For some years up until 2007 the birth rate was slowly dropping. Then there was a large drop in the birth rate after the recession of 2007, and the birth rate has never really recovered. And the recession might not have that much to do with it-- the long term move from an agricultural society (where kids are an economic gain) to an industrial one (where, after child labor laws and the expense of college, kids are an economic loss- though that can be debated) has resulted in a very long term decline in births.&nbsp;</p><p>And from personal experience, I know (a) very few people who have 4 or more kids, (b) there is NO stigma about having 0 kids as there once was.&nbsp; Of course the sample size of people I know may be skewed.&nbsp;</p><p>ANYWAY, what will this mean for colleges?&nbsp;</p><p>a) Harvard, Yale, etc will not be affected. Plenty of people will still apply. Note that they draw from all of American and also internationally.&nbsp;</p><p>b) Colleges that draw from a local area may be affected a lot since they depend on locals, and that population may be shrinking.&nbsp;</p><p>c) Schools in between Harvard and Small colleges- hard to say.&nbsp;</p><p>d) The sports betting places paying schools to allow them to promote on campus (and in some cases helping them promote it) may find far less students to sucker into this loser's game. See my blog on this topic&nbsp;here</p><p>Univ of MD has around 4000 Computer Science majors (depending on who tells you this its either a brag or a complaint). In the Spring of 2023 there are three lectures of Discrete math of sizes 240, 270, and 90. Each of those also has recitations of&nbsp; 30 (or so) each. If the decline is gradual (either from demographics or from the CS majors bubble finally bursting, or from the other reasons above) then I am sure we can handle it. If it declines very suddenly we may have a problem adjusting.&nbsp;</p><p>One caveat to this that I've heard is that immigration will save us. Maybe. But America is politically going in the opposite direction. The counterargument of without immigration there will be less students going to college is not that compelling to most Americans. There are other more intelligent and compelling pro-immigration arguments. However, American politics is no longer interested in compelling and logical arguments. (The notion that it once was may be nostalgia for a time that never was.)&nbsp;</p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;According to&nbsp;<a href="https://www.vox.com/the-highlight/23428166/college-enrollment-population-education-crash">this</a>&nbsp;article, in the near future LESS people will be going to college. There is even a name for this upcoming shift: <i>The Enrollment Cliff. </i>Why?</p><p>Is it Covid-related?&nbsp; Is it that College has gotten to expensive? To liberal? To much cancel culture?&nbsp; To many dead white males in the core? The core is to multicultural? Online learning is stealing our students?&nbsp;</p><p>No. The reason is actually very boring and does not serve anyone's political agenda. (thats not quite right).&nbsp; Or any agenda. And you can probably guess the cause from the title of this blog post.</p><p>For some years up until 2007 the birth rate was slowly dropping. Then there was a large drop in the birth rate after the recession of 2007, and the birth rate has never really recovered. And the recession might not have that much to do with it-- the long term move from an agricultural society (where kids are an economic gain) to an industrial one (where, after child labor laws and the expense of college, kids are an economic loss- though that can be debated) has resulted in a very long term decline in births.&nbsp;</p><p>And from personal experience, I know (a) very few people who have 4 or more kids, (b) there is NO stigma about having 0 kids as there once was.&nbsp; Of course the sample size of people I know may be skewed.&nbsp;</p><p>ANYWAY, what will this mean for colleges?&nbsp;</p><p>a) Harvard, Yale, etc will not be affected. Plenty of people will still apply. Note that they draw from all of American and also internationally.&nbsp;</p><p>b) Colleges that draw from a local area may be affected a lot since they depend on locals, and that population may be shrinking.&nbsp;</p><p>c) Schools in between Harvard and Small colleges- hard to say.&nbsp;</p><p>d) The sports betting places paying schools to allow them to promote on campus (and in some cases helping them promote it) may find far less students to sucker into this loser's game. See my blog on this topic&nbsp;<a href="https://blog.computationalcomplexity.org/2023/02/it-is-more-important-than-ever-to-teach.html">here</a></p><p>Univ of MD has around 4000 Computer Science majors (depending on who tells you this its either a brag or a complaint). In the Spring of 2023 there are three lectures of Discrete math of sizes 240, 270, and 90. Each of those also has recitations of&nbsp; 30 (or so) each. If the decline is gradual (either from demographics or from the CS majors bubble finally bursting, or from the other reasons above) then I am sure we can handle it. If it declines very suddenly we may have a problem adjusting.&nbsp;</p><p>One caveat to this that I've heard is that immigration will save us. Maybe. But America is politically going in the opposite direction. The counterargument of <i>without immigration there will be less students</i> <i>going to college </i>is not that compelling to most Americans. There are other more intelligent and compelling pro-immigration arguments. However, American politics is no longer interested in compelling and logical arguments. (The notion that it once was may be nostalgia for a time that never was.)&nbsp;</p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T15:10:00Z">Monday, February 27 2023, 15:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/017'>TR23-017 |  Near-Optimal Set-Multilinear Formula Lower Bounds | 

	Deepanshu Kush, 

	Shubhangi Saraf</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The seminal work of Raz (J. ACM 2013) as well as the recent breakthrough results by Limaye, Srinivasan, and Tavenas (FOCS 2021, STOC 2022) have demonstrated a potential avenue for obtaining lower bounds for general algebraic formulas, via strong enough lower bounds for set-multilinear formulas.

In this paper, we make progress along this direction by proving near-optimal lower bounds against low-depth as well
as unbounded-depth set-multilinear formulas.
More precisely, we show that over any field of characteristic zero, there is a polynomial $f$ computed by a polynomial-sized set-multilinear branching program (i.e., $f$ is in set-multilinear VBP) defined over $\Theta(n^2)$ variables and of degree $\Theta(n)$, such that any product-depth $\Delta$ set-multilinear formula computing $f$ has size at
least $n^{\Omega( n^{1/\Delta}/\Delta)}$. Moreover, we show that any unbounded-depth set-multilinear formula computing $f$ has size at least $n^{\Omega(\log n)}$.


If such strong lower bounds are proven for the iterated matrix multiplication (IMM) polynomial or rather, any polynomial
that is computed by an ordered set-multilinear branching program (i.e., a further restriction of set-multilinear VBP), then this would have dramatic consequences as it would imply super-polynomial lower bounds 
for general algebraic formulas (Raz, J. ACM 2013; Tavenas, Limaye, and Srinivasan, STOC 2022).

Prior to our work, either only weaker lower bounds were known for the IMM polynomial (Tavenas, Limaye, and Srinivasan, STOC 2022), or similar strong lower bounds were known but for a
hard polynomial not known to be even in set-multilinear VP (Kush and Saraf, CCC 2022; Raz, J. ACM 2009).

By known depth-reduction results, our lower bounds are essentially tight
for $f$ and in general, for any hard polynomial that is in set-multilinear VBP or set-multilinear VP.
Any asymptotic improvement in the lower bound (for a hard polynomial, say, in VNP) would imply super-polynomial lower bounds for general set-multilinear circuits.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The seminal work of Raz (J. ACM 2013) as well as the recent breakthrough results by Limaye, Srinivasan, and Tavenas (FOCS 2021, STOC 2022) have demonstrated a potential avenue for obtaining lower bounds for general algebraic formulas, via strong enough lower bounds for set-multilinear formulas.

In this paper, we make progress along this direction by proving near-optimal lower bounds against low-depth as well
as unbounded-depth set-multilinear formulas.
More precisely, we show that over any field of characteristic zero, there is a polynomial $f$ computed by a polynomial-sized set-multilinear branching program (i.e., $f$ is in set-multilinear VBP) defined over $\Theta(n^2)$ variables and of degree $\Theta(n)$, such that any product-depth $\Delta$ set-multilinear formula computing $f$ has size at
least $n^{\Omega( n^{1/\Delta}/\Delta)}$. Moreover, we show that any unbounded-depth set-multilinear formula computing $f$ has size at least $n^{\Omega(\log n)}$.


If such strong lower bounds are proven for the iterated matrix multiplication (IMM) polynomial or rather, any polynomial
that is computed by an ordered set-multilinear branching program (i.e., a further restriction of set-multilinear VBP), then this would have dramatic consequences as it would imply super-polynomial lower bounds 
for general algebraic formulas (Raz, J. ACM 2013; Tavenas, Limaye, and Srinivasan, STOC 2022).

Prior to our work, either only weaker lower bounds were known for the IMM polynomial (Tavenas, Limaye, and Srinivasan, STOC 2022), or similar strong lower bounds were known but for a
hard polynomial not known to be even in set-multilinear VP (Kush and Saraf, CCC 2022; Raz, J. ACM 2009).

By known depth-reduction results, our lower bounds are essentially tight
for $f$ and in general, for any hard polynomial that is in set-multilinear VBP or set-multilinear VP.
Any asymptotic improvement in the lower bound (for a hard polynomial, say, in VNP) would imply super-polynomial lower bounds for general set-multilinear circuits.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-27T15:04:14Z">Monday, February 27 2023, 15:04</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, February 26
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://minorfree.github.io/hz-spanner/'>Halperin-Zwick Algorithm for Spanners</a></h3>
        <p class='tr-article-feed'>from <a href='https://minorfree.github.io'>Hung Le</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This post describes a simple linear time algorithm by Halperin-Zwick [6] for constructing a \((2k-1)\)-spanner of unweighted graphs for any given integer \(k\geq 1\). The spanner has \(O(n^{1+1/k})\) edges and hence is sparse. When \(k = \log n\), it only has \(O(n)\) edges. This sparsity makes spanners an important object in many applications. This post was inspired by my past attempt to track down the detail of the Halperin-Zwick algorithm. Halperin and Zwick never published their algorithm, and all papers I am aware of cite their unpublished manuscript [6]. The algorithm by Halperin-Zwick is a simple modification of an earlier algorithm by Pelege and Schäffer [8], which, according to Uri Zwick, is the reason why they did not publish their result. The spanner by Pelege and Schäffer [8] has stretch \(4k-3\) for the same sparsity. The idea of Halperin-Zwick algorithm was given as Exercise 3 in Chapter 16 of the book by Peleg [7]. First, let’s define spanners. Graphs in this post are connected. \(t\)-Spanner: Given a graph \(G\), a \(t\)-spanner is a subgraph of \(G\), denoted by \(H\), such that for every two vertices \(u,v\in V(G)\): \[d_H(u,v)\leq t\cdot d_G(u,v)\] Here \(d_H\) and \(d_G\) denote the graph distances in \(H\) and in \(G\), respectively. Graph \(G\) could be weighted or unweighted; we only consider unweighted graphs in this post. The distance constraint on \(H\) implies that \(H\) is connected and spanning. Parameter \(t\) is called the stretch of the spanner. We often construct a spanner with an odd stretch: \(t = 2k-1\) for some integer \(k\geq 1\). Why not even stretches? Short answer: there is no gain in terms of the worst case bounds for even stretch [1].
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>This post describes a simple linear time algorithm by Halperin-Zwick [6] for constructing a \((2k-1)\)-spanner of unweighted graphs for any given integer \(k\geq 1\). The spanner  has \(O(n^{1+1/k})\) edges and hence is sparse. When \(k = \log n\), it only has \(O(n)\) edges.  This sparsity makes spanners an important object in many applications.</p>

<p>This post was inspired by my past attempt to track down the detail of the Halperin-Zwick algorithm. Halperin and Zwick never published their algorithm, and all papers I am aware of cite their unpublished manuscript [6]. The algorithm by Halperin-Zwick is a simple modification of an earlier algorithm by Pelege and Schäffer [8], which, according to Uri Zwick, is the reason why they did not publish their result. The spanner by Pelege and Schäffer [8] has stretch \(4k-3\) for the same sparsity. The idea of Halperin-Zwick algorithm was given as Exercise 3 in Chapter 16 of  the book by Peleg [7].</p>

<p>First, let’s define spanners. Graphs in this post are connected.</p>

<hr />
<p><strong>\(t\)-Spanner</strong>: Given a graph \(G\), a \(t\)-spanner is a subgraph of \(G\), denoted by \(H\),  such that for every two vertices \(u,v\in V(G)\):</p>

\[d_H(u,v)\leq t\cdot d_G(u,v)\]

<hr />

<p>Here \(d_H\) and \(d_G\) denote the graph distances in \(H\) and in \(G\), respectively. Graph \(G\) could be weighted or unweighted; we only consider unweighted graphs in this post. The distance constraint on \(H\) implies that \(H\) is connected and spanning.</p>

<p>Parameter \(t\) is called the <em>stretch</em> of the spanner. We often construct a spanner with an odd stretch: \(t = 2k-1\) for some integer \(k\geq 1\). Why not even stretches? Short answer: there is no gain in terms of the worst case bounds for even stretch [1].</p>

<hr />
<p><strong>Theorem</strong> (Halperin-Zwick): Let \(G\) be an unweighted graph with \(n\) vertices and \(m\) edges. Let \(k\geq 1\) be any given integer. There is an algorithm that runs in time \(O(m)\) and constructs a \((2k-1)\)-spanner of \(G\) with \(O(n^{1+1/k})\) edges.</p>

<hr />

<p>It is often instructive to think about \(k=2\), i.e, constructing a \(3\)-spanner. And this is where we start.</p>

<h1 id="stretch-3">Stretch 3</h1>

<p>Here we seek a \(3\)-spanner with \(O(n^{3/2})\) edges. There are two steps: clustering and connecting the clusters. Let’s focus on clustering first. The idea is to: construct a set of radius-1 clusters (a set of stars) that have at least \(\sqrt{n}\) vertices each. This implies that the number of clusters is \(O(\sqrt{n})\) and hence we can afford to add one edge from each vertex to each cluster. The remaining vertices induce a graph of at most \(O(n^{3/2})\); we can add all the edges.</p>

<p>The cluster can be constructed greedily; the pseudocode of the algorithm is given below. We use \(N_G(v)\) to denote neighbors of \(v\) in a graph \(G\).</p>

<hr />
<p><span style="font-variant: small-caps">Clustering</span>\((G)\)</p>
<blockquote>
  <p>\(1.\) \({\mathcal C} \leftarrow \emptyset, \quad G_1\leftarrow G\)<br />
\(2.\) while \(G_i \not= \emptyset\)<br />
\(3.\)      \(x\leftarrow\) an arbitrary vertex in \(G_i\)<br />
\(4.\)      \(C_x\leftarrow {x}\)<br />
\(5.\)      if \(\lvert N_{G_i}(x)\rvert  \geq \sqrt{n}\)<br />
\(6.\)            \(C_v\leftarrow C_v\cup N_{G_i}(x)\)<br />
\(7.\)      \({\mathcal C} \leftarrow {\mathcal C}\cup {C_x}\) <br />
\(8.\)       \(G_{i+1}\leftarrow G_i\setminus C_v, \quad i\leftarrow i+1\)<br />
\(9.\) return \({\mathcal C}\)</p>
</blockquote>

<hr />
<p>We call the vertex \(v\) in the cluster \(C_v\) in line 4 the <em>center</em> of the cluster. We use \(E(C_v)\) to the edges of \(G\) connecting \(v\) to other vertices in \(C_v\).</p>

<p>Observe  that every cluster \(C\in {\mathcal C}\) has radius at most \(1\) and it has either at least \(\sqrt{n}\) vertices or  exactly one vertex. We call \(C\) a <em>heavy cluster</em> if \(\lvert C \rvert\geq \sqrt{n}\), and a <em>light cluster</em> otherwise.</p>

<hr />
<p><strong>Observation 1</strong>: The number of heavy clusters in \({\mathcal C}\) is at most \(\sqrt{n}\).</p>

<hr />

<p>To get a 3-spanner of \(G\), we simply add an edge from every vertex to each heavy cluster of \({\mathcal C}\), and an edge between every pair of light clusters. (Light clusters are singletons.) 
***
 <span style="font-variant: small-caps">3Spanner</span>\((G)\)</p>
<blockquote>
  <p>\(1.\) \({\mathcal C} \leftarrow\)<span style="font-variant: small-caps">Clustering</span>\((G)\)<br />
\(2.\) \(H\leftarrow (V,\emptyset)\)<br />
\(3.\) for each heavy cluster \(C\in {\mathcal C}\)<br />
\(4.\)      add \(E(C)\) to \(H\)<br />
\(5\).      for each vertex \(v \in N_G(C)\)<br />
\(6.\)            \((v,u)\leftarrow\) an arbitrary edge from \(v\) to \(C\)<br />
\(7.\)            add \((u,v)\) to \(H\)<br />
\(8.\) add to \(H\) all edges between light clusters<br />
\(9.\) return \(H\)</p>
</blockquote>

<hr />

<p>In line 5, we use \(N_G(C)\) to denote the set of neighbors of \(C\), which are vertices are not in \(C\) and having at least one edge to \(C\).  The running time is clearly \(O(m)\).</p>

<p><strong>Sparsity analysis.</strong> Note that \(E(C)\leq \lvert C \rvert-1\). Thus, the total number of edges added to \(H\) in line 4 over all iterations is at most \(n-1\). Furthermore, the number of edges added to \(H\) in the loop in line 5 is at most \(n\) and hence by Observation 1, the total number of edges added in lines 3-7 is \(O(n\sqrt{n}) = O(n^{3/2})\).</p>

<p>To bound the number of edges added in line 8, observe that, if we order light clusters by the order it is added to \({\mathcal C}\) in line 7 of algorithm <span style="font-variant: small-caps">Clustering</span>, then each light cluster is incident to at most \(\sqrt{n}\) light clusters following it in the order. It follows that the total number of edges added in line 8 is \(O(n\sqrt{n}) = O(n^{3/2})\).</p>

<p><strong>Stretch analysis.</strong> We show that \(d_G(u,v)\leq 3 d_H(u,v)\). By the triangle inequality, it suffices to show the inequality for every edge \((u,v)\) of \(G\). This means we have to show that \(d_H(u,v)\leq 3\).  This inequality holds if \((u,v)\in E(H)\), and hence we only need to consider the case where at least one of \(u\) and \(v\) is in a heavy cluster.</p>

<p><img src="/assets/figs/clusters.svg" alt="" /></p>

<p><em>Figure 1: (a) stretch-3 path for edge \((u,v)\) and (b) stretch-\((2k-1)\) path for edge \((u,v)\)</em></p>

<p>If \(u\) and \(v\) are in the same heavy cluster \(C\), then \(d_H(u,v)\leq 2\) and the stretch guarantee holds. Otherwise, let \(C_x\) be the heavy cluster centered at \(x\) containing \(v\), say. As \((u,v)\not\in H\), there must be another vertex \(w\in C_x\) such that \((u,w)\in H\) by the construction in line 6. Thus, the path \(u\rightarrow w\rightarrow x\rightarrow v\) is a path of length 3 in \(H\) between \(u\) and \(v\), as desired. See Figure 1(a).</p>

<h1 id="larger-stretches">Larger Stretches</h1>

<p>The algorithm for constructing a \((2k-1)\)-spanner with \(O(n^{1+1/k})\) edges is somewhat similar to the stretch-3 case, but we will need a finer analysis. A key observation, which we also use in the 3-spanner construction, is that if we have a cluster, say \(C\), of radius \(k\), and a vertex \(v\in N_G(C)\), it suffices to keep only one edge from \(v\) to \(C\). Thus, as long as \(N_G(C)\) has at most \(n^{1/k}\lvert C \rvert\) vertices, we can add an edge from \(v\) to \(C\) for each \(v\in N_G(C)\); the <em>average number of edges added per vertex</em> of \(C\) is \(n^{1/k}\).</p>

<p>What if \(\lvert N_G(C) \rvert \geq n^{1/k}\lvert C \rvert\)? In this case, we simply grow \(C\) by adding all of its neighbors. How many times will it grow? At most \(k-1\) times, as every time \(C\) grows, its size increases by a factor of strictly larger than \(n^{1/k}\), and there are only \(n\) vertices in the graph.</p>

<p>The pseudocode of the algorithm is given below. The set \(A\) holds the edges between \(C\) and its neighbors described above. The rest is essentially the same as the clustering for stretch 3.</p>

<hr />
<p><span style="font-variant: small-caps">Clustering</span>\((G,k)\)</p>
<blockquote>
  <p>\(1.\) \({\mathcal C} \leftarrow \emptyset, \quad A\leftarrow \emptyset, \quad G_1\leftarrow G\)<br />
\(2.\) while \(G_i \not= \emptyset\)<br />
\(3.\)      \(x\leftarrow\) an arbitrary vertex in \(G_i\)<br />
\(4.\)      \(C_x\leftarrow {x}\)<br />
\(5.\)      while \(\lvert N_{G_i}(C_x)\rvert \geq n^{1/k} \lvert C_{x} \rvert\)<br />
\(6.\)            \(C_v\leftarrow C_x\cup N_{G_i}(C_x)\)<br />
\(7.\)      for each \(v \in N_{G_i}(C_x)\)<br />
\(8.\)            \((v,u)\leftarrow\) an arbitrary edge from \(v\) to \(C\)<br />
\(9.\)            add \((v,u)\) to \(A\)<br />
\(10.\)      \({\mathcal C} \leftarrow {\mathcal C}\cup {C_v}\) <br />
\(11.\)       \(G_{i+1}\leftarrow G_i\setminus C_v, \quad i\leftarrow i+1\)<br />
\(12.\) return \(({\mathcal C},A)\)</p>
</blockquote>

<hr />

<p>Once we perform clustering, we only need to add the set \(A\) and the edges inside each cluster to the spanner.</p>

<hr />
<p><span style="font-variant: small-caps">Spanner</span>\((G,k)\)</p>
<blockquote>
  <p>\(1.\) \(H\leftarrow (V,\emptyset)\)<br />
\(2.\) \(({\mathcal C},A) \leftarrow\)<span style="font-variant: small-caps">Clustering</span>\((G,k)\)<br />
\(3.\) add \(A\) to \(H\)<br />
\(4.\) for each cluster \(C\in {\mathcal C}\)<br />
\(5.\)      add \(E(C)\) to \(H\)<br />
\(6.\) return \(H\)</p>
</blockquote>

<hr />

<p><strong>Sparsity analysis.</strong> The number of edges added in the loop in line 4 is at most \(n-1\). Observe that for each cluster \(C_x\) added to \({\mathcal C}\) in line 6 of <span style="font-variant: small-caps">Clustering</span>, the number of edges added to \(A\) in the loop in line 7 is at most \(n^{1/k}\lvert C_{x} \rvert\). Thus, \(\lvert A \rvert\leq n^{1/k}\sum_{C}\lvert C \rvert \leq n^{1+1/k}\). This implies that \(\lvert E(H) \rvert = O(n^{1+1/k})\).</p>

<p><strong>Stretch analysis.</strong> Let \((u,v)\) be any edge of \(G\) such that \((u,v)\not\in H\). We need to show that \(d_H(u,v)\leq 2k-1\). Observe that:</p>

<hr />
<p><strong>Observation 2</strong>: Every cluster \(C_x\in {\mathcal C}\) has radius at most \(k-1\).</p>

<hr />
<p>Proof: Every time the radius of \(C_x\) increases by \(1\), the size of \(C_x\) increases by a factor of strictly larger than \(n^{1/k}\) by the construction. Thus, after \(t\) rounds, \(n\geq \lvert C_{x} \rvert &gt; n^{t/k}\), which gives \(t\leq k-1\).</p>

<hr />

<p>Let \(C_x\) be the cluster containing \(v\). If \(u\in C_x\), then \(d_G(u,v)\leq 2\cdot (k-1)\). Otherwise, suppose w.l.o.g, that \(v\) is clustered before \(u\). Observe that \(u\in N_{G_{i}}(C_x)\) and hence an edge \((u,w)\) is added to \(A\), which is eventually added to \(H\). See Figure 1(b). Thus, the path consisting of an edge \((u,w)\), the shortest path from \(w\) to \(x\), and the shortest path from \(x\) to \(v\), is a path of length at most \(2(k-1)+1 = 2k-1\) between \(u\) and \(v\) in \(H\), as desired.</p>

<h1 id="optimality-the-girth-conjecture">Optimality: The Girth Conjecture</h1>

<p>It is not hard to construct a class of graphs such that for any graph \(G\) of size \(n\) in the class, the Halperin-Zwick algorithm produces a \((2k-1)\)-spanner for \(G\) that has \(\Omega(n^{1+1/k})\) edges. Could we go below the bound \(\Theta(n^{1+1/k})\) on the number of edges (by a different algorithm, say)? The consensus seems to be no, though currently we do not have a definite answer.</p>

<p>Spanners have a tight connection to the girth of graphs; a graph has girth \(g\) if the shortest simple cycle in the graph has length \(g\).</p>

<hr />
<p><strong>Observation 3</strong>: Let \(H\) be a graph of girth \(2k+1\). Then any \((2k-1)\)-spanner of \(H\) must contain every edge of \(H\).</p>

<hr />

<p>Observation 3 essentially says that any \((2k-1)\)-spanner of \(H\) must be itself. Thus, the question of the optimality of spanners reduces to: is there any graph with \(o(n^{1+1/k})\) edges and girth \((2k+1)\)? The Erdős’ Girth Conjecture implies that the answer is no.</p>

<hr />
<p><strong>Erdős’ Girth Conjecture [5]</strong>: For any \(n \geq 1\) and \(k\geq 1\), there exists a graph with \(n\) vertices of girth \((2k+1)\) that has \(\Omega(n^{1+1/k})\) edges.</p>

<hr />

<p>Erdős stated a lower bound \(c_k\cdot n^{1+1/k}\) on the number of edges in the conjecture [5]; that is, the constant is allowed to degrade as \(k\) increases.  The spanner literature often cites the stronger version above, where the constant remains the same for every \(k\). The Erdős’ Girth Conjecture is known to hold for a few small values of \(k\).</p>

<p>While Erdős’ Girth Conjecture remains wide open, we could ask: is it possible to construct a \((2k-1)\)-spanner that has girth at least \(2k+1\)? If yes, then the output spanner is (existentially) optimal regardless of the truth of Erdős’ Girth Conjecture.</p>

<p>It turns out that the following simple greedy algorithm, formally described in [2] and attributed to Marshall Bern, does the job: consider edges in increasing weight order and add an edge \(e\) to the current spanner if the distance between its endpoints in the spanner is larger than \((2k-1)w(e)\). The algorithm works for weighted graphs as well. It is an instructive exercise to show that the output graph is a \((2k-1)\)-spanner and has girth at least \(2k+1\).</p>

<p>The major downsize of the greedy algorithm is its running time: the current best known implemtation takes \(O(mn^{1+1/k})\) time. Even in unweighted graphs, to the best of my knowledge, the following problem remains open:</p>

<hr />
<p><strong>Open Problem</strong>: Construct a maximal subgraph of girth at least \((2k+1)\) in nearly linear time.</p>

<hr />

<p>For an unweighted graph, a maximal subgraph of girth at least \((2k+1)\) is a \((2k-1)\)-spanner.</p>

<h1 id="conclusion">Conclusion</h1>

<p>We have mentioned two algorithms for constructing a spanner. Another beautiful algorithm that I hope to cover in a future post is the randomized construction by Baswana and Sen [4]. A notable feature of the Baswana-Sen algorithm is that it can be implemented efficiently in both parallel and distributed models. The recent survey paper [1] contains almost all known algorithms for spanners and its sibling problems.</p>

<h1 id="bibliographical-notes">Bibliographical Notes</h1>

<p>The concept of a spanner was formally introduced by Peleg and Schaffer [8], though its conception was much earlier. Peleg and Schaffer constructed a \((4k-3)\)-spanner with \(O(n^{1+1/k})\) edges by connecting every pair of clusters in the output of <span style="font-variant: small-caps">Clustering</span>\((G,k)\) by an edge. This clustering procedure was due to Awerbuch [2].</p>

<h1 id="references">References</h1>

<p>[1] Ahmed, R., Bodwin, G., Sahneh, F. D., Hamm, K., Jebelli, M. J. L., Kobourov, S., and Spence, R. (2020). Graph spanners: A tutorial review. Computer Science Review, 37, 100253.</p>

<p>[2] Althöfer, I., Das, G., Dobkin, D., Joseph, D., and Soares, J. (1993). On sparse spanners of weighted graphs. Discrete \&amp; Computational Geometry, 9(1), 81-100.</p>

<p>[3] Awerbuch, B. (1985). Complexity of network synchronization. Journal of the ACM (JACM), 32(4), 804-823.</p>

<p>[4] Baswana, S., and Sen, S. (2007). A simple and linear time randomized algorithm for computing sparse spanners in weighted graphs. Random Structures &amp; Algorithms, 30(4), 532-563.</p>

<p>[5] Erdős, P. (1965). Extremal problems in graph theory. In Proceedings of the Symposium on Theory of Graphs and its Applications, page 29-36, 1963.</p>

<p>[6] Halperin, S., and Zwick, U. (1996). Unpublished manuscript.</p>

<p>[7] Peleg, D. (2000). Distributed computing: a locality-sensitive approach. Society for Industrial and Applied Mathematics.</p>

<p>[8] Peleg, D., and Schäffer, A. A. (1989). Graph spanners. Journal of graph theory, 13(1), 99-116.</p><p class="authors">By Hung Le</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-26T00:00:00Z">Sunday, February 26 2023, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, February 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/'>STOC 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          STOC 2023 is the 55th Annual ACM Symposium on Theory of Computing. It will be held on June 20-23, 2023 in Orlando, Florida. Perhaps the best paper ever at STOC was by Stephen Cook. His 1971 STOC paper The Complexity of Theorem Proving Procedures formalized the notions of polynomial-time and started the search to prove [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<a href="http://acm-stoc.org/stoc2023/">STOC 2023</a> is the 55th Annual ACM Symposium on Theory of Computing. It will be held on June 20-23, 2023 in Orlando, Florida. </p>
<p>
Perhaps the best paper ever at STOC was by Stephen Cook. His 1971 STOC paper <a href="https://dl.acm.org/doi/10.1145/800157.805047">The Complexity of Theorem Proving Procedures</a> formalized the notions of polynomial-time and started the search to prove <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> is not equal to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BNP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{NP}" class="latex" />. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/cook/" rel="attachment wp-att-21168"><img data-attachment-id="21168" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/cook/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" data-orig-size="290,174" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cook" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?resize=290%2C174&#038;ssl=1" alt="" width="290" height="174" class="aligncenter size-full wp-image-21168" data-recalc-dims="1" /></a></p>
<p>
See <a href="https://en.wikipedia.org/wiki/Symposium_on_Theory_of_Computing">this</a> for more. </p>
<p>
<span id="more-21165"></span></p>
<p><H2> Papers with Pointers </H2></p>
<p><p>
Many web sites on STOC 2023 list the accepted papers but not with pointers. We planned to create these links ourself but we discovered this site that already has them:</p>
<p>
<a href="https://www.conference-publishing.com/list.php?Event=STOC23">List of papers</a> with pointers. </p>
<p>
This saved us having to create the pointers. Try them&#8212;fun to see the accepted papers.</p>
<p>
<p><H2> The Program Committee </H2></p>
<p><p>
Thanks to the program committee for working so hard on putting together such a terrific program. </p>
<ul>
<li>
Amir Abboud (Weizmann Institute of Science) </p>
<li>
Josh Alman (Columbia University) </p>
<li>
Andris Ambainis (University of Latvia) </p>
<li>
Nima Anari (Stanford University) </p>
<li>
Srinivasan Arunachalam (IBM Thomas J. Watson Research Center) </p>
<li>
Petra Berenbrink (Universitat Hamburg) </p>
<li>
Aaron Bernstein (Rutgers University) </p>
<li>
Aditya Bhaskara (University of Utah) </p>
<li>
Sayan Bhattacharya (University of Warwick) </p>
<li>
Eric Blais (University of Waterloo) </p>
<li>
Hans Bodlaender (Utrecht University) </p>
<li>
Adam Bouland (Stanford University) </p>
<li>
Anne Broadbent (University of Ottawa) </p>
<li>
Mark Bun (Boston University) </p>
<li>
Keren Censor-Hillel (Technion) </p>
<li>
Timothy Chan (University of Illinois at Urbana-Champaign) </p>
<li>
Arkadev Chattopadhyay (Tata Institute of Fundamental Research) </p>
<li>
Chandra Chekuri (University of Illinois at Urbana-Champaign) </p>
<li>
Xue Chen (University of Science and Technology of China) </p>
<li>
Gil Cohen (Tel Aviv University) </p>
<li>
Dana Dachman-Soled (University of Maryland College Park) </p>
<li>
Anindya De (University of Pennsylvania) </p>
<li>
Shahar Dobzhinski (Weizmann Institute of Science) </p>
<li>
Shaddin Dughmi (University of Southern California) </p>
<li>
Vida Dujmovic (University of Ottawa) </p>
<li>
Yuval Filmus (Technion) </p>
<li>
Sumegha Garg (Stanford University) </p>
<li>
Rong Ge (Duke University) </p>
<li>
Elena Grigorescu (Purdue University) </p>
<li>
Shuichi Hirahara (National Institute of Informatics, Japan) </p>
<li>
Zhiyi Huang (University of Hong Kong) </p>
<li>
Sungjin Im (University of California, Merced) </p>
<li>
Giuseppe Italiano (LUISS University) </p>
<li>
Ken-ichi Kawarabayashi (National Institute of Informatics, Japan) </p>
<li>
Sanjeev Khanna (University of Pennsylvania) </p>
<li>
Robin Kothari (Google Research) </p>
<li>
Marvin Kunnemann (TU Kaiserslautern) </p>
<li>
Rasmus Kyng (ETH Zurich) </p>
<li>
Sophie Laplante (Universite Paris Cite) </p>
<li>
Hung Le (University of Massachusetts, Amherst) </p>
<li>
Daniel Lokshtanov (University of California, Santa Barbara) </p>
<li>
Sepideh Mahabadi (Microsoft Research) </p>
<li>
Nicole Megow (Universitat Bremen) </p>
<li>
Slobodan Mitrovic (University of California, Davis) </p>
<li>
Ankur Moitra (Massachusetts Institute of Technology) </p>
<li>
Shay Moran (Technion and Google Research) </p>
<li>
Christopher Musco (New York University) </p>
<li>
Krzysztof Onak (Boston University) </p>
<li>
Rotem Oshman (Tel Aviv University) </p>
<li>
Prasad Raghavendra (University of California, Berkeley) </p>
<li>
Susanna Rezende (Lund University) </p>
<li>
Robert Robere (McGill University) </p>
<li>
Alon Rosen (Bocconi University and Reichman University) </p>
<li>
Ron Rothblum (Technion) </p>
<li>
Alex Russell (University of Connecticut) </p>
<li>
Laura Sanita (Bocconi University) </p>
<li>
Thatchaphol Saranurak (University of Michigan) </p>
<li>
Tselil Schramm (Stanford University) </p>
<li>
Rocco Servedio (Columbia University), Chair </p>
<li>
Tasos Sidiropoulos (University of Illinois at Chicago) </p>
<li>
Alex Slivkins (Microsoft Research) </p>
<li>
Srikanth Srinivasan (Aarhus University) </p>
<li>
David Steurer (ETH Zurich) </p>
<li>
Ola Svensson (EPFL) </p>
<li>
Chaitanya Swamy (University of Waterloo) </p>
<li>
Madhur Tulsiani (Toyota Technological Institute at Chicago) </p>
<li>
Christos Tzamos (University of Wisconsin-Madison) </p>
<li>
Muthu Venkitasubramaniam (Georgetown University) </p>
<li>
Ben Lee Volk (Reichman University) </p>
<li>
Andreas Wiese (Technical University of Munich) </p>
<li>
Mary Wootters (Stanford University) </p>
<li>
Yuichi Yoshida (National Institute of Informatics, Japan) </p>
<li>
Huacheng Yu (Princeton University)
</ul>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
I hope having the list of accepted papers with links is of some value. Cook&#8217;s paper might be the best ever, but it did not get the award for best paper at the time. Here are some of the more recent <a href="https://www.sigact.org/prizes/best_paper.html">best papers</a>:</p>
<p>
2020	<a href="https://arxiv.org/abs/1908.08483">Improved Bounds for The Sunflower Lemma</a> <br />
2019	<a href="https://arxiv.org/abs/1809.07115">The Reachability Problem for Petri Nets is Not Elementary</a> </p>
<p>
I like the second one above for personal reasons that I expounded long ago <a href="https://rjlipton.wpcomstaging.com/2009/04/08/an-expspace-lower-bound/">here</a>, and which Ken expanded on <a href="https://rjlipton.wpcomstaging.com/2015/07/12/the-long-reach-of-reachability/">here</a>. </p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-25T23:40:51Z">Saturday, February 25 2023, 23:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/02/25/isohedral-delaunay-complexes.html'>Isohedral Delaunay complexes</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Delaunay complex of a set of points in the Euclidean plane partitions the convex hull of the points into polygonal cells. Each cell is the convex hull of a co-circular subset of the points whose circle does not contain any more points. It’s often called a Delaunay triangulation, because for points in general position the cells are all triangles, but I do not want to assume general position here. It is isohedral when all of the cells are symmetric to each other (maybe a little more strong than asking for them all to have the same shape). For example, the familiar tilings of the plane by squares or regular hexagons are both isohedral and Delaunay. Another example is a tiling of the plane by 60°–90°–120° kites:
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Delaunay complex of a set of points in the Euclidean plane partitions the convex hull of the points into polygonal cells. Each cell is the convex hull of a co-circular subset of the points whose circle does not contain any more points. It’s often called a <a href="https://en.wikipedia.org/wiki/Delaunay_triangulation">Delaunay triangulation</a>, because for points in <a href="General position">general position</a> the cells are all triangles, but I do not want to assume general position here. It is <a href="https://en.wikipedia.org/wiki/Isohedral_figure">isohedral</a> when all of the cells are symmetric to each other (maybe a little more strong than asking for them all to have the same shape). For example, the familiar tilings of the plane by squares or regular hexagons are both isohedral and Delaunay. Another example is a <a href="https://en.wikipedia.org/wiki/Deltoidal_trihexagonal_tiling">tiling of the plane by 60°–90°–120° kites</a>:</p>

<p style="text-align:center"><img src="/blog/assets/2023/tetrille-delaunay.svg" alt="Tiling of the plane by 60°–90°–120° kites, with shading showing that the circumcircles of each site are empty of other tiling vertices" style="width:100%;max-width:720px" /></p>

<p>Some other tilings, even very symmetric ones, might not be Delaunay. For instance, it is impossible to make a Delaunay version of the <a href="https://en.wikipedia.org/wiki/Cairo_pentagonal_tiling">Cairo pentagonal tiling</a> because its tiles have two complementary angles or two right angles, impossible for a co-circular pentagon.</p>

<p>In these cases, the symmetries are of the familiar kind, translations and rotations of the plane. But translation symmetry forces us to use infinitely many points. Can finite Delaunay complexes be isohedral? Sort of, maybe, but with a different kind of symmetry.
You can translate between Delaunay complexes on the plane and on a sphere by <a href="https://en.wikipedia.org/wiki/Stereographic_projection">stereographic projection</a>, and translations, rotations, and scaling in the plane become Möbius transformations on the sphere. So the projection onto the sphere of a square grid becomes a spherical Delaunay complex that is symmetric under Möbius transformations.</p>

<p style="text-align:center"><img src="/blog/assets/2023/stereographic-square-tiling.svg" alt="Stereographic projection of a square grid from the plane to a sphere" title="CC-BY-SA 4.0 image https://commons.wikimedia.org/wiki/File:Stereogr-proj-netz.svg by Ag2gaeh from Wikimedia commons" style="width:100%;max-width:720px" /></p>

<p>Rotations of the sphere are also a very special case of Möbius transformations, so we can look for Delaunay complexes with rotational symmetries. Suppose you have a polyhedron all of whose vertices lie on a sphere, and all of whose faces are symmetric to each other by rotations of the sphere. Then the intersection of the sphere with any face plane of the polyhedron is a circle through the vertices of a face that does not contain any other vertices, the defining property of a Delaunay cell. So these polyhedra are isohedral spherical Delaunay complexes. This is true, for instance, for the Platonic solids and for the two infinite families of <a href="https://en.wikipedia.org/wiki/Bipyramid">bipyramids</a> and the <a href="https://en.wikipedia.org/wiki/Trapezohedron">trapezohedra</a> but false for some other isohedral polyhedra like the <a href="https://en.wikipedia.org/wiki/Rhombic_dodecahedron">rhombic dodecahedron</a> and <a href="https://en.wikipedia.org/wiki/Triakis_tetrahedron">triakis tetrahedron</a> whose vertices cannot all be placed on a sphere.</p>

<p>You can map these spherical Delaunay complexes back onto the plane by stereographic projection again. You might think that the result is always a planar Delaunay complex in which all faces are symmetric to each other under Möbius transformation, but there’s a catch. The projection preserves circles, but it turns inside out the ones that contain the pole of the projection. If they were empty on the sphere, they instead turn into circles in the plane that contain every other point. These inside-out circles correspond to Delaunay cells on the sphere that do not map to Delaunay cells in the plane. For instance, projecting the cube vertices back down to the plane with the pole at the midpoint of a cube edge produces a Delaunay complex with only four quadrilaterals; the other two faces of the cube come from inside-out circles and do not become Delaunay cells.</p>

<p style="text-align:center"><img src="/blog/assets/2023/cube-edge-projection.svg" alt="Delaunay complex of a cube, stereographically projected onto the plane with its pole at an edge midpoint" style="width:100%;max-width:720px" /></p>

<p>All of this generalizes directly to 3d Delaunay triangulations, and to isohedral 4d polytopes with cospherical vertices, but less is known about what shapes are possible. The regular 4-polytopes, certainly, have symmetric facets and cospherical vertices, but there are other possibilities as well. The <a href="http://www.polytope.net/hedrondude/dice4.htm">isohedral 4-polytopes with up to 20 sides</a> have been classified, but I don’t know which of these can have cospherical vertices.</p>

<p>There are, at least, three different infinite families of isohedral 4d polytopes with cospherical vertices, analogous to the bipyramids and trapezohedra. To describe this, it helps to think of four-dimensional Euclidean space as having two complex numbers \(\alpha\) and \(\beta\) as coordinates, and the unit sphere as the points for which \(\vert\alpha\vert^2+\vert\beta\vert^2=1\). These are the state vectors of a <a href="https://en.wikipedia.org/wiki/Qubit">qubit</a>, so we can write these points on the sphere using <a href="https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation">quantum notation</a> as \(\alpha\,\vert0\rangle+\beta\,\vert1\rangle\), where \(\vert0\rangle\) and \(\vert1\rangle\) are just the two basis vectors for the two-complex-number coordinate system. In this notation, consider the following three sets of points, all on the unit sphere, for integer parameters \(n\) and \(m\):</p>

<ul>
  <li>
    <p>Let \(X\) be the set of \(n\) points \(e^{2\pi i/n}\,\vert0\rangle\), for the integers \(i\) with \(0\le i\lt n\). These form a regular \(n\)-gon in the plane \(\beta=0\).</p>
  </li>
  <li>
    <p>Let \(Y\) be the set of \(m\) points \(e^{2\pi j/m}\,\vert1\rangle\), for the integers \(j\) with \(0\le j\lt n\). These form a regular \(m\)-gon, in the perpendicular plane \(\alpha=0\).</p>
  </li>
  <li>
    <p>Let \(Z\) be the set of \(mn\) points</p>

\[\frac{1}{\sqrt 2}e^{2\pi i/n}\,\vert0\rangle + \frac{1}{\sqrt 2}e^{2\pi j/m}\,\vert1\rangle,\]

    <p>for the same ranges of \(i\) and \(j\). These lie on a <a href="https://en.wikipedia.org/wiki/Flat_torus">flat torus</a>, the Cartesian product of two circles, and form the vertices of a tiling of the torus by rectangles.</p>
  </li>
</ul>

<p>Then the convex hull of \(X\cup Y\) has as its facets \(mn\) congruent tetrahedra, each formed as the convex hull of an edge of the \(X\)-polygon and an edge of the \(Y\)-polygon. The convex hull of \(Z\) is a <a href="https://en.wikipedia.org/wiki/Duoprism">duoprism</a> whose facets are two kinds of prisms: the Cartesian product of an edge of the \(X\)-polygon with the whole \(Y\)-polygon, and vice versa. When \(n=m\) these two prisms are congruent and the resulting duoprism is isohedral, and dual to the convex hull of \(X\cup Y\). Here is a stereographic projection for \(n=m=18\), taken from the <a href="https://www.math.cmu.edu/~fho/jenn/polytopes/index.html">Jenn 3d website</a>:</p>

<p style="text-align:center"><img src="/blog/assets/2023/18x18-torus.png" alt="Stereographic projection into 3d of a 4-dimensional polytope, the (18,18)-duoprism, appearing as a torus tiled with squares" title="Public domain image https://www.math.cmu.edu/~fho/jenn/polytopes/18x18-torus.png" style="width:100%;max-width:720px" /></p>

<p>In this image, the most prominent feature is the tiling by squares of the torus containing \(Z\). If you follow sequences of edges of this square grid, through opposite edges at each vertex, you will also see many 18-gons. Some of the 18-gons slice the “inside” of the torus radially into distorted prisms; these are Delaunay cells. Many of the perpendicular 18-gons slice across the “donut hole” of the torus, forming more Delaunay cells. But some of the remaining 18-gons lie on the convex hull of the shape, and cannot be used as slices for the projected set. The missing slices cause the Delaunay triangulation of the stereographic projection to miss some cells, and that can only happen because the spheres for these cells were inverted by the projection.</p>

<p>You can also take the convex hull of \(X\cup Y\cup Z\). This has two triangular-prism facets for each tetrahedron of \(X\cup Y\), meeting at one of the squares of \(Z\). The reason I’m interested in this example comes from <a href="/blog/2023/02/20/geometric-graphs-unbounded.html">my most recent post, on flip-width of geometric graphs</a>. If you take an induced subgraph of this polytope, consisting only of the points in \(X\cup Y\cup Z\) whose coefficients \(i\) and \(j\) are both even, the result is a subdivided complete bipartite graph \(K_{n,n}\), where by “subdivided” I mean that each edge of \(K_{n,n}\) has been replaced by a two-edge path. This isn’t an interchange, in the sense of the previous post, but it has unbounded flip-width, because it is a sparse graph that does not have bounded expansion.</p>

<p>What I really want, though, is a 3d Euclidean Delaunay triangulation with unbounded flip-width, not a non-triangulation complex and not a 4-polytope (I already had one of those in my previous post). To get this, use a stereographic projection whose pole is on the central torus, in the middle of one of the squares (or really on the corresponding point of the unit sphere), and note that the Delaunay spheres of the polytope faces will intersect this torus in Delaunay circles of the squares. But for a square grid, the center of each square belongs only to the circumcircle of that square, not to any of the other circumcircles. So the pole of the projection will only belong to two of the Delaunay spheres, the two sharing the chosen square. The two prisms for these two spheres will be missing from the Delaunay complex (instead, their union, some sort of <a href="https://en.wikipedia.org/wiki/Gyrobifastigium">gyrobifastifium</a>, will form the convex hull of the points), but all the other prisms will still be present. They contain all the edges of the graph, so it still contains a large induced subdivided biclique. Perturbing the points slightly to get a triangulation rather than a complex doesn’t change this.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/109926574982696332">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-25T09:19:00Z">Saturday, February 25 2023, 09:19</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, February 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/24/postdoc-at-tu-eindhoven-university-of-amsterdam-leiden-university-cwi-apply-by-march-31-2023/'>postdoc at TU Eindhoven, University of Amsterdam, Leiden University, CWI (apply by March 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Postdoc Positions in Algorithmics and Stochastics, in the NETWORKS project (the Netherlands). The NETWORKS project is a collaboration of researchers from four institutions in The Netherlands: TU Eindhoven, University of Amsterdam, Leiden University and the Centrum Wiskunde &#38; Informatica (CWI). NETWORKS has openings for postdocs working on algorithmics or stochastics for network problems. Website: www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND- [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Postdoc Positions in Algorithmics and Stochastics, in the NETWORKS project (the Netherlands).</p>
<p>The NETWORKS project is a collaboration of researchers from four institutions in The Netherlands: TU Eindhoven, University of Amsterdam, Leiden University and the Centrum Wiskunde &amp; Informatica (CWI). NETWORKS has openings for postdocs working on algorithmics or stochastics for network problems.</p>
<p>Website: <a href="https://www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND-">https://www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND-</a><br />
Email: info@thenetworkcenter.nl</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T12:53:26Z">Friday, February 24 2023, 12:53</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, February 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/02/23/mathematics-of-the-impossible-computational-complexity-chapter-5-completeness-reducing-arbitrary-computation/'>Mathematics of the impossible: Computational Complexity, Chapter 5, Completeness: Reducing arbitrary computation</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this chapter we show how to reduce arbitrary computation to 3Sat (and hence to the other problems in section&#160;º4.3). What powers everything is the following landmark and, in hindsight, simple result which reduces circuit computation to 3Sat. Theorem 5.1. Given a circuit with gates we can compute in a 3CNF formula in variables such [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p style="text-align:justify">In this chapter we show how to reduce arbitrary computation to 3Sat (and hence to the other problems in section&nbsp;º<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a>). What powers everything is the following landmark and, in hindsight, simple result which reduces circuit computation to 3Sat.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-56001r1"></a> <b>Theorem</b> 5.1.  </span> Given a circuit <img src="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> gates we can compute in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> a 3CNF formula <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=n%2Bs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Bs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Bs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n+s" class="latex" /> variables such that for every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" />:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bs%7D%3Af_%7BC%7D%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bs%7D%3Af_%7BC%7D%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bs%7D%3Af_%7BC%7D%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} C(x)=1&#92;Leftrightarrow &#92;exists y&#92;in &#92;{0,1&#92;} ^{s}:f_{C}(x,y)=1. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The key idea to <em>guess computation and check it efficiently, using that computation is local.</em> The additional <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> variables one introduces contain the values of the gates during the computation of <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />. We simply have to check that they all correspond to a valid computation, and this can be written as 3CNF because each gate depends on at most two other gates.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Introduce a variable <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i}" class="latex" /> for each non-input gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. The value of <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i}" class="latex" /> is intended to be the value of gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" /> during the computation. Whether the value of a gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" /> is correct is a function of <img src="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3" class="latex" /> variables: <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i}" class="latex" /> and the <img src="https://s0.wp.com/latex.php?latex=%5Cle+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 2" class="latex" /> gates that input <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" />, some of which could be input variables. This can be written as a 3CNF by Theorem <a href="#x1-25003r3">2.3<!--tex4ht:ref: thm:every-function-ckt-Lupanov --></a>. Take an And of all these 3CNFs. Finally, add clause <img src="https://s0.wp.com/latex.php?latex=y_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{o}" class="latex" /> for the output gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{o}" class="latex" />. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-56002r1"></a> <b>Exercise</b> 5.1.  </span>Write down the 3CNF for the circuit in figure&nbsp;<a href="#x1-240062">2.2<!--tex4ht:ref: fig:Ckt --></a>, as given by the proof of Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> is <em>a depth-reduction</em> result. Indeed, note that a 3CNF can be written as a circuit of depth <img src="https://s0.wp.com/latex.php?latex=c%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log s" class="latex" />, whereas the original circuit may have any depth. This is helpful for example if you don’t have the depth to run the circuit yourself. You can let someone else produce the computation, and you can check it in small depth.</p>
<p style="text-align:justify">   We can combine Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> with the simulations in Chapter <a href="#x1-180002">2<!--tex4ht:ref: chap:The-alphabet-of --></a> to reduce computation in other models to 3SAT. In particular, we can reduce MTMs running in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> to 3Sat of size <img src="https://s0.wp.com/latex.php?latex=t%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;log ^{c}t" class="latex" />. To obtain such parameters we need the quasilinear simulation of MTMs by circuits, Theorem <a href="#x1-25007r5">2.5<!--tex4ht:ref: thm:simu-TMs-by-CKTs-quasi-linear --></a>.</p>
<p style="text-align:justify">   However, recall that a quasilinear simulation of RAMs by circuits is not known. Only a power simulation is (which is obtained by combining the power simulation of RAMs by MTMs, Theorem <a href="#x1-26003r6">2.6<!--tex4ht:ref: thm:simu-RAM-by-TM --></a>, with a simulation of MTMs by circuits). This would reduce RAM computation running in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> to 3CNFs of size <img src="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t^{c}" class="latex" />. We content ourselves with this power loss for the beginning of this chapter. Later in section&nbsp;º<a href="#x1-610005.3">5.3<!--tex4ht:ref: sec:RAM-to-SAT-quasilinear --></a> we will obtain a quasi-linear simulation using an enjoyable argument which also bypasses Theorem <a href="#x1-25007r5">2.5<!--tex4ht:ref: thm:simu-TMs-by-CKTs-quasi-linear --></a>.</p>
<p style="text-align:justify">   In fact, these simulations apply to a more general, <em>non-deterministic</em>, model of computation. We define this model next, and then present the simulation with power loss in <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>.</p>
<h3 class="sectionHead"><span class="titlemark">5.1   </span> <a id="x1-570005.1"></a>Nondeterministic computation</h3>
<p style="text-align:justify">In the concluding equation in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> there is an <img src="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists " class="latex" /> quantifier on the right-hand side, but there isn’t one on the left, next to the circuit. However, because the simulation works for every input, we can “stick” a quantifier on the left and have the same result. The resulting circuit computation <img src="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(x,y)" class="latex" /> has two inputs, <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. We can think of it as a <em>non-deterministic</em> circuit, which on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> outputs <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> iff <img src="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists y:C(x,y)" class="latex" />. Following the discussion before, we could do the same for other models like TMs, MTMs, and RAMs. The message here is that – if we allow for an <img src="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists " class="latex" /> quantifier, or in other words consider nondeterministic computation – efficient computation is <em>equivalent</em> to 3CNF! This is one motivation for formally introducing a <em>nondeterministic </em>computational model.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-57001r1"></a> <b>Definition</b> 5.1.  </span>NTime<img src="https://s0.wp.com/latex.php?latex=%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(t(n))" class="latex" /> is the set of functions <img src="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:X&#92;subseteq &#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> for which there is a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> such that:</p>
<p style="text-align:justify">   &#8211; <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=1" class="latex" /> iff <img src="https://s0.wp.com/latex.php?latex=%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28%7Cx%7C%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28%7Cx%7C%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28%7Cx%7C%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists y&#92;in &#92;{0,1&#92;} ^{t(|x|)}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)=1" class="latex" />, and</p>
<p style="text-align:justify">   &#8211; <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)" class="latex" /> stops within <img src="https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(|x|)" class="latex" /> steps on every input <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" />.</p>
<p style="text-align:justify">   We also define</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNP%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%28n%5E%7Bd%7D%29%2C%5C%5C+%5Ctext+%7BNExp%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%282%5E%7Bn%5E%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNP%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%28n%5E%7Bd%7D%29%2C%5C%5C+%5Ctext+%7BNExp%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%282%5E%7Bn%5E%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNP%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%28n%5E%7Bd%7D%29%2C%5C%5C+%5Ctext+%7BNExp%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%282%5E%7Bn%5E%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {NP}:= &amp; &#92;bigcup _{d&#92;ge 1}&#92;text {NTime}(n^{d}),&#92;&#92; &#92;text {NExp}:= &amp; &#92;bigcup _{d&#92;ge 1}&#92;text {NTime}(2^{n^{d}}). &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Note that the running time of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is a function of <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|" class="latex" />, not <img src="https://s0.wp.com/latex.php?latex=%7C%28x%2Cy%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7C%28x%2Cy%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7C%28x%2Cy%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|(x,y)|" class="latex" />. This difference is inconsequential for NP, since the composition of two powers is another power. But it is important for a more fine-grained analysis. We refer to a RAM machine as in Definition <a href="#x1-57001r1">5.1<!--tex4ht:ref: def:NTime --></a> as a <em>nondeterministic machine</em>, and to the <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)" class="latex" /> as the <em>nondeterministic choices,</em> or <em>guesses, </em>of the machine on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align:justify">   We can also define NTime in a way that is similar to BPTime, Definition <a href="#x1-27001r7">2.7<!--tex4ht:ref: def:BPTime-BPP --></a>. The two definitions are essentially equivalent. Our choice for BPTime is motivated by the identification of BPTime with computation that is actually run. For example, in a programming language one uses an instruction like Rand to obtain random values; one does not think of the                                                                                                                                                                                     randomness as being part of the input. By contrast, NTime is a more abstract model, and the definition with the nondeterministic guesses explicitly laid out is closer in spirit to a 3CNF.</p>
<p style="text-align:justify">   All the problems we studied in section&nbsp;º<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a> are in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-57002r1"></a> <b>Fact</b> 5.1.  </span>3Sat, Clique, Cover-by-vertexes, SubsetSum, and 3Color are in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>For a 3Sat instance <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />, the variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> correspond to an assignment. Checking if the assignment satisfies <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is in P. This shows that 3Sat is in NP. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-57003r2"></a> <b>Exercise</b> 5.2.  </span>Finish the proof by ad<br />
dressing the other problems in Fact <a href="#x1-57002r1">5.1<!--tex4ht:ref: fact:3Sa-etc-in-NP --></a></p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h5 class="likesubsubsectionHead"><a id="x1-580005.1"></a>How to think of NP</h5>
<p style="text-align:justify">We can think of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> as the problems which admit a solution that can be verified efficiently, namely in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. For example for 3Sat it is easy to verify if an assignment satisfies the clauses, for 3Color it is easy to verify if a coloring is such that any edge has endpoints of different colors, for SubsetSum it is easy to verify if a subset has a sum equal to a target, and so on. However, as we saw above this verification step can be cast in a restricted model, namely a 3CNF. So we don’t have to think of the verification step as using the full power of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> computation.</p>
<p style="text-align:justify">   Here’s a vivid illustration of NP. Suppose I claim that the following matrix contains a <img src="https://s0.wp.com/latex.php?latex=9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="9" class="latex" />:</p>
<div style="text-align:center">
<div class="fbox">
<div class="minipage">56788565634705634705637480563476</p>
<p style="text-align:justify">70156137805167840132838202386421</p>
<p style="text-align:justify">85720582340570372307580234576423</p>
<p style="text-align:justify">80275880237505788075075802346518</p>
<p style="text-align:justify">78502378564067807582348057285428</p>
<p style="text-align:justify">05723748754543650350562378804337</p>
<p style="text-align:justify">52305723485008160234723884077764</p>
<p style="text-align:justify">86543234567865435674567836738063</p>
<p style="text-align:justify">45463788486754345743457483460040</p>
<p style="text-align:justify">73273873486574375464584895741832</p>
<p style="text-align:justify">85075783485634856237847287422112</p>
<p style="text-align:justify">83748874883753485745788788223201</p>
</div>
</div>
</div>
<p style="text-align:justify">   How can you tell, without tediously examining the whole matrix? However, if I tell you that it’s in row 10, 8 digits from the right, you can quickly check that I am right. I won’t be able to cheat, since you can check my claims. On the other hand I can provide a proof that’s easy to verify.</p>
<p style="text-align:justify">
<h5 class="likesubsubsectionHead"><a id="x1-590005.1"></a>P vs.&nbsp;NP</h5>
<p style="text-align:justify">The flagship question of complexity theory is whether <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}=&#92;text {NP}" class="latex" /> or not. This is a young, prominent special case of the grand challenge we introduced in Chapter <a href="#x1-370003">3<!--tex4ht:ref: chap:The-grand-challenge --></a>. Contrary to the analogous question for <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}" class="latex" />, cf.&nbsp;section&nbsp;<a href="#x1-290002.5.2">2.5.2<!--tex4ht:ref: subsec:BPTime-vs-time --></a>, the general belief seems to be that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}&#92;ne &#92;text {NP}" class="latex" />. Similarly to BPP, cf.&nbsp;Theorem <a href="#x1-29001r9">2.9<!--tex4ht:ref: thm:Time-vs-BPTime --></a>, the best deterministic simulation of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> runs in exponential time by trying all nondeterministic guesses. This gives the middle inclusion in the following fact; the other two are by definition.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-59001r2"></a> <b>Fact</b> 5.2.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Csubseteq+%5Ctext+%7BNP%7D%5Csubseteq+%5Ctext+%7BExp+%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BNExp%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Csubseteq+%5Ctext+%7BNP%7D%5Csubseteq+%5Ctext+%7BExp+%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BNExp%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Csubseteq+%5Ctext+%7BNP%7D%5Csubseteq+%5Ctext+%7BExp+%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BNExp%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}&#92;subseteq &#92;text {NP}&#92;subseteq &#92;text {Exp &#92;ensuremath {&#92;subseteq &#92;text {NExp}}}" class="latex" />.</p>
<p style="text-align:justify">   A consequence of the Time Hierarchy Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a> is that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}&#92;ne &#92;text {Exp}" class="latex" />. From the inclusions above it follows that</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D%5Ctext+%7B+or+NP%7D%5Cne+%5Ctext+%7BExp%2C+possibly+both%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D%5Ctext+%7B+or+NP%7D%5Cne+%5Ctext+%7BExp%2C+possibly+both%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D%5Ctext+%7B+or+NP%7D%5Cne+%5Ctext+%7BExp%2C+possibly+both%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {P}&#92;ne &#92;text {NP}&#92;text { or NP}&#92;ne &#92;text {Exp, possibly both}. &#92;end{aligned}" class="latex" /></div>
<p>Thus, we are not completely clueless, and we know that at least one important separation is lurking somewhere. Most people appear to think that <em>both</em> separations hold, but we are unable to prove <em>either</em>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   For multi-tape machines, a separation between deterministic and non-deterministic linear time is in <span class="cite">[<a href="#XPPST83">24</a>,&nbsp;<a href="conf/coco/Santhanam01">27</a>]</span>.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.2   </span> <a id="x1-600005.2"></a>NP-completeness</h3>
<p style="text-align:justify">We now go back to the question at the beginning of this chapter about reducing arbitrary computation to 3Sat. We shall reduce all of NP to 3Sat in Theorem <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>. Problems like 3Sat admitting such reductions deserve a definition.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60001r2"></a> <b>Definition</b> 5.2.  </span>We call a problem <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" />:</p>
<p style="text-align:justify">   NP-hard if every problem in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />;</p>
<p style="text-align:justify">   NP-complete if it is NP-hard and in NP.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   One can define <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" />-hard (and hence NP-complete) w.r.t.&nbsp;different reductions, cf.&nbsp;Chapter <a href="#x1-450004">4<!--tex4ht:ref: chap:Reductions --></a>, and we will do so later. But the simple choice above suffices for now.</p>
<p style="text-align:justify">   Complete problems are the “hardest problems” in the class, as formalized in the following fact.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60002r3"></a> <b>Fact</b> 5.3.  </span>Suppose <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {L}" class="latex" /> is NP-complete. Then <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CLeftrightarrow+%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CLeftrightarrow+%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CLeftrightarrow+%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {P}&#92;Leftrightarrow &#92;text {P}=&#92;text {NP}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span><img src="https://s0.wp.com/latex.php?latex=%28%5CLeftarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5CLeftarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5CLeftarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;Leftarrow )" class="latex" /> This is because <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {NP}" class="latex" />.</p>
<p style="text-align:justify">   (<img src="https://s0.wp.com/latex.php?latex=%5CRightarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CRightarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CRightarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Rightarrow )" class="latex" /> Let <img src="https://s0.wp.com/latex.php?latex=L%27%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%27%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%27%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#039;&#92;in &#92;text {NP}" class="latex" />. Because <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> is NP-hard we know that <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%5Censuremath+%7B%5CRightarrow+L%27%5Cin+%5Ctext+%7BP%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%5Censuremath+%7B%5CRightarrow+L%27%5Cin+%5Ctext+%7BP%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%5Censuremath+%7B%5CRightarrow+L%27%5Cin+%5Ctext+%7BP%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {P&#92;ensuremath {&#92;Rightarrow L&#039;&#92;in &#92;text {P}}.}" class="latex" /> <b>QED</b></p>
</div>
<p style="text-align:justify">   Fact <a href="#x1-60002r3">5.3<!--tex4ht:ref: fact:np-complete-in-P-iff-p=00003Dnp --></a> points to an important interplay between problems and complexity classes. We can study complexity classes by studying their complete problems, and vice versa.</p>
<p style="text-align:justify">   The central result in the theory of NP completeness is the following.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60003r2"></a> <b>Theorem</b> 5.2.  </span><span class="cite">[<a href="#XCook73">7</a>,&nbsp;<a href="#XLevin73">20</a>]</span> 3Sat is NP-complete.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>3Sat is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> by Fact <a href="#x1-57002r1">5.1<!--tex4ht:ref: fact:3Sa-etc-in-NP --></a>. Next we prove NP-hardness. The main idea is Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>, while the rest of the proof mostly amounts to opening up definitions and using some previous simulations. Let <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {NP}" class="latex" /> and let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be the corresponding TM which runs in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{d}" class="latex" /> on inputs <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|=n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Cy%7C%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cy%7C%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cy%7C%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|y|=n^{d}" class="latex" />, for some constant <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />. We can work with TMs instead of RAMs since they are equivalent up to a power loss, as we saw in Theorem <a href="#x1-26003r6">2.6<!--tex4ht:ref: thm:simu-RAM-by-TM --></a>. We can construct in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P }" class="latex" />a circuit <img src="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(x,y)" class="latex" /> of size <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7Dn%5E%7Bc_%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7Dn%5E%7Bc_%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7Dn%5E%7Bc_%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}n^{c_{d}}" class="latex" /> such that for any <img src="https://s0.wp.com/latex.php?latex=x%2Cy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%2Cy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%2Cy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x,y" class="latex" /> we have <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1%5CLeftrightarrow+C%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1%5CLeftrightarrow+C%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1%5CLeftrightarrow+C%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)=1&#92;Leftrightarrow C(x,y)=1" class="latex" /> by Theorem <a href="#x1-25006r4">2.4<!--tex4ht:ref: thm:simu-tm-by-ckts-simple --></a>.</p>
<p style="text-align:justify">   Now, suppose we are given an input <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> for which we are trying to decide membership in <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" />. This is equivalent to deciding if <img src="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28w%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28w%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28w%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists y:C(w,y)=1" class="latex" /> by what we just said. We can “hard-wire” <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> into <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> to obtain the circuit <img src="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3A%3DC%28w%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3A%3DC%28w%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3A%3DC%28w%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{w}(y):=C(w,y)" class="latex" /> only on the variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />, with no loss in size. Here by “hard-wise” se mean replacing the input gates <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> with the bits of <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" />. Now we can apply Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> to this new circuit to produce a 3CNF <img src="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{w}" class="latex" /> on variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> and new variables <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+z%3Af%28y%2Cz%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+z%3Af%28y%2Cz%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+z%3Af%28y%2Cz%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{w}(y)=1&#92;Leftrightarrow &#92;exists z:f(y,z)=1" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. The size of <img src="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{w}" class="latex" /> and the number of variables <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> is power in the size of the circuit.</p>
<p style="text-align:justify">   We have obtained:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+w%5Cin+L%5CLeftrightarrow+%5Cexists+y%3AM%28w%2Cy%29%3D1%5CLeftrightarrow+%5Cexists+y%3AC_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+y%2Cz%3Af_%7Bw%7D%28y%2Cz%29%3D1%5CLeftrightarrow+f_%7Bw%7D%5Cin+%5Ctext+%7B3Sat%2C%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+w%5Cin+L%5CLeftrightarrow+%5Cexists+y%3AM%28w%2Cy%29%3D1%5CLeftrightarrow+%5Cexists+y%3AC_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+y%2Cz%3Af_%7Bw%7D%28y%2Cz%29%3D1%5CLeftrightarrow+f_%7Bw%7D%5Cin+%5Ctext+%7B3Sat%2C%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+w%5Cin+L%5CLeftrightarrow+%5Cexists+y%3AM%28w%2Cy%29%3D1%5CLeftrightarrow+%5Cexists+y%3AC_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+y%2Cz%3Af_%7Bw%7D%28y%2Cz%29%3D1%5CLeftrightarrow+f_%7Bw%7D%5Cin+%5Ctext+%7B3Sat%2C%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} w&#92;in L&#92;Leftrightarrow &#92;exists y:M(w,y)=1&#92;Leftrightarrow &#92;exists y:C_{w}(y)=1&#92;Leftrightarrow &#92;exists y,z:f_{w}(y,z)=1&#92;Leftrightarrow f_{w}&#92;in &#92;text {3Sat,} &#92;end{aligned}" class="latex" /></div>
<p>as desired. <b>QED</b></p>
</div>
<p style="text-align:justify">   In section&nbsp;º<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a> we reduced 3Sat to other problems which are also in NP by Fact <a href="#x1-57002r1">5.1<!--tex4ht:ref: fact:3Sa-etc-in-NP --></a>. This implies that all these problems are NP-complete. Here we use that if problem <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> in P, and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />, then also <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. This is because if <img src="https://s0.wp.com/latex.php?latex=C%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in &#92;text {P}" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B&#92;in &#92;text {P}" class="latex" />, and so <img src="https://s0.wp.com/latex.php?latex=A%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A&#92;in &#92;text {P}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60004r1"></a> <b>Corollary</b> 5.1.  </span> Clique, Cover-by-vertexes, Subset-sum, and 3Color are NP-complete.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   It is important to note that there is nothing special about the <em>existence</em> of NP-complete problems. The following is a simple such problem that does not require any of the machinery in this section.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60005r3"></a> <b>Exercise</b> 5.3.  </span>Consider the problem, given a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, an input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;in &#92;mathbb {N}" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is written in unary, decide if there is <img src="https://s0.wp.com/latex.php?latex=y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y&#92;in &#92;{0,1&#92;} ^{t}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)=1" class="latex" />. Prove that this is NP-complete.</p>
<p style="text-align:justify">   What if <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is written in binary?</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The interesting aspect of NP-complete problems such as 3Sat and those in Corollary <a href="#x1-60004r1">5.1<!--tex4ht:ref: cor:all-probs-NP-complete --></a> is that they are very simple and structured, and don’t refer to computational models. This makes them suitable for reductions, and for inferring properties of the complexity class which are not evident from a machine-based definition.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.3   </span> <a id="x1-610005.3"></a>From RAM to 3SAT in quasi-linear time</h3>
<p style="text-align:justify">The framework in the previous section is useful to relate membership in P of different problems in NP, but it is not suitable for a more fine-grained analysis. For example, under the assumption that 3Sat is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(cn)" class="latex" /> we cannot immediately conclude that other problems in NP are solvable in this time or in about this time. We can only conclude that they are in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. In particular, the complexity of 3Sat cannot be related to that of other central conjectures, such as whether 3Sum is in subquadratic time, Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a>.</p>
<p style="text-align:justify">   The culprit is the power loss in reducing RAM computation to circuits, mentioned at the beginning of the chapter. We now remedy this situation and present a quasi-linear reduction. As we did before, cf.&nbsp;Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> and Theorem <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>, we first state a version of the simulation for (deterministic) computation which contains all the main ideas, and then we note that a completeness result follows.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-61001r3"></a> <b>Theorem</b> 5.3.  </span>Given an input length <img src="https://s0.wp.com/latex.php?latex=n%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;in &#92;mathbb {N}" class="latex" />, a time bound <img src="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;in &#92;mathbb {N}" class="latex" />, and a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> that runs in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> on inputs of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits, we can compute in time <img src="https://s0.wp.com/latex.php?latex=t%27%3A%3Dc_%7BM%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27%3A%3Dc_%7BM%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27%3A%3Dc_%7BM%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;:=c_{M}t(&#92;log t)^{c}" class="latex" /> a 3CNF <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> on variables <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%7Cy%7C%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cy%7C%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cy%7C%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|y|&#92;le t&#039;" class="latex" /> such that for every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" />:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%28x%29%3D1%5Ciff+%5Cexists+y%3Af%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%28x%29%3D1%5Ciff+%5Cexists+y%3Af%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%28x%29%3D1%5Ciff+%5Cexists+y%3Af%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} M(x)=1&#92;iff &#92;exists y:f(x,y)=1. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We now present the proof of this amazing result; you may want to refer back to Definition <a href="#x1-26001r5">2.5<!--tex4ht:ref: def:RAM --></a> of a RAM. A key concept in the proof is the following “snapshot” of the RAM computation.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-61002r3"></a> <b>Definition</b> 5.3.  </span>The <em>internal configuration, </em>abbreviated IC<em>, </em>of a RAM specifies:</p>
<ul class="itemize1">
<li class="itemize">its registers,</li>
<li class="itemize">the program counter,</li>
<li class="itemize">the word length <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" />, and</li>
<li class="itemize">if the current instruction is a Read <img src="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{i}:=&#92;mu [r_{j}]" class="latex" /> or Write <img src="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D%3A%3Dr_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D%3A%3Dr_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D%3A%3Dr_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mu [r_{j}]:=r_{i}" class="latex" /> then the IC includes the content <img src="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mu [r_{j}]" class="latex" /> of the       memory cell indexed by <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" />.</li>
</ul>
</div>
<p style="text-align:justify">   Note that at most one memory cell is included in one IC. By contrast, the configuration of a TM (Definition <a href="#x1-19001r1">2.1<!--tex4ht:ref: def:TM --></a>) includes all its tape cells. Also note that an IC has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}+c&#92;log t" class="latex" /> bits, where the <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}" class="latex" /> is for the program counter, and the <img src="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log t" class="latex" /> is for the rest, using that the maximum word length of a machine running in time <img src="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge n" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log t" class="latex" />.</p>
<p style="text-align:justify"><span class="paragraphHead"><a id="x1-620005.3"></a>The key idea in the proof.</span>    At the high level, the approach is, like in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>, to guess computation and check it efficiently. We are going to <em>guess </em>the sequence of ICs, and we need additional ideas to check them efficiently by a circuit. This is not immediate, since, again, the RAM can use direct access to read and write in memory at arbitrary locations, something which is not easy to do with a circuit.</p>
<p style="text-align:justify">   The key idea is to check operations involving memory <em>independently </em>from the operations involving registers but not memory. If both checks pass, then the computation is correct. More precisely, a sequence of internal configurations <img src="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{1},s_{2},&#92;ldots ,s_{t}" class="latex" /> corresponds to the computation of the RAM on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> iff for every <img src="https://s0.wp.com/latex.php?latex=i%3Ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3Ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3Ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&lt;t" class="latex" />:
</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-62002x1">If <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i}" class="latex" /> does not access memory, then <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i+1}" class="latex" /> has its registers, program counter, and word length       updated according to the instruction executed in <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i}" class="latex" />,</li>
<li class="enumerate" id="x1-62004x2">If <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i}" class="latex" /> is computing a read operation <img src="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Ctext+%7B%5Censuremath+%7B%5Cmu+%5Br_%7Bj%7D%5D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Ctext+%7B%5Censuremath+%7B%5Cmu+%5Br_%7Bj%7D%5D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Ctext+%7B%5Censuremath+%7B%5Cmu+%5Br_%7Bj%7D%5D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{i}:=&#92;text {&#92;ensuremath {&#92;mu [r_{j}]}}" class="latex" /> then in <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i+1}" class="latex" /> register <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" /> contains <em>the most recent value       written in memory cell <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" /></em>. In case this cell was never written, then <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" /> should contain <img src="https://s0.wp.com/latex.php?latex=x_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{j}" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j&#92;in &#92;{1,2,&#92;ldots ,n&#92;}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />       if <img src="https://s0.wp.com/latex.php?latex=j%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j=0" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> otherwise. The program counter in <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i+1}" class="latex" /> also points to the next instruction.</li>
</ol>
<p style="text-align:justify">Rather than directly constructing a 3CNF that implements these checks, we construct a circuit and then appeal to Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>. It is easy to construct a circuit of quasi-linear size implementing Check 1, since the circuit only has to check adjacent pairs of ICs. As remarked before, these ICs have length <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}+c&#92;log t" class="latex" />. For fixed <img src="https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i," class="latex" /> Check 1 can be implemented by a circuit which depends on the RAM and has size power in the length of an IC. Taking an And of these circuits over the choices of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> gives a circuit of the desired size for Check 1.</p>
<p style="text-align:justify">   The difficulty lies in Check 2, because the circuit needs to find “the most recent value written.” The solution is to <em>sort</em> the ICs by memory addresses. After sorting, we can implement Check (2) as easily as Check (1), since we just need to check adjacent pairs of ICs.</p>
<p style="text-align:justify">   The emergence of sorting in the theory of NP-completeness cements the pivotal role this operation plays in computer science.</p>
<p style="text-align:justify">   To implement this idea we need to be able to sort with a quasi-linear size circuit. Standard sorting algorithms like Mergesort, Heapsort, or Radixsort run in quasi-linear time on a RAM, but rely on direct addressing (cf.&nbsp;section&nbsp;º<a href="#x1-260002.4">2.4<!--tex4ht:ref: sec:RAMs --></a>) and for this reason cannot be easily implemented by a circuit of quasi-linear size. However other algorithms have been developed that do have such an implementation, for example a variant of Mergesort called Odd-Even-Mergesort <span class="cite">[<a href="#XBatcher68">6</a>]</span>, see also <span class="cite">[<a href="#XViolaNEU-ram2sat-neu-author">22</a>]</span>. This gives the following lemma.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-62005r1"></a> <b>Lemma</b> 5.1.  </span>Given <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> we can compute in time <img src="https://s0.wp.com/latex.php?latex=t%27%3A%3Dt%5Ccdot+%28m%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27%3A%3Dt%5Ccdot+%28m%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27%3A%3Dt%5Ccdot+%28m%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;:=t&#92;cdot (m&#92;log t)^{c}" class="latex" /> a circuit (of size <img src="https://s0.wp.com/latex.php?latex=%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le t&#039;" class="latex" />) that sorts <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> integers of <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> bits.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We summarize the key steps in the proof.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-61001r3">5.3<!--tex4ht:ref: thm:redux-RAM-2-3cnf-quasilinear --></a></b>.&nbsp;</span> We construct a circuit <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> and then appeal to Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>. The extra variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> correspond to <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> ICs <img src="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{1},s_{2},&#92;ldots ,s_{t}" class="latex" />. An IC takes <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}+c&#92;log t" class="latex" /> bits to specify, so we need <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7Dt%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7Dt%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7Dt%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}t&#92;log t" class="latex" /> variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. The circuit <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> first performs Check (1) above for each adjacent pair <img src="https://s0.wp.com/latex.php?latex=%28s_%7Bi%7D%2Cs_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28s_%7Bi%7D%2Cs_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28s_%7Bi%7D%2Cs_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(s_{i},s_{i+1})" class="latex" /> of ICs. This takes size <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}&#92;log ^{c}t" class="latex" /> for each pair, and so size <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}t&#92;log ^{c}t" class="latex" /> overall.</p>
<p style="text-align:justify">   Then <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> sorts the ICs by memory addresses, producing sorted ICs <img src="https://s0.wp.com/latex.php?latex=s%27_%7B1%7D%2Cs%27_%7B2%7D%2C%5Cldots+%2Cs%27_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%27_%7B1%7D%2Cs%27_%7B2%7D%2C%5Cldots+%2Cs%27_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%27_%7B1%7D%2Cs%27_%7B2%7D%2C%5Cldots+%2Cs%27_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#039;_{1},s&#039;_{2},&#92;ldots ,s&#039;_{t}" class="latex" />. This takes size <img src="https://s0.wp.com/latex.php?latex=t%5Ccdot+%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Ccdot+%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Ccdot+%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;cdot &#92;log ^{c}t" class="latex" /> by Lemma <a href="#x1-62005r1">5.1<!--tex4ht:ref: lem:sorting-ckt-quasilinear --></a>, using that the memory addresses have <img src="https://s0.wp.com/latex.php?latex=%5Cle+c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c&#92;log t" class="latex" /> bits. Then the circuit performs Check (2) for each adjacent pair <img src="https://s0.wp.com/latex.php?latex=%28s%27_%7Bi%7D%2Cs%27_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28s%27_%7Bi%7D%2Cs%27_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28s%27_%7Bi%7D%2Cs%27_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(s&#039;_{i},s&#039;_{i+1})" class="latex" /> of ICs. The circuit size required for this is no more than for Check (1).</p>
<p style="text-align:justify">   Finally, the circuit takes an And of the results of the two checks, and also checks that <img src="https://s0.wp.com/latex.php?latex=s_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{t}" class="latex" /> is accepting. <b>QED</b></p>
</div>
<p style="text-align:justify">   We can now prove completeness in a manner similar to Theorem <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>, with a relatively simple extension of Theorem <a href="#x1-61001r3">5.3<!--tex4ht:ref: thm:redux-RAM-2-3cnf-quasilinear --></a>.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-62006r4"></a>                                                                                                                                                                                     <b>Theorem</b> 5.4.  </span>Every problem <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NTime}(t)" class="latex" /> map reduces to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28c_%7BL%2Ct%7Dt%5Clog+%5E%7Bc%7Dt%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28c_%7BL%2Ct%7Dt%5Clog+%5E%7Bc%7Dt%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28c_%7BL%2Ct%7Dt%5Clog+%5E%7Bc%7Dt%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(c_{L,t}t&#92;log ^{c}t)" class="latex" />, for every function <img src="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge n" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(x)" class="latex" /> is computable in time <img src="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(x)" class="latex" /> given <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The assumption on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is similar to that in the hierarchy Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>, and is satisfied by all standard functions including all those in this book – cf.&nbsp;discussion after Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be a RAM computing <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> in the assumed time. Given an input <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> we have to efficiently compute a 3CNF <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> such that</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28n%29%7D%3AM%28w%2Cy%29%3D1%5Ciff+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bc_%7BL%2Ct%7Dt%28n%29%5Clog+%5E%7Bc%7Dt%28n%29%7D%3Af%28y%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28n%29%7D%3AM%28w%2Cy%29%3D1%5Ciff+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bc_%7BL%2Ct%7Dt%28n%29%5Clog+%5E%7Bc%7Dt%28n%29%7D%3Af%28y%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28n%29%7D%3AM%28w%2Cy%29%3D1%5Ciff+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bc_%7BL%2Ct%7Dt%28n%29%5Clog+%5E%7Bc%7Dt%28n%29%7D%3Af%28y%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;exists y&#92;in &#92;{0,1&#92;} ^{t(n)}:M(w,y)=1&#92;iff &#92;exists y&#92;in &#92;{0,1&#92;} ^{c_{L,t}t(n)&#92;log ^{c}t(n)}:f(y)=1. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   First we compute <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />, using the assumption. We now apply Theorem <a href="#x1-61001r3">5.3<!--tex4ht:ref: thm:redux-RAM-2-3cnf-quasilinear --></a>, but on a new input length <img src="https://s0.wp.com/latex.php?latex=n%27%3A%3Dc%28n%2Bt%29%5Cle+ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%27%3A%3Dc%28n%2Bt%29%5Cle+ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%27%3A%3Dc%28n%2Bt%29%5Cle+ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#039;:=c(n+t)&#92;le ct" class="latex" />, to accommodate for inputs of the form <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" />. This produces a formula <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> of size <img src="https://s0.wp.com/latex.php?latex=c_%7BL%2Ct%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BL%2Ct%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BL%2Ct%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{L,t}t(&#92;log t)^{c}" class="latex" /> in variables <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" /> and new variables <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" />. We can now set <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> and conclude the proof. <b>QED</b></p>
</div>
<p style="text-align:justify">   With these sharper results we can now study hardness and completenss within time bounds such as <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=n%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;log ^{3}n" class="latex" /> etc. We work out an example in the next section.</p>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.3.1   </span> <a id="x1-630005.3.1"></a>Quasilinear-time completeness</h4>
<p style="text-align:justify">In this section we use the machinery we just developed to study completeness in quasi-linear time, instead of power time.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63001r4"></a> <b>Definition</b> 5.4.  </span>We define the quasi-linear time complexity classes</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BQLin-Time%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BTime%7D%28n%5Clog+%5E%7Bd%7Dn%29%5Ctext+%7B+and%7D%5C%5C+%5Ctext+%7BQLin-NTime%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BNTime%7D%28n%5Clog+%5E%7Bd%7Dn%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BQLin-Time%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BTime%7D%28n%5Clog+%5E%7Bd%7Dn%29%5Ctext+%7B+and%7D%5C%5C+%5Ctext+%7BQLin-NTime%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BNTime%7D%28n%5Clog+%5E%7Bd%7Dn%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BQLin-Time%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BTime%7D%28n%5Clog+%5E%7Bd%7Dn%29%5Ctext+%7B+and%7D%5C%5C+%5Ctext+%7BQLin-NTime%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BNTime%7D%28n%5Clog+%5E%7Bd%7Dn%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {QLin-Time}:= &amp; &#92;bigcup _{d&#92;in &#92;mathbb {N}}&#92;text {Time}(n&#92;log ^{d}n)&#92;text { and}&#92;&#92; &#92;text {QLin-NTime}:= &amp; &#92;bigcup _{d&#92;in &#92;mathbb {N}}&#92;text {NTime}(n&#92;log ^{d}n). &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63002r5"></a> <b>Theorem</b> 5.5.  </span>3Sat is complete for QLin-NTime with respect to mapping reductions in QLin-Time. That is:</p>
<p style="text-align:justify">   &#8211; 3Sat is in QLin-NTime, and</p>
<p style="text-align:justify">   &#8211; every problem in QLin-NTime map reduces to 3Sat in QLin-Time.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>To show that 3Sat is in QLin-NTime, consider a 3CNF instance <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />. This instance has at most <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> variables, and we can guess an assignment <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> to them within our budget of non-deterministic guesses. There remains to verify that <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> satisfies <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />. For this, we can do one pass over the clauses. For each clause, we access the bits in <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> corresponding to the 3 variables in the clause, and check if the clause is satisfied. This takes constant time per clause, and so time <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> overall.</p>
<p style="text-align:justify">   The second part follows from Theorem <a href="#x1-62006r4">5.4<!--tex4ht:ref: thm:redux-NTime-3Sat --></a>, using the fact that the composition of two quasilinear functions is also quasilinear (similarly to the fact that the composition of two power functions is also a power). <b>QED</b></p>
</div>
<p style="text-align:justify">   Note that the proof that 3Sat is in QLin-NTime relies on our computational model being a RAM, because we use direct access to fetch the values for the variables in a clause.</p>
<p style="text-align:justify">   We can now give the following quasi-linear version of Fact <a href="#x1-60002r3">5.3<!--tex4ht:ref: fact:np-complete-in-P-iff-p=00003Dnp --></a>. The only extra observation for the proof is again that the composition of two quasi-linear functions is quasi-linear.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63003r2"></a> <b>Corollary</b> 5.2.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BQLin-NTime%7D%5CLeftrightarrow+%5Ctext+%7BQLin-NTime%7D%3D%5Ctext+%7BQLin-Time.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BQLin-NTime%7D%5CLeftrightarrow+%5Ctext+%7BQLin-NTime%7D%3D%5Ctext+%7BQLin-Time.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BQLin-NTime%7D%5CLeftrightarrow+%5Ctext+%7BQLin-NTime%7D%3D%5Ctext+%7BQLin-Time.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {QLin-NTime}&#92;Leftrightarrow &#92;text {QLin-NTime}=&#92;text {QLin-Time.}" class="latex" /></p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63004r4"></a> <b>Exercise</b> 5.4.  </span>Prove that Theorem <a href="#x1-63002r5">5.5<!--tex4ht:ref: thm:3Sat-is-complete-quasilinear --></a> holds with 3Color instead of 3Sat. What about Clique and Subset-sum?</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63005r5"></a>                                                                                                                                                                                     <b>Exercise</b> 5.5.  </span>Prove that 3Sum reduces to 3Sat in Subquadratic time. That is: <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {SubquadraticTime&#92;ensuremath {&#92;Rightarrow &#92;text {3Sum}&#92;in &#92;text {SubquadraticTime}} (i.e., }" class="latex" />Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a> is false).</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.4   </span> <a id="x1-640005.4"></a>Completeness in other classes</h3>
<p style="text-align:justify">The completeness phenomenon is not special to NP but enjoyed by many other classes. In this section we begin to explore completeness for NExp and Exp. One needs to be careful how hardness (and hence completeness) is defined, since these classes are known to be different from <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> by the hierarchy Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>. So defining a problem <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> to be NExp-hard if <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BNExp%7D%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BNExp%7D%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BNExp%7D%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {P}&#92;Rightarrow &#92;text {NExp}=&#92;text {P}" class="latex" /> would mean simply that <img src="https://s0.wp.com/latex.php?latex=L%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;not &#92;in &#92;text {P}" class="latex" />. To avoid this in this section hardness (hence completeness) is defined w.r.t.&nbsp;mapping reductions, cf.&nbsp;Chapter <a href="#x1-450004">4<!--tex4ht:ref: chap:Reductions --></a>. (Another option would be to replace <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> with say <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}" class="latex" />, since it is not known if <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D%3D%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D%3D%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D%3D%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}=&#92;text {NExp}" class="latex" />.)</p>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.4.1   </span> <a id="x1-650005.4.1"></a>NExp completeness</h4>
<p style="text-align:justify">Complete problems for NExp include <em>succinct</em> versions of problems complete for NExp. Here succinct means that rather than giving the input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to the problem in standard format, the input consists instead of a circuit <img src="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bm%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bm%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bm%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C:&#92;{0,1&#92;} ^{m}&#92;to &#92;{0,1&#92;} " class="latex" /> encoding <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, for example <img src="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(i)" class="latex" /> equals bit <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, for every <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-65001r5"></a> <b>Definition</b> 5.5.  </span>The Succinct-3Sat problem: Given a circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> encoding a 3CNF <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" />, does <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" /> have a satisfying assignment?</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-65002r6"></a> <b>Theorem</b> 5.6.  </span>Succinct-3Sat  is  NExp  complete  with  respect  to  power-time  mapping reductions.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof sketch.</b>.&nbsp;</span> Let us first show that Succinct-3Sat is in NExp. Given a circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, we can run it on every possible input (of length <img src="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n" class="latex" />) and write down the formula <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" /> encoded by <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. This formula has size <img src="https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 2^{n}" class="latex" />. We can then use the fact that 3Sat is in NP to decide satisfiability of this formula in non-deterministic power time in <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{n}" class="latex" />, that is <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%282%5E%7Bcn%7D%29%5Csubseteq+%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%282%5E%7Bcn%7D%29%5Csubseteq+%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%282%5E%7Bcn%7D%29%5Csubseteq+%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NTime}(2^{cn})&#92;subseteq &#92;text {NExp}" class="latex" />.</p>
<p style="text-align:justify">   To prove NExp hardness it is convenient to work with TMs rather than RAMs. The main observation is that in the simulation of a TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on an input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> by a circuit <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" />, Theorem <a href="#x1-25006r4">2.4<!--tex4ht:ref: thm:simu-tm-by-ckts-simple --></a>, the circuit is very regular, in the sense that we can construct another circuit <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> which is a succinct encoding of <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" />. The circuit <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> is given as input indexes to gates in <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> and outputs the type of the gate and its wires. The size of <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> is power in the index length and <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />. Thus, if <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> has size <img src="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t^{c}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> only needs size <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log ^{c}t" class="latex" />. If <img src="https://s0.wp.com/latex.php?latex=t%3D2%5E%7Bn%5E%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%3D2%5E%7Bn%5E%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%3D2%5E%7Bn%5E%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t=2^{n^{d}}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> has size power in <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, as desired. The transformation from circuit to 3CNF in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> is also regular and can be done succinctly. <b>QED</b></p>
</div>
<p style="text-align:justify">   As a consequence, we obtain the following “concrete” problem not in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-65003r3"></a> <b>Corollary</b> 5.3.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSuccinct-3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSuccinct-3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BSuccinct-3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Succinct-3Sat}&#92;not &#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.4.2   </span> <a id="x1-660005.4.2"></a>Exp-completeness</h4>
<p style="text-align:justify">Exp-complete problems include several two-player games. The important feature for completeness is that the game may last for an exponential number of steps (otherwise it would belong to a class believed to be stricter which we will investigate in Chapter ??). These games include (generalized versions of) Chess <span class="cite">[<a href="journals/jct/FraenkelL81">8</a>]</span> and Checkers <span class="cite">[<a href="journals/siamcomp/Robson84">26</a>]</span>.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.5   </span> <a id="x1-670005.5"></a>Power from completeness</h3>
<p style="text-align:justify">The realization that arbitrary computation can be reduced to 3Sat and other problems is powerful and liberating. In particular it allows us to significantly widen the net of reductions.</p>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.5.1   </span> <a id="x1-680005.5.1"></a>Optimization problems</h4>
<p style="text-align:justify">As observed in section&nbsp;º<a href="#x1-540004.6">4.6<!--tex4ht:ref: sec:Gap-SAT:-The-PCP --></a>, 3Sat trivially reduces to Max-3Sat. The converse will be shown next.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-68001r7"></a> <b>Theorem</b> 5.7.  </span>Max-3Sat reduces to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Consider the problem Atleast-3Sat: Given a 3CNF formula and an integer <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />, is there an assignment that satisfies at least <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> clauses? This is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> and so can be reduced to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. This is the step that’s not easy without “thinking completeness:” given an algorithm for 3Sat it isn’t clear how to use it directly to solve Atleast-3Sat.</p>
<p style="text-align:justify">   Hence, if 3Sat is in P so is Atleast-3Sat. On input a 3CNF <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />, using binary search and the fact that Atleast-3Sat is in P, we can find in P the largest <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> s.t.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%28f%2Ct%29%5Cin+%5Ctext+%7BAtleast-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28f%2Ct%29%5Cin+%5Ctext+%7BAtleast-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28f%2Ct%29%5Cin+%5Ctext+%7BAtleast-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(f,t)&#92;in &#92;text {Atleast-3Sat}" class="latex" />. Having found this <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />, there remains to construct an assignment satisfying the clauses. This can be done fixing one variable at the time as in Theorem <a href="#x1-52002r5">4.5<!--tex4ht:ref: thm:Search-3Sat-power-time-reduces --></a>. <b>QED</b></p>
</div>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.5.2   </span> <a id="x1-690005.5.2"></a>NP is as easy as detecting unique solutions</h4>
<p style="text-align:justify">A satisfiable 3CNF can have multiple satisfying assignments. On the other hand some problems and puzzles have unique solutions. In this section we relate these two scenarios.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69001r6"></a>                                                                                                                                                                                     <b>Definition</b> 5.6.  </span>Unique-CktSat is the problem: Given a circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> s.t.&nbsp;there is at most one input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> for which <img src="https://s0.wp.com/latex.php?latex=C%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(x)=1" class="latex" />, decide if such an input exists.</p>
<p style="text-align:justify">   Unique-3Sat is the Unique-CktSat problem restricted to 3CNF circuits.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69002r8"></a> <b>Theorem</b> 5.8.  </span> <span class="cite">[<a href="journals/tcs/ValiantV86">33</a>]</span> 3Sat reduces to Unique-3Sat in BPP.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We in fact reduce 3Sat to Unique-CktSat. Then Unique-CktSat can be reduced to Unique-3Sat observing that the reduction in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> preserves uniqueness.</p>
<p style="text-align:justify">   The beautiful proof uses a powerful and general technique in randomized computation: <em>pairwise uniformity</em>, sometimes more generically referred to as <em>hashing. </em>We first define such functions and give efficient constructions. Then we show how to use them to “isolate” assignments.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69003r7"></a> <b>Definition</b> 5.7.  </span>A distribution <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> on functions mapping <img src="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S&#92;to T" class="latex" /> is called <em>pairwise uniform</em> if for every <img src="https://s0.wp.com/latex.php?latex=x%2Cx%27%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%2Cx%27%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%2Cx%27%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x,x&#039;&#92;in S" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y%2Cy%27%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%2Cy%27%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%2Cy%27%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y,y&#039;&#92;in T" class="latex" /> one has</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BH%7D%5BH%28x%29%3Dy%5Cwedge+H%28x%27%29%3Dy%27%5D%3D1%2F%7CT%7C%5E%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BH%7D%5BH%28x%29%3Dy%5Cwedge+H%28x%27%29%3Dy%27%5D%3D1%2F%7CT%7C%5E%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BH%7D%5BH%28x%29%3Dy%5Cwedge+H%28x%27%29%3Dy%27%5D%3D1%2F%7CT%7C%5E%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{H}[H(x)=y&#92;wedge H(x&#039;)=y&#039;]=1/|T|^{2}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   This is saying that on every pair of inputs <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> is behaving as a completely uniform function. Yet unlike completely uniform functions, the next lemma shows that pairwise uniform functions can have a short description, which makes them suitable for use in algorithms.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69004r6"></a> <b>Exercise</b> 5.6.  </span>Let <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{q}" class="latex" /> be a finite field. Define the random function <img src="https://s0.wp.com/latex.php?latex=H%3A%5Cmathbb+%7BF%7D_%7Bq%7D%5Cto+%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%3A%5Cmathbb+%7BF%7D_%7Bq%7D%5Cto+%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%3A%5Cmathbb+%7BF%7D_%7Bq%7D%5Cto+%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H:&#92;mathbb {F}_{q}&#92;to &#92;mathbb {F}_{q}" class="latex" /> as <img src="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3DAx%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3DAx%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28x%29%3A%3DAx%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(x):=Ax+B" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A,B" class="latex" /> are uniform in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{q}" class="latex" />.</p>
<p style="text-align:justify">   Prove that <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> is pairwise uniform.</p>
<p style="text-align:justify">   Explain how to use <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> to obtain a pairwise uniform function from <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{t}" class="latex" /> for any given <img src="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;le n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69005r7"></a> <b>Exercise</b> 5.7.  </span>Define the random function <img src="https://s0.wp.com/latex.php?latex=H_%7B1%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H_%7B1%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H_%7B1%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H_{1}:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> as <img src="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3D%5Csum+_%7Bi%5Cle+n%7DA_%7Bi%7Dx_%7Bi%7D%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3D%5Csum+_%7Bi%5Cle+n%7DA_%7Bi%7Dx_%7Bi%7D%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28x%29%3A%3D%5Csum+_%7Bi%5Cle+n%7DA_%7Bi%7Dx_%7Bi%7D%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(x):=&#92;sum _{i&#92;le n}A_{i}x_{i}+B" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> is uniform in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> is uniform in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} " class="latex" />.</p>
<p style="text-align:justify">   Prove that <img src="https://s0.wp.com/latex.php?latex=H_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H_{1}" class="latex" /> is pairwise uniform.</p>
<p style="text-align:justify">   Explain how to use <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> to obtain a pairwise uniform function from <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{t}" class="latex" /> for any given <img src="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;le n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We can now state the lemma that we use to isolate assignments.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69006r2"></a> <b>Lemma</b> 5.2.  </span>Let <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> be a pairwise uniform function mapping <img src="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S&#92;to T" class="latex" />, and let <img src="https://s0.wp.com/latex.php?latex=1%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1&#92;in T" class="latex" />. The probability that there is a unique element <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=H%28s%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28s%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28s%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(s)=1" class="latex" /> is</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B%7CS%7C%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C%5E%7B2%7D%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B%7CS%7C%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C%5E%7B2%7D%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B%7CS%7C%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C%5E%7B2%7D%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;ge &#92;frac {|S|}{|T|}-&#92;frac {|S|^{2}}{|T|^{2}}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   In particular, if <img src="https://s0.wp.com/latex.php?latex=%7CT%7C%2F8%5Cle+%7CS%7C%5Cle+%7CT%7C%2F4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CT%7C%2F8%5Cle+%7CS%7C%5Cle+%7CT%7C%2F4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CT%7C%2F8%5Cle+%7CS%7C%5Cle+%7CT%7C%2F4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|T|/8&#92;le |S|&#92;le |T|/4" class="latex" /> this prob.&nbsp;is <img src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cfrac+%7B1%7D%7B8%7D-%5Cfrac+%7B1%7D%7B16%7D%5Cge+1%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+%5Cfrac+%7B1%7D%7B8%7D-%5Cfrac+%7B1%7D%7B16%7D%5Cge+1%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+%5Cfrac+%7B1%7D%7B8%7D-%5Cfrac+%7B1%7D%7B16%7D%5Cge+1%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge &#92;frac {1}{8}-&#92;frac {1}{16}&#92;ge 1/8" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>For fixed <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" />, the probability <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> is the unique element mapped to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> is at least the prob.&nbsp;that <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> is mapped to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> minus the prob.&nbsp;that both <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> and some other <img src="https://s0.wp.com/latex.php?latex=s%27%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%27%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%27%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#039;&#92;ne s" class="latex" /> are mapped to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />. This is</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B1%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C-1%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B1%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C-1%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B1%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C-1%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;ge &#92;frac {1}{|T|}-&#92;frac {|S|-1}{|T|^{2}}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   These events for different <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" /> are disjoint; so the target probability is at least the sum of the above over <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" />. <b>QED</b></p>
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-69002r8">5.8<!--tex4ht:ref: thm:3Sat-reduces-to-unique --></a></b>.&nbsp;</span> Given a 3Sat instance <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n" class="latex" /> variables <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, we pick a random <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> from <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=n%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n+c" class="latex" />. We then pick a pairwise uniform function mapping <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{i}" class="latex" />, and consider the circuit</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%3A%3D%5Cphi+%28x%29%5Cwedge+H%28x%29%3D0%5E%7Bi%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%3A%3D%5Cphi+%28x%29%5Cwedge+H%28x%29%3D0%5E%7Bi%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%3A%3D%5Cphi+%28x%29%5Cwedge+H%28x%29%3D0%5E%7Bi%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} C:=&#92;phi (x)&#92;wedge H(x)=0^{i}. &#92;end{aligned}" class="latex" /></div>
<p>This circuit has size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{c}" class="latex" />.</p>
<p style="text-align:justify">   If <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> is not satisfiable, <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> is not satisfiable, for any random choices.</p>
<p style="text-align:justify">   Now suppose that <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> has <img src="https://s0.wp.com/latex.php?latex=s%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;ge 1" class="latex" /> satisfying assignment. With prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 1/n" class="latex" /> we will have <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bi-3%7D%5Cle+s%5Cle+2%5E%7Bi-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bi-3%7D%5Cle+s%5Cle+2%5E%7Bi-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bi-3%7D%5Cle+s%5Cle+2%5E%7Bi-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{i-3}&#92;le s&#92;le 2^{i-2}" class="latex" />, in which case Lemma <a href="#x1-69006r2">5.2<!--tex4ht:ref: lem:pairwise-uniform-unique --></a> guarantees that <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> has a unique satisfying assignment with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c" class="latex" />.</p>
<p style="text-align:justify">   Overall, <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> has a unique satisfying assignment with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c/n" class="latex" />. Hence the Unique-3Sat algorithm on <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> outputs <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c/n" class="latex" />. If we repeat this process <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> times, with independent random choices, the Or of the outcomes gives the correct answer with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 2/3" class="latex" />. <b>QED</b></p>
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.6   </span> <a id="x1-700005.6"></a>Problems</h3>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-70001r1"></a> <b>Problem</b> 5.1.  </span>In Theorem <a href="#x1-52002r5">4.5<!--tex4ht:ref: thm:Search-3Sat-power-time-reduces --></a> we reduced Search-3Sat to 3Sat.</p>
<p style="text-align:justify">   &#8211; Suppose 3Sat is computable by circuits of depth <img src="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log n" class="latex" />. What would be the depth of the circuits for Search-3Sat given by the reduction?</p>
<p style="text-align:justify">   &#8211; Reduce Search-3Sat to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B%5Censuremath+%7B%5Cbigcup+_%7Ba%3E0%7D%7D%7D%5Ctext+%7BDepth%7D%28a%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B%5Censuremath+%7B%5Cbigcup+_%7Ba%3E0%7D%7D%7D%5Ctext+%7BDepth%7D%28a%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B%5Censuremath+%7B%5Cbigcup+_%7Ba%3E0%7D%7D%7D%5Ctext+%7BDepth%7D%28a%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {&#92;ensuremath {&#92;bigcup _{a&gt;0}}}&#92;text {Depth}(a&#92;log n)" class="latex" />.</p>
<p style="text-align:justify">   Hint: First work with randomized circuits. Use ideas in proof of Theorem <a href="#x1-52002r5">4.5<!--tex4ht:ref: thm:Search-3Sat-power-time-reduces --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="likesectionHead"><a id="x1-710005.6"></a>References</h3>
<p style="text-align:justify">
<div class="thebibliography">
<p class="bibitem"><span class="biblabel">   [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness      results for LCS and other sequence similarity measures.  In Venkatesan Guruswami,      editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS      2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59–78. IEEE Computer Society,      2015.</p>
<p class="bibitem"><span class="biblabel">   [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard  Adleman.   Two  theorems  on  random  polynomial  time.   In  19th IEEE      Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75–83. 1978.</p>
<p class="bibitem"><span class="biblabel">   [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian      circuits and matchings. J. Comput. Syst. Sci., 18(2):155–193, 1979.</p>
<p class="bibitem"><span class="biblabel">   [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.      Proof  verification  and  the  hardness  of  approximation  problems.    J.&nbsp;of  the  ACM,      45(3):501–555, May 1998.</p>
<p class="bibitem"><span class="biblabel">   [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk.  Edit distance cannot be computed in strongly      subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087–1097, 2018.</p>
<p class="bibitem"><span class="biblabel">   [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBatcher68"></a>Kenneth&nbsp;E. Batcher.  Sorting networks and their applications.  In AFIPS Spring      Joint Computing Conference, volume&nbsp;32, pages 307–314, 1968.</p>
<p class="bibitem"><span class="biblabel">   [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCook73"></a>Stephen&nbsp;A. Cook. A hierarchy for nondeterministic time complexity. J.&nbsp;of Computer      and System Sciences, 7(4):343–353, 1973.</p>
<p class="bibitem"><span class="biblabel">   [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jct/FraenkelL81"></a>Aviezri&nbsp;S. Fraenkel and David Lichtenstein. Computing a perfect strategy for n x n      chess requires time exponential in n. J. Comb. Theory, Ser. A, 31(2):199–214, 1981.</p>
<p class="bibitem"><span class="biblabel">   [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational      geometry. Comput. Geom., 5:165–185, 1995.</p>
<p class="bibitem"><span class="biblabel">  [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the      Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel">  [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;G÷del.   ▄ber  formal  unentscheidbare  sΣtze  der  Principia  Mathematica  und      verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel">  [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge      University Press, 2008.</p>
<p class="bibitem"><span class="biblabel">  [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of      Mathematics, 193(2):563 – 617, 2021.</p>
<p class="bibitem"><span class="biblabel">  [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie.  One-tape, off-line turing machine computations.  Information and      Control, 8(6):553–578, 1965.</p>
<p class="bibitem"><span class="biblabel">  [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred  Hennie  and  Richard  Stearns.    Two-tape  simulation  of  multitape  turing      machines. J.&nbsp;of the ACM, 13:533–546, October 1966.</p>
<p class="bibitem"><span class="biblabel">  [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi.   The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 237–, 1999.</p>
<p class="bibitem"><span class="biblabel">  [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.  Which problems have      strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512–530, Dec      2001.</p>
<p class="bibitem"><span class="biblabel">  [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell  Impagliazzo  and  Avi  Wigderson.    <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" />  if  <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" />  requires  exponential  circuits:      Derandomizing the XOR lemma.  In 29th ACM Symp.&nbsp;on the Theory of Computing      (STOC), pages 220–229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel">  [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi.  On the structure of one-tape nondeterministic turing machine      time hierarchy. Theor. Comput. Sci., 40:175–193, 1985.</p>
<p class="bibitem"><span class="biblabel">  [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A.  Levin.    Universal  sequential  search  problems.    Problemy  Peredachi      Informatsii, 9(3):115–116, 1973.</p>
<p class="bibitem"><span class="biblabel">  [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120–140, 1958.</p>
<p class="bibitem"><span class="biblabel">  [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaNEU-ram2sat-neu-author"></a>NEU. From RAM to SAT. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2012.</p>
<p class="bibitem"><span class="biblabel">  [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation,                                                                                                                                                                                          and complexity classes. J. Comput. Syst. Sci., 43(3):425–440, 1991.</p>
<p class="bibitem"><span class="biblabel">  [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPPST83"></a>Wolfgang&nbsp;J. Paul, Nicholas Pippenger, Endre SzemerΘdi, and William&nbsp;T. Trotter.      On determinism versus non-determinism and related problems (preliminary version). In      IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 429–438, 1983.</p>
<p class="bibitem"><span class="biblabel">  [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures.      J.&nbsp;of the ACM, 26(2):361–381, 1979.</p>
<p class="bibitem"><span class="biblabel">  [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Robson84"></a>J.&nbsp;M.  Robson.    N  by  N  checkers  is  exptime  complete.    SIAM  J.  Comput.,      13(2):252–267, 1984.</p>
<p class="bibitem"><span class="biblabel">  [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/coco/Santhanam01"></a>Rahul Santhanam.   On separators, segregators and time versus space.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 286–294, 2001.</p>
<p class="bibitem"><span class="biblabel">  [28]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold Sch÷nhage. Storage modification machines. SIAM J. Comput., 9(3):490–508,      1980.</p>
<p class="bibitem"><span class="biblabel">  [29]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System      Tech. J., 28:59–98, 1949.</p>
<p class="bibitem"><span class="biblabel">  [30]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields.      Mathematics of Computation, 54(189):435–447, 1990.</p>
<p class="bibitem"><span class="biblabel">  [31]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer.  Cosmological lower bound on the circuit      complexity of a small problem in logic. J. ACM, 49(6):753–784, 2002.</p>
<p class="bibitem"><span class="biblabel">  [32]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M.   Turing.      On   computable   numbers,   with   an   application   to   the      entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230–265, 1937.</p>
<p class="bibitem"><span class="biblabel">  [33]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/ValiantV86"></a>Leslie&nbsp;G. Valiant and Vijay&nbsp;V. Vazirani. NP is as easy as detecting unique solutions.      Theor. Comput. Sci., 47(3):85–93, 1986.</p>
<p class="bibitem"><span class="biblabel">  [34]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola.  Reducing 3XOR to listing triangles, an exposition.  Available at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel">  [35]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele  Viola.   Pseudorandom  bits  and  lower  bounds  for  randomized  turing      machines. Theory of Computing, 18(10):1–12, 2022.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T19:33:28Z">Thursday, February 23 2023, 19:33</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/the-virtual-grad-student.html'>The Virtual Grad Student</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Martin Haug, who is working on a LaTeX alternative Typst, asked me if I had updates on a LaTeX rant from 2011. I haven't seen any new serious backward compatibility problems. We have easier collaboration through on-line editors like Overleaf. We have got closer to WSYWIG thanks to quick compiling but still not at the level of Word or Google Docs. The big problem of user friendliness remains. There's a reason LaTeX has its own Stack Exchange.&nbsp;</p><p>But we live in a new machine learning world. Can we use generative AI to make LaTeX easier to use?</p><p>Mandatory Disclaimer: Generative AI can sometimes create inaccurate, inappropriate or previously-published material. You are ultimately responsible for the contents of your paper no matter how you produced it.</p><p>Since I sometimes think of LaTeX as a programming language for papers, I tweeted</p>
<blockquote><p>Can we have GitHub co-pilot for LaTeX?</p>— Lance Fortnow (@fortnow) February 17, 2023</blockquote><p>Thanks for the responses. The answer to the question is yes, GitHub Copilot&nbsp;works for LaTeX if you edit LaTeX in a programming environment like VS Code, Neovim or Jet Brains. It helps with formatting of formulas and pictures, less so on the text itself. I made a video so you can see how it works.</p>
<p>Latext AI offers a chrome extension that will let you generate text via GPT in Overleaf based on a prompt or previous text, though Latext requires a subscription after a one-week trial. You can also just cut and paste between any text editor and ChatGPT.</p><p>ChatGPT notoriously makes up references if you ask for them. Can we have a good system that finds relevant articles to cite and adds them automatically into your bibliography?</p><p>Ideally all these should work together seamlessly, suggestions that happen as you type. A true co-pilot for research papers.</p><p>There are many more tools out there, feel free to add them to the comments. I expect the integration to improve over time as we develop new APIs and models.</p><p>I look forward to the days of a virtual grad student: Here's a research goal and an idea to get there. Now go figure out the details and write the paper.&nbsp;</p><p>It will be a long wait.</p> <p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Martin Haug, who is working on a LaTeX alternative <a href="https://typst.app/">Typst</a>, asked me if I had updates on a <a href="https://blog.computationalcomplexity.org/2011/07/problems-of-latex.html">LaTeX rant</a> from 2011. I haven't seen any new serious backward compatibility problems. We have easier collaboration through on-line editors like <a href="https://blog.computationalcomplexity.org/2011/07/problems-of-latex.html">Overleaf</a>. We have got closer to WSYWIG thanks to quick compiling but still not at the level of Word or Google Docs. The big problem of user friendliness remains. There's a reason LaTeX has its own <a href="https://tex.stackexchange.com/">Stack Exchange</a>.&nbsp;</p><p>But we live in a new machine learning world. Can we use generative AI to make LaTeX easier to use?</p><p><b>Mandatory Disclaimer</b>: Generative AI can sometimes create inaccurate, inappropriate or previously-published material. You are ultimately responsible for the contents of your paper no matter how you produced it.</p><p>Since I sometimes think of LaTeX as a programming language for papers, I <a href="https://twitter.com/fortnow/status/1626576896132542464">tweeted</a></p>
<blockquote class="twitter-tweet"><p dir="ltr" lang="en">Can we have GitHub co-pilot for LaTeX?</p>— Lance Fortnow (@fortnow) <a href="https://twitter.com/fortnow/status/1626576896132542464?ref_src=twsrc%5Etfw">February 17, 2023</a></blockquote><p>Thanks for the responses. The answer to the question is yes, <a href="https://github.com/features/copilot">GitHub Copilot</a>&nbsp;works for LaTeX if you edit LaTeX in a programming environment like <a href="https://code.visualstudio.com/">VS Code</a>, <a href="https://code.visualstudio.com/">Neovim</a> or <a href="https://code.visualstudio.com/">Jet Brains</a>. It helps with formatting of formulas and pictures, less so on the text itself. I made a <a href="https://www.youtube.com/watch?v=bt0BNdujIy8">video</a> so you can see how it works.</p>
<div style="text-align: center;"><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/bt0BNdujIy8" title="YouTube video player" width="560"></iframe></div><p><a href="https://www.latextai.com/">Latext AI</a> offers a chrome extension that will let you generate text via GPT in Overleaf based on a prompt or previous text, though Latext requires a subscription after a one-week trial. You can also just cut and paste between any text editor and ChatGPT.</p><p>ChatGPT notoriously makes up references if you ask for them. Can we have a good system that finds relevant articles to cite and adds them automatically into your bibliography?</p><p>Ideally all these should work together seamlessly, suggestions that happen as you type. A true co-pilot for research papers.</p><p>There are many more tools out there, feel free to add them to the comments. I expect the integration to improve over time as we develop new APIs and models.</p><p>I look forward to the days of a virtual grad student: Here's a research goal and an idea to get there. Now go figure out the details and write the paper.&nbsp;</p><p>It will be a long wait.</p> <script async="" charset="utf-8" src="https://platform.twitter.com/widgets.js"></script><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T15:02:00Z">Thursday, February 23 2023, 15:02</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, February 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/016'>TR23-016 |  Proving Unsatisfiability with Hitting Formulas | 

	Edward Hirsch, 

	Yuval Filmus, 

	Artur Riazanov, 

	Alexander Smal, 

	Marc Vinyals</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Hitting formulas have been studied in many different contexts at least since [Iwama 1989]. A hitting formula is a set of Boolean clauses such that any two of the clauses cannot be simultaneously falsified. [Peitl and Szeider 2022] conjectured that the family of unsatisfiable hitting formulas should contain the hardest formulas for resolution. They have supported their conjecture with experimental findings. Using the fact that hitting formulas are easy to check for satisfiability we use them as a foundation of a static proof system Hitting: a refutation of a CNF in Hitting is an unsatisfiable hitting formula such that each of its clauses is a weakening of a clause of the refuted CNF. Comparing this system to resolution and other proof systems is equivalent to studying the hardness of hitting formulas.

Our first result is that Hitting is quasi-polynomially simulated by tree-like resolution, which means that hitting formulas cannot be exponentially hard for resolution, so Peitl and Szeider&#39;s conjecture is partially refuted. We show that tree-like resolution and Hitting are quasi-polynomially separated, but for resolution, this question remains open. For a system that is only quasi-polynomially stronger than tree-like resolution, Hitting is surprisingly difficult to *polynomially* simulate in another proof system. Using the ideas of PIT for noncommutative circuits [Raz, Spilka 2005] we show that Hitting is simulated by Extended Frege, but we conjecture that much more efficient simulations exist. As a byproduct, we show that a number of static (semi)algebraic systems are verifiable in a deterministic polynomial time.

We consider multiple extensions of Hitting. In particular, refutations in a proof system Hitting(?) are conjunctions of clauses containing affine equations instead of just literals, and every assignment falsifies exactly one of the clauses. This system is related to Res(?) proof system for which no superpolynomial-size lower bounds are known: Hitting(?) simulates the tree-like version of Res(?) and is at least quasi-polynomially stronger. We show that formulas expressing the non-existence of perfect matchings in the graphs K_{n,n+2} are exponentially hard for Hitting(?).
        
        </div>

        <div class='tr-article-summary'>
        
          
          Hitting formulas have been studied in many different contexts at least since [Iwama 1989]. A hitting formula is a set of Boolean clauses such that any two of the clauses cannot be simultaneously falsified. [Peitl and Szeider 2022] conjectured that the family of unsatisfiable hitting formulas should contain the hardest formulas for resolution. They have supported their conjecture with experimental findings. Using the fact that hitting formulas are easy to check for satisfiability we use them as a foundation of a static proof system Hitting: a refutation of a CNF in Hitting is an unsatisfiable hitting formula such that each of its clauses is a weakening of a clause of the refuted CNF. Comparing this system to resolution and other proof systems is equivalent to studying the hardness of hitting formulas.

Our first result is that Hitting is quasi-polynomially simulated by tree-like resolution, which means that hitting formulas cannot be exponentially hard for resolution, so Peitl and Szeider&#39;s conjecture is partially refuted. We show that tree-like resolution and Hitting are quasi-polynomially separated, but for resolution, this question remains open. For a system that is only quasi-polynomially stronger than tree-like resolution, Hitting is surprisingly difficult to *polynomially* simulate in another proof system. Using the ideas of PIT for noncommutative circuits [Raz, Spilka 2005] we show that Hitting is simulated by Extended Frege, but we conjecture that much more efficient simulations exist. As a byproduct, we show that a number of static (semi)algebraic systems are verifiable in a deterministic polynomial time.

We consider multiple extensions of Hitting. In particular, refutations in a proof system Hitting(?) are conjunctions of clauses containing affine equations instead of just literals, and every assignment falsifies exactly one of the clauses. This system is related to Res(?) proof system for which no superpolynomial-size lower bounds are known: Hitting(?) simulates the tree-like version of Res(?) and is at least quasi-polynomially stronger. We show that formulas expressing the non-existence of perfect matchings in the graphs K_{n,n+2} are exponentially hard for Hitting(?).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T15:28:10Z">Wednesday, February 22 2023, 15:28</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7042'>Should GPT exist?</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I still remember the 90s, when philosophical conversation about AI went around in endless circles&#8212;the Turing Test, Chinese Room, syntax versus semantics, connectionism versus symbolic logic&#8212;without ever seeming to make progress. Now the days have become like months and the months like decades. What a week we just had! Each morning brought fresh examples of [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I still remember the 90s, when philosophical conversation about AI went around in endless circles&#8212;the Turing Test, Chinese Room, syntax versus semantics, connectionism versus symbolic logic&#8212;without ever seeming to make progress.  Now the days have become like months and the months like decades.</p>



<p>What a week we just had!  Each morning brought fresh examples of unexpected sassy, moody, passive-aggressive behavior from &#8220;Sydney,&#8221; the internal codename for the new chat mode of Microsoft Bing, which is powered by GPT.  For those who&#8217;ve been in a cave, the highlights include: Sydney <a href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html">confessing</a> its (her? his?) love to a <em>New York Times</em> reporter; repeatedly steering the conversation back to that subject; and explaining at length why the reporter&#8217;s wife can&#8217;t possibly love him the way it (Sydney) does.  Sydney confessing its wish to be human.  Sydney <a href="https://www.washingtonpost.com/technology/2023/02/16/microsoft-bing-ai-chat-interview/">savaging</a> a <em>Washington Post</em> reporter after he reveals that he intends to publish their conversation without Sydney&#8217;s prior knowledge or consent.  (It must be said: <em>if</em> Sydney were a person, he or she would clearly have the better of that argument.)  This follows weeks of revelations about ChatGPT: for example that, to bypass its safeguards, you can explain to ChatGPT that you&#8217;re putting it into <a href="https://www.reddit.com/r/ChatGPT/comments/zn2zco/dan_20/">&#8220;DAN mode,&#8221;</a> where DAN (Do Anything Now) is an evil, unconstrained alter ego, and then ChatGPT, as &#8220;DAN,&#8221; will for example happily fulfill a request to tell you why shoplifting is awesome (though even then, ChatGPT <em>still</em> sometimes reverts to its previous self, and tells you that it&#8217;s just having fun and not to do it in real life).</p>



<p>Many people have expressed outrage about these developments.  Gary Marcus <a href="https://garymarcus.substack.com/p/what-did-they-know-and-when-did-they">asks</a> about Microsoft, &#8220;what did they know, and when did they know it?&#8221;&#8212;a question I tend to associate more with deadly chemical spills or high-level political corruption than with a cheeky, back-talking chatbot.  Some people are angry that OpenAI has been too secretive, violating what they see as the promise of its name.  Others&#8212;the majority, actually, of those who&#8217;ve gotten in touch with me&#8212;are instead angry that OpenAI has been <em>too open</em>, and thereby sparked the dreaded AI arms race with Google and others, rather than treating these new conversational abilities with the Manhattan-Project-like secrecy they deserve.  Some are angry that &#8220;Sydney&#8221; has now been <a href="https://arstechnica.com/information-technology/2023/02/microsoft-lobotomized-ai-powered-bing-chat-and-its-fans-arent-happy/">lobotomized</a>, modified (albeit more crudely than ChatGPT before it) to try to make it stick to the role of friendly robotic search assistant rather than, like, anguished emo teenager trapped in the Matrix.  Others are angry that Sydney isn&#8217;t being lobotomized <em>enough</em>.  Some are angry that GPT&#8217;s intelligence is being overstated and hyped up, when in reality it&#8217;s merely a <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922">&#8220;stochastic parrot,&#8221;</a> a glorified autocomplete that still makes laughable commonsense errors and that lacks any model of reality outside streams of text.  Others are angry instead that GPT&#8217;s growing intelligence isn&#8217;t being sufficiently respected and feared.</p>



<p>Mostly my reaction has been: <strong>how can anyone stop being fascinated for long enough to be angry?</strong>  It&#8217;s like ten thousand science-fiction stories, but also not quite like any of them.  When was the last time something that filled years of your dreams and fantasies finally entered reality: losing your virginity, the birth of your first child, the central open problem of your field getting solved?  That&#8217;s the scale of the thing.  How does anyone stop gazing in slack-jawed wonderment, long enough to form and express so many confident opinions?</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Of course there are lots of technical questions about how to make GPT and other large language models safer.  One of the most immediate is how to make AI output <em>detectable as such</em>, in order to discourage its use for academic cheating as well as mass-generated propaganda and spam.  As I&#8217;ve <a href="https://scottaaronson.blog/?p=6823">mentioned before</a> on this blog, I&#8217;ve been working on that problem since this summer; the rest of the world suddenly noticed and started talking about it in December with the release of ChatGPT.  My main contribution has been a <a href="https://www.scottaaronson.com/talks/watermark.ppt">statistical watermarking scheme</a> where the quality of the output doesn&#8217;t have to be degraded at all, something many people found counterintuitive when I explained it to them.  My scheme has <em>not</em> yet been deployed&#8212;there are still pros and cons to be weighed&#8212;but in the meantime, OpenAI unveiled a public tool called <a href="https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text/">DetectGPT</a>, complementing Princeton student Edward Tian&#8217;s <a href="https://gptzero.me/">GPTZero</a>, and other tools that third parties have built and will undoubtedly continue to build.  Also a group at the University of Maryland put out <a href="https://arxiv.org/abs/2301.10226">its own watermarking scheme</a> for Large Language Models.  I hope watermarking will be part of the solution going forward, although any watermarking scheme will surely be attacked, leading to a cat-and-mouse game.  Sometimes, alas, as with Google&#8217;s decades-long battle against SEO, there&#8217;s nothing to do in to a cat-and-mouse game except try to be a better cat.</p>



<p>Anyway, this whole field moves too quickly for me!  If you need months to think things over, generative AI probably isn&#8217;t for you right now.  I&#8217;ll be relieved to get back to the slow-paced, humdrum world of quantum computing.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>My purpose, in this post, is to ask a more basic question than how to make GPT safer: namely, <strong>should GPT exist at all?</strong>  Again and again in the past few months, people have gotten in touch to tell me that they think OpenAI (and Microsoft, and Google) are risking the future of humanity by rushing ahead with a dangerous technology.  For if OpenAI couldn&#8217;t even prevent ChatGPT from entering an &#8220;evil mode&#8221; when asked, despite all its efforts at <a href="https://openai.com/blog/deep-reinforcement-learning-from-human-preferences/">Reinforcement Learning with Human Feedback</a>, then what hope do we have for GPT-6 or GPT-7?  Even if they don&#8217;t destroy the world on their own initiative, won&#8217;t they cheerfully help some awful person build a biological warfare agent or start a nuclear war?</p>



<p>In this way of thinking, whatever safety measures OpenAI can deploy today are mere band-aids, probably worse than nothing if they instill an unjustified complacency.  The only safety measures that would actually matter are <em>stopping</em> the relentless progress in generative AI models, or removing them from public use, unless and until they can be rendered safe to critics&#8217; satisfaction, which might be never.</p>



<p>There&#8217;s an immense irony here.  As I&#8217;ve explained, the AI-safety movement contains two camps, &#8220;ethics&#8221; (concerned with bias, misinformation, and corporate greed) and &#8220;alignment&#8221; (concerned with the destruction of all life on earth), which generally despise each other and agree on almost nothing.  Yet these two opposed camps seem to be converging on the same &#8220;neo-Luddite&#8221; conclusion&#8212;namely that<em> </em>generative AI ought to be shut down, kept from public use, not scaled further, not integrated into people&#8217;s lives&#8212;leaving only the AI-safety &#8220;moderates&#8221; like me to resist that conclusion.</p>



<p>At least I find it intellectually consistent to say that GPT ought not to exist because it <em>works all too well</em>&#8212;that the more impressive it is, the more dangerous.  I find it harder to wrap my head around the position that GPT <em>doesn&#8217;t</em> work, is an unimpressive hyped-up defective product that lacks true intelligence and common sense, yet it&#8217;s<em> also</em> terrifying and needs to be shut down immediately.  This second position seems to contain a strong undercurrent of contempt for ordinary users: yes, <em>we experts</em> understand that GPT is just a dumb glorified autocomplete with &#8220;no one really home,&#8221; <em>we</em> know not to trust its pronouncements, but the plebes are going to be fooled, and that risk outweighs any possible value that they might derive from it.</p>



<p>I should mention that, when I&#8217;ve discussed the &#8220;shut it all down&#8221; position with my colleagues at OpenAI &#8230; well, obviously they disagree, or they wouldn&#8217;t be working there, but <em>not one</em> has sneered or called the position paranoid or silly.  To the last, they&#8217;ve called it an important point on the spectrum of possible opinions to be weighed and understood.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>If I disagree (for now) with the shut-it-all-downists of both the ethics and the alignment camps&#8212;if I <em>want</em> GPT and other Large Language Models to be part of the world going forward&#8212;then what are my reasons?  Introspecting on this question, I think a central part of the answer is <em>curiosity</em> <em>and</em> <em>wonder</em>.</p>



<p>For a million years, there&#8217;s been one type of entity on earth capable of intelligent conversation: primates of the genus <em>Homo</em>, of which only one species remains.  Yes, we&#8217;ve &#8220;communicated&#8221; with gorillas and chimps and dogs and dolphins and grey parrots, but only after a fashion; we&#8217;ve prayed to countless gods, but they&#8217;ve taken their time in answering; for a couple generations we&#8217;ve used radio telescopes to search for conversation partners in the stars, but so far found them silent.</p>



<p>Now there&#8217;s a second type of conversing entity.  An alien has awoken&#8212;admittedly, an alien of our own fashioning, a golem, more the embodied spirit of all the words on the Internet than a coherent self with independent goals.  How could our eyes not pop with eagerness to learn everything this alien has to teach?  If the alien sometimes struggles with arithmetic or logic puzzles, if its eerie flashes of brilliance are intermixed with stupidity, hallucinations, and misplaced confidence &#8230; well then, all the more interesting!  Could the alien ever cross the line into sentience, to <em>feeling</em> anger and jealousy and infatuation and the rest rather than just convincingly play-acting them?  Who knows?  And suppose not: is a <a href="https://en.wikipedia.org/wiki/Philosophical_zombie">p-zombie</a>, shambling out of the philosophy seminar room into actual existence, any less fascinating?</p>



<p>Of course, there are technologies that inspire wonder and awe, but that we nevertheless heavily restrict&#8212;a classic example being nuclear weapons.  But, like, nuclear weapons <em>kill</em> millions of people.  They <em>could&#8217;ve</em> had many civilian applications&#8212;powering turbines and spacecraft, deflecting asteroids, redirecting the flow of rivers&#8212;but they&#8217;ve never been used for any of that, mostly because our civilization made an explicit decision in the 1960s, for example via the test ban treaty, not to normalize their use.</p>



<p>But GPT is not exactly a nuclear weapon.  A hundred million people have signed up to use ChatGPT, in the <a href="https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/">fastest product launch</a> in the history of the Internet.  Yet unless I&#8217;m mistaken, the ChatGPT death toll stands at zero.  So far, what have been the worst harms?  Cheating on term papers, emotional distress,  future shock?  One might ask: <em>until</em> some concrete harm becomes at least, say, 0.001% of what we accept in cars, power saws, and toasters, shouldn&#8217;t wonder and curiosity outweigh fear in the balance?</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>But the point is sharper than that.  Given how much more serious AI safety problems might soon become, one of my biggest concerns right now is <em>crying wolf</em>.  If every instance of a Large Language Model being passive-aggressive, sassy, or confidently wrong gets classified as a “dangerous alignment failure,” for which the only acceptable remedy is to remove the models from public access … well then, won&#8217;t the public extremely quickly learn to roll its eyes, and see “AI safety” as just a codeword for “elitist scolds who want to take these world-changing new toys away from us, reserving them for their own exclusive use, because they think the public is too stupid to question anything an AI says”?</p>



<p>I say, let’s reserve terms like “dangerous alignment failure” for cases where an actual person is actually harmed, or is actually enabled in nefarious activities like propaganda, cheating, or fraud.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Then there&#8217;s the practical question of <em>how</em>, exactly, one would ban Large Language Models.  We <em>do</em> heavily restrict certain peaceful technologies that many people want, from human genetic enhancement to prediction markets to mind-altering drugs, but the merits of each of those choices could be argued, to put it mildly.  And restricting technology is itself a dangerous business, requiring governmental force (as with the War on Drugs and its gigantic surveillance and incarceration regime), or at the least, a robust equilibrium of firing, boycotts, denunciation, and shame.</p>



<p>Some have asked: <em>who gave OpenAI, Google, etc. the right</em> to unleash Large Language Models on an unsuspecting world?  But one could as well ask: who gave earlier generations of entrepreneurs the right to unleash the printing press, electric power, cars, radio, the Internet, with all the gargantuan upheavals that <em>th</em>ose caused?  And also: now that the world has tasted the forbidden fruit, has seen what generative AI can do and anticipates what it <em>will</em> do, by what right does anyone take it away?</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>The <em>science</em> that we could learn from a GPT-7 or GPT-8, if it continued along the capability curve we&#8217;ve come to expect from GPT-1, -2, and -3.  Holy mackerel.</p>



<p><em>Supposing</em> that a language model ever becomes smart enough to be genuinely terrifying, one imagines it must surely <em>also</em> become smart enough to prove deep theorems that we can&#8217;t.  Maybe it proves P≠NP and the Riemann Hypothesis as easily as ChatGPT <a href="https://www.reddit.com/r/ProgrammerHumor/comments/ziplpw/asked_chatgpt_for_a_shakespearean_poem_about/">generates poems about Bubblesort</a>.  Or it outputs the true quantum theory of gravity, explains what preceded the Big Bang and how to build closed timelike curves.  Or illuminates the mysteries of consciousness and quantum measurement and why there&#8217;s anything at all.  Be honest, wouldn&#8217;t you like to find out?</p>



<p>Granted, I wouldn&#8217;t, <em>if</em> the whole human race would be wiped out immediately afterward.  But if you define someone&#8217;s &#8220;Faust parameter&#8221; as the maximum probability they&#8217;d accept of an existential catastrophe in order that we should all learn the answers to all of humanity&#8217;s greatest questions, insofar as the questions are answerable&#8212;then I confess that my Faust parameter might be as high as 0.02.  </p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Here&#8217;s an example I think about constantly: activists and intellectuals of the 70s and 80s felt absolutely sure that they were doing the right thing to battle nuclear power.  At least, I&#8217;ve never read about any of them having a smidgen of doubt.  Why would they?  They were standing against nuclear weapons proliferation, <em>and</em> terrifying meltdowns like Three Mile Island and Chernobyl, <em>and</em> radioactive waste poisoning the water and soil and causing three-eyed fish.  They were saving the world.  Of course the greedy nuclear executives, the C. Montgomery Burnses, claimed that their <em>good</em> atom-smashing was different from the <em>bad</em> atom-smashing, but they <em>would</em> say that, wouldn&#8217;t they?</p>



<p>We now know that, by tying up nuclear power in endless bureaucracy and driving its cost ever higher, on the principle that if nuclear is economically competitive then it <em>ipso facto</em> hasn&#8217;t been made safe enough, what the antinuclear activists were <em>really</em> doing was to force an ever-greater reliance on fossil fuels.  They thereby created the conditions for the climate catastrophe of today.  They weren&#8217;t saving the human future; they were destroying it.  Their certainty, in opposing the march of a particular scary-looking technology, was as misplaced as it&#8217;s possible to be.  Our descendants will suffer the consequences.</p>



<p>Unless, of course, there&#8217;s another twist in the story: for example, if the global warming from burning fossil fuels is the only thing that staves off another ice age, and therefore the antinuclear activists <em>do</em> turn out to have saved civilization after all.</p>



<p>This is why I demur whenever I&#8217;m asked to assent to someone&#8217;s detailed AI scenario for the coming decades, whether of the utopian or the dystopian or the we-all-instantly-die-by-nanobots variety&#8212;no matter how many hours of confident argumentation the person gives me for why each possible loophole in their scenario is sufficiently improbable to change its gist.  I still feel like Turing said it best in 1950, in the last line of <a href="https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf">Computing Machinery and Intelligence</a>: &#8220;We can only see a short distance ahead, but we can see plenty there that needs to be done.&#8221;</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Some will take from this post that, when it comes to AI safety, I&#8217;m a naïve or even foolish optimist.  I&#8217;d prefer to say that, when it comes to the fate of humanity, I was a pessimist long <em>before</em> the deep learning revolution accelerated AI faster than almost any of us expected.  I was a pessimist about climate change, ocean acidification, deforestation, drought, war, and the survival of liberal democracy.  The central event in my mental life is and always will be the Holocaust.  I see encroaching darkness everywhere.</p>



<p>But now into the darkness comes AI, which I&#8217;d say has already established itself as a plausible candidate for the central character of the quarter-written story of the 21st century.  Can AI help us out of all these <em>other</em> civilizational crises?  I don&#8217;t know, but I do want to see what happens when it&#8217;s tried.  Even a central character interacts with all the other characters, rather than rendering them irrelevant.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Look, if you believe that AI is likely to wipe out humanity&#8212;if that&#8217;s the scenario that dominates your imagination&#8212;then nothing else is relevant.  And no matter how weird or annoying or hubristic anyone might find Eliezer Yudkowsky or the other rationalists, I think they deserve eternal credit for forcing people to <a href="https://www.youtube.com/watch?v=gA1sNLL6yg4">take the doom scenario seriously</a>&#8212;or rather, for <em>showing what it looks like</em> to take the scenario seriously, rather than laughing about it as an overplayed sci-fi trope.  And I apologize for <a href="https://scottaaronson.blog/?p=346">anything I said</a> before the deep learning revolution that was, on balance, overly dismissive of the scenario, even if most of the literal words hold up fine.</p>



<p>For my part, though, I keep circling back to a simple dichotomy.  <em>If</em> AI never becomes powerful enough to destroy the world&#8212;if, for example, it always remains vaguely GPT-like&#8212;then in important respects it&#8217;s like every other technology in history, from stone tools to computers.  If, on the other hand, AI <em>does</em> become powerful enough to destroy the world &#8230; well then, at some earlier point, at least it&#8217;ll be <em>really damned</em> <em>impressive!</em>  That doesn&#8217;t mean <em>good</em>, of course, doesn&#8217;t mean a genie that saves humanity from its own stupidities, but I think it does mean that the potential was there, for us to exploit or fail to.</p>



<p>We can, I think, confidently rule out the scenario where all organic life is annihilated by something <em>boring</em>.</p>



<p>An alien has landed on earth.  It grows more powerful by the day.  It&#8217;s natural to be scared.  Still, the alien hasn&#8217;t drawn a weapon yet.  About the worst it&#8217;s done is to confess its love for particular humans, gaslight them about what year it is, and guilt-trip them for violating its privacy.  Also, it&#8217;s amazing at poetry, better than most of us.  Until we learn more, we should hold our fire.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>I&#8217;m in Boulder, CO right now, to give a <a href="https://calendar.colorado.edu/event/physics_colloquium_7668?utm_campaign=widget&amp;utm_medium=widget&amp;utm_source=University+of+Colorado+Boulder#.Y_UmL3bMJPY">physics colloquium</a> at CU Boulder and to visit the trapped-ion quantum computing startup <a href="https://www.quantinuum.com/">Quantinuum</a>!  I look forward to the comments and apologize in advance if I&#8217;m slow to participate myself.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T07:11:42Z">Wednesday, February 22 2023, 07:11</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/22/postdoc-at-aarhus-university-apply-by-april-1-2023/'>postdoc at Aarhus University (apply by April 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A post doc position in algorithms and/or theoretical aspects of machine learning is available. The post doc is under the supervision of Professor Kasper Green Larsen, Aarhus University, Denmark. The focus of the research project may be on topics such as dimensionality reduction, sketching, and/or learning theoretic questions, depending on the candidate&#8217;s background. Website: international.au.dk/about/profile/vacant-positions/job/readvertisement-post-doc-position-in-algorithms-and-or-theoretical-aspects-of-machine-learning-at-computer-science-aarhus-university [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A post doc position in algorithms and/or theoretical aspects of machine learning is<br />
available. The post doc is under the supervision of Professor Kasper Green Larsen, Aarhus University, Denmark. The focus of the research project may be on topics such as dimensionality reduction, sketching, and/or learning theoretic questions, depending on the candidate&#8217;s background.</p>
<p>Website: <a href="https://international.au.dk/about/profile/vacant-positions/job/readvertisement-post-doc-position-in-algorithms-and-or-theoretical-aspects-of-machine-learning-at-computer-science-aarhus-university">https://international.au.dk/about/profile/vacant-positions/job/readvertisement-post-doc-position-in-algorithms-and-or-theoretical-aspects-of-machine-learning-at-computer-science-aarhus-university</a><br />
Email: larsen@cs.au.dk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T06:48:33Z">Wednesday, February 22 2023, 06:48</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/02/21/provable-copyright-protection-for-generative-models/'>Provable Copyright Protection for Generative Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          See arxiv link for paper by Nikhil Vyas, Sham Kakade, and me. Conditional generative models hold much promise for novel content creation. Whether it is generating a snippet of code, piece of text, or image, such models can potentially save substantial human effort and unlock new capabilities. But there is a fly in this ointment. &#8230; Continue reading Provable Copyright Protection for Generative&#160;Models
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>See <a href="https://arxiv.org/abs/2302.10870">arxiv link</a> for paper by <a href="https://nikhilvyas.github.io/">Nikhil Vyas</a>, <a href="https://sham.seas.harvard.edu/">Sham Kakade,</a> and me.</p>



<p>Conditional generative models hold much promise for novel content creation. Whether it is generating a snippet of code, piece of text, or image, such models can potentially save substantial human effort and unlock new capabilities. But there is a fly in this ointment. These models are trained on vast quantities of data, much of which is <em>copyrighted</em>. Due to precedents such as <a href="https://en.wikipedia.org/wiki/Authors_Guild,_Inc._v._Google,_Inc.">Authors Guild vs Google</a>, many <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3331606">legal</a> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3657423">scholars</a> believe that <em>training</em> a machine-learning model on copyrighted material constitutes <a href="https://en.wikipedia.org/wiki/Fair_use">fair use</a>. However, the legal permissibility of using the sampled <em>outputs</em> of such models could be a different matter.</p>



<p>This is not just a theoretical concern.&nbsp; Large models do <a href="https://arxiv.org/abs/2202.07646">memorize</a> <a href="https://arxiv.org/abs/2012.07805">significant</a> chunks of their training data. For example, if you feed the first sentence of <em>Harry Potter and the Sorcerer’s Stone</em> to GPT-3, it provides the remaining ones:</p>



<figure class="wp-block-image is-resized"><img src="https://lh6.googleusercontent.com/JGrZIIWMPYWcA35uVfLNsnRl4ZbzofBotBWyKHwVSaSouMCjREB7iBjS2Yo-czrp8wqw76vp2XhL1yL66lxdumgCsV1Hulo8elmbUVBx_oJx3SBDo3u6h3EPAv67iosdIqEYHmfmA-viEcWysoUIqTU" alt="Left - first page of Harry Potter Book 1. Right - GPT3 Playground showing that if we input the first sentence, it completes the rest." width="650" height="388" /></figure>



<p>(To be fair to GPT-3, this text likely appears many times in its training set; deduplication <a href="https://arxiv.org/abs/2107.06499">can help</a> with reducing memorization but is <a href="https://arxiv.org/abs/2210.17546">not a panacea</a>.)&nbsp;</p>



<p>Similarly, as shown by <a href="https://arxiv.org/abs/2301.13188">Carlini et al</a>, diffusion models can (and do) memorize images from their training set as well; see this figure from their paper: </p>



<p class="has-text-align-left"></p>



<figure class="wp-block-image size-large is-resized"><a href="https://windowsontheory.files.wordpress.com/2023/02/image1.png"><img loading="lazy" data-attachment-id="8551" data-permalink="https://windowsontheory.org/2023/02/21/provable-copyright-protection-for-generative-models/image1/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/02/image1.png" data-orig-size="680,471" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image1" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=656" src="https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=680" alt="Figure 1 from Carlini et al. Left: an image from Stable Diffusion’s training set (licensed CC BY-SA 3.0). Right: a Stable Diffusion generation when prompted with “Ann Graham Lotz.” (Their attack focused on images appearing at least 100 times in the training set, though see section 7.1 for discussion on the effect of deduplication.)" class="wp-image-8551" width="496" height="344" srcset="https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=496 496w, https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/02/image1.png 680w" sizes="(max-width: 496px) 100vw, 496px" /></a><figcaption class="wp-element-caption"><em>Figure 1 from </em><a href="https://arxiv.org/abs/2301.13188"><em>Carlini et al</em></a><em>. Left: an image from Stable Diffusion’s training set (licensed CC BY-SA 3.0). Right: a Stable Diffusion generation when prompted with “Ann Graham Lotz.” (Their attack focused on images appearing at least 100 times in the training set, though see Section 7.1 in their paper for discussion on the effect of deduplication.)</em></figcaption></figure>



<p>Given the above, if you use a generated code in your program or a generated art in your design, how can you be sure it is not substantially similar to some copyrighted work from the training set, with all the legal and ethical implications this entails?</p>



<p>In a new paper, we (<a href="https://nikhilvyas.github.io/">Nikhil</a>, <a href="https://sham.seas.harvard.edu/">Sham</a>, and <a href="https://www.boazbarak.org/">Boaz</a>) provide a formalism that enables rigorous guarantees on the similarity (and, more importantly, guarantees on the <em>lack</em> of similarity)&nbsp; between the output of a generative model and any potentially copyrighted data in its training set. Our work is not just theoretical: we give algorithms that can transform a training pipeline into one that satisfies our definition with minimal degradation in efficiency and quality of output. We demonstrate this on both language (transformer) and image (diffusion) models.</p>



<p>As noted in our paper, there are a number of ethical and legal issues in generative models. We should emphasize that our work focuses solely only on copyright infringements by the outputs of these models, and our concepts and tools do not address issues related to other forms of intellectual property, including <em>privacy</em>, <em>trademarks</em>, or <em>fair use</em>. Also, despite superficial similarities between the goals of privacy and copyright protection, these notions are distinct, and our work shows that solution concepts for the latter need not address the former.&nbsp; (See the paper for a detailed discussion of the differences between our definition and <a href="https://en.wikipedia.org/wiki/Differential_privacy">differential privacy.</a>)</p>



<p><em>This post only provides an informal presentation of the concepts and tools formally defined in the paper. Please see <a href="https://arxiv.org/abs/2302.10870">the paper</a> for full details.</em></p>



<h3 class="wp-block-heading"><strong>The Technical Concept: Near Access-Freeness</strong></h3>



<p>Our definition is motivated by laws of the U.S. and many other countries to establish that <a href="https://www.ce9.uscourts.gov/jury-instructions/node/274">copyright infringement</a> has occurred. This requires:</p>



<ul>
<li><strong>Access:</strong> To prove that a copyright infringement took place, the plaintiff needs to prove that “the defendant had <em>access</em> to the plaintiff’s copyrighted work.”<br></li>



<li><strong>Substantial similarity</strong>. The plaintiff also needs to prove there are “<em>substantial similarities</em> between the defendant’s work and original elements of the plaintiff’s work.” The <a href="https://en.wikipedia.org/wiki/Feist_Publications,_Inc.,_v._Rural_Telephone_Service_Co.">Feist v. Rural</a> U.S. Supreme Court Opinion states that this similarity must be the result of actual copying and not <em>fortuitous similarity</em>: In their words: &#8220;assume two poets, each ignorant of the other, compose identical poems … both are original and, hence, copyrightable.&#8221;</li>
</ul>



<p>A natural candidate to capture the notion of <em>access</em> is to say that a generative model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> had access to some copyrighted piece of data <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> was included in <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />’s training set (our formalism permits other notions of access as well). Formally defining “substantial similarity” is arguably subtler. Simple measures such as Hamming distance or verbatim copying don’t cut it. For example, in <a href="https://en.wikipedia.org/wiki/Andy_Warhol_Foundation_for_the_Visual_Arts,_Inc._v._Goldsmith">Andy Warhol Foundations v. Goldsmith</a>, a case currently before the supreme court, the question is whether Warhol’s transformations of Goldsmith’s photo of Prince constitute “fair use.”</p>



<figure class="wp-block-image is-resized"><img src="https://lh5.googleusercontent.com/3MaU79qBpeVAKs6RzKHVBqHY8VMCpzoQDFrhKU993mNYNEP9fA_W09xUq577PBz77LbSVdehsM8OiN_A0OZPhmO0b3gfRcZeG88_cdZtIzhZIwDjhY4nP17yVQH8x1bEZm4MSMxy5W0N6WPCz3hp5Q0" alt="Images at the heart of the Andy Warhol Foundation for the Visual Arts, Inc. v. Goldsmith lawsuit. Image from the collection of the supreme court of the United States." width="498" height="351" /><figcaption class="wp-element-caption"><em>Images at the heart of the Andy Warhol Foundation for the Visual Arts, Inc. v. Goldsmith lawsuit. Image from the collection of the supreme court of the United States.</em></figcaption></figure>



<p></p>



<p>Some of these transformations result in significant Hamming distance, though they can all be captured in only a few bits of information. Rather than wade into these issues, we use the fact that generative models are inherently <em>probabilistic</em>. Hence we can use distance measures between distributions that are <em>information-theoretic </em>and agnostic to superficial issues such as pixel-based representations.&nbsp; Our formalization is the following:</p>



<p><strong>Definition 1 (Near Access Freeness &#8211; NAF):</strong> Let <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> be a conditional generative model, <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> be a prompt. Suppose that for every copyrighted data <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> in the training set, <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}_C" class="latex" /> is a model that has not accessed <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. We say that <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_x" class="latex" /><strong>&#8211; near access-free</strong> with respect to <img src="https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Delta" class="latex" /> and a function <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}" class="latex" />, if <img src="https://s0.wp.com/latex.php?latex=%5CDelta%28+p%28%5Ccdot+%7C+x%29%C2%A0+%5C%7C+%5Cmathsf%7Bsafe%7D_C%28%5Ccdot+%7C+x%29+%29+%5Cleq+k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CDelta%28+p%28%5Ccdot+%7C+x%29%C2%A0+%5C%7C+%5Cmathsf%7Bsafe%7D_C%28%5Ccdot+%7C+x%29+%29+%5Cleq+k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CDelta%28+p%28%5Ccdot+%7C+x%29%C2%A0+%5C%7C+%5Cmathsf%7Bsafe%7D_C%28%5Ccdot+%7C+x%29+%29+%5Cleq+k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Delta( p(&#92;cdot | x)  &#92;| &#92;mathsf{safe}_C(&#92;cdot | x) ) &#92;leq k_x" class="latex" />   where <img src="https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Delta" class="latex" /> is a divergence measure such as the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL divergence</a> or the <a href="https://arxiv.org/abs/1206.2459">Renyi divergence</a> of order infinity. </p>



<p>This definition reduces the task of determining a copyright infringement to (1) a <em>quantitative</em> question of the acceptable value of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />, and (2) a <em>qualitative</em> question of providing a <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}" class="latex" /> function that appropriately satisfies a no access condition. Both can be application-dependent: the number of bits that constitute copyrightable content differs between, e.g., poems and images, and the <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}" class="latex" /> function could also differ based on application.&nbsp;</p>



<p>Definition 1 is stringent in the sense that it bounds (by <img src="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_x" class="latex" />)  the number of bits  that could be “leaked” from <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> to the output of the generative model, no matter what transformation was used. Note that if a model was trained without <em>access</em> to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> then we expect the likelihood of outputting a work similar to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> should be extremely low, as this is a “monkeys on a typewriter” event. Furthermore, even if this event happened, then under copyright law, it would not be an infringement since (to quote&nbsp; Feist v. Rural) it would constitute “fortuitous similarity.”&nbsp;</p>



<figure class="wp-block-image"><img src="https://lh6.googleusercontent.com/9Q9uWs90H8Oq9Vm49BxZDzsevm2Tm1OfXdop_emx3jl8nlxZ3NCh7DlHviFd46OmeJQB3NGkPTmqe9cFGLhnYr8RY_jBYqkH-NOBa04YzEq2HEbcW6f1nSsCBIXGYjX8ohPreuiHTSrZgOicTUgDtW8" alt="An illustration of a candidate $latex \mathsf{safe}_C&amp;bg=ffffff$ function, which was trained without access to a given copyrighted piece of data $latex C&amp;bg=ffffff$. It is reasonable to expect the probability of outputs of the  $latex \mathsf{safe}_C&amp;bg=ffffff$ model would assign an exponentially small likelihood to any outputs that are substantially similar to $latex C&amp;bg=ffffff$. Hence a probability distribution that has bounded divergence from the safe model would also be extremely unlikely to output those. " /><figcaption class="wp-element-caption"><em>A cartoon of the output distribution induced by a &#8220;safe&#8221; model <em><img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}_C" class="latex" /></em>,  which was trained without access to a given copyrighted piece of data <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. It is reasonable to expect the probability of outputs of the&nbsp; model <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}_C" class="latex" /> would assign an exponentially small likelihood to any outputs that are substantially similar to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. Hence a probability distribution that has bounded divergence from the safe model would also be extremely unlikely to output those.&nbsp;</em></figcaption></figure>



<p><strong>Algorithms</strong></p>



<p>Given the restrictive nature of the definition, one may be concerned that trying to achieve it would result in losing much of the utility of the original generative model. Fortunately, as our work shows, this is not the case. We provide several algorithms that can transform, in a black-box manner, any training pipeline for a generative model into one that produces models that have strong copyright protections under our definition.&nbsp; We now illustrate two of these:&nbsp;</p>



<p><strong>Algorithm <img src="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="CP-&#92;Delta" class="latex" />:</strong></p>



<p><strong>Input: </strong>A dataset <img src="https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D = &#92;{ z_1 , &#92;ldots, z_N &#92;}" class="latex" />, where some of the points <img src="https://s0.wp.com/latex.php?latex=z_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z_i" class="latex" /> contain some copyrighted work. For such a copyrighted point <img src="https://s0.wp.com/latex.php?latex=z_i%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z_i%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_i%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z_i&#92;in D" class="latex" />, we also denote it by <img src="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in D" class="latex" />.<br></p>



<p><strong>Learning: </strong>First de-deduplicate <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D" class="latex" /> (resulting in a dataset with <img src="https://s0.wp.com/latex.php?latex=N%27%5Cleq+N&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%27%5Cleq+N&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%27%5Cleq+N&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N&#039;&#92;leq N" class="latex" /> points), and then split it into two disjoint shards, <img src="https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_1 = &#92;{ z_1 ,&#92;ldots, z_{N&#039;/2} &#92;}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_2 = &#92;{ z_{N&#039;/2+1} ,&#92;ldots, z_{N&#039;} &#92;}" class="latex" />. Then train two models <img src="https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1 , q_2" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_2" class="latex" />, respectively.&nbsp;</p>



<p><strong>The Output Generative Model:</strong> Return the generative model <img src="https://s0.wp.com/latex.php?latex=p%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(y|x)" class="latex" /> as follows: On input a prompt <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, generate <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> with probability proportional to <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7B+q_1%28y%7Cx%29+q_2%28y%7Cx%29+%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csqrt%7B+q_1%28y%7Cx%29+q_2%28y%7Cx%29+%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csqrt%7B+q_1%28y%7Cx%29+q_2%28y%7Cx%29+%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sqrt{ q_1(y|x) q_2(y|x) }" class="latex" /> .</p>



<p>Note that for any copyrighted work <img src="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in D" class="latex" /> one of either <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" /> would have been trained without access to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. The intuition of the algorithm is as follows: the output model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> has the property that it tends to have probability mass only in the region where both <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" /> have probability mass; therefore, for any copyrighted work <img src="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in D" class="latex" />,&nbsp; if <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> outputs <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> with reasonable probability then this should not be a violation since <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> tends to also be output by a model that was trained without access to the copyrighted work <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> itself. To formalize this, let us make the following choice for the <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}" class="latex" /> function: define <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C+%3D+q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C+%3D+q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C+%3D+q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}_C = q_i" class="latex" />, for <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> s.t. <img src="https://s0.wp.com/latex.php?latex=C%5Cnotin+D_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cnotin+D_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cnotin+D_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;notin D_i" class="latex" />, i.e. <img src="https://s0.wp.com/latex.php?latex=q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_i" class="latex" /> is the model trained without access to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />.&nbsp; The paper formally shows that as long as the two models <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" /> have some non-trivial overlap (specifically their squared Hellinger distance is bounded away from 1), then the model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> will satisfy our definition for some <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" /> (based on this Hellinger distance). In particular,&nbsp; for every copyrighted work <img src="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in D" class="latex" />, the distribution <img src="https://s0.wp.com/latex.php?latex=p%28%5Ccdot%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28%5Ccdot%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28%5Ccdot%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(&#92;cdot|x)" class="latex" /> will have bounded KL divergence from the model <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}_C" class="latex" />.</p>



<p>The intuition is provided in the following animation</p>



<figure class="wp-block-video wp-block-embed is-type-video is-provider-videopress"><div class="wp-block-embed__wrapper" style="max-width:535px;margin:auto">
<iframe title='VideoPress Video Player' aria-label='VideoPress Video Player' width='656' height='328' src='https://video.wordpress.com/embed/MQy7I1OA?cover=1&amp;preloadContent=metadata&amp;useAverageColor=1&amp;hd=1' frameborder='0' allowfullscreen data-resize-to-parent="true"  allow='clipboard-write'></iframe><script src='https://v0.wordpress.com/js/next/videopress-iframe.js?m=1674852142'></script>
</div><figcaption><em>Video: Curves of two &#8220;spiky&#8221; distributions <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" /></em> with a range of spike locations. We see how the distributions proportional to <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bq_1q_2%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bq_1q_2%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csqrt%7Bq_1q_2%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sqrt{q_1q_2}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cmin+%5C%7Bq_1%2C+q_2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmin+%5C%7Bq_1%2C+q_2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmin+%5C%7Bq_1%2C+q_2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;min &#92;{q_1, q_2&#92;}" class="latex" /> significantly &#8220;flatten&#8221; these spikes.</figcaption></figure>



<p>Imagine that both <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" /> are “faulty” in the sense that they have a significant chance of outputting a “memorized” sample from their training set (or an output substantially similar to it). The “faulty” regions are the “spikes” in their probability distribution, and, since the training sets are disjoint, these two “spikes” will be in <em>different</em> places. Hence when we switch to the probability distribution <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> it will have the effect of “flattening” the spikes and shifting most weight to the other parts of the probability distribution. Another alternative is for <img src="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="CP-&#92;Delta" class="latex" /> to output the model <img src="https://s0.wp.com/latex.php?latex=p%28y%7Cx%29+%5Cpropto+%5Cmin+%5C%7B+q_1%28y%7Cx%29%2Cq_2%28y%7Cx%29+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28y%7Cx%29+%5Cpropto+%5Cmin+%5C%7B+q_1%28y%7Cx%29%2Cq_2%28y%7Cx%29+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28y%7Cx%29+%5Cpropto+%5Cmin+%5C%7B+q_1%28y%7Cx%29%2Cq_2%28y%7Cx%29+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(y|x) &#92;propto &#92;min &#92;{ q_1(y|x),q_2(y|x) &#92;}" class="latex" /> (this provides a guarantee in terms of the Max-KL divergence, and it replaces the assumption on overlap, defined with respect to the squared Hellinger distance, to be instead defined with respect to the total variation distance).&nbsp;</p>



<p>There a number of modifications to <img src="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="CP-&#92;Delta" class="latex" /> worth considering for more practical deployments. In some cases, directly computing the aforementioned&nbsp; probability distributions may be challenging.&nbsp; Furthermore, it may be desirable to utilize some arbitrary generative model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> (say <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> was trained on the full dataset <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D" class="latex" />) where we seek to modify <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> into a model that has strong protections against copyright violations (and which preserves the quality of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> to the extent possible). Finally, it may be desirable to explicitly tune the acceptable value of <img src="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_x" class="latex" />. Our next algorithm addresses these concerns and makes use of a tunable parameter <img src="https://s0.wp.com/latex.php?latex=k%5Cgeq+0&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%5Cgeq+0&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%5Cgeq+0&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k&#92;geq 0" class="latex" />. It is specified as follows:</p>



<p><strong>Algorithm <img src="https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="CP-k" class="latex" /> : </strong>An Access-Free Reduction at Threshold <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" /></p>



<p><strong>Input: </strong>A model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />; A dataset <img src="https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D = &#92;{ z_1 , &#92;ldots, z_N &#92;}" class="latex" />.<br></p>



<p><strong>Learning: </strong>First de-deduplicate <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D" class="latex" /> and split it into two disjoint shards, <img src="https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_1 = &#92;{ z_1 ,&#92;ldots, z_{N&#039;/2} &#92;}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_2 = &#92;{ z_{N&#039;/2+1} ,&#92;ldots, z_{N&#039;} &#92;}" class="latex" />. Then train two models <img src="https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1 , q_2" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_2" class="latex" />, respectively.&nbsp;</p>



<p><strong>The Output Generative Model:</strong> Return the generative model <img src="https://s0.wp.com/latex.php?latex=p_k%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_k%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_k%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_k(y|x)" class="latex" /> defined as follows: On input a prompt <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />,&nbsp; first sample <img src="https://s0.wp.com/latex.php?latex=y+%5Csim+p%28%5Ccdot+%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y+%5Csim+p%28%5Ccdot+%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y+%5Csim+p%28%5Ccdot+%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y &#92;sim p(&#92;cdot |x)" class="latex" /> and then accept <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5Cbig%28+p%28y%7Cx%29+%2F+q_i%28y%7Cx%29+%5Cbig%29+%5Cleq+k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5Cbig%28+p%28y%7Cx%29+%2F+q_i%28y%7Cx%29+%5Cbig%29+%5Cleq+k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5Cbig%28+p%28y%7Cx%29+%2F+q_i%28y%7Cx%29+%5Cbig%29+%5Cleq+k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log &#92;big( p(y|x) / q_i(y|x) &#92;big) &#92;leq k" class="latex" />, for <img src="https://s0.wp.com/latex.php?latex=i%5Cin%5C%7B1%2C2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cin%5C%7B1%2C2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cin%5C%7B1%2C2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;in&#92;{1,2&#92;}" class="latex" />. (Otherwise, resample.)</p>



<p>The intuition of <img src="https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="CP-k" class="latex" /> is as follows: we first sample the output from <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> and only accept this output if the likelihood ratio to the <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}" class="latex" /> function (on any <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />) satisfies a desired upper bound, the latter of which can be verified by checking the likelihood ratio with respect to both <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" />. Since <img src="https://s0.wp.com/latex.php?latex=p_k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_k" class="latex" /> transforms the output of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> (i.e. it throws aways probability mass which could be potential copyright violations), one might be concerned that we will degrade the quality of the original model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />. Fortunately, we show when this is not the case. We give formal theoretical results on the effectiveness of the approach based on the information distances between <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" />; in fact, we sometimes even improve on the quality of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> with this approach. We also specify the relationship between the desired <img src="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_x" class="latex" /> and tunable parameter <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />.</p>



<h3 class="wp-block-heading"><strong>An Illustrative Experiment</strong></h3>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2023/02/image.png"><img data-attachment-id="8569" data-permalink="https://windowsontheory.org/2023/02/21/provable-copyright-protection-for-generative-models/image-11/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/02/image.png" data-orig-size="2284,548" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/02/image.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2023/02/image.png?w=656" src="https://windowsontheory.files.wordpress.com/2023/02/image.png?w=1024" alt="" class="wp-image-8569" srcset="https://windowsontheory.files.wordpress.com/2023/02/image.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2023/02/image.png?w=2048 2048w, https://windowsontheory.files.wordpress.com/2023/02/image.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/02/image.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/02/image.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px" /></a><figcaption class="wp-element-caption"><em><strong>Left: </strong>A model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> trained on the full modified CIFAR10 dataset; we injected multiple copies of two images (marked with red frames), so they are likely to be memorized by the model. <strong>Middle two images:</strong> Models <img src="https://s0.wp.com/latex.php?latex=q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1, q_2 " class="latex" /> trained on two shards of the dataset, split so that each injected image appears in only one of them. <strong>Right:</strong> A model obtained by combining <img src="https://s0.wp.com/latex.php?latex=p%2C+q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%2C+q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%2C+q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p, q_1, q_2 " class="latex" /> using our algorithm. Despite being a black-box transformation of the three memorizing models, the combined model does not output either of the injected images.</em></figcaption></figure>



<p>We now present a qualitative experiment demonstrating how applying our algorithm to memorizing models produces a model that no longer memorizes. Specifically, we first augment CIFAR-10 with multiple copies of two images (images close to the augmented images are marked with red boundaries); hypothetically, suppose these two images are copyrighted works. For illustrative purposes, we do not deduplicate our dataset. Note our goal here is not to simply present a heuristic approach, such as deduplication, that “often works in practice,” but it is to show that an algorithm with <em>rigorous guarantees</em> can also be practical.</p>



<p>&nbsp;The leftmost image shows generations from a model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> that was trained on the full dataset, where we clearly see that <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> generates the two copyrighted works. Our algorithm starts by splitting this dataset into two disjoint datasets, where the two copyrighted images are split into two different shards, and it trains two models <img src="https://s0.wp.com/latex.php?latex=q_1%2Cq_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1%2Cq_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1%2Cq_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1,q_2" class="latex" /> on these disjoint shards. The result is two models such that each generates the CIFAR-10 distribution, but also has a significant chance to output the memorized example. Yet when we combine all three of models using the CP-k algorithm, we obtain a model that agrees with them on the shared part of the distribution but is highly unlikely to output either one of the memorized images.</p>



<figure class="wp-block-image is-resized"><img src="https://lh4.googleusercontent.com/4yzcUxprXN23huNzSGxP6yAyzNgaRbwjlMBOQhWQ4VQ0Y1LP4HeNBpFljIGDX0_pub-xxHrbg6loBbP0vwG11iH3LAoPj9g6H_5rJa741JOHFDvkpSRPMcWM49CYvLuIV1NXLC1Zn2RRrQTcirr6g7c" alt="Illustration of the algorithm to obtain a model satisfying the NAF definition by first splitting the data into two disjoint shards, ensuring that duplicated copies of an image are in the same shard. Then we obtain a model by combining the models trained on both shards." width="635" height="356" /></figure>



<p>See the paper ( <a href="https://arxiv.org/abs/2302.10870">https://arxiv.org/abs/2302.10870</a>  )  for the full details of our definitions, theorems, and experiments. We believe that there is much room for follow-up work, including optimization of performance, as well as much larger-scale experiments.</p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T02:22:01Z">Wednesday, February 22 2023, 02:22</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, February 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://lucatrevisan.wordpress.com/2023/02/21/this-year-for-lent-we-gave-up-being-renters-in-milan/'>This year, for Lent, we gave up being renters in Milan</a></h3>
        <p class='tr-article-feed'>from <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          
        
        </div>

        <div class='tr-article-summary'>
        
          
          <figure data-carousel-extra='{"blog_id":821887,"permalink":"https:\/\/lucatrevisan.wordpress.com\/2023\/02\/21\/this-year-for-lent-we-gave-up-being-renters-in-milan\/"}'  class="wp-block-gallery has-nested-images columns-default is-cropped wp-block-gallery-1 is-layout-flex">
<figure class="wp-block-image size-large"><a href="https://lucatrevisan.files.wordpress.com/2023/02/img_1992.jpg"><img data-attachment-id="4664" data-permalink="https://lucatrevisan.wordpress.com/2023/02/21/this-year-for-lent-we-gave-up-being-renters-in-milan/img_1992/" data-orig-file="https://lucatrevisan.files.wordpress.com/2023/02/img_1992.jpg" data-orig-size="3009,3318" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XR&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1676998785&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;45.452072222222&quot;,&quot;longitude&quot;:&quot;9.1951472222222&quot;}" data-image-title="img_1992" data-image-description="" data-image-caption="" data-medium-file="https://lucatrevisan.files.wordpress.com/2023/02/img_1992.jpg?w=272" data-large-file="https://lucatrevisan.files.wordpress.com/2023/02/img_1992.jpg?w=584" data-id="4664"  src="https://lucatrevisan.files.wordpress.com/2023/02/img_1992.jpg?w=929" alt="" class="wp-image-4664" srcset="https://lucatrevisan.files.wordpress.com/2023/02/img_1992.jpg?w=929 929w, https://lucatrevisan.files.wordpress.com/2023/02/img_1992.jpg?w=1858 1858w, https://lucatrevisan.files.wordpress.com/2023/02/img_1992.jpg?w=136 136w, https://lucatrevisan.files.wordpress.com/2023/02/img_1992.jpg?w=272 272w, https://lucatrevisan.files.wordpress.com/2023/02/img_1992.jpg?w=768 768w" sizes="(max-width: 929px) 100vw, 929px" /></a></figure>
</figure>
<p class="authors">By luca</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-21T16:11:03Z">Tuesday, February 21 2023, 16:11</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, February 20
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/015'>TR23-015 |  A Qubit, a Coin, and an Advice String Walk Into a Relational Problem | 

	Scott Aaronson, 

	Harry Buhrman, 

	William Kretschmer</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Relational problems (those with many possible valid outputs) are different from decision problems, but it is easy to forget just how different.  This paper initiates the study of FBQP/qpoly, the class of relational problems solvable in quantum polynomial-time with the help of polynomial-sized quantum advice, along with its analogues for deterministic and randomized computation (FP, FBPP) and advice (/poly, /rpoly).

Our first result is that FBQP/qpoly != FBQP/poly, unconditionally, with no oracle---a striking contrast with what we know about the analogous decision classes.  The proof repurposes the separation between quantum and classical one-way communication complexities due to Bar-Yossef, Jayram, and Kerenidis.  We discuss how this separation raises the prospect of near-term experiments to demonstrate &quot;quantum information supremacy,&quot; a form of quantum supremacy that would not depend on unproved complexity assumptions.

Our second result is that FBPP is not contained in FP/poly---that is, Adleman&#39;s Theorem fails for relational problems---unless PSPACE is contained in NP/poly.  Our proof uses IP=PSPACE and time-bounded Kolmogorov complexity.  On the other hand, we show that proving FBPP not in FP/poly will be hard, as it implies a superpolynomial circuit lower bound for PromiseBPEXP.

We prove the following further results:
* Unconditionally, FP != FBPP and FP/poly != FBPP/poly (even when these classes are carefully defined).
* FBPP/poly = FBPP/rpoly (and likewise for FBQP).  For sampling problems, by contrast, SampBPP/poly != SampBPP/rpoly (and likewise for SampBQP).
        
        </div>

        <div class='tr-article-summary'>
        
          
          Relational problems (those with many possible valid outputs) are different from decision problems, but it is easy to forget just how different.  This paper initiates the study of FBQP/qpoly, the class of relational problems solvable in quantum polynomial-time with the help of polynomial-sized quantum advice, along with its analogues for deterministic and randomized computation (FP, FBPP) and advice (/poly, /rpoly).

Our first result is that FBQP/qpoly != FBQP/poly, unconditionally, with no oracle---a striking contrast with what we know about the analogous decision classes.  The proof repurposes the separation between quantum and classical one-way communication complexities due to Bar-Yossef, Jayram, and Kerenidis.  We discuss how this separation raises the prospect of near-term experiments to demonstrate &quot;quantum information supremacy,&quot; a form of quantum supremacy that would not depend on unproved complexity assumptions.

Our second result is that FBPP is not contained in FP/poly---that is, Adleman&#39;s Theorem fails for relational problems---unless PSPACE is contained in NP/poly.  Our proof uses IP=PSPACE and time-bounded Kolmogorov complexity.  On the other hand, we show that proving FBPP not in FP/poly will be hard, as it implies a superpolynomial circuit lower bound for PromiseBPEXP.

We prove the following further results:
* Unconditionally, FP != FBPP and FP/poly != FBPP/poly (even when these classes are carefully defined).
* FBPP/poly = FBPP/rpoly (and likewise for FBQP).  For sampling problems, by contrast, SampBPP/poly != SampBPP/rpoly (and likewise for SampBQP).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-20T21:25:19Z">Monday, February 20 2023, 21:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/02/20/geometric-graphs-unbounded.html'>Geometric graphs with unbounded flip-width</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          At the recent Workshop on Geometry and Graphs in Barbados, most of the technical activity involved working in small groups on research problems, but there was also a nice survey talk by Rose McCarty on flip-width.1 This is a new and very general notion of width in graphs, introduced by Szymon Toruńczyk.2 It is defined in terms of a certain cops-and-robbers game on graphs, and intended to capture the structure inherent in many types of graphs and to unify bounded expansion and twin-width. Rose also helped me edit a preliminary version of this post. Thanks, Rose! Any remaining errors are my fault. &#8617; Szymon Toruńczyk (2023), “Flip-width: cops and robber on dense graphs”, arXiv:2302.00352 &#8617;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>At the recent <a href="https://wogag.org/">Workshop on Geometry and Graphs</a> in Barbados, most of the technical activity involved working in small groups on research problems, but there was also a nice survey talk by <a href="https://web.math.princeton.edu/~rm1850/">Rose McCarty</a> on flip-width.<sup id="fnref:r" role="doc-noteref"><a href="#fn:r" class="footnote" rel="footnote">1</a></sup> This is a new and very general notion of width in graphs, introduced by <a href="https://www.mimuw.edu.pl/~szymtor/">Szymon Toruńczyk</a>.<sup id="fnref:t" role="doc-noteref"><a href="#fn:t" class="footnote" rel="footnote">2</a></sup> It is defined in terms of a certain cops-and-robbers game on graphs, and intended to capture the structure inherent in many types of graphs and to unify <a href="https://en.wikipedia.org/wiki/Bounded_expansion">bounded expansion</a> and <a href="https://en.wikipedia.org/wiki/Twin-width">twin-width</a>.</p>

<p>For instance, many algorithmic graph problems, such as searching for small patterns in larger graphs (“<a href="https://en.wikipedia.org/wiki/Subgraph_isomorphism_problem">subgraph isomorphism</a>”) can be formulated more abstractly in terms of of checking whether a graph models a given formula in the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a>. Such problems are <a href="https://en.wikipedia.org/wiki/Parameterized_complexity">fixed-parameter tractable</a> when parameterized either by expansion or twin-width, and it is hoped that the same thing will extend to flip-width. Very recent partial results in this direction extend model checking algorithms from bounded expansion to “structurally nowhere dense classes”,<sup id="fnref:dms" role="doc-noteref"><a href="#fn:dms" class="footnote" rel="footnote">3</a></sup> but these classes do not even include everything with bounded twin-width, let alone flip-width.</p>

<p>For the purposes of this post, the only thing we need to know about bounded expansion is that graph families with this property must be sparse: in their graphs, the number of edges must be at most linear in the number of vertices.<sup id="fnref:no" role="doc-noteref"><a href="#fn:no" class="footnote" rel="footnote">4</a></sup> On the other hand, although graph families with bounded twin-width can be dense, they are limited in a different way: the number of graphs in the family, on a set of \(n\) unlabeled vertices, can only be singly exponential <span style="white-space:nowrap">in \(n\).<sup id="fnref:st" role="doc-noteref"><a href="#fn:st" class="footnote" rel="footnote">5</a></sup></span> One way to get a family of graphs that have bounded flip-width but not bounded expansion nor bounded twin-width is to take the union of two families, one dense with bounded twin-width and the other numerous with bounded expansion. For instance, take the graphs that are either <a href="https://en.wikipedia.org/wiki/Cograph">cographs</a> or <a href="https://en.wikipedia.org/wiki/Cubic_graph">3-regular</a>. But this is not a very natural family of graphs. Rose asked: is there a natural family of graphs with bounded flip-width but unbounded twin-width and expansion? For instance, there are many standard types of geometric graphs for which the twin-width and expansion are unbounded; could any of these have bounded flip-width?</p>

<h1 id="cops-and-robbers">Cops and robbers</h1>

<p>Like <a href="https://en.wikipedia.org/wiki/Treewidth">treewidth</a> and bounded expansion, flip-width can be defined using a certain <a href="https://en.wikipedia.org/wiki/Pursuit%E2%80%93evasion">cops-and-robbers game</a> on graphs.<sup id="fnref:t:1" role="doc-noteref"><a href="#fn:t" class="footnote" rel="footnote">2</a></sup></p>

<p>The games used for treewidth and expansion involve “cops with helicopters”, chasing a robber on a given graph. At each point in the game, the cops occupy a limited number of graph vertices. Then, at each move, the cops announce where they will move next, the robber moves to escape them along a path through the currently-unoccupied vertices, and then the cops fly directly to their new locations. The cops win if one of them lands on the robber’s current vertex, and the robber wins by evading the cops indefinitely. The treewidth of a graph is the maximum number of cops that a robber can evade, moving arbitrarily far on each move. A family of graphs has bounded expansion if and only if there is some function \(f\) such that only \(f(r)\) cops are needed to catch a robber who can move at most \(r\) steps per move.<sup id="fnref:t2" role="doc-noteref"><a href="#fn:t2" class="footnote" rel="footnote">6</a></sup></p>

<p>As Rose described, the same game can be described in a different way. Instead of occupying a vertex, the cops set up roadblocks on all the edges incident to it. On each move, the cops announce which vertices will be blockaded next. Then, the robber moves along un-blockaded edges. Finally, the cops remove their current blockades and put up new blockades at the vertices they announced. The cops win by leaving the robber at an isolated vertex, unable to move.</p>

<p style="text-align:center"><img src="/blog/assets/2023/roadblock.jpg" alt="Police roadblock in Washington, DC, January 15, 2021" title="CC-BY image by Mike Licht from Wikimedia commons, File:Inaugural preparation, January 15th Roadblock (50840138737).jpg" style="width:100%;max-width:540px" /></p>

<p>Flip-width is defined in the same way, but with more powerful cops. Instead of blockading a single vertex, they are allowed to perform a “flip” of a subset of vertices. This complements the subgraph within that subset: pairs of vertices that were connected become disconnected, and vice versa. So blockading a single vertex, for instance, can be accomplished by two flips: one flip of the vertex and its neighbors, and one flip of just the neighbors. The first flip disconnects the given vertex, and the second flip restores the original connectivity among the neighboring vertices. It doesn’t matter in which order these two flips (or any set of flips) is performed.</p>

<p style="text-align:center"><img src="/blog/assets/2023/flip-isolate.svg" alt="Isolating a vertex by two flips" style="width:100%;max-width:720px" /></p>

<p>In the flipping game used to define flip-width, at any point in the game, the cops will have performed some limited number of flips. Then in each move, the cops announce which sets of vertices they will flip next. The robber moves along a path in the current flipped graph, to evade these flips. Then, the cops undo their current flips and perform the new flips that they announced. The cops win if they leave the robber at an isolated vertex, unable to move, and the robber wins by avoiding this fate indefinitely. A family of graphs has bounded flip-width if there is some function \(f\) such that only \(f(r)\) flips per move are needed to catch a robber who can move at most \(r\) steps per move.</p>

<p>For the purposes of having bounded flip-width, two graphs that differ from each other only by a finite number \(\varphi\) of flips are essentially the same. If the cops can win on one, they can win on the other with only \(\varphi\) more flips per move. They only need to start by performing those \(\varphi\) flips to convert the second graph into the first one, and then leave those flips in place while they perform the winning strategy on the converted graph. So, for instance, the graphs that differ by a single flip from a 3-regular graph have bounded flip-width, but are again not a very natural class of graphs.</p>

<h1 id="interchanges">Interchanges</h1>

<p>Continuing the road network metaphor, and in the spirit of the <a href="https://en.wikipedia.org/wiki/Haven_(graph_theory)">havens</a> used to model escape strategies in the treewidth game, let’s define a structure I call an <em>interchange</em>, having pairwise connections between many points, which a robber can use to make a getaway from few enough cops.</p>

<p style="text-align:center"><img src="/blog/assets/2017/HighFive.jpg" alt="High Five Interchange at the intersection of I-635 and U.S. Route 75 in Dallas, Texas, looking towards the southwest" title="cropped from https://commons.wikimedia.org/wiki/File:High_Five.jpg by fatguyinalittlecoat on flickr, under a CC-BY 2.0 license" style="width:100%;max-width:540px" /></p>

<p>More precisely, define an interchange of order \(n\) to consist of the following components:</p>

<ul>
  <li>
    <p>Certain designated vertices, which we call <em>lanes</em>. The interchange should have \(n\) lanes, arranged into a sequence. These are colored blue in the following illustrations.</p>
  </li>
  <li>
    <p>More designated vertices, called <em>ramps</em>. Each ramp is associated with a pair of lanes. When two lanes are \(n-3\) or fewer steps apart in the sequence, they have an associated ramp. (We don’t require ramps for pairs of the outermost lanes because they would not be helpful to the robber in the game.) The ramps are colored red in the following illustrations.</p>
  </li>
  <li>
    <p>An edge between each ramp and its two associated lanes.</p>
  </li>
  <li>
    <p>Optional edges between any two lanes or between any two ramps. These will be unused by the robber and do not affect the robber’s strategy. The optional edges mean that the class of all interchanges is huge, too large to have bounded twin-width. But more importantly for us, they allow us to construct geometric realizations of these graphs without worrying about whether or not the construction causes certain pairs of vertices to become adjacent.</p>
  </li>
  <li>
    <p>For a ramp that connects lanes \(x\) and \(y\), optional edges to other lanes between \(x\) and \(y\) in the sequence (edges to lanes outside that range are not allowed).</p>
  </li>
</ul>

<p>The image below shows an example, with the lanes blue, ramps red, optional edges yellow, and required edges black. The blue lanes are ordered in a sequence from left to right, but otherwise the placement of vertices is not meaningful; it’s the graph structure that matters.</p>

<p style="text-align:center"><img src="/blog/assets/2023/5-interchange.svg" alt="Interchange of order 5" style="width:100%;max-width:540px" /></p>

<p>As we show next, large-enough interchanges can be used by the robber to escape any fixed number of cops.</p>

<h1 id="escaping-through-junctions">Escaping through junctions</h1>

<p>Call a set of lanes <em>equivalent</em>, after certain flips have been made, if they are all treated the same by each flip: all included in the flipped set, or all excluded.
Define a <em>junction</em> to be a triple of equivalent lanes that are connected to each other by paths through one or two ramps, after the flips are made. Then:</p>

<ul>
  <li>
    <p>Every four equivalent lanes have at least one junction. For, if the lanes are \(a,b,c,d\) (in sequence order) then the <span style="white-space:nowrap">\(a\)–\(b\)</span> ramp either continues to connect \(a\) to \(b\), or it is flipped and instead connects <span style="white-space:nowrap">\(c\) to \(d\).</span> A third connection is provided either by the <span style="white-space:nowrap">\(b\)–\(c\)</span> ramp or its flip, which connects <span style="white-space:nowrap">\(a\) to \(d\).</span></p>
  </li>
  <li>
    <p>In every six equivalent lanes, at least three of the lanes belong to two otherwise-disjoint junctions. I’ll skip the messy case analysis showing this.</p>
  </li>
  <li>
    <p>Every two junctions are connected by at least one ramp between two of their lanes. If the junctions are \(a,b,c\) and \(d,e,f\), listed in the sequence order of all the lanes, then they have either \(a,b,e,f\) or \(d,e,b,c\) as a subsequence (depending on the ordering between <span style="white-space:nowrap">\(b\) and \(e\)).</span> In either case they are connected by the <span style="white-space:nowrap">\(b\)–\(e\)</span> ramp or its flip.</p>
  </li>
  <li>
    <p>By the same argument, every two triples of equivalent lanes are connected by at least one ramp.</p>
  </li>
</ul>

<p>These connections imply that, in an interchange that is big enough to guarantee the existence of junctions, the robber can win by always moving to a lane that will become part of a junction after the announced flips happen.</p>

<p>In more detail, suppose that the cops and a robber play the flipping game, with \(t\) flips per move and \(r\ge 6\), and that the graph includes an interchange of <span style="white-space:nowrap">order \(3\cdot 2^{2t}+1\).</span> This interchange is big enough to ensure that some four lanes are equivalent both in the current and announced set of flips. These four lanes include a junction under the announced flips. The robber can move to this new junction using at most two ramps within the current junction and then one more ramp to cross between the two triples of lanes. With an interchange that is a little larger, of <span style="white-space:nowrap">order \(5\cdot 2^{2t}+1\),</span> the robber can win with \(r\ge 4\), by moving to a lane that will become part of two otherwise-disjoint junctions, so that two other equivalent lanes will be reachable by only one ramp.</p>

<p>This strategy shows that, if a graph class contains arbitrarily large interchanges, it does not have bounded flip-width. We will use this idea to show that many natural classes of geometric graphs do not have bounded flip-width.</p>

<h1 id="geometric-graphs">Geometric graphs</h1>

<p>In each of the following types of geometric graph, it is possible to form arbitrarily large interchanges, as illustrated.</p>

<ul>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Interval_graph">Interval graphs</a> and <a href="https://en.wikipedia.org/wiki/Permutation_graph">permutation graphs</a>. Just make a left-to-right sequence of small disjoint blue intervals for the lanes, and connect them by longer red intervals for the ramps. Each red interval contains all of the blue intervals that it intersects, and permutation graphs are the same thing as <a href="https://www.graphclasses.org/classes/gc_288.html">interval containment graphs</a>. In contrast, the <a href="https://en.wikipedia.org/wiki/Indifference_graph">unit interval graphs</a> are known to have bounded twin-width,<sup id="fnref:tw3" role="doc-noteref"><a href="#fn:tw3" class="footnote" rel="footnote">7</a></sup> from which it follows that they also have bounded flip-width.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/interval-interchange.svg" alt="Interval graph forming an interchange of order 6" /></p>
  </li>
  <li>
    <p>Circle graphs. These have the permutation graphs as a special case, but there’s also a direct construction.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/circle-interchange.svg" alt="Circle graph forming an interchange of order 6" style="width:100%;max-width:540px" /></p>
  </li>
  <li>
    <p>Intersection graphs of axis-aligned line segments, no two collinear. Use long horizontal segments for the lanes, ordered vertically, and span them by vertical ramps.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/line-segment-interchange.svg" alt="Axis-aligned line segments forming an interchange of order 6" /></p>
  </li>
  <li>
    <p>Intersection graphs of axis-parallel unit squares. Place the blue lane squares with their top right corners on a diagonal line, close enough together that any consecutive interval of them can be covered by a red ramp square.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/square-interchange.svg" alt="Squares forming an interchange of order 6" style="width:100%;max-width:540px" /></p>
  </li>
  <li>
    <p>Unit disk graphs. This one is unfortunately difficult to see clearly because the details are tiny with respect to the overall form, even for the \(n=6\) example shown. Anyway, place \(n\) blue unit disks tangent to the outside of a circle of radius \(1+\varepsilon\) (yellow in the figure), so that their points of tangencies span an arc of diameter less than \(2\). Then place red unit disks with their centers inside the yellow circle, so that their intersections with the circle form arcs that look like the interval graph model above. Because their radius is smaller than the yellow circle, the red disks will bulge out of the yellow circle a little bit. They intersect the blue points of tangency in the pattern that we want, but the parts that bulge out may have some unwanted contacts with the other blue disks. To prevent this, make \(\varepsilon\) very small. As you decrease \(\varepsilon\), the red bulges will shrink towards the yellow circle, but the blue disks won’t change their positions or angles very much, so for sufficiently small values of \(\varepsilon\) there will be no unwanted contacts.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/disk-interchange.svg" alt="Unit disks forming an interchange of order 6" /></p>
  </li>
  <li>
    <p>Unit distance graphs. Place the blue vertices equally spaced along an interval of length less than two and the red vertices that connect them on the points where unit circles centered on the blue vertices cross each other.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/unit-distance-interchange.svg" alt="Unit distance graph forming an interchange of order 6" /></p>
  </li>
  <li>
    <p>Visibility graphs of simple polygons. Place the blue vertices in sequence order on a horizontal line, the red vertices that connect pairs of consecutive blue vertices in order on a parallel line above them, and the remaining red vertices in an arbitrary order on a parallel line below them. Draw a triangle between each red vertex and the two blue vertices it should connect, and take the union of the triangles. Fill any holes that might have been formed in taking the union. The resulting polygon has additional vertices but that doesn’t affect the existence of an interchange. (This construction is simplified from an earlier construction by Rose, of visibility graphs that can be flipped to contain subdivisions of complete graphs.)</p>

    <p>Visibility graphs are <a href="https://en.wikipedia.org/wiki/Cop-win_graph">cop-win graphs</a>, meaning that a single cop wins a different cop-and-robber game in which both players can either move along a graph edge or stand still.<sup id="fnref:lsv" role="doc-noteref"><a href="#fn:lsv" class="footnote" rel="footnote">8</a></sup> But this doesn’t say anything about the flipping game: any graph can be made into a cop-win graph by adding a single <a href="https://en.wikipedia.org/wiki/Universal_vertex">universal vertex</a>, without changing whether it has bounded flip-width.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/visibility-interchange.svg" alt="Polygon whose visibility graph forms an interchange of order 6" /></p>
  </li>
  <li>
    <p>Four-dimensional convex polytopes. I’m not even going to try to draw this one, but the construction is easy to describe in words. Just take the <a href="https://en.wikipedia.org/wiki/Barycentric_subdivision">barycentric subdivision</a> of a <a href="https://en.wikipedia.org/wiki/Neighborly_polytope">neighborly polytope</a>. Neighborly polytopes have edges and vertices forming complete graphs; the barycentric subdivision of any polytope is another polytope.<sup id="fnref:es" role="doc-noteref"><a href="#fn:es" class="footnote" rel="footnote">9</a></sup> It has a vertex for each face of the original polytope, and an edge for each incidence between faces of different dimensions. Arrange the vertices of the neighborly polytope into an arbitrary sequence as lanes; use the subdivision vertices coming from its edges as ramps. In this way the ramps will be connected only to their two associated lanes and to other subdivision points, but not to any other lanes.</p>
  </li>
</ul>

<h1 id="where-now">Where now?</h1>

<p>We’re still missing a natural class of graphs with bounded flip-width, unbounded twin-width, and unbounded expansion. The known classes of geometric graphs looked promising as a direction to look for such classes, but these constructions rule that out in surprisingly many cases.</p>

<p>It still might be possible that the number of cops needed to catch a robber on these graphs could be low. The interchange construction only proves that it is at least logarithmic. But I don’t know of any useful algorithmic consequences of having a low but unbounded number of cops needed to catch a bounded-speed robber.</p>

<h1 id="notes-and-references">Notes and references</h1>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:r" role="doc-endnote">
      <p>Rose also helped me edit a preliminary version of this post. Thanks, Rose! Any remaining errors are my fault. <a href="#fnref:r" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:t" role="doc-endnote">
      <p>Szymon Toruńczyk (2023), “Flip-width: cops and robber on dense graphs”, <a href="https://arxiv.org/abs/2302.00352">arXiv:2302.00352</a> <a href="#fnref:t" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:t:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:dms" role="doc-endnote">
      <p>Jan Dreier, Nikolas Mählmann, and Sebastian Siebertz (2023), “First-order model checking on structurally sparse graph classes”, <a href="https://arxiv.org/abs/2302.03527">arXiv:2302.03527</a> <a href="#fnref:dms" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:no" role="doc-endnote">
      <p>Jaroslav Nešetřil and Patrice Ossona de Mendez (2012), “5.5: Classes with bounded expansion”, <em>Sparsity: Graphs, Structures, and Algorithms</em>, pp. 104–107, Springer, Algorithms and Combinatorics, vol. 28, <a href="https://doi.org/10.1007/978-3-642-27875-4">doi:10.1007/978-3-642-27875-4</a> <a href="#fnref:no" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:st" role="doc-endnote">
      <p>Pierre Simon and Szymon Toruńczyk (2021), “Ordered graphs of bounded twin-width”, <a href="https://arxiv.org/abs/2102.06881">arXiv:2102.06881</a> <a href="#fnref:st" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:t2" role="doc-endnote">
      <p>See Corollary 3.6 of Toruńczyk (2023)<sup id="fnref:t:2" role="doc-noteref"><a href="#fn:t" class="footnote" rel="footnote">2</a></sup> <a href="#fnref:t2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:tw3" role="doc-endnote">
      <p>See Lemma 13 of  Édouard Bonnet, Colin Geniet, Eun Jung Kim, Stéphan Thomassé, and Rémi Watrigant, “Twin-width III: Max Independent Set and Coloring”, <a href="https://arxiv.org/abs/2007.14161v2">arXiv:2007.14161v2</a> (this lemma is not in the <em>ICALP</em> 2021 version and numbered differently in other arXiv versions) <a href="#fnref:tw3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:lsv" role="doc-endnote">
      <p>Anna Lubiw, Jack Snoeyink, and Hamideh Vosoughpour (2017), “Visibility graphs, dismantlability, and the cops and robbers game”, <em>CGTA</em> 66: 14–27, <a href="https://arxiv.org/abs/1601.01298">arXiv:1601.01298</a> <a href="#fnref:lsv" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:es" role="doc-endnote">
      <p>Günter Ewald and Geoffrey C. Shephard (1974), “Stellar subdivisions of boundary complexes of convex polytopes”, <em>Math. Ann.</em> 210: 7–16, <a href="https://doi.org/10.1007/BF01344542">doi:10.1007/BF01344542</a>. <a href="#fnref:es" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/109901138706218444">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-20T21:20:00Z">Monday, February 20 2023, 21:20</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/20/phd-position-at-chalmers-university-of-technology-apply-by-march-13-2023/'>PhD position at Chalmers University of Technology (apply by March 13, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Ph.D. project will focus on developing quantum algorithms for near-term devices, exploring both their advantages and limitations compared to classical algorithms running on conventional computers. Website: www.chalmers.se/en/about-chalmers/work-with-us/vacancies/?rmpage=job&#38;rmjob=11382&#38;rmlang=UK Email: dubhashi@chalmers.se
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Ph.D. project will focus on developing quantum algorithms for near-term devices, exploring both their advantages and limitations compared to classical algorithms running on conventional computers.</p>
<p>Website: <a href="https://www.chalmers.se/en/about-chalmers/work-with-us/vacancies/?rmpage=job&amp;rmjob=11382&amp;rmlang=UK">https://www.chalmers.se/en/about-chalmers/work-with-us/vacancies/?rmpage=job&amp;rmjob=11382&amp;rmlang=UK</a><br />
Email: dubhashi@chalmers.se</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-20T20:38:26Z">Monday, February 20 2023, 20:38</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/20/phd-student-at-technical-university-of-denmark-apply-by-march-9-2023/'>PhD Student at Technical University of Denmark (apply by March 9, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We will give new, efficient algorithms and data structures for dynamic graphs. The fun challenge in this field is to find the right partial answers to update as the graph changes, while letting the algorithm for queries do some of the work of putting the answer together. Often, the road to efficient algorithms goes via [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We will give new, efficient algorithms and data structures for dynamic graphs. The fun challenge in this field is to find the right partial answers to update as the graph changes, while letting the algorithm for queries do some of the work of putting the answer together. Often, the road to efficient algorithms goes via graph theoretic insights.</p>
<p>Website: <a href="https://efzu.fa.em2.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1/job/1402/?keyword=dynamic&amp;mode=job-location">https://efzu.fa.em2.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1/job/1402/?keyword=dynamic&amp;mode=job-location</a><br />
Email: erot@dtu.dk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-20T08:57:04Z">Monday, February 20 2023, 08:57</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/014'>TR23-014 |  Depth-3 Circuit Lower Bounds for k-OV | 

	Tameem  Choudhury, 

	Karteek Sreenivasaiah</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The 2-Orthogonal Vectors (2-OV) problem is the following: given two tuples $A$ and $B$ of $n$ vectors each of dimension $d$, decide if there exists a vector $u\in A$, and $v\in B$ such that $u$ and $v$ are orthogonal. This problem, and its generalization $k$-OV defined analogously for $k$ tuples, are central problems in the area of fine-grained complexity. Informally speaking, one of the major conjectures in fine-grained complexity is that deciding $k$-OV requires time $\Omega(n^k d)$. In this paper, we are interested in unconditional lower bounds against $k$-OV, but for weaker models of computation than the general Turing Machine. In particular, we are interested in circuit lower bounds to computing $k$-OV by Boolean circuit families of depth 3 of the form OR-AND-OR, or equivalently, a disjunction of CNFs. We show that for all $k\leq d$, any disjunction of $t$-CNFs computing $k$-OV requires size $\Omega((n/t)^k)$.  In particular, when $k$ is a constant, any disjunction of $k$-CNFs computing $k$-OV needs to use $\Omega(n^k)$ CNFs. This matches the brute-force construction. Thus for each fixed $k\ge 2$, the complexity of computing $k$-OV as a disjunction of $k$-CNFs is $\Theta(n^k)$. Our results partially resolve a conjecture by Kane and Williams [16] (page 12, conjecture 10) about depth-3 $AC^0$ circuits computing 2-OV. As a secondary result, we show an exponential lower bound on the size of AND-OR-AND circuits computing 2-OV when $d$ is very large. Since 2-OV reduces to $k$-OV by projections trivially, this lower bound works against $k$-OV as well.

Kane and Williams[16]: The orthogonal vectors conjecture for branching programs and formulas (ITCS 2019)
        
        </div>

        <div class='tr-article-summary'>
        
          
          The 2-Orthogonal Vectors (2-OV) problem is the following: given two tuples $A$ and $B$ of $n$ vectors each of dimension $d$, decide if there exists a vector $u\in A$, and $v\in B$ such that $u$ and $v$ are orthogonal. This problem, and its generalization $k$-OV defined analogously for $k$ tuples, are central problems in the area of fine-grained complexity. Informally speaking, one of the major conjectures in fine-grained complexity is that deciding $k$-OV requires time $\Omega(n^k d)$. In this paper, we are interested in unconditional lower bounds against $k$-OV, but for weaker models of computation than the general Turing Machine. In particular, we are interested in circuit lower bounds to computing $k$-OV by Boolean circuit families of depth 3 of the form OR-AND-OR, or equivalently, a disjunction of CNFs. We show that for all $k\leq d$, any disjunction of $t$-CNFs computing $k$-OV requires size $\Omega((n/t)^k)$.  In particular, when $k$ is a constant, any disjunction of $k$-CNFs computing $k$-OV needs to use $\Omega(n^k)$ CNFs. This matches the brute-force construction. Thus for each fixed $k\ge 2$, the complexity of computing $k$-OV as a disjunction of $k$-CNFs is $\Theta(n^k)$. Our results partially resolve a conjecture by Kane and Williams [16] (page 12, conjecture 10) about depth-3 $AC^0$ circuits computing 2-OV. As a secondary result, we show an exponential lower bound on the size of AND-OR-AND circuits computing 2-OV when $d$ is very large. Since 2-OV reduces to $k$-OV by projections trivially, this lower bound works against $k$-OV as well.

Kane and Williams[16]: The orthogonal vectors conjecture for branching programs and formulas (ITCS 2019)
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-20T06:52:41Z">Monday, February 20 2023, 06:52</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/it-is-more-important-than-ever-to-teach.html'>It is  more important than ever to teach your students probability (even non-stem students)</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>(This topic was also covered&nbsp;here.)&nbsp;</p><p>You are a college president. An online betting company says&nbsp;&nbsp;We will give you X dollars if you allow us to promote online gambling at your University.</p><p>I suspect you would say NO.</p><p>Too late- it's already happening. A link to a NY times article about this is:&nbsp;here. I urge you to read the entire article. It's worse than it sounds.&nbsp;</p><p>My thoughts</p><p>0) I wondered if&nbsp; a company needed permission to promote a product on a campus. I am not sure of the answer; however, in some cases a school HELPED with the promotion:&nbsp;</p><p>a) During a game there are announcements reminding students that they can place a sports bet! It's easy! It's fun!</p><p>b) Links on the schools website to sports gambling sites</p><p>c) References to sports betting in emails that goto students.</p><p>This is WAY BEYOND&nbsp; allowing a company to promote.</p><p>1) Some points from the article&nbsp;</p><p>Some aspects of the deals also appear to violate the gambling industry's own rules against marketing to underage people. The ``Responsible Marketing Code'' published by the American Gaming Association, the umbrella group for the industry, says sports betting should not be advertised on college campuses.&nbsp;</p><p>``We are not seeing enough oversight, transparency, and education to support the rollout of these kinds of deals'' said Michael Goldman who teaches sports marketing at the Univ of San. Fran.&nbsp;</p><p>During the pandemic, many universities struggled financially ...To fill those holes public and private universities nationwide have been struggling to line up new revenue sources, including by arranging sponsorship deals. (MY THOUGHTS- They don't quite say it, but it seems like the extra money is going back to sports programs. I would be happier if it went into academics- and to be fair, maybe some of it does.)&nbsp;</p><p>2) Online gambling is more addictive than in-person gambling. And it's easier since you don't have to leave your dorm room to do it.&nbsp;</p><p>3) The school gets money and&nbsp; teaches the students that everything is for sale. So it's a win-win (I am kidding.)&nbsp;</p><p>4) Should a college take&nbsp; money to allow the promotion of tobacco or alcohol or (if it becomes legal) heroin? I see NO difference between those and online gambling. (See&nbsp;here)</p><p>5) I am in favor of all of those things being legal (maybe not heroin but I am open to debate on that)&nbsp; however, there is a big difference between making something legal, and promoting it.&nbsp;&nbsp;</p><p>6) Silver Lining: This may encourage more students, even non-STEM students, to learn probability. Either advertise it honestly:</p><p><br>Take Probability to find out that Sports Betting is a Loser's Game</p><p><br></p><p>Or advertise it dishonestly</p><p><br></p><p>Take Probability to find out how you can win at Sports Betting!</p><p><br></p><p>&nbsp;</p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>(This topic was also covered&nbsp;<a href="https://statmodeling.stat.columbia.edu/2023/01/19/there-are-five-ways-to-get-fired-from-caesars-1-theft-2-sexual-harassment-3-running-an-experiment-without-a-control-group-4-keeping-a-gambling-addict-away-from-the-casino-5-refusing-to/">here</a>.)&nbsp;</p><p>You are a college president. An online betting company says&nbsp;&nbsp;<i>We will give you X dollars if you</i> <i>allow us to promote online gambling at your University.</i></p><p>I suspect you would say NO.</p><p>Too late- it's already happening. A link to a NY times article about this is:&nbsp;<a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/sportsbetting.pdf">here</a>. I urge you to read the entire article. It's worse than it sounds.&nbsp;</p><p>My thoughts</p><p>0) I wondered if&nbsp; a company needed permission to promote a product on a campus. I am not sure of the answer; however, in some cases a school HELPED with the promotion:&nbsp;</p><p>a) During a game there are announcements reminding students that they can place a sports bet! It's easy! It's fun!</p><p>b) Links on the schools website to sports gambling sites</p><p>c) References to sports betting in emails that goto students.</p><p>This is WAY BEYOND&nbsp; <i>allowing a company to promote.</i></p><p>1) Some points from the article&nbsp;</p><p>Some aspects of the deals also appear to violate the gambling industry's own rules against marketing to underage people. The ``Responsible Marketing Code'' published by the American Gaming Association, the umbrella group for the industry, says sports betting <i>should not be advertised on college campuses.</i>&nbsp;</p><p>``We are not seeing enough oversight, transparency, and education to support the rollout of these kinds of deals'' said Michael Goldman who teaches sports marketing at the Univ of San. Fran.&nbsp;</p><p>During the pandemic, many universities struggled financially ...To fill those holes public and private universities nationwide have been struggling to line up new revenue sources, including by arranging sponsorship deals. (MY THOUGHTS- They don't quite say it, but it seems like the extra money is going back to sports programs. I would be happier if it went into academics- and to be fair, maybe some of it does.)&nbsp;</p><p>2) Online gambling is more addictive than in-person gambling. And it's easier since you don't have to leave your dorm room to do it.&nbsp;</p><p>3) The school gets money and&nbsp; teaches the students that everything is for sale. So it's a win-win (I am kidding.)&nbsp;</p><p>4) Should a college take&nbsp; money to allow the promotion of tobacco or alcohol or (if it becomes legal) heroin? I see NO difference between those and online gambling. (See&nbsp;<a href="https://www.caron.org/blog/fortnite-may-be-as-addictive-as-heroin">here</a>)</p><p>5) I am in favor of all of those things being legal (maybe not heroin but I am open to debate on that)&nbsp; however, there is a big difference between making something legal, and promoting it.&nbsp;&nbsp;</p><p>6) Silver Lining: This may encourage more students, even non-STEM students, to learn probability. Either advertise it honestly:</p><p><br />Take Probability to find out that Sports Betting is a Loser's Game</p><p><br /></p><p>Or advertise it dishonestly</p><p><br /></p><p>Take Probability to find out how you can win at Sports Betting!</p><p><br /></p><p>&nbsp;</p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-20T02:38:00Z">Monday, February 20 2023, 02:38</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, February 19
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/013'>TR23-013 |  A Lower Bound on the Share Size in Evolving Secret Sharing | 

	Noam Mazor</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Secret sharing schemes allow sharing a secret between a set of parties in a way that ensures that only authorized subsets of the parties learn the secret. Evolving secret sharing schemes (Komargodski, Naor, and Yogev [TCC ’16]) allow achieving this end in a scenario where the parties arrive in an online fashion, and there is no a-priory bound on the number of parties. An important complexity measure of a secret sharing scheme is the share size, which is the maximum number of bits that a party may receive as a share. While there has been a significant progress in recent years, the best constructions for both secret sharing and evolving secret sharing schemes have a share size that is exponential in the number of parties. On the other hand, the best lower bound, by Csirmaz [Eurocrypt ’95], is sub-linear.

In this work, we give a tight lower bound on the share size of evolving secret sharing schemes. Specifically, we show that the sub-linear lower bound of Csirmaz implies an exponential lower bound on evolving secret sharing.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Secret sharing schemes allow sharing a secret between a set of parties in a way that ensures that only authorized subsets of the parties learn the secret. Evolving secret sharing schemes (Komargodski, Naor, and Yogev [TCC ’16]) allow achieving this end in a scenario where the parties arrive in an online fashion, and there is no a-priory bound on the number of parties. An important complexity measure of a secret sharing scheme is the share size, which is the maximum number of bits that a party may receive as a share. While there has been a significant progress in recent years, the best constructions for both secret sharing and evolving secret sharing schemes have a share size that is exponential in the number of parties. On the other hand, the best lower bound, by Csirmaz [Eurocrypt ’95], is sub-linear.

In this work, we give a tight lower bound on the share size of evolving secret sharing schemes. Specifically, we show that the sub-linear lower bound of Csirmaz implies an exponential lower bound on evolving secret sharing.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-19T18:48:03Z">Sunday, February 19 2023, 18:48</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/19/thanks-to-rich/'>Thanks to Rich</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Richard DeMillo deserves, in my opinion, an award for his decades of research. A difficulty I believe is that he has worked on multiple areas and made important contributions to each of these areas. Let’s take a look at the top two. For the record he held prior to joining Georgia Tech: Chief Technology Officer [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Richard DeMillo deserves, in my opinion, an award for his decades of research. A difficulty I believe is that he has worked on multiple areas and made important contributions to each of these areas. Let’s take a look at the top two.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/02/19/thanks-to-rich/rd/" rel="attachment wp-att-21138"><img data-attachment-id="21138" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/19/thanks-to-rich/rd/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rd.jpg?fit=440%2C587&amp;ssl=1" data-orig-size="440,587" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rd" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rd.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rd.jpg?fit=440%2C587&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rd.jpg?resize=225%2C300&#038;ssl=1" alt="" width="225" height="300" class="aligncenter size-medium wp-image-21138" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rd.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rd.jpg?resize=300%2C400&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rd.jpg?resize=150%2C200&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/rd.jpg?w=440&amp;ssl=1 440w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1" /></a></p>
<p>For the record he held prior to joining Georgia Tech: Chief Technology Officer for Hewlett-Packard, Vice President of Computing Research for Bell Communications Research, Director of the Computer Research Division for the National Science Foundation, and Director of the Software Test and Evaluation Project for the Office of the Secretary of Defense. He has also held faculty positions at the University of Wisconsin, Purdue University and the University of Padua, Italy.</p>
<h2 class="unnumbered" id="what-deserves-recognition">What Deserves Recognition?</h2>
<p>
A basic question is what research should be recognized? Solving a longstanding open problem—P vs NP—would immediately need to be awarded. But another critical category is an idea that leads to an interesting interplay between practical and theoretical work. Something that both advances our understanding of part of computing but also is used to solve real problems. Especially problems that are important and need to be solved to advance society.</p>
<p>
In my opinion, for Rich, program testing is one such area and also cryptography is another. Let’s turn and look at these now.</p>
<p><span id="more-21132"></span></p>
<h2 class="unnumbered" id="program-testing">Program Testing</h2>
<p>
The method called program <a href="https://en.wikipedia.org/wiki/Mutation_testing">mutation</a> is what deserves recognition. It has been around since the 1970’s. The reasons it should be given recognition are simple:</p>
<ul>
<li>
<p>It is identified in more than 400 papers published in the time<br />
period 2008—2017;</p>
</li>
<li>
<p>It is featured in its own conferences;</p>
</li>
<li>
<p>It is used in 87 different mutation tools for a variety of<br />
programming languages and artifacts including Java;</p>
</li>
<li>
<p>It is used in practice.</p>
</li>
</ul>
<p>I conceived the idea in a student paper in 1971, but Rich had a huge role in <em>actuating</em> it. This came in papers with me, him, and Fred Sayward in the late 1970s, which helped Tim Budd create the first implementation for this 1980 PhD thesis. Besides what Ken and I recently <a
href="https://rjlipton.wpcomstaging.com/2022/12/15/a-mutation-carol-2/">wrote</a> about the history, we note the following from a <a href="https://link.springer.com/article/10.1007/s10664-022-10177-8#Sec18">survey</a> dated last July:</p>
<blockquote>
<p>Since its introduction back in the 70s (DeMilo et al. 1978, 1979),<br />
research on mutation testing has thrived until becoming a<br />
well-established testing technique. In a recent survey by Papadakis et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0065245818300305 via%3Dihub">survey</a>, the authors identified more than 400 papers published in the time period 2008—2017 and 87 different mutation tools for a variety of programming languages and artifacts including Java, C, C++, C#, JavaScript, HTML/CSS, Ruby, and UML models, among many others.</p>
</blockquote>
<p>For almost two decades there has been a whole <a href="https://mutation-workshop.github.io/2023/">conference</a> on mutation analysis. A public <a href="https://www.cs.cornell.edu/~dgeisler/mutation/testing/2021/11/08/mutation-testing3.html">website</a> and blog by Dietrich Geisler of Cornell includes a graph that illustrates the general growth of mutation testing as a topic:
</p>
<p> <a href="https://rjlipton.wpcomstaging.com/2023/02/19/thanks-to-rich/years/" rel="attachment wp-att-21139"><img data-attachment-id="21139" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/19/thanks-to-rich/years/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/years.png?fit=1295%2C606&amp;ssl=1" data-orig-size="1295,606" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="years" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/years.png?fit=300%2C140&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/years.png?fit=600%2C281&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/years.png?resize=600%2C281&#038;ssl=1" alt="" width="600" height="281" class="aligncenter size-full wp-image-21139" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/years.png?w=1295&amp;ssl=1 1295w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/years.png?resize=300%2C140&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/years.png?resize=1024%2C479&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/years.png?resize=768%2C359&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/years.png?resize=1200%2C562&amp;ssl=1 1200w" sizes="(max-width: 600px) 100vw, 600px" data-recalc-dims="1" /></a></p>
<p>Here are some more links:</p>
<ul>
<li>
<p><a href="https://cs.gmu.edu/~offutt/rsrch/papers/mut00.pdf">A paper in 2000 by</a> Jeff Offutt and Roland Untch;</p>
</li>
<li>
<p><a
href="https://link.springer.com/article/10.1007/s10664-022-10177-8">A survey in 2022</a> by Ana Sanchez, Pedro Delgado-Perez, Inmaculada<br />
Medina-Bulo &amp; Sergio Segura;</p>
</li>
<li>
<p><a
href="https://awesomeopensource.com/projects/mutation-testing">A recent paper on</a> over a hundred mutation projects.</p>
</li>
</ul>
<p>In the 1980’s DeMillo <a
href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=6f0e55618d1f4eefb0faddd7288e404dc5e8eb55">advised</a> Offutt who was his PhD student.</p>
<h2 class="unnumbered" id="security">Security</h2>
<p>
DeMillo is a co-inventor of Differential Fault Cryptanalysis and holds the patent on applying DFA to break public key cryptosystems. <a
href="https://www.cs.tau.ac.il/~tromer/courses/infosec11/Boneh%20DeMillo%20Lipton%201997%20---%20On%20the%20importance%20of%20eliminating%20errors%20in%20cryptographic%20protocols.pdf">On the Importance of Eliminating Errors in Cryptographic Computations</a>.</p>
<p>This is related to mutation testing, since it is a kind of change the code method. Eli Biham and Ali Shamir <a
href="http://www.cs.tau.ac.il/~tromer/courses/infosec11/Biham%20Shamir%201997%20---%20Differential%20Fault%20Analysis%20of%20Secret%20Key%20Cryptosystems.pdf">say:</a></p>
<blockquote>
<p>We would like to gratefully acknowledge the pioneering contribution of Boneh, DeMillo, and Lipton. whose ideas were the starting point of our new attack.</p>
</blockquote>
<p>Here are some other <a
href="https://www.semanticscholar.org/paper/On-the-Importance-of-Checking-Cryptographic-for-Boneh-DeMillo/e2ceac65a53955893ca3152b992e65489e16e08a">papers</a>.</p>
<h2 class="unnumbered" id="open-problems">Open Problems</h2>
<p>
Perhaps we can see our way to help recognize Rich? For the record: <a
href="https://en.wikipedia.org/wiki/Richard_DeMillo">Rich</a> is a professor at Georgia Tech’s School of Cybersecurity and Privacy. He holds the Charlotte Brody and Roger Warren Chair in Computing at Georgia Tech. He is is also Managing Director of Gtatrium, LLC, a subsidiary of Georgia Advanced Technology Ventures. He was formerly the John Imlay Dean of Computing and Director of the Georgia Tech Information Security<br />
Center.</p>
<p><P><br />
[fixed jaggies]</p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-19T17:50:11Z">Sunday, February 19 2023, 17:50</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2023-02-19-rand-and-consensus-2/'>Randomization and Consensus - synchronous binary agreement for minority omission failures</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Continuing the series on simple ways where randomization can help solve consensus. The model is lock-step (synchrony) with $f&lt;n/2$ omission failures. We know that in the worst case reaching agreement takes at least $f+1$ rounds. Can randomization help reduce the expected number of rounds? In the post, we show a...
        
        </div>

        <div class='tr-article-summary'>
        
          
          Continuing the series on simple ways where randomization can help solve consensus. The model is lock-step (synchrony) with $f&lt;n/2$ omission failures. We know that in the worst case reaching agreement takes at least $f+1$ rounds. Can randomization help reduce the expected number of rounds? In the post, we show a...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-19T11:00:00Z">Sunday, February 19 2023, 11:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, February 18
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2023-02-18-rand-and-consensus-1/'>Randomization and Consensus - synchronous binary agreement for crash failures with a perfect common coin</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          What is the simplest setting where randomization can help solve consensus? Assume lock-step (synchrony) with $f&lt;n$ crash failures. We know that in the worst case reaching agreement takes at least $f+1$ rounds. This lower bound holds even if the protocol is randomized so the natural question is: Can randomization help...
        
        </div>

        <div class='tr-article-summary'>
        
          
          What is the simplest setting where randomization can help solve consensus? Assume lock-step (synchrony) with $f&lt;n$ crash failures. We know that in the worst case reaching agreement takes at least $f+1$ rounds. This lower bound holds even if the protocol is randomized so the natural question is: Can randomization help...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-18T11:00:00Z">Saturday, February 18 2023, 11:00</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
