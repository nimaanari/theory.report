<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-03-03T01:34:27Z">Friday, March 03 2023, 01:34</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, March 02
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/020'>TR23-020 |  Certified Randomness from Quantum Supremacy | 

	Scott Aaronson, 

	Shih-Han Hung</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We propose an application for near-term quantum devices: namely, generating cryptographically certified random bits, to use (for example) in proof-of-stake cryptocurrencies. Our protocol repurposes the existing &quot;quantum supremacy&quot; experiments, based on random circuit sampling, that Google and USTC have successfully carried out starting in 2019. We show that, whenever the outputs of these experiments pass the now-standard Linear Cross-Entropy Benchmark (LXEB), under plausible hardness assumptions they necessarily contain $\Omega(n)$ min-entropy, where $n$ is the number of qubits. To achieve a net gain in randomness, we use a small random seed to produce pseudorandom challenge circuits. In response to the challenge circuits, the quantum computer generates output strings that, after verification, can then be fed into a randomness extractor to produce certified nearly-uniform bits---thereby &quot;bootstrapping&quot; from pseudorandomness to genuine randomness. We prove our protocol sound in two senses: (i) under a hardness assumption called Long List Quantum Supremacy Verification, which we justify in the random oracle model, and (ii) unconditionally in the random oracle model against an eavesdropper who could share arbitrary entanglement with the device. (Note that our protocol&#39;s output is unpredictable even to a computationally unbounded adversary who can see the random oracle.) Currently, the central drawback of our protocol is the exponential cost of verification, which in practice will limit its implementation to at most $n\sim 60$ qubits, a regime where attacks are expensive but not impossible. Modulo that drawback, our protocol appears to be the only practical application of quantum computing that both requires a QC and is physically realizable today.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We propose an application for near-term quantum devices: namely, generating cryptographically certified random bits, to use (for example) in proof-of-stake cryptocurrencies. Our protocol repurposes the existing &quot;quantum supremacy&quot; experiments, based on random circuit sampling, that Google and USTC have successfully carried out starting in 2019. We show that, whenever the outputs of these experiments pass the now-standard Linear Cross-Entropy Benchmark (LXEB), under plausible hardness assumptions they necessarily contain $\Omega(n)$ min-entropy, where $n$ is the number of qubits. To achieve a net gain in randomness, we use a small random seed to produce pseudorandom challenge circuits. In response to the challenge circuits, the quantum computer generates output strings that, after verification, can then be fed into a randomness extractor to produce certified nearly-uniform bits---thereby &quot;bootstrapping&quot; from pseudorandomness to genuine randomness. We prove our protocol sound in two senses: (i) under a hardness assumption called Long List Quantum Supremacy Verification, which we justify in the random oracle model, and (ii) unconditionally in the random oracle model against an eavesdropper who could share arbitrary entanglement with the device. (Note that our protocol&#39;s output is unpredictable even to a computationally unbounded adversary who can see the random oracle.) Currently, the central drawback of our protocol is the exponential cost of verification, which in practice will limit its implementation to at most $n\sim 60$ qubits, a regime where attacks are expensive but not impossible. Modulo that drawback, our protocol appears to be the only practical application of quantum computing that both requires a QC and is physically realizable today.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T23:10:26Z">Thursday, March 02 2023, 23:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/019'>TR23-019 |  Theory of Unconditional Pseudorandom Generators | 

	Pooya Hatami, 

	William Hoza</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This is a survey of unconditional *pseudorandom generators* (PRGs). A PRG uses a short, truly random seed to generate a long, &quot;pseudorandom&quot; sequence of bits. To be more specific, for each restricted model of computation (e.g., bounded-depth circuits or read-once branching programs), we would like to design a PRG that &quot;fools&quot; the model, meaning that every function computable in the model behaves approximately the same when we plug in pseudorandom bits from the PRG as it does when we plug in truly random bits. In this survey, we discuss four major paradigms for designing PRGs:

- We present several PRGs based on $k$-wise uniform generators, small-bias generators, and simple combinations thereof, including proofs of Viola&#39;s theorem on fooling low-degree polynomials (Comput. Complexity 2009) and Braverman&#39;s theorem on fooling $\mathbf{AC}^0$ circuits (J. ACM 2010).

- We present several PRGs based on &quot;recycling&quot; random bits to take advantage of communication bottlenecks, such as the Impagliazzo-Nisan-Wigderson generator (STOC 1994).

- We present connections between PRGs and computational hardness, including the Nisan-Wigderson framework for converting a hard Boolean function into a PRG (J. Comput. Syst. Sci. 1994).

- We present PRG frameworks based on random restrictions, including the &quot;polarizing random walks&quot; framework (Chattopadhyay, Hatami, Hosseini, and Lovett, Theory Comput. 2019).

We explain how to use these paradigms to construct PRGs that work *unconditionally*, with no unproven mathematical assumptions. The PRG constructions use ingredients such as finite field arithmetic, expander graphs, and randomness extractors. The analyses use techniques such as Fourier analysis, sandwiching approximators, and simplification-under-restrictions lemmas.
        
        </div>

        <div class='tr-article-summary'>
        
          
          This is a survey of unconditional *pseudorandom generators* (PRGs). A PRG uses a short, truly random seed to generate a long, &quot;pseudorandom&quot; sequence of bits. To be more specific, for each restricted model of computation (e.g., bounded-depth circuits or read-once branching programs), we would like to design a PRG that &quot;fools&quot; the model, meaning that every function computable in the model behaves approximately the same when we plug in pseudorandom bits from the PRG as it does when we plug in truly random bits. In this survey, we discuss four major paradigms for designing PRGs:

- We present several PRGs based on $k$-wise uniform generators, small-bias generators, and simple combinations thereof, including proofs of Viola&#39;s theorem on fooling low-degree polynomials (Comput. Complexity 2009) and Braverman&#39;s theorem on fooling $\mathbf{AC}^0$ circuits (J. ACM 2010).

- We present several PRGs based on &quot;recycling&quot; random bits to take advantage of communication bottlenecks, such as the Impagliazzo-Nisan-Wigderson generator (STOC 1994).

- We present connections between PRGs and computational hardness, including the Nisan-Wigderson framework for converting a hard Boolean function into a PRG (J. Comput. Syst. Sci. 1994).

- We present PRG frameworks based on random restrictions, including the &quot;polarizing random walks&quot; framework (Chattopadhyay, Hatami, Hosseini, and Lovett, Theory Comput. 2019).

We explain how to use these paradigms to construct PRGs that work *unconditionally*, with no unproven mathematical assumptions. The PRG constructions use ingredients such as finite field arithmetic, expander graphs, and randomness extractors. The analyses use techniques such as Fourier analysis, sandwiching approximators, and simplification-under-restrictions lemmas.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T23:09:23Z">Thursday, March 02 2023, 23:09</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/03/goodbye-dilbert.html'>Goodbye Dilbert</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Scott Adams, creator of Dilbert, had a racist rant in a video he posted last week. As a result most newspapers that carried the comic strip are dropping Dilbert, including our local Chicago Tribune. I fully support these moves. Much as I believe in separating the art from the artist, it's different when the artist is living and profiting from their art.</p><p>So we need to say to Dilbert, making the end of an era. Dilbert started in 1989 as a strip that captured the absurdities of the work place in an anonymous tech company, predating movies like Office Space and shows like Better Off Ted and&nbsp;Silicon Valley. I used Dilbert strips (with permission) in my book, namely&nbsp;this strip to introduce Kolmogorov complexity and this strip to describe my research area. Just call me Dan.</p><p>Farewell to Dilbert, Dogbert, Wally, Alice, Asok, the pointy-haired boss and the rest. I won't miss Scott Adams, but I will miss his creations.</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Scott Adams, creator of Dilbert, had a racist rant in a video he posted last week. As a result <a href="https://www.wsj.com/articles/newspapers-drop-dilbert-after-cartoonist-calls-black-americans-hate-group-21348ce1?st=mcxbs51a70by7i3&amp;reflink=desktopwebshare_permalink">most newspapers that carried the comic strip are dropping Dilbert</a>, including our local Chicago Tribune. I fully support these moves. Much as I believe in separating the art from the artist, it's different when the artist is living and profiting from their art.</p><p>So we need to say to Dilbert, making the end of an era. Dilbert started in 1989 as a strip that captured the absurdities of the work place in an anonymous tech company, predating movies like <a href="https://www.imdb.com/title/tt0151804/">Office Space</a> and shows like <a href="https://www.imdb.com/title/tt1235547/">Better Off Ted</a> and&nbsp;<a href="https://www.imdb.com/title/tt2575988/">Silicon Valley</a>. I used Dilbert strips (with permission) in my book, namely&nbsp;<a href="https://dilbert.com/strip/2001-10-25">this strip</a> to introduce Kolmogorov complexity and <a href="https://dilbert.com/strip/1997-12-22">this strip</a> to describe my research area. Just call me Dan.</p><p>Farewell to Dilbert, Dogbert, Wally, Alice, Asok, the pointy-haired boss and the rest. I won't miss Scott Adams, but I will miss his creations.</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T13:19:00Z">Thursday, March 02 2023, 13:19</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/018'>TR23-018 |  Memory-Sample Lower Bounds for Learning with Classical-Quantum Hybrid Memory | 

	Qipeng Liu, 

	Ran Raz, 

	Wei Zhan</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In a work by Raz (J. ACM and FOCS 16), it was proved that any algorithm for parity learning on $n$ bits requires either $\Omega(n^2)$ bits of classical memory or an exponential number (in~$n$) of random samples. A line of recent works continued that research direction and showed that for a large collection of classical learning tasks, either super-linear classical memory size or super-polynomially many samples are needed. All these works consider learning algorithms as classical branching programs, which perform classical computation within bounded memory.

However, these results do not capture all physical computational models, remarkably, quantum computers and the use of quantum memory. It leaves the possibility that a small piece of quantum memory could significantly reduce the need for classical memory or samples and thus completely change the nature of the classical learning task. Despite the recent research on the necessity of quantum memory for intrinsic quantum learning problems like shadow tomography and purity testing, the role of quantum memory in classical learning tasks remains obscure. 

In this work, we study classical learning tasks in the presence of quantum memory. We prove that any quantum algorithm with both, classical memory and quantum memory, for parity learning on $n$ bits, requires either $\Omega(n^2)$ bits of classical memory or $\Omega(n)$ bits of quantum  memory or an exponential number of samples. In other words, the memory-sample lower bound for parity learning remains qualitatively the same, even if the learning algorithm can use, in addition to the classical memory, a quantum memory of size $c n$ (for some constant $c&gt;0$).

Our result is more general and applies to many other classical learning tasks. Following previous works, we represent by the matrix $M: A \times X \to \{-1,1\}$ the following learning task. An unknown $x$ is sampled uniformly at random from a concept class $X$, and a learning algorithm tries to uncover $x$ by seeing streaming of random samples $(a_i, b_i = M(a_i, x))$ where for every $i$, $a_i\in A$ is chosen uniformly at random. Assume that $k,\ell,r$ are integers such that any submatrix of $M$ of at least $2^{-k}\cdot|A|$ rows and at least $2^{-\ell}\cdot|X|$ columns, has a bias of at most $2^{-r}$. We prove that any algorithm with classical and quantum hybrid memory for the learning problem corresponding to $M$ needs either (1) $\Omega(k \cdot \ell)$ bits of classical memory, or (2) $\Omega(r)$ qubits of quantum memory, or (3) $2^{\Omega(r)}$ random samples, to achieve a success probability at least $2^{-O(r)}$. 

Our results refute the possibility that a small amount of quantum memory significantly reduces the size of classical memory needed for efficient learning on these problems. Our results also imply improved security of several existing cryptographical protocols in the bounded-storage model (protocols that are based on parity learning on $n$ bits), proving that security holds even in the presence of a quantum adversary with at most $c n^2$ bits of classical memory and $c n$ bits of quantum memory (for some constant $c&gt;0$).
        
        </div>

        <div class='tr-article-summary'>
        
          
          In a work by Raz (J. ACM and FOCS 16), it was proved that any algorithm for parity learning on $n$ bits requires either $\Omega(n^2)$ bits of classical memory or an exponential number (in~$n$) of random samples. A line of recent works continued that research direction and showed that for a large collection of classical learning tasks, either super-linear classical memory size or super-polynomially many samples are needed. All these works consider learning algorithms as classical branching programs, which perform classical computation within bounded memory.

However, these results do not capture all physical computational models, remarkably, quantum computers and the use of quantum memory. It leaves the possibility that a small piece of quantum memory could significantly reduce the need for classical memory or samples and thus completely change the nature of the classical learning task. Despite the recent research on the necessity of quantum memory for intrinsic quantum learning problems like shadow tomography and purity testing, the role of quantum memory in classical learning tasks remains obscure. 

In this work, we study classical learning tasks in the presence of quantum memory. We prove that any quantum algorithm with both, classical memory and quantum memory, for parity learning on $n$ bits, requires either $\Omega(n^2)$ bits of classical memory or $\Omega(n)$ bits of quantum  memory or an exponential number of samples. In other words, the memory-sample lower bound for parity learning remains qualitatively the same, even if the learning algorithm can use, in addition to the classical memory, a quantum memory of size $c n$ (for some constant $c&gt;0$).

Our result is more general and applies to many other classical learning tasks. Following previous works, we represent by the matrix $M: A \times X \to \{-1,1\}$ the following learning task. An unknown $x$ is sampled uniformly at random from a concept class $X$, and a learning algorithm tries to uncover $x$ by seeing streaming of random samples $(a_i, b_i = M(a_i, x))$ where for every $i$, $a_i\in A$ is chosen uniformly at random. Assume that $k,\ell,r$ are integers such that any submatrix of $M$ of at least $2^{-k}\cdot|A|$ rows and at least $2^{-\ell}\cdot|X|$ columns, has a bias of at most $2^{-r}$. We prove that any algorithm with classical and quantum hybrid memory for the learning problem corresponding to $M$ needs either (1) $\Omega(k \cdot \ell)$ bits of classical memory, or (2) $\Omega(r)$ qubits of quantum memory, or (3) $2^{\Omega(r)}$ random samples, to achieve a success probability at least $2^{-O(r)}$. 

Our results refute the possibility that a small amount of quantum memory significantly reduces the size of classical memory needed for efficient learning on these problems. Our results also imply improved security of several existing cryptographical protocols in the bounded-storage model (protocols that are based on parity learning on $n$ bits), proving that security holds even in the presence of a quantum adversary with at most $c n^2$ bits of classical memory and $c n$ bits of quantum memory (for some constant $c&gt;0$).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T04:17:11Z">Thursday, March 02 2023, 04:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00209'>Memory-Sample Lower Bounds for Learning with Classical-Quantum Hybrid Memory</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Qipeng Liu, Ran Raz, Wei Zhan</p><p>In a work by Raz (J. ACM and FOCS 16), it was proved that any algorithm for
parity learning on $n$ bits requires either $\Omega(n^2)$ bits of classical
memory or an exponential number (in~$n$) of random samples. A line of recent
works continued that research direction and showed that for a large collection
of classical learning tasks, either super-linear classical memory size or
super-polynomially many samples are needed. However, these results do not
capture all physical computational models, remarkably, quantum computers and
the use of quantum memory. It leaves the possibility that a small piece of
quantum memory could significantly reduce the need for classical memory or
samples and thus completely change the nature of the classical learning task.
</p>
<p>In this work, we prove that any quantum algorithm with both, classical memory
and quantum memory, for parity learning on $n$ bits, requires either
$\Omega(n^2)$ bits of classical memory or $\Omega(n)$ bits of quantum memory or
an exponential number of samples. In other words, the memory-sample lower bound
for parity learning remains qualitatively the same, even if the learning
algorithm can use, in addition to the classical memory, a quantum memory of
size $c n$ (for some constant $c&gt;0$).
</p>
<p>Our results refute the possibility that a small amount of quantum memory
significantly reduces the size of classical memory needed for efficient
learning on these problems. Our results also imply improved security of several
existing cryptographical protocols in the bounded-storage model (protocols that
are based on parity learning on $n$ bits), proving that security holds even in
the presence of a quantum adversary with at most $c n^2$ bits of classical
memory and $c n$ bits of quantum memory (for some constant $c&gt;0$).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Liu_Q/0/1/0/all/0/1">Qipeng Liu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Raz_R/0/1/0/all/0/1">Ran Raz</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhan_W/0/1/0/all/0/1">Wei Zhan</a></p><p>In a work by Raz (J. ACM and FOCS 16), it was proved that any algorithm for
parity learning on $n$ bits requires either $\Omega(n^2)$ bits of classical
memory or an exponential number (in~$n$) of random samples. A line of recent
works continued that research direction and showed that for a large collection
of classical learning tasks, either super-linear classical memory size or
super-polynomially many samples are needed. However, these results do not
capture all physical computational models, remarkably, quantum computers and
the use of quantum memory. It leaves the possibility that a small piece of
quantum memory could significantly reduce the need for classical memory or
samples and thus completely change the nature of the classical learning task.
</p>
<p>In this work, we prove that any quantum algorithm with both, classical memory
and quantum memory, for parity learning on $n$ bits, requires either
$\Omega(n^2)$ bits of classical memory or $\Omega(n)$ bits of quantum memory or
an exponential number of samples. In other words, the memory-sample lower bound
for parity learning remains qualitatively the same, even if the learning
algorithm can use, in addition to the classical memory, a quantum memory of
size $c n$ (for some constant $c&gt;0$).
</p>
<p>Our results refute the possibility that a small amount of quantum memory
significantly reduces the size of classical memory needed for efficient
learning on these problems. Our results also imply improved security of several
existing cryptographical protocols in the bounded-storage model (protocols that
are based on parity learning on $n$ bits), proving that security holds even in
the presence of a quantum adversary with at most $c n^2$ bits of classical
memory and $c n$ bits of quantum memory (for some constant $c&gt;0$).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00109'>Linear Size Universal Point Sets for Classes of Planar Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Stefan Felsner, Hendrik Schrezenmaier, Felix Schr&#xf6;der, Raphael Steiner</p><p>A finite set $P$ of points in the plane is $n$-universal with respect to a
class $\mathcal{C}$ of planar graphs if every $n$-vertex graph in $\mathcal{C}$
admits a crossing-free straight-line drawing with vertices at points of $P$.
For the class of all planar graphs the best known upper bound on the size of a
universal point set is quadratic and the best known lower bound is linear in
$n$. Some classes of planar graphs are known to admit universal point sets of
near linear size, however, there are no truly linear bounds for interesting
classes beyond outerplanar graphs.
</p>
<p>In this paper, we show that there is a universal point set of size $2n-2$ for
the class of bipartite planar graphs with $n$ vertices. The same point set is
also universal for the class of $n$-vertex planar graphs of maximum degree $3$.
The point set used for the results is what we call an exploding double chain,
and we prove that this point set allows planar straight-line embeddings of many
more planar graphs, namely of all subgraphs of planar graphs admitting a
one-sided Hamiltonian cycle. The result for bipartite graphs also implies that
every $n$-vertex plane graph has a $1$-bend drawing all whose bends and
vertices are contained in a specific point set of size $4n-6$, this improves a
bound of $6n-10$ for the same problem by L\"offler and T\'oth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Felsner_S/0/1/0/all/0/1">Stefan Felsner</a>, <a href="http://arxiv.org/find/cs/1/au:+Schrezenmaier_H/0/1/0/all/0/1">Hendrik Schrezenmaier</a>, <a href="http://arxiv.org/find/cs/1/au:+Schroder_F/0/1/0/all/0/1">Felix Schr&#xf6;der</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_R/0/1/0/all/0/1">Raphael Steiner</a></p><p>A finite set $P$ of points in the plane is $n$-universal with respect to a
class $\mathcal{C}$ of planar graphs if every $n$-vertex graph in $\mathcal{C}$
admits a crossing-free straight-line drawing with vertices at points of $P$.
For the class of all planar graphs the best known upper bound on the size of a
universal point set is quadratic and the best known lower bound is linear in
$n$. Some classes of planar graphs are known to admit universal point sets of
near linear size, however, there are no truly linear bounds for interesting
classes beyond outerplanar graphs.
</p>
<p>In this paper, we show that there is a universal point set of size $2n-2$ for
the class of bipartite planar graphs with $n$ vertices. The same point set is
also universal for the class of $n$-vertex planar graphs of maximum degree $3$.
The point set used for the results is what we call an exploding double chain,
and we prove that this point set allows planar straight-line embeddings of many
more planar graphs, namely of all subgraphs of planar graphs admitting a
one-sided Hamiltonian cycle. The result for bipartite graphs also implies that
every $n$-vertex plane graph has a $1$-bend drawing all whose bends and
vertices are contained in a specific point set of size $4n-6$, this improves a
bound of $6n-10$ for the same problem by L\"offler and T\'oth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00556'>A linear bound for the Colin de Verdi\'ere parameter $\mu$ for graphs embedded on surfaces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Camille Lanuel, Francis Lazarus, Rudi Pendavingh</p><p>We provide a combinatorial and self-contained proof that for all graphs $G$
embedded on a surface $S$, the Colin de Verdi\`ere parameter $\mu(G)$ is upper
bounded by $7-2\chi(S)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Lanuel_C/0/1/0/all/0/1">Camille Lanuel</a>, <a href="http://arxiv.org/find/math/1/au:+Lazarus_F/0/1/0/all/0/1">Francis Lazarus</a>, <a href="http://arxiv.org/find/math/1/au:+Pendavingh_R/0/1/0/all/0/1">Rudi Pendavingh</a></p><p>We provide a combinatorial and self-contained proof that for all graphs $G$
embedded on a surface $S$, the Colin de Verdi\`ere parameter $\mu(G)$ is upper
bounded by $7-2\chi(S)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00252'>Is Planted Coloring Easier than Planted Clique?</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pravesh K. Kothari, Santosh S. Vempala, Alexander S. Wein, Jeff Xu</p><p>We study the computational complexity of two related problems: recovering a
planted $q$-coloring in $G(n,1/2)$, and finding efficiently verifiable
witnesses of non-$q$-colorability (a.k.a. refutations) in $G(n,1/2)$. Our main
results show hardness for both these problems in a restricted-but-powerful
class of algorithms based on computing low-degree polynomials in the inputs.
</p>
<p>The problem of recovering a planted $q$-coloring is equivalent to recovering
$q$ disjoint planted cliques that cover all the vertices -- a potentially
easier variant of the well-studied planted clique problem. Our first result
shows that this variant is as hard as the original planted clique problem in
the low-degree polynomial model of computation: each clique needs to have size
$k \gg \sqrt{n}$ for efficient recovery to be possible. For the related variant
where the cliques cover a $(1-\epsilon)$-fraction of the vertices, we also show
hardness by reduction from planted clique.
</p>
<p>Our second result shows that refuting $q$-colorability of $G(n,1/2)$ is hard
in the low-degree polynomial model when $q \gg n^{2/3}$ but easy when $q
\lesssim n^{1/2}$, and we leave closing this gap for future work. Our proof is
more subtle than similar results for planted clique and involves constructing a
non-standard distribution over $q$-colorable graphs. We note that while related
to several prior works, this is the first work that explicitly formulates
refutation problems in the low-degree polynomial model.
</p>
<p>The proofs of our main results involve showing low-degree hardness of
hypothesis testing between an appropriately constructed pair of distributions.
For refutation, we show completeness of this approach: in the low-degree model,
the refutation task is precisely as hard as the hardest associated testing
problem, i.e., proving hardness of refutation amounts to finding a "hard"
distribution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1">Pravesh K. Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1">Santosh S. Vempala</a>, <a href="http://arxiv.org/find/cs/1/au:+Wein_A/0/1/0/all/0/1">Alexander S. Wein</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jeff Xu</a></p><p>We study the computational complexity of two related problems: recovering a
planted $q$-coloring in $G(n,1/2)$, and finding efficiently verifiable
witnesses of non-$q$-colorability (a.k.a. refutations) in $G(n,1/2)$. Our main
results show hardness for both these problems in a restricted-but-powerful
class of algorithms based on computing low-degree polynomials in the inputs.
</p>
<p>The problem of recovering a planted $q$-coloring is equivalent to recovering
$q$ disjoint planted cliques that cover all the vertices -- a potentially
easier variant of the well-studied planted clique problem. Our first result
shows that this variant is as hard as the original planted clique problem in
the low-degree polynomial model of computation: each clique needs to have size
$k \gg \sqrt{n}$ for efficient recovery to be possible. For the related variant
where the cliques cover a $(1-\epsilon)$-fraction of the vertices, we also show
hardness by reduction from planted clique.
</p>
<p>Our second result shows that refuting $q$-colorability of $G(n,1/2)$ is hard
in the low-degree polynomial model when $q \gg n^{2/3}$ but easy when $q
\lesssim n^{1/2}$, and we leave closing this gap for future work. Our proof is
more subtle than similar results for planted clique and involves constructing a
non-standard distribution over $q$-colorable graphs. We note that while related
to several prior works, this is the first work that explicitly formulates
refutation problems in the low-degree polynomial model.
</p>
<p>The proofs of our main results involve showing low-degree hardness of
hypothesis testing between an appropriately constructed pair of distributions.
For refutation, we show completeness of this approach: in the low-degree model,
the refutation task is precisely as hard as the hardest associated testing
problem, i.e., proving hardness of refutation amounts to finding a "hard"
distribution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00660'>Computing the Best Policy That Survives a Vote</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andrei Constantinescu, Roger Wattenhofer</p><p>An assembly of $n$ voters needs to decide on $t$ independent binary issues.
Each voter has opinions about the issues, given by a $t$-bit vector. Anscombe's
paradox shows that a policy following the majority opinion in each issue may
not survive a vote by the very same set of $n$ voters, i.e., more voters may
feel unrepresented by such a majority-driven policy than represented. A natural
resolution is to come up with a policy that deviates a bit from the majority
policy but no longer gets more opposition than support from the electorate. We
show that a Hamming distance to the majority policy of at most $\lfloor (t - 1)
/ 2 \rfloor$ can always be guaranteed, by giving a new probabilistic argument
relying on structure-preserving symmetries of the space of potential policies.
Unless the electorate is evenly divided between the two options on all issues,
we in fact show that a policy strictly winning the vote exists within this
distance bound. Our approach also leads to a deterministic polynomial-time
algorithm for finding policies with the stated guarantees, answering an open
problem of previous work. For odd $t$, unless we are in the pathological case
described above, we also give a simpler and more efficient algorithm running in
expected polynomial time with the same guarantees. We further show that
checking whether distance strictly less than $\lfloor (t - 1) /2 \rfloor$ can
be achieved is NP-hard, and that checking for distance at most some input $k$
is FPT with respect to several natural parameters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Constantinescu_A/0/1/0/all/0/1">Andrei Constantinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1">Roger Wattenhofer</a></p><p>An assembly of $n$ voters needs to decide on $t$ independent binary issues.
Each voter has opinions about the issues, given by a $t$-bit vector. Anscombe's
paradox shows that a policy following the majority opinion in each issue may
not survive a vote by the very same set of $n$ voters, i.e., more voters may
feel unrepresented by such a majority-driven policy than represented. A natural
resolution is to come up with a policy that deviates a bit from the majority
policy but no longer gets more opposition than support from the electorate. We
show that a Hamming distance to the majority policy of at most $\lfloor (t - 1)
/ 2 \rfloor$ can always be guaranteed, by giving a new probabilistic argument
relying on structure-preserving symmetries of the space of potential policies.
Unless the electorate is evenly divided between the two options on all issues,
we in fact show that a policy strictly winning the vote exists within this
distance bound. Our approach also leads to a deterministic polynomial-time
algorithm for finding policies with the stated guarantees, answering an open
problem of previous work. For odd $t$, unless we are in the pathological case
described above, we also give a simpler and more efficient algorithm running in
expected polynomial time with the same guarantees. We further show that
checking whether distance strictly less than $\lfloor (t - 1) /2 \rfloor$ can
be achieved is NP-hard, and that checking for distance at most some input $k$
is FPT with respect to several natural parameters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00147'>Non-crossing Hamiltonian Paths and Cycles in Output-Polynomial Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David Eppstein</p><p>We show that, for planar point sets, the number of non-crossing Hamiltonian
paths is polynomially bounded in the number of non-crossing paths, and the
number of non-crossing Hamiltonian cycles (polygonalizations) is polynomially
bounded in the number of surrounding cycles. As a consequence, we can list the
non-crossing Hamiltonian paths or the polygonalizations, in time polynomial in
the output size, by filtering the output of simple backtracking algorithms for
non-crossing paths or surrounding cycles respectively. To prove these results
we relate the numbers of non-crossing structures to two easily-computed
parameters of the point set: the minimum number of points whose removal results
in a collinear set, and the number of points interior to the convex hull. These
relations also lead to polynomial-time approximation algorithms for the numbers
of structures of all four types, accurate to within a constant factor of the
logarithm of these numbers.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Eppstein_D/0/1/0/all/0/1">David Eppstein</a></p><p>We show that, for planar point sets, the number of non-crossing Hamiltonian
paths is polynomially bounded in the number of non-crossing paths, and the
number of non-crossing Hamiltonian cycles (polygonalizations) is polynomially
bounded in the number of surrounding cycles. As a consequence, we can list the
non-crossing Hamiltonian paths or the polygonalizations, in time polynomial in
the output size, by filtering the output of simple backtracking algorithms for
non-crossing paths or surrounding cycles respectively. To prove these results
we relate the numbers of non-crossing structures to two easily-computed
parameters of the point set: the minimum number of points whose removal results
in a collinear set, and the number of points interior to the convex hull. These
relations also lead to polynomial-time approximation algorithms for the numbers
of structures of all four types, accurate to within a constant factor of the
logarithm of these numbers.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00666'>Towards Space Efficient Two-Point Shortest Path Queries in a Polygonal Domain</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sarita de Berg, Tillman Miltzow, Frank Staals</p><p>We devise a data structure that can answer shortest path queries for two
query points in a polygonal domain $P$ on $n$ vertices. For any $\varepsilon &gt;
0$, the space complexity of the data structure is $O(n^{10+\varepsilon})$ and
queries can be answered in $O(\log n)$ time. This is the first improvement upon
a conference paper by Chiang and Mitchell from 1999. They present a data
structure with $O(n^{11})$ space complexity. Our main result can be extended to
include a space-time trade-off. Specifically, we devise data structures with
$O(n^{10+\varepsilon}/\hspace{1pt} \ell^{5 + O(\varepsilon)})$ space complexity
and $O(\ell \log n )$ query time for any integer $1 \leq \ell \leq n$.
</p>
<p>Furthermore, our main result can be improved if we restrict one (or both) of
the query points to lie on the boundary of $P$. When one of the query points is
restricted to lie on the boundary, and the other query point can still lie
anywhere in $P$, the space complexity becomes $O(n^{6+\varepsilon})$. When both
query points are on the boundary, the space is decreased further to
$O(n^{4+\varepsilon})$, thereby improving an earlier result of Bae and Okamoto.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berg_S/0/1/0/all/0/1">Sarita de Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Miltzow_T/0/1/0/all/0/1">Tillman Miltzow</a>, <a href="http://arxiv.org/find/cs/1/au:+Staals_F/0/1/0/all/0/1">Frank Staals</a></p><p>We devise a data structure that can answer shortest path queries for two
query points in a polygonal domain $P$ on $n$ vertices. For any $\varepsilon &gt;
0$, the space complexity of the data structure is $O(n^{10+\varepsilon})$ and
queries can be answered in $O(\log n)$ time. This is the first improvement upon
a conference paper by Chiang and Mitchell from 1999. They present a data
structure with $O(n^{11})$ space complexity. Our main result can be extended to
include a space-time trade-off. Specifically, we devise data structures with
$O(n^{10+\varepsilon}/\hspace{1pt} \ell^{5 + O(\varepsilon)})$ space complexity
and $O(\ell \log n )$ query time for any integer $1 \leq \ell \leq n$.
</p>
<p>Furthermore, our main result can be improved if we restrict one (or both) of
the query points to lie on the boundary of $P$. When one of the query points is
restricted to lie on the boundary, and the other query point can still lie
anywhere in $P$, the space complexity becomes $O(n^{6+\varepsilon})$. When both
query points are on the boundary, the space is decreased further to
$O(n^{4+\varepsilon})$, thereby improving an earlier result of Bae and Okamoto.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00745'>Coordination of Multiple Robots along Given Paths with Bounded Junction Complexity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mikkel Abrahamsen, Tzvika Geft, Dan Halperin, Barak Ugav</p><p>We study a fundamental NP-hard motion coordination problem for
multi-robot/multi-agent systems: We are given a graph $G$ and set of agents,
where each agent has a given directed path in $G$. Each agent is initially
located on the first vertex of its path. At each time step an agent can move to
the next vertex on its path, provided that the vertex is not occupied by
another agent. The goal is to find a sequence of such moves along the given
paths so that each reaches its target, or to report that no such sequence
exists. The problem models guidepath-based transport systems, which is a
pertinent abstraction for traffic in a variety of contemporary applications,
ranging from train networks or Automated Guided Vehicles (AGVs) in factories,
through computer game animations, to qubit transport in quantum computing. It
also arises as a sub-problem in the more general multi-robot motion-planning
problem.
</p>
<p>We provide a fine-grained tractability analysis of the problem by considering
new assumptions and identifying minimal values of key parameters for which the
problem remains NP-hard. Our analysis identifies a critical parameter called
vertex multiplicity (VM), defined as the maximum number of paths passing
through the same vertex. We show that a prevalent variant of the problem, which
is equivalent to Sequential Resource Allocation (concerning deadlock prevention
for concurrent processes), is NP-hard even when VM is 3. On the positive side,
for VM $\le$ 2 we give an efficient algorithm that iteratively resolves cycles
of blocking relations among agents. We also present a variant that is NP-hard
when the VM is 2 even when $G$ is a 2D grid and each path lies in a single grid
row or column. By studying highly distilled yet NP-hard variants, we deepen the
understanding of what makes the problem intractable and thereby guide the
search for efficient solutions under practical assumptions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Abrahamsen_M/0/1/0/all/0/1">Mikkel Abrahamsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Geft_T/0/1/0/all/0/1">Tzvika Geft</a>, <a href="http://arxiv.org/find/cs/1/au:+Halperin_D/0/1/0/all/0/1">Dan Halperin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ugav_B/0/1/0/all/0/1">Barak Ugav</a></p><p>We study a fundamental NP-hard motion coordination problem for
multi-robot/multi-agent systems: We are given a graph $G$ and set of agents,
where each agent has a given directed path in $G$. Each agent is initially
located on the first vertex of its path. At each time step an agent can move to
the next vertex on its path, provided that the vertex is not occupied by
another agent. The goal is to find a sequence of such moves along the given
paths so that each reaches its target, or to report that no such sequence
exists. The problem models guidepath-based transport systems, which is a
pertinent abstraction for traffic in a variety of contemporary applications,
ranging from train networks or Automated Guided Vehicles (AGVs) in factories,
through computer game animations, to qubit transport in quantum computing. It
also arises as a sub-problem in the more general multi-robot motion-planning
problem.
</p>
<p>We provide a fine-grained tractability analysis of the problem by considering
new assumptions and identifying minimal values of key parameters for which the
problem remains NP-hard. Our analysis identifies a critical parameter called
vertex multiplicity (VM), defined as the maximum number of paths passing
through the same vertex. We show that a prevalent variant of the problem, which
is equivalent to Sequential Resource Allocation (concerning deadlock prevention
for concurrent processes), is NP-hard even when VM is 3. On the positive side,
for VM $\le$ 2 we give an efficient algorithm that iteratively resolves cycles
of blocking relations among agents. We also present a variant that is NP-hard
when the VM is 2 even when $G$ is a 2D grid and each path lies in a single grid
row or column. By studying highly distilled yet NP-hard variants, we deepen the
understanding of what makes the problem intractable and thereby guide the
search for efficient solutions under practical assumptions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00217'>Improved Quantum Query Complexity on Easier Inputs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Noel T. Anderson, Jay-U Chung, Shelby Kimmel, Da-Yeon Koh, Xiaohan Ye</p><p>Quantum span program algorithms for function evaluation sometimes have
reduced query complexity when promised that the input has a certain structure.
We design a modified span program algorithm to show these improvements persist
even without a promise ahead of time, and we extend this approach to the more
general problem of state conversion. As an application, we prove exponential
and superpolynomial quantum advantages in average query complexity for several
search problems, generalizing Montanaro's Search with Advice [Montanaro, TQC
2010].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Anderson_N/0/1/0/all/0/1">Noel T. Anderson</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chung_J/0/1/0/all/0/1">Jay-U Chung</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kimmel_S/0/1/0/all/0/1">Shelby Kimmel</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Koh_D/0/1/0/all/0/1">Da-Yeon Koh</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ye_X/0/1/0/all/0/1">Xiaohan Ye</a></p><p>Quantum span program algorithms for function evaluation sometimes have
reduced query complexity when promised that the input has a certain structure.
We design a modified span program algorithm to show these improvements persist
even without a promise ahead of time, and we extend this approach to the more
general problem of state conversion. As an application, we prove exponential
and superpolynomial quantum advantages in average query complexity for several
search problems, generalizing Montanaro's Search with Advice [Montanaro, TQC
2010].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00259'>Computing All Restricted Skyline Probabilities for Uncertain Data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiangyu Gao, Jianzhong Li, Dongjing Miao</p><p>Since data uncertainty is inherent in multi-criteria decision making, recent
years have witnessed a dramatically increasing amount of attention devoted to
conducting advanced analysis on uncertain data. In this paper, we revisit
restricted skyline query on uncertain datasets from both complexity and
algorithm perspective. Instead of conducting probabilistic restricted skyline
analysis under threshold or top-$k$ semantics, we focus on a more general
problem that aims to compute the restricted skyline probability of all objects.
We prove that the problem can not be solved in truly subquadratic-time unless
the Orthogonal Vectors conjecture fails, and propose two algorithms, one with
near-optimal time complexity and the other with better expected time
complexity. We also propose an algorithm with sublinear query time and
polynomial preprocessing time for the case where the preference region is
described by $d - 1$ ratio bound constraints. Our thorough experiments over
real and synthetic datasets demonstrate the effectiveness of the problem and
the efficiency of the proposed algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiangyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianzhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_D/0/1/0/all/0/1">Dongjing Miao</a></p><p>Since data uncertainty is inherent in multi-criteria decision making, recent
years have witnessed a dramatically increasing amount of attention devoted to
conducting advanced analysis on uncertain data. In this paper, we revisit
restricted skyline query on uncertain datasets from both complexity and
algorithm perspective. Instead of conducting probabilistic restricted skyline
analysis under threshold or top-$k$ semantics, we focus on a more general
problem that aims to compute the restricted skyline probability of all objects.
We prove that the problem can not be solved in truly subquadratic-time unless
the Orthogonal Vectors conjecture fails, and propose two algorithms, one with
near-optimal time complexity and the other with better expected time
complexity. We also propose an algorithm with sublinear query time and
polynomial preprocessing time for the case where the preference region is
described by $d - 1$ ratio bound constraints. Our thorough experiments over
real and synthetic datasets demonstrate the effectiveness of the problem and
the efficiency of the proposed algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00480'>Sampling with Barriers: Faster Mixing via Lewis Weights</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Khashayar Gatmiry, Jonathan Kelner, Santosh S. Vempala</p><p>We analyze Riemannian Hamiltonian Monte Carlo (RHMC) for sampling a polytope
defined by $m$ inequalities in $\R^n$ endowed with the metric defined by the
Hessian of a self-concordant convex barrier function. We use a hybrid of the
$p$-Lewis weight barrier and the standard logarithmic barrier and prove that
the mixing rate is bounded by $\tilde O(m^{1/3}n^{4/3})$, improving on the
previous best bound of $\tilde O(mn^{2/3})$, based on the log barrier. Our
analysis overcomes several technical challenges to establish this result, in
the process deriving smoothness bounds on Hamiltonian curves and extending
self-concordance notions to the infinity norm; both properties appear to be of
independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gatmiry_K/0/1/0/all/0/1">Khashayar Gatmiry</a>, <a href="http://arxiv.org/find/cs/1/au:+Kelner_J/0/1/0/all/0/1">Jonathan Kelner</a>, <a href="http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1">Santosh S. Vempala</a></p><p>We analyze Riemannian Hamiltonian Monte Carlo (RHMC) for sampling a polytope
defined by $m$ inequalities in $\R^n$ endowed with the metric defined by the
Hessian of a self-concordant convex barrier function. We use a hybrid of the
$p$-Lewis weight barrier and the standard logarithmic barrier and prove that
the mixing rate is bounded by $\tilde O(m^{1/3}n^{4/3})$, improving on the
previous best bound of $\tilde O(mn^{2/3})$, based on the log barrier. Our
analysis overcomes several technical challenges to establish this result, in
the process deriving smoothness bounds on Hamiltonian curves and extending
self-concordance notions to the infinity norm; both properties appear to be of
independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00569'>A linear time algorithm for linearizing quadratic and higher-order shortest path problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eranda &#xc7;ela, Bettina Klinz, Stefan Lendl, Gerhard J. Woeginger, Lasse Wulf</p><p>An instance of the NP-hard Quadratic Shortest Path Problem (QSPP) is called
linearizable iff it is equivalent to an instance of the classic Shortest Path
Problem (SPP) on the same input digraph. The linearization problem for the QSPP
(LinQSPP) decides whether a given QSPP instance is linearizable and determines
the corresponding SPP instance in the positive case. We provide a novel linear
time algorithm for the LinQSPP on acyclic digraphs which runs considerably
faster than the previously best algorithm. The algorithm is based on a new
insight revealing that the linearizability of the QSPP for acyclic digraphs can
be seen as a local property. Our approach extends to the more general
higher-order shortest path problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cela_E/0/1/0/all/0/1">Eranda &#xc7;ela</a>, <a href="http://arxiv.org/find/cs/1/au:+Klinz_B/0/1/0/all/0/1">Bettina Klinz</a>, <a href="http://arxiv.org/find/cs/1/au:+Lendl_S/0/1/0/all/0/1">Stefan Lendl</a>, <a href="http://arxiv.org/find/cs/1/au:+Woeginger_G/0/1/0/all/0/1">Gerhard J. Woeginger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wulf_L/0/1/0/all/0/1">Lasse Wulf</a></p><p>An instance of the NP-hard Quadratic Shortest Path Problem (QSPP) is called
linearizable iff it is equivalent to an instance of the classic Shortest Path
Problem (SPP) on the same input digraph. The linearization problem for the QSPP
(LinQSPP) decides whether a given QSPP instance is linearizable and determines
the corresponding SPP instance in the positive case. We provide a novel linear
time algorithm for the LinQSPP on acyclic digraphs which runs considerably
faster than the previously best algorithm. The algorithm is based on a new
insight revealing that the linearizability of the QSPP for acyclic digraphs can
be seen as a local property. Our approach extends to the more general
higher-order shortest path problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.00709'>Robust and Practical Solution of Laplacian Equations by Approximate Elimination</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuan Gao, Rasmus Kyng, Daniel A. Spielman</p><p>We introduce a new algorithm and software for solving linear equations in
symmetric diagonally dominant matrices with non-positive off-diagonal entries
(SDDM matrices), including Laplacian matrices. We use pre-conditioned conjugate
gradient (PCG) to solve the system of linear equations. Our preconditioner is a
variant of the Approximate Cholesky factorization of Kyng and Sachdeva (FOCS
2016). Our factorization approach is simple: we eliminate matrix rows/columns
one at a time and update the remaining matrix using sampling to approximate the
outcome of complete Cholesky factorization. Unlike earlier approaches, our
sampling always maintains a connectivity in the remaining non-zero structure.
Our algorithm comes with a tuning parameter that upper bounds the number of
samples made per original entry. We implement our algorithm in Julia, providing
two versions, AC and AC2, that respectively use 1 and 2 samples per original
entry. We compare their single-threaded performance to that of current
state-of-the-art solvers Combinatorial Multigrid (CMG),
BoomerAMG-preconditioned Krylov solvers from HyPre and PETSc, Lean Algebraic
Multigrid (LAMG), and MATLAB's with Incomplete Cholesky Factorization (ICC).
Our evaluation uses a broad class of problems, including all large SDDM
matrices from the SuiteSparse collection and diverse programmatically generated
instances. Our experiments suggest that our algorithm attains a level of
robustness and reliability not seen before in SDDM solvers, while retaining
good performance across all instances. Our code and data are public, and we
provide a tutorial on how to replicate our tests. We hope that others will
adopt this suite of tests as a benchmark, which we refer to as SDDM2023. Our
solver code is available at: github.com/danspielman/Laplacians.jl/ Our
benchmarking data and tutorial are available at:
rjkyng.github.io/SDDM2023/
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gao_Y/0/1/0/all/0/1">Yuan Gao</a>, <a href="http://arxiv.org/find/math/1/au:+Kyng_R/0/1/0/all/0/1">Rasmus Kyng</a>, <a href="http://arxiv.org/find/math/1/au:+Spielman_D/0/1/0/all/0/1">Daniel A. Spielman</a></p><p>We introduce a new algorithm and software for solving linear equations in
symmetric diagonally dominant matrices with non-positive off-diagonal entries
(SDDM matrices), including Laplacian matrices. We use pre-conditioned conjugate
gradient (PCG) to solve the system of linear equations. Our preconditioner is a
variant of the Approximate Cholesky factorization of Kyng and Sachdeva (FOCS
2016). Our factorization approach is simple: we eliminate matrix rows/columns
one at a time and update the remaining matrix using sampling to approximate the
outcome of complete Cholesky factorization. Unlike earlier approaches, our
sampling always maintains a connectivity in the remaining non-zero structure.
Our algorithm comes with a tuning parameter that upper bounds the number of
samples made per original entry. We implement our algorithm in Julia, providing
two versions, AC and AC2, that respectively use 1 and 2 samples per original
entry. We compare their single-threaded performance to that of current
state-of-the-art solvers Combinatorial Multigrid (CMG),
BoomerAMG-preconditioned Krylov solvers from HyPre and PETSc, Lean Algebraic
Multigrid (LAMG), and MATLAB's with Incomplete Cholesky Factorization (ICC).
Our evaluation uses a broad class of problems, including all large SDDM
matrices from the SuiteSparse collection and diverse programmatically generated
instances. Our experiments suggest that our algorithm attains a level of
robustness and reliability not seen before in SDDM solvers, while retaining
good performance across all instances. Our code and data are public, and we
provide a tutorial on how to replicate our tests. We hope that others will
adopt this suite of tests as a benchmark, which we refer to as SDDM2023. Our
solver code is available at: https://github.com/danspielman/Laplacians.jl/ Our
benchmarking data and tutorial are available at:
https://rjkyng.github.io/SDDM2023/
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-02T01:30:00Z">Thursday, March 02 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, March 01
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/03/01/tcs-talk-wednesday-march-8-christos-tzamos-u-athens-uw-madison/'>TCS+ talk: Wednesday, March 8 — Christos Tzamos, U Athens/UW Madison</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, March 8th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Christos Tzamos from University of Athens/UW Madison will speak about &#8220;A Strongly Polynomial Algorithm for Approximate Forster Transforms and its Application to Halfspace Learning&#8221; (abstract below). You can [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, March 8th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Christos Tzamos</strong> from University of Athens/UW Madison will speak about &#8220;<em>A Strongly Polynomial Algorithm for Approximate Forster Transforms and its Application to Halfspace Learning</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: The Forster transform is a method of regularizing a dataset by placing it in radial isotropic position while maintaining some of its essential properties. Forster transforms have played a key role in a diverse range of settings spanning computer science and functional analysis. Prior work had given weakly polynomial time algorithms for computing Forster transforms, when they exist. Our main result is the first strongly polynomial time algorithm to compute an approximate Forster transform of a given dataset or certify that no such transformation exists. By leveraging our strongly polynomial Forster algorithm, we obtain the first strongly polynomial time algorithm for distribution-free PAC learning of halfspaces. This learning result is surprising because proper PAC learning of halfspaces is equivalent to linear programming. Our learning approach extends to give a strongly polynomial halfspace learner in the presence of random classification noise and, more generally, Massart noise.</p></blockquote>
<p>&#8220;</p>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T21:43:08Z">Wednesday, March 01 2023, 21:43</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/03/01/non-crossing-hamiltonian.html'>Non-crossing Hamiltonian paths and cycles in output-polynomial time</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          My paper “Non-crossing Hamiltonian paths and cycles in output-polynomial time”, to appear at SoCG, is now online as a preprint at arXiv:2303.00147. This is the full version; the SoCG version will need to be cut down by omitting proofs to reach the 500-line proceedings limit. It’s about polygonalization, the problem of finding all ways of connecting dots in the plane into a simple polygon (allowing connections that pass straight through a dot, but not allowing missing a dot altogether). The main results are that we can list all of these in time polynomial in the output size, and in polynomial time get an approximate count of them that is bounded above and below the true count by a polynomial of its value. Previously, the best we knew were that there were at most exponentially many polygonalizations and that we could list them in exponential time.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>My paper “Non-crossing Hamiltonian paths and cycles in output-polynomial time”, to appear at SoCG, is now online as a preprint at <a href="https://arxiv.org/abs/2303.00147">arXiv:2303.00147</a>. This is the full version; the SoCG version will need to be cut down by omitting proofs to reach the 500-line proceedings limit. It’s about <a href="https://en.wikipedia.org/wiki/Polygonalization">polygonalization</a>, the problem of finding all ways of connecting dots in the plane into a simple polygon (allowing connections that pass straight through a dot, but not allowing missing a dot altogether). The main results are that we can list all of these in time polynomial in the output size, and in polynomial time get an approximate count of them that is bounded above and below the true count by a polynomial of its value. Previously, the best we knew were that there were at most exponentially many polygonalizations and that we could list them in exponential time.</p>

<p>I think of this as being in the vein of recent conferences like the <a href="https://www.siam.org/conferences/cm/conference/sosa23">Symposium on Simplicity in Algorithms</a> or the new “simplicity track” of the <a href="http://esa-symposium.org/">European Symposium on Algorithms</a>: simple algorithms whose analysis isn’t. In fact, the algorithm in my paper isn’t even new. It’s the same one that was already used to achieve exponential time, in a paper “Algorithmic enumeration of surrounding polygons” by Katsuhisa Yamanaka, David Avis, Takashi Horiyama, Yoshio Okamoto, Ryuhei Uehara, and Tanami Yamauchi, published in 2021 in <em>Discrete Applied Mathematics</em> (<a href="https://doi.org/10.1016/j.dam.2020.03.034">doi:10.1016/j.dam.2020.03.03</a>).</p>

<p>If we want to list all structures, from an exponentally large family of structures, in time polynomial per structure, then I think there’s really only one idea and a lot of elaboration on that idea. The idea is: describe your structures as the vertices of a large state space, with some sort of local operation for moving from state to state; prove that this local operation suffices to connect all the states together; and then apply a graph exploration algorithm like depth-first search to find all of the states from some starting state. The trouble is, for polygonalizations, we don’t know a good local operation. The obvious candidates, local moves that replace two or three edges of a polygon by a different set of edges, <a href="/blog/2020/01/29/unflippable-polygon.html">were proven not to work</a> in a 2002 paper by Carmen Fernando, Michael Houle, and Ferran Hurtado (<a href="https://doi.org/10.1016%2FS0304-3975%2801%2900409-1">doi:10.1016/S0304-3975(01)00409-1</a>). Instead, Yamanaka et al. propose to list all of the members of a larger family of structures, and then filter out the ones that are really polygonalizations. These more general structures are the “surrounding polygons” of their paper’s title.</p>

<p>A surrounding polygon is just a simple polygon that uses some of the given dots as vertices and contains the rest. The example below is taken from the last section of my paper. There I show that point sets like the one in the illustration, with one concave chain of dots inside a triangle, have \((n-1)2^{n-4}\) polygonalizations but a polynomially-larger number of surrounding polygons proportional to \(n(1+\varphi)^n\). Here \(\varphi\) is the golden ratio; this is <a href="/blog/2020/01/12/counting-grid-polygonalizations.html">not the first occurrence of the golden ratio in counting polygonalizations</a>. A reviewer told me that these point sets are called “party-hat sets” or “ice-cream cone sets” but I’m not sure I believe it; I couldn’t find those names in a Google Scholar search.</p>

<p style="text-align:center"><img src="/blog/assets/2023/pseudotriangle.svg" alt="A set of points in the form of a triangle with a concave chain of points replacing one of its edges, and a surrounding polygon of the points. The points that are vertices of the polygon are colored blue, and the other points surrounded by the polygon are colored red." /></p>

<p>The simplest surrounding polygon of any input is just its <a href="https://en.wikipedia.org/wiki/Convex_hull">convex hull</a>. You can get from any surrounding polygon that is not the convex hull to a simpler one by “<a href="https://en.wikipedia.org/wiki/Two_ears_theorem">ear-cutting</a>”: find two consecutive edges of the polygon that form two sides of an empty triangle outside the polygon, and replace them by a single shortcut edge. The shortcutted vertex becomes surrounded, and the area of the polygon grows, so repeated ear-cutting can only stop at the convex hull, implying that all surrounding polygons are connected through the convex hull. If you choose carefully which ear to cut, you give all surrounding polygons the structure of a tree, and the algorithm of Yamanaka et al. amounts to depth-first search of this tree. You can then find the polygonalizations just by running this algorithm and outputting only the surrounding polygons that use all the dots, at some tree leaves.</p>

<p>The idea of my new paper is to analyze these structures in the style of my book, <a href="https://www.ics.uci.edu/~eppstein/forbidden/"><em>Forbidden Configurations in Discrete Geometry</em></a>, in terms of simple parameters of point sets that are monotonic (they don’t go down when you add more points) and that depend only on the order-type of the point set and not its exact coordinates. The question I set out to answer is: which point sets have only a very small number of polygonalizations, and which have many? I quickly identified two ways in which a point set could only have a small number:</p>

<ul>
  <li>
    <p>Most of its points could belong to a single line. If a set of \(n\) points has \(n-k\) points on a line, and only a much smaller number \(k\) of points elsewhere, then most of the edges would have to connect paths of consecutive points along the line, and there aren’t very many ways of doing that. This number \(k\) is one of the parameters studied in my book. Working out the details of this argument showed more specifically that the number of polygonalizations is \(n^{O(k)}\): there are only \(O(k)\) points of any polygonalization where something interesting happens, and only \(O(n)\) choices for what happens there.</p>
  </li>
  <li>
    <p>Most of its points could belong to the convex hull. If all points belong to the convex hull, then that is the only polygonalization. And if there are \(n-k\) points on the hull, and only a much smaller number \(k\) of points elsewhere, then the only points where something interesting happens are the \(O(k)\) points that are either not on the hull, or adjacent to a non-hull point. All the rest of their points have to be connected to their two hull neighbors. So again the number of polygonalizations is \(n^{O(k)}\). The parameter used here, the number of points interior to the hull, was not from my book, but maybe it should have been.</p>
  </li>
</ul>

<p>More strongly, upper bounds of the same form also apply to surrounding polygons. Allowing an interesting point to be skipped by the polygon doesn’t increase its number of choices much. Consecutive blocks of uninteresting points along a long line of points must either all be skipped or all be part of a surrounding polygon, again not increasing the number of choices by much. And a surrounding polygon cannot skip any point of the convex hull, because then it would not be surrounded. The part of the analysis that I found more difficult was proving that these are the only cases. If you have points that are mostly not on a line and mostly not on a hull, then there are exponentially many polygonalizations. And if you have one of the two situations with few polygonalizations described above, then the number of polygonalizations is accurately described by the upper bounds above. For details of these lower bounds, see the paper. The number of surrounding polygons can only be at least as large as the number of polygonalizations, because every polygonalization is a surrounding polygon.</p>

<p>Once that analysis was done, the algorithms for listing polygonalizations and for approximately counting them came for free. The lower bound and the upper bound on the number of polygonalizations have the same form as each other, so they give an accurate approximation without any more effort. And the bounds on the number of polygonalizations and on the number of surrounding polygons have the same form as each other, so the analysis of the algorithm for surrounding polygons (that it takes input-polynomial time per polygon) also shows that it generates all polygonalizations in output-polynomial time.</p>

<p>The “non-crossing Hamiltonian paths” of the new paper’s title are the same thing, but easier. The easier-to-generate structures are non-crossing paths, which you can form into a forest (rooted at the one-vertex paths) by a parent operation that removes the final edge of a path. And points in convex position still have many paths; the only point sets that have a small number of non-crossing Hamiltonian paths (or non-crossing paths) are the ones with most of the points on a single line.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/109951209389425592">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T17:51:00Z">Wednesday, March 01 2023, 17:51</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/03/01/soda-2023/'>SODA 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Traces of strings, plus ways of tracing accepted papers Anindya De was at Northwestern University and is now at the University of Pennsylvania&#8212;see here. He was advised by two of the top advisors ever there were: Luca Trevisan and Umesh Vazirani. Traces I recently ran across a great paper by Anindya titled Approximate Trace Reconstruction [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>Traces of strings, plus ways of tracing accepted papers</em><br />
<font color="#000000"></p>
<p>
Anindya De was at Northwestern University and is now at the University of Pennsylvania&#8212;see <a href="https://www.seas.upenn.edu/~anindyad/">here</a>. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/01/soda-2023/ad-2/" rel="attachment wp-att-21192"><img data-attachment-id="21192" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/01/soda-2023/ad-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?fit=400%2C400&amp;ssl=1" data-orig-size="400,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 5D Mark III&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1551052800&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;200&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.00625&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ad" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?fit=400%2C400&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?resize=250%2C250&#038;ssl=1" alt="" width="250" height="250" class="aligncenter wp-image-21192" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?w=400&amp;ssl=1 400w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/ad.jpg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 250px) 100vw, 250px" data-recalc-dims="1" /></a></p>
<p>
He was advised by two of the top advisors ever there were: Luca Trevisan and Umesh Vazirani. </p>
<p>
<p><H2> Traces </H2></p>
<p><p>
I recently ran across a great paper by Anindya titled <a href="https://arxiv.org/abs/2211.03292">Approximate Trace Reconstruction from a Single Trace</a>. It is co-authored with Xi Chen (Columbia University), Chin Ho Lee (Harvard University), and Rocco Servedio and Sandip Sinha (Columbia University). Notice that we did not put an <a href="https://jewishstandard.timesofisrael.com/horse-mule-horse-mule/">Oxford comma</a> between Servedio and Sinha as they are both from Columbia. The paper appeared at <a href="https://www.siam.org/conferences/cm/program/accepted-papers/soda23-accepted-papers">SODA 2023</a> this January. </p>
<p>
Here are pointers to the almost 200 papers that were in the conference. I put this together before discovering the site <a href="https://www.conference-publishing.com/">conference-publishing.com</a>, which as mentioned in my STOC 2023 <a href="https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/">post</a> generates paper lists with links for a host of conferences. So I did all the following links myself. Do scroll past the list to the bottom to read a little more about traces which Ken and I put together.</p>
<ol>
<p><li>
<a href="https://arxiv.org/pdf/2204.09129.pdf">Small Shadows of Lattice Polytopes</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.05186">Fair allocation of a multiset of indivisible items</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.02277">Hierarchies of Minion Tests for PCSPs through Tensors</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.08293">Approximate Graph Colouring and Crystals</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.04455">The Price of Stability for First Price Auction</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.04549">Spencer&#8217;s theorem in nearly input-sparsity time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.11195">Spatial Mixing and the random-cluster dynamics on lattices</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch157">Nonlinear codes exceeding the Gilbert-Varshamov and Tsfasman-Vladut-Zink bounds</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.09391">A Near-Linear Time Sampler for the Ising Model with External Field</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.02655">Concentration of polynomial random matrices via Efron-Stein inequalities</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.15945">Quantum Speed-ups for String Synchronizing Sets, Longest Common Substring, and kmismatch Matching</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.11275">Halving by a Thousand Cuts or Punctures</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch50">On the number incidences when avoiding an induced biclique in geometric settings</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.00579">Subexponential mixing for partition chains on grid-like graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2103.02972">Weisfeilera Leman and Graph Spectra</a></p>
<p><li>
<a href="https://arxiv.org/abs/2203.09334">Stronger 3SUM-Indexing Lower Bounds</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.10556">Tight Bounds for Monotone Minimal Perfect Hashing</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.02732">Almost Consistent Systems of Linear Equations</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.05898">Testing and Learning Quantum Juntas Nearly Optimally</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch155">Testing Convex Truncation</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch55">Player-optimal Stable Regret for Bandit Learning in Matching Markets</a></p>
<p><li>
<a href="https://arxiv.org/abs/2103.03769">Competitive Information Design for Pandoras Box</a></p>
<p><li>
<a href="https://arxiv.org/abs/2106.12725">Breaking the O(n)-Barrier in the Construction of Compressed Suffix Arrays and Suffix Trees</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.14108">Short Synchronizing Words for Random Automata</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.00450">Packing cycles in planar and bounded-genus graphs</a></p>
<p><li>
<a href="https://web.eecs.umich.edu/~pettie/papers/LLL.pdf">Improved Distributed Algorithms for the Lovasz Local Lemma and Edge Coloring</a></p>
<p><li>
<a href="https://arxiv.org/abs/2112.07050">Optimal Fully Dynamic <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" />-Center Clustering for Adaptive and Oblivious Adversaries</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.13335">A logic-based algorithmic meta-theorem for mim-width</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.12800">Tiny Pointers</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07158">Streaming complexity of CSPs with randomly ordered constraints</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.04458">Computing Square Colorings on Bounded-Treewidth and Planar Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2203.00751">Near-Linear Time Approximations for Cut Problems via Fair Cuts</a></p>
<p><li>
<a href="https://deepai.org/publication/stronger-privacy-amplification-by-shuffling-for-renyi-and-approximate-differential-privacy">Stronger Privacy Amplification by Shuffling for R&eacute;nyi and Approximate Differential Privacy</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.13696">Minimizing Completion Times for Stochastic Jobs via Batched Free Times</a></p>
<p><li>
<a href="https://arxiv.org/abs/2106.02149">Optimal Pricing Schemes for an Impatient Buyer</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07974">Online Prediction in Sub-linear Space</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.03268">Fast Discrepancy Minimization with Hereditary Guarantees</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07363">Exact Flow Sparsification Requires Unbounded Size</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07809">Curve Simplification and Clustering under Frechet Distance</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08783">Almost Tight Bounds for Online Facility Location in the Random-Order Model</a></p>
<p><li>
<a href="https://arxiv.org/abs/2104.00406">The complete classification for quantified equality constraints</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.02170">Small subgraphs with large average degree</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.07544">Mean estimation when you have the source code; or, quantum Monte Carlo methods</a></p>
<p><li>
<a href="https://arxiv.org/abs/2212.03016">Online Min-Max Paging</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.08904">Gap-ETH-Tight Approximation Schemes for Red-Green-Blue Separation and BicoloredEuclidean Travelling Salesman Tours</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.02951">Map matching queries on realistic input graphs under the Frachet distance</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.07410">Private Query Release via the Johnson Lindenstrauss Transform</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.07571">Efficient decoding up to a constant fraction of the code length for asymptotically goodquantum codes</a> </p>
<p><li>
<a href="https://arxiv.org/abs/2202.01248">Passing the Limits of Pure Local Search for weighted k-Set Packing</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.11892">Improved Bounds for Sampling Solutions of Random CNF Formulas</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.03158">Pricing Query Complexity of Revenue Maximization</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07422">Flow-augmentation III: complexity dichotomy for Boolean CSPs parameterized by thenumber of unsatisfied constraints</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07425">Parameter tractability of Directed Multicut with three terminal pairs parameterizedby the size of the cutset: twin-width meets flow-augmentation</a> </p>
<p><li>
<a href="https://arxiv.org/abs/2012.06713">Approximate Trace Reconstruction from a Single Trace</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07519">Dynamic Algorithms for Packing-Covering LPs via Multiplicative Weight Updates</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.03469">Sharp threshold sequence and universality for Ising perceptron models</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.02519">Maintaining Expander Decompositions via Sparse Cuts</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.09341">Near Optimal Analysis of the Cube versus Cube Test</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.09341">Approximating Knapsack and Partition via Dense Subset Sums</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.13755">Online and Bandit Algorithms for Norms with Gradient-Stable Approximations</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.04868">On complex roots of the independence polynomial</a></p>
<p><li>
<a href="https://deepai.org/publication/simplex-range-searching-revisited-how-to-shave-logs-in-multi-level-data-structures">Simplex Range Searching Revisited: How to Shave Logs in Multi-Level Data Structures</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.04112">Improved Pattern-Avoidance Bounds for Greedy BSTs via Matrix Decomposition</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.06527">Moser-Tardos Algorithm: Beyond Shearer&#8217;s Bound</a></p>
<p><li>
<a href="https://arxiv.org/abs/2212.14847">Deterministic counting Lovasz local lemma beyond linear programming</a></p>
<p><li>
<a href="https://arxiv.org/abs/2205.05564">Conflict-free hypergraph matchings</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.12721">A Subquadratic <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%5Cepsilon%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n^&#92;epsilon}" class="latex" />-approximation for the Continuous Frachet Distance</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.08044">Interdependent Public Projects</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.04994">A Nearly Time-Optimal Distributed Approximation of Minimum Cost <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" />-Edge-Connected Spanning Subgraph</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07426">A tight quasi-polynomial bound for Global Label Min-Cut</a></p>
<p><li>
<a href="https://arxiv.org/abs/2205.07709">Polynomial formulations as a barrier for reduction-based hardness proofs</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch173">Faster Algorithm for Turn-based Stochastic Games with Bounded Treewidth</a></p>
<p><li>
<a href="https://arxiv.org/abs/2203.17144">Instability of backoff protocols with arbitrary arrival rates</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch158">On the orbit closure intersection problems for matrix tuples under conjugation and leftright actions</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.04377">Constant Approximating Parameterized k-SetCover is W[2]-hard</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08268?context=stat.ML">Online Lewis Weight Sampling</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.11328">Toeplitz Low-Rank Approximation with Sublinear Query Complexity</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.06874">Kernelization for Graph Packing Problems via Rainbow Matching</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.01143">Improved Integrality Gap in Max-Min Allocation: or Topology at the North Pole</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.06292">Generalized Unrelated Machine Scheduling Problem</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.04278">Tight Complexity Bounds for Counting Generalized Dominating Sets in Bounded-Treewidth Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2301.07537">An Improved Approximation for Maximum Weighted k-Set Packing</a></p>
<p><li>
<a href="https://arxiv.org/abs/2212.09348">Excluding Single-Crossing Matching Minors in Bipartite Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.15335">Byzantine Agreement with Optimal Resilience via Statistical Fraud Detection</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05345">Finding Triangles and Other Small Subgraphs in Geometric Intersection Graphs</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch188">Simple, deterministic, fast (but weak) approximations to edit distance and Dyck edit distance</a> </p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch132">From algorithms to connectivity and back: finding a giant component in random k-SAT</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.00594">Sparse graphs with bounded induced cycle packing number have logarithmic treewidth</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08311">Shrunk subspaces via operator Sinkhorn iteration</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.10398">Improved Approximation Algorithms for Unrelated Machines</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.01723">Model-Checking for First-Order Logic with Disjoint Paths Predicates in Proper MinorClosed Graph Classes</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.10556">A Distanced Matching Game, Decremental APSP in Expanders, and Faster DeterministicAlgorithms for Graph Cut Problems</a> </p>
<p><li>
<a href="https://arxiv.org/abs/2005.06156">Super-resolution and Robust Sparse Continuous Fourier Transform in Any Constant Dimension: Nearly Linear Time and Sample Complexity</a></p>
<p><li>
<a href="https://chaoxuprime.com/files/papers/sub4part.pdf">A Polynomial Time Algorithm for Finding a Minimum 4-Partition of a Submodular Function</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.05423">Positivity of the symmetric group characters is PH-hard</a></p>
<p><li>
<a href="https://arxiv.org/abs/1905.08841">Parallel Exact Shortest Paths in Almost Linear Work and Square Root Depth</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/10.1137/1.9781611977554.ch40">On the Integrality Gap of MFN Relaxation for the Capacitated Facility Location Problem</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch105">Weak Bisimulation Finiteness of Pushdown Systems With Deterministic Transitions-ExpTime-Complete</a></p>
<p><li>
<a href="https://arxiv.org/abs/2206.13057">Beating Greedy Matching in Sublinear Time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2203.11863">Integrality Gaps for Random Integer Programs via Discrepancy</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.10265">Improved Approximation for Two-Edge-Connectivity</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch117">Zigzagging through acyclic orientations of chordal graphs and hypergraphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.04797">Shortest Cycles With Monotone Submodular Costs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2107.07347">Traversing the FFT Computation Tree for Dimension-Independent Sparse FourierTransforms</a> </p>
<p><li>
<a href="https://arxiv.org/abs/2207.07449">Fixed-Parameter Tractability of Maximum Colored Path and Beyond</a></p>
<p><li>
<a href="https://arxiv.org/abs/2007.12257">A half-integral Erd&#337;s-P&oacute;sa theorem for directed odd cycles</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.13395">Improved Bi-point Rounding Algorithms and a Golden Barrier for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" />-Median</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.05659">Approximate Distance Oracles for Planar Graphs with Subpolynomial Error Dependency</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.02717">A Framework for Approximation Schemes on Disk Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.13281">Cubic Goldreich-Levin</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.04507">Closing the Gap Between Directed Hopsets and Shortcut Sets</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.09215">&#8220;Who is Next in Line?&#8221; On the Significance of Knowing the Arrival Order in Bayesian Online Settings</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05217">Smaller Low-Depth Circuits for Kronecker Powers</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.14759">Fast algorithms for solving the Hamilton Cycle problem with high probability</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05053">On Minimizing Tardy Processing Time, Max-Min Skewed Convolution, and TrianglarStructured ILPs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2302.02290">Maximal k-Edge-Connected Subgraphs in Weighted Graphs via Local Random Contraction</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.10850">A simple and sharper proof of the hypergraph Moore bound</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08643">A Sublinear-Time Quantum Algorithm for Approximating Partition Functions</a></p>
<p><li>
<a href="https://arxiv.org/abs/2202.13484">On Problems Related to Unbounded SubsetSum: A Unified Combinatorial Approach</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.03893">Query Complexity of the Metric Steiner Tree Problem</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.12601">Sublinear-Time Algorithms for Max Cut, Max E2Lin<img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%28q%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{(q)}" class="latex" />, and Unique Label Cover on Expanders</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.06790">Near-Linear Sample Complexity for <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BL_p%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{L_p}" class="latex" /> Polynomial Regression</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.07520">On (Random-order) Online Contention Resolution Schemes for the Matching Polytope of (Bipartite) Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.09964">Optimal Algorithms for Linear Algebra in the Current Matrix Multiplication Time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07946">Algebraic Algorithms for Fractional Linear Matroid Parity via Non-commutative Rank</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05006">Almost Tight Error Bounds on Differentially Private Continual Counting</a></p>
<p><li>
<a href="https://arxiv.org/abs/2208.09159">Secretary Problems: The Power of a Single Sample</a></p>
<p><li>
<a href="https://arxiv.org/abs/2112.06380">Robust Voting Rules from Algorithmic Robust Statistics</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch9">Faster and Unified Algorithms for Diameter Reducing Shortcuts and Minimum Chain Cover</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch85">Improved girth approximation in weighted undirected graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2112.03791">Online Sorting and Translational Packing of Convex Polygons</a></p>
<p><li>
<a href="https://arxiv.org/abs/2302.05951">Fully Dynamic Exact Edge Connectivity in Sublinear Time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.11072">Algorithmizing the Multiplicity Schwartz-Zippel Lemma</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07949">A Nearly Tight Analysis of Greedy k-means++</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07007?context=cs">A polynomial-time algorithm for 1/2-well-supported Nash equilibria in bimatrix games</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.10969">Bidder subset selection problem in auction design</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.09035">Massively Parallel Computation on Embedded Planar Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2301.09810">Balanced Allocations: The Power of Memory with Heterogeneous Bins</a></p>
<p><li>
<a href="https://arxiv.org/abs/2003.00545">Simple Mechanisms for Agents with Non-linear Utilities</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch59">The Power of Clairvoyance for Multi-Level Aggregation and Set Cover with Delay</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05769">Steiner Connectivity Augmentation and Splitting-off in Poly-logarithmic Maximum Flows</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05509">Discrepancy minimization via regularization</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch162">Equivalence Test for Read-Once Arithmetic Formulas</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.07534">Time-Space Tradeoffs for Element Distinctness and Set Intersection via Pseudorandomness</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.11651">Local Distributed Rounding: Generalized to MIS, Matching, Set Cover, and Beyond</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch143">Parameterized Approximation Scheme for Biclique-free Max k-Weight SAT and Max Coverage</a></p>
<p><li>
<a href="https://arxiv.org/abs/2209.11669">Improved Distributed Network Decomposition, Hitting Sets, and Spanners, via Derandomization</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.05150">Breaching the 2 LMP Approximation Barrier for Facility Location with Applications to kMedian</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.12441">Query Complexity of Inversion Minimization on Trees</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch4">Faster Deterministic Worst-Case Fully Dynamic All-Pairs Shortest Paths via Decremental Hop-Restricted Shortest Paths</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch189">Optimal Square Detection Over General Alphabets</a></p>
<p><li>
<a href="https://arxiv.org/abs/2203.16476">Differentially Private All-Pairs Shortest Path Distances: Improved Algorithms and Lower Bounds</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch96">Faster Computation of 3-Edge-Connected Components in Digraphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2201.10758">Sampling Equilibria: Fast No-Regret Learning in Structured Games</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.07327">Higher degree sum-of-squares relaxations robust against oblivious outliers</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.07606">Fast Distributed Brooks Theorem</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch119">Graph Classes With Few Minimal Separators. I. Finite Forbidden Subgraphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.03530">Optimal Deterministic Massively Parallel Connectivity on Forests</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.03151">Foundations of Transaction Fee Mechanism Design</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch119">Graph Classes With Few Minimal Separators. II. A Dichotomy</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.01945">Distributed Maximal Matching and Maximal Independent Set on Hypergraphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08800">Quantum tomography using state-preparation unitaries</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.01911">Almost-Linear Planted Cliques Elude the Metropolis Process</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.05450">Timeliness Through Telephones</a></p>
<p><li>
<a href="https://www.ccs.neu.edu/home/viola/papers/resilient.pdf">Efficient resilient functions</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07438">Dynamic Matching with Better-than-2 Approximation in Polylogarithmic Update Time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.03877">The Need for Seed (in the abstract Tile Assembly Model)</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.08347">Private Convex Optimization in General Norms</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07607">Dynamic Algorithms for Maximum Matching Size</a></p>
<p><li>
<a href="https://arxiv.org/abs/2111.01254">Unique Games hardness of Quantum Max-Cut, and a conjectured vector-valued Borell&#8217;s inequality</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch23">A Nearly-tight Analysis of Multipass Pairing Heaps</a></p>
<p><li>
<a href="https://arxiv.org/abs/2108.04458">A Tight Analysis of Slim Heaps and Smooth Heaps</a></p>
<p><li>
<a href="https://arxiv.org/abs/2106.04863">Lossless Online Rounding for Online Bipartite Matching (Despite its Impossibility)</a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.07983?context=cs">Approximation Algorithms for Steiner Tree Augmentation Problems</a></p>
<p><li>
<a href="https://arxiv.org/abs/2204.08404">Low Degree Testing over the Reals</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.05170">Streaming algorithms for the missing item finding problem</a></p>
<p><li>
<a href="https://cse.hkust.edu.hk/faculty/arya/pub/soda23.pdf">Economical Convex Coverings and Applications</a></p>
<p><li>
<a href="https://eccc.weizmann.ac.il/report/2022/146/">Interactive Coding with Small Memory</a></p>
<p><li>
<a href="https://arxiv.org/abs/2301.05682">Non-Stochastic CDF Estimation Using Threshold Queries</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch30">Elliptic Curve Fast Fourier Transform Part I : Low-degree extension in time O(n log n) over all finite fields</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch33">Single-Pass Streaming Algorithms for Correlation Clustering</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.01468">A New Approach to Estimating Effective Resistances and Counting Spanning Trees in Expander Graphs</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.06375">Superpolynomial Lower Bounds for Decision Tree Learning and Testing</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.07132">The <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_p%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;ell_p}" class="latex" />-Subspace Sketch Problem in Small Dimensions with Applications to Support Vector Machines</a></p>
<p><li>
<a href="https://arxiv.org/abs/2210.17515">Beating <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%281-1%2Fe%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{(1-1/e)}" class="latex" />-Approximation for Weighted Stochastic Matching</a></p>
<p><li>
<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch35">Towards Multi-Pass Streaming Lower Bounds for Optimal Approximation of Max-Cut</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.03341">Parameterized Algorithm for the Planar Disjoint Paths Problem: Exponential in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%5E2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k^2}" class="latex" />, and Linear in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /></a></p>
<p><li>
<a href="https://arxiv.org/abs/2207.02581">Learning Hierarchical Cluster Structure of Graphs in Sublinear Time</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.09106">The Exact Bipartite Matching Polytope Has Exponential Extension Complexity</a></p>
<p><li>
<a href="https://arxiv.org/abs/2211.03161">4D Range Reporting in the Pointer Machine Model in Almost-Optimal Time</a></p>
</ol>
<p>
<p><H2> The Trace Result </H2></p>
<p><p>
The trace problem begins by sending a binary string <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> of length <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> through a <b>deletion channel</b> with parameter <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cin+%5B0%2C1%5D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;delta &#92;in [0,1]}" class="latex" />. Each bit <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x_i}" class="latex" /> entering the channel survives with probability <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B1+-+%5Cdelta%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{1 - &#92;delta}" class="latex" /> to be part of the output string <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" />. That is, <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x_i}" class="latex" /> is deleted with probability <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;delta}" class="latex" />. The deletions are independent. For an unknown string <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />, the problem is:</p>
<blockquote><p><b> </b> <em> Given <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> strings <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By_1%2C%5Cdots%2Cy_k%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y_1,&#92;dots,y_k}" class="latex" /> produced by <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k}" class="latex" /> runs of the channel on <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />, reconstruct <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> if possible. Else, calculate a binary string <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x&#039;}" class="latex" /> of length <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{n}" class="latex" /> that minimizes a distance metric <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bd%28x%2Cx%27%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{d(x,x&#039;)}" class="latex" />. The metric of choice is to maximize the length <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28x%2Cx%27%29%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;ell(x,x&#039;)}" class="latex" /> of the longest common subsequence (not necessarily contiguous) of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> and <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x&#039;}" class="latex" />, which corresponds to minimizing their edit distance. </em>
</p></blockquote>
<p><p>
As indicated by its title &#8220;Approximate Trace Reconstruction from a Single Trace,&#8221; the <a href="https://arxiv.org/abs/2211.03292">paper</a> tackles the extreme case <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{k=1}" class="latex" />. Of course one cannot reconstruct <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> (unless no deletions occur so <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By+%3D+x%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y = x}" class="latex" />) so the game is to find <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x&#039;}" class="latex" /> that are most likely to have produced the lone observed <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" />. The scoring function takes the expectation of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28x%27%2Cx%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;ell(x&#039;,x)}" class="latex" /> over both the generation of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> from the true <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> and the run of the algorithm guessing <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x&#039;}" class="latex" /> from <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" />. There are two main questions:</p>
<ul>
<li>
How well does the algorithm perform&#8212;relative to theoretically optimal choices given <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" />&#8212;when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> itself is generated uniformly at random? </p>
<li>
How well does the algorithm perform when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> is generated adversarially? Note that <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> is still probabilistic, and the performance of both the theoretical optimal algorithm and their algorithm are evaluated based on the distribution of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> for the fixed (unseen) <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />.
</ul>
<p>
These questions are posed for small, medium, and large values of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;delta}" class="latex" />. When the deletion probability is close to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{1}" class="latex" />, the strings <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> are most often tiny. One would think they offer no help in coming close to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />. However, they do help efficient algorithms come close to the optimal policy for a worst-case chosen <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />. The paradoxical results of their paper, in their own words (but reversing their order), are: </p>
<ol>
<li>
In the average-case setting, having access to a single trace is provably not very useful: no algorithm, computationally efficient or otherwise, can achieve significantly higher accuracy given one trace that is <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bo%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{o(n)}" class="latex" /> bits long than it could with no traces. </p>
<li>
Having access to a single trace is already quite useful for worst-case trace reconstruction: an efficient algorithm can perform much more accurate reconstruction, given one trace that is even only a few bits long, than it could given no traces at all.
</ol>
<p>
The deep point is that when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> as well as <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> is random, seeing <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> gives little advantage to both the optimal strategy (which does not know <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" />) and their algorithm. Whereas, when <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{x}" class="latex" /> is fixed, the knowledge of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> is more valuable to the optimal strategy and separates it from the case of not seeing <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> at all. However, the profit given by even a short <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" /> is one that is apprehendable by a complexity-limited deterministic algorithm that sees only <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7By%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{y}" class="latex" />. That&#8217;s our attempt at an intuitive takeaway; as always we invite readers to consult the paper in detail.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Comparing my list of pointer to the papers from SODA, which was a bit of trouble to create by hand, to the STOC&#8217;23 <a href="https://www.conference-publishing.com/list.php?Event=STOC23">output</a> from the conference-publishing site, leads to a curious question:</p>
<blockquote><p><b> </b> <em> Do we scan lists of papers more by looking for subject words in their titles or looking for authors we know? </em>
</p></blockquote>
<p><p>
Well, I have not found SODA&#8217;23 on that website, where authors too would be given; for me, copying the authors would more than double the manual work.</p>
<p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T06:02:29Z">Wednesday, March 01 2023, 06:02</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14412'>An Algorithm and Complexity Results for Causal Unit Selection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haiying Huang, Adnan Darwiche</p><p>The unit selection problem aims to identify objects, called units, that are
most likely to exhibit a desired mode of behavior when subjected to stimuli
(e.g., customers who are about to churn but would change their mind if
encouraged). Unit selection with counterfactual objective functions was
introduced relatively recently with existing work focusing on bounding a
specific class of objective functions, called the benefit functions, based on
observational and interventional data -- assuming a fully specified model is
not available to evaluate these functions. We complement this line of work by
proposing the first exact algorithm for finding optimal units given a broad
class of causal objective functions and a fully specified structural causal
model (SCM). We show that unit selection under this class of objective
functions is $\text{NP}^\text{PP}$-complete but is $\text{NP}$-complete when
unit variables correspond to all exogenous variables in the SCM. We also
provide treewidth-based complexity bounds on our proposed algorithm while
relating it to a well-known algorithm for Maximum a Posteriori (MAP) inference.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haiying Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Darwiche_A/0/1/0/all/0/1">Adnan Darwiche</a></p><p>The unit selection problem aims to identify objects, called units, that are
most likely to exhibit a desired mode of behavior when subjected to stimuli
(e.g., customers who are about to churn but would change their mind if
encouraged). Unit selection with counterfactual objective functions was
introduced relatively recently with existing work focusing on bounding a
specific class of objective functions, called the benefit functions, based on
observational and interventional data -- assuming a fully specified model is
not available to evaluate these functions. We complement this line of work by
proposing the first exact algorithm for finding optimal units given a broad
class of causal objective functions and a fully specified structural causal
model (SCM). We show that unit selection under this class of objective
functions is $\text{NP}^\text{PP}$-complete but is $\text{NP}$-complete when
unit variables correspond to all exogenous variables in the SCM. We also
provide treewidth-based complexity bounds on our proposed algorithm while
relating it to a well-known algorithm for Maximum a Posteriori (MAP) inference.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14585'>On Degeneracy in the P-Matroid Oriented Matroid Complementarity Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michaela Borzechowski, Simon Weber</p><p>We investigate degeneracy in the P-Matroid Oriented Matroid Complementarity
Problem (P-OMCP) and its impact on the reduction of this problem to
sink-finding in Unique Sink Orientations (USOs). On one hand, this
understanding of degeneracies allows us to prove a linear lower bound for
sink-finding in P-matroid USOs. On the other hand, it allows us to prove a
promise preserving reduction from P-OMCP to USO sink-finding, where we can drop
the assumption that the given P-OMCP is non-degenerate. This places the promise
version of P-OMCP in the complexity class PromiseUEOPL.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Borzechowski_M/0/1/0/all/0/1">Michaela Borzechowski</a>, <a href="http://arxiv.org/find/math/1/au:+Weber_S/0/1/0/all/0/1">Simon Weber</a></p><p>We investigate degeneracy in the P-Matroid Oriented Matroid Complementarity
Problem (P-OMCP) and its impact on the reduction of this problem to
sink-finding in Unique Sink Orientations (USOs). On one hand, this
understanding of degeneracies allows us to prove a linear lower bound for
sink-finding in P-matroid USOs. On the other hand, it allows us to prove a
promise preserving reduction from P-OMCP to USO sink-finding, where we can drop
the assumption that the given P-OMCP is non-degenerate. This places the promise
version of P-OMCP in the complexity class PromiseUEOPL.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14755'>Local Hamiltonians with no low-energy stabilizer states</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nolan J. Coble, Matthew Coudron, Jon Nelson, Seyed Sajjad Nezhadi</p><p>The recently-defined No Low-energy Sampleable States (NLSS) conjecture of
Gharibian and Le Gall [GL22] posits the existence of a family of local
Hamiltonians where all states of low-enough constant energy do not have
succinct representations allowing perfect sampling access. States that can be
prepared using only Clifford gates (i.e. stabilizer states) are an example of
sampleable states, so the NLSS conjecture implies the existence of local
Hamiltonians whose low-energy space contains no stabilizer states. We describe
families that exhibit this requisite property via a simple alteration to local
Hamiltonians corresponding to CSS codes. Our method can also be applied to the
recent NLTS Hamiltonians of Anshu, Breuckmann, and Nirkhe [ABN22], resulting in
a family of local Hamiltonians whose low-energy space contains neither
stabilizer states nor trivial states. We hope that our techniques will
eventually be helpful for constructing Hamiltonians which simultaneously
satisfy NLSS and NLTS.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Coble_N/0/1/0/all/0/1">Nolan J. Coble</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Coudron_M/0/1/0/all/0/1">Matthew Coudron</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nelson_J/0/1/0/all/0/1">Jon Nelson</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Nezhadi_S/0/1/0/all/0/1">Seyed Sajjad Nezhadi</a></p><p>The recently-defined No Low-energy Sampleable States (NLSS) conjecture of
Gharibian and Le Gall [GL22] posits the existence of a family of local
Hamiltonians where all states of low-enough constant energy do not have
succinct representations allowing perfect sampling access. States that can be
prepared using only Clifford gates (i.e. stabilizer states) are an example of
sampleable states, so the NLSS conjecture implies the existence of local
Hamiltonians whose low-energy space contains no stabilizer states. We describe
families that exhibit this requisite property via a simple alteration to local
Hamiltonians corresponding to CSS codes. Our method can also be applied to the
recent NLTS Hamiltonians of Anshu, Breuckmann, and Nirkhe [ABN22], resulting in
a family of local Hamiltonians whose low-energy space contains neither
stabilizer states nor trivial states. We hope that our techniques will
eventually be helpful for constructing Hamiltonians which simultaneously
satisfy NLSS and NLTS.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14125'>A Note on the Faces of the Dual Koch Arrangement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bernd G&#xe4;rtner, Manuel Wettstein</p><p>We analyze the faces of the dual Koch arrangement, which is the arrangement
of $2^s + 1$ lines obtained by projective duality from the Koch chain $K_s$. In
particular, we show that this line arrangement does not contain any $k$-gons
for $k &gt; 5$, and that the number of pentagons is $3 \cdot 2^{s-1} - 3$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gartner_B/0/1/0/all/0/1">Bernd G&#xe4;rtner</a>, <a href="http://arxiv.org/find/cs/1/au:+Wettstein_M/0/1/0/all/0/1">Manuel Wettstein</a></p><p>We analyze the faces of the dual Koch arrangement, which is the arrangement
of $2^s + 1$ lines obtained by projective duality from the Koch chain $K_s$. In
particular, we show that this line arrangement does not contain any $k$-gons
for $k &gt; 5$, and that the number of pentagons is $3 \cdot 2^{s-1} - 3$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14213'>Crossing Minimization in Time Interval Storylines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Dobler, Martin N&#xf6;llenburg, Daniel Stojanovic, Ana&#xef;s Villedieu, Jules Wulms</p><p>Storyline visualizations are a popular way of visualizing characters and
their interactions over time: Characters are drawn as x-monotone curves and
interactions are visualized through close proximity of the corresponding
character curves in a vertical strip. Existing methods to generate storylines
assume a total ordering of the interactions, although real-world data often do
not contain such a total order. Instead, multiple interactions are often
grouped into coarser time intervals such as years. We exploit this grouping
property by introducing a new model called storylines with time intervals and
present two methods to minimize the number of crossings and horizontal space
usage. We then evaluate these algorithms on a small benchmark set to show their
effectiveness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dobler_A/0/1/0/all/0/1">Alexander Dobler</a>, <a href="http://arxiv.org/find/cs/1/au:+Nollenburg_M/0/1/0/all/0/1">Martin N&#xf6;llenburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Stojanovic_D/0/1/0/all/0/1">Daniel Stojanovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Villedieu_A/0/1/0/all/0/1">Ana&#xef;s Villedieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wulms_J/0/1/0/all/0/1">Jules Wulms</a></p><p>Storyline visualizations are a popular way of visualizing characters and
their interactions over time: Characters are drawn as x-monotone curves and
interactions are visualized through close proximity of the corresponding
character curves in a vertical strip. Existing methods to generate storylines
assume a total ordering of the interactions, although real-world data often do
not contain such a total order. Instead, multiple interactions are often
grouped into coarser time intervals such as years. We exploit this grouping
property by introducing a new model called storylines with time intervals and
present two methods to minimize the number of crossings and horizontal space
usage. We then evaluate these algorithms on a small benchmark set to show their
effectiveness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14251'>LaplacianFusion: Detailed 3D Clothed-Human Body Reconstruction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hyomin Kim, Hyeonseo Nam, Jungeon Kim, Jaesik Park, Seungyong Lee</p><p>We propose LaplacianFusion, a novel approach that reconstructs detailed and
controllable 3D clothed-human body shapes from an input depth or 3D point cloud
sequence. The key idea of our approach is to use Laplacian coordinates,
well-known differential coordinates that have been used for mesh editing, for
representing the local structures contained in the input scans, instead of
implicit 3D functions or vertex displacements used previously. Our approach
reconstructs a controllable base mesh using SMPL, and learns a surface function
that predicts Laplacian coordinates representing surface details on the base
mesh. For a given pose, we first build and subdivide a base mesh, which is a
deformed SMPL template, and then estimate Laplacian coordinates for the mesh
vertices using the surface function. The final reconstruction for the pose is
obtained by integrating the estimated Laplacian coordinates as a whole.
Experimental results show that our approach based on Laplacian coordinates
successfully reconstructs more visually pleasing shape details than previous
methods. The approach also enables various surface detail manipulations, such
as detail transfer and enhancement.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyomin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Nam_H/0/1/0/all/0/1">Hyeonseo Nam</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jungeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jaesik Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seungyong Lee</a></p><p>We propose LaplacianFusion, a novel approach that reconstructs detailed and
controllable 3D clothed-human body shapes from an input depth or 3D point cloud
sequence. The key idea of our approach is to use Laplacian coordinates,
well-known differential coordinates that have been used for mesh editing, for
representing the local structures contained in the input scans, instead of
implicit 3D functions or vertex displacements used previously. Our approach
reconstructs a controllable base mesh using SMPL, and learns a surface function
that predicts Laplacian coordinates representing surface details on the base
mesh. For a given pose, we first build and subdivide a base mesh, which is a
deformed SMPL template, and then estimate Laplacian coordinates for the mesh
vertices using the surface function. The final reconstruction for the pose is
obtained by integrating the estimated Laplacian coordinates as a whole.
Experimental results show that our approach based on Laplacian coordinates
successfully reconstructs more visually pleasing shape details than previous
methods. The approach also enables various surface detail manipulations, such
as detail transfer and enhancement.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14721'>On the geometric thickness of 2-degenerate graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rahul Jain, Marco Ricci, Jonathan Rollin, Andr&#xe9; Schulz</p><p>A graph is 2-degenerate if every subgraph contains a vertex of degree at most
2. We show that every 2-degenerate graph can be drawn with straight lines such
that the drawing decomposes into 4 plane forests. Therefore, the geometric
arboricity, and hence the geometric thickness, of 2-degenerate graphs is at
most 4. On the other hand, we show that there are 2-degenerate graphs that do
not admit any straight-line drawing with a decomposition of the edge set into 2
plane graphs. That is, there are 2-degenerate graphs with geometric thickness,
and hence geometric arboricity, at least 3. This answers two questions posed by
Eppstein [Separating thickness from geometric thickness. In Towards a Theory of
Geometric Graphs, vol. 342 of Contemp. Math., AMS, 2004].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Jain_R/0/1/0/all/0/1">Rahul Jain</a>, <a href="http://arxiv.org/find/math/1/au:+Ricci_M/0/1/0/all/0/1">Marco Ricci</a>, <a href="http://arxiv.org/find/math/1/au:+Rollin_J/0/1/0/all/0/1">Jonathan Rollin</a>, <a href="http://arxiv.org/find/math/1/au:+Schulz_A/0/1/0/all/0/1">Andr&#xe9; Schulz</a></p><p>A graph is 2-degenerate if every subgraph contains a vertex of degree at most
2. We show that every 2-degenerate graph can be drawn with straight lines such
that the drawing decomposes into 4 plane forests. Therefore, the geometric
arboricity, and hence the geometric thickness, of 2-degenerate graphs is at
most 4. On the other hand, we show that there are 2-degenerate graphs that do
not admit any straight-line drawing with a decomposition of the edge set into 2
plane graphs. That is, there are 2-degenerate graphs with geometric thickness,
and hence geometric arboricity, at least 3. This answers two questions posed by
Eppstein [Separating thickness from geometric thickness. In Towards a Theory of
Geometric Graphs, vol. 342 of Contemp. Math., AMS, 2004].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14066'>Query-optimal estimation of unitary channels in diamond distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jeongwan Haah, Robin Kothari, Ryan O&#x27;Donnell, Ewin Tang</p><p>We consider process tomography for unitary quantum channels. Given access to
an unknown unitary channel acting on a $\textsf{d}$-dimensional qudit, we aim
to output a classical description of a unitary that is $\varepsilon$-close to
the unknown unitary in diamond norm. We design an algorithm achieving error
$\varepsilon$ using $O(\textsf{d}^2/\varepsilon)$ applications of the unknown
channel and only one qudit. This improves over prior results, which use
$O(\textsf{d}^3/\varepsilon^2)$ [via standard process tomography] or
$O(\textsf{d}^{2.5}/\varepsilon)$ [Yang, Renner, and Chiribella, PRL 2020]
applications. To show this result, we introduce a simple technique to
"bootstrap" an algorithm that can produce constant-error estimates to one that
can produce $\varepsilon$-error estimates with the Heisenberg scaling. Finally,
we prove a complementary lower bound showing that estimation requires
$\Omega(\textsf{d}^2/\varepsilon)$ applications, even with access to the
inverse or controlled versions of the unknown unitary. This shows that our
algorithm has both optimal query complexity and optimal space complexity.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Haah_J/0/1/0/all/0/1">Jeongwan Haah</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kothari_R/0/1/0/all/0/1">Robin Kothari</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+ODonnell_R/0/1/0/all/0/1">Ryan O&#x27;Donnell</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tang_E/0/1/0/all/0/1">Ewin Tang</a></p><p>We consider process tomography for unitary quantum channels. Given access to
an unknown unitary channel acting on a $\textsf{d}$-dimensional qudit, we aim
to output a classical description of a unitary that is $\varepsilon$-close to
the unknown unitary in diamond norm. We design an algorithm achieving error
$\varepsilon$ using $O(\textsf{d}^2/\varepsilon)$ applications of the unknown
channel and only one qudit. This improves over prior results, which use
$O(\textsf{d}^3/\varepsilon^2)$ [via standard process tomography] or
$O(\textsf{d}^{2.5}/\varepsilon)$ [Yang, Renner, and Chiribella, PRL 2020]
applications. To show this result, we introduce a simple technique to
"bootstrap" an algorithm that can produce constant-error estimates to one that
can produce $\varepsilon$-error estimates with the Heisenberg scaling. Finally,
we prove a complementary lower bound showing that estimation requires
$\Omega(\textsf{d}^2/\varepsilon)$ applications, even with access to the
inverse or controlled versions of the unknown unitary. This shows that our
algorithm has both optimal query complexity and optimal space complexity.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14099'>On Differentially Private Online Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haim Kaplan, Yishay Mansour, Shay Moran, Kobbi Nissim, Uri Stemmer</p><p>In this work we introduce an interactive variant of joint differential
privacy towards handling online processes in which existing privacy definitions
seem too restrictive. We study basic properties of this definition and
demonstrate that it satisfies (suitable variants) of group privacy,
composition, and post processing. We then study the cost of interactive joint
privacy in the basic setting of online classification. We show that any
(possibly non-private) learning rule can be effectively transformed to a
private learning rule with only a polynomial overhead in the mistake bound.
This demonstrates a stark difference with more restrictive notions of privacy
such as the one studied by Golowich and Livni (2021), where only a double
exponential overhead on the mistake bound is known (via an information
theoretic upper bound).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kaplan_H/0/1/0/all/0/1">Haim Kaplan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1">Yishay Mansour</a>, <a href="http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1">Shay Moran</a>, <a href="http://arxiv.org/find/cs/1/au:+Nissim_K/0/1/0/all/0/1">Kobbi Nissim</a>, <a href="http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1">Uri Stemmer</a></p><p>In this work we introduce an interactive variant of joint differential
privacy towards handling online processes in which existing privacy definitions
seem too restrictive. We study basic properties of this definition and
demonstrate that it satisfies (suitable variants) of group privacy,
composition, and post processing. We then study the cost of interactive joint
privacy in the basic setting of online classification. We show that any
(possibly non-private) learning rule can be effectively transformed to a
private learning rule with only a polynomial overhead in the mistake bound.
This demonstrates a stark difference with more restrictive notions of privacy
such as the one studied by Golowich and Livni (2021), where only a double
exponential overhead on the mistake bound is known (via an information
theoretic upper bound).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14128'>Tight Algorithms for Connectivity Problems Parameterized by Modular-Treewidth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Falko Hegerfeld, Stefan Kratsch</p><p>We study connectivity problems from a fine-grained parameterized perspective.
Cygan et al. (TALG 2022) obtained algorithms with single-exponential running
time $\alpha^{tw} n^{O(1)}$ for connectivity problems parameterized by
treewidth ($tw$) by introducing the cut-and-count-technique, which reduces
connectivity problems to locally checkable counting problems. In addition, the
bases $\alpha$ were proven to be optimal assuming the Strong Exponential-Time
Hypothesis (SETH).
</p>
<p>As only sparse graphs may admit small treewidth, these results do not apply
to graphs with dense structure. A well-known tool to capture dense structure is
the modular decomposition, which recursively partitions the graph into modules
whose members have the same neighborhood outside of the module. Contracting the
modules yields a quotient graph describing the adjacencies between modules.
Measuring the treewidth of the quotient graph yields the parameter
modular-treewidth, a natural intermediate step between treewidth and
clique-width.
</p>
<p>We obtain the first tight running times for connectivity problems
parameterized by modular-treewidth. For some problems the obtained bounds are
the same as relative to treewidth, showing that we can deal with a greater
generality in input structure at no cost in complexity. We obtain the following
randomized algorithms for graphs of modular-treewidth $k$, given an appropriate
decomposition: Steiner Tree can be solved in time $3^k n^{O(1)}$, Connected
Dominating Set can be solved in time $4^k n^{O(1)}$, Connected Vertex Cover can
be solved in time $5^k n^{O(1)}$, Feedback Vertex Set can be solved in time
$5^k n^{O(1)}$.
</p>
<p>The first two algorithms are tight due to known results and the last two
algorithms are complemented by new tight lower bounds under SETH.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hegerfeld_F/0/1/0/all/0/1">Falko Hegerfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Kratsch_S/0/1/0/all/0/1">Stefan Kratsch</a></p><p>We study connectivity problems from a fine-grained parameterized perspective.
Cygan et al. (TALG 2022) obtained algorithms with single-exponential running
time $\alpha^{tw} n^{O(1)}$ for connectivity problems parameterized by
treewidth ($tw$) by introducing the cut-and-count-technique, which reduces
connectivity problems to locally checkable counting problems. In addition, the
bases $\alpha$ were proven to be optimal assuming the Strong Exponential-Time
Hypothesis (SETH).
</p>
<p>As only sparse graphs may admit small treewidth, these results do not apply
to graphs with dense structure. A well-known tool to capture dense structure is
the modular decomposition, which recursively partitions the graph into modules
whose members have the same neighborhood outside of the module. Contracting the
modules yields a quotient graph describing the adjacencies between modules.
Measuring the treewidth of the quotient graph yields the parameter
modular-treewidth, a natural intermediate step between treewidth and
clique-width.
</p>
<p>We obtain the first tight running times for connectivity problems
parameterized by modular-treewidth. For some problems the obtained bounds are
the same as relative to treewidth, showing that we can deal with a greater
generality in input structure at no cost in complexity. We obtain the following
randomized algorithms for graphs of modular-treewidth $k$, given an appropriate
decomposition: Steiner Tree can be solved in time $3^k n^{O(1)}$, Connected
Dominating Set can be solved in time $4^k n^{O(1)}$, Connected Vertex Cover can
be solved in time $5^k n^{O(1)}$, Feedback Vertex Set can be solved in time
$5^k n^{O(1)}$.
</p>
<p>The first two algorithms are tight due to known results and the last two
algorithms are complemented by new tight lower bounds under SETH.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14168'>Signal Propagation in Double Edged Relays</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam Boucher</p><p>A discrete signal propagation model blending characteristics of linear wave
propagation and finite state automata is developed. We show this model obeys a
limited form of superposition and is capable of displaying a wide variety of
interesting behaviors. We show how the model's superposition properties permit
information to be encoded and retained by signals that pass through discrete
networks. We outline a SPIDER model replacement for Dijkstra's algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Boucher_A/0/1/0/all/0/1">Adam Boucher</a></p><p>A discrete signal propagation model blending characteristics of linear wave
propagation and finite state automata is developed. We show this model obeys a
limited form of superposition and is capable of displaying a wide variety of
interesting behaviors. We show how the model's superposition properties permit
information to be encoded and retained by signals that pass through discrete
networks. We outline a SPIDER model replacement for Dijkstra's algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14324'>A CS guide to the quantum singular value transformation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ewin Tang, Kevin Tian</p><p>We present a simplified exposition of some pieces of [Gily\'en, Su, Low, and
Wiebe, STOC'19, arXiv:1806.01838], who introduced a quantum singular value
transformation (QSVT) framework for applying polynomial functions to
block-encoded matrices. The QSVT framework has garnered substantial recent
interest from the quantum algorithms community, as it was demonstrated by
[GSLW19] to encapsulate many existing algorithms naturally phrased as an
application of a matrix function. First, we posit that the lifting of quantum
singular processing (QSP) to QSVT is better viewed not through Jordan's lemma
(as was suggested by [GSLW19]) but as an application of the cosine-sine
decomposition, which can be thought of as a more explicit and stronger version
of Jordan's lemma. Second, we demonstrate that the constructions of bounded
polynomial approximations given in [GSLW19], which use a variety of ad hoc
approaches drawing from Fourier analysis, Chebyshev series, and Taylor series,
can be unified under the framework of truncation of Chebyshev series, and
indeed, can in large part be matched via a bounded variant of a standard
meta-theorem from [Trefethen, 2013]. We hope this work finds use to the
community as a companion guide for understanding and applying the powerful
framework of [GSLW19].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Tang_E/0/1/0/all/0/1">Ewin Tang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tian_K/0/1/0/all/0/1">Kevin Tian</a></p><p>We present a simplified exposition of some pieces of [Gily\'en, Su, Low, and
Wiebe, STOC'19, <a href="/abs/1806.01838">arXiv:1806.01838</a>], who introduced a quantum singular value
transformation (QSVT) framework for applying polynomial functions to
block-encoded matrices. The QSVT framework has garnered substantial recent
interest from the quantum algorithms community, as it was demonstrated by
[GSLW19] to encapsulate many existing algorithms naturally phrased as an
application of a matrix function. First, we posit that the lifting of quantum
singular processing (QSP) to QSVT is better viewed not through Jordan's lemma
(as was suggested by [GSLW19]) but as an application of the cosine-sine
decomposition, which can be thought of as a more explicit and stronger version
of Jordan's lemma. Second, we demonstrate that the constructions of bounded
polynomial approximations given in [GSLW19], which use a variety of ad hoc
approaches drawing from Fourier analysis, Chebyshev series, and Taylor series,
can be unified under the framework of truncation of Chebyshev series, and
indeed, can in large part be matched via a bounded variant of a standard
meta-theorem from [Trefethen, 2013]. We hope this work finds use to the
community as a companion guide for understanding and applying the powerful
framework of [GSLW19].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14386'>Practical Algorithms for Orientations of Partially Directed Graphical Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Malte Luttermann, Marcel Wien&#xf6;bst, Maciej Li&#x15b;kiewicz</p><p>In observational studies, the true causal model is typically unknown and
needs to be estimated from available observational and limited experimental
data. In such cases, the learned causal model is commonly represented as a
partially directed acyclic graph (PDAG), which contains both directed and
undirected edges indicating uncertainty of causal relations between random
variables. The main focus of this paper is on the maximal orientation task,
which, for a given PDAG, aims to orient the undirected edges maximally such
that the resulting graph represents the same Markov equivalent DAGs as the
input PDAG. This task is a subroutine used frequently in causal discovery, e.
g., as the final step of the celebrated PC algorithm. Utilizing connections to
the problem of finding a consistent DAG extension of a PDAG, we derive faster
algorithms for computing the maximal orientation by proposing two novel
approaches for extending PDAGs, both constructed with an emphasis on simplicity
and practical effectiveness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Luttermann_M/0/1/0/all/0/1">Malte Luttermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Wienobst_M/0/1/0/all/0/1">Marcel Wien&#xf6;bst</a>, <a href="http://arxiv.org/find/cs/1/au:+Liskiewicz_M/0/1/0/all/0/1">Maciej Li&#x15b;kiewicz</a></p><p>In observational studies, the true causal model is typically unknown and
needs to be estimated from available observational and limited experimental
data. In such cases, the learned causal model is commonly represented as a
partially directed acyclic graph (PDAG), which contains both directed and
undirected edges indicating uncertainty of causal relations between random
variables. The main focus of this paper is on the maximal orientation task,
which, for a given PDAG, aims to orient the undirected edges maximally such
that the resulting graph represents the same Markov equivalent DAGs as the
input PDAG. This task is a subroutine used frequently in causal discovery, e.
g., as the final step of the celebrated PC algorithm. Utilizing connections to
the problem of finding a consistent DAG extension of a PDAG, we derive faster
algorithms for computing the maximal orientation by proposing two novel
approaches for extending PDAGs, both constructed with an emphasis on simplicity
and practical effectiveness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14421'>Publicly verifiable delegative democracy with secret voting power</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dimitrios Karoukis</p><p>We use a commitment scheme to track every individual's voting power on a
public ledger with the ability to validate transfers and transitive, reversible
delegations of it between them without sacrificing their privacy. Every unit of
voting power is represented by the Merkle root of a tree consisting of its
latest owner's public key, a random nonce and the Merkle root of the tree of
its previous owner's public key and random nonce and so on. Transfers and
delegations mention the input units, their owner's public keys, the hashes of
their nonces and the output units, which are the Merkle roots of the new
owners' public keys, new random nonces and the previous units' identifiers. In
case of a delegation, the receiver provides the sender with the hashed random
nonces and the hashed public keys whose secret keys they control. In case of a
transfer, only the hashes of these hashes' concatenations are provided. To
reverse a delegation, a historical owner reveals the individual hashes that
resulted the subsequent units. In voting, the owner reveals the actual nonces
and public keys of the units.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Karoukis_D/0/1/0/all/0/1">Dimitrios Karoukis</a></p><p>We use a commitment scheme to track every individual's voting power on a
public ledger with the ability to validate transfers and transitive, reversible
delegations of it between them without sacrificing their privacy. Every unit of
voting power is represented by the Merkle root of a tree consisting of its
latest owner's public key, a random nonce and the Merkle root of the tree of
its previous owner's public key and random nonce and so on. Transfers and
delegations mention the input units, their owner's public keys, the hashes of
their nonces and the output units, which are the Merkle roots of the new
owners' public keys, new random nonces and the previous units' identifiers. In
case of a delegation, the receiver provides the sender with the hashed random
nonces and the hashed public keys whose secret keys they control. In case of a
transfer, only the hashes of these hashes' concatenations are provided. To
reverse a delegation, a historical owner reveals the individual hashes that
resulted the subsequent units. In voting, the owner reveals the actual nonces
and public keys of the units.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14692'>Massively Parallel Computation in a Heterogeneous Regime</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Orr Fischer, Adi Horowitz, Rotem Oshman</p><p>Massively-parallel graph algorithms have received extensive attention over
the past decade, with research focusing on three memory regimes: the
superlinear regime, the near-linear regime, and the sublinear regime. The
sublinear regime is the most desirable in practice, but conditional hardness
results point towards its limitations.
</p>
<p>In this work we study a \emph{heterogeneous} model, where the memory of the
machines varies in size. We focus mostly on the heterogeneous setting created
by adding a single near-linear machine to the sublinear MPC regime, and show
that even a single large machine suffices to circumvent most of the conditional
hardness results for the sublinear regime: for graphs with $n$ vertices and $m$
edges, we give (a) an MST algorithm that runs in $O(\log\log(m/n))$ rounds; (b)
an algorithm that constructs an $O(k)$-spanner of size $O(n^{1+1/k})$ in $O(1)$
rounds; and (c) a maximal-matching algorithm that runs in
$O(\sqrt{\log(m/n)}\log\log(m/n))$ rounds.
</p>
<p>We also observe that the best known near-linear MPC algorithms for several
other graph problems which are conjectured to be hard in the sublinear regime
(minimum cut, maximal independent set, and vertex coloring) can easily be
transformed to work in the heterogeneous MPC model with a single near-linear
machine, while retaining their original round complexity in the near-linear
regime. If the large machine is allowed to have \emph{superlinear} memory, all
of the problems above can be solved in $O(1)$ rounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fischer_O/0/1/0/all/0/1">Orr Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Horowitz_A/0/1/0/all/0/1">Adi Horowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Oshman_R/0/1/0/all/0/1">Rotem Oshman</a></p><p>Massively-parallel graph algorithms have received extensive attention over
the past decade, with research focusing on three memory regimes: the
superlinear regime, the near-linear regime, and the sublinear regime. The
sublinear regime is the most desirable in practice, but conditional hardness
results point towards its limitations.
</p>
<p>In this work we study a \emph{heterogeneous} model, where the memory of the
machines varies in size. We focus mostly on the heterogeneous setting created
by adding a single near-linear machine to the sublinear MPC regime, and show
that even a single large machine suffices to circumvent most of the conditional
hardness results for the sublinear regime: for graphs with $n$ vertices and $m$
edges, we give (a) an MST algorithm that runs in $O(\log\log(m/n))$ rounds; (b)
an algorithm that constructs an $O(k)$-spanner of size $O(n^{1+1/k})$ in $O(1)$
rounds; and (c) a maximal-matching algorithm that runs in
$O(\sqrt{\log(m/n)}\log\log(m/n))$ rounds.
</p>
<p>We also observe that the best known near-linear MPC algorithms for several
other graph problems which are conjectured to be hard in the sublinear regime
(minimum cut, maximal independent set, and vertex coloring) can easily be
transformed to work in the heterogeneous MPC model with a single near-linear
machine, while retaining their original round complexity in the near-linear
regime. If the large machine is allowed to have \emph{superlinear} memory, all
of the problems above can be solved in $O(1)$ rounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14698'>Heuristic Modularity Maximization Algorithms for Community Detection Rarely Return an Optimal Partition or Anything Similar</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samin Aref, Mahdi Mostajabdaveh, Hriday Chheda</p><p>Community detection is a classic problem in network science with extensive
applications in various fields. The most commonly used methods are the
algorithms designed to maximize modularity over different partitions of the
network nodes into communities. Using 80 real and random networks from a wide
range of contexts, we investigate the extent to which current heuristic
modularity maximization algorithms succeed in returning modularity-maximum
(optimal) partitions. We evaluate (1) the ratio of their output modularity to
the maximum modularity for each input graph and (2) the maximum similarity
between their output partition and any optimal partition of that graph. Our
computational experiments involve eight existing heuristic algorithms which we
compare against an exact integer programming method that globally maximizes
modularity. The average modularity-based heuristic algorithm returns optimal
partitions for only 16.9% of the 80 graphs considered. Results on adjusted
mutual information show considerable dissimilarity between the sub-optimal
partitions and any optimal partitions of the graphs in our experiments. More
importantly, our results show that near-optimal partitions tend to be
disproportionally dissimilar to any optimal partition. Taken together, our
analysis points to a crucial limitation of commonly used modularity-based
algorithms for discovering communities: they rarely return an optimal partition
or a partition resembling an optimal partition. Given this finding, developing
an exact or approximate algorithm for modularity maximization is recommendable
for a more methodologically sound usage of modularity in community detection.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aref_S/0/1/0/all/0/1">Samin Aref</a>, <a href="http://arxiv.org/find/cs/1/au:+Mostajabdaveh_M/0/1/0/all/0/1">Mahdi Mostajabdaveh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chheda_H/0/1/0/all/0/1">Hriday Chheda</a></p><p>Community detection is a classic problem in network science with extensive
applications in various fields. The most commonly used methods are the
algorithms designed to maximize modularity over different partitions of the
network nodes into communities. Using 80 real and random networks from a wide
range of contexts, we investigate the extent to which current heuristic
modularity maximization algorithms succeed in returning modularity-maximum
(optimal) partitions. We evaluate (1) the ratio of their output modularity to
the maximum modularity for each input graph and (2) the maximum similarity
between their output partition and any optimal partition of that graph. Our
computational experiments involve eight existing heuristic algorithms which we
compare against an exact integer programming method that globally maximizes
modularity. The average modularity-based heuristic algorithm returns optimal
partitions for only 16.9% of the 80 graphs considered. Results on adjusted
mutual information show considerable dissimilarity between the sub-optimal
partitions and any optimal partitions of the graphs in our experiments. More
importantly, our results show that near-optimal partitions tend to be
disproportionally dissimilar to any optimal partition. Taken together, our
analysis points to a crucial limitation of commonly used modularity-based
algorithms for discovering communities: they rarely return an optimal partition
or a partition resembling an optimal partition. Given this finding, developing
an exact or approximate algorithm for modularity maximization is recommendable
for a more methodologically sound usage of modularity in community detection.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.14725'>Parameterized Complexity of Vertex Splitting to Pathwidth at most 1</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jakob Baumann, Matthias Pfretzschner, Ignaz Rutter</p><p>Motivated by the planarization of 2-layered straight-line drawings, we
consider the problem of modifying a graph such that the resulting graph has
pathwidth at most 1. The problem Pathwidth-One Vertex Explosion (POVE) asks
whether such a graph can be obtained using at most $k$ vertex explosions, where
a vertex explosion replaces a vertex $v$ by deg$(v)$ degree-1 vertices, each
incident to exactly one edge that was originally incident to $v$. For POVE, we
give an FPT algorithm with running time $O(4^k \cdot m)$ and a quadratic
kernel, thereby improving over the $O(k^6)$-kernel by Ahmed et al. [GD 22] in a
more general setting. Similarly, a vertex split replaces a vertex $v$ by two
distinct vertices $v_1$ and $v_2$ and distributes the edges originally incident
to $v$ arbitrarily to $v_1$ and $v_2$. Analogously to POVE, we define the
problem variant Pathwidth-One Vertex Splitting (POVS) that uses the split
operation instead of vertex explosions. Here we obtain a linear kernel and an
algorithm with running time $O((6k+12)^k \cdot m)$. This answers an open
question by Ahmed et al. [GD22].
</p>
<p>Finally, we consider the problem $\Pi$ Vertex Splitting ($\Pi$-VS), which
generalizes the problem POVS and asks whether a given graph can be turned into
a graph of a specific graph class $\Pi$ using at most $k$ vertex splits. For
graph classes $\Pi$ that can be tested in monadic second-order graph logic
(MSO$_2$), we show that the problem $\Pi$-VS can be expressed as an MSO$_2$
formula, resulting in an FPT algorithm for $\Pi$-VS parameterized by $k$ if
$\Pi$ additionally has bounded treewidth. We obtain the same result for the
problem variant using vertex explosions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Baumann_J/0/1/0/all/0/1">Jakob Baumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfretzschner_M/0/1/0/all/0/1">Matthias Pfretzschner</a>, <a href="http://arxiv.org/find/cs/1/au:+Rutter_I/0/1/0/all/0/1">Ignaz Rutter</a></p><p>Motivated by the planarization of 2-layered straight-line drawings, we
consider the problem of modifying a graph such that the resulting graph has
pathwidth at most 1. The problem Pathwidth-One Vertex Explosion (POVE) asks
whether such a graph can be obtained using at most $k$ vertex explosions, where
a vertex explosion replaces a vertex $v$ by deg$(v)$ degree-1 vertices, each
incident to exactly one edge that was originally incident to $v$. For POVE, we
give an FPT algorithm with running time $O(4^k \cdot m)$ and a quadratic
kernel, thereby improving over the $O(k^6)$-kernel by Ahmed et al. [GD 22] in a
more general setting. Similarly, a vertex split replaces a vertex $v$ by two
distinct vertices $v_1$ and $v_2$ and distributes the edges originally incident
to $v$ arbitrarily to $v_1$ and $v_2$. Analogously to POVE, we define the
problem variant Pathwidth-One Vertex Splitting (POVS) that uses the split
operation instead of vertex explosions. Here we obtain a linear kernel and an
algorithm with running time $O((6k+12)^k \cdot m)$. This answers an open
question by Ahmed et al. [GD22].
</p>
<p>Finally, we consider the problem $\Pi$ Vertex Splitting ($\Pi$-VS), which
generalizes the problem POVS and asks whether a given graph can be turned into
a graph of a specific graph class $\Pi$ using at most $k$ vertex splits. For
graph classes $\Pi$ that can be tested in monadic second-order graph logic
(MSO$_2$), we show that the problem $\Pi$-VS can be expressed as an MSO$_2$
formula, resulting in an FPT algorithm for $\Pi$-VS parameterized by $k$ if
$\Pi$ additionally has bounded treewidth. We obtain the same result for the
problem variant using vertex explosions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-01T01:30:00Z">Wednesday, March 01 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, February 28
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/02/28/linkage-200k-edits.html'>Linkage for 200,000 edits to Wikipedia</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government (\(\mathbb{M}\)), including guidelines for equitable use of AI and automated systems through a new Blueprint for an AI Bill of Rights (that is, rights for people to be protected against unfair uses of AI, not rights for artificial intelligences).
        
        </div>

        <div class='tr-article-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/02/16/executive-order-on-further-advancing-racial-equity-and-support-for-underserved-communities-through-the-federal-government/">Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@sorelle@mastodon.social/109875326202971711">\(\mathbb{M}\)</a>),</span> including guidelines for equitable use of AI and automated systems through a new <a href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/">Blueprint for an AI Bill of Rights</a> (that is, rights for people to be protected against unfair uses of AI, not rights for artificial intelligences).</p>
  </li>
  <li>
    <p><a href="https://press.princeton.edu/ideas/why-prove-it">Why prove it?</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@highergeometer/109854745668334423">\(\mathbb{M}\)</a>,</span> <a href="https://www.math.columbia.edu/~woit/wordpress/?p=13288">via</a>). John Stillwell on human-written vs machine-checkable proofs, with reference to the abc conjecture.</p>
  </li>
  <li>
    <p><a href="https://www.ics.uci.edu/~eppstein/pix/ltcc/index.html">Low tide at Crystal Cove State Park</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109894403539276698">\(\mathbb{M}\)</a>).</span></p>

    <p style="text-align:center"><img src="https://www.ics.uci.edu/~eppstein/pix/ltcc/Seagrass2-m.jpg" alt="Low tide at Crystal Cove State Park, California" style="border-style:solid;border-color:black" /></p>
  </li>
  <li>
    <p>Another newly promoted Wikipedia Good Article: <a href="https://en.wikipedia.org/wiki/Polygonalization">Polygonalization</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109906715996859674">\(\mathbb{M}\)</a>),</span> about finding a polygon that uses all of a given set of points as vertices. The usual definitions allow it to go straight through some of the vertices, rather than always turning, though, and the illustration below shows why: for some point sets, including 3x3 grids, a polygon that turns everywhere might not exist.</p>

    <p style="text-align:center"><img src="/blog/assets/2023/3x3_grid_polygonalizations.svg" alt="Eight ways of polygonalizing a 3x3 grid" /></p>
  </li>
  <li>
    <p><a href="https://terrytao.wordpress.com/2023/02/18/would-it-be-possible-to-create-a-tool-to-automatically-diagram-papers/">Would it be possible to create a tool to automatically diagram papers?</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@tao/109887019658810502">\(\mathbb{M}\)</a>),</span> by Terry Tao, inspired by the diagrams the proof-assistant people have been using to guide their work.</p>
  </li>
  <li>
    <p>People who indulge in the fringe belief in the reality of certain folklore beasts are sad that <a href="https://boingboing.net/2023/02/22/the-cryptid-complications-of-wikipedias-editing-policies.html">Wikipedia now focuses on the folklore of these beasts without going into much detail about the fringe belief in their reality</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109918360457067075">\(\mathbb{M}\)</a>).</span> (Based on a both-sides-ist <em>Slate</em> article that I’m not going to link.)</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=MDhT6-6Yr_I">Origami actuators</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@logicalelegance@mastodon.online/109920746034435458">\(\mathbb{M}\)</a>),</span> for simple repetitive motions of origami models, by attaching flat-printed electromagnets to them.</p>
  </li>
  <li>
    <p>Gasarch writes: <a href="https://blog.computationalcomplexity.org/2023/02/it-is-more-important-than-ever-to-teach.html">It is more important than ever to teach your students probability (even non-stem students)</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109935523877122235">\(\mathbb{M}\)</a>).</span> Why: because your university may be making deals promoting online gambling to the same students, as the linked copy of a New York Times article details.</p>
  </li>
  <li>
    <p><a href="https://xtools.wmflabs.org/ec/en.wikipedia.org/David_Eppstein">Sometime in the last month (not exactly sure when) I passed the milestone of 200,000 edits (all non-automated) to Wikipedia</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109941265893054592">\(\mathbb{M}\)</a>).</span> That’s…a lot of edits. Although, as of earlier in the month when it was below 200,000, it only places me at 260 on the <a href="https://en.wikipedia.org/w/index.php?title=Wikipedia:List_of_Wikipedians_by_number_of_edits&amp;oldid=1138516223">list of all-time prolific editors</a>. And a couple of the top ten are now blocked, so it’s not exactly always a place of pride.</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2023/02/zai-divecha-phase-shift/">Mesmerizing paper sculptures and animations by Zai Divecha convey the subtlety of change</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@colossal@mastodon.art/109937307601608046">\(\mathbb{M}\)</a>,</span> <a href="https://zaidivecha.com/">see also</a>). Basically a 3d papercraft zoetrope.</p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T17:40:00Z">Tuesday, February 28 2023, 17:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.simons.berkeley.edu/2023/02/theory-at-the-institute-and-beyond-february-2023/'>Theory at the Institute and Beyond, February 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          by Venkatesan Guruswami (Simons Institute) This semester at the Simons Institute, the Meta-Complexity program is buzzing along with intense activity in the form of multiple reading groups and a weekly seminar, on top of the usual three workshops and boot &#8230; Continue reading &#8594;<p>By Simons Institute Editor</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          by Venkatesan Guruswami (Simons Institute) This semester at the Simons Institute, the Meta-Complexity program is buzzing along with intense activity in the form of multiple reading groups and a weekly seminar, on top of the usual three workshops and boot &#8230; <a href="https://blog.simons.berkeley.edu/2023/02/theory-at-the-institute-and-beyond-february-2023/">Continue reading <span class="meta-nav">&#8594;</span></a><p class="authors">By Simons Institute Editor</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T17:00:08Z">Tuesday, February 28 2023, 17:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/'>Alef’s Corner: Democracy (Israel, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Democracy in Hebrew is דמוקרטיה represented by the letter &#8220;dalet&#8221; ד  
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p></p>


<h2><img loading="lazy" data-attachment-id="23916" data-permalink="https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/dem1/" data-orig-file="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg" data-orig-size="684,701" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Dem1" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=293" data-large-file="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=640" class="alignnone size-full wp-image-23916" src="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg" alt="Dem1" width="684" height="701" srcset="https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg 684w, https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=146&amp;h=150 146w, https://gilkalai.files.wordpress.com/2023/02/dem1.jpeg?w=293&amp;h=300 293w" sizes="(max-width: 684px) 100vw, 684px" /><img loading="lazy" data-attachment-id="23918" data-permalink="https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/dem2/" data-orig-file="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg" data-orig-size="1000,1000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Dem2" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=640" class="alignnone size-full wp-image-23918" src="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg" alt="Dem2" width="1000" height="1000" srcset="https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg 1000w, https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=150&amp;h=150 150w, https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=300&amp;h=300 300w, https://gilkalai.files.wordpress.com/2023/02/dem2.jpeg?w=768&amp;h=768 768w" sizes="(max-width: 1000px) 100vw, 1000px" /></h2>
<h2>Democracy in Hebrew is דמוקרטיה represented by the letter &#8220;dalet&#8221; <strong><span style="color: #ff0000">ד</span></strong></h2>
<p> </p><p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T16:27:04Z">Tuesday, February 28 2023, 16:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12937'>Constraint Optimization over Semirings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: A. Pavan, Kuldeep S. Meel, N. V. Vinodchandran, Arnab Bhattacharyya</p><p>Interpretations of logical formulas over semirings have applications in
various areas of computer science including logic, AI, databases, and security.
Such interpretations provide richer information beyond the truth or falsity of
a statement. Examples of such semirings include Viterbi semiring, min-max or
access control semiring, tropical semiring, and fuzzy semiring.
</p>
<p>The present work investigates the complexity of constraint optimization
problems over semirings. The generic optimization problem we study is the
following: Given a propositional formula $\varphi$ over $n$ variable and a
semiring $(K,+,\cdot,0,1)$, find the maximum value over all possible
interpretations of $\varphi$ over $K$. This can be seen as a generalization of
the well-known satisfiability problem. A related problem is to find an
interpretation that achieves the maximum value. In this work, we first focus on
these optimization problems over the Viterbi semiring, which we call optConfVal
and optConf.
</p>
<p>We show that for general propositional formulas in negation normal form,
optConfVal and optConf are in ${\mathrm{FP}}^{\mathrm{NP}}$. We investigate
optConf when the input formula $\varphi$ is represented as a CNF. For CNF
formulae, we first derive an upper bound on optConfVal as a function of the
number of maximum satisfiable clauses. In particular, we show that if $r$ is
the maximum number of satisfiable clauses in a CNF formula with $m$ clauses,
then its optConfVal is at most $1/4^{m-r}$. Building on this we establish that
optConfVal for CNF formulae is hard for the complexity class
${\mathrm{FP}}^{\mathrm{NP}[\log]}$. We also design polynomial-time
approximation algorithms and establish an inapproximability for optConfVal. We
establish similar complexity results for these optimization problems over other
semirings including tropical, fuzzy, and access control semirings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pavan_A/0/1/0/all/0/1">A. Pavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Meel_K/0/1/0/all/0/1">Kuldeep S. Meel</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinodchandran_N/0/1/0/all/0/1">N. V. Vinodchandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_A/0/1/0/all/0/1">Arnab Bhattacharyya</a></p><p>Interpretations of logical formulas over semirings have applications in
various areas of computer science including logic, AI, databases, and security.
Such interpretations provide richer information beyond the truth or falsity of
a statement. Examples of such semirings include Viterbi semiring, min-max or
access control semiring, tropical semiring, and fuzzy semiring.
</p>
<p>The present work investigates the complexity of constraint optimization
problems over semirings. The generic optimization problem we study is the
following: Given a propositional formula $\varphi$ over $n$ variable and a
semiring $(K,+,\cdot,0,1)$, find the maximum value over all possible
interpretations of $\varphi$ over $K$. This can be seen as a generalization of
the well-known satisfiability problem. A related problem is to find an
interpretation that achieves the maximum value. In this work, we first focus on
these optimization problems over the Viterbi semiring, which we call optConfVal
and optConf.
</p>
<p>We show that for general propositional formulas in negation normal form,
optConfVal and optConf are in ${\mathrm{FP}}^{\mathrm{NP}}$. We investigate
optConf when the input formula $\varphi$ is represented as a CNF. For CNF
formulae, we first derive an upper bound on optConfVal as a function of the
number of maximum satisfiable clauses. In particular, we show that if $r$ is
the maximum number of satisfiable clauses in a CNF formula with $m$ clauses,
then its optConfVal is at most $1/4^{m-r}$. Building on this we establish that
optConfVal for CNF formulae is hard for the complexity class
${\mathrm{FP}}^{\mathrm{NP}[\log]}$. We also design polynomial-time
approximation algorithms and establish an inapproximability for optConfVal. We
establish similar complexity results for these optimization problems over other
semirings including tropical, fuzzy, and access control semirings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12940'>Exponential Hardness of Reinforcement Learning with Linear Function Approximation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Kane, Sihan Liu, Shachar Lovett, Gaurav Mahajan, Csaba Szepesv&#xe1;ri, Gell&#xe9;rt Weisz</p><p>A fundamental question in reinforcement learning theory is: suppose the
optimal value functions are linear in given features, can we learn them
efficiently? This problem's counterpart in supervised learning, linear
regression, can be solved both statistically and computationally efficiently.
Therefore, it was quite surprising when a recent work
\cite{kane2022computational} showed a computational-statistical gap for linear
reinforcement learning: even though there are polynomial sample-complexity
algorithms, unless NP = RP, there are no polynomial time algorithms for this
setting.
</p>
<p>In this work, we build on their result to show a computational lower bound,
which is exponential in feature dimension and horizon, for linear reinforcement
learning under the Randomized Exponential Time Hypothesis. To prove this we
build a round-based game where in each round the learner is searching for an
unknown vector in a unit hypercube. The rewards in this game are chosen such
that if the learner achieves large reward, then the learner's actions can be
used to simulate solving a variant of 3-SAT, where (a) each variable shows up
in a bounded number of clauses (b) if an instance has no solutions then it also
has no solutions that satisfy more than (1-$\epsilon$)-fraction of clauses. We
use standard reductions to show this 3-SAT variant is approximately as hard as
3-SAT. Finally, we also show a lower bound optimized for horizon dependence
that almost matches the best known upper bound of $\exp(\sqrt{H})$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1">Daniel Kane</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sihan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lovett_S/0/1/0/all/0/1">Shachar Lovett</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_G/0/1/0/all/0/1">Gaurav Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1">Csaba Szepesv&#xe1;ri</a>, <a href="http://arxiv.org/find/cs/1/au:+Weisz_G/0/1/0/all/0/1">Gell&#xe9;rt Weisz</a></p><p>A fundamental question in reinforcement learning theory is: suppose the
optimal value functions are linear in given features, can we learn them
efficiently? This problem's counterpart in supervised learning, linear
regression, can be solved both statistically and computationally efficiently.
Therefore, it was quite surprising when a recent work
\cite{kane2022computational} showed a computational-statistical gap for linear
reinforcement learning: even though there are polynomial sample-complexity
algorithms, unless NP = RP, there are no polynomial time algorithms for this
setting.
</p>
<p>In this work, we build on their result to show a computational lower bound,
which is exponential in feature dimension and horizon, for linear reinforcement
learning under the Randomized Exponential Time Hypothesis. To prove this we
build a round-based game where in each round the learner is searching for an
unknown vector in a unit hypercube. The rewards in this game are chosen such
that if the learner achieves large reward, then the learner's actions can be
used to simulate solving a variant of 3-SAT, where (a) each variable shows up
in a bounded number of clauses (b) if an instance has no solutions then it also
has no solutions that satisfy more than (1-$\epsilon$)-fraction of clauses. We
use standard reductions to show this 3-SAT variant is approximately as hard as
3-SAT. Finally, we also show a lower bound optimized for horizon dependence
that almost matches the best known upper bound of $\exp(\sqrt{H})$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12953'>Optimization Problems on The Weighted Massively Parallel Computation Model: Hardness and Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hengzhao Ma, Jianzhong Li, Xiangyu Gao</p><p>The topology-aware Massively Parallel Computation (MPC) model is proposed and
studied recently, which enhances the classical MPC model by the awareness of
network topology. The work of Hu et. al. on topology-aware MPC model considers
only the tree topology. In this paper a more general case is considered, where
the underlying network is a weighted complete graph. We then call this model as
Weighted Massively Parallel Computation (WMPC) model, and study the problem of
minimizing communication cost under it. Three communication cost minimization
problems are defined based on different pattern of communication, which are the
Data Redistribution Problem, Data Allocation Problem on Continuous data, and
Data Allocation Problem on Categorized data. We also define four kinds of
objective functions for communication cost, which consider the total cost,
bottleneck cost, maximum of send and receive cost, and summation of send and
receive cost, respectively. Combining the three problems in different
communication pattern with the four kinds of objective cost functions, 12
problems are obtained. The hardness results and algorithms of the 12 problems
make up the content of this paper. With rigorous proof, we prove that some of
the 12 problems are in P, some FPT, some NP-complete, and some W[1]-complete.
Approximate algorithms are proposed for several selected problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Hengzhao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianzhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiangyu Gao</a></p><p>The topology-aware Massively Parallel Computation (MPC) model is proposed and
studied recently, which enhances the classical MPC model by the awareness of
network topology. The work of Hu et. al. on topology-aware MPC model considers
only the tree topology. In this paper a more general case is considered, where
the underlying network is a weighted complete graph. We then call this model as
Weighted Massively Parallel Computation (WMPC) model, and study the problem of
minimizing communication cost under it. Three communication cost minimization
problems are defined based on different pattern of communication, which are the
Data Redistribution Problem, Data Allocation Problem on Continuous data, and
Data Allocation Problem on Categorized data. We also define four kinds of
objective functions for communication cost, which consider the total cost,
bottleneck cost, maximum of send and receive cost, and summation of send and
receive cost, respectively. Combining the three problems in different
communication pattern with the four kinds of objective cost functions, 12
problems are obtained. The hardness results and algorithms of the 12 problems
make up the content of this paper. With rigorous proof, we prove that some of
the 12 problems are in P, some FPT, some NP-complete, and some W[1]-complete.
Approximate algorithms are proposed for several selected problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13031'>Cosecure Domination: Hardness Results and Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kusum, Arti Pandey</p><p>For a simple graph $G=(V,E)$ without any isolated vertex, a cosecure
dominating set $D$ of $G$ satisfies the following two properties (i) $S$ is a
dominating set of $G$, (ii) for every vertex $v \in S$ there exists a vertex $u
\in V \setminus S$ such that $uv \in E$ and $(S \setminus \{v\}) \cup \{u\}$ is
a dominating set of $G$. The minimum cardinality of a cosecure dominating set
of $G$ is called cosecure domination number of $G$ and is denoted by
$\gamma_{cs}(G)$. The Minimum Cosecure Domination problem is to find a cosecure
dominating set of a graph $G$ of cardinality $\gamma_{cs}(G)$. The decision
version of the problem is known to be NP-complete for bipartite, planar, and
split graphs. Also, it is known that the Minimum Cosecure Domination problem is
efficiently solvable for proper interval graphs and cographs.
</p>
<p>In this paper, we work on various important graph classes in an effort to
reduce the complexity gap of the Minimum Cosecure Domination problem. We show
that the decision version of the problem remains NP-complete for circle graphs,
doubly chordal graphs, chordal bipartite graphs, star-convex bipartite graphs
and comb-convex bipartite graphs. On the positive side, we give an efficient
algorithm to compute the cosecure domination number of chain graphs, which is
an important subclass of bipartite graphs. In addition, we show that the
problem is linear-time solvable for bounded tree-width graphs. Further, we
prove that the computational complexity of this problem varies from the
domination problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kusum/0/1/0/all/0/1">Kusum</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Arti Pandey</a></p><p>For a simple graph $G=(V,E)$ without any isolated vertex, a cosecure
dominating set $D$ of $G$ satisfies the following two properties (i) $S$ is a
dominating set of $G$, (ii) for every vertex $v \in S$ there exists a vertex $u
\in V \setminus S$ such that $uv \in E$ and $(S \setminus \{v\}) \cup \{u\}$ is
a dominating set of $G$. The minimum cardinality of a cosecure dominating set
of $G$ is called cosecure domination number of $G$ and is denoted by
$\gamma_{cs}(G)$. The Minimum Cosecure Domination problem is to find a cosecure
dominating set of a graph $G$ of cardinality $\gamma_{cs}(G)$. The decision
version of the problem is known to be NP-complete for bipartite, planar, and
split graphs. Also, it is known that the Minimum Cosecure Domination problem is
efficiently solvable for proper interval graphs and cographs.
</p>
<p>In this paper, we work on various important graph classes in an effort to
reduce the complexity gap of the Minimum Cosecure Domination problem. We show
that the decision version of the problem remains NP-complete for circle graphs,
doubly chordal graphs, chordal bipartite graphs, star-convex bipartite graphs
and comb-convex bipartite graphs. On the positive side, we give an efficient
algorithm to compute the cosecure domination number of chain graphs, which is
an important subclass of bipartite graphs. In addition, we show that the
problem is linear-time solvable for bounded tree-width graphs. Further, we
prove that the computational complexity of this problem varies from the
domination problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13116'>The $\mathsf{AC}^0$-Complexity Of Visibly Pushdown Languages</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Stefan G&#xf6;ller, Nathan Grosshans</p><p>We concern ourselves with the question which visibly pushdown languages are
in the complexity class $\mathsf{AC}^0$.
</p>
<p>We provide a conjectural characterization that isolates a stubborn subclass
of particular one-turn visibly pushdown languages (that we call intermediate
VPLs) all of which our community seems to lack tools for determining
containment in $\mathsf{AC}^0$.
</p>
<p>Our main result states that there is an algorithm that, given a visibly
pushdown automaton, correctly outputs if its language is in $\mathsf{AC}^0$,
some $m\geq 2$ such that $\text{MOD}_m\leq_{\text{cd}} L$ (implying that $L$ is
not in $\mathsf{AC}^0$), or a finite disjoint union of intermediate languages
$L$ is constant-depth equivalent to. In the latter case one can moreover
effectively compute $k,l&gt;0$ with $k\not=l$ such that the visibly pushdown
language is hard for the more concrete intermediate language $L(S\rightarrow
\varepsilon\mid a c^{k-1} S b_1\mid ac^{l-1}Sb_2)$.
</p>
<p>For our proofs we revisit so-called Ext-algebras, introduced by Czarnetzki,
Krebs and Lange, which in turn are closely related to forest algebras
introduced by Boja\'nczyk and Walukiewicz, and Green's relations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goller_S/0/1/0/all/0/1">Stefan G&#xf6;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Grosshans_N/0/1/0/all/0/1">Nathan Grosshans</a></p><p>We concern ourselves with the question which visibly pushdown languages are
in the complexity class $\mathsf{AC}^0$.
</p>
<p>We provide a conjectural characterization that isolates a stubborn subclass
of particular one-turn visibly pushdown languages (that we call intermediate
VPLs) all of which our community seems to lack tools for determining
containment in $\mathsf{AC}^0$.
</p>
<p>Our main result states that there is an algorithm that, given a visibly
pushdown automaton, correctly outputs if its language is in $\mathsf{AC}^0$,
some $m\geq 2$ such that $\text{MOD}_m\leq_{\text{cd}} L$ (implying that $L$ is
not in $\mathsf{AC}^0$), or a finite disjoint union of intermediate languages
$L$ is constant-depth equivalent to. In the latter case one can moreover
effectively compute $k,l&gt;0$ with $k\not=l$ such that the visibly pushdown
language is hard for the more concrete intermediate language $L(S\rightarrow
\varepsilon\mid a c^{k-1} S b_1\mid ac^{l-1}Sb_2)$.
</p>
<p>For our proofs we revisit so-called Ext-algebras, introduced by Czarnetzki,
Krebs and Lange, which in turn are closely related to forest algebras
introduced by Boja\'nczyk and Walukiewicz, and Green's relations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12950'>Two-Disk Compound Symmetry Groups</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Robert A. Hearn, William Kretschmer, Tomas Rokicki, Benjamin Streeter, Eric Vergo</p><p>Symmetry is at the heart of much of mathematics, physics, and art.
Traditional geometric symmetry groups are defined in terms of isometries of the
ambient space of a shape or pattern. If we slightly generalize this notion to
allow the isometries to operate on overlapping but non-identical metric spaces,
we obtain what we call compound symmetry groups. A natural example is that of
the groups generated by discrete rotations of overlapping disks in the plane.
Investigation of these groups reveals a new family of fractals, as well as a
rich structure that is intriguing both mathematically and artistically. We
report on our initial investigations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Hearn_R/0/1/0/all/0/1">Robert A. Hearn</a>, <a href="http://arxiv.org/find/math/1/au:+Kretschmer_W/0/1/0/all/0/1">William Kretschmer</a>, <a href="http://arxiv.org/find/math/1/au:+Rokicki_T/0/1/0/all/0/1">Tomas Rokicki</a>, <a href="http://arxiv.org/find/math/1/au:+Streeter_B/0/1/0/all/0/1">Benjamin Streeter</a>, <a href="http://arxiv.org/find/math/1/au:+Vergo_E/0/1/0/all/0/1">Eric Vergo</a></p><p>Symmetry is at the heart of much of mathematics, physics, and art.
Traditional geometric symmetry groups are defined in terms of isometries of the
ambient space of a shape or pattern. If we slightly generalize this notion to
allow the isometries to operate on overlapping but non-identical metric spaces,
we obtain what we call compound symmetry groups. A natural example is that of
the groups generated by discrete rotations of overlapping disks in the plane.
Investigation of these groups reveals a new family of fractals, as well as a
rich structure that is intriguing both mathematically and artistically. We
report on our initial investigations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13036'>Limited Query Graph Connectivity Test</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mingyu Guo, Jialiang Li, Aneta Neumann, Frank Neumann, Hung Nguyen</p><p>We propose a combinatorial optimisation model called Limited Query Graph
Connectivity Test. We consider a graph whose edges have two possible states
(on/off). The edges' states are hidden initially. We could query an edge to
reveal its state. Given a source s and a destination t, we aim to test s-t
connectivity by identifying either a path (consisting of only on edges) or a
cut (consisting of only off edges). We are limited to B queries, after which we
stop regardless of whether graph connectivity is established. We aim to design
a query policy that minimizes the expected number of queries.
</p>
<p>If we remove the query limit B (i.e., by setting B to the total number of
edges), then our problem becomes a special case of (monotone) Stochastic
Boolean Function Evaluation (SBFE). There are two existing exact algorithms
that are prohibitively expensive. They have best known upper bounds of O(3^m)
and O(2^{2^k}) respectively, where m is the number of edges and k is the number
of paths/cuts. These algorithms do not scale well in practice.
</p>
<p>We propose a significantly more scalable exact algorithm. Our exact algorithm
works by iteratively improving the performance lower bound until the lower
bound becomes achievable. Even when our exact algorithm does not scale, it can
be used as an anytime algorithm for calculating lower bound.
</p>
<p>We experiment on a wide range of practical graphs. We observe that even for
large graphs (i.e., tens of thousands of edges), it mostly takes only a few
queries to reach conclusion, which is the practical motivation behind the query
limit B. B is also an algorithm parameter that controls scalability. For small
B, our exact algorithm scales well. For large B, our exact algorithm can be
converted to a heuristic (i.e., always pretend that there are only 5 queries
left). Our heuristic outperforms all existing heuristics ported from SBFE and
related literature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mingyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jialiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_A/0/1/0/all/0/1">Aneta Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_F/0/1/0/all/0/1">Frank Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Hung Nguyen</a></p><p>We propose a combinatorial optimisation model called Limited Query Graph
Connectivity Test. We consider a graph whose edges have two possible states
(on/off). The edges' states are hidden initially. We could query an edge to
reveal its state. Given a source s and a destination t, we aim to test s-t
connectivity by identifying either a path (consisting of only on edges) or a
cut (consisting of only off edges). We are limited to B queries, after which we
stop regardless of whether graph connectivity is established. We aim to design
a query policy that minimizes the expected number of queries.
</p>
<p>If we remove the query limit B (i.e., by setting B to the total number of
edges), then our problem becomes a special case of (monotone) Stochastic
Boolean Function Evaluation (SBFE). There are two existing exact algorithms
that are prohibitively expensive. They have best known upper bounds of O(3^m)
and O(2^{2^k}) respectively, where m is the number of edges and k is the number
of paths/cuts. These algorithms do not scale well in practice.
</p>
<p>We propose a significantly more scalable exact algorithm. Our exact algorithm
works by iteratively improving the performance lower bound until the lower
bound becomes achievable. Even when our exact algorithm does not scale, it can
be used as an anytime algorithm for calculating lower bound.
</p>
<p>We experiment on a wide range of practical graphs. We observe that even for
large graphs (i.e., tens of thousands of edges), it mostly takes only a few
queries to reach conclusion, which is the practical motivation behind the query
limit B. B is also an algorithm parameter that controls scalability. For small
B, our exact algorithm scales well. For large B, our exact algorithm can be
converted to a heuristic (i.e., always pretend that there are only 5 queries
left). Our heuristic outperforms all existing heuristics ported from SBFE and
related literature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13110'>On the Cost of Demographic Parity in Influence Maximization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ruben Becker, Gianlorenzo D&#x27;Angelo, Sajjad Ghobadi</p><p>Modeling and shaping how information spreads through a network is a major
research topic in network analysis. While initially the focus has been mostly
on efficiency, recently fairness criteria have been taken into account in this
setting. Most work has focused on the maximin criteria however, and thus still
different groups can receive very different shares of information. In this work
we propose to consider fairness as a notion to be guaranteed by an algorithm
rather than as a criterion to be maximized. To this end, we propose three
optimization problems that aim at maximizing the overall spread while enforcing
strict levels of demographic parity fairness via constraints (either ex-post or
ex-ante). The level of fairness hence becomes a user choice rather than a
property to be observed upon output. We study this setting from various
perspectives. First, we prove that the cost of introducing demographic parity
can be high in terms of both overall spread and computational complexity, i.e.,
the price of fairness may be unbounded for all three problems and optimal
solutions are hard to compute, in some case even approximately or when fairness
constraints may be violated. For one of our problems, we still design an
algorithm with both constant approximation factor and fairness violation. We
also give two heuristics that allow the user to choose the tolerated fairness
violation. By means of an extensive experimental study, we show that our
algorithms perform well in practice, that is, they achieve the best demographic
parity fairness values. For certain instances we additionally even obtain an
overall spread comparable to the most efficient algorithms that come without
any fairness guarantee, indicating that the empirical price of fairness may
actually be small when using our algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Becker_R/0/1/0/all/0/1">Ruben Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+DAngelo_G/0/1/0/all/0/1">Gianlorenzo D&#x27;Angelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghobadi_S/0/1/0/all/0/1">Sajjad Ghobadi</a></p><p>Modeling and shaping how information spreads through a network is a major
research topic in network analysis. While initially the focus has been mostly
on efficiency, recently fairness criteria have been taken into account in this
setting. Most work has focused on the maximin criteria however, and thus still
different groups can receive very different shares of information. In this work
we propose to consider fairness as a notion to be guaranteed by an algorithm
rather than as a criterion to be maximized. To this end, we propose three
optimization problems that aim at maximizing the overall spread while enforcing
strict levels of demographic parity fairness via constraints (either ex-post or
ex-ante). The level of fairness hence becomes a user choice rather than a
property to be observed upon output. We study this setting from various
perspectives. First, we prove that the cost of introducing demographic parity
can be high in terms of both overall spread and computational complexity, i.e.,
the price of fairness may be unbounded for all three problems and optimal
solutions are hard to compute, in some case even approximately or when fairness
constraints may be violated. For one of our problems, we still design an
algorithm with both constant approximation factor and fairness violation. We
also give two heuristics that allow the user to choose the tolerated fairness
violation. By means of an extensive experimental study, we show that our
algorithms perform well in practice, that is, they achieve the best demographic
parity fairness values. For certain instances we additionally even obtain an
overall spread comparable to the most efficient algorithms that come without
any fairness guarantee, indicating that the empirical price of fairness may
actually be small when using our algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13112'>Improving Fairness in Information Exposure by Adding Links</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ruben Becker, Gianlorenzo D&#x27;Angelo, Sajjad Ghobadi</p><p>Fairness in influence maximization has been a very active research topic
recently. Most works in this context study the question of how to find seeding
strategies (deterministic or probabilistic) such that nodes or communities in
the network get their fair share of coverage. Different fairness criteria have
been used in this context. All these works assume that the entity that is
spreading the information has an inherent interest in spreading the information
fairly, otherwise why would they want to use the developed fair algorithms?
This assumption may however be flawed in reality -- the spreading entity may be
purely \emph{efficiency-oriented}. In this paper we propose to study two
optimization problems with the goal to modify the network structure by adding
links in such a way that efficiency-oriented information spreading becomes
\emph{automatically fair}. We study the proposed optimization problems both
from a theoretical and experimental perspective, that is, we give several
hardness and hardness of approximation results, provide efficient algorithms
for some special cases, and more importantly provide heuristics for solving one
of the problems in practice. In our experimental study we then first compare
the proposed heuristics against each other and establish the most successful
one. In a second experiment, we then show that our approach can be very
successful in practice. That is, we show that already after adding a few edges
to the networks the greedy algorithm that purely maximizes spread surpasses all
fairness-tailored algorithms in terms of ex-post fairness. Maybe surprisingly,
we even show that our approach achieves ex-post fairness values that are
comparable or even better than the ex-ante fairness values of the currently
most efficient algorithms that optimize ex-ante fairness.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Becker_R/0/1/0/all/0/1">Ruben Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+DAngelo_G/0/1/0/all/0/1">Gianlorenzo D&#x27;Angelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghobadi_S/0/1/0/all/0/1">Sajjad Ghobadi</a></p><p>Fairness in influence maximization has been a very active research topic
recently. Most works in this context study the question of how to find seeding
strategies (deterministic or probabilistic) such that nodes or communities in
the network get their fair share of coverage. Different fairness criteria have
been used in this context. All these works assume that the entity that is
spreading the information has an inherent interest in spreading the information
fairly, otherwise why would they want to use the developed fair algorithms?
This assumption may however be flawed in reality -- the spreading entity may be
purely \emph{efficiency-oriented}. In this paper we propose to study two
optimization problems with the goal to modify the network structure by adding
links in such a way that efficiency-oriented information spreading becomes
\emph{automatically fair}. We study the proposed optimization problems both
from a theoretical and experimental perspective, that is, we give several
hardness and hardness of approximation results, provide efficient algorithms
for some special cases, and more importantly provide heuristics for solving one
of the problems in practice. In our experimental study we then first compare
the proposed heuristics against each other and establish the most successful
one. In a second experiment, we then show that our approach can be very
successful in practice. That is, we show that already after adding a few edges
to the networks the greedy algorithm that purely maximizes spread surpasses all
fairness-tailored algorithms in terms of ex-post fairness. Maybe surprisingly,
we even show that our approach achieves ex-post fairness values that are
comparable or even better than the ex-ante fairness values of the currently
most efficient algorithms that optimize ex-ante fairness.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.13113'>Toward Self-Adjusting k-ary Search Tree Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Evgenii Feder, Anton Paramonov, Iosif Salem, Stefan Schmid, Vitaly Aksenov</p><p>Datacenter networks are becoming increasingly flexible with the incorporation
of new networking technologies, such as optical circuit switches. These
technologies allow for programmable network topologies that can be reconfigured
to better serve network traffic, thus enabling a trade-off between the benefits
(i.e., shorter routes) and costs of reconfigurations (i.e., overhead).
Self-Adjusting Networks (SANs) aim at addressing this trade-off by exploiting
patterns in network traffic, both when it is revealed piecewise (online dynamic
topologies) or known in advance (offline static topologies). In this paper, we
take the first steps toward Self-Adjusting k-ary tree networks. These are more
powerful generalizations of existing binary search tree networks (like
SplayNets), which have been at the core of SAN designs. k-ary search tree
networks are a natural generalization offering nodes of higher degrees, reduced
route lengths for a fixed number of nodes, and local routing in spite of
reconfigurations. We first compute an offline (optimal) static network for
arbitrary traffic patterns in $O(n^3 \cdot k)$ time via dynamic programming,
and also improve the bound to $O(n^2 \cdot k)$ for the special case of
uniformly distributed traffic. Then, we present a centroid-based topology of
the network that can be used both in the offline static and the online setting.
In the offline uniform-workload case, we construct this quasi-optimal network
in linear time $O(n)$ and, finally, we present online self-adjusting k-ary
search tree versions of SplayNet. We evaluate experimentally our new structure
for $k=2$ (allowing for a comparison with existing SplayNets) on real and
synthetic network traces. Our results show that this approach works better than
SplayNet in most of the real network traces and in average to low locality
synthetic traces, and is only little inferior to SplayNet in all remaining
traces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Feder_E/0/1/0/all/0/1">Evgenii Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Paramonov_A/0/1/0/all/0/1">Anton Paramonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Salem_I/0/1/0/all/0/1">Iosif Salem</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Aksenov_V/0/1/0/all/0/1">Vitaly Aksenov</a></p><p>Datacenter networks are becoming increasingly flexible with the incorporation
of new networking technologies, such as optical circuit switches. These
technologies allow for programmable network topologies that can be reconfigured
to better serve network traffic, thus enabling a trade-off between the benefits
(i.e., shorter routes) and costs of reconfigurations (i.e., overhead).
Self-Adjusting Networks (SANs) aim at addressing this trade-off by exploiting
patterns in network traffic, both when it is revealed piecewise (online dynamic
topologies) or known in advance (offline static topologies). In this paper, we
take the first steps toward Self-Adjusting k-ary tree networks. These are more
powerful generalizations of existing binary search tree networks (like
SplayNets), which have been at the core of SAN designs. k-ary search tree
networks are a natural generalization offering nodes of higher degrees, reduced
route lengths for a fixed number of nodes, and local routing in spite of
reconfigurations. We first compute an offline (optimal) static network for
arbitrary traffic patterns in $O(n^3 \cdot k)$ time via dynamic programming,
and also improve the bound to $O(n^2 \cdot k)$ for the special case of
uniformly distributed traffic. Then, we present a centroid-based topology of
the network that can be used both in the offline static and the online setting.
In the offline uniform-workload case, we construct this quasi-optimal network
in linear time $O(n)$ and, finally, we present online self-adjusting k-ary
search tree versions of SplayNet. We evaluate experimentally our new structure
for $k=2$ (allowing for a comparison with existing SplayNets) on real and
synthetic network traces. Our results show that this approach works better than
SplayNet in most of the real network traces and in average to low locality
synthetic traces, and is only little inferior to SplayNet in all remaining
traces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-28T01:30:00Z">Tuesday, February 28 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
