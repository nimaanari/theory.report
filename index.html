<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-05-11T02:30:18Z">Thursday, May 11 2023, 02:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, May 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05676'>Scheme-Theoretic Approach to Computational Complexity. IV. A New Perspective on Hardness of Approximation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ali &#xc7;ivril</p><p>We provide a new approach for establishing hardness of approximation results,
based on the theory recently introduced by the author. It allows one to
directly show that approximating a problem beyond a certain threshold requires
super-polynomial time. To exhibit the framework, we revisit two famous problems
in this paper. The particular results we prove are:
</p>
<p>MAX-3-SAT$(1,\frac{7}{8}+\epsilon)$ requires exponential time for any
constant $\epsilon$ satisfying $\frac{1}{8} \geq \epsilon &gt; 0$. In particular,
the gap exponential time hypothesis (Gap-ETH) holds.
</p>
<p>MAX-3-LIN-2$(1-\epsilon, \frac{1}{2}+\epsilon)$ requires exponential time for
any constant $\epsilon$ satisfying $\frac{1}{4} \geq \epsilon &gt; 0$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Civril_A/0/1/0/all/0/1">Ali &#xc7;ivril</a></p><p>We provide a new approach for establishing hardness of approximation results,
based on the theory recently introduced by the author. It allows one to
directly show that approximating a problem beyond a certain threshold requires
super-polynomial time. To exhibit the framework, we revisit two famous problems
in this paper. The particular results we prove are:
</p>
<p>MAX-3-SAT$(1,\frac{7}{8}+\epsilon)$ requires exponential time for any
constant $\epsilon$ satisfying $\frac{1}{8} \geq \epsilon &gt; 0$. In particular,
the gap exponential time hypothesis (Gap-ETH) holds.
</p>
<p>MAX-3-LIN-2$(1-\epsilon, \frac{1}{2}+\epsilon)$ requires exponential time for
any constant $\epsilon$ satisfying $\frac{1}{4} \geq \epsilon &gt; 0$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05765'>On the average-case complexity of learning output distributions of quantum circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Nietner, Marios Ioannou, Ryan Sweke, Richard Kueng, Jens Eisert, Marcel Hinsche, Jonas Haferkamp</p><p>In this work, we show that learning the output distributions of brickwork
random quantum circuits is average-case hard in the statistical query model.
This learning model is widely used as an abstract computational model for most
generic learning algorithms. In particular, for brickwork random quantum
circuits on $n$ qubits of depth $d$, we show three main results:
</p>
<p>- At super logarithmic circuit depth $d=\omega(\log(n))$, any learning
algorithm requires super polynomially many queries to achieve a constant
probability of success over the randomly drawn instance.
</p>
<p>- There exists a $d=O(n)$, such that any learning algorithm requires
$\Omega(2^n)$ queries to achieve a $O(2^{-n})$ probability of success over the
randomly drawn instance.
</p>
<p>- At infinite circuit depth $d\to\infty$, any learning algorithm requires
$2^{2^{\Omega(n)}}$ many queries to achieve a $2^{-2^{\Omega(n)}}$ probability
of success over the randomly drawn instance.
</p>
<p>As an auxiliary result of independent interest, we show that the output
distribution of a brickwork random quantum circuit is constantly far from any
fixed distribution in total variation distance with probability $1-O(2^{-n})$,
which confirms a variant of a conjecture by Aaronson and Chen.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Nietner_A/0/1/0/all/0/1">Alexander Nietner</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ioannou_M/0/1/0/all/0/1">Marios Ioannou</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sweke_R/0/1/0/all/0/1">Ryan Sweke</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kueng_R/0/1/0/all/0/1">Richard Kueng</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Eisert_J/0/1/0/all/0/1">Jens Eisert</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hinsche_M/0/1/0/all/0/1">Marcel Hinsche</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Haferkamp_J/0/1/0/all/0/1">Jonas Haferkamp</a></p><p>In this work, we show that learning the output distributions of brickwork
random quantum circuits is average-case hard in the statistical query model.
This learning model is widely used as an abstract computational model for most
generic learning algorithms. In particular, for brickwork random quantum
circuits on $n$ qubits of depth $d$, we show three main results:
</p>
<p>- At super logarithmic circuit depth $d=\omega(\log(n))$, any learning
algorithm requires super polynomially many queries to achieve a constant
probability of success over the randomly drawn instance.
</p>
<p>- There exists a $d=O(n)$, such that any learning algorithm requires
$\Omega(2^n)$ queries to achieve a $O(2^{-n})$ probability of success over the
randomly drawn instance.
</p>
<p>- At infinite circuit depth $d\to\infty$, any learning algorithm requires
$2^{2^{\Omega(n)}}$ many queries to achieve a $2^{-2^{\Omega(n)}}$ probability
of success over the randomly drawn instance.
</p>
<p>As an auxiliary result of independent interest, we show that the output
distribution of a brickwork random quantum circuit is constantly far from any
fixed distribution in total variation distance with probability $1-O(2^{-n})$,
which confirms a variant of a conjecture by Aaronson and Chen.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05808'>On the Information Capacity of Nearest Neighbor Representations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kordag Mehmet Kilic, Jin Sima, Jehoshua Bruck</p><p>The $\textit{von Neumann Computer Architecture}$ has a distinction between
computation and memory. In contrast, the brain has an integrated architecture
where computation and memory are indistinguishable. Motivated by the
architecture of the brain, we propose a model of $\textit{associative
computation}$ where memory is defined by a set of vectors in $\mathbb{R}^n$
(that we call $\textit{anchors}$), computation is performed by convergence from
an input vector to a nearest neighbor anchor, and the output is a label
associated with an anchor. Specifically, in this paper, we study the
representation of Boolean functions in the associative computation model, where
the inputs are binary vectors and the corresponding outputs are the labels ($0$
or $1$) of the nearest neighbor anchors. The information capacity of a Boolean
function in this model is associated with two quantities: $\textit{(i)}$ the
number of anchors (called $\textit{Nearest Neighbor (NN) Complexity}$) and
$\textit{(ii)}$ the maximal number of bits representing entries of anchors
(called $\textit{Resolution}$). We study symmetric Boolean functions and
present constructions that have optimal NN complexity and resolution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kilic_K/0/1/0/all/0/1">Kordag Mehmet Kilic</a>, <a href="http://arxiv.org/find/cs/1/au:+Sima_J/0/1/0/all/0/1">Jin Sima</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruck_J/0/1/0/all/0/1">Jehoshua Bruck</a></p><p>The $\textit{von Neumann Computer Architecture}$ has a distinction between
computation and memory. In contrast, the brain has an integrated architecture
where computation and memory are indistinguishable. Motivated by the
architecture of the brain, we propose a model of $\textit{associative
computation}$ where memory is defined by a set of vectors in $\mathbb{R}^n$
(that we call $\textit{anchors}$), computation is performed by convergence from
an input vector to a nearest neighbor anchor, and the output is a label
associated with an anchor. Specifically, in this paper, we study the
representation of Boolean functions in the associative computation model, where
the inputs are binary vectors and the corresponding outputs are the labels ($0$
or $1$) of the nearest neighbor anchors. The information capacity of a Boolean
function in this model is associated with two quantities: $\textit{(i)}$ the
number of anchors (called $\textit{Nearest Neighbor (NN) Complexity}$) and
$\textit{(ii)}$ the maximal number of bits representing entries of anchors
(called $\textit{Resolution}$). We study symmetric Boolean functions and
present constructions that have optimal NN complexity and resolution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06064'>DNN Verification, Reachability, and the Exponential Function Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Omri Isac, Yoni Zohar, Clark Barrett, Guy Katz</p><p>Deep neural networks (DNNs) are increasingly being deployed to perform
safety-critical tasks. The opacity of DNNs, which prevents humans from
reasoning about them, presents new safety and security challenges. To address
these challenges, the verification community has begun developing techniques
for rigorously analyzing DNNs, with numerous verification algorithms proposed
in recent years. While a significant amount of work has gone into developing
these verification algorithms, little work has been devoted to rigorously
studying the computability and complexity of the underlying theoretical
problems. Here, we seek to contribute to the bridging of this gap. We focus on
two kinds of DNNs: those that employ piecewise-linear activation functions
(e.g., ReLU), and those that employ piecewise-smooth activation functions
(e.g., Sigmoids). We prove the two following theorems: 1) The decidability of
verifying DNNs with piecewise-smooth activation functions is equivalent to a
well-known, open problem formulated by Tarski; and 2) The DNN verification
problem for any quantifier-free linear arithmetic specification can be reduced
to the DNN reachability problem, whose approximation is NP-complete. These
results answer two fundamental questions about the computability and complexity
of DNN verification, and the ways it is affected by the network's activation
functions and error tolerance; and could help guide future efforts in
developing DNN verification tools.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Isac_O/0/1/0/all/0/1">Omri Isac</a>, <a href="http://arxiv.org/find/cs/1/au:+Zohar_Y/0/1/0/all/0/1">Yoni Zohar</a>, <a href="http://arxiv.org/find/cs/1/au:+Barrett_C/0/1/0/all/0/1">Clark Barrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1">Guy Katz</a></p><p>Deep neural networks (DNNs) are increasingly being deployed to perform
safety-critical tasks. The opacity of DNNs, which prevents humans from
reasoning about them, presents new safety and security challenges. To address
these challenges, the verification community has begun developing techniques
for rigorously analyzing DNNs, with numerous verification algorithms proposed
in recent years. While a significant amount of work has gone into developing
these verification algorithms, little work has been devoted to rigorously
studying the computability and complexity of the underlying theoretical
problems. Here, we seek to contribute to the bridging of this gap. We focus on
two kinds of DNNs: those that employ piecewise-linear activation functions
(e.g., ReLU), and those that employ piecewise-smooth activation functions
(e.g., Sigmoids). We prove the two following theorems: 1) The decidability of
verifying DNNs with piecewise-smooth activation functions is equivalent to a
well-known, open problem formulated by Tarski; and 2) The DNN verification
problem for any quantifier-free linear arithmetic specification can be reduced
to the DNN reachability problem, whose approximation is NP-complete. These
results answer two fundamental questions about the computability and complexity
of DNN verification, and the ways it is affected by the network's activation
functions and error tolerance; and could help guide future efforts in
developing DNN verification tools.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06093'>Deterministic and Strongly Nondeterministic Decision Trees for Decision Tables from Closed Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Azimkhon Ostonov, Mikhail Moshkov</p><p>In this paper, we consider classes of decision tables with 0-1-decisions
closed relative to removal of attributes (columns) and changing decisions
assigned to rows. For tables from an arbitrary closed class, we study the
dependence of the minimum complexity of deterministic decision trees on various
parameters of the tables: the minimum complexity of a test, the complexity of
the set of attributes attached to columns, and the minimum complexity of a
strongly nondeterministic decision tree. We also study the dependence of the
minimum complexity of strongly nondeterministic decision trees on the
complexity of the set of attributes attached to columns. Note that a strongly
nondeterministic decision tree can be interpreted as a set of true decision
rules that cover all rows labeled with the decision 1.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ostonov_A/0/1/0/all/0/1">Azimkhon Ostonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshkov_M/0/1/0/all/0/1">Mikhail Moshkov</a></p><p>In this paper, we consider classes of decision tables with 0-1-decisions
closed relative to removal of attributes (columns) and changing decisions
assigned to rows. For tables from an arbitrary closed class, we study the
dependence of the minimum complexity of deterministic decision trees on various
parameters of the tables: the minimum complexity of a test, the complexity of
the set of attributes attached to columns, and the minimum complexity of a
strongly nondeterministic decision tree. We also study the dependence of the
minimum complexity of strongly nondeterministic decision trees on the
complexity of the set of attributes attached to columns. Note that a strongly
nondeterministic decision tree can be interpreted as a set of true decision
rules that cover all rows labeled with the decision 1.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06146'>Shape Formation and Locomotion with Joint Movements in the Amoebot Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andreas Padalkin, Manish Kumar, Christian Scheideler</p><p>We are considering the geometric amoebot model where a set of $n$ amoebots is
placed on the triangular grid. An amoebot is able to send information to its
neighbors, and to move via expansions and contractions. Since amoebots and
information can only travel node by node, most problems have a natural lower
bound of $\Omega(D)$ where $D$ denotes the diameter of the structure. Inspired
by the nervous and muscular system, Feldmann et al. have proposed the
reconfigurable circuit extension and the joint movement extension of the
amoebot model with the goal of breaking this lower bound.
</p>
<p>In the joint movement extension, the way amoebots move is altered. Amoebots
become able to push and pull other amoebots. Feldmann et al. demonstrated the
power of joint movements by transforming a line of amoebots into a rhombus
within $O(\log n)$ rounds. However, they left the details of the extension
open. The goal of this paper is therefore to formalize and extend the joint
movement extension. In order to provide a proof of concept for the extension,
we consider two fundamental problems of modular robot systems: shape formation
and locomotion.
</p>
<p>We approach these problems by defining meta-modules of rhombical and
hexagonal shape, respectively. The meta-modules are capable of movement
primitives like sliding, rotating, and tunneling. This allows us to simulate
shape formation algorithms of various modular robot systems. Finally, we
construct three amoebot structures capable of locomotion by rolling, crawling,
and walking, respectively.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Padalkin_A/0/1/0/all/0/1">Andreas Padalkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1">Manish Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheideler_C/0/1/0/all/0/1">Christian Scheideler</a></p><p>We are considering the geometric amoebot model where a set of $n$ amoebots is
placed on the triangular grid. An amoebot is able to send information to its
neighbors, and to move via expansions and contractions. Since amoebots and
information can only travel node by node, most problems have a natural lower
bound of $\Omega(D)$ where $D$ denotes the diameter of the structure. Inspired
by the nervous and muscular system, Feldmann et al. have proposed the
reconfigurable circuit extension and the joint movement extension of the
amoebot model with the goal of breaking this lower bound.
</p>
<p>In the joint movement extension, the way amoebots move is altered. Amoebots
become able to push and pull other amoebots. Feldmann et al. demonstrated the
power of joint movements by transforming a line of amoebots into a rhombus
within $O(\log n)$ rounds. However, they left the details of the extension
open. The goal of this paper is therefore to formalize and extend the joint
movement extension. In order to provide a proof of concept for the extension,
we consider two fundamental problems of modular robot systems: shape formation
and locomotion.
</p>
<p>We approach these problems by defining meta-modules of rhombical and
hexagonal shape, respectively. The meta-modules are capable of movement
primitives like sliding, rotating, and tunneling. This allows us to simulate
shape formation algorithms of various modular robot systems. Finally, we
construct three amoebot structures capable of locomotion by rolling, crawling,
and walking, respectively.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06315'>NervePool: A Simplicial Pooling Layer</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sarah McGuire, Elizabeth Munch, Matthew Hirn</p><p>For deep learning problems on graph-structured data, pooling layers are
important for down sampling, reducing computational cost, and to minimize
overfitting. We define a pooling layer, NervePool, for data structured as
simplicial complexes, which are generalizations of graphs that include
higher-dimensional simplices beyond vertices and edges; this structure allows
for greater flexibility in modeling higher-order relationships. The proposed
simplicial coarsening scheme is built upon partitions of vertices, which allow
us to generate hierarchical representations of simplicial complexes, collapsing
information in a learned fashion. NervePool builds on the learned vertex
cluster assignments and extends to coarsening of higher dimensional simplices
in a deterministic fashion. While in practice, the pooling operations are
computed via a series of matrix operations, the topological motivation is a
set-theoretic construction based on unions of stars of simplices and the nerve
complex
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+McGuire_S/0/1/0/all/0/1">Sarah McGuire</a>, <a href="http://arxiv.org/find/cs/1/au:+Munch_E/0/1/0/all/0/1">Elizabeth Munch</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirn_M/0/1/0/all/0/1">Matthew Hirn</a></p><p>For deep learning problems on graph-structured data, pooling layers are
important for down sampling, reducing computational cost, and to minimize
overfitting. We define a pooling layer, NervePool, for data structured as
simplicial complexes, which are generalizations of graphs that include
higher-dimensional simplices beyond vertices and edges; this structure allows
for greater flexibility in modeling higher-order relationships. The proposed
simplicial coarsening scheme is built upon partitions of vertices, which allow
us to generate hierarchical representations of simplicial complexes, collapsing
information in a learned fashion. NervePool builds on the learned vertex
cluster assignments and extends to coarsening of higher dimensional simplices
in a deterministic fashion. While in practice, the pooling operations are
computed via a series of matrix operations, the topological motivation is a
set-theoretic construction based on unions of stars of simplices and the nerve
complex
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05671'>Parallel External Sorting of ASCII Records Using Learned Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ani Kristo, Tim Kraska</p><p>External sorting is at the core of many operations in large-scale database
systems, such as ordering and aggregation queries for large result sets,
building indexes, sort-merge joins, duplicate removal, sharding, and record
clustering. Unlike in-memory sorting, these algorithms need to work together
with the OS and the filesystem to efficiently utilize system resources and
minimize disk I/O.
</p>
<p>In this paper we describe ELSAR: a parallel external sorting algorithm that
uses an innovative paradigm based on a learned data distribution model. The
algorithm leverages the model to arrange the input records into mutually
exclusive, monotonic, and equi-depth partitions that, once sorted, can simply
be concatenated to form the output. This method completely eliminates the need
for multi-way file merging, which is typically used in external sorting.
</p>
<p>We present thorough benchmarks for uniform and skewed datasets in various
storage media, where we measure the sorting rates, size scalability, and energy
efficiency of ELSAR and other sorting algorithms. We observed that ELSAR has up
to 1.65x higher sorting rates than the next-best external sort (Nsort) on SSD
drives and 5.31x higher than the GNU coreutils' sort utility on Intel Optane
non-volatile memory. In addition, ELSAR supersedes the current winner of the
SortBenchmark for the most energy-efficient external string sorting algorithm
by an impressive margin of 41%.
</p>
<p>These results reinforce the premise that novel learning-enhanced algorithms
can provide remarkable performance benefits over traditional ones.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kristo_A/0/1/0/all/0/1">Ani Kristo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kraska_T/0/1/0/all/0/1">Tim Kraska</a></p><p>External sorting is at the core of many operations in large-scale database
systems, such as ordering and aggregation queries for large result sets,
building indexes, sort-merge joins, duplicate removal, sharding, and record
clustering. Unlike in-memory sorting, these algorithms need to work together
with the OS and the filesystem to efficiently utilize system resources and
minimize disk I/O.
</p>
<p>In this paper we describe ELSAR: a parallel external sorting algorithm that
uses an innovative paradigm based on a learned data distribution model. The
algorithm leverages the model to arrange the input records into mutually
exclusive, monotonic, and equi-depth partitions that, once sorted, can simply
be concatenated to form the output. This method completely eliminates the need
for multi-way file merging, which is typically used in external sorting.
</p>
<p>We present thorough benchmarks for uniform and skewed datasets in various
storage media, where we measure the sorting rates, size scalability, and energy
efficiency of ELSAR and other sorting algorithms. We observed that ELSAR has up
to 1.65x higher sorting rates than the next-best external sort (Nsort) on SSD
drives and 5.31x higher than the GNU coreutils' sort utility on Intel Optane
non-volatile memory. In addition, ELSAR supersedes the current winner of the
SortBenchmark for the most energy-efficient external string sorting algorithm
by an impressive margin of 41%.
</p>
<p>These results reinforce the premise that novel learning-enhanced algorithms
can provide remarkable performance benefits over traditional ones.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05763'>On the Number of $t$-Lee-Error-Correcting Codes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nadja Willenborg, Anna-Lena Horlemann, Violetta Weger</p><p>We consider $t$-Lee-error-correcting codes of length $n$ over the residue
ring $\mathbb{Z}_m := \mathbb{Z}/m\mathbb{Z}$ and determine upper and lower
bounds on the number of $t$-Lee-error-correcting codes. We use two different
methods, namely estimating isolated nodes on bipartite graphs and the graph
container method. The former gives density results for codes of fixed size and
the latter for any size. This confirms some recent density results for linear
Lee metric codes and provides new density results for nonlinear codes. To apply
a variant of the graph container algorithm we also investigate some geometrical
properties of the balls in the Lee metric.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Willenborg_N/0/1/0/all/0/1">Nadja Willenborg</a>, <a href="http://arxiv.org/find/cs/1/au:+Horlemann_A/0/1/0/all/0/1">Anna-Lena Horlemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Weger_V/0/1/0/all/0/1">Violetta Weger</a></p><p>We consider $t$-Lee-error-correcting codes of length $n$ over the residue
ring $\mathbb{Z}_m := \mathbb{Z}/m\mathbb{Z}$ and determine upper and lower
bounds on the number of $t$-Lee-error-correcting codes. We use two different
methods, namely estimating isolated nodes on bipartite graphs and the graph
container method. The former gives density results for codes of fixed size and
the latter for any size. This confirms some recent density results for linear
Lee metric codes and provides new density results for nonlinear codes. To apply
a variant of the graph container algorithm we also investigate some geometrical
properties of the balls in the Lee metric.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05826'>Universal Matrix Sparsifiers and Fast Deterministic Algorithms for Linear Algebra</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rajarshi Bhattacharjee, Gregory Dexter, Cameron Musco, Archan Ray, David P Woodruff</p><p>Given $\mathbf A \in \mathbb{R}^{n \times n}$ with entries bounded in
magnitude by $1$, it is well-known that if $S \subset [n] \times [n]$ is a
uniformly random subset of $\tilde{O} (n/\epsilon^2)$ entries, and if ${\mathbf
A}_S$ equals $\mathbf A$ on the entries in $S$ and is zero elsewhere, then
$\|\mathbf A - \frac{n^2}{s} \cdot {\mathbf A}_S\|_2 \le \epsilon n$ with high
probability, where $\|\cdot\|_2$ is the spectral norm. We show that for
positive semidefinite (PSD) matrices, no randomness is needed at all in this
statement. Namely, there exists a fixed subset $S$ of $\tilde{O}
(n/\epsilon^2)$ entries that acts as a universal sparsifier: the above error
bound holds simultaneously for every bounded entry PSD matrix $\mathbf A \in
\mathbb{R}^{n \times n}$. One can view this result as a significant extension
of a Ramanujan expander graph, which sparsifies any bounded entry PSD matrix,
not just the all ones matrix.
</p>
<p>We leverage the existence of such universal sparsifiers to give the first
deterministic algorithms for several central problems related to singular value
computation that run in faster than matrix multiplication time. We also prove
universal sparsification bounds for non-PSD matrices, showing that $\tilde{O}
(n/\epsilon^4)$ entries suffices to achieve error $\epsilon \cdot
\max(n,\|\mathbf A\|_1)$, where $\|\mathbf A\|_1$ is the trace norm. We prove
that this is optimal up to an $\tilde{O} (1/\epsilon^2)$ factor. Finally, we
give an improved deterministic spectral approximation algorithm for PSD
$\mathbf A$ with entries lying in $\{-1,0,1\}$, which we show is nearly
information-theoretically optimal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharjee_R/0/1/0/all/0/1">Rajarshi Bhattacharjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Dexter_G/0/1/0/all/0/1">Gregory Dexter</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>, <a href="http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1">Archan Ray</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P Woodruff</a></p><p>Given $\mathbf A \in \mathbb{R}^{n \times n}$ with entries bounded in
magnitude by $1$, it is well-known that if $S \subset [n] \times [n]$ is a
uniformly random subset of $\tilde{O} (n/\epsilon^2)$ entries, and if ${\mathbf
A}_S$ equals $\mathbf A$ on the entries in $S$ and is zero elsewhere, then
$\|\mathbf A - \frac{n^2}{s} \cdot {\mathbf A}_S\|_2 \le \epsilon n$ with high
probability, where $\|\cdot\|_2$ is the spectral norm. We show that for
positive semidefinite (PSD) matrices, no randomness is needed at all in this
statement. Namely, there exists a fixed subset $S$ of $\tilde{O}
(n/\epsilon^2)$ entries that acts as a universal sparsifier: the above error
bound holds simultaneously for every bounded entry PSD matrix $\mathbf A \in
\mathbb{R}^{n \times n}$. One can view this result as a significant extension
of a Ramanujan expander graph, which sparsifies any bounded entry PSD matrix,
not just the all ones matrix.
</p>
<p>We leverage the existence of such universal sparsifiers to give the first
deterministic algorithms for several central problems related to singular value
computation that run in faster than matrix multiplication time. We also prove
universal sparsification bounds for non-PSD matrices, showing that $\tilde{O}
(n/\epsilon^4)$ entries suffices to achieve error $\epsilon \cdot
\max(n,\|\mathbf A\|_1)$, where $\|\mathbf A\|_1$ is the trace norm. We prove
that this is optimal up to an $\tilde{O} (1/\epsilon^2)$ factor. Finally, we
give an improved deterministic spectral approximation algorithm for PSD
$\mathbf A$ with entries lying in $\{-1,0,1\}$, which we show is nearly
information-theoretically optimal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05829'>Constant Approximation for Network Revenue Management with Markovian-Correlated Customer Arrivals</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jiashuo Jiang</p><p>The Network Revenue Management (NRM) problem is a well-known challenge in
dynamic decision-making under uncertainty. In this problem, fixed resources
must be allocated to serve customers over a finite horizon, while customers
arrive according to a stochastic process. The typical NRM model assumes that
customer arrivals are independent over time. However, in this paper, we explore
a more general setting where customer arrivals over different periods can be
correlated. We propose a new model that assumes the existence of a system
state, which determines customer arrivals for the current period. This system
state evolves over time according to a time-inhomogeneous Markov chain. Our
model can be used to represent correlation in various settings and synthesizes
previous literature on correlation models.
</p>
<p>To solve the NRM problem under our correlated model, we derive a new linear
programming (LP) approximation of the optimal policy. Our approximation
provides a tighter upper bound on the total expected value collected by the
optimal policy than existing upper bounds. We use our LP to develop a new bid
price policy, which computes bid prices for each system state and time period
in a backward induction manner. The decision is then made by comparing the
reward of the customer against the associated bid prices. Our policy guarantees
to collect at least $1/(1+L)$ fraction of the total reward collected by the
optimal policy, where $L$ denotes the maximum number of resources required by a
customer.
</p>
<p>In summary, our work presents a new model for correlated customer arrivals in
the NRM problem and provides an LP approximation for solving the problem under
this model. We derive a new bid price policy and provides a theoretical
guarantee on the performance of the policy.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiashuo Jiang</a></p><p>The Network Revenue Management (NRM) problem is a well-known challenge in
dynamic decision-making under uncertainty. In this problem, fixed resources
must be allocated to serve customers over a finite horizon, while customers
arrive according to a stochastic process. The typical NRM model assumes that
customer arrivals are independent over time. However, in this paper, we explore
a more general setting where customer arrivals over different periods can be
correlated. We propose a new model that assumes the existence of a system
state, which determines customer arrivals for the current period. This system
state evolves over time according to a time-inhomogeneous Markov chain. Our
model can be used to represent correlation in various settings and synthesizes
previous literature on correlation models.
</p>
<p>To solve the NRM problem under our correlated model, we derive a new linear
programming (LP) approximation of the optimal policy. Our approximation
provides a tighter upper bound on the total expected value collected by the
optimal policy than existing upper bounds. We use our LP to develop a new bid
price policy, which computes bid prices for each system state and time period
in a backward induction manner. The decision is then made by comparing the
reward of the customer against the associated bid prices. Our policy guarantees
to collect at least $1/(1+L)$ fraction of the total reward collected by the
optimal policy, where $L$ denotes the maximum number of resources required by a
customer.
</p>
<p>In summary, our work presents a new model for correlated customer arrivals in
the NRM problem and provides an LP approximation for solving the problem under
this model. We derive a new bid price policy and provides a theoretical
guarantee on the performance of the policy.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05893'>Acceleration of FM-index Queries Through Prefix-free Parsing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aaron Hong, Marco Oliva, Dominik K&#xf6;ppl, Hideo Bannai, Christina Boucher, Travis Gagie</p><p>FM-indexes are a crucial data structure in DNA alignment, for example, but
searching with them usually takes at least one random access per character in
the query pattern. Ferragina and Fischer observed in 2007 that word-based
indexes often use fewer random accesses than character-based indexes, and thus
support faster searches. Since DNA lacks natural word-boundaries, however, it
is necessary to parse it somehow before applying word-based FM-indexing. Last
year, Deng et al.\ proposed parsing genomic data by induced suffix sorting, and
showed the resulting word-based FM-indexes support faster counting queries than
standard FM-indexes when patterns are a few thousand characters or longer. In
this paper we show that using prefix-free parsing -- which takes parameters
that let us tune the average length of the phrases -- instead of induced suffix
sorting, gives a significant speedup for patterns of only a few hundred
characters. We implement our method and demonstrate it is between 3 and 18
times faster than competing methods on queries to GRCh38. And was consistently
faster on queries made to 25,000, 50,000 and 100,000 SARS-CoV-2 genomes. Hence,
it is very clear that our method accelerates the performance of count over all
state-of-the-art methods with a minor increase in the memory. Our source code
is available at github.com/marco-oliva/afm .
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hong_A/0/1/0/all/0/1">Aaron Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliva_M/0/1/0/all/0/1">Marco Oliva</a>, <a href="http://arxiv.org/find/cs/1/au:+Koppl_D/0/1/0/all/0/1">Dominik K&#xf6;ppl</a>, <a href="http://arxiv.org/find/cs/1/au:+Bannai_H/0/1/0/all/0/1">Hideo Bannai</a>, <a href="http://arxiv.org/find/cs/1/au:+Boucher_C/0/1/0/all/0/1">Christina Boucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1">Travis Gagie</a></p><p>FM-indexes are a crucial data structure in DNA alignment, for example, but
searching with them usually takes at least one random access per character in
the query pattern. Ferragina and Fischer observed in 2007 that word-based
indexes often use fewer random accesses than character-based indexes, and thus
support faster searches. Since DNA lacks natural word-boundaries, however, it
is necessary to parse it somehow before applying word-based FM-indexing. Last
year, Deng et al.\ proposed parsing genomic data by induced suffix sorting, and
showed the resulting word-based FM-indexes support faster counting queries than
standard FM-indexes when patterns are a few thousand characters or longer. In
this paper we show that using prefix-free parsing -- which takes parameters
that let us tune the average length of the phrases -- instead of induced suffix
sorting, gives a significant speedup for patterns of only a few hundred
characters. We implement our method and demonstrate it is between 3 and 18
times faster than competing methods on queries to GRCh38. And was consistently
faster on queries made to 25,000, 50,000 and 100,000 SARS-CoV-2 genomes. Hence,
it is very clear that our method accelerates the performance of count over all
state-of-the-art methods with a minor increase in the memory. Our source code
is available at https://github.com/marco-oliva/afm .
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05953'>Novel Quantum Information Processing Methods and Investigation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhang Ze Yu</p><p>Quantum information processing and its subfield, quantum image processing,
are rapidly growing fields as a result of advancements in the practicality of
quantum mechanics. In this paper, we propose a quantum algorithm for processing
information, such as one-dimensional time series and two-dimensional images, in
the frequency domain. The information of interest is encoded into the magnitude
of probability amplitude or the coefficient of each basis state. The oracle for
filtering operates based on postselection results, and its explicit circuit
design is presented. This oracle is versatile enough to perform all basic
filtering, including high pass, low pass, band pass, band stop, and many other
processing techniques. Finally, we present two novel schemes for transposing
matrices in this paper. They use similar encoding rules but with deliberate
choices in terms of selecting basis states. These schemes could potentially be
useful for other quantum information processing tasks, such as edge detection.
The proposed techniques are implemented on the IBM Qiskit quantum simulator.
Some results are compared with traditional information processing results to
verify their correctness and are presented in this paper.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Yu_Z/0/1/0/all/0/1">Zhang Ze Yu</a></p><p>Quantum information processing and its subfield, quantum image processing,
are rapidly growing fields as a result of advancements in the practicality of
quantum mechanics. In this paper, we propose a quantum algorithm for processing
information, such as one-dimensional time series and two-dimensional images, in
the frequency domain. The information of interest is encoded into the magnitude
of probability amplitude or the coefficient of each basis state. The oracle for
filtering operates based on postselection results, and its explicit circuit
design is presented. This oracle is versatile enough to perform all basic
filtering, including high pass, low pass, band pass, band stop, and many other
processing techniques. Finally, we present two novel schemes for transposing
matrices in this paper. They use similar encoding rules but with deliberate
choices in terms of selecting basis states. These schemes could potentially be
useful for other quantum information processing tasks, such as edge detection.
The proposed techniques are implemented on the IBM Qiskit quantum simulator.
Some results are compared with traditional information processing results to
verify their correctness and are presented in this paper.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05972'>Coding for IBLTs with Listing Guarantees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniella Bar-Lev, Avi Mizrahi, Tuvi Etzion, Ori Rottenstreich, Eitan Yaakobi</p><p>The Invertible Bloom Lookup Table (IBLT) is a probabilistic data structure
for set representation, with applications in network and traffic monitoring. It
is known for its ability to list its elements, an operation that succeeds with
high probability for sufficiently large table. However, listing can fail even
for relatively small sets. This paper extends recent work on the worst-case
analysis of IBLT, which guarantees successful listing for all sets of a certain
size, by introducing more general IBLT schemes. These schemes allow for greater
freedom in the implementation of the insert, delete, and listing operations and
demonstrate that the IBLT memory can be reduced while still maintaining
successful listing guarantees. The paper also explores the time-memory
trade-off of these schemes, some of which are based on linear codes and
\(B_h\)-sequences over finite fields.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bar_Lev_D/0/1/0/all/0/1">Daniella Bar-Lev</a>, <a href="http://arxiv.org/find/cs/1/au:+Mizrahi_A/0/1/0/all/0/1">Avi Mizrahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Etzion_T/0/1/0/all/0/1">Tuvi Etzion</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottenstreich_O/0/1/0/all/0/1">Ori Rottenstreich</a>, <a href="http://arxiv.org/find/cs/1/au:+Yaakobi_E/0/1/0/all/0/1">Eitan Yaakobi</a></p><p>The Invertible Bloom Lookup Table (IBLT) is a probabilistic data structure
for set representation, with applications in network and traffic monitoring. It
is known for its ability to list its elements, an operation that succeeds with
high probability for sufficiently large table. However, listing can fail even
for relatively small sets. This paper extends recent work on the worst-case
analysis of IBLT, which guarantees successful listing for all sets of a certain
size, by introducing more general IBLT schemes. These schemes allow for greater
freedom in the implementation of the insert, delete, and listing operations and
demonstrate that the IBLT memory can be reduced while still maintaining
successful listing guarantees. The paper also explores the time-memory
trade-off of these schemes, some of which are based on linear codes and
\(B_h\)-sequences over finite fields.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05988'>Improving the performance of classical linear algebra iterative methods via hybrid parallelism</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pedro J. Martinez-Ferrer, Tufan Arslan, Vicen&#xe7; Beltran</p><p>We propose fork-join and task-based hybrid implementations of four classical
linear algebra iterative methods (Jacobi, Gauss-Seidel, conjugate gradient and
biconjugate gradient stabilised) as well as variations of them. Algorithms are
duly documented and the corresponding source code is made publicly available
for reproducibility. Both weak and strong scalability benchmarks are conducted
to statistically analyse their relative efficiencies.
</p>
<p>The weak scalability results assert the superiority of a task-based hybrid
parallelisation over MPI-only and fork-join hybrid implementations. Indeed, the
task-based model is able to achieve speedups of up to 25% larger than its
MPI-only counterpart depending on the numerical method and the computational
resources used. For strong scalability scenarios, hybrid methods based on tasks
remain more efficient with moderate computational resources where data locality
does not play an important role. Fork-join hybridisation often yields mixed
results and hence does not present a competitive advantage over a much simpler
MPI approach.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Martinez_Ferrer_P/0/1/0/all/0/1">Pedro J. Martinez-Ferrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Arslan_T/0/1/0/all/0/1">Tufan Arslan</a>, <a href="http://arxiv.org/find/cs/1/au:+Beltran_V/0/1/0/all/0/1">Vicen&#xe7; Beltran</a></p><p>We propose fork-join and task-based hybrid implementations of four classical
linear algebra iterative methods (Jacobi, Gauss-Seidel, conjugate gradient and
biconjugate gradient stabilised) as well as variations of them. Algorithms are
duly documented and the corresponding source code is made publicly available
for reproducibility. Both weak and strong scalability benchmarks are conducted
to statistically analyse their relative efficiencies.
</p>
<p>The weak scalability results assert the superiority of a task-based hybrid
parallelisation over MPI-only and fork-join hybrid implementations. Indeed, the
task-based model is able to achieve speedups of up to 25% larger than its
MPI-only counterpart depending on the numerical method and the computational
resources used. For strong scalability scenarios, hybrid methods based on tasks
remain more efficient with moderate computational resources where data locality
does not play an important role. Fork-join hybridisation often yields mixed
results and hence does not present a competitive advantage over a much simpler
MPI approach.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06067'>Pebble guided Treasure Hunt in Plane</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adri Bhattacharya, Barun Gorain, Partha Sarathi Mandal</p><p>We study the problem of treasure hunt in a Euclidean plane by a mobile agent
with the guidance of pebbles. The initial position of the agent and position of
the treasure are modeled as special points in the Euclidean plane. The treasure
is situated at a distance at most $D&gt;0$ from the initial position of the agent.
The agent has a perfect compass, but an adversary controls the speed of the
agent. Hence, the agent can not measure how much distance it traveled for a
given time. The agent can find the treasure only when it reaches the exact
position of the treasure. The cost of the treasure hunt is defined as the total
distance traveled by the agent before it finds the treasure. The agent has no
prior knowledge of the position of the treasure or the value of $D$. An Oracle,
which knows the treasure's position and the agent's initial location, places
some pebbles to guide the agent towards the treasure. Once decided to move
along some specified angular direction, the agent can decide to change its
direction only when it encounters a pebble or a special point.
</p>
<p>We ask the following central question in this paper:
</p>
<p>``For given $k \ge 0$, What is cheapest treasure hunt algorithm if at most
$k$ pebbles are placed by the Oracle?"
</p>
<p>We show that for $k=1$, there does not exist any treasure hunt algorithm that
finds the treasure with finite cost. We show the existence of an algorithm with
cost $O(D)$ for $k=2$. For $k&gt;8$ we have designed an algorithm that uses $k$
many pebbles to find the treasure with cost $O(k^{2}) + D(\sin\theta' +
\cos\theta')$, where $\theta'=\frac{\pi}{2^{k-8}}$. The second result shows the
existence of an algorithm with cost arbitrarily close to $D$ for sufficiently
large values of $D$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1">Adri Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorain_B/0/1/0/all/0/1">Barun Gorain</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandal_P/0/1/0/all/0/1">Partha Sarathi Mandal</a></p><p>We study the problem of treasure hunt in a Euclidean plane by a mobile agent
with the guidance of pebbles. The initial position of the agent and position of
the treasure are modeled as special points in the Euclidean plane. The treasure
is situated at a distance at most $D&gt;0$ from the initial position of the agent.
The agent has a perfect compass, but an adversary controls the speed of the
agent. Hence, the agent can not measure how much distance it traveled for a
given time. The agent can find the treasure only when it reaches the exact
position of the treasure. The cost of the treasure hunt is defined as the total
distance traveled by the agent before it finds the treasure. The agent has no
prior knowledge of the position of the treasure or the value of $D$. An Oracle,
which knows the treasure's position and the agent's initial location, places
some pebbles to guide the agent towards the treasure. Once decided to move
along some specified angular direction, the agent can decide to change its
direction only when it encounters a pebble or a special point.
</p>
<p>We ask the following central question in this paper:
</p>
<p>``For given $k \ge 0$, What is cheapest treasure hunt algorithm if at most
$k$ pebbles are placed by the Oracle?"
</p>
<p>We show that for $k=1$, there does not exist any treasure hunt algorithm that
finds the treasure with finite cost. We show the existence of an algorithm with
cost $O(D)$ for $k=2$. For $k&gt;8$ we have designed an algorithm that uses $k$
many pebbles to find the treasure with cost $O(k^{2}) + D(\sin\theta' +
\cos\theta')$, where $\theta'=\frac{\pi}{2^{k-8}}$. The second result shows the
existence of an algorithm with cost arbitrarily close to $D$ for sufficiently
large values of $D$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06120'>Average Awake Complexity of MIS and Matching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Ghaffari, Julian Portmann</p><p>Chatterjee, Gmyr, and Pandurangan [PODC 2020] recently introduced the notion
of awake complexity for distributed algorithms, which measures the number of
rounds in which a node is awake. In the other rounds, the node is sleeping and
performs no computation or communication. Measuring the number of awake rounds
can be of significance in many settings of distributed computing, e.g., in
sensor networks where energy consumption is of concern.
</p>
<p>In that paper, Chatterjee et al. provide an elegant randomized algorithm for
the Maximal Independent Set (MIS) problem that achieves an $O(1)$ node-averaged
awake complexity. That is, the average awake time among the nodes is $O(1)$
rounds. However, to achieve that, the algorithm sacrifices the more standard
round complexity measure from the well-known $O(\log n)$ bound of MIS, due to
Luby [STOC'85], to $O(\log^{3.41} n)$ rounds.
</p>
<p>Our first contribution is to present a simple randomized distributed MIS
algorithm that, with high probability, has $O(1)$ node-averaged awake
complexity and $O(\log n)$ worst-case round complexity. Our second, and more
technical contribution, is to show algorithms with the same $O(1)$
node-averaged awake complexity and $O(\log n)$ worst-case round complexity for
$(1+\varepsilon)$-approximation of maximum matching and
$(2+\varepsilon)$-approximation of minimum vertex cover, where $\varepsilon$
denotes an arbitrary small positive constant.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Portmann_J/0/1/0/all/0/1">Julian Portmann</a></p><p>Chatterjee, Gmyr, and Pandurangan [PODC 2020] recently introduced the notion
of awake complexity for distributed algorithms, which measures the number of
rounds in which a node is awake. In the other rounds, the node is sleeping and
performs no computation or communication. Measuring the number of awake rounds
can be of significance in many settings of distributed computing, e.g., in
sensor networks where energy consumption is of concern.
</p>
<p>In that paper, Chatterjee et al. provide an elegant randomized algorithm for
the Maximal Independent Set (MIS) problem that achieves an $O(1)$ node-averaged
awake complexity. That is, the average awake time among the nodes is $O(1)$
rounds. However, to achieve that, the algorithm sacrifices the more standard
round complexity measure from the well-known $O(\log n)$ bound of MIS, due to
Luby [STOC'85], to $O(\log^{3.41} n)$ rounds.
</p>
<p>Our first contribution is to present a simple randomized distributed MIS
algorithm that, with high probability, has $O(1)$ node-averaged awake
complexity and $O(\log n)$ worst-case round complexity. Our second, and more
technical contribution, is to show algorithms with the same $O(1)$
node-averaged awake complexity and $O(\log n)$ worst-case round complexity for
$(1+\varepsilon)$-approximation of maximum matching and
$(2+\varepsilon)$-approximation of minimum vertex cover, where $\varepsilon$
denotes an arbitrary small positive constant.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.06198'>Optimal mixing of the down-up walk on independent sets of a given size</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vishesh Jain, Marcus Michelen, Huy Tuan Pham, Thuy-Duong Vuong</p><p>Let $G$ be a graph on $n$ vertices of maximum degree $\Delta$. We show that,
for any $\delta &gt; 0$, the down-up walk on independent sets of size $k \leq
(1-\delta)\alpha_c(\Delta)n$ mixes in time $O_{\Delta,\delta}(k\log{n})$,
thereby resolving a conjecture of Davies and Perkins in an optimal form. Here,
$\alpha_{c}(\Delta)n$ is the NP-hardness threshold for the problem of counting
independent sets of a given size in a graph on $n$ vertices of maximum degree
$\Delta$. Our mixing time has optimal dependence on $k,n$ for the entire range
of $k$; previously, even polynomial mixing was not known. In fact, for $k =
\Omega_{\Delta}(n)$ in this range, we establish a log-Sobolev inequality with
optimal constant $\Omega_{\Delta,\delta}(1/n)$.
</p>
<p>At the heart of our proof are three new ingredients, which may be of
independent interest. The first is a method for lifting
$\ell_\infty$-independence from a suitable distribution on the discrete cube --
in this case, the hard-core model -- to the slice by proving stability of an
Edgeworth expansion using a multivariate zero-free region for the base
distribution. The second is a generalization of the Lee-Yau induction to prove
log-Sobolev inequalities for distributions on the slice with considerably less
symmetry than the uniform distribution. The third is a sharp decomposition-type
result which provides a lossless comparison between the Dirichlet form of the
original Markov chain and that of the so-called projected chain in the presence
of a contractive coupling.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1">Vishesh Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Michelen_M/0/1/0/all/0/1">Marcus Michelen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Huy Tuan Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Vuong_T/0/1/0/all/0/1">Thuy-Duong Vuong</a></p><p>Let $G$ be a graph on $n$ vertices of maximum degree $\Delta$. We show that,
for any $\delta &gt; 0$, the down-up walk on independent sets of size $k \leq
(1-\delta)\alpha_c(\Delta)n$ mixes in time $O_{\Delta,\delta}(k\log{n})$,
thereby resolving a conjecture of Davies and Perkins in an optimal form. Here,
$\alpha_{c}(\Delta)n$ is the NP-hardness threshold for the problem of counting
independent sets of a given size in a graph on $n$ vertices of maximum degree
$\Delta$. Our mixing time has optimal dependence on $k,n$ for the entire range
of $k$; previously, even polynomial mixing was not known. In fact, for $k =
\Omega_{\Delta}(n)$ in this range, we establish a log-Sobolev inequality with
optimal constant $\Omega_{\Delta,\delta}(1/n)$.
</p>
<p>At the heart of our proof are three new ingredients, which may be of
independent interest. The first is a method for lifting
$\ell_\infty$-independence from a suitable distribution on the discrete cube --
in this case, the hard-core model -- to the slice by proving stability of an
Edgeworth expansion using a multivariate zero-free region for the base
distribution. The second is a generalization of the Lee-Yau induction to prove
log-Sobolev inequalities for distributions on the slice with considerably less
symmetry than the uniform distribution. The third is a sharp decomposition-type
result which provides a lossless comparison between the Dirichlet form of the
original Markov chain and that of the so-called projected chain in the presence
of a contractive coupling.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-11T00:30:00Z">Thursday, May 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, May 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7299'>Robin Hanson and I discuss the AI future</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          That&#8217;s all. No real post this morning, just an hour-long podcast on YouTube featuring two decades-long veterans of the nerd blogosphere, Robin Hanson and yours truly, talking about AI, trying to articulate various possibilities outside the Yudkowskyan doom scenario. The podcast was Robin&#8217;s idea. Hope you enjoy, and looking forward to your comments! Update: Oh, [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>That&#8217;s all.  No real post this morning, just an <a href="https://www.youtube.com/watch?v=GANvcj019S0">hour-long podcast on YouTube</a> featuring two decades-long veterans of the nerd blogosphere, Robin Hanson and yours truly, talking about AI, trying to articulate various possibilities outside the Yudkowskyan doom scenario.  The podcast was Robin&#8217;s idea.  Hope you enjoy, and looking forward to your comments!</p>



<p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Update: </mark></strong>Oh, and <a href="https://share.transistor.fm/s/33bf25d3">another new podcast</a> is up, with me and Sebastian Hassinger of Amazon/AWS!  Audio only.  Mostly quantum computing but with a little AI thrown in.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T13:59:59Z">Wednesday, May 10 2023, 13:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/05/10/phd-postdoc-at-hasso-plattner-institute-apply-by-may-31-2023/'>PhD, Postdoc at Hasso Plattner Institute (apply by May 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Algorithm Engineering group at the Hasso Plattner Institute (HPI) currently hosts about thirty researchers and invites applications for two new Ph.D. Students and/or Postdoctoral Researchers in Algorithms. Website: hpi.de/offers/2023/may-31.html Email: Timo.Koetzing@hpi.de
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Algorithm Engineering group at the Hasso Plattner Institute (HPI) currently hosts about thirty researchers and invites applications for two new Ph.D. Students and/or Postdoctoral Researchers in Algorithms.</p>
<p>Website: <a href="https://hpi.de/offers/2023/may-31.html">https://hpi.de/offers/2023/may-31.html</a><br />
Email: Timo.Koetzing@hpi.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T13:13:11Z">Wednesday, May 10 2023, 13:13</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.04983'>Low-Degree Testing Over Grids</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prashanth Amireddy, Srikanth Srinivasan, Madhu Sudan</p><p>We study the question of local testability of low (constant) degree functions
from a product domain $S_1 \times \dots \times {S}_n$ to a field $\mathbb{F}$,
where ${S_i} \subseteq \mathbb{F}$ can be arbitrary constant sized sets. We
show that this family is locally testable when the grid is "symmetric". That
is, if ${S_i} = {S}$ for all i, there is a probabilistic algorithm using
constantly many queries that distinguishes whether $f$ has a polynomial
representation of degree at most $d$ or is $\Omega(1)$-far from having this
property. In contrast, we show that there exist asymmetric grids with $|{S}_1|
=\dots= |{S}_n| = 3$ for which testing requires $\omega_n(1)$ queries, thereby
establishing that even in the context of polynomials, local testing depends on
the structure of the domain and not just the distance of the underlying code.
</p>
<p>The low-degree testing problem has been studied extensively over the years
and a wide variety of tools have been applied to propose and analyze tests. Our
work introduces yet another new connection in this rich field, by building
low-degree tests out of tests for "junta-degrees". A function $f : {S}_1 \times
\dots \times {S}_n \to {G}$, for an abelian group ${G}$ is said to be a
junta-degree-$d$ function if it is a sum of $d$-juntas. We derive our
low-degree test by giving a new local test for junta-degree-$d$ functions. For
the analysis of our tests, we deduce a small-set expansion theorem for
spherical noise over large grids, which may be of independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Amireddy_P/0/1/0/all/0/1">Prashanth Amireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1">Srikanth Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudan_M/0/1/0/all/0/1">Madhu Sudan</a></p><p>We study the question of local testability of low (constant) degree functions
from a product domain $S_1 \times \dots \times {S}_n$ to a field $\mathbb{F}$,
where ${S_i} \subseteq \mathbb{F}$ can be arbitrary constant sized sets. We
show that this family is locally testable when the grid is "symmetric". That
is, if ${S_i} = {S}$ for all i, there is a probabilistic algorithm using
constantly many queries that distinguishes whether $f$ has a polynomial
representation of degree at most $d$ or is $\Omega(1)$-far from having this
property. In contrast, we show that there exist asymmetric grids with $|{S}_1|
=\dots= |{S}_n| = 3$ for which testing requires $\omega_n(1)$ queries, thereby
establishing that even in the context of polynomials, local testing depends on
the structure of the domain and not just the distance of the underlying code.
</p>
<p>The low-degree testing problem has been studied extensively over the years
and a wide variety of tools have been applied to propose and analyze tests. Our
work introduces yet another new connection in this rich field, by building
low-degree tests out of tests for "junta-degrees". A function $f : {S}_1 \times
\dots \times {S}_n \to {G}$, for an abelian group ${G}$ is said to be a
junta-degree-$d$ function if it is a sum of $d$-juntas. We derive our
low-degree test by giving a new local test for junta-degree-$d$ functions. For
the analysis of our tests, we deduce a small-set expansion theorem for
spherical noise over large grids, which may be of independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05011'>In Honour of Ted Swart</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Stephen Gismondi</p><p>This is a tribute to my dear life-long friend, mentor and colleague Ted
Swart. It includes anecdotal stories and memories of our times together, and
also includes a new academic contribution in his honour, Teds polytope. Tweeks
made to the Birkhoff polytope Bn endow Teds polytope Tn({\epsilon}) with a
special tunable parameter {\epsilon} = {\epsilon}(n). Observe how Bn can be
viewed as the convex hull of both the TSP polytope, and the set of non-tour
permutation extrema, and, that its extended formulation is compact. Tours
(connected 2-factor permutation matrices when viewed as adjacency matrices) can
be distinguished from non-tours (disconnected 2-factor permutation matrices)
where {\epsilon} scales the magnitude of tweeks made to Bn. For {\epsilon} &gt; 0,
Tn({\epsilon}) is tuned so that the convex hull of extrema corresponding to
transformed tours is lifted from Bn, and separated (by a hyperplane) from the
convex hull of extrema corresponding to translated non-tours. This leads to
creation of the feasible region of an LP model that can decide existence of a
tour in a graph based on an extended formulation of the TSP polytope. That is,
by designing for polynomial-time distinguishable tour extrema embedded in a
subspace disjoint from non-tour extrema, NP-completeness strongholds come into
play, necessarily expressed in a non-compact extended formulation of
Tn({\epsilon}) i.e. a compact extended formulation of the TSP polytope cannot
exist. No matter, Ted would have loved these ideas, and Tn({\epsilon}) might
one day yet be useful in the study of the P versus NP conundrum. In summary,
Tn({\epsilon}) is a perturbed Bn i.e. the convex hull of both an
{\epsilon}-stretched TSP polytope, and the set of translated non-tour
permutation extrema i.e. a TSP-like polytope and separable non-tour extrema.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gismondi_S/0/1/0/all/0/1">Stephen Gismondi</a></p><p>This is a tribute to my dear life-long friend, mentor and colleague Ted
Swart. It includes anecdotal stories and memories of our times together, and
also includes a new academic contribution in his honour, Teds polytope. Tweeks
made to the Birkhoff polytope Bn endow Teds polytope Tn({\epsilon}) with a
special tunable parameter {\epsilon} = {\epsilon}(n). Observe how Bn can be
viewed as the convex hull of both the TSP polytope, and the set of non-tour
permutation extrema, and, that its extended formulation is compact. Tours
(connected 2-factor permutation matrices when viewed as adjacency matrices) can
be distinguished from non-tours (disconnected 2-factor permutation matrices)
where {\epsilon} scales the magnitude of tweeks made to Bn. For {\epsilon} &gt; 0,
Tn({\epsilon}) is tuned so that the convex hull of extrema corresponding to
transformed tours is lifted from Bn, and separated (by a hyperplane) from the
convex hull of extrema corresponding to translated non-tours. This leads to
creation of the feasible region of an LP model that can decide existence of a
tour in a graph based on an extended formulation of the TSP polytope. That is,
by designing for polynomial-time distinguishable tour extrema embedded in a
subspace disjoint from non-tour extrema, NP-completeness strongholds come into
play, necessarily expressed in a non-compact extended formulation of
Tn({\epsilon}) i.e. a compact extended formulation of the TSP polytope cannot
exist. No matter, Ted would have loved these ideas, and Tn({\epsilon}) might
one day yet be useful in the study of the P versus NP conundrum. In summary,
Tn({\epsilon}) is a perturbed Bn i.e. the convex hull of both an
{\epsilon}-stretched TSP polytope, and the set of translated non-tour
permutation extrema i.e. a TSP-like polytope and separable non-tour extrema.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05415'>Scheme-Theoretic Approach to Computational Complexity. III. SETH</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ali &#xc7;ivril</p><p>We show that there exist infinitely many $n \in \mathbb{Z}^+$ such that for
any constant $\epsilon &gt; 0$, any deterministic algorithm to solve
$k$-\textsf{SAT} for $k \geq 3$ must perform at least
$(2^{k-\frac{3}{2}-\epsilon})^{\frac{n}{k+1}}$ operations, where $n$ is the
number of variables in the $k$\textsf{-SAT} instance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Civril_A/0/1/0/all/0/1">Ali &#xc7;ivril</a></p><p>We show that there exist infinitely many $n \in \mathbb{Z}^+$ such that for
any constant $\epsilon &gt; 0$, any deterministic algorithm to solve
$k$-\textsf{SAT} for $k \geq 3$ must perform at least
$(2^{k-\frac{3}{2}-\epsilon})^{\frac{n}{k+1}}$ operations, where $n$ is the
number of variables in the $k$\textsf{-SAT} instance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05055'>CPMA: An Efficient Batch-Parallel Compressed Set Without Pointers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Brian Wheatman, Randal Burns, Ayd&#x131;n Bulu&#xe7;, Helen Xu</p><p>This paper introduces the batch-parallel Compressed Packed Memory Array
(CPMA), a compressed dynamic ordered batch-parallel set data structure based on
the Packed Memory Array (PMA). Traditionally, batch-parallel sets are built on
pointer-based data structures such as trees because pointer-based structures
enable fast parallel unions via pointer manipulation. When compared to
cache-optimized trees, PMAs were slower to update but faster to scan.
</p>
<p>The batch-parallel CPMA overcomes this tradeoff between updates and scans by
optimizing for cache-friendliness. On average, the CPMA is faster than
compressed PaC-trees, a state-of-the-art batch-parallel set library based on
cache-optimized trees, by 1.2x on range queries and 3x on batch updates.
</p>
<p>We further evaluate the CPMA compared to compressed PaC-trees on a real-world
application of dynamic graph processing. The CPMA is on average 1.2x faster on
a suite of graph algorithms and 2x faster on batch inserts for graphs when
compared with compressed PaC-trees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wheatman_B/0/1/0/all/0/1">Brian Wheatman</a>, <a href="http://arxiv.org/find/cs/1/au:+Burns_R/0/1/0/all/0/1">Randal Burns</a>, <a href="http://arxiv.org/find/cs/1/au:+Buluc_A/0/1/0/all/0/1">Ayd&#x131;n Bulu&#xe7;</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Helen Xu</a></p><p>This paper introduces the batch-parallel Compressed Packed Memory Array
(CPMA), a compressed dynamic ordered batch-parallel set data structure based on
the Packed Memory Array (PMA). Traditionally, batch-parallel sets are built on
pointer-based data structures such as trees because pointer-based structures
enable fast parallel unions via pointer manipulation. When compared to
cache-optimized trees, PMAs were slower to update but faster to scan.
</p>
<p>The batch-parallel CPMA overcomes this tradeoff between updates and scans by
optimizing for cache-friendliness. On average, the CPMA is faster than
compressed PaC-trees, a state-of-the-art batch-parallel set library based on
cache-optimized trees, by 1.2x on range queries and 3x on batch updates.
</p>
<p>We further evaluate the CPMA compared to compressed PaC-trees on a real-world
application of dynamic graph processing. The CPMA is on average 1.2x faster on
a suite of graph algorithms and 2x faster on batch inserts for graphs when
compared with compressed PaC-trees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05074'>Autumn: A Scalable Read Optimized LSM-tree based Key-Value Stores with Fast Point and Range Read Speed</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fuheng Zhao, Leron Reznikov, Divyakant Agrawal, Amr El Abbadi</p><p>The Log Structured Merge Trees (LSM-tree) based key-value stores are widely
used in many storage systems to support a variety of operations such as
updates, point reads, and range reads. Traditionally, LSM-tree's merge policy
organizes data into multiple levels of exponentially increasing capacity to
support high-speed writes. However, we contend that the traditional merge
policies are not optimized for reads. In this work, we present Autumn, a
scalable and read optimized LSM-tree based key-value stores with minimal point
and range read cost. The key idea in improving the read performance is to
dynamically adjust the capacity ratio between two adjacent levels as more data
are stored. As a result, smaller levels gradually increase their capacities and
merge more often. In particular, the point and range read cost improves from
the previous best known $O(logN)$ complexity to $O(\sqrt{logN})$ in Autumn by
applying the new novel Garnering merge policy. While Garnering merge policy
optimizes for both point reads and range reads, it maintains high performance
for updates. Moreover, to further improve the update costs, Autumn uses a small
amount of bounded space of DRAM to pin/keep the first level of LSM-tree. We
implemented Autumn on top of LevelDB and experimentally showcases the gain in
performance for real world workloads.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Fuheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Reznikov_L/0/1/0/all/0/1">Leron Reznikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_D/0/1/0/all/0/1">Divyakant Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbadi_A/0/1/0/all/0/1">Amr El Abbadi</a></p><p>The Log Structured Merge Trees (LSM-tree) based key-value stores are widely
used in many storage systems to support a variety of operations such as
updates, point reads, and range reads. Traditionally, LSM-tree's merge policy
organizes data into multiple levels of exponentially increasing capacity to
support high-speed writes. However, we contend that the traditional merge
policies are not optimized for reads. In this work, we present Autumn, a
scalable and read optimized LSM-tree based key-value stores with minimal point
and range read cost. The key idea in improving the read performance is to
dynamically adjust the capacity ratio between two adjacent levels as more data
are stored. As a result, smaller levels gradually increase their capacities and
merge more often. In particular, the point and range read cost improves from
the previous best known $O(logN)$ complexity to $O(\sqrt{logN})$ in Autumn by
applying the new novel Garnering merge policy. While Garnering merge policy
optimizes for both point reads and range reads, it maintains high performance
for updates. Moreover, to further improve the update costs, Autumn uses a small
amount of bounded space of DRAM to pin/keep the first level of LSM-tree. We
implemented Autumn on top of LevelDB and experimentally showcases the gain in
performance for real world workloads.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05121'>Memory-Efficient Solutions to Large-Graph MST Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arjun Bhalla</p><p>Minimum Spanning Trees are a well-studied subset of graph problems. While
classical algorithms have existed to solve these problems for decades, new
variations and application areas are constantly being discovered. When dealing
with large graph problems, however, memory constraints can often be limiting,
especially when using these classical methods in memory restricted
environments. In this work, we propose an augmentation of Prim's algorithm that
can be empirically shown to solve MST problems with a reduction in auxiliary
memory usage of over 90%, and a margin of error of less than 0.3%.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhalla_A/0/1/0/all/0/1">Arjun Bhalla</a></p><p>Minimum Spanning Trees are a well-studied subset of graph problems. While
classical algorithms have existed to solve these problems for decades, new
variations and application areas are constantly being discovered. When dealing
with large graph problems, however, memory constraints can often be limiting,
especially when using these classical methods in memory restricted
environments. In this work, we propose an augmentation of Prim's algorithm that
can be empirically shown to solve MST problems with a reduction in auxiliary
memory usage of over 90%, and a margin of error of less than 0.3%.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05129'>Sorting Finite Automata via Partition Refinement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ruben Becker, Manuel C&#xe1;ceres, Davide Cenzato, Sung-Hwan Kim, Bojana Kodric, Francisco Olivares, Nicola Prezza</p><p>Wheeler nondeterministic finite automata (WNFAs) were introduced as a
generalization of prefix sorting from strings to labeled graphs. WNFAs admit
optimal solutions to classic hard problems on labeled graphs and languages. The
problem of deciding whether a given NFA is Wheeler is known to be NP-complete.
Recently, however, Alanko et al. showed how to side-step this complexity by
switching to preorders: letting $Q$ be the set of states, $E$ the set of
transitions, $|Q|=n$, and $|E|=m$, they provided a $O(mn^2)$-time algorithm
computing a totally-ordered partition of the WNFA's states such that (1)
equivalent states recognize the same regular language, and (2) the order of
non-equivalent states is consistent with any Wheeler order, when one exists.
Then, the output is a preorder of the states as useful for pattern matching as
standard Wheeler orders. Further research generalized these concepts to
arbitrary NFAs by introducing co-lex partial preorders: any NFA admits a
partial preorder of its states reflecting the co-lex order of their accepted
strings; the smaller the width of such preorder is, the faster regular
expression matching queries can be performed. To date, the fastest algorithm
for computing the smallest-width partial preorder on NFAs runs in
$O(m^2+n^{5/2})$ time, while on DFAs the same can be done in $O(\min(n^2\log
n,mn))$ time. In this paper, we provide much more efficient solutions to the
problem above. Our results are achieved by extending a classic algorithm for
the relational coarsest partition refinement problem to work with ordered
partitions. Specifically, we provide a $O(m\log n)$-time algorithm computing a
co-lex total preorder when the input is a WNFA, and an algorithm with the same
time complexity computing the smallest-width co-lex partial order of any DFA.
Also, we present implementations of our algorithms and show that they are very
efficient in practice.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Becker_R/0/1/0/all/0/1">Ruben Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Caceres_M/0/1/0/all/0/1">Manuel C&#xe1;ceres</a>, <a href="http://arxiv.org/find/cs/1/au:+Cenzato_D/0/1/0/all/0/1">Davide Cenzato</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sung-Hwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kodric_B/0/1/0/all/0/1">Bojana Kodric</a>, <a href="http://arxiv.org/find/cs/1/au:+Olivares_F/0/1/0/all/0/1">Francisco Olivares</a>, <a href="http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1">Nicola Prezza</a></p><p>Wheeler nondeterministic finite automata (WNFAs) were introduced as a
generalization of prefix sorting from strings to labeled graphs. WNFAs admit
optimal solutions to classic hard problems on labeled graphs and languages. The
problem of deciding whether a given NFA is Wheeler is known to be NP-complete.
Recently, however, Alanko et al. showed how to side-step this complexity by
switching to preorders: letting $Q$ be the set of states, $E$ the set of
transitions, $|Q|=n$, and $|E|=m$, they provided a $O(mn^2)$-time algorithm
computing a totally-ordered partition of the WNFA's states such that (1)
equivalent states recognize the same regular language, and (2) the order of
non-equivalent states is consistent with any Wheeler order, when one exists.
Then, the output is a preorder of the states as useful for pattern matching as
standard Wheeler orders. Further research generalized these concepts to
arbitrary NFAs by introducing co-lex partial preorders: any NFA admits a
partial preorder of its states reflecting the co-lex order of their accepted
strings; the smaller the width of such preorder is, the faster regular
expression matching queries can be performed. To date, the fastest algorithm
for computing the smallest-width partial preorder on NFAs runs in
$O(m^2+n^{5/2})$ time, while on DFAs the same can be done in $O(\min(n^2\log
n,mn))$ time. In this paper, we provide much more efficient solutions to the
problem above. Our results are achieved by extending a classic algorithm for
the relational coarsest partition refinement problem to work with ordered
partitions. Specifically, we provide a $O(m\log n)$-time algorithm computing a
co-lex total preorder when the input is a WNFA, and an algorithm with the same
time complexity computing the smallest-width co-lex partial order of any DFA.
Also, we present implementations of our algorithms and show that they are very
efficient in practice.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05353'>Constant-Competitiveness for Random Assignment Matroid Secretary Without Knowing the Matroid</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Richard Santiago, Ivan Sergeev, Rico Zenklusen</p><p>The Matroid Secretary Conjecture is a notorious open problem in online
optimization. It claims the existence of an $O(1)$-competitive algorithm for
the Matroid Secretary Problem (MSP). Here, the elements of a weighted matroid
appear one-by-one, revealing their weight at appearance, and the task is to
select elements online with the goal to get an independent set of largest
possible weight. $O(1)$-competitive MSP algorithms have so far only been
obtained for restricted matroid classes and for MSP variations, including
Random-Assignment MSP (RA-MSP), where an adversary fixes a number of weights
equal to the ground set size of the matroid, which then get assigned randomly
to the elements of the ground set. Unfortunately, these approaches heavily rely
on knowing the full matroid upfront. This is an arguably undesirable
requirement, and there are good reasons to believe that an approach towards
resolving the MSP Conjecture should not rely on it. Thus, both Soto [SIAM
Journal on Computing 2013] and Oveis Gharan &amp; Vondrak [Algorithmica 2013]
raised as an open question whether RA-MSP admits an $O(1)$-competitive
algorithm even without knowing the matroid upfront.
</p>
<p>In this work, we answer this question affirmatively. Our result makes RA-MSP
the first well-known MSP variant with an $O(1)$-competitive algorithm that does
not need to know the underlying matroid upfront and without any restriction on
the underlying matroid. Our approach is based on first approximately learning
the rank-density curve of the matroid, which we then exploit algorithmically.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Santiago_R/0/1/0/all/0/1">Richard Santiago</a>, <a href="http://arxiv.org/find/cs/1/au:+Sergeev_I/0/1/0/all/0/1">Ivan Sergeev</a>, <a href="http://arxiv.org/find/cs/1/au:+Zenklusen_R/0/1/0/all/0/1">Rico Zenklusen</a></p><p>The Matroid Secretary Conjecture is a notorious open problem in online
optimization. It claims the existence of an $O(1)$-competitive algorithm for
the Matroid Secretary Problem (MSP). Here, the elements of a weighted matroid
appear one-by-one, revealing their weight at appearance, and the task is to
select elements online with the goal to get an independent set of largest
possible weight. $O(1)$-competitive MSP algorithms have so far only been
obtained for restricted matroid classes and for MSP variations, including
Random-Assignment MSP (RA-MSP), where an adversary fixes a number of weights
equal to the ground set size of the matroid, which then get assigned randomly
to the elements of the ground set. Unfortunately, these approaches heavily rely
on knowing the full matroid upfront. This is an arguably undesirable
requirement, and there are good reasons to believe that an approach towards
resolving the MSP Conjecture should not rely on it. Thus, both Soto [SIAM
Journal on Computing 2013] and Oveis Gharan &amp; Vondrak [Algorithmica 2013]
raised as an open question whether RA-MSP admits an $O(1)$-competitive
algorithm even without knowing the matroid upfront.
</p>
<p>In this work, we answer this question affirmatively. Our result makes RA-MSP
the first well-known MSP variant with an $O(1)$-competitive algorithm that does
not need to know the underlying matroid upfront and without any restriction on
the underlying matroid. Our approach is based on first approximately learning
the rank-density curve of the matroid, which we then exploit algorithmically.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05398'>An Improved Approximation Algorithm for the Minimum 2-Vertex-Connected Spanning Subgraph Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ali &#xc7;ivril</p><p>We provide an algorithm for the minimum 2-vertex-connected spanning subgraph
problem with approximation ratio $\frac{4}{3}$, improving upon the previous
best factor $\frac{10}{7}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Civril_A/0/1/0/all/0/1">Ali &#xc7;ivril</a></p><p>We provide an algorithm for the minimum 2-vertex-connected spanning subgraph
problem with approximation ratio $\frac{4}{3}$, improving upon the previous
best factor $\frac{10}{7}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05411'>4/3-Approximation of Graphic TSP</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ali &#xc7;ivril</p><p>We describe a $\frac{4}{3}$-approximation algorithm for the traveling
salesman problem in which the distances between points are induced by
graph-theoretical distances in an unweighted graph. The algorithm is based on
finding a minimum cost perfect matching on the odd degree vertices of a
carefully computed 2-edge-connected spanning subgraph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Civril_A/0/1/0/all/0/1">Ali &#xc7;ivril</a></p><p>We describe a $\frac{4}{3}$-approximation algorithm for the traveling
salesman problem in which the distances between points are induced by
graph-theoretical distances in an unweighted graph. The algorithm is based on
finding a minimum cost perfect matching on the odd degree vertices of a
carefully computed 2-edge-connected spanning subgraph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05417'>Fast Many-to-Many Routing for Ridesharing with Multiple Pickup and Dropoff Locations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Moritz Laupichler, Peter Sanders</p><p>We introduce KaRRi, an improved algorithm for scheduling a fleet of shared
vehicles as it is used by services like UberXShare and Lyft Shared. We speed up
the basic online algorithm that looks for all possible insertions of a new
customer into a set of existing routes, we generalize the objective function,
and efficiently support a large number of possible pick-up and drop-off
locations. This lays an algorithmic foundation for ridesharing systems with
higher vehicle occupancy -- enabling greatly reduced cost and ecological impact
at comparable service quality. We find that our algorithm computes assignments
between vehicles and riders several times faster than a previous
state-of-the-art approach. Further, we observe that allowing meeting points for
vehicles and riders can reduce the operating cost of vehicle fleets by up to
$15\%$ while also reducing passenger wait and trip times.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Laupichler_M/0/1/0/all/0/1">Moritz Laupichler</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanders_P/0/1/0/all/0/1">Peter Sanders</a></p><p>We introduce KaRRi, an improved algorithm for scheduling a fleet of shared
vehicles as it is used by services like UberXShare and Lyft Shared. We speed up
the basic online algorithm that looks for all possible insertions of a new
customer into a set of existing routes, we generalize the objective function,
and efficiently support a large number of possible pick-up and drop-off
locations. This lays an algorithmic foundation for ridesharing systems with
higher vehicle occupancy -- enabling greatly reduced cost and ecological impact
at comparable service quality. We find that our algorithm computes assignments
between vehicles and riders several times faster than a previous
state-of-the-art approach. Further, we observe that allowing meeting points for
vehicles and riders can reduce the operating cost of vehicle fleets by up to
$15\%$ while also reducing passenger wait and trip times.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05487'>Testing versus estimation of graph properties, revisited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lior Gishboliner, Nick Kushnir, Asaf Shapira</p><p>A distance estimator for a graph property $\mathcal{P}$ is an algorithm that
given $G$ and $\alpha, \varepsilon &gt;0$ distinguishes between the case that $G$
is $(\alpha-\varepsilon)$-close to $\mathcal{P}$ and the case that $G$ is
$\alpha$-far from $\mathcal{P}$ (in edit distance). We say that $\mathcal{P}$
is estimable if it has a distance estimator whose query complexity depends only
on $\varepsilon$.
</p>
<p>Every estimable property is also testable, since testing corresponds to
estimating with $\alpha=\varepsilon$. A central result in the area of property
testing, the Fischer--Newman theorem, gives an inverse statement: every
testable property is in fact estimable. The proof of Fischer and Newman was
highly ineffective, since it incurred a tower-type loss when transforming a
testing algorithm for $\mathcal{P}$ into a distance estimator. This raised the
natural problem, studied recently by Fiat--Ron and by
Hoppen--Kohayakawa--Lang--Lefmann--Stagni, whether one can find a
transformation with a polynomial loss. We obtain the following results.
</p>
<p>1. If $\mathcal{P}$ is hereditary, then one can turn a tester for
$\mathcal{P}$ into a distance estimator with an exponential loss. This is an
exponential improvement over the result of Hoppen et. al., who obtained a
transformation with a double exponential loss.
</p>
<p>2. For every $\mathcal{P}$, one can turn a testing algorithm for
$\mathcal{P}$ into a distance estimator with a double exponential loss. This
improves over the transformation of Fischer--Newman that incurred a tower-type
loss. Our main conceptual contribution in this work is that we manage to turn
the approach of Fischer--Newman, which was inherently ineffective, into an
efficient one. On the technical level, our main contribution is in establishing
certain properties of Frieze--Kannan Weak Regular partitions that are of
independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gishboliner_L/0/1/0/all/0/1">Lior Gishboliner</a>, <a href="http://arxiv.org/find/math/1/au:+Kushnir_N/0/1/0/all/0/1">Nick Kushnir</a>, <a href="http://arxiv.org/find/math/1/au:+Shapira_A/0/1/0/all/0/1">Asaf Shapira</a></p><p>A distance estimator for a graph property $\mathcal{P}$ is an algorithm that
given $G$ and $\alpha, \varepsilon &gt;0$ distinguishes between the case that $G$
is $(\alpha-\varepsilon)$-close to $\mathcal{P}$ and the case that $G$ is
$\alpha$-far from $\mathcal{P}$ (in edit distance). We say that $\mathcal{P}$
is estimable if it has a distance estimator whose query complexity depends only
on $\varepsilon$.
</p>
<p>Every estimable property is also testable, since testing corresponds to
estimating with $\alpha=\varepsilon$. A central result in the area of property
testing, the Fischer--Newman theorem, gives an inverse statement: every
testable property is in fact estimable. The proof of Fischer and Newman was
highly ineffective, since it incurred a tower-type loss when transforming a
testing algorithm for $\mathcal{P}$ into a distance estimator. This raised the
natural problem, studied recently by Fiat--Ron and by
Hoppen--Kohayakawa--Lang--Lefmann--Stagni, whether one can find a
transformation with a polynomial loss. We obtain the following results.
</p>
<p>1. If $\mathcal{P}$ is hereditary, then one can turn a tester for
$\mathcal{P}$ into a distance estimator with an exponential loss. This is an
exponential improvement over the result of Hoppen et. al., who obtained a
transformation with a double exponential loss.
</p>
<p>2. For every $\mathcal{P}$, one can turn a testing algorithm for
$\mathcal{P}$ into a distance estimator with a double exponential loss. This
improves over the transformation of Fischer--Newman that incurred a tower-type
loss. Our main conceptual contribution in this work is that we manage to turn
the approach of Fischer--Newman, which was inherently ineffective, into an
efficient one. On the technical level, our main contribution is in establishing
certain properties of Frieze--Kannan Weak Regular partitions that are of
independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.05565'>Greedy Heuristics and Linear Relaxations for the Random Hitting Set Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gabriel Arpino, Daniil Dmitriev, Nicolo Grometto</p><p>Consider the Hitting Set problem where, for a given universe $\mathcal{X} =
\left\{ 1, ... , n \right\}$ and a collection of subsets $\mathcal{S}_1, ... ,
\mathcal{S}_m$, one seeks to identify the smallest subset of $\mathcal{X}$
which has nonempty intersection with every element in the collection. We study
a probabilistic formulation of this problem, where the underlying subsets are
formed by including each element of the universe with probability $p$,
independently of one another. For large enough values of $n$, we rigorously
analyse the average case performance of Lov\'asz's celebrated greedy algorithm
(Lov\'asz, 1975) with respect to the chosen input distribution. In addition, we
study integrality gaps between linear programming and integer programming
solutions of the problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Arpino_G/0/1/0/all/0/1">Gabriel Arpino</a>, <a href="http://arxiv.org/find/math/1/au:+Dmitriev_D/0/1/0/all/0/1">Daniil Dmitriev</a>, <a href="http://arxiv.org/find/math/1/au:+Grometto_N/0/1/0/all/0/1">Nicolo Grometto</a></p><p>Consider the Hitting Set problem where, for a given universe $\mathcal{X} =
\left\{ 1, ... , n \right\}$ and a collection of subsets $\mathcal{S}_1, ... ,
\mathcal{S}_m$, one seeks to identify the smallest subset of $\mathcal{X}$
which has nonempty intersection with every element in the collection. We study
a probabilistic formulation of this problem, where the underlying subsets are
formed by including each element of the universe with probability $p$,
independently of one another. For large enough values of $n$, we rigorously
analyse the average case performance of Lov\'asz's celebrated greedy algorithm
(Lov\'asz, 1975) with respect to the chosen input distribution. In addition, we
study integrality gaps between linear programming and integer programming
solutions of the problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-10T00:30:00Z">Wednesday, May 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, May 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03946'>An Improved PTAS for Covering Targets with Mobile Sensors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nonthaphat Wongwattanakij, Nattawut Phetmak, Chaiporn Jaikaeo, Jittat Fakcharoenphol</p><p>This paper considers a movement minimization problem for mobile sensors.
Given a set of $n$ point targets, the $k$-Sink Minimum Movement Target Coverage
Problem is to schedule mobile sensors, initially located at $k$ base stations,
to cover all targets minimizing the total moving distance of the sensors. We
present a polynomial-time approximation scheme for finding a $(1+\epsilon)$
approximate solution running in time $n^{O(1/\epsilon)}$ for this problem when
$k$, the number of base stations, is constant. Our algorithm improves the
running time exponentially from the previous work that runs in time
$n^{O(1/\epsilon^2)}$, without any target distribution assumption. To devise a
faster algorithm, we prove a stronger bound on the number of sensors in any
unit area in the optimal solution and employ a more refined dynamic programming
algorithm whose complexity depends only on the width of the problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wongwattanakij_N/0/1/0/all/0/1">Nonthaphat Wongwattanakij</a>, <a href="http://arxiv.org/find/cs/1/au:+Phetmak_N/0/1/0/all/0/1">Nattawut Phetmak</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaikaeo_C/0/1/0/all/0/1">Chaiporn Jaikaeo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakcharoenphol_J/0/1/0/all/0/1">Jittat Fakcharoenphol</a></p><p>This paper considers a movement minimization problem for mobile sensors.
Given a set of $n$ point targets, the $k$-Sink Minimum Movement Target Coverage
Problem is to schedule mobile sensors, initially located at $k$ base stations,
to cover all targets minimizing the total moving distance of the sensors. We
present a polynomial-time approximation scheme for finding a $(1+\epsilon)$
approximate solution running in time $n^{O(1/\epsilon)}$ for this problem when
$k$, the number of base stations, is constant. Our algorithm improves the
running time exponentially from the previous work that runs in time
$n^{O(1/\epsilon^2)}$, without any target distribution assumption. To devise a
faster algorithm, we prove a stronger bound on the number of sensors in any
unit area in the optimal solution and employ a more refined dynamic programming
algorithm whose complexity depends only on the width of the problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-09T00:30:00Z">Tuesday, May 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03985'>Minimum-Membership Geometric Set Cover, Revisited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sayan Bandyapadhyay, William Lochet, Saket Saurabh, Jie Xue</p><p>We revisit a natural variant of geometric set cover, called
minimum-membership geometric set cover (MMGSC). In this problem, the input
consists of a set $S$ of points and a set $\mathcal{R}$ of geometric objects,
and the goal is to find a subset $\mathcal{R}^*\subseteq\mathcal{R}$ to cover
all points in $S$ such that the \textit{membership} of $S$ with respect to
$\mathcal{R}^*$, denoted by $\mathsf{memb}(S,\mathcal{R}^*)$, is minimized,
where $\mathsf{memb}(S,\mathcal{R}^*)=\max_{p\in S}|\{R\in\mathcal{R}^*: p\in
R\}|$. We achieve the following two main results.
</p>
<p>* We give the first polynomial-time constant-approximation algorithm for
MMGSC with unit squares. This answers a question left open since the work of
Erlebach and Leeuwen [SODA'08], who gave a constant-approximation algorithm
with running time $n^{O(\mathsf{opt})}$ where $\mathsf{opt}$ is the optimum of
the problem (i.e., the minimum membership).
</p>
<p>* We give the first polynomial-time approximation scheme (PTAS) for MMGSC
with halfplanes. Prior to this work, it was even unknown whether the problem
can be approximated with a factor of $o(\log n)$ in polynomial time, while it
is well-known that the minimum-size set cover problem with halfplanes can be
solved in polynomial time.
</p>
<p>We also consider a problem closely related to MMGSC, called minimum-ply
geometric set cover (MPGSC), in which the goal is to find
$\mathcal{R}^*\subseteq\mathcal{R}$ to cover $S$ such that the ply of
$\mathcal{R}^*$ is minimized, where the ply is defined as the maximum number of
objects in $\mathcal{R}^*$ which have a nonempty common intersection. Very
recently, Durocher et al. gave the first constant-approximation algorithm for
MPGSC with unit squares which runs in $O(n^{12})$ time. We give a significantly
simpler constant-approximation algorithm with near-linear running time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bandyapadhyay_S/0/1/0/all/0/1">Sayan Bandyapadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Lochet_W/0/1/0/all/0/1">William Lochet</a>, <a href="http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1">Saket Saurabh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jie Xue</a></p><p>We revisit a natural variant of geometric set cover, called
minimum-membership geometric set cover (MMGSC). In this problem, the input
consists of a set $S$ of points and a set $\mathcal{R}$ of geometric objects,
and the goal is to find a subset $\mathcal{R}^*\subseteq\mathcal{R}$ to cover
all points in $S$ such that the \textit{membership} of $S$ with respect to
$\mathcal{R}^*$, denoted by $\mathsf{memb}(S,\mathcal{R}^*)$, is minimized,
where $\mathsf{memb}(S,\mathcal{R}^*)=\max_{p\in S}|\{R\in\mathcal{R}^*: p\in
R\}|$. We achieve the following two main results.
</p>
<p>* We give the first polynomial-time constant-approximation algorithm for
MMGSC with unit squares. This answers a question left open since the work of
Erlebach and Leeuwen [SODA'08], who gave a constant-approximation algorithm
with running time $n^{O(\mathsf{opt})}$ where $\mathsf{opt}$ is the optimum of
the problem (i.e., the minimum membership).
</p>
<p>* We give the first polynomial-time approximation scheme (PTAS) for MMGSC
with halfplanes. Prior to this work, it was even unknown whether the problem
can be approximated with a factor of $o(\log n)$ in polynomial time, while it
is well-known that the minimum-size set cover problem with halfplanes can be
solved in polynomial time.
</p>
<p>We also consider a problem closely related to MMGSC, called minimum-ply
geometric set cover (MPGSC), in which the goal is to find
$\mathcal{R}^*\subseteq\mathcal{R}$ to cover $S$ such that the ply of
$\mathcal{R}^*$ is minimized, where the ply is defined as the maximum number of
objects in $\mathcal{R}^*$ which have a nonempty common intersection. Very
recently, Durocher et al. gave the first constant-approximation algorithm for
MPGSC with unit squares which runs in $O(n^{12})$ time. We give a significantly
simpler constant-approximation algorithm with near-linear running time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-09T00:30:00Z">Tuesday, May 09 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, May 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/05/other-ramseys.html'>Other Ramsey's</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;I often Google Ramsey stuff to find something. I often end up back on my own collection of Ramsey theory&nbsp; papers. But I sometimes find OTHER uses of the phrase&nbsp; Ramsey.&nbsp;</p><p>To tell these Ramsey's apart we will call the math Ramsey guy Frank Ramsey since that was his name.&nbsp;</p><p>1) Frank's brother Arthur Michael Ramsey (usually just Michael Ramsey). He was the Archbishop of Canterbury from 1961 until 1974.&nbsp; &nbsp;He was ahead of his time in being Ecumenical and supporting women clergy. His Wikipedia page is&nbsp;here.&nbsp;</p><p>2) The Ramsey Effect. Aaron Ramsey is a football player (what Americans call Soccer). There were four time when he scored a goal and soon after an important person died. This was dubbed The Ramsey Effect. This is of course silly, and if he asked Frank about the probabilities (unlikely-Frank died in the 1930's and Aaron was born in 1990) I am sure Frank would tell you that four is too small a number to make anything out of this. The Ramsey Effect is discussed&nbsp;here. There is no Wikipedia page about it, and I found it by accident so, as the kids say, its NOT a think.&nbsp;</p><p>3) Jon Bennett Ramsey. A girl who was murdered when she was six. Case still unsolved. See the Wikipedia page on this&nbsp;here.</p><p>4) First name Ramsey:&nbsp;here. The only one I had heard of is Ramsey Clark.</p><p>5) Last name Ramsey:&nbsp;here. Lots of people! Most I had not heard of.&nbsp;</p><p>(With regard to 4 and 5: there are so many famous people you can't have heard of all of them)</p><p>6) For more Ramsey Stuff see&nbsp;here</p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;I often Google Ramsey stuff to find something. I often end up back on my own collection of Ramsey theory&nbsp; papers. But I sometimes find OTHER uses of the phrase&nbsp; <i>Ramsey.&nbsp;</i></p><p>To tell these Ramsey's apart we will call the math Ramsey guy <i>Frank Ramsey </i>since that was his name.&nbsp;</p><p>1) Frank's brother Arthur Michael Ramsey (usually just Michael Ramsey). He was the Archbishop of Canterbury from 1961 until 1974.&nbsp; &nbsp;He was ahead of his time in being Ecumenical and supporting women clergy. His Wikipedia page is&nbsp;<a href="https://en.wikipedia.org/wiki/Michael_Ramsey">here</a>.&nbsp;</p><p>2) The Ramsey Effect. Aaron Ramsey is a football player (what Americans call Soccer). There were four time when he scored a goal and soon after an important person died. This was dubbed <i>The Ramsey Effect. </i>This is of course silly, and if he asked Frank about the probabilities (unlikely-Frank died in the 1930's and Aaron was born in 1990) I am sure Frank would tell you that four is too small a number to make anything out of this. The Ramsey Effect is discussed&nbsp;<a href="https://knowyourmeme.com/memes/the-ramsey-effect">here</a>. There is no Wikipedia page about it, and I found it by accident so, as the kids say, its NOT a think.&nbsp;</p><p>3) Jon Bennett Ramsey. A girl who was murdered when she was six. Case still unsolved. See the Wikipedia page on this&nbsp;<a href="https://en.wikipedia.org/wiki/Killing_of_JonBen%C3%A9t_Ramsey">here</a>.</p><p>4) First name Ramsey:&nbsp;<a href="https://en.wikipedia.org/wiki/Ramsey_(given_name)">here</a>. The only one I had heard of is Ramsey Clark.</p><p>5) Last name Ramsey:&nbsp;<a href="https://en.wikipedia.org/wiki/Ramsey_(surname)">here</a>. Lots of people! Most I had not heard of.&nbsp;</p><p>(With regard to 4 and 5: there are so many famous people you can't have heard of all of them)</p><p>6) For more Ramsey Stuff see&nbsp;<a href="https://en.wikipedia.org/wiki/Ramsey">here</a></p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T23:06:00Z">Monday, May 08 2023, 23:06</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2023/05/news-for-april-2023/'>News for April 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          After an empty month, the engines of PTReview are roaring back to life with a fresh batch of papers for this month&#8217;s edition. In total, we have four papers that are sure to pique your interest. It&#8217;s been an action-packed month with a diverse range of topics covered in the featured papers. The first paper [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>After an empty month, the engines of PTReview are roaring back to life with a fresh batch of papers for this month&#8217;s edition. In total, we have four papers that are sure to pique your interest. It&#8217;s been an action-packed month with a diverse range of topics covered in the featured papers. The first paper delves into new variations in distribution testing, while the second paper discusses optimal testers for Bayes Nets. The third paper focuses on optimal tolerant junta-testers, and the final paper presents a cool monotonicity tester over hypergrids.</p>



<p><strong>Distribution Testing Under the Parity Trace</strong> by Renato Ferreira Pinto Jr and Nathaniel Harms (<a href="https://arxiv.org/abs/2304.01374">arXiv</a>) The featured paper considers the classic setup in distribution testing with <em>a twist</em>. To explain the results, let me introduce the framework considered in this work. Consider distributions supported over \([n]\). Suppose I want to design distribution testers where instead of obtaining samples in the usual way, I first obtain an ordered list of samples, I store it in a sequence \(S\) and only the least significant bit of each element of \(S\) is made available to your distribution testing algorithm. This is called a parity trace.  Note that with this access model, suddenly a bunch of standard tasks become non-trivial. To take an example from the paper, you can no longer distinguish between the uniform distribution supported on \(\{1,2, \ldots, n\}\) and the uniform distribution supported on \(\{n+1, n+2, \ldots 2n\}\) in this access model. Nevertheless, the paper shows, you can still obtain testers which require only sublinear number of accesses for testing uniformity in this model.</p>



<p>Another cool feature of this <em>big</em> paper is an unexpected foray into the trace reconstruction literature from a property testing viewpoint. I wish I understood the formal connection better to describe a bit more about it. But for now, let me leave that as an appetizer which (hopefully) encourages you to take a look at the paper.</p>



<p></p>



<p><strong>New Lower Bounds for Adaptive Tolerant Junta Testing</strong> by Xi Chen and Shyamal Patel (<a href="https://arxiv.org/abs/2304.10647">arXiv</a>) If you are a regular here on the PTReview corner, you are probably no stranger to the <em>tolerant junta testing</em> problem. As a corollary to the main result, the paper in question proves a lower bound of \(k^{\Omega(\log k)}\) queries on any adaptive algorithm that wishes to test whether the input function \(f\) is \(\varepsilon_1\) close to being a \(k\)-junta or whether it is \(\varepsilon_2\)-far \(\left(\text{where } \varepsilon_2 \geq \varepsilon_1 + \displaystyle\frac{1}{poly(k)}\right)\). Indeed, another remarkable achievement of the paper is that it achieves a superpolynomial separation between non-tolerant versions and the tolerant versions of any natural property of boolean functions under the adaptive setting.</p>



<p></p>



<p><strong>Near-Optimal Degree Testing for Bayes Nets</strong> by Vipul Arora, Arnab Bhattacharyya, Clément L. Canonne (our own!) and Joy Qiping Yang (<a href="https://arxiv.org/abs/2304.06733">arXiv</a>) This paper continues a line of investigation which a subset of the authors were a part of (which we also covered in our <a href="https://ptreview.sublinear.info/2022/05/news-for-april-2022/">News for April 2022</a>). Let us remind ourselves of the setup. You are given a probability distribution \(\mathcal{P}\) supported over the Boolean Hypercube. Suppose \(\mathcal{P}\) can be generated by a Bayseian Network. You may think of a Bayesian Network as a DAG where each vertex tosses a coin (with different heads probabilities). The question seeks to test whether \(\mathcal{P}\) admits a sparse Bayesian Net (in the sense of each vertex having small in-degree). The main result of the paper gives an algorithm for this task which requires \(\Theta(2^{n/2}/\varepsilon^2)\) samples. The paper also proves an almost matching lower bound.</p>



<p></p>



<p><strong>A \(d^{1/2+o(1)}\) Monotonicity Tester for Boolean Functions on \(d\)-Dimensional Hypergrids</strong> by Hadley Black, Deeparnab Chakrabarty and C. Seshadhri (again, our own!) (<a href="https://arxiv.org/abs/2304.01416">arXiv</a>) Again, the problem of monotonicity testing of boolean functions hardly requires any detailing to the regular readers of PTReview. As you can see in our <a href="https://ptreview.sublinear.info/2022/12/news-for-october-2022-2/">News from November 2022</a> there were two concurrent papers mulling over this problem over the hypergrid domain. The featured paper is the result of a dedicated pursuit by the authors and the key result is what the title says. Namely, you can test monotonicity with a number of (non-adaptive, one-sided) queries that has no dependence on \(n\).</p>
<p class="authors">By Akash</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T13:54:49Z">Monday, May 08 2023, 13:54</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/05/08/mathematics-mainly-combinatorics-related-matters-a-lot-of-activity/'>Mathematics (mainly combinatorics) related matters: A lot of activity.</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Plan for next weeks blogging There are various things to blog about and let me give a quick preview for the plan for the next few posts. The purpose of this post is to give an impression about the hectic &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <h3>Plan for next weeks blogging</h3>
<p>There are various things to blog about and let me give a quick preview for the plan for the next few posts. The purpose of this post is to give an impression about the hectic mathematical activities around here with special emphasis on combinatorics and early-in-the-week activities. There is so much action around that I feel tired just to write about it. Next post will be around <a href="https://youtu.be/Qz3q6jcknHE">Amnon Shashua&#8217;s lecture</a> at Reichman university giving a deep dive on LLMs. Following it I will tell you about developments around physics with special emphasis to the <a href="https://www.youtube.com/live/mg3gy4Et_xY?feature=share">evening at the Israeli Academy</a> celebrating Israel entrance to CERN. Fourth in line is a post about my<a href="https://arxiv.org/abs/2305.01064"> recent paper with Yosef Rinott and Tomer Shoham</a> on the Google 2019 quantum supremacy experiment (this is our third paper on the subject).</p>
<p>Let&#8217;s move on to today&#8217;s post which will include more than the usual dose of Hebrew.</p>
<h2>Avinoam</h2>
<p>A few weeks ago, Avinoam Mann, a dear member of our department in Jerusalem, passed away. Avinoam was a famous group theorist working on many aspects of this theory. I have many warm memories of Avinoam since I was a student when I took with Avinoam two very demanding reading courses, and later as colleagues and friends for many decades. Avinoam was also a poet and here is a poem he wrote.</p>
<p><a href="https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg"><img data-attachment-id="24262" data-permalink="https://gilkalai.wordpress.com/2023/05/08/mathematics-mainly-combinatorics-related-matters-a-lot-of-activity/avinoam/" data-orig-file="https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg" data-orig-size="1036,723" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G986B&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1680451480&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.4&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.02&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Avinoam" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg?w=640" class="alignnone size-full wp-image-24262" src="https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg?w=640" alt="Avinoam" srcset="https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg?w=640 640w, https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg?w=150 150w, https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg?w=300 300w, https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg?w=768 768w, https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg?w=1024 1024w, https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg 1036w" sizes="(max-width: 640px) 100vw, 640px"   /></a></p>
<h2>Many many many Seminars</h2>
<h3>HUJI Combinatorics  seminars</h3>
<p>The seminar takes place on Mondays between 11-13. The 2-hour format allows ample discussions. There were brilliant talks at the HUJI (Hebrew University of Jerusalem) Combinatorics Seminar. The last four were given by  Illay Hoshen, Yuval Filmus, Igor Balla, and Nathan Keller. <strong>Ilay Hoshen</strong> spoke about his paper with <strong>Wojtek Samotij</strong> on Simonovits&#8217;s theorem for random graphs, and presented a (partial) resolution to a conjecture by DeMarco and Kahn.  <strong>Yuval Filmus</strong> talked about a joint work with <strong>Nathan Lindzey</strong>, where the starting point was Fourier expansion for function on the Boolean cube  and asked what happens if we study functions on other domains, such as the &#8220;slice&#8221; or the symmetric group? (very elegant connection with representation theory.) Once it&#8217;s on the arxive we will add the link. <strong>Igor Balla</strong> talked about <span style="color: initial">Equiangular lines via matrix projection. This work presents a definite progress on the classical problem of equiangular lines as well as some connections to problems in quantum information theory.  <strong>Nathan Keller</strong> talked about <a href="https://arxiv.org/abs/2303.15755">his joint work</a> with </span><strong>Noam Lifshitz, Dor Minzer</strong>, and <strong>Ohad Sheinfeld. </strong>Hypercontractivity for global functions is used for far reaching Erdos-Ko-Rado theorems for permutations. Nati Linial wrote to me about the lecture: <span style="color: #ff0000"><strong>מצויינת, מדוייקת, אינפורמטיבית, א-מחיה</strong></span> . (which roughly translates to: “Outstanding, Accurate, Informative – Oh the Joy!”). Today <b></b><strong>Amir Yehudayoff</strong> will talk about <a href="https://arxiv.org/abs/2304.05456">his work</a> with <strong>Dan Carmon</strong> on dual systolic graphs.</p>
<p>This is not the only HUJI combinatorics seminar, on Thursday afternoon we have a joint Jerusalem-Copenhagen combinatorics seminar and at noon we have a joint Jerusalem Copenhagen lunch seminar. I gave a lecture in the lunch seminar a couple of weeks ago about challenges in the combinatorial theory of convex polytopes and spheres beyond the <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g" class="latex" />-theorem. Of course, our CS-theory Wednesday seminars have plenty of lectures of combinatorial flavour.</p>
<h3>Shachar Lovett&#8217;s lecture at Tel Aviv Combinatorics Seminar</h3>
<p>Things in TAU (Tel Aviv University) are not calmer.</p>
<p>TAU combinatorics seminar is on Sundays 10:05-11:05, and last  week (April 30) the legendary <strong>Shachar Lovett</strong> gave a talk about his paper with <strong>Alexander Knop</strong>, <strong>Sam McGuire</strong>, and <strong>Weiqiang Yuan </strong>about <a title="Structure of monomials of Boolean functions" href="https://gilkalai.files.wordpress.com/2023/05/structure-of-monomials-of-boolean-functions.pptx">Structure of monomials of Boolean functions.</a> (Click for the slides.)</p>
<p>The main theorem is the following one. <strong>Theorem:</strong> Let <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^n &#92;to &#92;{0,1&#92;}" class="latex" /> be a Boolean function with <img src="https://s0.wp.com/latex.php?latex=%7CM%28f%29%7C%3Dm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CM%28f%29%7C%3Dm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CM%28f%29%7C%3Dm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|M(f)|=m" class="latex" />. (<img src="https://s0.wp.com/latex.php?latex=M%28f%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28f%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28f%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(f)" class="latex" /> is the number of monomials in the presentation of <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />) Then f can be computed by an AND decision tree of depth <img src="https://s0.wp.com/latex.php?latex=d%3DO%28%5Clog+%5E5m%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%3DO%28%5Clog+%5E5m%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%3DO%28%5Clog+%5E5m%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d=O(&#92;log ^5m&#92;log n)" class="latex" />.</p>
<p>The proof uses an auxiliary (sharp) result about hitting sets (aka transversals) for monomials. It is not known if the <img src="https://s0.wp.com/latex.php?latex=%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log n" class="latex" /> factor in the main theorem is needed. Shachar described exciting connections with the log-rank conjecture and with Frankl&#8217;s union-closed conjecture. He also described the analogous (Fourier) question for functions  <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B-1%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B-1%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B-1%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{-1,1&#92;}^n &#92;to &#92;{0,1&#92;}" class="latex" />.</p>
<p>After the lecture Shachar told me about some basic details of the recent amazing proof of Kelly and Meka for sharp bound for Roth&#8217;s theorems. Shachar promised me that the crucial new ideas giving a Fourier proof for similar bounds for the cup set problem could be presented in four to six hours. (He started with two hours but I flatly disbelieved it.) We also came back to the idea of a polymath project devoted to Frankl&#8217;s conjecture.</p>
<p>This Sunday <strong> Shir Peleg-Priester </strong> talked about Sylvester-Gallai type theorems for quadratic polynomials. (Joint work with <strong> Amir Shpilka, Abhibhav Garg, Rafael Oliveira, Akash K Sengupta.)</strong></p>
<p>Sunday seminar is not the only TAU combinatorics seminar.  Two days later, on May 2 <strong>Patrick Morris</strong> gave a special seminar about <a href="https://arxiv.org/abs/2209.01116"> a robust Corrádi–Hajnal Theorem</a> (joint work with <strong>Peter Allen, Julia Böttcher, Jan Corsten, Ewan Davies, Matthew Jenssen, Barnaby Roberts</strong> and <strong>Jozef Skokan</strong>.) As far as I know there are plans to have special seminars dedicated to both the new ultimate Roth bounds and the Ramsey breakthrough. (Update: just learned too late that the Ramsey seminar already took place on Tuesday.)</p>
<p>Of course, there is also the weekly discrete and computational geometry seminar, and a few weeks ago I gave a talk about &#8220;covering problems&#8221; which was well accepted and is in line with this year&#8217;s theme for the seminar.</p>
<h3>More combinatorics seminars</h3>
<p>There are many other combinatorics seminars around. If you have an urge for combinatorics lectures between the Tel Aviv seminar and the one in Jerusalem,  on Sundays at 2 o&#8217;clock there is the Bar Ilan weekly Combinatorics Seminar, and on May 7  <b>Yelena Yuditsky </b>talked about <a href="https://arxiv.org/abs/2207.01041">Conflict-free colouring of subsets</a> (joint work with <strong>Bruno Jartoux, Chaya Keller</strong> and <strong>Shakhar Smorodinsky</strong>.) On Mondays Martin Golumbic runs the seminar: &#8220;Monday with Marty and Students of Sunil&#8221; devoted to algorithmic graph theory.  Tomorrow, <strong>Pradeesha Ashok</strong> talks about: Exact and Parameterised algorithms for Graph Burning (joint work with <strong>Avi Tomar, Shaily Verma, Sayani Das, Lawqueen Kanesh</strong> and <strong>Saket Saurabh</strong>).</p>
<h3>Shmuel Weinberger&#8217;s lectures</h3>
<p>Of course, things are just as amazingly intense in other fields of mathematics as well. Last week I attended two great talks by <strong>Shmuel Weinberger</strong>. The first talk gave the answer to the question which groups act without fixed points on some aspherical topological space. Shmuel said that his talk will be structured like a Tarantino&#8217;s movie, and at the end he expressed hope that the talk was as entertaining but not as violent.  This is based on joint work with <strong>Sylvain Cappell,</strong> and <strong>Min Yan.</strong> The second talk gave (among other things) a lower bound for the number of vertices needed to triangulate <img src="https://s0.wp.com/latex.php?latex=%282d-1%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%282d-1%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%282d-1%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(2d-1)" class="latex" />-dimensional lens spaces which is the quotient space of an action of <img src="https://s0.wp.com/latex.php?latex=Z_n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Z_n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Z_n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Z_n" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+C%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+C%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+C%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb C^d" class="latex" />. The proof goes via the notions of <img src="https://s0.wp.com/latex.php?latex=%5Cell_2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cell_2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cell_2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ell_2" class="latex" />-homology and certain invariants of Cheeger and Gromov and it would be really nice to have some simpler proofs. (This is based on an old work with <strong>Stanley Chang</strong>, and <a href="https://arxiv.org/abs/2301.08870">a new work</a> with <strong>Geunho Lim</strong>.</p>
<p><iframe class="youtube-player" width="640" height="360" src="https://www.youtube.com/embed/qwojzqAcHqw?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></p>
<p><span style="color: #ff0000">Here is a lecture on calculus on extraordinary spaces by Yael Karshon (Hebrew).</span></p>
<h2>Kazhdan&#8217;s Sunday seminars &#8211; a plan for fall 2024 (maybe 2023).</h2>
<p>Since David Kazhdan moved from Harvard to HUJI he is running four-five semester-long seminars every  year on Sundays, and a basic notion seminar on Thursday afternoons. This semester, for example, in one of the seminars, Udi de Shalit presents Wiles&#8217; proof of Fermat&#8217;s last theorem (taking Ribet&#8217;s part for granted).</p>
<p>Once every decade or so, I serve as a co-teacher in a Kazhdan seminar. In fall 2003 David Kazhdan and I ran a <a href="http://www.ma.huji.ac.il/~kalai/polytopes.html">seminar on polytopes</a>, toric varieties, and related combinatorics and algebra.  In 2013 David and I felt that it was time to run another such event in 2014, perhaps establishing a tradition for a decennial joint seminar.  I announced this coming event in my <a href="https://gilkalai.wordpress.com/2013/01/01/symplectic-geometry-quantization-and-quantum-noise/">January 2013 post</a> and wrote: &#8220;So next spring, the plan is &#8230;[to] devote one of David’s Sunday seminars to computation, quantumness, symplectic geometry, and information.&#8221; Alas, David had a terrible car accident and we had to delay the plan to <a href="https://gilkalai.wordpress.com/2019/10/27/starting-today-kazhdan-sunday-seminar-computation-quantumness-symplectic-geometry-and-information/">a fall 2019 seminar</a> that Leonid Polterovich, Dorit Aharonov, Guy Kindler and I ran.  Also, in fall 2018, Karim Adiprasito gave a Kazhdan seminar on  &#8220;Positivity in combinatorics and beyond&#8221; where Karim presented his proof for the g-conjecture. We are now planning a  Kazhdan seminar in fall 2024 around &#8220;global hypercontractivity&#8221; with Noam Lifshitz, myself and perhaps also Guy Kindler and others. (Kazhdan&#8217;s 2023/2024 schedule was fully booked, but come to think of it, since Dor Minzer is in town in fall 2023, maybe we will do something then.)</p>
<h2>60th birthday conferences for the young: Gunter Ziegler and Leonid Polterovich</h2>
<p>Noga Alon recently complained that &#8220;younger and younger people are celebrating their 60th birthdays&#8221;. Indeed, two weeks from now there will be a <a href="http://ehrhart.math.fu-berlin.de/gmz60/#arnau">day-and-a half workshop</a> in Berlin celebrating Günter Ziegler&#8217;s birthday and in June there will be a <a href="https://math.ethz.ch/fim/activities/conferences/lp60-geometry-and-dynamics-polterovich.html">Leonid Polterovich fest</a> in Zurich. Happy birthdays, kids!</p>
<h2>Maybe it is over</h2>
<p>A well-known Israeli poet and writer Yonatan Gefen passed away recently and here is a nice song he wrote (performed by Arik Einstein): <a href="https://youtu.be/R384MOGq7HM">Yhachol lihyot sheze nigmar</a>  (It is possible that it is over.)</p>
<p><iframe class="youtube-player" width="640" height="360" src="https://www.youtube.com/embed/R384MOGq7HM?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T06:50:10Z">Monday, May 08 2023, 06:50</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03439'>Degrees of Second and Higher-Order Polynomials</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Donghyun Lim, Martin Ziegler</p><p>Second-order polynomials generalize classical first-order ones in allowing
for additional variables that range over functions rather than values. We are
motivated by their applications in higher-order computational complexity
theory, extending for example classical classes like P or PSPACE to operators
in Analysis [doi:10.1137/S0097539794263452, doi:10.1145/2189778.2189780]. The
degree subclassifies ordinary polynomial growth into linear, quadratic, cubic
etc. In order to similarly classify second-order polynomials, define their
degree to be an 'arctic' first-order polynomial (namely a term/expression over
variable $D$ and operations $+$ and $\cdot$ and $\max$). Our normal form and
semantic uniqueness results for second-order polynomials assert said
second-order degree to be well-defined; and it turns out to transform well
under (now two kinds of) polynomial composition. More generally we define the
degree of a third-order polynomial to be an arctic second-order polynomial, and
establish its transformation under three kinds of composition.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lim_D/0/1/0/all/0/1">Donghyun Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziegler_M/0/1/0/all/0/1">Martin Ziegler</a></p><p>Second-order polynomials generalize classical first-order ones in allowing
for additional variables that range over functions rather than values. We are
motivated by their applications in higher-order computational complexity
theory, extending for example classical classes like P or PSPACE to operators
in Analysis [doi:10.1137/S0097539794263452, doi:10.1145/218<a href="/abs/9778.21897">9778.21897</a>80]. The
degree subclassifies ordinary polynomial growth into linear, quadratic, cubic
etc. In order to similarly classify second-order polynomials, define their
degree to be an 'arctic' first-order polynomial (namely a term/expression over
variable $D$ and operations $+$ and $\cdot$ and $\max$). Our normal form and
semantic uniqueness results for second-order polynomials assert said
second-order degree to be well-defined; and it turns out to transform well
under (now two kinds of) polynomial composition. More generally we define the
degree of a third-order polynomial to be an arctic second-order polynomial, and
establish its transformation under three kinds of composition.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03180'>On Range Summary Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Peyman Afshani, Pingan Cheng, Aniket Basu Roy, Zhewei Wei</p><p>We study the query version of the approximate heavy hitter and quantile
problems. In the former problem, the input is a parameter $\varepsilon$ and a
set $P$ of $n$ points in $\mathbb{R}^d$ where each point is assigned a color
from a set $C$, and we want to build a structure s.t. given any geometric range
$\gamma$, we can efficiently find a list of approximate heavy hitters in
$\gamma\cap P$, i.e., colors that appear at least $\varepsilon |\gamma \cap P|$
times in $\gamma \cap P$, as well as their frequencies with an additive error
of $\varepsilon |\gamma \cap P|$. In the latter problem, each point is assigned
a weight from a totally ordered universe and the query must output a sequence
$S$ of $1+1/\varepsilon$ weights s.t. the $i$-th weight in $S$ has approximate
rank $i\varepsilon|\gamma\cap P|$, meaning, rank $i\varepsilon|\gamma\cap P|$
up to an additive error of $\varepsilon|\gamma\cap P|$. Previously, optimal
results were only known in 1D [WY11] but a few sub-optimal methods were
available in higher dimensions [AW17, ACH+12].
</p>
<p>We study the problems for 3D halfspace and dominance queries. We consider the
real RAM model with integer registers of size $w=\Theta(\log n)$ bits. For
dominance queries, we show optimal solutions for both heavy hitter and quantile
problems: using linear space, we can answer both queries in time $O(\log n +
1/\varepsilon)$. Note that as the output size is $\frac{1}{\varepsilon}$, after
investing the initial $O(\log n)$ searching time, our structure takes on
average $O(1)$ time to find a heavy hitter or a quantile! For more general
halfspace heavy hitter queries, the same optimal query time can be achieved by
increasing the space by an extra $\log_w\frac{1}{\varepsilon}$ (resp.
$\log\log_w\frac{1}{\varepsilon}$) factor in 3D (resp. 2D). By spending extra
$\log^{O(1)}\frac{1}{\varepsilon}$ factors in time and space, we can also
support quantile queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Afshani_P/0/1/0/all/0/1">Peyman Afshani</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Pingan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1">Aniket Basu Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zhewei Wei</a></p><p>We study the query version of the approximate heavy hitter and quantile
problems. In the former problem, the input is a parameter $\varepsilon$ and a
set $P$ of $n$ points in $\mathbb{R}^d$ where each point is assigned a color
from a set $C$, and we want to build a structure s.t. given any geometric range
$\gamma$, we can efficiently find a list of approximate heavy hitters in
$\gamma\cap P$, i.e., colors that appear at least $\varepsilon |\gamma \cap P|$
times in $\gamma \cap P$, as well as their frequencies with an additive error
of $\varepsilon |\gamma \cap P|$. In the latter problem, each point is assigned
a weight from a totally ordered universe and the query must output a sequence
$S$ of $1+1/\varepsilon$ weights s.t. the $i$-th weight in $S$ has approximate
rank $i\varepsilon|\gamma\cap P|$, meaning, rank $i\varepsilon|\gamma\cap P|$
up to an additive error of $\varepsilon|\gamma\cap P|$. Previously, optimal
results were only known in 1D [WY11] but a few sub-optimal methods were
available in higher dimensions [AW17, ACH+12].
</p>
<p>We study the problems for 3D halfspace and dominance queries. We consider the
real RAM model with integer registers of size $w=\Theta(\log n)$ bits. For
dominance queries, we show optimal solutions for both heavy hitter and quantile
problems: using linear space, we can answer both queries in time $O(\log n +
1/\varepsilon)$. Note that as the output size is $\frac{1}{\varepsilon}$, after
investing the initial $O(\log n)$ searching time, our structure takes on
average $O(1)$ time to find a heavy hitter or a quantile! For more general
halfspace heavy hitter queries, the same optimal query time can be achieved by
increasing the space by an extra $\log_w\frac{1}{\varepsilon}$ (resp.
$\log\log_w\frac{1}{\varepsilon}$) factor in 3D (resp. 2D). By spending extra
$\log^{O(1)}\frac{1}{\varepsilon}$ factors in time and space, we can also
support quantile queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03609'>Differentially Private Topological Data Analysis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Taegyu Kang, Sehwan Kim, Jinwon Sohn, Jordan Awan</p><p>This paper is the first to attempt differentially private (DP) topological
data analysis (TDA), producing near-optimal private persistence diagrams. We
analyze the sensitivity of persistence diagrams in terms of the bottleneck
distance, and we show that the commonly used \v{C}ech complex has sensitivity
that does not decrease as the sample size $n$ increases. This makes it
challenging for the persistence diagrams of \v{C}ech complexes to be
privatized. As an alternative, we show that the persistence diagram obtained by
the $L^1$-distance to measure (DTM) has sensitivity $O(1/n)$. Based on the
sensitivity analysis, we propose using the exponential mechanism whose utility
function is defined in terms of the bottleneck distance of the $L^1$-DTM
persistence diagrams. We also derive upper and lower bounds of the accuracy of
our privacy mechanism; the obtained bounds indicate that the privacy error of
our mechanism is near-optimal. We demonstrate the performance of our privatized
persistence diagrams through simulations as well as on a real dataset tracking
human movement.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Kang_T/0/1/0/all/0/1">Taegyu Kang</a>, <a href="http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1">Sehwan Kim</a>, <a href="http://arxiv.org/find/stat/1/au:+Sohn_J/0/1/0/all/0/1">Jinwon Sohn</a>, <a href="http://arxiv.org/find/stat/1/au:+Awan_J/0/1/0/all/0/1">Jordan Awan</a></p><p>This paper is the first to attempt differentially private (DP) topological
data analysis (TDA), producing near-optimal private persistence diagrams. We
analyze the sensitivity of persistence diagrams in terms of the bottleneck
distance, and we show that the commonly used \v{C}ech complex has sensitivity
that does not decrease as the sample size $n$ increases. This makes it
challenging for the persistence diagrams of \v{C}ech complexes to be
privatized. As an alternative, we show that the persistence diagram obtained by
the $L^1$-distance to measure (DTM) has sensitivity $O(1/n)$. Based on the
sensitivity analysis, we propose using the exponential mechanism whose utility
function is defined in terms of the bottleneck distance of the $L^1$-DTM
persistence diagrams. We also derive upper and lower bounds of the accuracy of
our privacy mechanism; the obtained bounds indicate that the privacy error of
our mechanism is near-optimal. We demonstrate the performance of our privatized
persistence diagrams through simulations as well as on a real dataset tracking
human movement.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03146'>Testing Convex Truncation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anindya De, Shivam Nadimpalli, Rocco A. Servedio</p><p>We study the basic statistical problem of testing whether normally
distributed $n$-dimensional data has been truncated, i.e. altered by only
retaining points that lie in some unknown truncation set $S \subseteq
\mathbb{R}^n$. As our main algorithmic results,
</p>
<p>(1) We give a computationally efficient $O(n)$-sample algorithm that can
distinguish the standard normal distribution $N(0,I_n)$ from $N(0,I_n)$
conditioned on an unknown and arbitrary convex set $S$.
</p>
<p>(2) We give a different computationally efficient $O(n)$-sample algorithm
that can distinguish $N(0,I_n)$ from $N(0,I_n)$ conditioned on an unknown and
arbitrary mixture of symmetric convex sets.
</p>
<p>These results stand in sharp contrast with known results for learning or
testing convex bodies with respect to the normal distribution or learning
convex-truncated normal distributions, where state-of-the-art algorithms
require essentially $n^{\sqrt{n}}$ samples. An easy argument shows that no
finite number of samples suffices to distinguish $N(0,I_n)$ from an unknown and
arbitrary mixture of general (not necessarily symmetric) convex sets, so no
common generalization of results (1) and (2) above is possible.
</p>
<p>We also prove that any algorithm (computationally efficient or otherwise)
that can distinguish $N(0,I_n)$ from $N(0,I_n)$ conditioned on an unknown
symmetric convex set must use $\Omega(n)$ samples. This shows that the sample
complexity of each of our algorithms is optimal up to a constant factor.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1">Anindya De</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadimpalli_S/0/1/0/all/0/1">Shivam Nadimpalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Servedio_R/0/1/0/all/0/1">Rocco A. Servedio</a></p><p>We study the basic statistical problem of testing whether normally
distributed $n$-dimensional data has been truncated, i.e. altered by only
retaining points that lie in some unknown truncation set $S \subseteq
\mathbb{R}^n$. As our main algorithmic results,
</p>
<p>(1) We give a computationally efficient $O(n)$-sample algorithm that can
distinguish the standard normal distribution $N(0,I_n)$ from $N(0,I_n)$
conditioned on an unknown and arbitrary convex set $S$.
</p>
<p>(2) We give a different computationally efficient $O(n)$-sample algorithm
that can distinguish $N(0,I_n)$ from $N(0,I_n)$ conditioned on an unknown and
arbitrary mixture of symmetric convex sets.
</p>
<p>These results stand in sharp contrast with known results for learning or
testing convex bodies with respect to the normal distribution or learning
convex-truncated normal distributions, where state-of-the-art algorithms
require essentially $n^{\sqrt{n}}$ samples. An easy argument shows that no
finite number of samples suffices to distinguish $N(0,I_n)$ from an unknown and
arbitrary mixture of general (not necessarily symmetric) convex sets, so no
common generalization of results (1) and (2) above is possible.
</p>
<p>We also prove that any algorithm (computationally efficient or otherwise)
that can distinguish $N(0,I_n)$ from $N(0,I_n)$ conditioned on an unknown
symmetric convex set must use $\Omega(n)$ samples. This shows that the sample
complexity of each of our algorithms is optimal up to a constant factor.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03307'>On Optimization and Counting of Non-Broken Bases of Matroids</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dorna Abdolazimi, Kasper Lindberg, Shayan Oveis Gharan</p><p>Given a matroid $M=(E,{\cal I})$, and a total ordering over the elements $E$,
a broken circuit is a circuit where the smallest element is removed and an NBC
independent set is an independent set in ${\cal I}$ with no broken circuit. The
set of NBC independent sets of any matroid $M$ define a simplicial complex
called the broken circuit complex which has been the subject of intense study
in combinatorics. Recently, Adiprasito, Huh and Katz showed that the face of
numbers of any broken circuit complex form a log-concave sequence, proving a
long-standing conjecture of Rota.
</p>
<p>We study counting and optimization problems on NBC bases of a generic
matroid. We find several fundamental differences with the independent set
complex: for example, we show that it is NP-hard to find the max-weight NBC
base of a matroid or that the convex hull of NBC bases of a matroid has edges
of arbitrary large length. We also give evidence that the natural down-up walk
on the space of NBC bases of a matroid may not mix rapidly by showing that for
some family of matroids it is NP-hard to count the number of NBC bases after
certain conditionings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Abdolazimi_D/0/1/0/all/0/1">Dorna Abdolazimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindberg_K/0/1/0/all/0/1">Kasper Lindberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gharan_S/0/1/0/all/0/1">Shayan Oveis Gharan</a></p><p>Given a matroid $M=(E,{\cal I})$, and a total ordering over the elements $E$,
a broken circuit is a circuit where the smallest element is removed and an NBC
independent set is an independent set in ${\cal I}$ with no broken circuit. The
set of NBC independent sets of any matroid $M$ define a simplicial complex
called the broken circuit complex which has been the subject of intense study
in combinatorics. Recently, Adiprasito, Huh and Katz showed that the face of
numbers of any broken circuit complex form a log-concave sequence, proving a
long-standing conjecture of Rota.
</p>
<p>We study counting and optimization problems on NBC bases of a generic
matroid. We find several fundamental differences with the independent set
complex: for example, we show that it is NP-hard to find the max-weight NBC
base of a matroid or that the convex hull of NBC bases of a matroid has edges
of arbitrary large length. We also give evidence that the natural down-up walk
on the space of NBC bases of a matroid may not mix rapidly by showing that for
some family of matroids it is NP-hard to count the number of NBC bases after
certain conditionings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03110'>A Sparse Johnson-Lindenstrauss Transform using Fast Hashing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jakob B&#xe6;k Tejs Houen, Mikkel Thorup</p><p>The \emph{Sparse Johnson-Lindenstrauss Transform} of Kane and Nelson (SODA
2012) provides a linear dimensionality-reducing map $A \in \mathbb{R}^{m \times
u}$ in $\ell_2$ that preserves distances up to distortion of $1 + \varepsilon$
with probability $1 - \delta$, where $m = O(\varepsilon^{-2} \log 1/\delta)$
and each column of $A$ has $O(\varepsilon m)$ non-zero entries. The previous
analyses of the Sparse Johnson-Lindenstrauss Transform all assumed access to a
$\Omega(\log 1/\delta)$-wise independent hash function. The main contribution
of this paper is a more general analysis of the Sparse Johnson-Lindenstrauss
Transform with less assumptions on the hash function. We also show that the
\emph{Mixed Tabulation hash function} of Dahlgaard, Knudsen, Rotenberg, and
Thorup (FOCS 2015) satisfies the conditions of our analysis, thus giving us the
first analysis of a Sparse Johnson-Lindenstrauss Transform that works with a
practical hash function.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Houen_J/0/1/0/all/0/1">Jakob B&#xe6;k Tejs Houen</a>, <a href="http://arxiv.org/find/cs/1/au:+Thorup_M/0/1/0/all/0/1">Mikkel Thorup</a></p><p>The \emph{Sparse Johnson-Lindenstrauss Transform} of Kane and Nelson (SODA
2012) provides a linear dimensionality-reducing map $A \in \mathbb{R}^{m \times
u}$ in $\ell_2$ that preserves distances up to distortion of $1 + \varepsilon$
with probability $1 - \delta$, where $m = O(\varepsilon^{-2} \log 1/\delta)$
and each column of $A$ has $O(\varepsilon m)$ non-zero entries. The previous
analyses of the Sparse Johnson-Lindenstrauss Transform all assumed access to a
$\Omega(\log 1/\delta)$-wise independent hash function. The main contribution
of this paper is a more general analysis of the Sparse Johnson-Lindenstrauss
Transform with less assumptions on the hash function. We also show that the
\emph{Mixed Tabulation hash function} of Dahlgaard, Knudsen, Rotenberg, and
Thorup (FOCS 2015) satisfies the conditions of our analysis, thus giving us the
first analysis of a Sparse Johnson-Lindenstrauss Transform that works with a
practical hash function.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03194'>Testing Convexity of Discrete Sets in High Dimensions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hadley Black, Eric Blais, Nathaniel Harms</p><p>We study the problem of testing whether an unknown set $S$ in $n$ dimensions
is convex or far from convex, using membership queries. The simplest
high-dimensional discrete domain where the problem of testing convexity is
non-trivial is the domain $\{-1,0,1\}^n$. Our main results are nearly-tight
upper and lower bounds of $3^{\widetilde \Theta( \sqrt n)}$ for one-sided error
testing of convex sets over this domain with non-adaptive queries. Together
with our $3^{\Omega(n)}$ lower bound on one-sided error testing with samples,
this shows that non-adaptive queries are significantly more powerful than
samples for this problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Black_H/0/1/0/all/0/1">Hadley Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Blais_E/0/1/0/all/0/1">Eric Blais</a>, <a href="http://arxiv.org/find/cs/1/au:+Harms_N/0/1/0/all/0/1">Nathaniel Harms</a></p><p>We study the problem of testing whether an unknown set $S$ in $n$ dimensions
is convex or far from convex, using membership queries. The simplest
high-dimensional discrete domain where the problem of testing convexity is
non-trivial is the domain $\{-1,0,1\}^n$. Our main results are nearly-tight
upper and lower bounds of $3^{\widetilde \Theta( \sqrt n)}$ for one-sided error
testing of convex sets over this domain with non-adaptive queries. Together
with our $3^{\Omega(n)}$ lower bound on one-sided error testing with samples,
this shows that non-adaptive queries are significantly more powerful than
samples for this problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03240'>Sum-of-Local-Effects Data Structures for Separable Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xing Lyu, Travis Gagie, Meng He, Yakov Nekrich, Norbert Zeh</p><p>It is not difficult to think of applications that can be modelled as graph
problems in which placing some facility or commodity at a vertex has some
positive or negative effect on the values of all the vertices out to some
distance, and we want to be able to calculate quickly the cumulative effect on
any vertex's value at any time or the list of the most beneficial or most
detrimential effects on a vertex. In this paper we show how, given an
edge-weighted graph with constant-size separators, we can support the following
operations on it in time polylogarithmic in the number of vertices and the
number of facilities placed on the vertices, where distances between vertices
are measured with respect to the edge weights:
</p>
<p>Add (v, f, w, d) places a facility of weight w and with effect radius d onto
vertex v.
</p>
<p>Remove (v, f) removes a facility f previously placed on v using Add from v.
</p>
<p>Sum (v) or Sum (v, d) returns the total weight of all facilities affecting v
or, with a distance parameter d, the total weight of all facilities whose
effect region intersects the ``circle'' with radius d around v.
</p>
<p>Top (v, k) or Top (v, k, d) returns the k facilities of greatest weight that
affect v or, with a distance parameter d, whose effect region intersects the
``circle'' with radius d around v.
</p>
<p>The weights of the facilities and the operation that Sum uses to ``sum'' them
must form a semigroup. For Top queries, the weights must be drawn from a total
order.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1">Xing Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gagie_T/0/1/0/all/0/1">Travis Gagie</a>, <a href="http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1">Meng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Nekrich_Y/0/1/0/all/0/1">Yakov Nekrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeh_N/0/1/0/all/0/1">Norbert Zeh</a></p><p>It is not difficult to think of applications that can be modelled as graph
problems in which placing some facility or commodity at a vertex has some
positive or negative effect on the values of all the vertices out to some
distance, and we want to be able to calculate quickly the cumulative effect on
any vertex's value at any time or the list of the most beneficial or most
detrimential effects on a vertex. In this paper we show how, given an
edge-weighted graph with constant-size separators, we can support the following
operations on it in time polylogarithmic in the number of vertices and the
number of facilities placed on the vertices, where distances between vertices
are measured with respect to the edge weights:
</p>
<p>Add (v, f, w, d) places a facility of weight w and with effect radius d onto
vertex v.
</p>
<p>Remove (v, f) removes a facility f previously placed on v using Add from v.
</p>
<p>Sum (v) or Sum (v, d) returns the total weight of all facilities affecting v
or, with a distance parameter d, the total weight of all facilities whose
effect region intersects the ``circle'' with radius d around v.
</p>
<p>Top (v, k) or Top (v, k, d) returns the k facilities of greatest weight that
affect v or, with a distance parameter d, whose effect region intersects the
``circle'' with radius d around v.
</p>
<p>The weights of the facilities and the operation that Sum uses to ``sum'' them
must form a semigroup. For Top queries, the weights must be drawn from a total
order.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03381'>Tighter Approximation for the Uniform Cost-Distance Steiner Tree Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Josefine Foos, Stephan Held, Yannik Kyle Dustin Spitzley</p><p>Uniform cost-distance Steiner trees minimize the sum of the total length and
weighted path lengths from a dedicated root to the other terminals. They are
applied when the tree is intended for signal transmission, e.g. in chip design
or telecommunication networks. They are a special case of general cost-distance
Steiner trees, where different distance functions are used for total length and
path lengths.
</p>
<p>We improve the best published approximation factor for the uniform
cost-distance Steiner tree problem from 2.39 to 2.05. If we can approximate the
minimum-length Steiner tree problem arbitrarily well, our algorithm achieves an
approximation factor arbitrarily close to $ 1 + \frac{1}{\sqrt{2}} $. This
bound is tight in the following sense. We also prove the gap $ 1 +
\frac{1}{\sqrt{2}} $ between optimum solutions and the lower bound which we and
all previous approximation algorithms for this problem use.
</p>
<p>Similarly to previous approaches, we start with an approximate minimum-length
Steiner tree and split it into subtrees that are later re-connected. To improve
the approximation factor, we split it into components more carefully, taking
the cost structure into account, and we significantly enhance the analysis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Foos_J/0/1/0/all/0/1">Josefine Foos</a>, <a href="http://arxiv.org/find/cs/1/au:+Held_S/0/1/0/all/0/1">Stephan Held</a>, <a href="http://arxiv.org/find/cs/1/au:+Spitzley_Y/0/1/0/all/0/1">Yannik Kyle Dustin Spitzley</a></p><p>Uniform cost-distance Steiner trees minimize the sum of the total length and
weighted path lengths from a dedicated root to the other terminals. They are
applied when the tree is intended for signal transmission, e.g. in chip design
or telecommunication networks. They are a special case of general cost-distance
Steiner trees, where different distance functions are used for total length and
path lengths.
</p>
<p>We improve the best published approximation factor for the uniform
cost-distance Steiner tree problem from 2.39 to 2.05. If we can approximate the
minimum-length Steiner tree problem arbitrarily well, our algorithm achieves an
approximation factor arbitrarily close to $ 1 + \frac{1}{\sqrt{2}} $. This
bound is tight in the following sense. We also prove the gap $ 1 +
\frac{1}{\sqrt{2}} $ between optimum solutions and the lower bound which we and
all previous approximation algorithms for this problem use.
</p>
<p>Similarly to previous approaches, we start with an approximate minimum-length
Steiner tree and split it into subtrees that are later re-connected. To improve
the approximation factor, we split it into components more carefully, taking
the cost structure into account, and we significantly enhance the analysis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03440'>Tight Bounds for Chordal/Interval Vertex Deletion Parameterized by Treewidth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michal Wlodarczyk</p><p>In Chordal/Interval Vertex Deletion we ask how many vertices one needs to
remove from a graph to make it chordal (respectively: interval). We study these
problems under the parameterization by treewidth $tw$ of the input graph $G$.
On the one hand, we present an algorithm for Chordal Vertex Deletion with
running time $2^{O(tw)} \cdot |V(G)|$, improving upon the running time
$2^{O(tw^2)} \cdot |V(G)|^{O(1)}$ by Jansen, de Kroon, and Wlodarczyk
(STOC'21). When a tree decomposition of width $tw$ is given, then the base of
the exponent equals $2^{\omega-1}\cdot 3 + 1$. Our algorithm is based on a
novel link between chordal graphs and graphic matroids, which allows us to
employ the framework of representative families. On the other hand, we prove
that the known $2^{O(tw \log tw)} \cdot |V(G)|$-time algorithm for Interval
Vertex Deletion cannot be improved assuming Exponential Time Hypothesis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wlodarczyk_M/0/1/0/all/0/1">Michal Wlodarczyk</a></p><p>In Chordal/Interval Vertex Deletion we ask how many vertices one needs to
remove from a graph to make it chordal (respectively: interval). We study these
problems under the parameterization by treewidth $tw$ of the input graph $G$.
On the one hand, we present an algorithm for Chordal Vertex Deletion with
running time $2^{O(tw)} \cdot |V(G)|$, improving upon the running time
$2^{O(tw^2)} \cdot |V(G)|^{O(1)}$ by Jansen, de Kroon, and Wlodarczyk
(STOC'21). When a tree decomposition of width $tw$ is given, then the base of
the exponent equals $2^{\omega-1}\cdot 3 + 1$. Our algorithm is based on a
novel link between chordal graphs and graphic matroids, which allows us to
employ the framework of representative families. On the other hand, we prove
that the known $2^{O(tw \log tw)} \cdot |V(G)|$-time algorithm for Interval
Vertex Deletion cannot be improved assuming Exponential Time Hypothesis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03693'>Fast Dynamic Programming in Trees in the MPC Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chetan Gupta, Rustam Latypov, Yannic Maus, Shreyas Pai, Simo S&#xe4;rkk&#xe4;, Jan Studen&#xfd;, Jukka Suomela, Jara Uitto, Hossein Vahidi</p><p>We present a deterministic algorithm for solving a wide range of dynamic
programming problems in trees in $O(\log D)$ rounds in the massively parallel
computation model (MPC), with $O(n^\delta)$ words of local memory per machine,
for any given constant $0 &lt; \delta &lt; 1$. Here $D$ is the diameter of the tree
and $n$ is the number of nodes--we emphasize that our running time is
independent of $n$.
</p>
<p>Our algorithm can solve many classical graph optimization problems such as
maximum weight independent set, maximum weight matching, minimum weight
dominating set, and minimum weight vertex cover. It can also be used to solve
many accumulation tasks in which some aggregate information is propagated
upwards or downwards in the tree--this includes, for example, computing the
sum, minimum, or maximum of the input labels in each subtree, as well as many
inference tasks commonly solved with belief propagation. Our algorithm can also
solve any locally checkable labeling problem (LCLs) in trees. Our algorithm
works for any reasonable representation of the input tree; for example, the
tree can be represented as a list of edges or as a string with nested
parentheses or tags. The running time of $O(\log D)$ rounds is also known to be
necessary, assuming the widely-believed $2$-cycle conjecture.
</p>
<p>Our algorithm strictly improves on two prior algorithms: (i) Bateni,
Behnezhad, Derakhshan, Hajiaghayi, and Mirrokni [ICALP'18] solve problems of
these flavors in $O(\log n)$ rounds, while our algorithm is much faster in
low-diameter trees. Furthermore, their algorithm also uses randomness, while
our algorithm is deterministic. (ii) Balliu, Latypov, Maus, Olivetti, and Uitto
[SODA'23] solve only locally checkable labeling problems in $O(\log D)$ rounds,
while our algorithm can be applied to a much broader family of problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gupta_C/0/1/0/all/0/1">Chetan Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Latypov_R/0/1/0/all/0/1">Rustam Latypov</a>, <a href="http://arxiv.org/find/cs/1/au:+Maus_Y/0/1/0/all/0/1">Yannic Maus</a>, <a href="http://arxiv.org/find/cs/1/au:+Pai_S/0/1/0/all/0/1">Shreyas Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkka_S/0/1/0/all/0/1">Simo S&#xe4;rkk&#xe4;</a>, <a href="http://arxiv.org/find/cs/1/au:+Studeny_J/0/1/0/all/0/1">Jan Studen&#xfd;</a>, <a href="http://arxiv.org/find/cs/1/au:+Suomela_J/0/1/0/all/0/1">Jukka Suomela</a>, <a href="http://arxiv.org/find/cs/1/au:+Uitto_J/0/1/0/all/0/1">Jara Uitto</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahidi_H/0/1/0/all/0/1">Hossein Vahidi</a></p><p>We present a deterministic algorithm for solving a wide range of dynamic
programming problems in trees in $O(\log D)$ rounds in the massively parallel
computation model (MPC), with $O(n^\delta)$ words of local memory per machine,
for any given constant $0 &lt; \delta &lt; 1$. Here $D$ is the diameter of the tree
and $n$ is the number of nodes--we emphasize that our running time is
independent of $n$.
</p>
<p>Our algorithm can solve many classical graph optimization problems such as
maximum weight independent set, maximum weight matching, minimum weight
dominating set, and minimum weight vertex cover. It can also be used to solve
many accumulation tasks in which some aggregate information is propagated
upwards or downwards in the tree--this includes, for example, computing the
sum, minimum, or maximum of the input labels in each subtree, as well as many
inference tasks commonly solved with belief propagation. Our algorithm can also
solve any locally checkable labeling problem (LCLs) in trees. Our algorithm
works for any reasonable representation of the input tree; for example, the
tree can be represented as a list of edges or as a string with nested
parentheses or tags. The running time of $O(\log D)$ rounds is also known to be
necessary, assuming the widely-believed $2$-cycle conjecture.
</p>
<p>Our algorithm strictly improves on two prior algorithms: (i) Bateni,
Behnezhad, Derakhshan, Hajiaghayi, and Mirrokni [ICALP'18] solve problems of
these flavors in $O(\log n)$ rounds, while our algorithm is much faster in
low-diameter trees. Furthermore, their algorithm also uses randomness, while
our algorithm is deterministic. (ii) Balliu, Latypov, Maus, Olivetti, and Uitto
[SODA'23] solve only locally checkable labeling problems in $O(\log D)$ rounds,
while our algorithm can be applied to a much broader family of problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2305.03697'>Fault-Tolerant ST-Diameter Oracles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davide Bil&#xf2;, Keerti Choudhary, Sarel Cohen, Tobias Friedrich, Simon Krogmann, Martin Schirneck</p><p>We study the problem of estimating the $ST$-diameter of a graph that is
subject to a bounded number of edge failures. An $f$-edge fault-tolerant
$ST$-diameter oracle ($f$-FDO-$ST$) is a data structure that preprocesses a
given graph $G$, two sets of vertices $S,T$, and positive integer $f$. When
queried with a set $F$ of at most $f$ edges, the oracle returns an estimate
$\widehat{D}$ of the $ST$-diameter $\operatorname{diam}(G-F,S,T)$, the maximum
distance between vertices in $S$ and $T$ in $G-F$. The oracle has stretch
$\sigma \geq 1$ if $\operatorname{diam}(G-F,S,T) \leq \widehat{D} \leq \sigma
\operatorname{diam}(G-F,S,T)$. If $S$ and $T$ both contain all vertices, the
data structure is called an $f$-edge fault-tolerant diameter oracle ($f$-FDO).
An $f$-edge fault-tolerant distance sensitivity oracles ($f$-DSO) estimates the
pairwise graph distances under up to $f$ failures.
</p>
<p>We design new $f$-FDOs and $f$-FDO-$ST$s by reducing their construction to
that of all-pairs and single-source $f$-DSOs. We obtain several new tradeoffs
between the size of the data structure, stretch guarantee, query and
preprocessing times for diameter oracles by combining our black-box reductions
with known results from the literature.
</p>
<p>We also provide an information-theoretic lower bound on the space requirement
of approximate $f$-FDOs. We show that there exists a family of graphs for which
any $f$-FDO with sensitivity $f \ge 2$ and stretch less than $5/3$ requires
$\Omega(n^{3/2})$ bits of space, regardless of the query time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bilo_D/0/1/0/all/0/1">Davide Bil&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_K/0/1/0/all/0/1">Keerti Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Sarel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrich_T/0/1/0/all/0/1">Tobias Friedrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Krogmann_S/0/1/0/all/0/1">Simon Krogmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schirneck_M/0/1/0/all/0/1">Martin Schirneck</a></p><p>We study the problem of estimating the $ST$-diameter of a graph that is
subject to a bounded number of edge failures. An $f$-edge fault-tolerant
$ST$-diameter oracle ($f$-FDO-$ST$) is a data structure that preprocesses a
given graph $G$, two sets of vertices $S,T$, and positive integer $f$. When
queried with a set $F$ of at most $f$ edges, the oracle returns an estimate
$\widehat{D}$ of the $ST$-diameter $\operatorname{diam}(G-F,S,T)$, the maximum
distance between vertices in $S$ and $T$ in $G-F$. The oracle has stretch
$\sigma \geq 1$ if $\operatorname{diam}(G-F,S,T) \leq \widehat{D} \leq \sigma
\operatorname{diam}(G-F,S,T)$. If $S$ and $T$ both contain all vertices, the
data structure is called an $f$-edge fault-tolerant diameter oracle ($f$-FDO).
An $f$-edge fault-tolerant distance sensitivity oracles ($f$-DSO) estimates the
pairwise graph distances under up to $f$ failures.
</p>
<p>We design new $f$-FDOs and $f$-FDO-$ST$s by reducing their construction to
that of all-pairs and single-source $f$-DSOs. We obtain several new tradeoffs
between the size of the data structure, stretch guarantee, query and
preprocessing times for diameter oracles by combining our black-box reductions
with known results from the literature.
</p>
<p>We also provide an information-theoretic lower bound on the space requirement
of approximate $f$-FDOs. We show that there exists a family of graphs for which
any $f$-FDO with sensitivity $f \ge 2$ and stretch less than $5/3$ requires
$\Omega(n^{3/2})$ bits of space, regardless of the query time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-05-08T00:30:00Z">Monday, May 08 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
