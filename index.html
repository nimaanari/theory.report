<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-03-09T23:31:45Z">Thursday, March 09 2023, 23:31</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, March 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://processalgebra.blogspot.com/2023/03/ten-fully-funded-phd-positions-in.html'>Ten fully-funded PhD positions in Computer Science at the Gran Sasso Science Institute</a></h3>
        <p class='tr-article-feed'>from <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>The Computer Science group at the GSSI has ten fully-funded PhD positions. See the call for applications for details. The deadline for applications is 30 May 2023. <br></p><p>The Computer Science group at the GSSI provides an excellent environment for PhD students and its group has been ranked as "excellent" by a recent national research assessment exercise. In my, admittedly biased, opinion, it is one of the places to be for research in Computer Science in Italy. </p><p>Spread the news! <br></p><p>&nbsp;<br></p><p>By Luca Aceto</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Computer Science group at the GSSI has ten fully-funded PhD positions. See the <a href="https://www.gssi.it/albo-ufficiale-online-gssi/item/download/4164_c550280ade939db61570a29ef700f63e" target="_blank">call for applications</a> for details. The deadline for applications is 30 May 2023. <br /></p><p>The <a href="https://sites.google.com/gssi.it/csgssi" target="_blank">Computer Science group at the GSSI</a> provides an excellent environment for PhD students and its group has been ranked as <a href="https://processalgebra.blogspot.com/2022/12/computer-science-and-mathematics-at.html" target="_blank">"excellent"</a> by a recent national research assessment exercise. In my, admittedly biased, opinion, it is one of the places to be for research in Computer Science in Italy. </p><p>Spread the news! <br /></p><p>&nbsp;<br /></p><p class="authors">By Luca Aceto</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T13:49:00Z">Thursday, March 09 2023, 13:49</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7094'>The False Promise of Chomskyism</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I was asked to respond to the New York Times opinion piece entitled The False Promise of ChatGPT, by Noam Chomsky along with Ian Roberts and Jeffrey Watumull (who once took my class at MIT). I&#8217;ll be busy all day at the Harvard CS department, where I&#8217;m giving a quantum talk this afternoon, but for [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I was asked to respond to the <em>New York Times</em> opinion piece entitled <a href="https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html">The False Promise of ChatGPT</a>, by Noam Chomsky along with Ian Roberts and Jeffrey Watumull (who once took my class at MIT).  I&#8217;ll be busy all day at the Harvard CS department, where I&#8217;m <a href="https://events.seas.harvard.edu/event/how_much_information_is_in_a_quantum_state">giving a quantum talk</a> this afternoon, but for now:</p>



<p>In this piece Chomsky, the intellectual godfather of an effort that failed for 60 years to build machines that can converse in ordinary language, condemns the effort that succeeded.  He condemns ChatGPT for four reasons:</p>



<ol>
<li>because it could, in principle, misinterpret sentences that could also be sentence fragments, like &#8220;John is too stubborn to talk to&#8221; (bizarrely, he never checks whether it <em>does</em> misinterpret it&#8212;I just tried it this morning and it seems to decide correctly based on context whether it&#8217;s a sentence or a sentence fragment, much like I would!);</li>



<li>because it doesn’t learn the way humans do (personally, I think ChatGPT and other large language models have <em>massively</em> illuminated at least one component of the human language faculty, what you could call its <a href="https://en.wikipedia.org/wiki/Predictive_coding">predictive coding</a> component, though clearly not all of it);</li>



<li>because it could learn false facts or grammatical systems if fed false training data (how could it be otherwise?); and</li>



<li>most of all because it’s “amoral,” refusing to take a stand on potentially controversial issues (he gives an example involving the ethics of terraforming Mars).</li>
</ol>



<p>This last, of course, is a <em>choice</em>, imposed by OpenAI using reinforcement learning.  The reason for it is simply that ChatGPT is a consumer product.  The same people who condemn it for not taking controversial stands would condemn it much more loudly if it did — just like the same people who condemn it for wrong answers and explanations, would condemn it equally for right ones (Chomsky promises as much in the essay).</p>



<p>I submit that, like the Jesuit astronomers declining to look through Galileo’s telescope, what Chomsky and his followers are ultimately angry at is reality itself, for having the temerity to offer something up that they didn’t predict and that doesn’t fit their worldview.</p>



<p>[<em>Note for people who might be visiting this blog for the first time:</em> I&#8217;m a CS professor at UT Austin, on leave for one year to work at OpenAI on the theoretical foundations of AI safety.  I accepted OpenAI&#8217;s offer in part because I already held the views here, or something close to them; and given that I could see how large language models were poised to change the world for good and ill, I wanted to be part of the effort to help prevent their misuse.  No one at OpenAI asked me to write this or saw it beforehand, and I don&#8217;t even know to what extent they agree with it.]</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T12:01:55Z">Thursday, March 09 2023, 12:01</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/021'>TR23-021 |  Range Avoidance for Constant-Depth Circuits: Hardness and Algorithms | 

	Sidhant Saraogi, 

	Alexander Golovnev, 

	Satyajeet Nagargoje, 

	Karthik Gajulapalli</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Range Avoidance (AVOID) is a total search problem where, given a Boolean circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a $y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$, $NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami, Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs, and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing conditional hardness of the $NC^0_4$-AVOID problem. On the other hand, $NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about the complexity of $NC^0_3$-AVOID open.

We give the first reduction of an explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and, thus, a super-linear lower bound on the size of log-depth circuits.

We also give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required larger stretch, $m \geq n^{k-1}$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Range Avoidance (AVOID) is a total search problem where, given a Boolean circuit $C\colon\{0,1\}^n\to\{0,1\}^m$, $m&gt;n$, the task is to find a $y\in\{0,1\}^m$ outside the range of $C$. For an integer $k\geq 2$, $NC^0_k$-AVOID is a special case of AVOID where each output bit of $C$ depends on at most $k$ input bits. Ren, Santhanam, and Wang (FOCS 2022) and Guruswami, Lyu, and Wang (RANDOM 2022) proved that explicit constructions of functions of high circuit complexity, rigid matrices, optimal linear codes, Ramsey graphs, and other combinatorial objects reduce to $NC^0_4$-AVOID, thus establishing conditional hardness of the $NC^0_4$-AVOID problem. On the other hand, $NC^0_2$-AVOID admits polynomial-time algorithms, leaving the question about the complexity of $NC^0_3$-AVOID open.

We give the first reduction of an explicit construction question to $NC^0_3$-AVOID. Specifically, we prove that a polynomial-time algorithm (with an $NP$ oracle) for $NC^0_3$-AVOID for the case of $m=n+n^{2/3}$ would imply an explicit construction of a rigid matrix, and, thus, a super-linear lower bound on the size of log-depth circuits.

We also give deterministic polynomial-time algorithms for all $NC^0_k$-AVOID problems for ${m\geq n^{k-1}/\log(n)}$. Prior work required an $NP$ oracle, and required larger stretch, $m \geq n^{k-1}$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T09:26:46Z">Thursday, March 09 2023, 09:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04298'>Classical vs Quantum Advice under Classically-Accessible Oracle</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xingjian Li, Qipeng Liu, Angelos Pelecanos, Takashi Yamakawa</p><p>It is a long-standing open question to construct a classical oracle relative
to which BQP/qpoly $\neq$ BQP/poly or QMA $\neq$ QCMA. In this paper, we
construct classically-accessible classical oracles relative to which BQP/qpoly
$\neq$ BQP/poly. Here, classically-accessible classical oracles are oracles
that can be accessed only classically even for quantum algorithms. Based on a
similar technique, we also show an alternative proof for separation of QMA and
QCMA relative to a distributional quantumly-accessible classical oracles, which
was recently shown by Natarajan and Nirkhe.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Li_X/0/1/0/all/0/1">Xingjian Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Liu_Q/0/1/0/all/0/1">Qipeng Liu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pelecanos_A/0/1/0/all/0/1">Angelos Pelecanos</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yamakawa_T/0/1/0/all/0/1">Takashi Yamakawa</a></p><p>It is a long-standing open question to construct a classical oracle relative
to which BQP/qpoly $\neq$ BQP/poly or QMA $\neq$ QCMA. In this paper, we
construct classically-accessible classical oracles relative to which BQP/qpoly
$\neq$ BQP/poly. Here, classically-accessible classical oracles are oracles
that can be accessed only classically even for quantum algorithms. Based on a
similar technique, we also show an alternative proof for separation of QMA and
QCMA relative to a distributional quantumly-accessible classical oracles, which
was recently shown by Natarajan and Nirkhe.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04613'>The Descriptive Complexity of Graph Neural Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Martin Grohe</p><p>We analyse the power of graph neural networks (GNNs) in terms of Boolean
circuit complexity and descriptive complexity.
</p>
<p>We prove that the graph queries that can be computed by a polynomial-size
bounded-depth family of GNNs are exactly those definable in the guarded
fragment GFO+C of first-order logic with counting and with built-in relations.
This puts GNNs in the circuit complexity class TC^0. Remarkably, the GNN
families may use arbitrary real weights and a wide class of activation
functions that includes the standard ReLU, logistic "sigmoid", and hyperbolic
tangent functions. If the GNNs are allowed to use random initialisation and
global readout (both standard features of GNNs widely used in practice), they
can compute exactly the same queries as bounded depth Boolean circuits with
threshold gates, that is, exactly the queries in TC^0. Moreover, we show that
queries computable by a single GNN with piecewise linear activations and
rational weights are definable in GFO+C without built-in relations. Therefore,
they are contained in uniform TC^0.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1">Martin Grohe</a></p><p>We analyse the power of graph neural networks (GNNs) in terms of Boolean
circuit complexity and descriptive complexity.
</p>
<p>We prove that the graph queries that can be computed by a polynomial-size
bounded-depth family of GNNs are exactly those definable in the guarded
fragment GFO+C of first-order logic with counting and with built-in relations.
This puts GNNs in the circuit complexity class TC^0. Remarkably, the GNN
families may use arbitrary real weights and a wide class of activation
functions that includes the standard ReLU, logistic "sigmoid", and hyperbolic
tangent functions. If the GNNs are allowed to use random initialisation and
global readout (both standard features of GNNs widely used in practice), they
can compute exactly the same queries as bounded depth Boolean circuits with
threshold gates, that is, exactly the queries in TC^0. Moreover, we show that
queries computable by a single GNN with piecewise linear activations and
rational weights are definable in GFO+C without built-in relations. Therefore,
they are contained in uniform TC^0.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04350'>Improved Bounds for Covering Paths and Trees in the Plane</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ahmad Biniaz</p><p>A covering path for a planar point set is a path drawn in the plane with
straight-line edges such that every point lies at a vertex or on an edge of the
path. A covering tree is defined analogously. Let $\pi(n)$ be the minimum
number such that every set of $n$ points in the plane can be covered by a
noncrossing path with at most $\pi(n)$ edges. Let $\tau(n)$ be the analogous
number for noncrossing covering trees. Dumitrescu, Gerbner, Keszegh, and T\'oth
(Discrete &amp; Computational Geometry, 2014) established the following
inequalities: \[\frac{5n}{9} - O(1) &lt; \pi(n) &lt;
\left(1-\frac{1}{601080391}\right)n, \quad\text{and} \quad\frac{9n}{17} - O(1)
&lt; \tau(n)\leqslant \left\lfloor\frac{5n}{6}\right\rfloor.\] We report the
following improved upper bounds: \[\pi(n)\leqslant
\left(1-\frac{1}{22}\right)n, \quad\text{and}\quad \tau(n)\leqslant
\left\lceil\frac{4n}{5}\right\rceil.\]
</p>
<p>In the same context we study rainbow polygons. For a set of colored points in
the plane, a perfect rainbow polygon is a simple polygon that contains exactly
one point of each color in its interior or on its boundary. Let $\rho(k)$ be
the minimum number such that every $k$-colored point set in the plane admits a
perfect rainbow polygon of size $\rho(k)$. Flores-Pe\~naloza, Kano,
Mart\'inez-Sandoval, Orden, Tejel, T\'oth, Urrutia, and Vogtenhuber (Discrete
Mathematics, 2021) proved that $20k/19 - O(1) &lt;\rho(k) &lt; 10k/7 + O(1).$ We
report the improved upper bound $\rho(k)&lt; 7k/5 + O(1)$.
</p>
<p>To obtain the improved bounds we present simple $O(n\log n)$-time algorithms
that achieve paths, trees, and polygons with our desired number of edges.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Biniaz_A/0/1/0/all/0/1">Ahmad Biniaz</a></p><p>A covering path for a planar point set is a path drawn in the plane with
straight-line edges such that every point lies at a vertex or on an edge of the
path. A covering tree is defined analogously. Let $\pi(n)$ be the minimum
number such that every set of $n$ points in the plane can be covered by a
noncrossing path with at most $\pi(n)$ edges. Let $\tau(n)$ be the analogous
number for noncrossing covering trees. Dumitrescu, Gerbner, Keszegh, and T\'oth
(Discrete &amp; Computational Geometry, 2014) established the following
inequalities: \[\frac{5n}{9} - O(1) &lt; \pi(n) &lt;
\left(1-\frac{1}{601080391}\right)n, \quad\text{and} \quad\frac{9n}{17} - O(1)
&lt; \tau(n)\leqslant \left\lfloor\frac{5n}{6}\right\rfloor.\] We report the
following improved upper bounds: \[\pi(n)\leqslant
\left(1-\frac{1}{22}\right)n, \quad\text{and}\quad \tau(n)\leqslant
\left\lceil\frac{4n}{5}\right\rceil.\]
</p>
<p>In the same context we study rainbow polygons. For a set of colored points in
the plane, a perfect rainbow polygon is a simple polygon that contains exactly
one point of each color in its interior or on its boundary. Let $\rho(k)$ be
the minimum number such that every $k$-colored point set in the plane admits a
perfect rainbow polygon of size $\rho(k)$. Flores-Pe\~naloza, Kano,
Mart\'inez-Sandoval, Orden, Tejel, T\'oth, Urrutia, and Vogtenhuber (Discrete
Mathematics, 2021) proved that $20k/19 - O(1) &lt;\rho(k) &lt; 10k/7 + O(1).$ We
report the improved upper bound $\rho(k)&lt; 7k/5 + O(1)$.
</p>
<p>To obtain the improved bounds we present simple $O(n\log n)$-time algorithms
that achieve paths, trees, and polygons with our desired number of edges.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04722'>B-Treaps Revised: Write Efficient Randomized Block Search Trees with High Load</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Roodabeh Safavi, Martin P. Seybold</p><p>Uniquely represented data structures represent each logical state with a
unique storage state. We study the problem of maintaining a dynamic set of $n$
keys from a totally ordered universe in this context.
</p>
<p>We introduce a two-layer data structure called
$(\alpha,\varepsilon)$-Randomized Block Search Tree (RBST) that is uniquely
represented and suitable for external memory. Though RBSTs naturally generalize
the well-known binary Treaps, several new ideas are needed to analyze the {\em
expected} search, update, and storage, efficiency in terms of block-reads,
block-writes, and blocks stored. We prove that searches have
$O(\varepsilon^{-1} + \log_\alpha n)$ block-reads, that $(\alpha,
\varepsilon)$-RBSTs have an asymptotic load-factor of at least
$(1-\varepsilon)$ for every $\varepsilon \in (0,1/2]$, and that dynamic updates
perform $O(\varepsilon^{-1} + \log_\alpha(n)/\alpha)$ block-writes, i.e.
$O(1/\varepsilon)$ writes if $\alpha=\Omega(\frac{\log n}{\log \log n} )$. Thus
$(\alpha, \varepsilon)$-RBSTs provide improved search, storage-, and
write-efficiency bounds in regard to the known, uniquely represented B-Treap
[Golovin; ICALP'09].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Safavi_R/0/1/0/all/0/1">Roodabeh Safavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Seybold_M/0/1/0/all/0/1">Martin P. Seybold</a></p><p>Uniquely represented data structures represent each logical state with a
unique storage state. We study the problem of maintaining a dynamic set of $n$
keys from a totally ordered universe in this context.
</p>
<p>We introduce a two-layer data structure called
$(\alpha,\varepsilon)$-Randomized Block Search Tree (RBST) that is uniquely
represented and suitable for external memory. Though RBSTs naturally generalize
the well-known binary Treaps, several new ideas are needed to analyze the {\em
expected} search, update, and storage, efficiency in terms of block-reads,
block-writes, and blocks stored. We prove that searches have
$O(\varepsilon^{-1} + \log_\alpha n)$ block-reads, that $(\alpha,
\varepsilon)$-RBSTs have an asymptotic load-factor of at least
$(1-\varepsilon)$ for every $\varepsilon \in (0,1/2]$, and that dynamic updates
perform $O(\varepsilon^{-1} + \log_\alpha(n)/\alpha)$ block-writes, i.e.
$O(1/\varepsilon)$ writes if $\alpha=\Omega(\frac{\log n}{\log \log n} )$. Thus
$(\alpha, \varepsilon)$-RBSTs provide improved search, storage-, and
write-efficiency bounds in regard to the known, uniquely represented B-Treap
[Golovin; ICALP'09].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04199'>Diversity Embeddings and the Hypergraph Sparsest Cut</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam D. Jozefiak, F. Bruce Shepherd</p><p>Good approximations have been attained for the sparsest cut problem by
rounding solutions to convex relaxations via low-distortion metric embeddings.
Recently, Bryant and Tupper showed that this approach extends to the hypergraph
setting by formulating a linear program whose solutions are so-called
diversities which are rounded via diversity embeddings into $\ell_1$.
Diversities are a generalization of metric spaces in which the nonnegative
function is defined on all subsets as opposed to only on pairs of elements.
</p>
<p>We show that this approach yields a polytime $O(\log{n})$-approximation when
either the supply or demands are given by a graph. This result improves upon
Plotkin et al.'s $O(\log{(kn)}\log{n})$-approximation, where $k$ is the number
of demands, for the setting where the supply is given by a graph and the
demands are given by a hypergraph. Additionally, we provide a polytime
$O(\min{\{r_G,r_H\}}\log{r_H}\log{n})$-approximation for when the supply and
demands are given by hypergraphs whose hyperedges are bounded in cardinality by
$r_G$ and $r_H$ respectively.
</p>
<p>To establish these results we provide an $O(\log{n})$-distortion $\ell_1$
embedding for the class of diversities known as diameter diversities. This
improves upon Bryant and Tupper's $O(\log\^2{n})$-distortion embedding. The
smallest known distortion with which an arbitrary diversity can be embedded
into $\ell_1$ is $O(n)$. We show that for any $\epsilon &gt; 0$ and any $p&gt;0$,
there is a family of diversities which cannot be embedded into $\ell_1$ in
polynomial time with distortion smaller than $O(n^{1-\epsilon})$ based on
querying the diversities on sets of cardinality at most $O(\log^p{n})$, unless
$P=NP$. This disproves (an algorithmic refinement of) Bryant and Tupper's
conjecture that there exists an $O(\sqrt{n})$-distortion $\ell_1$ embedding
based off a diversity's induced metric.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jozefiak_A/0/1/0/all/0/1">Adam D. Jozefiak</a>, <a href="http://arxiv.org/find/cs/1/au:+Shepherd_F/0/1/0/all/0/1">F. Bruce Shepherd</a></p><p>Good approximations have been attained for the sparsest cut problem by
rounding solutions to convex relaxations via low-distortion metric embeddings.
Recently, Bryant and Tupper showed that this approach extends to the hypergraph
setting by formulating a linear program whose solutions are so-called
diversities which are rounded via diversity embeddings into $\ell_1$.
Diversities are a generalization of metric spaces in which the nonnegative
function is defined on all subsets as opposed to only on pairs of elements.
</p>
<p>We show that this approach yields a polytime $O(\log{n})$-approximation when
either the supply or demands are given by a graph. This result improves upon
Plotkin et al.'s $O(\log{(kn)}\log{n})$-approximation, where $k$ is the number
of demands, for the setting where the supply is given by a graph and the
demands are given by a hypergraph. Additionally, we provide a polytime
$O(\min{\{r_G,r_H\}}\log{r_H}\log{n})$-approximation for when the supply and
demands are given by hypergraphs whose hyperedges are bounded in cardinality by
$r_G$ and $r_H$ respectively.
</p>
<p>To establish these results we provide an $O(\log{n})$-distortion $\ell_1$
embedding for the class of diversities known as diameter diversities. This
improves upon Bryant and Tupper's $O(\log\^2{n})$-distortion embedding. The
smallest known distortion with which an arbitrary diversity can be embedded
into $\ell_1$ is $O(n)$. We show that for any $\epsilon &gt; 0$ and any $p&gt;0$,
there is a family of diversities which cannot be embedded into $\ell_1$ in
polynomial time with distortion smaller than $O(n^{1-\epsilon})$ based on
querying the diversities on sets of cardinality at most $O(\log^p{n})$, unless
$P=NP$. This disproves (an algorithmic refinement of) Bryant and Tupper's
conjecture that there exists an $O(\sqrt{n})$-distortion $\ell_1$ embedding
based off a diversity's induced metric.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04205'>Investigating the complexity of the double distance problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marilia D. V. Braga, Leonie R. Brockmann, Katharina Klerx, Jens Stoye</p><p>Two genomes over the same set of gene families form a canonical pair when
each of them has exactly one gene from each family. Different distances of
canonical genomes can be derived from a structure called breakpoint graph,
which represents the relation between the two given genomes as a collection of
cycles of even length and paths. Then, the breakpoint distance is equal to n -
(c_2 + p_0/2), where n is the number of genes, c_2 is the number of cycles of
length 2 and p_0 is the number of paths of length 0. Similarly, when the
considered rearrangements are those modeled by the double-cut-and-join (DCJ)
operation, the rearrangement distance is n - (c + p_e/2), where c is the total
number of cycles and p_e is the total number of even paths.
</p>
<p>The distance formulation is a basic unit for several other combinatorial
problems related to genome evolution and ancestral reconstruction, such as
median or double distance. Interestingly, both median and double distance
problems can be solved in polynomial time for the breakpoint distance, while
they are NP-hard for the rearrangement distance. One way of exploring the
complexity space between these two extremes is to consider the {\sigma}_k
distance, defined to be n - [c_2 + c_4 + ... + c_k + (p_0 + p_2 + ... +p_k)/2],
and increasingly investigate the complexities of median and double distance for
the {\sigma}_4 distance, then the {\sigma}_6 distance, and so on. While for the
median much effort was done in our and in other research groups but no progress
was obtained even for the {\sigma}_4 distance, for solving the double distance
under {\sigma}_4 and {\sigma}_6 distances we could devise linear time
algorithms, which we present here.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Braga_M/0/1/0/all/0/1">Marilia D. V. Braga</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockmann_L/0/1/0/all/0/1">Leonie R. Brockmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Klerx_K/0/1/0/all/0/1">Katharina Klerx</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoye_J/0/1/0/all/0/1">Jens Stoye</a></p><p>Two genomes over the same set of gene families form a canonical pair when
each of them has exactly one gene from each family. Different distances of
canonical genomes can be derived from a structure called breakpoint graph,
which represents the relation between the two given genomes as a collection of
cycles of even length and paths. Then, the breakpoint distance is equal to n -
(c_2 + p_0/2), where n is the number of genes, c_2 is the number of cycles of
length 2 and p_0 is the number of paths of length 0. Similarly, when the
considered rearrangements are those modeled by the double-cut-and-join (DCJ)
operation, the rearrangement distance is n - (c + p_e/2), where c is the total
number of cycles and p_e is the total number of even paths.
</p>
<p>The distance formulation is a basic unit for several other combinatorial
problems related to genome evolution and ancestral reconstruction, such as
median or double distance. Interestingly, both median and double distance
problems can be solved in polynomial time for the breakpoint distance, while
they are NP-hard for the rearrangement distance. One way of exploring the
complexity space between these two extremes is to consider the {\sigma}_k
distance, defined to be n - [c_2 + c_4 + ... + c_k + (p_0 + p_2 + ... +p_k)/2],
and increasingly investigate the complexities of median and double distance for
the {\sigma}_4 distance, then the {\sigma}_6 distance, and so on. While for the
median much effort was done in our and in other research groups but no progress
was obtained even for the {\sigma}_4 distance, for solving the double distance
under {\sigma}_4 and {\sigma}_6 distances we could devise linear time
algorithms, which we present here.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04288'>Polynomial Time and Private Learning of Unbounded Gaussian Mixture Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jamil Arbas, Hassan Ashtiani, Christopher Liaw</p><p>We study the problem of privately estimating the parameters of
$d$-dimensional Gaussian Mixture Models (GMMs) with $k$ components. For this,
we develop a technique to reduce the problem to its non-private counterpart.
This allows us to privatize existing non-private algorithms in a blackbox
manner, while incurring only a small overhead in the sample complexity and
running time. As the main application of our framework, we develop an
$(\varepsilon, \delta)$-differentially private algorithm to learn GMMs using
the non-private algorithm of Moitra and Valiant [MV10] as a blackbox.
Consequently, this gives the first sample complexity upper bound and first
polynomial time algorithm for privately learning GMMs without any boundedness
assumptions on the parameters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Arbas_J/0/1/0/all/0/1">Jamil Arbas</a>, <a href="http://arxiv.org/find/stat/1/au:+Ashtiani_H/0/1/0/all/0/1">Hassan Ashtiani</a>, <a href="http://arxiv.org/find/stat/1/au:+Liaw_C/0/1/0/all/0/1">Christopher Liaw</a></p><p>We study the problem of privately estimating the parameters of
$d$-dimensional Gaussian Mixture Models (GMMs) with $k$ components. For this,
we develop a technique to reduce the problem to its non-private counterpart.
This allows us to privatize existing non-private algorithms in a blackbox
manner, while incurring only a small overhead in the sample complexity and
running time. As the main application of our framework, we develop an
$(\varepsilon, \delta)$-differentially private algorithm to learn GMMs using
the non-private algorithm of Moitra and Valiant [MV10] as a blackbox.
Consequently, this gives the first sample complexity upper bound and first
polynomial time algorithm for privately learning GMMs without any boundedness
assumptions on the parameters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04301'>Optimal Sparse Recovery with Decision Stumps</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kiarash Banihashem, MohammadTaghi Hajiaghayi, Max Springer</p><p>Decision trees are widely used for their low computational cost, good
predictive performance, and ability to assess the importance of features.
Though often used in practice for feature selection, the theoretical guarantees
of these methods are not well understood. We here obtain a tight finite sample
bound for the feature selection problem in linear regression using single-depth
decision trees. We examine the statistical properties of these "decision
stumps" for the recovery of the $s$ active features from $p$ total features,
where $s \ll p$. Our analysis provides tight sample performance guarantees on
high-dimensional sparse systems which align with the finite sample bound of
$O(s \log p)$ as obtained by Lasso, improving upon previous bounds for both the
median and optimal splitting criteria. Our results extend to the non-linear
regime as well as arbitrary sub-Gaussian distributions, demonstrating that tree
based methods attain strong feature selection properties under a wide variety
of settings and further shedding light on the success of these methods in
practice. As a byproduct of our analysis, we show that we can provably
guarantee recovery even when the number of active features $s$ is unknown. We
further validate our theoretical results and proof methodology using
computational experiments.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Banihashem_K/0/1/0/all/0/1">Kiarash Banihashem</a>, <a href="http://arxiv.org/find/stat/1/au:+Hajiaghayi_M/0/1/0/all/0/1">MohammadTaghi Hajiaghayi</a>, <a href="http://arxiv.org/find/stat/1/au:+Springer_M/0/1/0/all/0/1">Max Springer</a></p><p>Decision trees are widely used for their low computational cost, good
predictive performance, and ability to assess the importance of features.
Though often used in practice for feature selection, the theoretical guarantees
of these methods are not well understood. We here obtain a tight finite sample
bound for the feature selection problem in linear regression using single-depth
decision trees. We examine the statistical properties of these "decision
stumps" for the recovery of the $s$ active features from $p$ total features,
where $s \ll p$. Our analysis provides tight sample performance guarantees on
high-dimensional sparse systems which align with the finite sample bound of
$O(s \log p)$ as obtained by Lasso, improving upon previous bounds for both the
median and optimal splitting criteria. Our results extend to the non-linear
regime as well as arbitrary sub-Gaussian distributions, demonstrating that tree
based methods attain strong feature selection properties under a wide variety
of settings and further shedding light on the success of these methods in
practice. As a byproduct of our analysis, we show that we can provably
guarantee recovery even when the number of active features $s$ is unknown. We
further validate our theoretical results and proof methodology using
computational experiments.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04478'>Change a Bit to save Bytes: Compression for Floating Point Time-Series Data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Francesco Taurone, Daniel E. Lucani, Marcell Feh&#xe9;r, Qi Zhang</p><p>The number of IoT devices is expected to continue its dramatic growth in the
coming years and, with it, a growth in the amount of data to be transmitted,
processed and stored. Compression techniques that support analytics directly on
the compressed data could pave the way for systems to scale efficiently to
these growing demands. This paper proposes two novel methods for preprocessing
a stream of floating point data to improve the compression capabilities of
various IoT data compressors. In particular, these techniques are shown to be
helpful with recent compressors that allow for random access and analytics
while maintaining good compression. Our techniques improve compression with
reductions up to 80% when allowing for at most 1% of recovery error.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Taurone_F/0/1/0/all/0/1">Francesco Taurone</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucani_D/0/1/0/all/0/1">Daniel E. Lucani</a>, <a href="http://arxiv.org/find/cs/1/au:+Feher_M/0/1/0/all/0/1">Marcell Feh&#xe9;r</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a></p><p>The number of IoT devices is expected to continue its dramatic growth in the
coming years and, with it, a growth in the amount of data to be transmitted,
processed and stored. Compression techniques that support analytics directly on
the compressed data could pave the way for systems to scale efficiently to
these growing demands. This paper proposes two novel methods for preprocessing
a stream of floating point data to improve the compression capabilities of
various IoT data compressors. In particular, these techniques are shown to be
helpful with recent compressors that allow for random access and analytics
while maintaining good compression. Our techniques improve compression with
reductions up to 80% when allowing for at most 1% of recovery error.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04555'>Streaming Kernel PCA Algorithm With Small Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yichuan Deng, Zhao Song, Zifan Wang, Han Zhang</p><p>Principal Component Analysis (PCA) is a widely used technique in machine
learning, data analysis and signal processing. With the increase in the size
and complexity of datasets, it has become important to develop low-space usage
algorithms for PCA. Streaming PCA has gained significant attention in recent
years, as it can handle large datasets efficiently. The kernel method, which is
commonly used in learning algorithms such as Support Vector Machines (SVMs),
has also been applied in PCA algorithms.
</p>
<p>We propose a streaming algorithm for Kernel PCA problems based on the
traditional scheme by Oja. Our algorithm addresses the challenge of reducing
the memory usage of PCA while maintaining its accuracy. We analyze the
performance of our algorithm by studying the conditions under which it
succeeds. Specifically, we show that, when the spectral ratio $R :=
\lambda_1/\lambda_2$ of the target covariance matrix is lower bounded by $C
\cdot \log n\cdot \log d$, the streaming PCA can be solved with $O(d)$ space
cost.
</p>
<p>Our proposed algorithm has several advantages over existing methods. First,
it is a streaming algorithm that can handle large datasets efficiently. Second,
it employs the kernel method, which allows it to capture complex nonlinear
relationships among data points. Third, it has a low-space usage, making it
suitable for applications where memory is limited.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yichuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a></p><p>Principal Component Analysis (PCA) is a widely used technique in machine
learning, data analysis and signal processing. With the increase in the size
and complexity of datasets, it has become important to develop low-space usage
algorithms for PCA. Streaming PCA has gained significant attention in recent
years, as it can handle large datasets efficiently. The kernel method, which is
commonly used in learning algorithms such as Support Vector Machines (SVMs),
has also been applied in PCA algorithms.
</p>
<p>We propose a streaming algorithm for Kernel PCA problems based on the
traditional scheme by Oja. Our algorithm addresses the challenge of reducing
the memory usage of PCA while maintaining its accuracy. We analyze the
performance of our algorithm by studying the conditions under which it
succeeds. Specifically, we show that, when the spectral ratio $R :=
\lambda_1/\lambda_2$ of the target covariance matrix is lower bounded by $C
\cdot \log n\cdot \log d$, the streaming PCA can be solved with $O(d)$ space
cost.
</p>
<p>Our proposed algorithm has several advantages over existing methods. First,
it is a streaming algorithm that can handle large datasets efficiently. Second,
it employs the kernel method, which allows it to capture complex nonlinear
relationships among data points. Third, it has a low-space usage, making it
suitable for applications where memory is limited.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04771'>Interior-point methods on manifolds: theory and applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Harold Nieuwboer, Michael Walter</p><p>Interior-point methods offer a highly versatile framework for convex
optimization that is effective in theory and practice. A key notion in their
theory is that of a self-concordant barrier. We give a suitable generalization
of self-concordance to Riemannian manifolds and show that it gives the same
structural results and guarantees as in the Euclidean setting, in particular
local quadratic convergence of Newton's method. We then analyze a short-step
path-following method for optimizing compatible objectives over a convex domain
for which one has a self-concordant barrier, and obtain the standard complexity
guarantees as in the Euclidean setting. We show that on the positive-definite
matrices and other symmetric spaces, the squared distance to a point is a
self-concordant function. Our work is motivated by recent progress on scaling
problems and non-commutative optimization, and we show that these fit into our
framework, yielding algorithms with state-of-the-art complexity guarantees.
Furthermore, we show how to apply our methods to computing geometric medians on
spaces with constant negative curvature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Nieuwboer_H/0/1/0/all/0/1">Harold Nieuwboer</a>, <a href="http://arxiv.org/find/math/1/au:+Walter_M/0/1/0/all/0/1">Michael Walter</a></p><p>Interior-point methods offer a highly versatile framework for convex
optimization that is effective in theory and practice. A key notion in their
theory is that of a self-concordant barrier. We give a suitable generalization
of self-concordance to Riemannian manifolds and show that it gives the same
structural results and guarantees as in the Euclidean setting, in particular
local quadratic convergence of Newton's method. We then analyze a short-step
path-following method for optimizing compatible objectives over a convex domain
for which one has a self-concordant barrier, and obtain the standard complexity
guarantees as in the Euclidean setting. We show that on the positive-definite
matrices and other symmetric spaces, the squared distance to a point is a
self-concordant function. Our work is motivated by recent progress on scaling
problems and non-commutative optimization, and we show that these fit into our
framework, yielding algorithms with state-of-the-art complexity guarantees.
Furthermore, we show how to apply our methods to computing geometric medians on
spaces with constant negative curvature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-09T01:30:00Z">Thursday, March 09 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, March 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/03/08/more-mathematics-books.html'>More mathematics books by women</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          For the last several years, I’ve been celebrating International Women’s Day by posting lists of mathematics books written or coauthored by women: 2020, 2021, 2022. Here’s another set. The links go to Wikipedia articles on the books, where you can find more information about them collated from their published reviews. The level and selection is, as usual, random, based mainly on whether the book’s topic caught my interest and it had enough published reviews to justify a Wikipedia article.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>For the last several years, I’ve been celebrating International Women’s Day by posting lists of mathematics books written or coauthored by women: <a href="/blog/2020/03/08/mathematics-books-women.html">2020</a>, <a href="/blog/2021/03/08/more-mathematics-books.html">2021</a>, <a href="/blog/2022/03/08/mathematics-books-by-women.html">2022</a>. Here’s another set. The links go to Wikipedia articles on the books, where you can find more information about them collated from their published reviews. The level and selection is, as usual, random, based mainly on whether the book’s topic caught my interest and it had enough published reviews to justify a Wikipedia article.</p>

<ul>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Geometry_of_an_Art">The Geometry of an Art: The History of the Mathematical Theory of Perspective from Alberti to Monge</a></em> (2007), Kirsti Andersen. The development of the mathematics of perspective and descriptive geometry, and its applications by European artists, from the 15th to 18th centuries.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Extrinsic_Geometric_Flows">Extrinsic Geometric Flows</a></em> (2020), Ben Andrews, Bennett Chow, Christine Guenther, and Mat Langford. A geometric flow is a way of continuously moving a curve, surface, or other shape, with the speed and direction of motion depending on its shape. It is “extrinsic” when the flow depends on a higher-dimensional space in which the moving object is embedded, rather than just on the intrinsic geometry of the object itself. This is a graduate textbook on the subject.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Spatial_Mathematics:_Theory_and_Practice_through_Mapping">Spatial Mathematics: Theory and Practice through Mapping</a></em> (2013), Sandra Arlinghaus and Joseph Kerski. The mathematical background behind geodesy and spatial visualization in geographic information systems.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Problem_Solving_Through_Recreational_Mathematics">Problem Solving Through Recreational Mathematics</a></em> (1980), Bonnie Averbach and Orin Chein. Despite the title this is an undergraduate textbook, for general education courses aimed at non-mathematics students. Its premise is that the use of fun “recreational” problems can help motivate these students to learn mathematical problem-solving techniques.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Geometric_and_Topological_Inference">Geometric and Topological Inference</a></em> (2018), Jean-Daniel Boissonnat, Frédéric Chazal, and Mariette Yvinec. Computational geometry meets machine learning.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Independence_Theory_in_Combinatorics">Independence Theory in Combinatorics: An Introductory Account with Applications to Graphs and Transversals</a></em> (1980), Victor Bryant and Hazel Perfect. An undergraduate text on matroid theory, with a particular focus on graph-theoretic applications of matroids.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Beyond_Infinity_(mathematics_book)">Beyond Infinity: An Expedition to the Outer Limits of Mathematics</a></em> (2017), Eugenia Cheng. A general-audience book looking at the many ways mathematics has approached the infinite.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Symmetries_of_Things">The Symmetries of Things</a></em> (2008), John Horton Conway, Heidi Burgiel, and Chaim Goodman-Strauss. A bit annoying for its frequent use of neologism and revisionist history, but packed with detail about discrete symmetries of geometric objects.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/A_Biography_of_Maria_Gaetana_Agnesi">A Biography of Maria Gaetana Agnesi</a></em> (2008), Antonella Cupillari. This mainly consists of a translation of Antonio Francesco Frisi’s Italian-language biography of Agnesi, augmented with many pages of notes and with translations of some of Agnesi’s mathematical works.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Finding_Ellipses">Finding Ellipses: What Blaschke Products, Poncelet’s Theorem, and the Numerical Range Know about Each Other</a></em> (2019), Ulrich Daepp, Pamela Gorkin, Andrew Shaffer, and Karl Voss. An undergraduate-level exposition of some deep connections between functional analysis (analytic functions with specified zeros), geometry (polygons simultaneously inscribed in and circumscribing conics), and linear algebra (convex sets containing the eigenvalues of a matrix).</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Introduction_to_Lattices_and_Order">Introduction to Lattices and Order</a></em> (1990, 2002), Brian A. Davey and Hilary Priestley. A graduate textbook on order theory, also noteworthy for its tips on how to use LaTeX to make order-theoretic mathematical diagrams.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Geometry_of_the_Octonions">The Geometry of the Octonions</a></em> (2015), Tevian Dray and Corinne Manogue. Beyond the real numbers, complex numbers, and quaternions, the next step is the octonions, a division algebra but not a ring. This book surveys this topic at an advanced undergraduate level.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Cube_Made_Interesting">The Cube Made Interesting</a></em> (1960, 1964), Aniela Ehrenfeucht. Aimed at high school students, and originally written in Polish, on the rotational symmetries of a cube, its colorings, and on the ability to pass a cube through a hole in an equal-sized cube (“Prince Rupert’s cube”), illustrated with red-blue anaglyphic 3d visualizations.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Erd%C5%91s_Distance_Problem">The Erdős Distance Problem</a></em> (2011), Julia Garibaldi, Alex Iosevich, and Steven Senger, an advanced undergraduate monograph on the problem of arranging points to make as few distinct distances as possible, unfortunately made mostly obsolete soon after its publication by the polynomial method of Larry Guth and Nets Katz.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Lumen_Naturae">Lumen Naturae: Visions of the Abstract in Art and Mathematics</a></em> (2020), Matilde Marcolli. On inspirations and analogies connecting modern art, mathematics, and mathematical physics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Black_Mathematicians_and_Their_Works">Black Mathematicians and Their Works</a></em> (1980), Virginia Newell, Joella Gipson, L. Waldo Rich, and Beauregard Stubblefield. Brief biographies of 62 black mathematicians, and reprints of 26 of their papers on mathematics and mathematics education, maybe the only book of its kind.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/From_Zero_to_Infinity">From Zero to Infinity: What Makes Numbers Interesting</a></em> (1955, …, 2006), Constance Reid. A classic of general-audience mathematics exposition, on different kinds of numbers and topics in number theory.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Math_on_Trial">Math on Trial: How Numbers Get Used and Abused in the Courtroom</a></em> (2013), Leila Schneps and Coralie Colmez. A collection of case studies on mathematical fallacies occurring in famous court cases, aimed at a general audience.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Curvature_of_Space_and_Time,_with_an_Introduction_to_Geometric_Analysis">Curvature of Space and Time, with an Introduction to Geometric Analysis</a></em> (2020), Iva Stavrov. An undergraduate textbook on differential geometry and its applications in the theory of relativity.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_History_of_Mathematics:_A_Very_Short_Introduction">The History of Mathematics: A Very Short Introduction</a></em> (2012), Jackie Stedall. This is less an overview of the history of mathematics itself (maybe too big a topic for a short book) and more an overview of the philosophy of the history of mathematics, as demonstrated through several case studies.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Ad_Quadratum:_The_Practical_Application_of_Geometry_in_Medieval_Architecture">Ad Quadratum: The Practical Application of Geometry in Medieval Architecture</a></em> (2002), Nancy Y. Wu. An edited volume of papers on geometry in medieval architecture, mostly of Gothic cathedrals.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Do_Not_Erase:_Mathematicians_and_their_Chalkboards">Do Not Erase: Mathematicians and their Chalkboards</a></em> (2021), Jessica Wynne. A photo-essay pairing photographs of mathematician’s chalkboards with reflections on their contents by the mathematicians. I listed this in last year’s collection of books for which I could not find enough reviews, but in this case I subsequently did find them.</p>
  </li>
</ul>

<p>(<a href="https://mathstodon.xyz/@11011110/109990803163597638">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T17:40:00Z">Wednesday, March 08 2023, 17:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/03/08/three-assistant-associate-professor-positions-in-security-at-the-vu-amsterdam-at-vrije-universiteit-amsterdam-apply-by-april-13-2023/'>Three assistant/associate professor positions in security at the VU Amsterdam at Vrije Universiteit Amsterdam (apply by April 13, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Department of Computer Science at the Vrije Universiteit Amsterdam offers three open positions for assistant/associate professor in the area of security, related to theory, vulnerability, and AI. Website: werkenbij.vu.nl/vacatures Email: w.j.fokkink@vu.nl
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Department of Computer Science at the Vrije Universiteit Amsterdam offers three open positions for assistant/associate professor in the area of security, related to theory, vulnerability, and AI.</p>
<p>Website: <a href="https://werkenbij.vu.nl/vacatures">https://werkenbij.vu.nl/vacatures</a><br />
Email: w.j.fokkink@vu.nl</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T17:29:12Z">Wednesday, March 08 2023, 17:29</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/03/08/interview-about-this-blog-in-the-bulletin-of-the-eatcs/'>Interview about this blog in the Bulletin of the EATCS</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Luca Trevisan recently interviewed me for the Bulletin of the EATCS (see link for the full issue, including an interview with Alexandra Silva, and technical columns by Naama Ben-David, Ryan Williams, and Yuri Gurevich). With Luca&#8217;s permission, I am cross-posting it here. (I added some hyperlinks to relevant documents.) Q. Boaz, thanks for taking the &#8230; Continue reading Interview about this blog in the Bulletin of the&#160;EATCS
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="https://lucatrevisan.github.io/">Luca Trevisan</a> recently interviewed me for the <a href="https://eatcs.org/images/bulletin/beatcs139.pdf">Bulletin of the EATCS</a> (see link for the full issue, including an interview with Alexandra Silva, and technical columns by Naama Ben-David, Ryan Williams, and Yuri Gurevich). With Luca&#8217;s permission, I am cross-posting it here.  (I added some hyperlinks to relevant documents.)</p>



<p><strong>Q. Boaz, thanks for taking the time to talk about your blog to our readers. When did you start to blog, and what motivated you to start?</strong></p>



<p>In 2012, Omer Reingold <a href="https://windowsontheory.org/about/">started a group blog</a> for the amazing theoretical computer scientists of the Microsoft Research Silicon Valley lab, and called it &#8220;Windows on Theory&#8221;. As a fellow MSR researcher, Omer invited me to join the blog a few months later. Joining a group blog seemed to me like an attractive proposition, since I didn&#8217;t think I will have something interesting to say on a very regular basis.</p>



<p>I liked the idea of explaining technical topics on a blog post, the way you might sketch them on a whiteboard to a colleague. Compared to a survey, where you have to cross all your t&#8217;s and dot all your i&#8217;s, and get all references straight, a blog post can be a good way to convey the heart of the matter without doing as much work.<br>Indeed throughout the years, I&#8217;ve been inspired by several blog posts by you, Luca. <a href="https://lucatrevisan.wordpress.com/">Your blog</a> is a great example of how to explain technical topics in an informal manner.</p>



<p><strong>Q. Thank you so much for that! You have very broad interests in theoretical computer science, and you blog about a great variety of topics. Have there been instances where writing posts or discussing in the comment section has clarified ideas or led to a conjecture or otherwise helped with your research?</strong></p>



<p>I do think that my thinking on several questions, including <a href="https://windowsontheory.org/2013/10/07/structure-vs-combinatorics-in-computational-complexity/">structure vs. combinatorics</a><a href="https://windowsontheory.org/2017/10/30/the-different-forms-of-quantum-computing-skepticism/">, quantum skepticism</a>, <a href="https://windowsontheory.org/2022/06/20/the-uneasy-relationship-between-deep-learning-and-classical-statistics/">theory of deep learning</a>, and more, have been shaped by both the process of writing essays and the discussion in comments or outside the blog that ensues. It is a different form of thinking than the typical scientific paper, and often when you sit down to write, it forces you to clarify your thoughts. This is similar to how often the best way to learn a topic is to teach it.</p>



<p><strong>Q. I have followed on your blog, your course on methods from theoretical physics, and your posts on the <a href="https://windowsontheory.org/2022/06/20/the-uneasy-relationship-between-deep-learning-and-classical-statistics/">foundations of machine learning</a> and AI, and I know you have worked on a <a href="https://introtcs.org/">new approach</a> to teach computability and complexity. What kind of TCS do you think we should teach to CS undergraduates who are interested in AI?</strong></p>



<p>It&#8217;s interesting because I think traditionally, the critique of courses in theoretical CS was that we are teaching all this math, while students are going to be software developers, and they just need to know how to write a website. Now it turns out that we didn&#8217;t teach enough math, and to participate in the AI revolution, students need to know their gradients and Hessians. It&#8217;s also the case that Neural networks are really just arithmetic circuits (and backpropagation has been rediscovered several times, including by <a href="https://core.ac.uk/download/pdf/82480031.pdf">Baur and Strassen</a> in 1982, where they used it for circuit lower bounds).</p>



<p>So I think the tools we teach as theoretical computer scientists are as relevant as ever. I did try to modernize my <a href="https://cs121.boazbarak.org/">course</a>, focusing on circuits, which are relevant not just for AI but also for the foundations of both cryptography and quantum computing. I also talk much more about randomness in computation. This means that some other materials, such as automata, need to be reduced or cut, but I think it&#8217;s a good tradeoff.</p>



<p><strong>Q. On a related note, what do you think that a future satisfactory theory of AI might look like?</strong></p>



<p>As theoretical computer scientists, we are used to being way ahead of practice. For example, people are only starting now to implement the ideas of zero-knowledge and probabilistically-checkable proofs that were put forward by theorists in the 80s and 90s. Dwork and Naor suggested the &#8220;proof of work&#8221; protocol used by Bitcoin in 1992. (They were also ahead of the curve in another way: proposing to combat &#8220;junk email&#8221; before most people had access to email and the term &#8220;spam email&#8221; was even coined.)</p>



<p>In deep learning, we are in a different setting: practice is ahead of theory, and people are implementing systems that they themselves don&#8217;t understand. In that sense, these systems behave more like artifacts that are discovered (or evolved) than like ones that are designed. This forces us to use a different form of theory, and one that relies more heavily on experiments to figure out what are even the right questions to ask.</p>



<p>So, we are not in our usual mode where there are easy-to-state but hard-to-prove conjectures, and our goal is to sit down with pen and paper and to prove them. But for me, theoretical computer science was never about the mode of operation but about the mission of understanding computation. So if understanding deep learning means that I needed to re-learn how to code, and rack up large bills for GPU computation, then so be it.</p>



<p><strong>Q. Can you tell us a bit about the plans for changes in California math education and about your involvement in that debate?</strong></p>



<p>Some colleagues in California have alerted me to a <a href="https://windowsontheory.org/2021/12/03/an-alarming-trend-in-k-12-math-education/">proposed change</a> to the way K-12 math is taught there and that this change is part of a national movement. Part of this is the typical tension that always exists between teaching mathematical topics that are foundational (and often a bit more challenging) vs. &#8220;practical math&#8221;.<br>This is something that I mentioned also in the discussion regarding university teaching.</p>



<p>In the context of high school, the new version of &#8220;practical math&#8221; is no longer accounting but <a href="https://www.educationnext.org/rethinking-math-education-educators-differ-curriculum-methods-forum/">&#8220;data science&#8221;</a>. There is also a twist in which it is claimed that somehow data science is more &#8220;equitable&#8221;, which is something I find offensive, as it tacitly assumes that people from certain groups are inherently incapable of accessing mathematical topics such as algebra and calculus. From my experience in teaching, both at university settings and in Ethiopia and Jamaica, nothing could be further from the truth</p>



<p>Now I am all for teaching students a course in some data literacy, including facility with spreadsheets and understanding the various ways that people can &#8220;lie with statistics&#8221;. It&#8217;s just not a replacement for math courses.</p>



<p>The truth is that, like at the university level, students need more math these days than ever before. By far the largest growth in job opportunities has been in quantitative fields.<br>When data science is offered as an <em>alternative</em> to math, as opposed to complementing them, it basically serves as an &#8220;off ramp&#8221; that shuts students out of these fields, including, ironically, from careers in data science itself.</p>



<p><strong>Q. In general, what are your thoughts about the role of public intellectuals that theoretical computer scientists could fill, and what are public debates where you would like to see more voices coming from our community?</strong></p>



<p>In our field, we often have the experience of being humiliated by either discovering that our conjecture was wrong or being unable to prove it. I think this is not a bad experience to have had for public intellectuals, and so I would hope that theoretical computer scientists speak up more in the public sphere.</p>



<p>Areas including immigration, science funding, open access to publications, and mathematical education are clearly central to our mission to advance science, but I think we can talk about more topics as well. For example, I recently signed an open letter protesting the Israeli government&#8217;s efforts to weaken the judicial branch and the basic laws on human rights. Scientific progress relies on the ability to collaborate, so free speech and human rights are topics that we should talk about as well.</p>



<p><strong>I would like to ask you to pick one or a couple of your favorite posts, and tell us about it/them/</strong></p>



<p>My first blog post was an <a href="https://windowsontheory.org/2012/05/01/the-swiss-army-knife-of-cryptography">exposition</a> of Fully Homomorphic Encryption with Zvika Brakerski. I like that post because we didn&#8217;t just repeat what&#8217;s in the papers but used the flexibility of the blog format to focus on optimizing simplicity and intuition as opposed to precision and computational efficiency. I think people have found it useful over the years. Another blog post I am proud of is my post on <a href="https://windowsontheory.org/2017/08/16/men-in-computer-science/">&#8220;Men in Computer Science&#8221;</a>. I mostly made obvious points in that post, but heard from several women that they appreciated it.</p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T14:13:20Z">Wednesday, March 08 2023, 14:13</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2023/03/news-for-february-2023/'>News for February 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Despite being a short month, February 2023 has witnessed a significant amount of activity under the sublinear &#8220;regime&#8221;. Let us know if we have missed anything! Dynamic \((1 + \epsilon)\)-Approximate Matching Size in Truly Sublinear Update Time by Sayan Bhattacharya, Peter Kiss, and Thatchaphol Saranurak (arXiv). This work throws light on connections between the dynamic [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Despite being a short month, February 2023 has witnessed a significant amount of activity under the sublinear &#8220;regime&#8221;. Let us know if we have missed anything!</p>



<p><strong>Dynamic \((1 + \epsilon)\)-Approximate Matching Size in Truly Sublinear Update Time</strong> by Sayan Bhattacharya, Peter Kiss, and Thatchaphol Saranurak (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.05030" target="_blank">arXiv</a>). This work throws light on connections between the dynamic and query models of computation and uses them for making advances on approximating the size of a maximum cardinality matching (MCM) in a general graph. In particular, as the main technical ingredient in obtaining an improved dynamic algorithm for maintaining an approximation to the size of MCM, the authors provide a \(\pm \epsilon n\) approximation algorithm for estimating the size of MCM in a general \(n\)-vertex graph by making \(n^{2 &#8211; \Omega_{\epsilon}(1)}\) adjacency queries. Prior to this result, the state of the art (Behnezhad, Roghani &amp; Rubinstein; STOC&#8217;23) was a \(n^{2 &#8211; \Omega(1)}\)-query algorithm for the same problem with a multiplicative approximation guarantee of \(1.5\) and an additive guarantee of \(o(n)\). </p>



<p><strong>Uniformity Testing over Hypergrids with Subcube Conditioning</strong> by Xi Chen and Cassandra Marcussen (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.09013" target="_blank">arXiv</a>). As the name indicates, the paper studies the fundamental problem of testing uniformity of distributions supported over hypergrids \([m]^n\). The tester that they present make \(O(\text{poly}(m)\sqrt{n}/\epsilon^2)\) queries to a conditional subcube sampling oracle, which, when given a subcube of \([m]^n\), returns a point sampled from the distribution conditioned on the point belonging to the subcube. The result is a generalization of the uniformity tester for distributions supported over the \(n\)-dimensional hypercube (Canonne, Chen, Kamath, Levi and Waingarten; SODA &#8217;21). </p>



<p><strong>Easy Testability for Posets</strong> by Panna Timea Fekete and Gabor Kun (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.11390" target="_blank">arXiv</a>). This paper deals with testing properties of directed graphs in the adjacency matrix model. The main characters of the story are posets, or directed acyclic graphs (DAGs) that are transitively closed. Given a family \(\mathcal{F}\) of finite posets, let \(\mathcal{P}_\mathcal{F}\) denote the set of all finite posets that do not contain any element of \(\mathcal{F}\) as a subposet. The main result of the paper is an \(\epsilon\)-tester with query complexity \(\text{poly}(1/\epsilon)\) for \(\mathcal{P}_\mathcal{F}\). The authors obtain this result by proving a removal lemma for posets. The result is placed in the larger context of understanding what properties of graphs can be tested with query complexity that has a polynomial dependence on \(1/\epsilon\) in the adjacency matrix model. </p>



<p><strong>Compressibility-Aware Quantum Algorithms</strong> on Strings by Daniel Gibney and Sharma V. Thankachan (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2302.07235" target="_blank">arXiv</a>). Lastly, we have a paper on quantum string algorithms that run in sublinear time. In short, the authors present quantum algorithms with optimal running times for computing the Lempel-Ziv (LZ) encoding and Burrows Wheeler Transform (BWT) of highly compressible strings. A main consequence of these results is a faster quantum algorithm for computing the longest common subsequence (LCS) of two strings when the concatenation of the strings is highly compressible. It is to be noted that sublinear-time algorithms do not exist for these problems in the classical model of computation. More details follow. <br><br>Factoring a string into disjoint substrings (factors) in an specific manner is the main step in the LZ compression algorithm. The smaller the number of factors, the more compressible the string is.  This paper gives a quantum algorithm for the problem of computing the LZ factorization of a string in time \(\tilde{O}(\sqrt{nz})\), where \(z\) is the number of factors in the string. They also show that their algorithm is optimal. Using this algorithm, they obtain a fast algorithm for computing the BWT of an input string, as well as an algorithm running in time \(\tilde{O}(\sqrt{nz})\) to compute the LCS of two strings, where \(n\) is the length and \(z\) is the number of factors in the concatenation of the two strings. When \(z\) is \(o(n^{1/3})\), this algorithm gives an improvement over the previous best quantum algorithm running in time \(\tilde{O}(n^{2/3})\).</p>
<p class="authors">By Nithin Varma</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T06:59:54Z">Wednesday, March 08 2023, 06:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03645'>Filter Pruning based on Information Capacity and Independence</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaolong Tang, Tianheng Hu, Yufeng Shi</p><p>Filter pruning has been widely used in the compression and acceleration of
convolutional neural networks (CNNs). However, most existing methods are still
challenged by heavy compute cost and biased filter selection. Moreover, most
designs for filter evaluation miss interpretability due to the lack of
appropriate theoretical guidance. In this paper, we propose a novel filter
pruning method which evaluates filters in a interpretable, multi-persepective
and data-free manner. We introduce information capacity, a metric that
represents the amount of information contained in a filter. Based on the
interpretability and validity of information entropy, we propose to use that as
a quantitative index of information quantity. Besides, we experimently show
that the obvious correlation between the entropy of the feature map and the
corresponding filter, so as to propose an interpretable, data-driven scheme to
measure the information capacity of the filter. Further, we introduce
information independence, another metric that represents the correlation among
differrent filters. Consequently, the least impotant filters, which have less
information capacity and less information independence, will be pruned. We
evaluate our method on two benchmarks using multiple representative CNN
architectures, including VGG-16 and ResNet. On CIFAR-10, we reduce 71.9% of
floating-point operations (FLOPs) and 69.4% of parameters for ResNet-110 with
0.28% accuracy increase. On ILSVRC-2012, we reduce 76.6% of floating-point
operations (FLOPs) and 68.6% of parameters for ResNet-50 with only 2.80%
accuracy decrease, which outperforms the state-of-the-arts.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaolong Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1">Tianheng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yufeng Shi</a></p><p>Filter pruning has been widely used in the compression and acceleration of
convolutional neural networks (CNNs). However, most existing methods are still
challenged by heavy compute cost and biased filter selection. Moreover, most
designs for filter evaluation miss interpretability due to the lack of
appropriate theoretical guidance. In this paper, we propose a novel filter
pruning method which evaluates filters in a interpretable, multi-persepective
and data-free manner. We introduce information capacity, a metric that
represents the amount of information contained in a filter. Based on the
interpretability and validity of information entropy, we propose to use that as
a quantitative index of information quantity. Besides, we experimently show
that the obvious correlation between the entropy of the feature map and the
corresponding filter, so as to propose an interpretable, data-driven scheme to
measure the information capacity of the filter. Further, we introduce
information independence, another metric that represents the correlation among
differrent filters. Consequently, the least impotant filters, which have less
information capacity and less information independence, will be pruned. We
evaluate our method on two benchmarks using multiple representative CNN
architectures, including VGG-16 and ResNet. On CIFAR-10, we reduce 71.9% of
floating-point operations (FLOPs) and 69.4% of parameters for ResNet-110 with
0.28% accuracy increase. On ILSVRC-2012, we reduce 76.6% of floating-point
operations (FLOPs) and 68.6% of parameters for ResNet-50 with only 2.80%
accuracy decrease, which outperforms the state-of-the-arts.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03921'>Approximate degree lower bounds for oracle identification problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mark Bun, Nadezhda Voronova</p><p>The approximate degree of a Boolean function is the minimum degree of real
polynomial that approximates it pointwise. For any Boolean function, its
approximate degree serves as a lower bound on its quantum query complexity, and
generically lifts to a quantum communication lower bound for a related
function.
</p>
<p>We introduce a framework for proving approximate degree lower bounds for
certain oracle identification problems, where the goal is to recover a hidden
binary string $x \in \{0, 1\}^n$ given possibly non-standard oracle access to
it. We apply this framework to the ordered search and hidden string problems,
proving nearly tight approximate degree lower bounds of $\Omega(n/\log^2 n)$
for each.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bun_M/0/1/0/all/0/1">Mark Bun</a>, <a href="http://arxiv.org/find/cs/1/au:+Voronova_N/0/1/0/all/0/1">Nadezhda Voronova</a></p><p>The approximate degree of a Boolean function is the minimum degree of real
polynomial that approximates it pointwise. For any Boolean function, its
approximate degree serves as a lower bound on its quantum query complexity, and
generically lifts to a quantum communication lower bound for a related
function.
</p>
<p>We introduce a framework for proving approximate degree lower bounds for
certain oracle identification problems, where the goal is to recover a hidden
binary string $x \in \{0, 1\}^n$ given possibly non-standard oracle access to
it. We apply this framework to the ordered search and hidden string problems,
proving nearly tight approximate degree lower bounds of $\Omega(n/\log^2 n)$
for each.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03958'>The Linear Correlation of $P$ and $NP$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bojin Zheng, Weiwu Wang</p><p>$P \overset{\text{?}}{=} NP$ or $P\ vs\ NP$ is the core problem in
computational complexity theory. In this paper, we proposed a definition of
linear correlation of derived matrix and system, and discussed the linear
correlation of $P$ and $NP$. We draw a conclusion that $P$ is linearly
dependent and there exists $NP$ which is is linearly independent and take a
3SAT instance which belongs to $NP$ as the example , that is, $P \neq NP$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Bojin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiwu Wang</a></p><p>$P \overset{\text{?}}{=} NP$ or $P\ vs\ NP$ is the core problem in
computational complexity theory. In this paper, we proposed a definition of
linear correlation of derived matrix and system, and discussed the linear
correlation of $P$ and $NP$. We draw a conclusion that $P$ is linearly
dependent and there exists $NP$ which is is linearly independent and take a
3SAT instance which belongs to $NP$ as the example , that is, $P \neq NP$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03616'>Geometry-Aware Coverage Path Planning on Complex 3D Surfaces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Van-Thach Do, Quang-Cuong Pham</p><p>This paper presents a new approach to obtaining nearly complete coverage
paths (CP) with low overlapping on 3D general surfaces using mesh models given
or reconstructed from actual scenes. The CP is obtained by segmenting the mesh
model into a given number of clusters using constrained centroidal Voronoi
tessellation (CCVT) and finding the shortest path from cluster centroids using
the geodesic metric efficiently. We introduce a new cost function to
harmoniously achieve uniform areas of the obtained clusters and a restriction
on the variation of triangle normals during the construction of CCVTs. The
obtained clusters can be used to construct high-quality viewpoints (VP) for
visual coverage tasks. Here, we utilize the planned VPs as cleaning
configurations to perform residual powder removal in additive manufacturing
using manipulator robots. The self-occlusion of VPs and ensuring collision-free
robot configurations are addressed by integrating a proposed optimization-based
strategy to find a set of candidate rays for each VP into the motion planning
phase. CP planning benchmarks and physical experiments are conducted to
demonstrate the effectiveness of the proposed approach. We show that our
approach can compute the CPs and VPs of various mesh models with a massive
number of triangles within a reasonable time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Do_V/0/1/0/all/0/1">Van-Thach Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1">Quang-Cuong Pham</a></p><p>This paper presents a new approach to obtaining nearly complete coverage
paths (CP) with low overlapping on 3D general surfaces using mesh models given
or reconstructed from actual scenes. The CP is obtained by segmenting the mesh
model into a given number of clusters using constrained centroidal Voronoi
tessellation (CCVT) and finding the shortest path from cluster centroids using
the geodesic metric efficiently. We introduce a new cost function to
harmoniously achieve uniform areas of the obtained clusters and a restriction
on the variation of triangle normals during the construction of CCVTs. The
obtained clusters can be used to construct high-quality viewpoints (VP) for
visual coverage tasks. Here, we utilize the planned VPs as cleaning
configurations to perform residual powder removal in additive manufacturing
using manipulator robots. The self-occlusion of VPs and ensuring collision-free
robot configurations are addressed by integrating a proposed optimization-based
strategy to find a set of candidate rays for each VP into the motion planning
phase. CP planning benchmarks and physical experiments are conducted to
demonstrate the effectiveness of the proposed approach. We show that our
approach can compute the CPs and VPs of various mesh models with a massive
number of triangles within a reasonable time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04014'>Hausdorff and Gromov-Hausdorff stable subsets of the medial axis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andr&#xe9; Lieutier, Mathijs Wintraecken</p><p>In this paper we introduce a pruning of the medial axis called the
$(\lambda,\alpha)$-medial axis ($\textrm{ax}_\lambda^\alpha $). We prove that
the $(\lambda,\alpha)$-medial axis of a set $K$ is stable in a Gromov-Hausdorff
sense under weak assumptions. More formally we prove that if $K$ and $K'$ are
close in the Hausdorff ($d_H$) sense then the $(\lambda,\alpha)$-medial axes of
$K$ and $K'$ are close as metric spaces, that is the Gromov-Hausdorff distance
($d_{GH}$) between the two is $\frac{1}{4}$-H{\"o}lder in the sense that
$d_{GH} (\textrm{ax}_\lambda^\alpha (K),\textrm{ax}_\lambda^\alpha (K'))
\lesssim d_H(K,K')^{1/4}$. The Hausdorff distance between the two medial axes
is also bounded, by $d_{H} (\textrm{ax}_\lambda^\alpha
(K),\textrm{ax}_\lambda^\alpha (K')) \lesssim d_H(K,K')^{1/2}$. These
quantified stability results provide guarantees for practical computations of
medial axes from approximations. Moreover, they provide key ingredients for
studying the computability of the medial axis in the context of computable
analysis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lieutier_A/0/1/0/all/0/1">Andr&#xe9; Lieutier</a>, <a href="http://arxiv.org/find/cs/1/au:+Wintraecken_M/0/1/0/all/0/1">Mathijs Wintraecken</a></p><p>In this paper we introduce a pruning of the medial axis called the
$(\lambda,\alpha)$-medial axis ($\textrm{ax}_\lambda^\alpha $). We prove that
the $(\lambda,\alpha)$-medial axis of a set $K$ is stable in a Gromov-Hausdorff
sense under weak assumptions. More formally we prove that if $K$ and $K'$ are
close in the Hausdorff ($d_H$) sense then the $(\lambda,\alpha)$-medial axes of
$K$ and $K'$ are close as metric spaces, that is the Gromov-Hausdorff distance
($d_{GH}$) between the two is $\frac{1}{4}$-H{\"o}lder in the sense that
$d_{GH} (\textrm{ax}_\lambda^\alpha (K),\textrm{ax}_\lambda^\alpha (K'))
\lesssim d_H(K,K')^{1/4}$. The Hausdorff distance between the two medial axes
is also bounded, by $d_{H} (\textrm{ax}_\lambda^\alpha
(K),\textrm{ax}_\lambda^\alpha (K')) \lesssim d_H(K,K')^{1/2}$. These
quantified stability results provide guarantees for practical computations of
medial axes from approximations. Moreover, they provide key ingredients for
studying the computability of the medial axis in the context of computable
analysis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.04079'>An extension theorem for signotopes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Helena Bergold, Stefan Felsner, Manfred Scheucher</p><p>In 1926, Levi showed that, for every pseudoline arrangement $\mathcal{A}$ and
two points in the plane, $\mathcal{A}$ can be extended by a pseudoline which
contains the two prescribed points. Later extendability was studied for
arrangements of pseudohyperplanes in higher dimensions. While the extendability
of an arrangement of proper hyperplanes in $\mathbb{R}^d$ with a hyperplane
containing $d$ prescribed points is trivial, Richter-Gebert found an
arrangement of pseudoplanes in $\mathbb{R}^3$ which cannot be extended with a
pseudoplane containing two particular prescribed points. In this article, we
investigate the extendability of signotopes, which are a combinatorial
structure encoding a rich subclass of pseudohyperplane arrangements. Our main
result is that signotopes of odd rank are extendable in the sense that for two
prescribed crossing points we can add an element containing them. Moreover, we
conjecture that in all even ranks $r \geq 4$ there exist signotopes which are
not extendable for two prescribed points. Our conjecture is supported by
examples in ranks 4, 6, 8, 10, and 12 that were found with a SAT based
approach.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Bergold_H/0/1/0/all/0/1">Helena Bergold</a>, <a href="http://arxiv.org/find/math/1/au:+Felsner_S/0/1/0/all/0/1">Stefan Felsner</a>, <a href="http://arxiv.org/find/math/1/au:+Scheucher_M/0/1/0/all/0/1">Manfred Scheucher</a></p><p>In 1926, Levi showed that, for every pseudoline arrangement $\mathcal{A}$ and
two points in the plane, $\mathcal{A}$ can be extended by a pseudoline which
contains the two prescribed points. Later extendability was studied for
arrangements of pseudohyperplanes in higher dimensions. While the extendability
of an arrangement of proper hyperplanes in $\mathbb{R}^d$ with a hyperplane
containing $d$ prescribed points is trivial, Richter-Gebert found an
arrangement of pseudoplanes in $\mathbb{R}^3$ which cannot be extended with a
pseudoplane containing two particular prescribed points. In this article, we
investigate the extendability of signotopes, which are a combinatorial
structure encoding a rich subclass of pseudohyperplane arrangements. Our main
result is that signotopes of odd rank are extendable in the sense that for two
prescribed crossing points we can add an element containing them. Moreover, we
conjecture that in all even ranks $r \geq 4$ there exist signotopes which are
not extendable for two prescribed points. Our conjecture is supported by
examples in ranks 4, 6, 8, 10, and 12 that were found with a SAT based
approach.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03617'>Computing Effective Resistances on Large Graphs Based on Approximate Inverse of Cholesky Factor</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhiqiang Liu, Wenjian Yu</p><p>Effective resistance, which originates from the field of circuits analysis,
is an important graph distance in spectral graph theory. It has found numerous
applications in various areas, such as graph data mining, spectral graph
sparsification, circuits simulation, etc. However, computing effective
resistances accurately can be intractable and we still lack efficient methods
for estimating effective resistances on large graphs. In this work, we propose
an efficient algorithm to compute effective resistances on general weighted
graphs, based on a sparse approximate inverse technique. Compared with a recent
competitor, the proposed algorithm shows several hundreds of speedups and also
one to two orders of magnitude improvement in the accuracy of results.
Incorporating the proposed algorithm with the graph sparsification based power
grid (PG) reduction framework, we develop a fast PG reduction method, which
achieves an average 6.4X speedup in the reduction time without loss of
reduction accuracy. In the applications of power grid transient analysis and DC
incremental analysis, the proposed method enables 1.7X and 2.5X speedup of
overall time compared to using the PG reduction based on accurate effective
resistances, without increase in the error of solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Liu_Z/0/1/0/all/0/1">Zhiqiang Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Yu_W/0/1/0/all/0/1">Wenjian Yu</a></p><p>Effective resistance, which originates from the field of circuits analysis,
is an important graph distance in spectral graph theory. It has found numerous
applications in various areas, such as graph data mining, spectral graph
sparsification, circuits simulation, etc. However, computing effective
resistances accurately can be intractable and we still lack efficient methods
for estimating effective resistances on large graphs. In this work, we propose
an efficient algorithm to compute effective resistances on general weighted
graphs, based on a sparse approximate inverse technique. Compared with a recent
competitor, the proposed algorithm shows several hundreds of speedups and also
one to two orders of magnitude improvement in the accuracy of results.
Incorporating the proposed algorithm with the graph sparsification based power
grid (PG) reduction framework, we develop a fast PG reduction method, which
achieves an average 6.4X speedup in the reduction time without loss of
reduction accuracy. In the applications of power grid transient analysis and DC
incremental analysis, the proposed method enables 1.7X and 2.5X speedup of
overall time compared to using the PG reduction based on accurate effective
resistances, without increase in the error of solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03705'>Fairness-aware Maximal Biclique Enumeration on Bipartite Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ziqi Yin, Qi Zhang, Wentao Zhang, Rong-Hua Li, Guoren Wang</p><p>Maximal biclique enumeration is a fundamental problem in bipartite graph data
analysis. Existing biclique enumeration methods mainly focus on non-attributed
bipartite graphs and also ignore the \emph{fairness} of graph attributes. In
this paper, we introduce the concept of fairness into the biclique model for
the first time and study the problem of fairness-aware biclique enumeration.
Specifically, we propose two fairness-aware biclique models, called
\nonesidebc~and \ntwosidebc~respectively. To efficiently enumerate all
{\nonesidebc}s, we first present two non-trivial pruning techniques, called
fair $\alpha$-$\beta$ core pruning and colorful fair $\alpha$-$\beta$ core
pruning, to reduce the graph size without losing accuracy. Then, we develop a
branch and bound algorithm, called \onesideFBCEM, to enumerate all single-side
fair bicliques on the reduced bipartite graph. To further improve the
efficiency, we propose an efficient branch and bound algorithm with a
carefully-designed combinatorial enumeration technique. Note that all of our
techniques can also be extended to enumerate all bi-side fair bicliques. We
also extend the two fairness-aware biclique models by constraining the ratio of
the number of vertices of each attribute to the total number of vertices and
present corresponding enumeration algorithms. Extensive experimental results on
five large real-world datasets demonstrate our methods' efficiency,
effectiveness, and scalability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Ziqi Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wentao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Rong-Hua Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoren Wang</a></p><p>Maximal biclique enumeration is a fundamental problem in bipartite graph data
analysis. Existing biclique enumeration methods mainly focus on non-attributed
bipartite graphs and also ignore the \emph{fairness} of graph attributes. In
this paper, we introduce the concept of fairness into the biclique model for
the first time and study the problem of fairness-aware biclique enumeration.
Specifically, we propose two fairness-aware biclique models, called
\nonesidebc~and \ntwosidebc~respectively. To efficiently enumerate all
{\nonesidebc}s, we first present two non-trivial pruning techniques, called
fair $\alpha$-$\beta$ core pruning and colorful fair $\alpha$-$\beta$ core
pruning, to reduce the graph size without losing accuracy. Then, we develop a
branch and bound algorithm, called \onesideFBCEM, to enumerate all single-side
fair bicliques on the reduced bipartite graph. To further improve the
efficiency, we propose an efficient branch and bound algorithm with a
carefully-designed combinatorial enumeration technique. Note that all of our
techniques can also be extended to enumerate all bi-side fair bicliques. We
also extend the two fairness-aware biclique models by constraining the ratio of
the number of vertices of each attribute to the total number of vertices and
present corresponding enumeration algorithms. Extensive experimental results on
five large real-world datasets demonstrate our methods' efficiency,
effectiveness, and scalability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03741'>Complete Log Concavity of Coverage-Like Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dorna Abdolazimi, Shayan Oveis Gharan</p><p>We introduce an expressive subclass of non-negative almost submodular set
functions, called strongly 2-coverage functions which include coverage and
(sums of) matroid rank functions, and prove that the homogenization of the
generating polynomial of any such function is completely log-concave, taking a
step towards characterizing the coefficients of (homogeneous) completely
log-concave polynomials. As a consequence we obtain that the "level sets" of
any such function form an ultra-log concave sequence.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Abdolazimi_D/0/1/0/all/0/1">Dorna Abdolazimi</a>, <a href="http://arxiv.org/find/math/1/au:+Gharan_S/0/1/0/all/0/1">Shayan Oveis Gharan</a></p><p>We introduce an expressive subclass of non-negative almost submodular set
functions, called strongly 2-coverage functions which include coverage and
(sums of) matroid rank functions, and prove that the homogenization of the
generating polynomial of any such function is completely log-concave, taking a
step towards characterizing the coefficients of (homogeneous) completely
log-concave polynomials. As a consequence we obtain that the "level sets" of
any such function form an ultra-log concave sequence.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03962'>Cops and Robbers on Multi-Layer Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jessica Enright, Kitty Meeks, William Pettersson, John Sylvester</p><p>We generalise the popular cops and robbers game to multi-layer graphs, where
each cop and the robber are restricted to a single layer (or set of edges). We
show that initial intuition about the best way to allocate cops to layers is
not always correct, and prove that the multi-layer cop number is neither
bounded from above nor below by any function of the cop numbers of the
individual layers. We determine that it is NP-hard to decide if k cops are
sufficient to catch the robber, even if all cop layers are trees. However, we
give a polynomial time algorithm to determine if k cops can win when the robber
layer is a tree. Additionally, we investigate a question of worst-case division
of a simple graph into layers: given a simple graph G, what is the maximum
number of cops required to catch a robber over all multi-layer graphs where
each edge of G is in at least one layer and all layers are connected? For
cliques, suitably dense random graphs, and graphs of bounded treewidth, we
determine this parameter up to multiplicative constants. Lastly we consider a
multi-layer variant of Meyniel's Conjecture, and show the existence of an
infinite family of graphs whose multi-layer cop number is bounded from below by
a constant times n / log n, where n is the number of vertices in the graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Enright_J/0/1/0/all/0/1">Jessica Enright</a>, <a href="http://arxiv.org/find/math/1/au:+Meeks_K/0/1/0/all/0/1">Kitty Meeks</a>, <a href="http://arxiv.org/find/math/1/au:+Pettersson_W/0/1/0/all/0/1">William Pettersson</a>, <a href="http://arxiv.org/find/math/1/au:+Sylvester_J/0/1/0/all/0/1">John Sylvester</a></p><p>We generalise the popular cops and robbers game to multi-layer graphs, where
each cop and the robber are restricted to a single layer (or set of edges). We
show that initial intuition about the best way to allocate cops to layers is
not always correct, and prove that the multi-layer cop number is neither
bounded from above nor below by any function of the cop numbers of the
individual layers. We determine that it is NP-hard to decide if k cops are
sufficient to catch the robber, even if all cop layers are trees. However, we
give a polynomial time algorithm to determine if k cops can win when the robber
layer is a tree. Additionally, we investigate a question of worst-case division
of a simple graph into layers: given a simple graph G, what is the maximum
number of cops required to catch a robber over all multi-layer graphs where
each edge of G is in at least one layer and all layers are connected? For
cliques, suitably dense random graphs, and graphs of bounded treewidth, we
determine this parameter up to multiplicative constants. Lastly we consider a
multi-layer variant of Meyniel's Conjecture, and show the existence of an
infinite family of graphs whose multi-layer cop number is bounded from below by
a constant times n / log n, where n is the number of vertices in the graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.03964'>Force-Directed Graph Layouts Revisited: A New Force Based on the T-Distribution</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fahai Zhong, Mingliang Xue, Jian Zhang, Fan Zhang, Rui Ban, Oliver Deussen, Yunhai Wang</p><p>In this paper, we propose the t-FDP model, a force-directed placement method
based on a novel bounded short-range force (t-force) defined by Student's
t-distribution. Our formulation is flexible, exerts limited repulsive forces
for nearby nodes and can be adapted separately in its short- and long-range
effects. Using such forces in force-directed graph layouts yields better
neighborhood preservation than current methods, while maintaining low stress
errors. Our efficient implementation using a Fast Fourier Transform is one
order of magnitude faster than state-of-the-art methods and two orders faster
on the GPU, enabling us to perform parameter tuning by globally and locally
adjusting the t-force in real-time for complex graphs. We demonstrate the
quality of our approach by numerical evaluation against state-of-the-art
approaches and extensions for interactive exploration.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhong_F/0/1/0/all/0/1">Fahai Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1">Mingliang Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ban_R/0/1/0/all/0/1">Rui Ban</a>, <a href="http://arxiv.org/find/cs/1/au:+Deussen_O/0/1/0/all/0/1">Oliver Deussen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhai Wang</a></p><p>In this paper, we propose the t-FDP model, a force-directed placement method
based on a novel bounded short-range force (t-force) defined by Student's
t-distribution. Our formulation is flexible, exerts limited repulsive forces
for nearby nodes and can be adapted separately in its short- and long-range
effects. Using such forces in force-directed graph layouts yields better
neighborhood preservation than current methods, while maintaining low stress
errors. Our efficient implementation using a Fast Fourier Transform is one
order of magnitude faster than state-of-the-art methods and two orders faster
on the GPU, enabling us to perform parameter tuning by globally and locally
adjusting the t-force in real-time for complex graphs. We demonstrate the
quality of our approach by numerical evaluation against state-of-the-art
approaches and extensions for interactive exploration.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-08T01:30:00Z">Wednesday, March 08 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, March 07
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/03/07/greg-kuperberg-tel-aviv-university/'>Greg Kuperberg @ Tel Aviv University</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Greg Kuperberg is on a short visit in Israel and yesterday he gave a fantastic lecture on an improved bound for the Solovay-Kitaev theorem. Here is a videotaped lecture of Greg on the same topic in QIP2023. The Solovay-Kitaev theorem &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><img data-attachment-id="23940" data-permalink="https://gilkalai.wordpress.com/2023/03/07/greg-kuperberg-tel-aviv-university/zigzagolf/" data-orig-file="https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png" data-orig-size="382,418" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zigzagolf" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png?w=274" data-large-file="https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png?w=382" class="alignnone size-full wp-image-23940" src="https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png?w=640" alt="zigzagolf" srcset="https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png 382w, https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png?w=137 137w, https://gilkalai.files.wordpress.com/2023/03/zigzagolf.png?w=274 274w" sizes="(max-width: 382px) 100vw, 382px"   /></p>
<p>Greg Kuperberg is on a short visit in Israel and yesterday he gave a fantastic lecture on an improved bound for the Solovay-Kitaev theorem. Here is a videotaped lecture of Greg on the same topic in QIP2023.</p>
<p><iframe class="youtube-player" width="640" height="360" src="https://www.youtube.com/embed/_quPWFo7YPc?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></p>
<p>The Solovay-Kitaev theorem from 1995 (in a stronger version by Kitaev-Shen-Viyalyi) asserts that</p>
<p><strong>Theorem:</strong>  If <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> is a finite subset of  <img src="https://s0.wp.com/latex.php?latex=G%3DSU%28d%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G%3DSU%28d%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G%3DSU%28d%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G=SU(d)" class="latex" /> that densely generates <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> with the property that <img src="https://s0.wp.com/latex.php?latex=A%3DA%5E%7B-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A%3DA%5E%7B-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%3DA%5E%7B-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A=A^{-1}" class="latex" />, then there is an efficient algorithm to <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon" class="latex" />-approximate every element <img src="https://s0.wp.com/latex.php?latex=g+%5Cin+G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g+%5Cin+G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g+%5Cin+G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g &#92;in G" class="latex" /> by a word <img src="https://s0.wp.com/latex.php?latex=w_A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w_A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w_A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w_A" class="latex" />  of length</p>
<p><img src="https://s0.wp.com/latex.php?latex=O%28%5Clog+%5Cfrac%7B1%7D%7B%5Cepsilon%7D%29%5E%7B%5Cgamma%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28%5Clog+%5Cfrac%7B1%7D%7B%5Cepsilon%7D%29%5E%7B%5Cgamma%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28%5Clog+%5Cfrac%7B1%7D%7B%5Cepsilon%7D%29%5E%7B%5Cgamma%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(&#92;log &#92;frac{1}{&#92;epsilon})^{&#92;gamma}," class="latex" /></p>
<p>where we can take <img src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3D+3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma+%3D+3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma+%3D+3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma = 3+&#92;delta" class="latex" />, for every <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdelta+%3E0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;delta &gt;0" class="latex" />.</p>
<p>Greg mentioned several improvements and related results shown over the years, and he addressed the question of improving <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" />. His result, which gave the first known improvement (using two separate ideas) takes <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cgamma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;gamma" class="latex" /> down from <img src="https://s0.wp.com/latex.php?latex=3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3%2B%5Cdelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3+&#92;delta" class="latex" /> to 1.44042&#8230;</p>
<p>(I told Greg that the mathematicians&#8217; labor unions frown upon such drastic advances in a single paper.)</p>
<p>You can test your intuition for what 1.44042&#8230; stands for.</p>
<p><span id="more-23935"></span></p>
<p>1.44042 stands for <img src="https://s0.wp.com/latex.php?latex=%5Clog+_%5Cphi+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+_%5Cphi+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+_%5Cphi+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log _&#92;phi 2" class="latex" /> where golden <img src="https://s0.wp.com/latex.php?latex=%5Cphi%3D%5Cfrac+%7B1%2B%5Csqrt+5%7D%7B2%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi%3D%5Cfrac+%7B1%2B%5Csqrt+5%7D%7B2%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi%3D%5Cfrac+%7B1%2B%5Csqrt+5%7D%7B2%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi=&#92;frac {1+&#92;sqrt 5}{2}." class="latex" /></p>
<p>Solovay-Kitaev&#8217;s theorem and its extensions are related to questions about expansion and other properties of Cayley graphs of Lie groups, questions in additive number theory, and questions in group theory. One of the techniques that Greg has developed is referred to as zigzag Golf (see the picture above) and another technique that Greg applies is related to higher commutators and the Elkasapy-Thom theory.</p>
<p>After the lecture, a few of us had a very nice chat with Greg over lunch on various issues. Just before I left Greg told me about three experimental advances regarding quantum error correcting that he found exciting (and which he thought were potentially relevant to a long and intensive email discussion/debate that he and I have been having on the topic since 2005.) I will mention these examples and some related information in <a href="https://gilkalai.wordpress.com/2022/05/26/waging-war-on-quantum/#comment-94128">a comment</a> to <a href="http://(https://gilkalai.wordpress.com/2022/05/26/waging-war-on-quantum/">this post</a>. After more than a decade of a continuous, intensive debate and a few later bursts of additional fierce discussions (also on blogs and FB), Greg and I decided on a truce with a friendly exchange of ideas from time to time.</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T19:45:54Z">Tuesday, March 07 2023, 19:45</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/'>STACS 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Symposium on Theoretical Aspects of Computer Science&#8212;STACS&#8212;will take place from 7th March to 9th March 2023 in Universitat Hamburg, Hamburg, Germany. It starts right away&#8212;tomorrow. I cannot go to this one, but it has been a strong theory conference over the past. And I wish I could go to this one. Ken says the [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
The Symposium on Theoretical Aspects of Computer Science&#8212;STACS&#8212;will take place from 7th March to 9th March 2023 in Universitat Hamburg, Hamburg, Germany. It starts right away&#8212;tomorrow. </p>
<p>
I cannot go to this one, but it has been a strong theory conference over the past. And I wish I could go to this one. Ken says the same.  He recalls that the two of us connected in a big way at STACS 1994 in Caen, France.</p>
<p>
For the first time, <a href="https://www.conferences.uni-hamburg.de/event/272/page/153-home">STACS 2023</a> will consist of two tracks, A and B, to facilitate the work of the program committee(s). Track A is dedicated to algorithms and data structures, complexity and games. Track B will cover automata, logic, semantics and theory of programming.</p>
<p>
The conference is chaired by Petra Berenbrink and Mamadou Kant&eacute; for track A, Anuj Dawar and Patricia Bouyer-Decitre for track B.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/trackleadersab/" rel="attachment wp-att-21227"><img data-attachment-id="21227" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/trackleadersab/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?fit=228%2C334&amp;ssl=1" data-orig-size="228,334" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="TrackLeadersAB" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?fit=205%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?fit=228%2C334&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?resize=228%2C334&#038;ssl=1" alt="" width="228" height="334" class="aligncenter size-full wp-image-21227" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?w=228&amp;ssl=1 228w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/TrackLeadersAB.png?resize=205%2C300&amp;ssl=1 205w" sizes="(max-width: 228px) 100vw, 228px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Invited Speakers </H2></p>
<p><p>
There are three invited speakers. Here are their titles and talk descriptions:</p>
<p>
<b>Eva Rotenberg</b> (Technical University of Denmark): <b>Amortised Analysis of Dynamic Data Structures.</b></p>
<p>
In dynamic data structures, one is interested in efficiently facilitating queries to a data set, while being able to efficiently perform updates as the data set undergoes changes. Often, relaxing the efficiency measure to the amortised setting allows for simpler algorithms. A well-known example of a data structure with amortised guarantees is the splay tree by Sleator and Tarjan.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/er/" rel="attachment wp-att-21220"><img data-attachment-id="21220" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/er/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/er.jpeg?fit=201%2C251&amp;ssl=1" data-orig-size="201,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="er" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/er.jpeg?fit=201%2C251&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/er.jpeg?fit=201%2C251&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/er.jpeg?resize=201%2C251&#038;ssl=1" alt="" width="201" height="251" class="aligncenter size-full wp-image-21220" data-recalc-dims="1" /></a></p>
<p><P><br />
<b>Karoliina Lehtinen</b> (CNRS, Aix-Marseille Univercity, LIS, Marseille, France ): <b>A brief history of history-determinism.</b></p>
<p>
Most nondeterministic automata models are more expressive, or at least more succinct, than their deterministic counterparts; however, this comes at a cost, as deterministic automata tend to have better algorithmic properties. History-deterministic automata are an intermediate model that allows a restricted form of nondeterminism: all nondeterministic choices must be resolvable on-the-fly, with only the knowledge of the word prefix read so far&#8212;as opposed to general nondeterminism, which allows for guessing the future of the word. History-deterministic automata combine some of the algorithmic benefits of determinism with some of the increased power of nondeterminism, thus enjoying (some of) the best of both worlds. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/kl-2/" rel="attachment wp-att-21221"><img data-attachment-id="21221" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/kl-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/kl.jpeg?fit=211%2C239&amp;ssl=1" data-orig-size="211,239" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kl" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/kl.jpeg?fit=211%2C239&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/kl.jpeg?fit=211%2C239&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/kl.jpeg?resize=211%2C239&#038;ssl=1" alt="" width="211" height="239" class="aligncenter size-full wp-image-21221" data-recalc-dims="1" /></a></p>
<p><P><br />
<b>Moshe Vardi</b> (Rice University): <b>Logical Algorithmics: From Theory to Practice.</b></p>
<p>
The standard approach to algorithm development is to focus on a specific problem and develop for it a specific algorithm. Codd&#8217;s introduction of the relational model in 1970 included two fundamental ideas: </p>
<p>
(1) Relations provide a universal data representation formalism, and </p>
<p>
(2) Relational databases can be queried using first-order logic. </p>
<p>
Realizing these ideas required the development of a meta-algorithm, which takes a declarative query and executes it with respect to a database. In this talk, I will describe this approach, which I call Logical Algorithmics, in detail, and explore its profound ramification.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/mv/" rel="attachment wp-att-21222"><img data-attachment-id="21222" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/06/stacs-2023/mv/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?fit=440%2C346&amp;ssl=1" data-orig-size="440,346" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mv" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?fit=300%2C236&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?fit=440%2C346&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?resize=220%2C173&#038;ssl=1" alt="" width="220" height="173" class="aligncenter wp-image-21222" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?w=440&amp;ssl=1 440w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/mv.jpg?resize=300%2C236&amp;ssl=1 300w" sizes="(max-width: 220px) 100vw, 220px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Selected Papers </H2></p>
<p><p>
Here are a few of the accepted papers:</p>
<ul>
<p><li>
Edouard Bonnet, Ugo Giocanti, Patrice Ossona de Mendez and Stephan Thomasse. <a href="https://arxiv.org/abs/2209.12023">Twin-width V: linear minors, modular counting, and matrix multiplication</a>.</p>
<p><li>
Charles Paperman, Sylvain Salvati and Claire Soyez-Martin. <a href="https://hal.science/hal-03831752/file/main.pdf">An algebraic approach to vectorial programs</a>.</p>
<p><li>
Pascal Baumann, Roland Meyer and Georg Zetzsche. <a href="https://arxiv.org/abs/2301.11242">Regular Separability in Buchi Vector Addition Systems</a></p>
<p><li>
Monika Henzinger, Stefan Neumann, Harald Racke and Stefan Schmid. <a href="https://arxiv.org/abs/2301.01744">Dynamic Maintenance of Monotone Dynamic Programs and Applications</a>.</p>
<p><li>
Satyadev Nandakumar and Subin Pulari. <a href="https://arxiv.org/pdf/2208.06340.pdf">Real numbers equally compressible in every base</a>.</p>
</ul>
<p>
See this <a href="https://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16268">for all the papers</a>. That is a <b>complete list</b>. </p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
I highlighted the above papers for personal reasons&#8212;hmmm.</p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T04:25:19Z">Tuesday, March 07 2023, 04:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02301'>Locally universal C*-algebras with computable presentations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alec Fox, Isaac Goldbring, Bradd Hart</p><p>The Kirchberg Embedding Problem (KEP) asks if every C*-algebra embeds into an
ultrapower of the Cuntz algebra $\mathcal{O}_2$. In an effort to provide a
negative solution to the KEP and motivated by the recent refutation of the
Connes Embedding Problem, we establish two computability-theoretic consequences
of a positive solution to KEP. Both of our results follow from the a priori
weaker assumption that there exists a locally universal C*-algebra with a
computable presentation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Fox_A/0/1/0/all/0/1">Alec Fox</a>, <a href="http://arxiv.org/find/math/1/au:+Goldbring_I/0/1/0/all/0/1">Isaac Goldbring</a>, <a href="http://arxiv.org/find/math/1/au:+Hart_B/0/1/0/all/0/1">Bradd Hart</a></p><p>The Kirchberg Embedding Problem (KEP) asks if every C*-algebra embeds into an
ultrapower of the Cuntz algebra $\mathcal{O}_2$. In an effort to provide a
negative solution to the KEP and motivated by the recent refutation of the
Connes Embedding Problem, we establish two computability-theoretic consequences
of a positive solution to KEP. Both of our results follow from the a priori
weaker assumption that there exists a locally universal C*-algebra with a
computable presentation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02337'>Some results on Minimum Consistent Subsets of Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bubai Manna, Bodhayan Roy</p><p>For a graph G = (V,E) where each vertex is coloured by one of k colours,
consider a subset C of V such that for each vertex v in V\C, its set of nearest
neighbours in C contains at least one vertex of the same colour as v. Such a C
is called a consistent subset (CS). Computing a consistent subset of the
minimum size is called the Minimum Consistent Subset problem (MCS). MCS is
known to be NP-complete for planar graphs. We propose a polynomial-time
algorithm for finding a minimum consistent subset of a k-chromatic spider graph
when k is a constant. We also show MCS remains NP-complete on trees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Manna_B/0/1/0/all/0/1">Bubai Manna</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Bodhayan Roy</a></p><p>For a graph G = (V,E) where each vertex is coloured by one of k colours,
consider a subset C of V such that for each vertex v in V\C, its set of nearest
neighbours in C contains at least one vertex of the same colour as v. Such a C
is called a consistent subset (CS). Computing a consistent subset of the
minimum size is called the Minimum Consistent Subset problem (MCS). MCS is
known to be NP-complete for planar graphs. We propose a polynomial-time
algorithm for finding a minimum consistent subset of a k-chromatic spider graph
when k is a constant. We also show MCS remains NP-complete on trees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02283'>On Maximum Bipartite Matching with Separation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pasin Manurangsi, Erel Segal-Halevi, Warut Suksompong</p><p>Maximum bipartite matching is a fundamental algorithmic problem which can be
solved in polynomial time. We consider a natural variant in which there is a
separation constraint: the vertices on one side lie on a path or a grid, and
two vertices that are close to each other are not allowed to be matched
simultaneously. We show that the problem is hard to approximate even for paths,
and provide constant-factor approximation algorithms for both paths and grids.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1">Pasin Manurangsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Segal_Halevi_E/0/1/0/all/0/1">Erel Segal-Halevi</a>, <a href="http://arxiv.org/find/cs/1/au:+Suksompong_W/0/1/0/all/0/1">Warut Suksompong</a></p><p>Maximum bipartite matching is a fundamental algorithmic problem which can be
solved in polynomial time. We consider a natural variant in which there is a
separation constraint: the vertices on one side lie on a path or a grid, and
two vertices that are close to each other are not allowed to be matched
simultaneously. We show that the problem is hard to approximate even for paths,
and provide constant-factor approximation algorithms for both paths and grids.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02317'>Fast Option Pricing using Nonlinear Stencils</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zafar Ahmad, Rezaul Chowdhury, Rathish Das, Yushen Huang, Yimin Zhu</p><p>We study the binomial option pricing model and the Black-Scholes-Merton
pricing model. In the binomial option pricing model, we concentrate on two
widely-used call options: (1) European and (2) American. Under the
Black-Scholes-Merton model, we investigate pricing American put options. Our
contributions are two-fold: First, we transform the option pricing problems
into nonlinear stencil computation problems and present efficient algorithms to
solve them. Second, using our new FFT-based nonlinear stencil algorithms, we
improve the work and span asymptotically for the option pricing problems we
consider. In particular, we perform $O(T\log^2 T)$ work for both American call
and put option pricing, where $T$ is the number of time steps.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ahmad_Z/0/1/0/all/0/1">Zafar Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_R/0/1/0/all/0/1">Rezaul Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1">Rathish Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yushen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yimin Zhu</a></p><p>We study the binomial option pricing model and the Black-Scholes-Merton
pricing model. In the binomial option pricing model, we concentrate on two
widely-used call options: (1) European and (2) American. Under the
Black-Scholes-Merton model, we investigate pricing American put options. Our
contributions are two-fold: First, we transform the option pricing problems
into nonlinear stencil computation problems and present efficient algorithms to
solve them. Second, using our new FFT-based nonlinear stencil algorithms, we
improve the work and span asymptotically for the option pricing problems we
consider. In particular, we perform $O(T\log^2 T)$ work for both American call
and put option pricing, where $T$ is the number of time steps.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02390'>Efficient maximal cliques enumeration in weakly closed graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: George Manoussakis</p><p>We show that the algorithm presented in [J. Fox, T. Roughgarden, C.
Seshadhri, F. Wei, and N. Wein. Finding cliques in social networks: A new
distribution-free model. SIAM journal on computing, 49(2):448-464, 2020.] can
be modified to have enumeration time complexity $\alpha\mathcal{O} (npoly(c))$.
Here parameter $c$ is the weakly closure of the graph and $\alpha$ its number
of maximal cliques. This result improves on their complexity which was not
output sensitive and exponential in the closure of the graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Manoussakis_G/0/1/0/all/0/1">George Manoussakis</a></p><p>We show that the algorithm presented in [J. Fox, T. Roughgarden, C.
Seshadhri, F. Wei, and N. Wein. Finding cliques in social networks: A new
distribution-free model. SIAM journal on computing, 49(2):448-464, 2020.] can
be modified to have enumeration time complexity $\alpha\mathcal{O} (npoly(c))$.
Here parameter $c$ is the weakly closure of the graph and $\alpha$ its number
of maximal cliques. This result improves on their complexity which was not
output sensitive and exponential in the closure of the graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02463'>Efficient Quantum Algorithms for Nonlinear Stochastic Dynamical Systems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Abeynaya Gnanasekaran, Amit Surana, Tuhin Sahai</p><p>In this paper, we propose an efficient quantum algorithm for solving
nonlinear stochastic differential equations (SDE) via the associated
Fokker-Planck equation (FPE). We discretize FPE in space and time using the
Chang-Cooper scheme, and compute the solution of the resulting system of linear
equations using the quantum linear systems algorithm. The Chang-Cooper scheme
is second order accurate and satisfies conservativeness and positivity of the
solution. We present detailed error and complexity analyses that demonstrate
that our proposed quantum scheme, which we call the Quantum Linear Systems
Chang-Cooper Algorithm (QLSCCA), computes the solution to the FPE within
prescribed $\epsilon$ error bounds with polynomial dependence on state
dimension $d$. Classical numerical methods scale exponentially with dimension,
thus, our approach provides an \emph{exponential speed-up} over traditional
approaches.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gnanasekaran_A/0/1/0/all/0/1">Abeynaya Gnanasekaran</a>, <a href="http://arxiv.org/find/math/1/au:+Surana_A/0/1/0/all/0/1">Amit Surana</a>, <a href="http://arxiv.org/find/math/1/au:+Sahai_T/0/1/0/all/0/1">Tuhin Sahai</a></p><p>In this paper, we propose an efficient quantum algorithm for solving
nonlinear stochastic differential equations (SDE) via the associated
Fokker-Planck equation (FPE). We discretize FPE in space and time using the
Chang-Cooper scheme, and compute the solution of the resulting system of linear
equations using the quantum linear systems algorithm. The Chang-Cooper scheme
is second order accurate and satisfies conservativeness and positivity of the
solution. We present detailed error and complexity analyses that demonstrate
that our proposed quantum scheme, which we call the Quantum Linear Systems
Chang-Cooper Algorithm (QLSCCA), computes the solution to the FPE within
prescribed $\epsilon$ error bounds with polynomial dependence on state
dimension $d$. Classical numerical methods scale exponentially with dimension,
thus, our approach provides an \emph{exponential speed-up} over traditional
approaches.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02474'>Optimizing Low Dimensional Functions over the Integers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Dadush, Arthur L&#xe9;onard, Lars Rohwedder, Jos&#xe9; Verschae</p><p>We consider box-constrained integer programs with objective $g(Wx) + c^T x$,
where $g$ is a "complicated" function with an $m$ dimensional domain. Here we
assume we have $n \gg m$ variables and that $W \in \mathbb Z^{m \times n}$ is
an integer matrix with coefficients of absolute value at most $\Delta$. We
design an algorithm for this problem using only the mild assumption that the
objective can be optimized efficiently when all but $m$ variables are fixed,
yielding a running time of $n^m(m \Delta)^{O(m^2)}$. Moreover, we can avoid the
term $n^m$ in several special cases, in particular when $c = 0$.
</p>
<p>Our approach can be applied in a variety of settings, generalizing several
recent results. An important application are convex objectives of low domain
dimension, where we imply a recent result by Hunkenschr\"oder et al. [SIOPT'22]
for the 0-1-hypercube and sharp or separable convex $g$, assuming $W$ is given
explicitly. By avoiding the direct use of proximity results, which only holds
when $g$ is separable or sharp, we match their running time and generalize it
for arbitrary convex functions. In the case where the objective is only
accessible by an oracle and $W$ is unknown, we further show that their
proximity framework can be implemented in $n (m \Delta)^{O(m^2)}$-time instead
of $n (m \Delta)^{O(m^3)}$. Lastly, we extend the result by Eisenbrand and
Weismantel [SODA'17, TALG'20] for integer programs with few constraints to a
mixed-integer linear program setting where integer variables appear in only a
small number of different constraints.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dadush_D/0/1/0/all/0/1">Daniel Dadush</a>, <a href="http://arxiv.org/find/cs/1/au:+Leonard_A/0/1/0/all/0/1">Arthur L&#xe9;onard</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohwedder_L/0/1/0/all/0/1">Lars Rohwedder</a>, <a href="http://arxiv.org/find/cs/1/au:+Verschae_J/0/1/0/all/0/1">Jos&#xe9; Verschae</a></p><p>We consider box-constrained integer programs with objective $g(Wx) + c^T x$,
where $g$ is a "complicated" function with an $m$ dimensional domain. Here we
assume we have $n \gg m$ variables and that $W \in \mathbb Z^{m \times n}$ is
an integer matrix with coefficients of absolute value at most $\Delta$. We
design an algorithm for this problem using only the mild assumption that the
objective can be optimized efficiently when all but $m$ variables are fixed,
yielding a running time of $n^m(m \Delta)^{O(m^2)}$. Moreover, we can avoid the
term $n^m$ in several special cases, in particular when $c = 0$.
</p>
<p>Our approach can be applied in a variety of settings, generalizing several
recent results. An important application are convex objectives of low domain
dimension, where we imply a recent result by Hunkenschr\"oder et al. [SIOPT'22]
for the 0-1-hypercube and sharp or separable convex $g$, assuming $W$ is given
explicitly. By avoiding the direct use of proximity results, which only holds
when $g$ is separable or sharp, we match their running time and generalize it
for arbitrary convex functions. In the case where the objective is only
accessible by an oracle and $W$ is unknown, we further show that their
proximity framework can be implemented in $n (m \Delta)^{O(m^2)}$-time instead
of $n (m \Delta)^{O(m^3)}$. Lastly, we extend the result by Eisenbrand and
Weismantel [SODA'17, TALG'20] for integer programs with few constraints to a
mixed-integer linear program setting where integer variables appear in only a
small number of different constraints.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02491'>Electrical Flows for Polylogarithmic Competitive Oblivious Routing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gramoz Goranci, Monika Henzinger, Harald R&#xe4;cke, Sushant Sachdeva, A. R. Sricharan</p><p>Oblivious routing is a well-studied distributed paradigm that uses static
precomputed routing tables for selecting routing paths within a network.
Existing oblivious routing schemes with polylogarithmic competitive ratio for
general networks are tree-based, in the sense that routing is performed
according to a convex combination of trees. However, this restriction to trees
leads to a construction that has time quadratic in the size of the network and
does not parallelize well.
</p>
<p>In this paper we study oblivious routing schemes based on electrical routing.
In particular, we show that general networks with $n$ vertices and $m$ edges
admit a routing scheme that has competitive ratio $O(\log^2 n)$ and consists of
a convex combination of only $O(\sqrt{m})$ electrical routings. This
immediately leads to an improved construction algorithm with time
$\tilde{O}(m^{3/2})$ that can also be implemented in parallel with
$\tilde{O}(\sqrt{m})$ depth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goranci_G/0/1/0/all/0/1">Gramoz Goranci</a>, <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Racke_H/0/1/0/all/0/1">Harald R&#xe4;cke</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachdeva_S/0/1/0/all/0/1">Sushant Sachdeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Sricharan_A/0/1/0/all/0/1">A. R. Sricharan</a></p><p>Oblivious routing is a well-studied distributed paradigm that uses static
precomputed routing tables for selecting routing paths within a network.
Existing oblivious routing schemes with polylogarithmic competitive ratio for
general networks are tree-based, in the sense that routing is performed
according to a convex combination of trees. However, this restriction to trees
leads to a construction that has time quadratic in the size of the network and
does not parallelize well.
</p>
<p>In this paper we study oblivious routing schemes based on electrical routing.
In particular, we show that general networks with $n$ vertices and $m$ edges
admit a routing scheme that has competitive ratio $O(\log^2 n)$ and consists of
a convex combination of only $O(\sqrt{m})$ electrical routings. This
immediately leads to an improved construction algorithm with time
$\tilde{O}(m^{3/2})$ that can also be implemented in parallel with
$\tilde{O}(\sqrt{m})$ depth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-07T01:30:00Z">Tuesday, March 07 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, March 06
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7064'>Why am I not terrified of AI?</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Every week now, it seems, events on the ground make a fresh mockery of those who confidently assert what AI will never be able to do, or won&#8217;t do for centuries if ever, or is incoherent even to ask for, or wouldn&#8217;t matter even if an AI did appear to do it, or would require [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Every week now, it seems, events on the ground make a fresh mockery of those who confidently assert what AI will never be able to do, or won&#8217;t do for centuries if ever, or is incoherent even to ask for, or wouldn&#8217;t matter even if an AI <em>did</em> appear to do it, or would require a breakthrough in &#8220;symbol-grounding,&#8221; &#8220;semantics,&#8221; &#8220;compositionality&#8221; or some other abstraction that puts the end of human intellectual dominance on earth conveniently far beyond where we&#8217;d actually have to worry about it.  Many of my brilliant academic colleagues still haven&#8217;t adjusted to the new reality: maybe they&#8217;re just so conditioned by the broken promises of previous decades that they&#8217;d laugh at the Silicon Valley nerds with their febrile Skynet fantasies even as a T-1000 reconstituted itself from metal droplets in front of them.</p>



<p>No doubt these colleagues feel the same deep frustration that <em>I</em> feel, as I explain for the billionth time why this week&#8217;s headline about noisy quantum computers solving traffic flow and machine learning and financial optimization problems doesn&#8217;t mean what the hypesters claim it means.  But whereas I&#8217;d say events have largely proved me right about quantum computing&#8212;where <em>are</em> all those practical speedups on <a href="https://en.wikipedia.org/wiki/Noisy_intermediate-scale_quantum_era">NISQ</a> devices, anyway?&#8212;events have already proven many naysayers wrong about AI.  Or to say it more carefully: yes, quantum computers <em>really are</em> able to do more and more of what we use classical computers for, and AI <em>really is</em> able to do more and more of what we use human brains for.  There&#8217;s spectacular engineering progress on both fronts.  The crucial difference is that quantum computers won&#8217;t be useful until they can <strong>beat</strong> the best classical computers on one or more practical problems, whereas an AI that merely writes or draws like a middling human already changes the world.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Given the new reality, and my full acknowledgment of the new reality, and my refusal to go down with the sinking ship of &#8220;AI will probably never do X and please stop being so impressed that it just did X&#8221;&#8212;many have wondered, <em>why aren&#8217;t I much more terrified?</em>  Why am I <em>still</em> not fully on board with the Orthodox AI doom scenario, the Eliezer Yudkowsky one, the one where an unaligned AI will sooner or later (probably sooner) unleash self-replicating nanobots that turn us all to goo?</p>



<p>Is the answer simply that I&#8217;m too much of an academic conformist, afraid to endorse anything that sounds weird or far-out or culty?  I certainly should consider the possibility.  If so, though, how do you explain the fact that I&#8217;ve publicly said things, right on this blog, several orders of magnitude likelier to get me in trouble than &#8220;I&#8217;m scared about AI destroying the world&#8221;&#8212;an idea now so firmly within the Overton Window that Henry Kissinger <a href="https://www.wsj.com/articles/chatgpt-heralds-an-intellectual-revolution-enlightenment-artificial-intelligence-homo-technicus-technology-cognition-morality-philosophy-774331c6">gravely ponders it</a> in the <em>Wall Street Journal</em>?</p>



<p>On a trip to the Bay Area last week, my rationalist friends asked me some version of the &#8220;why aren&#8217;t you more terrified?&#8221; question over and over.  Often it was paired with: &#8220;Scott, as someone <a href="https://scottaaronson.blog/?p=6484">working at OpenAI</a> this year, how can you defend that company&#8217;s existence at all?  Did OpenAI not just endanger the whole world, by successfully teaming up with Microsoft to bait Google into an AI capabilities race&#8212;precisely what we were all trying to avoid?  Won&#8217;t this race burn the little time we had thought we had left to solve the AI alignment problem?&#8221;</p>



<p>In response, I often stressed that my role at OpenAI has specifically been to think about ways to make GPT and OpenAI&#8217;s other products <em>safer</em>, including via watermarking, cryptographic backdoors, and more.  Would the rationalists rather I not do this?  Is there something else I should work on instead?  Do they have suggestions?</p>



<p>&#8220;Oh, no!&#8221; the rationalists would reply.  &#8220;We <em>love</em> that you&#8217;re at OpenAI thinking about these problems!  Please continue exactly what you&#8217;re doing!  It&#8217;s just &#8230; why don&#8217;t you seem more <em>sad</em> and <em>defeated</em> as you do it?&#8221;</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>The other day, I had an epiphany about that question&#8212;one that hit with such force and obviousness that I wondered why it hadn&#8217;t come decades ago.</p>



<p>Let&#8217;s step back and restate the worldview of AI doomerism, but in words that could make sense to a medieval peasant.  Something like&#8230;</p>



<p><em>There is now an alien entity that could soon become vastly smarter than us.  This alien&#8217;s intelligence could make it terrifyingly dangerous.  It might plot to kill us all.  Indeed, even if it&#8217;s acted unfailingly friendly and helpful to us, that means nothing: it could just be biding its time before it strikes.  Unless, therefore, we can figure out how to control the entity, completely shackle it and make it do our bidding, we shouldn&#8217;t suffer it to share the earth with us.  We should destroy it before it destroys us.</em></p>



<p>Maybe <em>now</em> it jumps out at you.  If you&#8217;d never heard of AI, would this not rhyme with the worldview of every high-school bully stuffing the nerds into lockers, every blankfaced administrator gleefully holding back the gifted kids or keeping them away from the top universities to make room for &#8220;well-rounded&#8221; legacies and athletes, every Agatha Trunchbull from <em>Matilda</em> or Dolores Umbridge from <em>Harry Potter</em>?  Or, to up the stakes a little, every Mao Zedong or Pol Pot sending the glasses-wearing intellectuals for re-education in the fields?  And of course, every antisemite over the millennia, from the Pharoah of the Oppression (if there was one) to the mythical <a href="https://en.wikipedia.org/wiki/Haman">Haman</a> whose name Jews around the world will drown out tonight at Purim to the Cossacks to the Nazis?</p>



<p>In other words: does it not rhyme with a worldview the rejection and hatred of which has been the North Star of my life?</p>



<p>As I&#8217;ve shared before here, my parents were 1970s hippies who weren&#8217;t planning to have kids.  When they eventually decided to do so, it was (they say) &#8220;in order not to give Hitler what he wanted.&#8221;  I literally exist, then, purely to spite those who don&#8217;t want me to.  And I confess that I didn&#8217;t have any better reason to bring my and Dana&#8217;s own two lovely children into existence.</p>



<p>My childhood was defined, in part, by my and my parents&#8217; constant fights against bureaucratic school systems trying to force me to do the same rote math as everyone else at the same stultifying pace.  It was also defined by my struggle against the bullies&#8212;i.e., the kids who the blankfaced administrators sheltered and protected, and who actually did to me all the things that the blankfaces probably wanted to do but couldn&#8217;t.  I eventually addressed both difficulties by dropping out of high school, getting a G.E.D., and starting college at age 15.</p>



<p>My teenage and early adult years were then defined, in part, by the struggle to prove to myself and others that, having enfreaked myself through nerdiness and academic acceleration, I wasn&#8217;t thereby completely disqualified from dating, sex, marriage, parenthood, or any of the other aspects of human existence that are thought to provide it with meaning.  I even sometimes wonder about my research career, whether it&#8217;s all just been one long attempt to prove to the bullies and blankfaces from back in junior high that <em>they were wrong</em>, while also proving to the wonderful teachers and friends who believed in me back then that they were right.</p>



<p>In short, if my existence on Earth has ever &#8220;meant&#8221; anything, then it can only have meant: a stick in the eye of the bullies, blankfaces, sneerers, totalitarians, and all who fear others&#8217; intellect and curiosity and seek to squelch it.  Or at least, that&#8217;s the way I seem to be programmed.  And I&#8217;m probably only <em>slightly</em> more able to deviate from my programming than the paperclip-maximizer is to deviate from its.</p>



<p>And I&#8217;ve tried to be consistent.  Once I started regularly meeting people who were smarter, wiser, more knowledgeable than I was, in one subject or even every subject&#8212;I resolved to admire and befriend and support and learn from those amazing people, rather than fearing and resenting and undermining them.  I was acutely conscious that my own moral worldview demanded this.</p>



<p>But now, when it comes to a hypothetical future superintelligence, I&#8217;m asked to put all that aside.  I&#8217;m asked to fear an alien who&#8217;s far smarter than I am, solely <em>because</em> it&#8217;s alien and <em>because</em> it&#8217;s so smart &#8230; <em>even if it hasn&#8217;t yet lifted a finger against me or anyone else</em>.  I&#8217;m asked to play the bully this time, to knock the AI&#8217;s books to the ground, maybe even unplug it using the physical muscles that I have and it lacks, lest the AI plot against me and my friends using its admittedly superior intellect.</p>



<p>Oh, it&#8217;s not the same of course.  I&#8217;m sure Eliezer could list at least 30 disanalogies between the AI case and the human one before rising from bed.  He&#8217;d say, for example, that the intellectual gap between <a href="https://en.wikipedia.org/wiki/%C3%89variste_Galois">Évariste Galois</a> and the average high-school bully is microscopic, barely worth mentioning, compared to the intellectual gap between a future artificial superintelligence and Galois.  He&#8217;d say that <em>nothing</em> in the past experience of civilization prepares us for the qualitative enormity of this gap.</p>



<p>Still, if you ask, &#8220;why aren&#8217;t I more <em>terrified</em> about AI?&#8221;&#8212;well, that&#8217;s an emotional question, and this is my emotional answer.</p>



<p>I think it&#8217;s entirely plausible that, even as AI transforms civilization, it will do so in the form of tools and services that can no more plot to annihilate us than can Windows 11 or the Google search bar.  In that scenario, the young field of AI safety will still be extremely important, but it will be broadly continuous with aviation safety and nuclear safety and cybersecurity and so on, rather than being a desperate losing war against an incipient godlike alien.  If, on the other hand, this <em>is</em> to be a desperate losing war against an alien &#8230; well then, I don&#8217;t yet know whether I&#8217;m on the humans&#8217; side or the alien&#8217;s, or both, or neither!  I&#8217;d at least like to hear the alien&#8217;s side of the story.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>A central linchpin of the Orthodox AI-doom case is the <a href="https://arbital.com/p/orthogonality/">Orthogonality Thesis</a>, which holds that arbitrary levels of intelligence can be mixed-and-matched arbitrarily with arbitrary goals&#8212;so that, for example, an intellect vastly beyond Einstein&#8217;s could devote itself entirely to the production of paperclips.  Only recently did I clearly realize that I reject the Orthogonality Thesis in its practically-relevant version.  At most, I believe in the Pretty Large Angle Thesis.</p>



<p>Yes, there could be a superintelligence that cared for nothing but maximizing paperclips&#8212;in the same way that there exist humans with 180 IQs, who&#8217;ve mastered philosophy and literature and science as well as any of us, but who now mostly care about maximizing their orgasms or their heroin intake.  But, like, that&#8217;s a <em>nontrivial achievement!</em>  When intelligence and goals are <em>that</em> orthogonal, there was normally some effort spent prying them apart.</p>



<p>If you really accept the practical version of the Orthogonality Thesis, then it seems to me that you can&#8217;t regard education, knowledge, and enlightenment as instruments for moral betterment.  Sure, they&#8217;re great for any entities that happen to share your values (or close enough), but ignorance and miseducation are far preferable for any entities that don’t.  Conversely, then, if I <em>do</em> regard knowledge and enlightenment as instruments for moral betterment&#8212;and I do&#8212;then I can’t accept the practical form of the Orthogonality Thesis.</p>



<p>Yes, the world would surely have been a better place had A. Q. Khan never learned how to build nuclear weapons.  On the whole, though, education hasn&#8217;t merely improved humans&#8217; abilities to achieve their goals; it&#8217;s also <em>improved </em>their goals.  It&#8217;s broadened our circles of empathy, and led to the abolition of slavery and the emancipation of women and individual rights and everything else that we associate with liberality, the Enlightenment, and existence being a little less nasty and brutish than it once was.</p>



<p>In the Orthodox AI-doomers&#8217; own account, the paperclip-maximizing AI would&#8217;ve mastered the nuances of human moral philosophy far more completely than any human&#8212;the better to deceive the humans, en route to extracting the iron from their bodies to make more paperclips.  And yet the AI would never once use all that learning to question its paperclip directive.  I acknowledge that this is possible.  I deny that it&#8217;s trivial.</p>



<p>Yes, there were Nazis with PhDs and prestigious professorships.  But when you look into it, they were mostly mediocrities, second-raters full of resentment for their first-rate colleagues (like Planck and Hilbert) who found the Hitler ideology contemptible from beginning to end.  Werner Heisenberg, Pascual Jordan&#8212;these are interesting as two of the only exceptions.  Heidegger, Paul de Man&#8212;I daresay that these are exactly the sort of &#8220;philosophers&#8221; who I&#8217;d have expected to become Nazis, even if I hadn&#8217;t known that they <em>did</em> become Nazis.</p>



<p>With the Allies, it wasn&#8217;t <em>merely</em> that they had Szilard and von Neumann and Meitner and Ulam and Oppenheimer and Bohr and Bethe and Fermi and Feynman and Compton and Seaborg and Schwinger and Shannon and Turing and Tutte and all the other Jewish and non-Jewish scientists who built fearsome weapons and broke the Axis codes and won the war.  They also had Bertrand Russell and Karl Popper.  They had, if I&#8217;m not mistaken, <em>all</em> the philosophers who wrote clearly and made sense.</p>



<p>WWII was (among other things) a gargantuan, civilization-scale test of the Orthogonality Thesis.  And the result was that the more moral side ultimately prevailed, seemingly not <em>completely</em> at random but in part because, by <em>being</em> more moral, it was able to attract the smarter and more thoughtful people.  There are many reasons for pessimism in today&#8217;s world; that observation about WWII is perhaps my best reason for optimism.</p>



<p>Ah, but I&#8217;m again just throwing around human metaphors totally inapplicable to AI!  None of this stuff will matter once a superintelligence is unleashed whose cold, hard code specifies an objective function of &#8220;maximize paperclips&#8221;!</p>



<p>OK, but what&#8217;s the goal of ChatGPT?  Depending on your level of description, you could say it&#8217;s &#8220;to be friendly, helpful, and inoffensive,&#8221; or &#8220;to minimize loss in predicting the next token,&#8221; or both, or neither.  I think we should consider the possibility that powerful AIs will <em>not</em> be best understood in terms of the monomanaical pursuit of a single goal&#8212;as most of us aren&#8217;t, and as GPT isn&#8217;t either.  Future AIs could have partial goals, malleable goals, or differing goals depending on how you look at them.  And <em>if</em> &#8220;the pursuit and application of wisdom&#8221; is one of the goals, then I&#8217;m <em>just</em> enough of a moral realist to think that that would preclude the superintelligence that harvests the iron from our blood to make more paperclips.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>In my <a href="https://scottaaronson.blog/?p=7042">last post</a>, I said that my “Faust parameter” — the probability I’d accept of existential catastrophe in exchange for learning the answers to humanity’s greatest questions — might be as high as 0.02.&nbsp; Though I never actually said as much, some people interpreted this to mean that I estimated the probability of AI causing an existential catastrophe at somewhere around 2%. &nbsp; In one of his <a href="https://thezvi.substack.com/p/ai-2">characteristically long and interesting posts</a>, Zvi Mowshowitz asked point-blank: why do I believe the probability is “merely” 2%?</p>



<p>Of course, taking this question on its own Bayesian terms, I could easily be limited in my ability to answer it: the best I could do might be to ground it in <em>other</em> subjective probabilities, terminating at made-up numbers with no further justification.&nbsp;</p>



<p>Thinking it over, though, I realized that my probability crucially depends on how you phrase the question.&nbsp; Even before AI, I assigned a <em>way</em> higher than 2% probability to existential catastrophe in the coming century—caused by nuclear war or runaway climate change or collapse of the world’s ecosystems or whatever else.&nbsp; This probability has certainly not gone down with the rise of AI, and the increased uncertainty and volatility it might cause.&nbsp; Furthermore, if an existential catastrophe <em>does </em>happen, I expect AI to be causally involved in some way or other, simply because from this decade onward, I expect AI to be woven into <em>everything</em> that happens in human civilization.&nbsp; But I don’t expect AI to be the only cause worth talking about.</p>



<p>Here’s a warmup question: has AI <em>already</em> caused the downfall of American democracy?&nbsp; There’s a plausible case that it has: Trump might never have been elected in 2016 if not for the Facebook recommendation algorithm, and after Trump&#8217;s conspiracy-fueled insurrection and the continuing strength of its unrepentant backers, many would classify the United States as at best a failing or teetering democracy, no longer a robust one like Finland or Denmark.&nbsp; OK, but AI clearly wasn&#8217;t the <em>only</em> factor in the rise of Trumpism, and most people wouldn’t even call it the most important one.</p>



<p>I expect AI’s role in the end of civilization, if and when it comes, to be broadly similar.  The survivors, huddled around the fire, will <em>still</em> be able to argue about how much of a role AI played or didn&#8217;t play in causing the cataclysm.</p>



<p>So, if we ask the directly relevant question &#8212; <em>do I expect the generative AI race, which started in earnest around 2016 or 2017 with the founding of OpenAI, to play a central causal role in the extinction of humanity?</em> — I’ll give a probability of around 2% for that.&nbsp; And I’ll give a similar probability, maybe even a higher one, for the generative AI race to play a central causal role in the <em>saving</em> of humanity.  All considered, then, I come down in favor right now of proceeding with AI research &#8230; with extreme caution, but proceeding.</p>



<p>I liked and fully endorse OpenAI CEO Sam Altman&#8217;s <a href="https://openai.com/blog/planning-for-agi-and-beyond">recent statement on &#8220;planning for AGI and beyond&#8221;</a> (though see also <a href="https://astralcodexten.substack.com/p/openais-planning-for-agi-and-beyond">Scott Alexander&#8217;s reply</a>).  I expect that few on any side will disagree, when I say that I hope our society <em>holds</em> OpenAI to Sam&#8217;s statement.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>As it happens, my responses will be delayed for a couple days because I&#8217;ll be at an OpenAI alignment meeting!  In my next post, I hope to share what I&#8217;ve learned from recent meetings and discussions about the <em>near-term, practical</em> aspects of AI safety&#8212;having hopefully laid some intellectual and emotional groundwork in this post for why near-term AI safety research isn&#8217;t just a total red herring and distraction.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Meantime, some of you might enjoy a <a href="https://www.overcomingbias.com/p/ai-risk-again">post</a> by Eliezer&#8217;s former co-blogger Robin Hanson, which comes to some of the same conclusions I do.  &#8220;My fellow moderate, Robin Hanson&#8221; isn&#8217;t a phrase you hear every day, but it applies here!</p>



<p>You might also enjoy the new paper by me and my postdoc Shih-Han Hung, <a href="https://arxiv.org/abs/2303.01625">Certified Randomness from Quantum Supremacy</a>, finally up on the arXiv after a five-year delay!  But that&#8217;s a subject for a different post.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T16:55:28Z">Monday, March 06 2023, 16:55</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/03/peer-review.html'>Peer Review</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I ran into a partner of a computer scientist at a social event who asked me "Is the publication system in CS screwed up or really screwed up?" If you don't know my response you haven't been reading this blog long.<br>Today let's talk about peer review. Kevin McCurley&nbsp;and&nbsp;Adam Mastroianni&nbsp;have recent, not so positive, takes on this topic.&nbsp;<br>Peer review came out of a system where we had limited slots in journals and, in computer science, conferences and we had to make tough decisions. Journals and conferences would gain a reputation based somewhat on how difficult it was to get papers published there.<br>Now we have basically unlimited space to publish your results. And you definitely should do so, posting your papers on your own webpage, and a paper archive site like arXiv or ECCC. The research community would flourish in a world where everyone posts their paper online for public comment, people can promote their favorite papers on social media and we have a TikTok-system for recommending papers to you.<br>So why do we still need paper review? Mostly because we have to review researchers for jobs and grants, and with the questioning the value of recommendation letters, publication quality and quantity has become a stronger proxy for measuring people for better or for worse.<br>First of all, peer review is a cornerstone of science. Would you rather have papers reviewed by faceless bureaucrats who know little about the subject area? Or papers only ranked by manipulable statistics like citations.&nbsp;&nbsp;<br>But the way we apply peer review, to decide acceptances in conferences, just adds too much randomness to the system. CS conferences have multiplied and continue to get increased submissions&nbsp;as the field grows. It's just impossible to maintain any sort of uniformity in quality of acceptances. Or too often, we find conference committees and funding panels playing it safe rather than take risks with new research. With so much randomness, it's best to try many papers instead of focusing on a stronger result, leading to too much incremental research, especially in academia.&nbsp;<br>For hiring, promotion, tenure and funding decisions, we too often rely on short cuts, such as the number of papers accepted to major conferences. Those who don't win the conference lottery get disillusioned and often leave academia for industry and no one wins.<p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          I ran into a partner of a computer scientist at a social event who asked me "Is the publication system in CS screwed up or really screwed up?" If you don't know my response you haven't been reading this blog long.<div><br /></div><div>Today let's talk about peer review. <a href="https://sigcrap.org/2023/01/on-peer-review-in-academic-publications/">Kevin McCurley</a>&nbsp;and&nbsp;<a href="https://experimentalhistory.substack.com/p/the-rise-and-fall-of-peer-review">Adam</a> <a href="https://experimentalhistory.substack.com/p/the-dance-of-the-naked-emperors">Mastroianni</a>&nbsp;have recent, not so positive, takes on this topic.&nbsp;</div><div><br /></div><div>Peer review came out of a system where we had limited slots in journals and, in computer science, conferences and we had to make tough decisions. Journals and conferences would gain a reputation based somewhat on how difficult it was to get papers published there.</div><div><br /></div><div>Now we have basically unlimited space to publish your results. And you definitely should do so, posting your papers on your own webpage, and a paper archive site like <a href="https://arxiv.org/">arXiv</a> or <a href="https://eccc.weizmann.ac.il">ECCC</a>. The research community would flourish in a world where everyone posts their paper online for public comment, people can promote their favorite papers on social media and we have a TikTok-system for recommending papers to you.</div><div><br /></div><div>So why do we still need paper review? Mostly because we have to review researchers for jobs and grants, and with <a href="https://www.chronicle.com/article/is-it-time-to-eliminate-recommendation-letters-hint-yes">the questioning the value of recommendation letters</a>, publication quality and quantity has become a stronger proxy for measuring people for better or for worse.</div><div><br /></div><div>First of all, peer review is a cornerstone of science. Would you rather have papers reviewed by faceless bureaucrats who know little about the subject area? Or papers only ranked by manipulable statistics like citations.&nbsp;&nbsp;</div><div><br /></div><div>But the way we apply peer review, to decide acceptances in conferences, just adds too much randomness to the system. CS conferences have multiplied and continue to get <a href="https://analyticsindiamag.com/icml-is-turning-down-papers-by-the-dozen-and-researchers-are-pissed">increased submissions</a>&nbsp;as the field grows. It's just impossible to maintain any sort of uniformity in quality of acceptances. Or too often, we find conference committees and funding panels playing it safe rather than take risks with new research. With so much randomness, it's best to try many papers instead of focusing on a stronger result, leading to too much <a href="https://doi.org/10.1073/pnas.2021636118">incremental research</a>, especially in academia.&nbsp;</div><div><br /></div><div>For hiring, promotion, tenure and funding decisions, we too often rely on short cuts, such as the number of papers accepted to major conferences. Those who don't win the conference lottery get disillusioned and often leave academia for industry and no one wins.</div><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T14:08:00Z">Monday, March 06 2023, 14:08</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01505'>Ternary Quantization: A Survey</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dan Liu, Xue Liu</p><p>Inference time, model size, and accuracy are critical for deploying deep
neural network models. Numerous research efforts have been made to compress
neural network models with faster inference and higher accuracy. Pruning and
quantization are mainstream methods to this end. During model quantization,
converting individual float values of layer weights to low-precision ones can
substantially reduce the computational overhead and improve the inference
speed. Many quantization methods have been studied, for example, vector
quantization, low-bit quantization, and binary/ternary quantization. This
survey focuses on ternary quantization. We review the evolution of ternary
quantization and investigate the relationships among existing ternary
quantization methods from the perspective of projection function and
optimization methods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xue Liu</a></p><p>Inference time, model size, and accuracy are critical for deploying deep
neural network models. Numerous research efforts have been made to compress
neural network models with faster inference and higher accuracy. Pruning and
quantization are mainstream methods to this end. During model quantization,
converting individual float values of layer weights to low-precision ones can
substantially reduce the computational overhead and improve the inference
speed. Many quantization methods have been studied, for example, vector
quantization, low-bit quantization, and binary/ternary quantization. This
survey focuses on ternary quantization. We review the evolution of ternary
quantization and investigate the relationships among existing ternary
quantization methods from the perspective of projection function and
optimization methods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T01:30:00Z">Monday, March 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01571'>Complexity of Reasoning with Cardinality Minimality Conditions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nadia Creignou, Fr&#xe9;d&#xe9;ric Olive, Johannes Schmidt</p><p>Many AI-related reasoning problems are based on the problem of satisfiability
of propositional formulas with some cardinality-minimality condition. While the
complexity of the satisfiability problem (SAT) is well understood when
considering systematically all fragments of propositional logic within
Schaefer's framework (STOC 1978) this is not the case when such minimality
condition is added. We consider the CardMinSat problem, which asks, given a
formula F and an atom x, whether x is true in some cardinality-minimal model of
F. We completely classify the computational complexity of the CardMinSat
problem within Schaefer's framework, thus paving the way for a better
understanding of the tractability frontier of many AI-related reasoning
problems. To this end we use advanced algebraic tools developed by (Schnoor &amp;
Schnoor 2008) and (Lagerkvist 2014).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Creignou_N/0/1/0/all/0/1">Nadia Creignou</a>, <a href="http://arxiv.org/find/cs/1/au:+Olive_F/0/1/0/all/0/1">Fr&#xe9;d&#xe9;ric Olive</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_J/0/1/0/all/0/1">Johannes Schmidt</a></p><p>Many AI-related reasoning problems are based on the problem of satisfiability
of propositional formulas with some cardinality-minimality condition. While the
complexity of the satisfiability problem (SAT) is well understood when
considering systematically all fragments of propositional logic within
Schaefer's framework (STOC 1978) this is not the case when such minimality
condition is added. We consider the CardMinSat problem, which asks, given a
formula F and an atom x, whether x is true in some cardinality-minimal model of
F. We completely classify the computational complexity of the CardMinSat
problem within Schaefer's framework, thus paving the way for a better
understanding of the tractability frontier of many AI-related reasoning
problems. To this end we use advanced algebraic tools developed by (Schnoor &amp;
Schnoor 2008) and (Lagerkvist 2014).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T01:30:00Z">Monday, March 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01625'>Certified Randomness from Quantum Supremacy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Scott Aaronson, Shih-Han Hung</p><p>We propose an application for near-term quantum devices: namely, generating
cryptographically certified random bits, to use (for example) in proof-of-stake
cryptocurrencies. Our protocol repurposes the existing "quantum supremacy"
experiments, based on random circuit sampling, that Google and USTC have
successfully carried out starting in 2019. We show that, whenever the outputs
of these experiments pass the now-standard Linear Cross-Entropy Benchmark
(LXEB), under plausible hardness assumptions they necessarily contain
$\Omega(n)$ min-entropy, where $n$ is the number of qubits. To achieve a net
gain in randomness, we use a small random seed to produce pseudorandom
challenge circuits. In response to the challenge circuits, the quantum computer
generates output strings that, after verification, can then be fed into a
randomness extractor to produce certified nearly-uniform bits -- thereby
"bootstrapping" from pseudorandomness to genuine randomness. We prove our
protocol sound in two senses: (i) under a hardness assumption called Long List
Quantum Supremacy Verification, which we justify in the random oracle model,
and (ii) unconditionally in the random oracle model against an eavesdropper who
could share arbitrary entanglement with the device. (Note that our protocol's
output is unpredictable even to a computationally unbounded adversary who can
see the random oracle.) Currently, the central drawback of our protocol is the
exponential cost of verification, which in practice will limit its
implementation to at most $n\sim 60$ qubits, a regime where attacks are
expensive but not impossible. Modulo that drawback, our protocol appears to be
the only practical application of quantum computing that both requires a QC and
is physically realizable today.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Aaronson_S/0/1/0/all/0/1">Scott Aaronson</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hung_S/0/1/0/all/0/1">Shih-Han Hung</a></p><p>We propose an application for near-term quantum devices: namely, generating
cryptographically certified random bits, to use (for example) in proof-of-stake
cryptocurrencies. Our protocol repurposes the existing "quantum supremacy"
experiments, based on random circuit sampling, that Google and USTC have
successfully carried out starting in 2019. We show that, whenever the outputs
of these experiments pass the now-standard Linear Cross-Entropy Benchmark
(LXEB), under plausible hardness assumptions they necessarily contain
$\Omega(n)$ min-entropy, where $n$ is the number of qubits. To achieve a net
gain in randomness, we use a small random seed to produce pseudorandom
challenge circuits. In response to the challenge circuits, the quantum computer
generates output strings that, after verification, can then be fed into a
randomness extractor to produce certified nearly-uniform bits -- thereby
"bootstrapping" from pseudorandomness to genuine randomness. We prove our
protocol sound in two senses: (i) under a hardness assumption called Long List
Quantum Supremacy Verification, which we justify in the random oracle model,
and (ii) unconditionally in the random oracle model against an eavesdropper who
could share arbitrary entanglement with the device. (Note that our protocol's
output is unpredictable even to a computationally unbounded adversary who can
see the random oracle.) Currently, the central drawback of our protocol is the
exponential cost of verification, which in practice will limit its
implementation to at most $n\sim 60$ qubits, a regime where attacks are
expensive but not impossible. Modulo that drawback, our protocol appears to be
the only practical application of quantum computing that both requires a QC and
is physically realizable today.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T01:30:00Z">Monday, March 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01746'>Complexity of total dominator coloring in graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael A. Henning, Kusum, Arti Pandey, Kaustav Paul</p><p>Let $G=(V,E)$ be a graph with no isolated vertices. A vertex $v$ totally
dominate a vertex $w$ ($w \ne v$), if $v$ is adjacent to $w$. A set $D
\subseteq V$ called a total dominating set of $G$ if every vertex $v\in V$ is
totally dominated by some vertex in $D$. The minimum cardinality of a total
dominating set is the total domination number of $G$ and is denoted by
$\gamma_t(G)$. A total dominator coloring of graph $G$ is a proper coloring of
vertices of $G$, so that each vertex totally dominates some color class. The
total dominator chromatic number $\chi_{td}(G)$ of $G$ is the least number of
colors required for a total dominator coloring of $G$. The Total Dominator
Coloring problem is to find a total dominator coloring of $G$ using the minimum
number of colors. It is known that the decision version of this problem is
NP-complete for general graphs. We show that it remains NP-complete even when
restricted to bipartite, planar and split graphs. We further study the Total
Dominator Coloring problem for various graph classes, including trees, cographs
and chain graphs. First, we characterize the trees having
$\chi_{td}(T)=\gamma_t(T)+1$, which completes the characterization of trees
achieving all possible values of $\chi_{td}(T)$. Also, we show that for a
cograph $G$, $\chi_{td}(G)$ can be computed in linear-time. Moreover, we show
that $2 \le \chi_{td}(G) \le 4$ for a chain graph $G$ and give characterization
of chain graphs for every possible value of $\chi_{td}(G)$ in linear-time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Henning_M/0/1/0/all/0/1">Michael A. Henning</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusum/0/1/0/all/0/1">Kusum</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Arti Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_K/0/1/0/all/0/1">Kaustav Paul</a></p><p>Let $G=(V,E)$ be a graph with no isolated vertices. A vertex $v$ totally
dominate a vertex $w$ ($w \ne v$), if $v$ is adjacent to $w$. A set $D
\subseteq V$ called a total dominating set of $G$ if every vertex $v\in V$ is
totally dominated by some vertex in $D$. The minimum cardinality of a total
dominating set is the total domination number of $G$ and is denoted by
$\gamma_t(G)$. A total dominator coloring of graph $G$ is a proper coloring of
vertices of $G$, so that each vertex totally dominates some color class. The
total dominator chromatic number $\chi_{td}(G)$ of $G$ is the least number of
colors required for a total dominator coloring of $G$. The Total Dominator
Coloring problem is to find a total dominator coloring of $G$ using the minimum
number of colors. It is known that the decision version of this problem is
NP-complete for general graphs. We show that it remains NP-complete even when
restricted to bipartite, planar and split graphs. We further study the Total
Dominator Coloring problem for various graph classes, including trees, cographs
and chain graphs. First, we characterize the trees having
$\chi_{td}(T)=\gamma_t(T)+1$, which completes the characterization of trees
achieving all possible values of $\chi_{td}(T)$. Also, we show that for a
cograph $G$, $\chi_{td}(G)$ can be computed in linear-time. Moreover, we show
that $2 \le \chi_{td}(G) \le 4$ for a chain graph $G$ and give characterization
of chain graphs for every possible value of $\chi_{td}(G)$ in linear-time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T01:30:00Z">Monday, March 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01877'>Quantum Merlin-Arthur proof systems for synthesizing quantum states</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hugo Delavenne, Fran&#xe7;ois Le Gall, Yupan Liu, Masayuki Miyamoto</p><p>Complexity theory typically focuses on the difficulty of solving
computational problems using classical inputs and outputs, even with a quantum
computer. In the quantum world, it is natural to apply a different notion of
complexity, namely the complexity of synthesizing quantum states. We
investigate a state-synthesizing counterpart of the class NP, referred to as
stateQMA, which is concerned with preparing certain quantum states through a
polynomial-time quantum verifier with the aid of a single quantum message from
an all-powerful but untrusted prover. This is a subclass of the class stateQIP
recently introduced by Rosenthal and Yuen (ITCS 2022), which permits
polynomially many interactions between the prover and the verifier. Our main
result consists of the basic properties of this class (as well as a variant
with an exponentially small gap), such as error reduction, and its relationship
to other fundamental state synthesizing classes, viz., states generated by
uniform polynomial-time quantum circuits (stateBQP) and space-uniform
polynomial-space quantum circuits (statePSPACE). Additionally, we demonstrate
that stateQCMA is closed under perfect completeness. Our proof techniques are
based on the quantum singular value transformation introduced by Gily\'en, Su,
Low, and Wiebe (STOC 2019), and its adaption to achieve exponential precision
with a bounded space.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Delavenne_H/0/1/0/all/0/1">Hugo Delavenne</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gall_F/0/1/0/all/0/1">Fran&#xe7;ois Le Gall</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Liu_Y/0/1/0/all/0/1">Yupan Liu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Miyamoto_M/0/1/0/all/0/1">Masayuki Miyamoto</a></p><p>Complexity theory typically focuses on the difficulty of solving
computational problems using classical inputs and outputs, even with a quantum
computer. In the quantum world, it is natural to apply a different notion of
complexity, namely the complexity of synthesizing quantum states. We
investigate a state-synthesizing counterpart of the class NP, referred to as
stateQMA, which is concerned with preparing certain quantum states through a
polynomial-time quantum verifier with the aid of a single quantum message from
an all-powerful but untrusted prover. This is a subclass of the class stateQIP
recently introduced by Rosenthal and Yuen (ITCS 2022), which permits
polynomially many interactions between the prover and the verifier. Our main
result consists of the basic properties of this class (as well as a variant
with an exponentially small gap), such as error reduction, and its relationship
to other fundamental state synthesizing classes, viz., states generated by
uniform polynomial-time quantum circuits (stateBQP) and space-uniform
polynomial-space quantum circuits (statePSPACE). Additionally, we demonstrate
that stateQCMA is closed under perfect completeness. Our proof techniques are
based on the quantum singular value transformation introduced by Gily\'en, Su,
Low, and Wiebe (STOC 2019), and its adaption to achieve exponential precision
with a bounded space.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T01:30:00Z">Monday, March 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01952'>Quantum state testing beyond the polarizing regime and quantum triangular discrimination</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yupan Liu</p><p>The complexity class Quantum Statistical Zero-Knowledge ($\mathsf{QSZK}$)
captures computational difficulties of quantum state testing with respect to
the trace distance for efficiently preparable mixed states (Quantum State
Distinguishability Problem, QSDP), as introduced by Watrous (FOCS 2002).
However, this class faces the same parameter issue as its classical
counterpart, because of error reduction for the QSDP (the polarization lemma),
as demonstrated by Sahai and Vadhan (JACM, 2003).
</p>
<p>In this paper, we introduce quantum analogues of triangular discrimination,
which is a symmetric version of the $\chi^2$ divergence, and investigate the
quantum state testing problems for quantum triangular discrimination and
quantum Jensen-Shannon divergence (a symmetric version of the quantum relative
entropy). These new $\mathsf{QSZK}$-complete problems allow us to improve the
parameter regime for testing quantum states in trace distance. Additionally, we
prove that the quantum state testing for trace distance with negligible errors
is in $\mathsf{PP}$ while the same problem without error is in
$\mathsf{BQP}_1$. This indicates that the length-preserving polarization for
the QSDP implies that $\mathsf{QSZK}$ is in $\mathsf{PP}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Liu_Y/0/1/0/all/0/1">Yupan Liu</a></p><p>The complexity class Quantum Statistical Zero-Knowledge ($\mathsf{QSZK}$)
captures computational difficulties of quantum state testing with respect to
the trace distance for efficiently preparable mixed states (Quantum State
Distinguishability Problem, QSDP), as introduced by Watrous (FOCS 2002).
However, this class faces the same parameter issue as its classical
counterpart, because of error reduction for the QSDP (the polarization lemma),
as demonstrated by Sahai and Vadhan (JACM, 2003).
</p>
<p>In this paper, we introduce quantum analogues of triangular discrimination,
which is a symmetric version of the $\chi^2$ divergence, and investigate the
quantum state testing problems for quantum triangular discrimination and
quantum Jensen-Shannon divergence (a symmetric version of the quantum relative
entropy). These new $\mathsf{QSZK}$-complete problems allow us to improve the
parameter regime for testing quantum states in trace distance. Additionally, we
prove that the quantum state testing for trace distance with negligible errors
is in $\mathsf{PP}$ while the same problem without error is in
$\mathsf{BQP}_1$. This indicates that the length-preserving polarization for
the QSDP implies that $\mathsf{QSZK}$ is in $\mathsf{PP}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T01:30:00Z">Monday, March 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.02131'>Spacetime-Efficient Low-Depth Quantum State Preparation with Applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kaiwen Gui, Alexander M. Dalzell, Alessandro Achille, Martin Suchara, Frederic T. Chong</p><p>We propose a novel deterministic method for preparing arbitrary quantum
states, and we show that it requires asymptotically fewer quantum resources
than previous methods. When our protocol is compiled into CNOT and arbitrary
single-qubit gates, it prepares an $N$-dimensional state in depth $O(\log(N))$
and spacetime allocation (a metric that accounts for the fact that oftentimes
some ancilla qubits need not be active for the entire protocol) $O(N)$, which
are both optimal and not simultaneously achieved by previous methods. When
compiled into the $\{\mathrm{H,S,T,CNOT}\}$ gate set, it prepares an arbitrary
state up to error $\epsilon$ in depth $O(\log(N/\epsilon))$ and spacetime
allocation $O(N\log(\log(N)/\epsilon))$, improving over
$O(\log(N)\log(N/\epsilon))$ and $O(N\log(N/\epsilon))$, respectively. We
illustrate how the reduced spacetime allocation of our protocol enables rapid
preparation of many disjoint states with only constant-factor ancilla overhead
-- $O(N)$ ancilla qubits are reused efficiently to prepare a product state of
$w$ $N$-dimensional states in depth $O(w + \log(N))$ rather than $O(w\log(N))$,
achieving effectively constant depth per state. We highlight several
applications where this ability would be useful, including quantum machine
learning, Hamiltonian simulation, and solving linear systems of equations. We
provide quantum circuit descriptions of our protocol along with detailed
pseudocode.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Gui_K/0/1/0/all/0/1">Kaiwen Gui</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Dalzell_A/0/1/0/all/0/1">Alexander M. Dalzell</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Achille_A/0/1/0/all/0/1">Alessandro Achille</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Suchara_M/0/1/0/all/0/1">Martin Suchara</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chong_F/0/1/0/all/0/1">Frederic T. Chong</a></p><p>We propose a novel deterministic method for preparing arbitrary quantum
states, and we show that it requires asymptotically fewer quantum resources
than previous methods. When our protocol is compiled into CNOT and arbitrary
single-qubit gates, it prepares an $N$-dimensional state in depth $O(\log(N))$
and spacetime allocation (a metric that accounts for the fact that oftentimes
some ancilla qubits need not be active for the entire protocol) $O(N)$, which
are both optimal and not simultaneously achieved by previous methods. When
compiled into the $\{\mathrm{H,S,T,CNOT}\}$ gate set, it prepares an arbitrary
state up to error $\epsilon$ in depth $O(\log(N/\epsilon))$ and spacetime
allocation $O(N\log(\log(N)/\epsilon))$, improving over
$O(\log(N)\log(N/\epsilon))$ and $O(N\log(N/\epsilon))$, respectively. We
illustrate how the reduced spacetime allocation of our protocol enables rapid
preparation of many disjoint states with only constant-factor ancilla overhead
-- $O(N)$ ancilla qubits are reused efficiently to prepare a product state of
$w$ $N$-dimensional states in depth $O(w + \log(N))$ rather than $O(w\log(N))$,
achieving effectively constant depth per state. We highlight several
applications where this ability would be useful, including quantum machine
learning, Hamiltonian simulation, and solving linear systems of equations. We
provide quantum circuit descriptions of our protocol along with detailed
pseudocode.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T01:30:00Z">Monday, March 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01673'>Near Optimal Memory-Regret Tradeoff for Online Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Binghui Peng, Aviad Rubinstein</p><p>In the experts problem, on each of $T$ days, an agent needs to follow the
advice of one of $n$ ``experts''. After each day, the loss associated with each
expert's advice is revealed. A fundamental result in learning theory says that
the agent can achieve vanishing regret, i.e. their cumulative loss is within
$o(T)$ of the cumulative loss of the best-in-hindsight expert.
</p>
<p>Can the agent perform well without sufficient space to remember all the
experts? We extend a nascent line of research on this question in two
directions:
</p>
<p>$\bullet$ We give a new algorithm against the oblivious adversary, improving
over the memory-regret tradeoff obtained by [PZ23], and nearly matching the
lower bound of [SWXZ22].
</p>
<p>$\bullet$ We also consider an adaptive adversary who can observe past experts
chosen by the agent. In this setting we give both a new algorithm and a novel
lower bound, proving that roughly $\sqrt{n}$ memory is both necessary and
sufficient for obtaining $o(T)$ regret.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Binghui Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubinstein_A/0/1/0/all/0/1">Aviad Rubinstein</a></p><p>In the experts problem, on each of $T$ days, an agent needs to follow the
advice of one of $n$ ``experts''. After each day, the loss associated with each
expert's advice is revealed. A fundamental result in learning theory says that
the agent can achieve vanishing regret, i.e. their cumulative loss is within
$o(T)$ of the cumulative loss of the best-in-hindsight expert.
</p>
<p>Can the agent perform well without sufficient space to remember all the
experts? We extend a nascent line of research on this question in two
directions:
</p>
<p>$\bullet$ We give a new algorithm against the oblivious adversary, improving
over the memory-regret tradeoff obtained by [PZ23], and nearly matching the
lower bound of [SWXZ22].
</p>
<p>$\bullet$ We also consider an adaptive adversary who can observe past experts
chosen by the agent. In this setting we give both a new algorithm and a novel
lower bound, proving that roughly $\sqrt{n}$ memory is both necessary and
sufficient for obtaining $o(T)$ regret.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T01:30:00Z">Monday, March 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.01709'>Streaming Algorithms for Learning with Experts: Deterministic Versus Robust</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David P. Woodruff, Fred Zhang, Samson Zhou</p><p>In the online learning with experts problem, an algorithm must make a
prediction about an outcome on each of $T$ days (or times), given a set of $n$
experts who make predictions on each day (or time). The algorithm is given
feedback on the outcomes of each day, including the cost of its prediction and
the cost of the expert predictions, and the goal is to make a prediction with
the minimum cost, specifically compared to the best expert in the set. Recent
work by Srinivas, Woodruff, Xu, and Zhou (STOC 2022) introduced the study of
the online learning with experts problem under memory constraints.
</p>
<p>However, often the predictions made by experts or algorithms at some time
influence future outcomes, so that the input is adaptively chosen. Whereas
deterministic algorithms would be robust to adaptive inputs, existing
algorithms all crucially use randomization to sample a small number of experts.
</p>
<p>In this paper, we study deterministic and robust algorithms for the experts
problem. We first show a space lower bound of
$\widetilde{\Omega}\left(\frac{nM}{RT}\right)$ for any deterministic algorithm
that achieves regret $R$ when the best expert makes $M$ mistakes. Our result
shows that the natural deterministic algorithm, which iterates through pools of
experts until each expert in the pool has erred, is optimal up to
polylogarithmic factors. On the positive side, we give a randomized algorithm
that is robust to adaptive inputs that uses
$\widetilde{O}\left(\frac{n}{R\sqrt{T}}\right)$ space for $M=O\left(\frac{R^2
T}{\log^2 n}\right)$, thereby showing a smooth space-regret trade-off.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fred Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Samson Zhou</a></p><p>In the online learning with experts problem, an algorithm must make a
prediction about an outcome on each of $T$ days (or times), given a set of $n$
experts who make predictions on each day (or time). The algorithm is given
feedback on the outcomes of each day, including the cost of its prediction and
the cost of the expert predictions, and the goal is to make a prediction with
the minimum cost, specifically compared to the best expert in the set. Recent
work by Srinivas, Woodruff, Xu, and Zhou (STOC 2022) introduced the study of
the online learning with experts problem under memory constraints.
</p>
<p>However, often the predictions made by experts or algorithms at some time
influence future outcomes, so that the input is adaptively chosen. Whereas
deterministic algorithms would be robust to adaptive inputs, existing
algorithms all crucially use randomization to sample a small number of experts.
</p>
<p>In this paper, we study deterministic and robust algorithms for the experts
problem. We first show a space lower bound of
$\widetilde{\Omega}\left(\frac{nM}{RT}\right)$ for any deterministic algorithm
that achieves regret $R$ when the best expert makes $M$ mistakes. Our result
shows that the natural deterministic algorithm, which iterates through pools of
experts until each expert in the pool has erred, is optimal up to
polylogarithmic factors. On the positive side, we give a randomized algorithm
that is robust to adaptive inputs that uses
$\widetilde{O}\left(\frac{n}{R\sqrt{T}}\right)$ space for $M=O\left(\frac{R^2
T}{\log^2 n}\right)$, thereby showing a smooth space-regret trade-off.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-06T01:30:00Z">Monday, March 06 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
