<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-03-24T01:00:16Z">Friday, March 24 2023, 01:00</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, March 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.13256'>Analyzing Innermost Runtime Complexity Through Tuple Interpretations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Liye Guo (Radboud University), Deivid Vale (Radboud University)</p><p>Time complexity in rewriting is naturally understood as the number of steps
needed to reduce terms to normal forms. Establishing complexity bounds to this
measure is a well-known problem in the rewriting community. A vast majority of
techniques to find such bounds consist of modifying termination proofs in order
to recover complexity information. This has been done for instance with
semantic interpretations, recursive path orders, and dependency pairs. In this
paper, we follow the same program by tailoring tuple interpretations to deal
with innermost complexity analysis. A tuple interpretation interprets terms as
tuples holding upper bounds to the cost of reduction and size of normal forms.
In contrast with the full rewriting setting, the strongly monotonic requirement
for cost components is dropped when reductions are innermost. This weakened
requirement on cost tuples allows us to prove the innermost version of the
compatibility result: if all rules in a term rewriting system can be strictly
oriented, then the innermost rewrite relation is well-founded. We establish the
necessary conditions for which tuple interpretations guarantee polynomial
bounds to the runtime of compatible systems and describe a search procedure for
such interpretations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Liye Guo</a> (Radboud University), <a href="http://arxiv.org/find/cs/1/au:+Vale_D/0/1/0/all/0/1">Deivid Vale</a> (Radboud University)</p><p>Time complexity in rewriting is naturally understood as the number of steps
needed to reduce terms to normal forms. Establishing complexity bounds to this
measure is a well-known problem in the rewriting community. A vast majority of
techniques to find such bounds consist of modifying termination proofs in order
to recover complexity information. This has been done for instance with
semantic interpretations, recursive path orders, and dependency pairs. In this
paper, we follow the same program by tailoring tuple interpretations to deal
with innermost complexity analysis. A tuple interpretation interprets terms as
tuples holding upper bounds to the cost of reduction and size of normal forms.
In contrast with the full rewriting setting, the strongly monotonic requirement
for cost components is dropped when reductions are innermost. This weakened
requirement on cost tuples allows us to prove the innermost version of the
compatibility result: if all rules in a term rewriting system can be strictly
oriented, then the innermost rewrite relation is well-founded. We establish the
necessary conditions for which tuple interpretations guarantee polynomial
bounds to the runtime of compatible systems and describe a search procedure for
such interpretations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-24T00:30:00Z">Friday, March 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.13395'>Dual-Quaternion Interpolation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benjamin Kenwright</p><p>Transformations in the field of computer graphics and geometry are one of the
most important concepts for efficient manipulation and control of objects in
2-dimensional and 3-dimensional space. Transformations take many forms each
with their advantages and disadvantages. A particularly powerful tool for
representing transforms in a unified form are dual-quaternions. A benefit of
this unified form is the interpolation properties, which address a range of
limitations (compact form that allows a rotational and translational components
to be coupled). In this article, we examine various dual-quaternion
interpolation options that achieve different trade-offs between computational
cost, aesthetic factors and coupling dependency. Surprisingly, despite
dual-quaternions being a common tool in graphics libraries, there are limited
details on the interpolation details. Here we attempt to explain interpolation
concept, elaborating on underpinning theories, while explaining concepts and
bespoke modifications for added control.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kenwright_B/0/1/0/all/0/1">Benjamin Kenwright</a></p><p>Transformations in the field of computer graphics and geometry are one of the
most important concepts for efficient manipulation and control of objects in
2-dimensional and 3-dimensional space. Transformations take many forms each
with their advantages and disadvantages. A particularly powerful tool for
representing transforms in a unified form are dual-quaternions. A benefit of
this unified form is the interpolation properties, which address a range of
limitations (compact form that allows a rotational and translational components
to be coupled). In this article, we examine various dual-quaternion
interpolation options that achieve different trade-offs between computational
cost, aesthetic factors and coupling dependency. Surprisingly, despite
dual-quaternions being a common tool in graphics libraries, there are limited
details on the interpolation details. Here we attempt to explain interpolation
concept, elaborating on underpinning theories, while explaining concepts and
bespoke modifications for added control.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-24T00:30:00Z">Friday, March 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.13486'>The strength of a simplex is the key to a continuous isometry classification of Euclidean clouds of unlabelled points</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vitaliy Kurlin</p><p>This paper solves the continuous classification problem for finite clouds of
unlabelled points under Euclidean isometry. The Lipschitz continuity of
required invariants in a suitable metric under perturbations of points is
motivated by the inevitable noise in measurements of real objects.
</p>
<p>The best solved case of this isometry classification is known as the SSS
theorem in school geometry saying that any triangle up to congruence (isometry
in the plane) has a continuous complete invariant of three side lengths.
</p>
<p>However, there is no easy extension of the SSS theorem even to four points in
the plane partially due to a 4-parameter family of 4-point clouds that have the
same six pairwise distances. The computational time of most past metrics that
are invariant under isometry was exponential in the size of the input. The
final obstacle was the discontinuity of previous invariants at singular
configurations, for example, when a triangle degenerates to a straight line.
</p>
<p>All the challenges above are now resolved by the Simplexwise Centred
Distributions that combine inter-point distances of a given cloud with the new
strength of a simplex that finally guarantees the Lipschitz continuity. The
computational times of new invariants and metrics are polynomial in the number
of points for a fixed Euclidean dimension.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Kurlin_V/0/1/0/all/0/1">Vitaliy Kurlin</a></p><p>This paper solves the continuous classification problem for finite clouds of
unlabelled points under Euclidean isometry. The Lipschitz continuity of
required invariants in a suitable metric under perturbations of points is
motivated by the inevitable noise in measurements of real objects.
</p>
<p>The best solved case of this isometry classification is known as the SSS
theorem in school geometry saying that any triangle up to congruence (isometry
in the plane) has a continuous complete invariant of three side lengths.
</p>
<p>However, there is no easy extension of the SSS theorem even to four points in
the plane partially due to a 4-parameter family of 4-point clouds that have the
same six pairwise distances. The computational time of most past metrics that
are invariant under isometry was exponential in the size of the input. The
final obstacle was the discontinuity of previous invariants at singular
configurations, for example, when a triangle degenerates to a straight line.
</p>
<p>All the challenges above are now resolved by the Simplexwise Centred
Distributions that combine inter-point distances of a given cloud with the new
strength of a simplex that finally guarantees the Lipschitz continuity. The
computational times of new invariants and metrics are polynomial in the number
of points for a fixed Euclidean dimension.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-24T00:30:00Z">Friday, March 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.13279'>Parameterized Algorithms for Topological Indices in Chemistry</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Giovanna K. Conrado, Amir K. Goharshady, Harshit J. Motwani, Sergei Novozhilov</p><p>We have developed efficient parameterized algorithms for the enumeration
problems of graphs arising in chemistry. In particular, we have focused on the
following problems: enumeration of Kekul\'e structures, computation of Hosoya
index, computation of Merrifield-Simmons index, and computation of graph
entropy based on matchings and independent sets. All these problems are known
to be $\# P$-complete. We have developed FPT algorithms for bounded treewidth
and bounded pathwidth for these problems with a better time complexity than the
known state-of-the-art in the literature. We have also conducted experiments on
the entire PubChem database of chemical compounds and tested our algorithms. We
also provide a comparison with naive baseline algorithms for these problems,
along with a distribution of treewidth for the chemical compounds available in
the PubChem database.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Conrado_G/0/1/0/all/0/1">Giovanna K. Conrado</a>, <a href="http://arxiv.org/find/cs/1/au:+Goharshady_A/0/1/0/all/0/1">Amir K. Goharshady</a>, <a href="http://arxiv.org/find/cs/1/au:+Motwani_H/0/1/0/all/0/1">Harshit J. Motwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Novozhilov_S/0/1/0/all/0/1">Sergei Novozhilov</a></p><p>We have developed efficient parameterized algorithms for the enumeration
problems of graphs arising in chemistry. In particular, we have focused on the
following problems: enumeration of Kekul\'e structures, computation of Hosoya
index, computation of Merrifield-Simmons index, and computation of graph
entropy based on matchings and independent sets. All these problems are known
to be $\# P$-complete. We have developed FPT algorithms for bounded treewidth
and bounded pathwidth for these problems with a better time complexity than the
known state-of-the-art in the literature. We have also conducted experiments on
the entire PubChem database of chemical compounds and tested our algorithms. We
also provide a comparison with naive baseline algorithms for these problems,
along with a distribution of treewidth for the chemical compounds available in
the PubChem database.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-24T00:30:00Z">Friday, March 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.12850'>Polyhedral Aspects of Feedback Vertex Set and Pseudoforest Deletion Set</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Karthekeyan Chandrasekaran, Chandra Chekuri, Samuel Fiorini, Shubhang Kulkarni, Stefan Weltge</p><p>We consider the feedback vertex set problem in undirected graphs (FVS). The
input to FVS is an undirected graph $G=(V,E)$ with non-negative vertex costs.
The goal is to find a least cost subset of vertices $S \subseteq V$ such that
$G-S$ is acyclic. FVS is a well-known NP-hard problem with no
$(2-\epsilon)$-approximation assuming the Unique Games Conjecture and it admits
a $2$-approximation via combinatorial local-ratio methods (Bafna, Berman and
Fujito, Algorithms and Computations '95; Becker and Geiger, Artificial
Intelligence '96) which can also be interpreted as LP-based primal-dual
algorithms (Chudak, Goemans, Hochbaum and Williamson, Operations Research
Letters '98). Despite the existence of these algorithms for several decades,
there is no known polynomial-time solvable LP relaxation for FVS with a
provable integrality gap of at most $2$. More recent work (Chekuri and Madan
SODA '16) developed a polynomial-sized LP relaxation for a more general
problem, namely Subset FVS, and showed that its integrality gap is at most $13$
for Subset FVS, and hence also for FVS.
</p>
<p>Motivated by this gap in our knowledge, we undertake a polyhedral study of
FVS and related problems. In this work, we formulate new integer linear
programs (ILPs) for FVS whose LP-relaxation can be solved in polynomial time,
and whose integrality gap is at most $2$. The new insights in this process also
enable us to prove that the formulation in (Chekuri and Madan, SODA '16) has an
integrality gap of at most $2$ for FVS. Our results for FVS are inspired by new
formulations and polyhedral results for the closely-related pseudoforest
deletion set problem (PFDS). Our formulations for PFDS are in turn inspired by
a connection to the densest subgraph problem. We also conjecture an extreme
point property for a LP-relaxation for FVS, and give evidence for the
conjecture via a corresponding result for PFDS.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chandrasekaran_K/0/1/0/all/0/1">Karthekeyan Chandrasekaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Chekuri_C/0/1/0/all/0/1">Chandra Chekuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fiorini_S/0/1/0/all/0/1">Samuel Fiorini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1">Shubhang Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Weltge_S/0/1/0/all/0/1">Stefan Weltge</a></p><p>We consider the feedback vertex set problem in undirected graphs (FVS). The
input to FVS is an undirected graph $G=(V,E)$ with non-negative vertex costs.
The goal is to find a least cost subset of vertices $S \subseteq V$ such that
$G-S$ is acyclic. FVS is a well-known NP-hard problem with no
$(2-\epsilon)$-approximation assuming the Unique Games Conjecture and it admits
a $2$-approximation via combinatorial local-ratio methods (Bafna, Berman and
Fujito, Algorithms and Computations '95; Becker and Geiger, Artificial
Intelligence '96) which can also be interpreted as LP-based primal-dual
algorithms (Chudak, Goemans, Hochbaum and Williamson, Operations Research
Letters '98). Despite the existence of these algorithms for several decades,
there is no known polynomial-time solvable LP relaxation for FVS with a
provable integrality gap of at most $2$. More recent work (Chekuri and Madan
SODA '16) developed a polynomial-sized LP relaxation for a more general
problem, namely Subset FVS, and showed that its integrality gap is at most $13$
for Subset FVS, and hence also for FVS.
</p>
<p>Motivated by this gap in our knowledge, we undertake a polyhedral study of
FVS and related problems. In this work, we formulate new integer linear
programs (ILPs) for FVS whose LP-relaxation can be solved in polynomial time,
and whose integrality gap is at most $2$. The new insights in this process also
enable us to prove that the formulation in (Chekuri and Madan, SODA '16) has an
integrality gap of at most $2$ for FVS. Our results for FVS are inspired by new
formulations and polyhedral results for the closely-related pseudoforest
deletion set problem (PFDS). Our formulations for PFDS are in turn inspired by
a connection to the densest subgraph problem. We also conjecture an extreme
point property for a LP-relaxation for FVS, and give evidence for the
conjecture via a corresponding result for PFDS.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-24T00:30:00Z">Friday, March 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.12921'>Stability is Stable: Connections between Replicability, Privacy, and Adaptive Generalization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mark Bun, Marco Gaboardi, Max Hopkins, Russell Impagliazzo, Rex Lei, Toniann Pitassi, Jessica Sorrell, Satchit Sivakumar</p><p>The notion of replicable algorithms was introduced in Impagliazzo et al.
[STOC '22] to describe randomized algorithms that are stable under the
resampling of their inputs. More precisely, a replicable algorithm gives the
same output with high probability when its randomness is fixed and it is run on
a new i.i.d. sample drawn from the same distribution. Using replicable
algorithms for data analysis can facilitate the verification of published
results by ensuring that the results of an analysis will be the same with high
probability, even when that analysis is performed on a new data set.
</p>
<p>In this work, we establish new connections and separations between
replicability and standard notions of algorithmic stability. In particular, we
give sample-efficient algorithmic reductions between perfect generalization,
approximate differential privacy, and replicability for a broad class of
statistical problems. Conversely, we show any such equivalence must break down
computationally: there exist statistical problems that are easy under
differential privacy, but that cannot be solved replicably without breaking
public-key cryptography. Furthermore, these results are tight: our reductions
are statistically optimal, and we show that any computational separation
between DP and replicability must imply the existence of one-way functions.
</p>
<p>Our statistical reductions give a new algorithmic framework for translating
between notions of stability, which we instantiate to answer several open
questions in replicability and privacy. This includes giving sample-efficient
replicable algorithms for various PAC learning, distribution estimation, and
distribution testing problems, algorithmic amplification of $\delta$ in
approximate DP, conversions from item-level to user-level privacy, and the
existence of private agnostic-to-realizable learning reductions under
structured distributions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bun_M/0/1/0/all/0/1">Mark Bun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaboardi_M/0/1/0/all/0/1">Marco Gaboardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hopkins_M/0/1/0/all/0/1">Max Hopkins</a>, <a href="http://arxiv.org/find/cs/1/au:+Impagliazzo_R/0/1/0/all/0/1">Russell Impagliazzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_R/0/1/0/all/0/1">Rex Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Pitassi_T/0/1/0/all/0/1">Toniann Pitassi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorrell_J/0/1/0/all/0/1">Jessica Sorrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivakumar_S/0/1/0/all/0/1">Satchit Sivakumar</a></p><p>The notion of replicable algorithms was introduced in Impagliazzo et al.
[STOC '22] to describe randomized algorithms that are stable under the
resampling of their inputs. More precisely, a replicable algorithm gives the
same output with high probability when its randomness is fixed and it is run on
a new i.i.d. sample drawn from the same distribution. Using replicable
algorithms for data analysis can facilitate the verification of published
results by ensuring that the results of an analysis will be the same with high
probability, even when that analysis is performed on a new data set.
</p>
<p>In this work, we establish new connections and separations between
replicability and standard notions of algorithmic stability. In particular, we
give sample-efficient algorithmic reductions between perfect generalization,
approximate differential privacy, and replicability for a broad class of
statistical problems. Conversely, we show any such equivalence must break down
computationally: there exist statistical problems that are easy under
differential privacy, but that cannot be solved replicably without breaking
public-key cryptography. Furthermore, these results are tight: our reductions
are statistically optimal, and we show that any computational separation
between DP and replicability must imply the existence of one-way functions.
</p>
<p>Our statistical reductions give a new algorithmic framework for translating
between notions of stability, which we instantiate to answer several open
questions in replicability and privacy. This includes giving sample-efficient
replicable algorithms for various PAC learning, distribution estimation, and
distribution testing problems, algorithmic amplification of $\delta$ in
approximate DP, conversions from item-level to user-level privacy, and the
existence of private agnostic-to-realizable learning reductions under
structured distributions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-24T00:30:00Z">Friday, March 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, March 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/031'>TR23-031 |  The Round Complexity of Statistical MPC with Optimal Resiliency | 

	Benny Applebaum, 

	Eliran Kachlon, 

	Arpita Patra</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In STOC 1989, Rabin and Ben-Or (RB) established an important milestone in the fields of cryptography and distributed computing by showing that every functionality can be computed with statistical (information-theoretic) security in the presence of an active (aka Byzantine) rushing adversary that controls up to half of the parties. We study the round complexity of general secure multiparty computation and several related tasks in the RB model. 

Our main result shows that every functionality can be realized in only four rounds of interaction which is known to be optimal. This completely settles the round complexity of statistical actively-secure optimally-resilient MPC, resolving a long line of research.

Along the way, we construct the first round-optimal statistically-secure verifiable secret sharing protocol (Chor, Goldwasser, Micali, and Awerbuch; STOC 1985), show that every single-input functionality (e.g., multi-verifier zero-knowledge) can be realized in 3 rounds, and prove that the latter bound is optimal. The complexity of all our protocols is exponential in the number of parties, and the question of deriving polynomially-efficient protocols is left for future research.

Our main technical contribution is a construction of a new type of statistically-secure signature scheme whose existence was open even for smaller resiliency thresholds. We also describe a new statistical compiler that lifts up passively-secure protocols to actively-secure protocols in a round-efficient way via the aid of protocols for single-input functionalities. This compiler can be viewed as a statistical variant of the GMW compiler (Goldreich, Micali, Wigderson; STOC, 1987) that originally employed zero-knowledge proofs and public-key encryption.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In STOC 1989, Rabin and Ben-Or (RB) established an important milestone in the fields of cryptography and distributed computing by showing that every functionality can be computed with statistical (information-theoretic) security in the presence of an active (aka Byzantine) rushing adversary that controls up to half of the parties. We study the round complexity of general secure multiparty computation and several related tasks in the RB model. 

Our main result shows that every functionality can be realized in only four rounds of interaction which is known to be optimal. This completely settles the round complexity of statistical actively-secure optimally-resilient MPC, resolving a long line of research.

Along the way, we construct the first round-optimal statistically-secure verifiable secret sharing protocol (Chor, Goldwasser, Micali, and Awerbuch; STOC 1985), show that every single-input functionality (e.g., multi-verifier zero-knowledge) can be realized in 3 rounds, and prove that the latter bound is optimal. The complexity of all our protocols is exponential in the number of parties, and the question of deriving polynomially-efficient protocols is left for future research.

Our main technical contribution is a construction of a new type of statistically-secure signature scheme whose existence was open even for smaller resiliency thresholds. We also describe a new statistical compiler that lifts up passively-secure protocols to actively-secure protocols in a round-efficient way via the aid of protocols for single-input functionalities. This compiler can be viewed as a statistical variant of the GMW compiler (Goldreich, Micali, Wigderson; STOC, 1987) that originally employed zero-knowledge proofs and public-key encryption.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-23T17:02:13Z">Thursday, March 23 2023, 17:02</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/03/a-strange-hiring-season.html'>A Strange Hiring Season</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>In my fall jobs post, I had trouble predicting this season's CS faculty job market but I didn't expect this:&nbsp; strong supply and strong demand, something we haven't seen since the early '80s when the then young CS departments were ramping up.</p><p>We have a confluence of two forces that have both strengthened since my post back in November: The layoffs and hiring freezes at the major internet companies (Alphabet, Amazon, Apple, Meta and Microsoft) contrasted with major excitement in machine learning. I wrote the jobs post before ChatGPT was released and Amazon and Meta have since announced even more layoffs.</p><p>ML-mania is leading to very strong demand from undergrad and grad students for computing degrees. Across the US we have a record number of open faculty slots in computing as universities try to meet that need.</p><p>Meanwhile, PhDs who might have gone to industry are going on the academic job market instead. Also some tech researchers who have been laid off or spooked by the layoffs are considering academic jobs.</p><p>Between these two forces we will likely have a record number of faculty hires this year but we may see fewer senior people switching universities because good departments can fill their needs with junior faculty.</p><p>There is a mismatch of area. There is a big demand in CS departments to hire in machine learning because that is where the student interest is. ML is not where the big companies are cutting back. If you are on the market this year, position your research to make it relevant to learning, or at least that you are willing to teach ML courses.</p><p>By the way, this post is for computer science. Count yourself extremely lucky if you can get a tenure-track job in a non-computing field.</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In my <a href="https://blog.computationalcomplexity.org/2022/11/fall-jobs-post-2022.html">fall jobs post</a>, I had trouble predicting this season's CS faculty job market but I didn't expect this:&nbsp; strong supply and strong demand, something we haven't seen since the early '80s when the then young CS departments were ramping up.</p><p>We have a confluence of two forces that have both strengthened since my post back in November: The layoffs and hiring freezes at the major internet companies (Alphabet, Amazon, Apple, Meta and Microsoft) contrasted with major excitement in machine learning. I wrote the jobs post before ChatGPT was released and Amazon and Meta have since announced even more layoffs.</p><p>ML-mania is leading to very strong demand from undergrad and grad students for computing degrees. Across the US we have a record number of open faculty slots in computing as universities try to meet that need.</p><p>Meanwhile, PhDs who might have gone to industry are going on the academic job market instead. Also some tech researchers who have been laid off or spooked by the layoffs are considering academic jobs.</p><p>Between these two forces we will likely have a record number of faculty hires this year but we may see fewer senior people switching universities because good departments can fill their needs with junior faculty.</p><p>There is a mismatch of area. There is a big demand in CS departments to hire in machine learning because that is where the student interest is. ML is not where the big companies are cutting back. If you are on the market this year, position your research to make it relevant to learning, or at least that you are willing to teach ML courses.</p><p>By the way, this post is for computer science. Count yourself extremely lucky if you can get a tenure-track job in a non-computing field.</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-23T13:58:00Z">Thursday, March 23 2023, 13:58</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-events.org/2023/03/23/dimacs-workshop-on-modern-techniques-in-graph-algorithms/'>DIMACS Workshop on Modern Techniques in Graph Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-events.org'>CS Theory Events</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          June 12-15, 2023 DIMACS, Rutgers University, Piscataway, NJ sites.google.com/view/dimacswmtga Registration deadline: June 4, 2023 The goal of this workshop is to bring together researchers from different areas of graph algorithms to share the techniques that have been recently influential in their area. The program will include a combination of tutorials, talks, open problem sessions, and &#8230; Continue reading DIMACS Workshop on Modern Techniques in Graph&#160;Algorithms<p>By shacharlovett</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          June 12-15, 2023 DIMACS, Rutgers University, Piscataway, NJ https://sites.google.com/view/dimacswmtga Registration deadline: June 4, 2023 The goal of this workshop is to bring together researchers from different areas of graph algorithms to share the techniques that have been recently influential in their area. The program will include a combination of tutorials, talks, open problem sessions, and &#8230; <a href="https://cstheory-events.org/2023/03/23/dimacs-workshop-on-modern-techniques-in-graph-algorithms/" class="more-link">Continue reading <span class="screen-reader-text">DIMACS Workshop on Modern Techniques in Graph&#160;Algorithms</span></a><p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-23T06:10:06Z">Thursday, March 23 2023, 06:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.12172'>Algorithmic Threshold for Multi-Species Spherical Spin Glasses</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Brice Huang, Mark Sellke</p><p>We study efficient optimization of the Hamiltonians of multi-species
spherical spin glasses. Our results characterize the maximum value attained by
algorithms that are suitably Lipschitz with respect to the disorder through a
variational principle that we study in detail. We rely on the branching overlap
gap property introduced in our previous work and develop a new method to
establish it that does not require the interpolation method. Consequently our
results apply even for models with non-convex covariance, where the Parisi
formula for the true ground state remains open. As a special case, we obtain
the algorithmic threshold for all single-species spherical spin glasses, which
was previously known only for even models. We also obtain closed-form formulas
for pure models which coincide with the $E_{\infty}$ value previously
determined by the Kac-Rice formula.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Huang_B/0/1/0/all/0/1">Brice Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Sellke_M/0/1/0/all/0/1">Mark Sellke</a></p><p>We study efficient optimization of the Hamiltonians of multi-species
spherical spin glasses. Our results characterize the maximum value attained by
algorithms that are suitably Lipschitz with respect to the disorder through a
variational principle that we study in detail. We rely on the branching overlap
gap property introduced in our previous work and develop a new method to
establish it that does not require the interpolation method. Consequently our
results apply even for models with non-convex covariance, where the Parisi
formula for the true ground state remains open. As a special case, we obtain
the algorithmic threshold for all single-species spherical spin glasses, which
was previously known only for even models. We also obtain closed-form formulas
for pure models which coincide with the $E_{\infty}$ value previously
determined by the Kac-Rice formula.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-23T00:30:00Z">Thursday, March 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.12277'>Stochastic Nonsmooth Convex Optimization with Heavy-Tailed Noises</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zijian Liu, Zhengyuan Zhou</p><p>Recently, several studies consider the stochastic optimization problem but in
a heavy-tailed noise regime, i.e., the difference between the stochastic
gradient and the true gradient is assumed to have a finite $p$-th moment (say
being upper bounded by $\sigma^{p}$ for some $\sigma\geq0$) where $p\in(1,2]$,
which not only generalizes the traditional finite variance assumption ($p=2$)
but also has been observed in practice for several different tasks. Under this
challenging assumption, lots of new progress has been made for either convex or
nonconvex problems, however, most of which only consider smooth objectives. In
contrast, people have not fully explored and well understood this problem when
functions are nonsmooth. This paper aims to fill this crucial gap by providing
a comprehensive analysis of stochastic nonsmooth convex optimization with
heavy-tailed noises. We revisit a simple clipping-based algorithm, whereas,
which is only proved to converge in expectation but under the additional strong
convexity assumption. Under appropriate choices of parameters, for both convex
and strongly convex functions, we not only establish the first high-probability
rates but also give refined in-expectation bounds compared with existing works.
Remarkably, all of our results are optimal (or nearly optimal up to logarithmic
factors) with respect to the time horizon $T$ even when $T$ is unknown in
advance. Additionally, we show how to make the algorithm parameter-free with
respect to $\sigma$, in other words, the algorithm can still guarantee
convergence without any prior knowledge of $\sigma$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Liu_Z/0/1/0/all/0/1">Zijian Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Zhou_Z/0/1/0/all/0/1">Zhengyuan Zhou</a></p><p>Recently, several studies consider the stochastic optimization problem but in
a heavy-tailed noise regime, i.e., the difference between the stochastic
gradient and the true gradient is assumed to have a finite $p$-th moment (say
being upper bounded by $\sigma^{p}$ for some $\sigma\geq0$) where $p\in(1,2]$,
which not only generalizes the traditional finite variance assumption ($p=2$)
but also has been observed in practice for several different tasks. Under this
challenging assumption, lots of new progress has been made for either convex or
nonconvex problems, however, most of which only consider smooth objectives. In
contrast, people have not fully explored and well understood this problem when
functions are nonsmooth. This paper aims to fill this crucial gap by providing
a comprehensive analysis of stochastic nonsmooth convex optimization with
heavy-tailed noises. We revisit a simple clipping-based algorithm, whereas,
which is only proved to converge in expectation but under the additional strong
convexity assumption. Under appropriate choices of parameters, for both convex
and strongly convex functions, we not only establish the first high-probability
rates but also give refined in-expectation bounds compared with existing works.
Remarkably, all of our results are optimal (or nearly optimal up to logarithmic
factors) with respect to the time horizon $T$ even when $T$ is unknown in
advance. Additionally, we show how to make the algorithm parameter-free with
respect to $\sigma$, in other words, the algorithm can still guarantee
convergence without any prior knowledge of $\sigma$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-23T00:30:00Z">Thursday, March 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.12298'>A General Algorithm for Solving Rank-one Matrix Sensing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lianke Qin, Zhao Song, Ruizhe Zhang</p><p>Matrix sensing has many real-world applications in science and engineering,
such as system control, distance embedding, and computer vision. The goal of
matrix sensing is to recover a matrix $A_\star \in \mathbb{R}^{n \times n}$,
based on a sequence of measurements $(u_i,b_i) \in \mathbb{R}^{n} \times
\mathbb{R}$ such that $u_i^\top A_\star u_i = b_i$. Previous work [ZJD15]
focused on the scenario where matrix $A_{\star}$ has a small rank, e.g.
rank-$k$. Their analysis heavily relies on the RIP assumption, making it
unclear how to generalize to high-rank matrices. In this paper, we relax that
rank-$k$ assumption and solve a much more general matrix sensing problem. Given
an accuracy parameter $\delta \in (0,1)$, we can compute $A \in \mathbb{R}^{n
\times n}$ in $\widetilde{O}(m^{3/2} n^2 \delta^{-1} )$, such that $ |u_i^\top
A u_i - b_i| \leq \delta$ for all $i \in [m]$. We design an efficient algorithm
with provable convergence guarantees using stochastic gradient descent for this
problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1">Lianke Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruizhe Zhang</a></p><p>Matrix sensing has many real-world applications in science and engineering,
such as system control, distance embedding, and computer vision. The goal of
matrix sensing is to recover a matrix $A_\star \in \mathbb{R}^{n \times n}$,
based on a sequence of measurements $(u_i,b_i) \in \mathbb{R}^{n} \times
\mathbb{R}$ such that $u_i^\top A_\star u_i = b_i$. Previous work [ZJD15]
focused on the scenario where matrix $A_{\star}$ has a small rank, e.g.
rank-$k$. Their analysis heavily relies on the RIP assumption, making it
unclear how to generalize to high-rank matrices. In this paper, we relax that
rank-$k$ assumption and solve a much more general matrix sensing problem. Given
an accuracy parameter $\delta \in (0,1)$, we can compute $A \in \mathbb{R}^{n
\times n}$ in $\widetilde{O}(m^{3/2} n^2 \delta^{-1} )$, such that $ |u_i^\top
A u_i - b_i| \leq \delta$ for all $i \in [m]$. We design an efficient algorithm
with provable convergence guarantees using stochastic gradient descent for this
problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-23T00:30:00Z">Thursday, March 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.12325'>Critical Relaxed Stable Matchings with Two-Sided Ties</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Meghana Nasre, Prajakta Nimbhorkar, Keshav Ranjan</p><p>We consider the stable marriage problem in the presence of ties in
preferences and critical vertices. The input to our problem is a bipartite
graph G = (A U B, E) where A and B denote sets of vertices which need to be
matched. Each vertex has a preference ordering over its neighbours possibly
containing ties. In addition, a subset of vertices in A U B are marked as
critical and the goal is to output a matching that matches as many critical
vertices as possible. Such matchings are called critical matchings in the
literature and in our setting, we seek to compute a matching that is critical
as well as optimal with respect to the preferences of the vertices.
</p>
<p>Stability, which is a well-accepted notion of optimality in the presence of
two-sided preferences, is generalized to weak-stability in the presence of
ties. It is well known that in the presence of critical vertices, a matching
that is critical as well as weakly stable may not exist. Popularity is another
well-investigated notion of optimality for the two-sided preference list
setting, however, in the presence of ties (even with no critical vertices), a
popular matching need not exist. We, therefore, consider the notion of relaxed
stability which was introduced and studied by Krishnaa et. al. (SAGT 2020). We
show that a critical matching which is relaxed stable always exists in our
setting although computing a maximum-sized relaxed stable matching turns out to
be NP-hard. Our main contribution is a 3/2 approximation to the maximum-sized
critical relaxed stable matching for the stable marriage problem with two-sided
ties and critical vertices.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nasre_M/0/1/0/all/0/1">Meghana Nasre</a>, <a href="http://arxiv.org/find/cs/1/au:+Nimbhorkar_P/0/1/0/all/0/1">Prajakta Nimbhorkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranjan_K/0/1/0/all/0/1">Keshav Ranjan</a></p><p>We consider the stable marriage problem in the presence of ties in
preferences and critical vertices. The input to our problem is a bipartite
graph G = (A U B, E) where A and B denote sets of vertices which need to be
matched. Each vertex has a preference ordering over its neighbours possibly
containing ties. In addition, a subset of vertices in A U B are marked as
critical and the goal is to output a matching that matches as many critical
vertices as possible. Such matchings are called critical matchings in the
literature and in our setting, we seek to compute a matching that is critical
as well as optimal with respect to the preferences of the vertices.
</p>
<p>Stability, which is a well-accepted notion of optimality in the presence of
two-sided preferences, is generalized to weak-stability in the presence of
ties. It is well known that in the presence of critical vertices, a matching
that is critical as well as weakly stable may not exist. Popularity is another
well-investigated notion of optimality for the two-sided preference list
setting, however, in the presence of ties (even with no critical vertices), a
popular matching need not exist. We, therefore, consider the notion of relaxed
stability which was introduced and studied by Krishnaa et. al. (SAGT 2020). We
show that a critical matching which is relaxed stable always exists in our
setting although computing a maximum-sized relaxed stable matching turns out to
be NP-hard. Our main contribution is a 3/2 approximation to the maximum-sized
critical relaxed stable matching for the stable marriage problem with two-sided
ties and critical vertices.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-23T00:30:00Z">Thursday, March 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.12506'>Leximin Approximation: From Single-Objective to Multi-Objective</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eden Hartman, Avinatan Hassidim, Yonatan Aumann, Erel Segal-Halevi</p><p>Leximin is a common approach to multi-objective optimization, frequently
employed in fair division applications. In leximin optimization, one first aims
to maximize the smallest objective value; subject to this, one maximizes the
second-smallest objective; and so on. Often, even the single-objective problem
of maximizing the smallest value cannot be solved accurately, e.g. due to
computational hardness. What can we hope to accomplish for leximin optimization
in this situation? Recently, Henzinger et al (2022) defined a notion of
approximate leximin optimality, and showed how it can be computed for the
problem of representative cohort selection. However, their definition considers
only an additive approximation in the single-objective problem.
</p>
<p>In this work, we define approximate leximin optimality allowing
approximations that have multiplicative and additive errors. We show how to
compute a solution that approximates leximin in polynomial time, using an
oracle that finds an approximation to the single-objective problem. The
approximation factors of the algorithms are closely related: a factor of
$(\alpha,\epsilon)$ for the single-objective problem translates into a factor
of $\left(\frac{\alpha^2}{1-\alpha + \alpha^2},
\frac{\alpha(2-\alpha)\epsilon}{1-\alpha +\alpha^2}\right)$ for the
multi-objective leximin problem, regardless of the number of objectives.
</p>
<p>As a usage example, we apply our algorithm to the problem of stochastic
allocations of indivisible goods. For this problem, assuming sub-modular
objectives functions, the single-objective egalitarian welfare can be
approximated, with only a multiplicative error, to an optimal
$1-\frac{1}{e}\approx 0.632$ factor w.h.p. We show how to extend the
approximation to leximin, over all the objective functions, to a multiplicative
factor of $\frac{(e-1)^2}{e^2-e+1}\approx 0.52$ w.h.p or $\frac{1}{3}$
deterministically.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hartman_E/0/1/0/all/0/1">Eden Hartman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassidim_A/0/1/0/all/0/1">Avinatan Hassidim</a>, <a href="http://arxiv.org/find/cs/1/au:+Aumann_Y/0/1/0/all/0/1">Yonatan Aumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Segal_Halevi_E/0/1/0/all/0/1">Erel Segal-Halevi</a></p><p>Leximin is a common approach to multi-objective optimization, frequently
employed in fair division applications. In leximin optimization, one first aims
to maximize the smallest objective value; subject to this, one maximizes the
second-smallest objective; and so on. Often, even the single-objective problem
of maximizing the smallest value cannot be solved accurately, e.g. due to
computational hardness. What can we hope to accomplish for leximin optimization
in this situation? Recently, Henzinger et al (2022) defined a notion of
approximate leximin optimality, and showed how it can be computed for the
problem of representative cohort selection. However, their definition considers
only an additive approximation in the single-objective problem.
</p>
<p>In this work, we define approximate leximin optimality allowing
approximations that have multiplicative and additive errors. We show how to
compute a solution that approximates leximin in polynomial time, using an
oracle that finds an approximation to the single-objective problem. The
approximation factors of the algorithms are closely related: a factor of
$(\alpha,\epsilon)$ for the single-objective problem translates into a factor
of $\left(\frac{\alpha^2}{1-\alpha + \alpha^2},
\frac{\alpha(2-\alpha)\epsilon}{1-\alpha +\alpha^2}\right)$ for the
multi-objective leximin problem, regardless of the number of objectives.
</p>
<p>As a usage example, we apply our algorithm to the problem of stochastic
allocations of indivisible goods. For this problem, assuming sub-modular
objectives functions, the single-objective egalitarian welfare can be
approximated, with only a multiplicative error, to an optimal
$1-\frac{1}{e}\approx 0.632$ factor w.h.p. We show how to extend the
approximation to leximin, over all the objective functions, to a multiplicative
factor of $\frac{(e-1)^2}{e^2-e+1}\approx 0.52$ w.h.p or $\frac{1}{3}$
deterministically.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-23T00:30:00Z">Thursday, March 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.12560'>Degree Sequence Optimization in Bounded Treewidth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shmuel Onn</p><p>We consider the problem of finding a subgraph of a given graph which
minimizes the sum of given functions at vertices evaluated at their subgraph
degrees. While the problem is NP-hard already when all functions are the same,
we show that it can be solved for arbitrary functions in polynomial time over
graphs of bounded treewidth. Its complexity remains widely open, in particular
over complete graphs and complete bipartite graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Onn_S/0/1/0/all/0/1">Shmuel Onn</a></p><p>We consider the problem of finding a subgraph of a given graph which
minimizes the sum of given functions at vertices evaluated at their subgraph
degrees. While the problem is NP-hard already when all functions are the same,
we show that it can be solved for arbitrary functions in polynomial time over
graphs of bounded treewidth. Its complexity remains widely open, in particular
over complete graphs and complete bipartite graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-23T00:30:00Z">Thursday, March 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.12768'>Almost-Optimal Sublinear Additive Spanners</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zihan Tan, Tianyi Zhang</p><p>Given an undirected unweighted graph $G = (V, E)$ on $n$ vertices and $m$
edges, a subgraph $H\subseteq G$ is a spanner of $G$ with stretch function $f:
\mathbb{R}_+ \rightarrow \mathbb{R}_+$, iff for every pair $s, t$ of vertices
in $V$, $\textsf{dist}_{H}(s, t)\le f(\textsf{dist}_{G}(s, t))$. When $f(d) = d
+ o(d)$, $H$ is called a sublinear additive spanner; when $f(d) = d + o(n)$,
$H$ is called an additive spanner, and $f(d) - d$ is usually called the
additive stretch of $H$.
</p>
<p>As our primary result, we show that for any constant $\delta&gt;0$ and constant
integer $k\geq 2$, every graph on $n$ vertices has a sublinear additive spanner
with stretch function $f(d)=d+O(d^{1-1/k})$ and
$O\big(n^{1+\frac{1+\delta}{2^{k+1}-1}}\big)$ edges. When $k = 2$, this
improves upon the previous spanner construction with stretch function $f(d) = d
+ O(d^{1/2})$ and $\tilde{O}(n^{1+3/17})$ edges [Chechik, 2013]; for any
constant integer $k\geq 3$, this improves upon the previous spanner
construction with stretch function $f(d) = d + O(d^{1-1/k})$ and
$O\bigg(n^{1+\frac{(3/4)^{k-2}}{7 - 2\cdot (3/4)^{k-2}}}\bigg)$ edges [Pettie,
2009]. Most importantly, the size of our spanners almost matches the lower
bound of $\Omega\big(n^{1+\frac{1}{2^{k+1}-1}}\big)$ [Abboud, Bodwin, Pettie,
2017].
</p>
<p>As our second result, we show a new construction of additive spanners with
stretch $O(n^{0.403})$ and $O(n)$ edges, which slightly improves upon the
previous stretch bound of $O(n^{3/7+\epsilon})$ achieved by linear-size
spanners [Bodwin and Vassilevska Williams, 2016]. An additional advantage of
our spanner is that it admits a subquadratic construction runtime of
$\tilde{O}(m + n^{13/7})$, while the previous construction in [Bodwin and
Vassilevska Williams, 2016] requires all-pairs shortest paths computation which
takes $O(\min\{mn, n^{2.373}\})$ time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zihan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianyi Zhang</a></p><p>Given an undirected unweighted graph $G = (V, E)$ on $n$ vertices and $m$
edges, a subgraph $H\subseteq G$ is a spanner of $G$ with stretch function $f:
\mathbb{R}_+ \rightarrow \mathbb{R}_+$, iff for every pair $s, t$ of vertices
in $V$, $\textsf{dist}_{H}(s, t)\le f(\textsf{dist}_{G}(s, t))$. When $f(d) = d
+ o(d)$, $H$ is called a sublinear additive spanner; when $f(d) = d + o(n)$,
$H$ is called an additive spanner, and $f(d) - d$ is usually called the
additive stretch of $H$.
</p>
<p>As our primary result, we show that for any constant $\delta&gt;0$ and constant
integer $k\geq 2$, every graph on $n$ vertices has a sublinear additive spanner
with stretch function $f(d)=d+O(d^{1-1/k})$ and
$O\big(n^{1+\frac{1+\delta}{2^{k+1}-1}}\big)$ edges. When $k = 2$, this
improves upon the previous spanner construction with stretch function $f(d) = d
+ O(d^{1/2})$ and $\tilde{O}(n^{1+3/17})$ edges [Chechik, 2013]; for any
constant integer $k\geq 3$, this improves upon the previous spanner
construction with stretch function $f(d) = d + O(d^{1-1/k})$ and
$O\bigg(n^{1+\frac{(3/4)^{k-2}}{7 - 2\cdot (3/4)^{k-2}}}\bigg)$ edges [Pettie,
2009]. Most importantly, the size of our spanners almost matches the lower
bound of $\Omega\big(n^{1+\frac{1}{2^{k+1}-1}}\big)$ [Abboud, Bodwin, Pettie,
2017].
</p>
<p>As our second result, we show a new construction of additive spanners with
stretch $O(n^{0.403})$ and $O(n)$ edges, which slightly improves upon the
previous stretch bound of $O(n^{3/7+\epsilon})$ achieved by linear-size
spanners [Bodwin and Vassilevska Williams, 2016]. An additional advantage of
our spanner is that it admits a subquadratic construction runtime of
$\tilde{O}(m + n^{13/7})$, while the previous construction in [Bodwin and
Vassilevska Williams, 2016] requires all-pairs shortest paths computation which
takes $O(\min\{mn, n^{2.373}\})$ time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-23T00:30:00Z">Thursday, March 23 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, March 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/03/22/tenure-track-at-toulouse-mathematics-institute-apply-by-may-19-2023/'>tenure track at Toulouse Mathematics Institute (apply by May 19, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Toulouse Institute of Mathematics is hiring a top-level researcher specializing in the mathematical aspects of complexity theory. The fixed-term contract of 3 years as an associate professor will open the way to tenure as a full professor at Paul Sabatier University (Toulouse 3). Website: www.math.univ-toulouse.fr/fr/institut/actualites/4bc613f1-bcd7-4d85-8005-9eb18a827a0e/ Email: direction.imt@math.univ-toulouse.fr
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Toulouse Institute of Mathematics is hiring a top-level researcher specializing in the mathematical aspects of complexity theory. The fixed-term contract of 3 years as an associate professor will open the way to tenure as a full professor at Paul Sabatier University (Toulouse 3).</p>
<p>Website: <a href="https://www.math.univ-toulouse.fr/fr/institut/actualites/4bc613f1-bcd7-4d85-8005-9eb18a827a0e/">https://www.math.univ-toulouse.fr/fr/institut/actualites/4bc613f1-bcd7-4d85-8005-9eb18a827a0e/</a><br />
Email: direction.imt@math.univ-toulouse.fr</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-22T17:25:01Z">Wednesday, March 22 2023, 17:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7143'>Of course Grover&#8217;s algorithm offers a quantum advantage!</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Unrelated Update: Huge congratulations to Ethernet inventor Bob Metcalfe, for winning UT Austin&#8217;s third Turing Award after Dijkstra and Emerson! I was really, really hoping that I&#8217;d be able to avoid blogging about this new arXiv preprint, by E. M. Stoudenmire and Xavier Waintal: Grover&#8217;s Algorithm Offers No Quantum Advantage Grover&#8217;s algorithm is one of [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Unrelated Update:</mark></strong> Huge congratulations to Ethernet inventor Bob Metcalfe, for <a href="https://www.nytimes.com/2023/03/22/technology/turing-award-bob-metcalfe-ethernet.html">winning UT Austin&#8217;s third Turing Award</a> after Dijkstra and Emerson!</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>I was really, <em>really</em> hoping that I&#8217;d be able to avoid blogging about <a href="https://arxiv.org/abs/2303.11317">this new arXiv preprint</a>, by E. M. Stoudenmire and Xavier Waintal:</p>



<blockquote class="wp-block-quote">
<p><strong>Grover&#8217;s Algorithm Offers No Quantum Advantage</strong></p>



<p>Grover&#8217;s algorithm is one of the primary algorithms offered as evidence that quantum computers can provide an advantage over classical computers. It involves an &#8220;oracle&#8221; (external quantum subroutine) which must be specified for a given application and whose internal structure is not part of the formal scaling of the quantum speedup guaranteed by the algorithm. Grover&#8217;s algorithm also requires exponentially many steps to succeed, raising the question of its implementation on near-term, non-error-corrected hardware and indeed even on error-corrected quantum computers. In this work, we construct a quantum inspired algorithm, executable on a classical computer, that performs Grover&#8217;s task in a linear number of call to the oracle &#8211; an exponentially smaller number than Grover&#8217;s algorithm &#8211; and demonstrate this algorithm explicitly for boolean satisfiability problems (3-SAT). Our finding implies that there is no a priori theoretical quantum speedup associated with Grover&#8217;s algorithm. We critically examine the possibility of a practical speedup, a possibility that depends on the nature of the quantum circuit associated with the oracle. We argue that the unfavorable scaling of the success probability of Grover&#8217;s algorithm, which in the presence of noise decays as the exponential of the exponential of the number of qubits, makes a practical speedup unrealistic even under extremely optimistic assumptions on both hardware quality and availability.</p>
</blockquote>



<p>Alas, inquiries from journalists soon made it clear that silence on my part wasn&#8217;t an option.</p>



<p>So, desperately seeking an escape, this morning I asked GPT-4 to read the preprint and comment on it just like I would.  Sadly, it turns out the technology isn&#8217;t quite ready to replace me at this blogging task.  I suppose I should feel good: in every such instance, <em>either</em> I&#8217;m vindicated in all my recent screaming here about generative AI&#8212;what the naysayers call &#8220;glorified autocomplete&#8221;&#8212;being on the brink of remaking civilization, <em>or else</em> I still, for another few months at least, have a role to play on the Internet.</p>



<p>So, on to the preprint, as reviewed by the human Scott Aaronson.  Yeah, it&#8217;s basically a tissue of confusions, a mishmash of the well-known and the mistaken.  As they say, both novel and correct, but not in the same places.</p>



<p>The paper&#8217;s most eye-popping claim is that the <a href="https://en.wikipedia.org/wiki/Grover%27s_algorithm">Grover search problem</a>&#8212;namely, finding an n-bit string x such that f(x)=1, given oracle access to a Boolean function f:{0,1}<sup>n</sup>â{0,1}&#8212;is solvable <em>classically</em>, using a number of calls that&#8217;s only linear in n, or in many cases only constant (!!).  Since this claim contradicts a well-known, easily <em>provable</em> lower bound&#8212;namely, that Î©(2<sup>n</sup>) oracle calls are needed for classical brute-force searching&#8212;the authors <em>must</em> be using words in nonstandard ways, leaving only the question of how.</p>



<p>It turns out that, for their &#8220;quantum-inspired classical algorithm,&#8221; the authors assume you&#8217;re given, not merely an oracle for f, but the <em>actual circuit</em> to compute f.  They then use that circuit in a non-oracular way to extract the marked item.  In which case, I&#8217;d prefer to say that they&#8217;ve actually solved the Grover problem with <strong>zero</strong> queries&#8212;simply because they&#8217;ve entirely left the black-box setting where Grover&#8217;s algorithm is normally formulated!</p>



<p>What could possibly justify such a move?  Well, the authors argue that <em>sometimes</em> one can use the actual circuit to do better classically than Grover&#8217;s algorithm would do quantumly, and therefore, they&#8217;ve shown that the Grover speedup is not &#8220;generic,&#8221; as the quantum algorithms people always say it is.</p>



<p>But this is pure wordplay around the meaning of &#8220;generic.&#8221;  When we say that Grover&#8217;s algorithm achieves a &#8220;generic&#8221; square-root speedup, what we mean is that it solves the generic black-box search problem in O(2<sup>n/2</sup>) queries, whereas any classical algorithm for that generic problem requires Î©(2<sup>n</sup>) queries.  We don&#8217;t mean that for <em>every</em> f, Grover achieves a quadratic speedup for searching <em>that</em> f, compared to the best classical algorithm that could be tailored to that f.  Of course we don&#8217;t; that would be trivially false!</p>



<p>Remarkably, later in the paper, the authors seem to realize that they haven&#8217;t delivered the knockout blow against Grover&#8217;s algorithm that they&#8217;d hoped for, because they then turn around and argue that, well, even for those f&#8217;s where Grover <em>does</em> provide a quadratic speedup over the best (or best-known) classical algorithm, noise and decoherence could negate the advantage in practice, and solving that problem would require a fault-tolerant quantum computer, but fault-tolerance could require an enormous overhead, pushing a practical Grover speedup far into the future.</p>



<p>The response here boils down to &#8220;no duh.&#8221;  Yes, if Grover&#8217;s algorithm can yield any practical advantage in the medium term, it will <em>either</em> be because we&#8217;ve discovered much cheaper ways to do quantum fault-tolerance, or <em>else</em> because we&#8217;ve discovered &#8220;<a href="https://en.wikipedia.org/wiki/Noisy_intermediate-scale_quantum_era#:~:text=The%20current%20state%20of%20quantum,enough%20to%20achieve%20quantum%20supremacy.">NISQy</a>&#8221; ways to exploit the Grover speedup, which avoid the need for full fault-tolerance&#8212;for example, via quantum annealing.  The prospects are actually better for a medium-term advantage from Shor&#8217;s factoring algorithm, because of its exponential speedup.  Hopefully everyone in quantum computing theory has realized all this for a long time.</p>



<p>Anyway, as you can see, by this point we&#8217;ve already conceded the principle of Grover&#8217;s algorithm, and are just haggling over the practicalities!  Which brings us back to the authors&#8217; original claim to have a <em>principled</em> argument against the Grover speedup, which (as I said) rests on a confusion over words.</p>



<p>Some people dread the day when GPT will replace them.  In my case, for this task, I can&#8217;t wait.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p><em>Thanks to students Yuxuan Zhang (UT) and Alex Meiburg (UCSB) for discussions of the Stoudenmire-Waintal preprint that informed this post.  Of course, I take sole blame for anything anyone dislikes about the post!</em></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>For a much more technical response&#8212;one that explains <em>how</em> this preprint&#8217;s detailed attempt to simulate Grover classically fails, rather than merely proving that it must fail&#8212;check out <a href="https://scottaaronson.blog/?p=7143#comment-1947843">this comment by Alex Meiburg</a>.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-22T14:56:42Z">Wednesday, March 22 2023, 14:56</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/03/21/problems-better-than-solutions/'>Problems Better Than Solutions</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Defining the problem often means more than solving it Avrim Blum is the CAO at TTIC who got his degrees at MIT and then was at CMU almost for 25 years: CAO is Chief Academic Officer; TTIC is Toyota Technological Institute at Chicago; MIT is Massachusetts Institute of Technology; CMU is Carnegie Mellon University.. See [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>Defining the problem often means more than solving it</em><br />
<font color="#000000"></p>
<p>
Avrim Blum is the CAO at TTIC who got his degrees at MIT and then was at CMU almost for 25 years: </p>
<ul>
<li>
CAO is Chief Academic Officer; </p>
<li>
TTIC is Toyota Technological Institute at Chicago; </p>
<li>
MIT is Massachusetts Institute of Technology; </p>
<li>
CMU is Carnegie Mellon University..
</ul>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/21/problems-better-than-solutions/avrim/" rel="attachment wp-att-21318"><img data-attachment-id="21318" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/21/problems-better-than-solutions/avrim/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/avrim.jpeg?fit=150%2C197&amp;ssl=1" data-orig-size="150,197" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="avrim" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/avrim.jpeg?fit=150%2C197&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/avrim.jpeg?fit=150%2C197&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/avrim.jpeg?resize=150%2C197&#038;ssl=1" alt="" width="150" height="197" class="aligncenter size-full wp-image-21318" data-recalc-dims="1" /></a></p>
<p>
See his <a href="https://home.ttic.edu/~avrim/">own site</a> for details on TTIC. Quoting <a href="https://www.ttic.edu/faculty/blum/">his TTIC site</a>, his main research interests are in:</p>
<blockquote><p>
Theoretical Computer Science and Machine Learning, including Machine Learning Theory, Approximation Algorithms, Algorithmic Game Theory, Privacy, and Algorithmic Fairness. Some current specific interests include multi-agent and distributed learning, learning systems that know when they don&#8217;t know, and relations among fairness, accuracy, and incentives.
</p></blockquote>
<p>
At the very bottom of his webpage is a note about <a href="https://www.cs.cmu.edu/~weigand/staff/">RPP</a>. No, this is not a new complexity class. Let&#8217;s talk about what it is. </p>
<p>
<p><H2> Reasonable Person </H2></p>
<p><p>
Avrim endorses the CMU SCS <a href="https://en.wikipedia.org/wiki/Reasonable_person">Reasonable Person Principle</a> (RPP), which basically asks to be reasonable and assume everyone else is doing likewise.</p>
<ul>
<li>
Everyone will be reasonable. </p>
<li>
Everyone expects everyone else to be reasonable. </p>
<li>
No one is special. </p>
<li>
Do not be offended if someone suggests you are not being reasonable.
</ul>
<p>
This seems reasonable. </p>
<p>
<p><H2> Reasonable Problem </H2></p>
<p><p>
Some of the key results in Computer Science are new algorithms&#8212;that is new methods for solving old problems. For instance, faster <a href="https://en.wikipedia.org/wiki/Strassen_algorithm">matrix product</a>&#8212; of course due to Volker Strassen. But some of the coolest results are not new solutions. Rather they are entirely new problems. </p>
<p>
Here is an example of a reasonable behavior that maybe people in my walk of life have done for centuries, but that can cause problems in today&#8217;s world of available data and rapid updates. Suppose 98 students take a midterm exam but two students have to take it later because they traveled with the school band to March Madness. The professor posts the class average of 75.2 so the class knows the exam was reasonable. Then the other two make up the exam and the professor reposts the new average 74.3. </p>
<p>
Innocent enough? Actually not. Everyone can deduce that the two late takers both <em>failed</em> the exam. This kind of issue arises in myriad walks of life where summaries of aggregate information are made available for purposes of research, transparency, and social obligation to have an informed populace. But updates to the aggregate can in some important cases leak information about individual data.</p>
<p>
Defining this problem and criteria for combatting it was one of the most important results by Avrim and his coauthors. It is like the RPP&#8212;the definition is more critical than the implementation of the principle. </p>
<p>
<p><H2> Recognition </H2></p>
<p><p>
We have <a href="https://rjlipton.wpcomstaging.com/2015/02/06/cynthia-dwork-and-a-brilliant-idea/">previously</a> <a href="https://rjlipton.wpcomstaging.com/2015/02/07/still-a-brilliant-idea/">blogged</a> about differential privacy, including <a href="https://rjlipton.wpcomstaging.com/2022/05/11/differential-privacy/">last year</a> about the following recognition, from which we <a href="https://privacytools.seas.harvard.edu/blog/contributors-development-differential-privacy-receive-kanellakis-award">quote</a>:</p>
<blockquote><p><b> </b> <em> Avrim Blum, Toyota Technological Institute at Chicago; Irit Dinur, Weizmann Institute; Cynthia Dwork, Harvard University; Frank McSherry, Materialize Inc.; Kobbi Nissim, Georgetown University, and Adam Davison Smith, Boston University received the <i>2021 ACM Paris Kanellakis Theory and Practice</i> <a href="https://awards.acm.org/award-recipients/blum_3732674">Award</a> for their fundamental contributions to the development of differential privacy. </em>
</p></blockquote>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/03/21/problems-better-than-solutions/acm/" rel="attachment wp-att-21319"><img data-attachment-id="21319" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/21/problems-better-than-solutions/acm/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/acm.jpeg?fit=764%2C430&amp;ssl=1" data-orig-size="764,430" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="acm" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/acm.jpeg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/acm.jpeg?fit=600%2C338&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/acm.jpeg?resize=382%2C215&#038;ssl=1" alt="" width="382" height="215" class="aligncenter wp-image-21319" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/acm.jpeg?w=764&amp;ssl=1 764w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/acm.jpeg?resize=300%2C169&amp;ssl=1 300w" sizes="(max-width: 382px) 100vw, 382px" data-recalc-dims="1" /></a></p>
<p><P><br />
Here is a <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2008/04/dwork_tamc.pdf">survey</a> on this notion and a discussion of <a href="https://en.wikipedia.org/wiki/Implementations_of_differentially_private_analyses#deployments">implementations</a> of this idea. Quoting further:</p>
<blockquote><p><b> </b> <em> The theory of differential privacy gave a conceptually new, simple, and mathematically rigorous definition of privacy that allows for the development of mechanisms which provably protect individual information while at the same time enabling statistical analyses of databases. [&#8230;It] has important advantages over previously used methods: it requires no assumptions about the knowledge of the attacker and its computational capabilities; and it allows for formal analysis of privacy under composition. It is relatively easy to explain and use and has broad applicability. Differential privacy has been employed by a number of large companies and start-ups and notably the 2020 US Census, to make available data for analyses, including machine learning, with applications from marketing to social science research. </em>
</p></blockquote>
<p>
<p><H2> Another Definition </H2></p>
<p><p>
The aspect of &#8220;enabling statistical analysis of databases&#8221; is exemplified by this STOC 2008 <a href="https://www.cs.cmu.edu/~avrim/Papers/privacy.pdf">paper</a> by Blum with Katrina Ligett and Aaron Roth while at CMU. Their introduction states:</p>
<blockquote><p><b> </b> <em> We also introduce a new concept, <b>distributional privacy</b>, which makes explicit the notion that when run on a database drawn from a distribution, privacy-preserving mechanisms should reveal only information about the underlying distribution, and nothing else. </em>
</p></blockquote>
<p><p>
This kind of definition already had a 25-year track record from the theory of <a href="https://en.wikipedia.org/wiki/Zero-knowledge_proof">zero-knowledge</a> protocols. More precisely stated in this case:</p>
<blockquote><p><b> </b> <em> Given a distribution <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BD%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{D}" class="latex" /> over database points, a database privatization mechanism satisfies distributional privacy if with high probability, drawing an entirely new database from <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BD%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{D}" class="latex" /> does not change the probability of any outcome of the privatization mechanism by more than some small amount. </em>
</p></blockquote>
<p><p>
Having an inkling for the right definition is the best guidance toward a payoff, which in this case improved over an already successful idea:</p>
<blockquote><p><b> </b> <em> We show that distributional privacy is a strictly stronger guarantee than differential privacy by showing that any mechanism that satisfies distributional privacy also satisfies differential privacy, but that there are some functions that can be answered accurately while satisfying differential privacy, and yet reveal information about the particular database (although not about any particular database element) that is not &#8220;distributional.&#8221; </em>
</p></blockquote>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
I must say that I was involved decades ago in other attempts to define notions of security and privacy. See <a href="https://dl.acm.org/doi/pdf/10.1145/320064.320068">this</a> joint paper with David Dobkin and Anita Jones, titled &#8220;Secure Databases: Protection Against User Influence.&#8221; We missed the better boat, but we did try back in 1979 to create definitions of security. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/21/problems-better-than-solutions/boat-2/" rel="attachment wp-att-21320"><img data-attachment-id="21320" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/21/problems-better-than-solutions/boat-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/boat.jpg?fit=265%2C300&amp;ssl=1" data-orig-size="265,300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="boat" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/boat.jpg?fit=265%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/boat.jpg?fit=265%2C300&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/boat.jpg?resize=178%2C200&#038;ssl=1" alt="" width="178" height="200" class="aligncenter wp-image-21320" data-recalc-dims="1" /></a></p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-22T02:09:26Z">Wednesday, March 22 2023, 02:09</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.11779'>Online Hitting of Unit Balls and Hypercubes in $\mathbb{R}^d$ using Points from $\mathbb{Z}^d$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Minati De, Satyam Singh</p><p>We consider the online hitting set problem for the range space $\Sigma=(\cal
X,\cal R)$, where the point set $\cal X$ is known beforehand, but the set $\cal
R$ of geometric objects is not known in advance. Here, geometric objects arrive
one by one, the objective is to maintain a hitting set of minimum cardinality
by taking irrevocable decisions. In this paper, we have considered the problem
when the objects are unit balls or unit hypercubes in $\mathbb{R}^d$, and the
points from $\mathbb{Z}^d$ are used for hitting them. First, we consider the
problem for objects (unit balls and unit hypercubes) in lower dimensions. We
obtain $4$ and $8$-competitive deterministic online algorithms for hitting unit
hypercubes in $\mathbb{R}^2$ and $\mathbb{R}^3$, respectively. On the other
hand, we present $4$ and $14$-competitive deterministic online algorithms for
hitting unit balls in $\mathbb{R}^2$ and $\mathbb{R}^3$, respectively. Next, we
consider the problem for objects (unit balls and unit hypercubes) in the higher
dimension. For hitting unit hypercubes in $\mathbb{R}^d$, we present a
$O(d^2)$-competitive randomized online algorithm for $d\geq 3$ and prove the
competitive ratio of any deterministic algorithm for the problem is at least
$d+1$ for any $d\in\mathbb{N}$. Then, for hitting unit balls in $\mathbb{R}^d$,
we propose a $O(d^4)$-competitive deterministic algorithm, and for $d&lt;4$, we
establish that the competitive ratio of any deterministic algorithm is at least
$d+1$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+De_M/0/1/0/all/0/1">Minati De</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Satyam Singh</a></p><p>We consider the online hitting set problem for the range space $\Sigma=(\cal
X,\cal R)$, where the point set $\cal X$ is known beforehand, but the set $\cal
R$ of geometric objects is not known in advance. Here, geometric objects arrive
one by one, the objective is to maintain a hitting set of minimum cardinality
by taking irrevocable decisions. In this paper, we have considered the problem
when the objects are unit balls or unit hypercubes in $\mathbb{R}^d$, and the
points from $\mathbb{Z}^d$ are used for hitting them. First, we consider the
problem for objects (unit balls and unit hypercubes) in lower dimensions. We
obtain $4$ and $8$-competitive deterministic online algorithms for hitting unit
hypercubes in $\mathbb{R}^2$ and $\mathbb{R}^3$, respectively. On the other
hand, we present $4$ and $14$-competitive deterministic online algorithms for
hitting unit balls in $\mathbb{R}^2$ and $\mathbb{R}^3$, respectively. Next, we
consider the problem for objects (unit balls and unit hypercubes) in the higher
dimension. For hitting unit hypercubes in $\mathbb{R}^d$, we present a
$O(d^2)$-competitive randomized online algorithm for $d\geq 3$ and prove the
competitive ratio of any deterministic algorithm for the problem is at least
$d+1$ for any $d\in\mathbb{N}$. Then, for hitting unit balls in $\mathbb{R}^d$,
we propose a $O(d^4)$-competitive deterministic algorithm, and for $d&lt;4$, we
establish that the competitive ratio of any deterministic algorithm is at least
$d+1$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-22T00:30:00Z">Wednesday, March 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.11703'>Being an Influencer is Hard: The Complexity of Influence Maximization in Temporal Graphs with a Fixed Source</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Argyrios Deligkas, Michelle D&#xf6;ring, Eduard Eiben, Tiger-Lily Goldsmith, George Skretas</p><p>We consider the influence maximization problem over a temporal graph, where
there is a single fixed source. We deviate from the standard model of influence
maximization, where the goal is to choose the set of most influential vertices.
Instead, in our model we are given a fixed vertex, or source, and the goal is
to find the best time steps to transmit so that the influence of this vertex is
maximized. We frame this problem as a spreading process that follows a variant
of the susceptible-infected-susceptible (SIS) model and we focus on four
objective functions. In the MaxSpread objective, the goal is to maximize the
total number of vertices that get infected at least once. In the MaxViral
objective, the goal is to maximize the number of vertices that are infected at
the same time step. In the MaxViralTstep objective, the goal is to maximize the
number of vertices that are infected at a given time step. Finally, in
MinNonViralTime, the goal is to maximize the total number of vertices that get
infected every $d$ time steps. We perform a thorough complexity theoretic
analysis for these four objectives over three different scenarios: (1) the
unconstrained setting where the source can transmit whenever it wants; (2) the
window-constrained setting where the source has to transmit at either a
predetermined, or a shifting window; (3) the periodic setting where the
temporal graph has a small period. We prove that all of these problems, with
the exception of MaxSpread for periodic graphs, are intractable even for very
simple underlying graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deligkas_A/0/1/0/all/0/1">Argyrios Deligkas</a>, <a href="http://arxiv.org/find/cs/1/au:+Doring_M/0/1/0/all/0/1">Michelle D&#xf6;ring</a>, <a href="http://arxiv.org/find/cs/1/au:+Eiben_E/0/1/0/all/0/1">Eduard Eiben</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldsmith_T/0/1/0/all/0/1">Tiger-Lily Goldsmith</a>, <a href="http://arxiv.org/find/cs/1/au:+Skretas_G/0/1/0/all/0/1">George Skretas</a></p><p>We consider the influence maximization problem over a temporal graph, where
there is a single fixed source. We deviate from the standard model of influence
maximization, where the goal is to choose the set of most influential vertices.
Instead, in our model we are given a fixed vertex, or source, and the goal is
to find the best time steps to transmit so that the influence of this vertex is
maximized. We frame this problem as a spreading process that follows a variant
of the susceptible-infected-susceptible (SIS) model and we focus on four
objective functions. In the MaxSpread objective, the goal is to maximize the
total number of vertices that get infected at least once. In the MaxViral
objective, the goal is to maximize the number of vertices that are infected at
the same time step. In the MaxViralTstep objective, the goal is to maximize the
number of vertices that are infected at a given time step. Finally, in
MinNonViralTime, the goal is to maximize the total number of vertices that get
infected every $d$ time steps. We perform a thorough complexity theoretic
analysis for these four objectives over three different scenarios: (1) the
unconstrained setting where the source can transmit whenever it wants; (2) the
window-constrained setting where the source has to transmit at either a
predetermined, or a shifting window; (3) the periodic setting where the
temporal graph has a small period. We prove that all of these problems, with
the exception of MaxSpread for periodic graphs, are intractable even for very
simple underlying graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-22T00:30:00Z">Wednesday, March 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.11843'>Optimal Fully Dynamic $k$-Center Clustering for Adaptive and Oblivious Adversaries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: MohammadHossein Bateni, Hossein Esfandiari, Hendrik Fichtenberger, Monika Henzinger, Rajesh Jayaram, Vahab Mirrokni, Andreas Wiese</p><p>In fully dynamic clustering problems, a clustering of a given data set in a
metric space must be maintained while it is modified through insertions and
deletions of individual points. In this paper, we resolve the complexity of
fully dynamic $k$-center clustering against both adaptive and oblivious
adversaries. Against oblivious adversaries, we present the first algorithm for
fully dynamic $k$-center in an arbitrary metric space that maintains an optimal
$(2+\epsilon)$-approximation in $O(k \cdot \mathrm{polylog}(n,\Delta))$
amortized update time. Here, $n$ is an upper bound on the number of active
points at any time, and $\Delta$ is the aspect ratio of the metric space.
Previously, the best known amortized update time was $O(k^2\cdot
\mathrm{polylog}(n,\Delta))$, and is due to Chan, Gourqin, and Sozio (2018).
Moreover, we demonstrate that our runtime is optimal up to
$\mathrm{polylog}(n,\Delta)$ factors. In fact, we prove that even offline
algorithms for $k$-clustering tasks in arbitrary metric spaces, including
$k$-medians, $k$-means, and $k$-center, must make at least $\Omega(n k)$
distance queries to achieve any non-trivial approximation factor. This implies
a lower bound of $\Omega(k)$ which holds even for the insertions-only setting.
</p>
<p>We also show deterministic lower and upper bounds for adaptive adversaries,
demonstrate that an update time sublinear in $k$ is possible against oblivious
adversaries for metric spaces which admit locally sensitive hash functions
(LSH) and give the first fully dynamic $O(1)$-approximation algorithms for the
closely related $k$-sum-of-radii and $k$-sum-of-diameter problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bateni_M/0/1/0/all/0/1">MohammadHossein Bateni</a>, <a href="http://arxiv.org/find/cs/1/au:+Esfandiari_H/0/1/0/all/0/1">Hossein Esfandiari</a>, <a href="http://arxiv.org/find/cs/1/au:+Fichtenberger_H/0/1/0/all/0/1">Hendrik Fichtenberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaram_R/0/1/0/all/0/1">Rajesh Jayaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiese_A/0/1/0/all/0/1">Andreas Wiese</a></p><p>In fully dynamic clustering problems, a clustering of a given data set in a
metric space must be maintained while it is modified through insertions and
deletions of individual points. In this paper, we resolve the complexity of
fully dynamic $k$-center clustering against both adaptive and oblivious
adversaries. Against oblivious adversaries, we present the first algorithm for
fully dynamic $k$-center in an arbitrary metric space that maintains an optimal
$(2+\epsilon)$-approximation in $O(k \cdot \mathrm{polylog}(n,\Delta))$
amortized update time. Here, $n$ is an upper bound on the number of active
points at any time, and $\Delta$ is the aspect ratio of the metric space.
Previously, the best known amortized update time was $O(k^2\cdot
\mathrm{polylog}(n,\Delta))$, and is due to Chan, Gourqin, and Sozio (2018).
Moreover, we demonstrate that our runtime is optimal up to
$\mathrm{polylog}(n,\Delta)$ factors. In fact, we prove that even offline
algorithms for $k$-clustering tasks in arbitrary metric spaces, including
$k$-medians, $k$-means, and $k$-center, must make at least $\Omega(n k)$
distance queries to achieve any non-trivial approximation factor. This implies
a lower bound of $\Omega(k)$ which holds even for the insertions-only setting.
</p>
<p>We also show deterministic lower and upper bounds for adaptive adversaries,
demonstrate that an update time sublinear in $k$ is possible against oblivious
adversaries for metric spaces which admit locally sensitive hash functions
(LSH) and give the first fully dynamic $O(1)$-approximation algorithms for the
closely related $k$-sum-of-radii and $k$-sum-of-diameter problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-22T00:30:00Z">Wednesday, March 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.11937'>High Probability Bounds for Stochastic Continuous Submodular Maximization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Evan Becker, Jingdong Gao, Ted Zadouri, Baharan Mirzasoleiman</p><p>We consider maximization of stochastic monotone continuous submodular
functions (CSF) with a diminishing return property. Existing algorithms only
guarantee the performance \textit{in expectation}, and do not bound the
probability of getting a bad solution. This implies that for a particular run
of the algorithms, the solution may be much worse than the provided guarantee
in expectation. In this paper, we first empirically verify that this is indeed
the case. Then, we provide the first \textit{high-probability} analysis of the
existing methods for stochastic CSF maximization, namely PGA, boosted PGA, SCG,
and SCG++. Finally, we provide an improved high-probability bound for SCG,
under slightly stronger assumptions, with a better convergence rate than that
of the expected solution. Through extensive experiments on non-concave
quadratic programming (NQP) and optimal budget allocation, we confirm the
validity of our bounds and show that even in the worst-case, PGA converges to
$OPT/2$, and boosted PGA, SCG, SCG++ converge to $(1 - 1/e)OPT$, but at a
slower rate than that of the expected solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Becker_E/0/1/0/all/0/1">Evan Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jingdong Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zadouri_T/0/1/0/all/0/1">Ted Zadouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirzasoleiman_B/0/1/0/all/0/1">Baharan Mirzasoleiman</a></p><p>We consider maximization of stochastic monotone continuous submodular
functions (CSF) with a diminishing return property. Existing algorithms only
guarantee the performance \textit{in expectation}, and do not bound the
probability of getting a bad solution. This implies that for a particular run
of the algorithms, the solution may be much worse than the provided guarantee
in expectation. In this paper, we first empirically verify that this is indeed
the case. Then, we provide the first \textit{high-probability} analysis of the
existing methods for stochastic CSF maximization, namely PGA, boosted PGA, SCG,
and SCG++. Finally, we provide an improved high-probability bound for SCG,
under slightly stronger assumptions, with a better convergence rate than that
of the expected solution. Through extensive experiments on non-concave
quadratic programming (NQP) and optimal budget allocation, we confirm the
validity of our bounds and show that even in the worst-case, PGA converges to
$OPT/2$, and boosted PGA, SCG, SCG++ converge to $(1 - 1/e)OPT$, but at a
slower rate than that of the expected solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-22T00:30:00Z">Wednesday, March 22 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, March 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/030'>TR23-030 |  A proof complexity conjecture and the Incompleteness theorem | 

	Jan  Krajicek</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Given a sound first-order p-time theory $T$ capable of formalizing syntax of 
first-order logic we define a p-time function $g_T$ that stretches all inputs by one 
bit and we use its properties to show that $T$ must be incomplete. We leave it as an 
open problem whether for some $T$ the range of $g_T$ intersects all infinite NP sets 
(i.e. whether it is a proof complexity generator hard for all proof systems).

A propositional version of the construction shows that at least one of the following 
three statements is true:

- there is no p-optimal propositional proof system (this is equivalent to the 
non-existence of a time-optimal propositional proof search algorithm),
	
- $E \not\subseteq P/poly$,
	
- there exists function $h$ that stretches all inputs by one bit, 
is computable in sub-exponential time and its range $Rng(h)$ intersects all infinite 
N sets.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Given a sound first-order p-time theory $T$ capable of formalizing syntax of 
first-order logic we define a p-time function $g_T$ that stretches all inputs by one 
bit and we use its properties to show that $T$ must be incomplete. We leave it as an 
open problem whether for some $T$ the range of $g_T$ intersects all infinite NP sets 
(i.e. whether it is a proof complexity generator hard for all proof systems).

A propositional version of the construction shows that at least one of the following 
three statements is true:

- there is no p-optimal propositional proof system (this is equivalent to the 
non-existence of a time-optimal propositional proof search algorithm),
	
- $E \not\subseteq P/poly$,
	
- there exists function $h$ that stretches all inputs by one bit, 
is computable in sub-exponential time and its range $Rng(h)$ intersects all infinite 
N sets.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-21T10:10:27Z">Tuesday, March 21 2023, 10:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.10244'>One Weird Trick Tightens the Quantum Adversary Bound, Especially for Success Probability Close to $1/2$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Duyal Yolcu</p><p>The textbook adversary bound for function evaluation states that to evaluate
a function $f\colon D\to C$ with success probability $\frac{1}{2}+\delta$ in
the quantum query model, one needs at least $\left( 2\delta -\sqrt{1-4\delta^2}
\right) Adv(f)$ queries, where $Adv(f)$ is the optimal value of a certain
optimization problem. For $\delta \ll 1$, this only allows for a bound of
$\Theta\left(\delta^2 Adv(f)\right)$ even after a
repetition-and-majority-voting argument. In contrast, the polynomial method can
sometimes prove a bound that doesn't converge to $0$ as $\delta \to 0$. We
improve the $\delta$-dependent prefactor and achieve a bound of $2\delta
Adv(f)$. The proof idea is to "turn the output condition into an input
condition": From an algorithm that transforms perfectly input-independent
initial to imperfectly distinguishable final states, we construct one that
transforms imperfectly input-independent initial to perfectly distinguishable
final states in the same number of queries by projecting onto the "correct"
final subspaces and uncomputing. The resulting $\delta$-dependent condition on
initial Gram matrices, compared to the original algorithm's condition on final
Gram matrices, allows deriving the tightened prefactor.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Yolcu_D/0/1/0/all/0/1">Duyal Yolcu</a></p><p>The textbook adversary bound for function evaluation states that to evaluate
a function $f\colon D\to C$ with success probability $\frac{1}{2}+\delta$ in
the quantum query model, one needs at least $\left( 2\delta -\sqrt{1-4\delta^2}
\right) Adv(f)$ queries, where $Adv(f)$ is the optimal value of a certain
optimization problem. For $\delta \ll 1$, this only allows for a bound of
$\Theta\left(\delta^2 Adv(f)\right)$ even after a
repetition-and-majority-voting argument. In contrast, the polynomial method can
sometimes prove a bound that doesn't converge to $0$ as $\delta \to 0$. We
improve the $\delta$-dependent prefactor and achieve a bound of $2\delta
Adv(f)$. The proof idea is to "turn the output condition into an input
condition": From an algorithm that transforms perfectly input-independent
initial to imperfectly distinguishable final states, we construct one that
transforms imperfectly input-independent initial to perfectly distinguishable
final states in the same number of queries by projecting onto the "correct"
final subspaces and uncomputing. The resulting $\delta$-dependent condition on
initial Gram matrices, compared to the original algorithm's condition on final
Gram matrices, allows deriving the tightened prefactor.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-21T00:30:00Z">Tuesday, March 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.10490'>On the Parameterized Complexity of Relaxations of Clique</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ambroise Baril, Antoine Castillon, Nacim Oijid</p><p>We investigate the parameterized complexity of several problems formalizing
cluster identification in graphs. In other words we ask whether a graph
contains a large enough and sufficiently connected subgraph. We study here
three relaxations of CLIQUE: $s$-CLUB and $s$-CLIQUE, in which the relaxation
is focused on the distances in respectively the cluster and the original graph,
and $\gamma$-COMPLETE SUBGRAPH in which the relaxation is made on the minimal
degree in the cluster. As these three problems are known to be NP-hard, we
study here their parameterized complexities. We prove that $s$-CLUB and
$s$-CLIQUE are NP-hard even restricted to graphs of degeneracy $\le 3$ whenever
$s \ge 3$, and to graphs of degeneracy $\le 2$ whenever $s \ge 5$, which is a
strictly stronger result than its W[1]-hardness parameterized by the
degeneracy. We also obtain that these problems are solvable in polynomial time
on graphs of degeneracy $1$. Concerning $\gamma$-COMPLETE SUBGRAPH, we prove
that it is W[1]-hard parameterized by both the degeneracy, which implies the
W[1]-hardness parameterized by the number of vertices in the
$\gamma$-complete-subgraph, and the number of elements outside the
$\gamma$-complete subgraph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Baril_A/0/1/0/all/0/1">Ambroise Baril</a>, <a href="http://arxiv.org/find/cs/1/au:+Castillon_A/0/1/0/all/0/1">Antoine Castillon</a>, <a href="http://arxiv.org/find/cs/1/au:+Oijid_N/0/1/0/all/0/1">Nacim Oijid</a></p><p>We investigate the parameterized complexity of several problems formalizing
cluster identification in graphs. In other words we ask whether a graph
contains a large enough and sufficiently connected subgraph. We study here
three relaxations of CLIQUE: $s$-CLUB and $s$-CLIQUE, in which the relaxation
is focused on the distances in respectively the cluster and the original graph,
and $\gamma$-COMPLETE SUBGRAPH in which the relaxation is made on the minimal
degree in the cluster. As these three problems are known to be NP-hard, we
study here their parameterized complexities. We prove that $s$-CLUB and
$s$-CLIQUE are NP-hard even restricted to graphs of degeneracy $\le 3$ whenever
$s \ge 3$, and to graphs of degeneracy $\le 2$ whenever $s \ge 5$, which is a
strictly stronger result than its W[1]-hardness parameterized by the
degeneracy. We also obtain that these problems are solvable in polynomial time
on graphs of degeneracy $1$. Concerning $\gamma$-COMPLETE SUBGRAPH, we prove
that it is W[1]-hard parameterized by both the degeneracy, which implies the
W[1]-hardness parameterized by the number of vertices in the
$\gamma$-complete-subgraph, and the number of elements outside the
$\gamma$-complete subgraph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-21T00:30:00Z">Tuesday, March 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.10251'>Conformal Generative Modeling on Triangulated Surfaces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Victor Dorobantu, Charlotte Borcherds, Yisong Yue</p><p>We propose conformal generative modeling, a framework for generative modeling
on 2D surfaces approximated by discrete triangle meshes. Our approach leverages
advances in discrete conformal geometry to develop a map from a source triangle
mesh to a target triangle mesh of a simple manifold such as a sphere. After
accounting for errors due to the mesh discretization, we can use any generative
modeling approach developed for simple manifolds as a plug-and-play subroutine.
We demonstrate our framework on multiple complicated manifolds and multiple
generative modeling subroutines, where we show that our approach can learn good
estimates of distributions on meshes from samples, and can also learn
simultaneously from multiple distinct meshes of the same underlying manifold.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dorobantu_V/0/1/0/all/0/1">Victor Dorobantu</a>, <a href="http://arxiv.org/find/cs/1/au:+Borcherds_C/0/1/0/all/0/1">Charlotte Borcherds</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yisong Yue</a></p><p>We propose conformal generative modeling, a framework for generative modeling
on 2D surfaces approximated by discrete triangle meshes. Our approach leverages
advances in discrete conformal geometry to develop a map from a source triangle
mesh to a target triangle mesh of a simple manifold such as a sphere. After
accounting for errors due to the mesh discretization, we can use any generative
modeling approach developed for simple manifolds as a plug-and-play subroutine.
We demonstrate our framework on multiple complicated manifolds and multiple
generative modeling subroutines, where we show that our approach can learn good
estimates of distributions on meshes from samples, and can also learn
simultaneously from multiple distinct meshes of the same underlying manifold.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-21T00:30:00Z">Tuesday, March 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.10581'>An Evaluation of GPU Filters for Accelerating the 2D Convex Hull</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Roberto Carrasco, H&#xe9;ctor Ferrada, Crist&#xf3;bal A. Navarro, Nancy Hitschfeld</p><p>The Convex Hull algorithm is one of the most important algorithms in
computational geometry, with many applications such as in computer graphics,
robotics, and data mining. Despite the advances in the new algorithms in this
area, it is often needed to improve the performance to solve more significant
problems quickly or in real-time processing. This work presents an experimental
evaluation of GPU filters to reduce the cost of computing the 2D convex hull.
The technique first performs a preprocessing of the input set, filtering all
points within an eight-vertex polygon in logarithmic time, to obtain a reduced
set of candidate points. We use parallel computation and the use of the
Manhattan distance as a metric to find the vertices of the polygon and perform
the point filtering. For the filtering stage we study different approaches;
from custom CUDA kernels to libraries such as Thrust and CUB. Three types of
point distributions are tested: a normal distribution (favorable case),
circumference (the worst case), and a case where points are shifted randomly
from the circumference (intermediate case). Experimental evaluation shows that
the GPU filtering algorithm can be up to 23x faster than a sequential CPU
implementation, and the whole convex hull computation can be up to 30x faster
than the fastest implementation provided by the CGAL library.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Carrasco_R/0/1/0/all/0/1">Roberto Carrasco</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrada_H/0/1/0/all/0/1">H&#xe9;ctor Ferrada</a>, <a href="http://arxiv.org/find/cs/1/au:+Navarro_C/0/1/0/all/0/1">Crist&#xf3;bal A. Navarro</a>, <a href="http://arxiv.org/find/cs/1/au:+Hitschfeld_N/0/1/0/all/0/1">Nancy Hitschfeld</a></p><p>The Convex Hull algorithm is one of the most important algorithms in
computational geometry, with many applications such as in computer graphics,
robotics, and data mining. Despite the advances in the new algorithms in this
area, it is often needed to improve the performance to solve more significant
problems quickly or in real-time processing. This work presents an experimental
evaluation of GPU filters to reduce the cost of computing the 2D convex hull.
The technique first performs a preprocessing of the input set, filtering all
points within an eight-vertex polygon in logarithmic time, to obtain a reduced
set of candidate points. We use parallel computation and the use of the
Manhattan distance as a metric to find the vertices of the polygon and perform
the point filtering. For the filtering stage we study different approaches;
from custom CUDA kernels to libraries such as Thrust and CUB. Three types of
point distributions are tested: a normal distribution (favorable case),
circumference (the worst case), and a case where points are shifted randomly
from the circumference (intermediate case). Experimental evaluation shows that
the GPU filtering algorithm can be up to 23x faster than a sequential CPU
implementation, and the whole convex hull computation can be up to 30x faster
than the fastest implementation provided by the CGAL library.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-21T00:30:00Z">Tuesday, March 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.10394'>Explorable families of graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andrzej Pelc</p><p>Graph exploration is one of the fundamental tasks performed by a mobile agent
in a graph. An $n$-node graph has unlabeled nodes, and all ports at any node of
degree $d$ are arbitrarily numbered $0,\dots, d-1$. A mobile agent, initially
situated at some starting node $v$, has to visit all nodes of the graph and
stop. In the absence of any initial knowledge of the graph the task of
deterministic exploration is often impossible. On the other hand, for some
families of graphs it is possible to design deterministic exploration
algorithms working for any graph of the family. We call such families of graphs
{\em explorable}. Examples of explorable families are all finite families of
graphs, as well as the family of all trees.
</p>
<p>In this paper we study the problem of which families of graphs are
explorable. We characterize all such families, and then ask the question
whether there exists a universal deterministic algorithm that, given an
explorable family of graphs, explores any graph of this family, without knowing
which graph of the family is being explored. The answer to this question turns
out to depend on how the explorable family is given to the hypothetical
universal algorithm. If the algorithm can get the answer to any yes/no question
about the family, then such a universal algorithm can be constructed. If, on
the other hand, the algorithm can be only given an algorithmic description of
the input explorable family, then such a universal deterministic algorithm does
not exist.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pelc_A/0/1/0/all/0/1">Andrzej Pelc</a></p><p>Graph exploration is one of the fundamental tasks performed by a mobile agent
in a graph. An $n$-node graph has unlabeled nodes, and all ports at any node of
degree $d$ are arbitrarily numbered $0,\dots, d-1$. A mobile agent, initially
situated at some starting node $v$, has to visit all nodes of the graph and
stop. In the absence of any initial knowledge of the graph the task of
deterministic exploration is often impossible. On the other hand, for some
families of graphs it is possible to design deterministic exploration
algorithms working for any graph of the family. We call such families of graphs
{\em explorable}. Examples of explorable families are all finite families of
graphs, as well as the family of all trees.
</p>
<p>In this paper we study the problem of which families of graphs are
explorable. We characterize all such families, and then ask the question
whether there exists a universal deterministic algorithm that, given an
explorable family of graphs, explores any graph of this family, without knowing
which graph of the family is being explored. The answer to this question turns
out to depend on how the explorable family is given to the hypothetical
universal algorithm. If the algorithm can get the answer to any yes/no question
about the family, then such a universal algorithm can be constructed. If, on
the other hand, the algorithm can be only given an algorithmic description of
the input explorable family, then such a universal deterministic algorithm does
not exist.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-21T00:30:00Z">Tuesday, March 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, March 20
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/03/new-upper-bound-on-rk-wow.html'>New Upper Bound on R(k).  WOW!</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;R(k) is the least n such that for all 2-colorings of the edges of \(K_n\) there is a monochromatic \(K_k\)</p><p>(so there are k vertices such that the coloring restricted to the edges between those k vertices is constant)</p><p><br>Here is some history. If I miss a reference or a result, let me know in the comments</p><p><br></p><p>\(R(k) \le 2^{2k} = 4^k \) seems to be folklore and is a very old result. Proof could be shown to HS students. I have. Or 9 year old's who are good at math. I have.&nbsp;</p><p><br></p><p>\(R(k)\le {2k-2 \choose k-1}\) which is approx \(\frac{4^k}{\sqrt k}\) was shown by Erdos and Szekeres in 1935. Proof could be shown to HS students. I have. Or 9 year old's who are good at math. I have.&nbsp;</p><p><br></p><p>Thomson in 1988 got</p><p>$$R(k) \le \frac{4^k}{k^A\sqrt{\log k}}$$</p><p>for some A. This paper is behind paywalls so will be lost to history and I cannot comment on if the proof is easy or hard. (If you know of a link it, let me know and I will provide it).&nbsp;</p><p>Conlon in 2006 got the denom to be super-poly. We omit the result but the paper is&nbsp;here. Proof used the next method of quasi-randomness.&nbsp;</p><p>Sah&nbsp; (his paper is&nbsp;here) optimized Conlon's technique to get&nbsp;</p><p>$$R(k) \le 4^{k-c(\log k)^2}.$$</p><p>(According to the paper I will point to soon that has the major result, Sah's result is the best one can do with the Thomason-Conlon technique. In Complexity theory we may have formalized that and called it a barrier result.)</p><p>These results were interesting and used interesting techniques. However, the best known lower bound is&nbsp; \(R(k) \ge 2^{k/2}\) (I've left out constants) so the REAL questions are</p><p>a) Can the 4 be replaced with a smaller number in the upper bound?</p><p>b) Is there a number a so that R(k) is essentially \(2^{ak}\)?&nbsp;&nbsp;</p><p>We note in passing that the lower bound was proven by the Prob Method. That last statement obscures the history--- the Prob Method was invented by Erdos TO PROVE the lower bound. I've seen the prob method called an application of Ramsey Theory&nbsp;which is not quite right. Its more like Ramsey INSPIRED a technique that is used A LOT, including things that are actually practical.&nbsp;</p><p>But&nbsp; back to our story. SO, while all of the above results were interesting, were they making progress towards the REAL question? We can now say YES as progress HAS been made and DID use some of the techniques.</p><p>On March 16, 2023 Campos, Griffthis, Morris, Sahasrabudhe posted a paper on arxiv,&nbsp;here, that showed</p><p>$$R(k) \le (4-\epsilon)^k$$</p><p>&nbsp;for some (quite small) epsilon.&nbsp;</p><p>Here are some thoughts which are influenced by my email correspondence with Jacob Fox (an eminent combinatorist) on this topic.</p><p>1) I am NOT surprised that the result is true.&nbsp;</p><p>2) I AM surprised that it's been proven. Lots of brilliant people have worked on this problem for many years so... .why now? Since its been open for around 70 years, I thought it would take another 70 years to crack.</p><p>3) Will this result lead to better results? I hope so!</p><p>4) Does R(k) have a nice upper bound? Not clear. The following is unlikely though something like it may be possible:</p><p>R(k) roughly\( (3.5)^k\) for k a power of a Fibonacci prime</p><p>R(k) roughly\( (3.8)^k \)othewise</p><p>5) (Jacob pointed me to this) There is a paper on Book-Ramsey Numbers that also (on page 2) notes a connection to Ramsey Numbers. The paper is&nbsp;here. A conjecture on Book-Ramsey will lead to a big improvement on Ramsey. Those kinds of results are odd since I can't tell if the upshot is</p><p>Lets work hard on Book-Ramsey so we can get better bounds on Ramsey!</p><p>or</p><p>Book-Ramsey is HARD so lets give up. (Who first said if at first you don't succeed, quit. Why make a damn fool of yourself? ?)&nbsp;</p><p>6) The paper with the new result is 57 pages. It looks dense. I will wait for the movie.&nbsp; I may have to wait a long time.&nbsp;</p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;R(k) is the least n such that for all 2-colorings of the edges of \(K_n\) there is a monochromatic \(K_k\)</p><p>(so there are k vertices such that the coloring restricted to the edges between those k vertices is constant)</p><p><br />Here is some history. If I miss a reference or a result, let me know in the comments</p><p><br /></p><p>\(R(k) \le 2^{2k} = 4^k \) seems to be folklore and is a very old result. Proof could be shown to HS students. I have. Or 9 year old's who are good at math. I have.&nbsp;</p><p><br /></p><p>\(R(k)\le {2k-2 \choose k-1}\) which is approx \(\frac{4^k}{\sqrt k}\) was shown by Erdos and Szekeres in 1935. Proof could be shown to HS students. I have. Or 9 year old's who are good at math. I have.&nbsp;</p><p><br /></p><p>Thomson in 1988 got</p><p>$$R(k) \le \frac{4^k}{k^A\sqrt{\log k}}$$</p><p>for some A. This paper is behind paywalls so will be lost to history and I cannot comment on if the proof is easy or hard. (If you know of a link it, let me know and I will provide it).&nbsp;</p><p>Conlon in 2006 got the denom to be super-poly. We omit the result but the paper is&nbsp;<a href="https://arxiv.org/abs/math/0607788">here</a>. Proof used the next method of quasi-randomness.&nbsp;</p><p>Sah&nbsp; (his paper is&nbsp;<a href="https://arxiv.org/abs/2005.09251">here</a>) optimized Conlon's technique to get&nbsp;</p><p>$$R(k) \le 4^{k-c(\log k)^2}.$$</p><p>(According to the paper I will point to soon that has the major result, Sah's result is the best one can do with the Thomason-Conlon technique. In Complexity theory we may have formalized that and called it a barrier result.)</p><p>These results were interesting and used interesting techniques. However, the best known lower bound is&nbsp; \(R(k) \ge 2^{k/2}\) (I've left out constants) so the REAL questions are</p><p>a) Can the 4 be replaced with a smaller number in the upper bound?</p><p>b) Is there a number a so that R(k) is essentially \(2^{ak}\)?&nbsp;&nbsp;</p><p>We note in passing that the lower bound was proven by the Prob Method. That last statement obscures the history--- the Prob Method was invented by Erdos TO PROVE the lower bound. I've seen the prob method called <i>an application of Ramsey Theory</i>&nbsp;which is not quite right. Its more like Ramsey INSPIRED a technique that is used A LOT, including things that are actually practical.&nbsp;</p><p>But&nbsp; back to our story. SO, while all of the above results were interesting, were they making progress towards the REAL question? We can now say YES as progress HAS been made and DID use some of the techniques.</p><p>On March 16, 2023 Campos, Griffthis, Morris, Sahasrabudhe posted a paper on arxiv,&nbsp;<a href="https://arxiv.org/pdf/2303.09521.pdf">here</a>, that showed</p><p>$$R(k) \le (4-\epsilon)^k$$</p><p>&nbsp;for some (quite small) epsilon.&nbsp;</p><p>Here are some thoughts which are influenced by my email correspondence with Jacob Fox (an eminent combinatorist) on this topic.</p><p>1) I am NOT surprised that the result is true.&nbsp;</p><p>2) I AM surprised that it's been proven. Lots of brilliant people have worked on this problem for many years so... .why now? Since its been open for around 70 years, I thought it would take another 70 years to crack.</p><p>3) Will this result lead to better results? I hope so!</p><p>4) Does R(k) have a nice upper bound? Not clear. The following is unlikely though something like it may be possible:</p><p>R(k) roughly\( (3.5)^k\) for k a power of a Fibonacci prime</p><p>R(k) roughly\( (3.8)^k \)othewise</p><p>5) (Jacob pointed me to this) There is a paper on Book-Ramsey Numbers that also (on page 2) notes a connection to Ramsey Numbers. The paper is&nbsp;<a href="https://arxiv.org/pdf/2001.00407.pdf">here</a>. A conjecture on Book-Ramsey will lead to a big improvement on Ramsey. Those kinds of results are odd since I can't tell if the upshot is</p><p>Lets work hard on Book-Ramsey so we can get better bounds on Ramsey!</p><p>or</p><p>Book-Ramsey is HARD so lets give up. (Who first said <i>if at first you don't succeed, quit. Why make a damn fool of yourself? ?)&nbsp;</i></p><p>6) The paper with the new result is 57 pages. It looks dense. I will wait for the movie.&nbsp; I may have to wait a long time.&nbsp;</p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-20T00:47:00Z">Monday, March 20 2023, 00:47</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.09586'>Optimal Volume-Sensitive Bounds for Polytope Approximation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sunil Arya, David M. Mount</p><p>Approximating convex bodies is a fundamental question in geometry and has a
wide variety of applications. Consider a convex body $K$ of diameter $\Delta$
in $\textbf{R}^d$ for fixed $d$. The objective is to minimize the number of
vertices (alternatively, the number of facets) of an approximating polytope for
a given Hausdorff error $\varepsilon$. It is known from classical results of
Dudley (1974) and Bronshteyn and Ivanov (1976) that
$\Theta((\Delta/\varepsilon)^{(d-1)/2})$ vertices (alternatively, facets) are
both necessary and sufficient. While this bound is tight in the worst case,
that of Euclidean balls, it is far from optimal for skinny convex bodies.
</p>
<p>A natural way to characterize a convex object's skinniness is in terms of its
relationship to the Euclidean ball. Given a convex body $K$, define its
\emph{volume diameter} $\Delta_d$ to be the diameter of a Euclidean ball of the
same volume as $K$, and define its \emph{surface diameter} $\Delta_{d-1}$
analogously for surface area. It follows from generalizations of the
isoperimetric inequality that $\Delta \geq \Delta_{d-1} \geq \Delta_d$.
</p>
<p>Arya, da Fonseca, and Mount (SoCG 2012) demonstrated that the diameter-based
bound could be made surface-area sensitive, improving the above bound to
$O((\Delta_{d-1}/\varepsilon)^{(d-1)/2})$. In this paper, we strengthen this by
proving the existence of an approximation with
$O((\Delta_d/\varepsilon)^{(d-1)/2})$ facets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Arya_S/0/1/0/all/0/1">Sunil Arya</a>, <a href="http://arxiv.org/find/cs/1/au:+Mount_D/0/1/0/all/0/1">David M. Mount</a></p><p>Approximating convex bodies is a fundamental question in geometry and has a
wide variety of applications. Consider a convex body $K$ of diameter $\Delta$
in $\textbf{R}^d$ for fixed $d$. The objective is to minimize the number of
vertices (alternatively, the number of facets) of an approximating polytope for
a given Hausdorff error $\varepsilon$. It is known from classical results of
Dudley (1974) and Bronshteyn and Ivanov (1976) that
$\Theta((\Delta/\varepsilon)^{(d-1)/2})$ vertices (alternatively, facets) are
both necessary and sufficient. While this bound is tight in the worst case,
that of Euclidean balls, it is far from optimal for skinny convex bodies.
</p>
<p>A natural way to characterize a convex object's skinniness is in terms of its
relationship to the Euclidean ball. Given a convex body $K$, define its
\emph{volume diameter} $\Delta_d$ to be the diameter of a Euclidean ball of the
same volume as $K$, and define its \emph{surface diameter} $\Delta_{d-1}$
analogously for surface area. It follows from generalizations of the
isoperimetric inequality that $\Delta \geq \Delta_{d-1} \geq \Delta_d$.
</p>
<p>Arya, da Fonseca, and Mount (SoCG 2012) demonstrated that the diameter-based
bound could be made surface-area sensitive, improving the above bound to
$O((\Delta_{d-1}/\varepsilon)^{(d-1)/2})$. In this paper, we strengthen this by
proving the existence of an approximation with
$O((\Delta_d/\varepsilon)^{(d-1)/2})$ facets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-20T00:30:00Z">Monday, March 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.09702'>The geodesic edge center of a simple polygon</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anna Lubiw, Anurag Murty Naredla</p><p>The geodesic edge center of a polygon is a point c inside the polygon that
minimizes the maximum geodesic distance from c to any edge of the polygon,
where geodesic distance is the shortest path distance inside the polygon. We
give a linear-time algorithm to find a geodesic edge center of a simple
polygon. This improves on the previous O(n log n) time algorithm by Lubiw and
Naredla [European Symposium on Algorithms, 2021]. The algorithm builds on an
algorithm to find the geodesic vertex center of a simple polygon due to
Pollack, Sharir, and Rote [Discrete &amp; Computational Geometry, 1989] and an
improvement to linear time by Ahn, Barba, Bose, De Carufel, Korman, and Oh
[Discrete &amp; Computational Geometry, 2016]. The geodesic edge center can easily
be found from the geodesic farthest-edge Voronoi diagram of the polygon.
Finding that Voronoi diagram in linear time is an open question, although the
geodesic nearest edge Voronoi diagram (the medial axis) can be found in linear
time. As a first step of our geodesic edge center algorithm, we give a
linear-time algorithm to find the geodesic farthest-edge Voronoi diagram
restricted to the polygon boundary.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lubiw_A/0/1/0/all/0/1">Anna Lubiw</a>, <a href="http://arxiv.org/find/cs/1/au:+Naredla_A/0/1/0/all/0/1">Anurag Murty Naredla</a></p><p>The geodesic edge center of a polygon is a point c inside the polygon that
minimizes the maximum geodesic distance from c to any edge of the polygon,
where geodesic distance is the shortest path distance inside the polygon. We
give a linear-time algorithm to find a geodesic edge center of a simple
polygon. This improves on the previous O(n log n) time algorithm by Lubiw and
Naredla [European Symposium on Algorithms, 2021]. The algorithm builds on an
algorithm to find the geodesic vertex center of a simple polygon due to
Pollack, Sharir, and Rote [Discrete &amp; Computational Geometry, 1989] and an
improvement to linear time by Ahn, Barba, Bose, De Carufel, Korman, and Oh
[Discrete &amp; Computational Geometry, 2016]. The geodesic edge center can easily
be found from the geodesic farthest-edge Voronoi diagram of the polygon.
Finding that Voronoi diagram in linear time is an open question, although the
geodesic nearest edge Voronoi diagram (the medial axis) can be found in linear
time. As a first step of our geodesic edge center algorithm, we give a
linear-time algorithm to find the geodesic farthest-edge Voronoi diagram
restricted to the polygon boundary.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-20T00:30:00Z">Monday, March 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.09632'>Conflict Optimization for Binary CSP Applied to Minimum Partition into Plane Subgraphs and Graph Coloring</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lo&#xef;c Crombez, Guilherme D. da Fonseca, Florian Fontan, Yan Gerard, Aldo Gonzalez-Lorenzo, Pascal Lafourcade, Luc Libralesso, Benjamin Mom&#xe8;ge, Jack Spalding-Jamieso, Brandon Zhang, Da Wei Zheng</p><p>CG:SHOP is an annual geometric optimization challenge and the 2022 edition
proposed the problem of coloring a certain geometric graph defined by line
segments. Surprisingly, the top three teams used the same technique, called
conflict optimization. This technique has been introduced in the 2021 edition
of the challenge, to solve a coordinated motion planning problem. In this
paper, we present the technique in the more general framework of binary
constraint satisfaction problems (binary CSP). Then, the top three teams
describe their different implementations of the same underlying strategy. We
evaluate the performance of those implementations to vertex color not only
geometric graphs, but also other types of graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Crombez_L/0/1/0/all/0/1">Lo&#xef;c Crombez</a>, <a href="http://arxiv.org/find/cs/1/au:+Fonseca_G/0/1/0/all/0/1">Guilherme D. da Fonseca</a>, <a href="http://arxiv.org/find/cs/1/au:+Fontan_F/0/1/0/all/0/1">Florian Fontan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerard_Y/0/1/0/all/0/1">Yan Gerard</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Lorenzo_A/0/1/0/all/0/1">Aldo Gonzalez-Lorenzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lafourcade_P/0/1/0/all/0/1">Pascal Lafourcade</a>, <a href="http://arxiv.org/find/cs/1/au:+Libralesso_L/0/1/0/all/0/1">Luc Libralesso</a>, <a href="http://arxiv.org/find/cs/1/au:+Momege_B/0/1/0/all/0/1">Benjamin Mom&#xe8;ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Spalding_Jamieso_J/0/1/0/all/0/1">Jack Spalding-Jamieso</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Brandon Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1">Da Wei Zheng</a></p><p>CG:SHOP is an annual geometric optimization challenge and the 2022 edition
proposed the problem of coloring a certain geometric graph defined by line
segments. Surprisingly, the top three teams used the same technique, called
conflict optimization. This technique has been introduced in the 2021 edition
of the challenge, to solve a coordinated motion planning problem. In this
paper, we present the technique in the more general framework of binary
constraint satisfaction problems (binary CSP). Then, the top three teams
describe their different implementations of the same underlying strategy. We
evaluate the performance of those implementations to vertex color not only
geometric graphs, but also other types of graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-20T00:30:00Z">Monday, March 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.10028'>Connectivity with uncertainty regions given as line segments</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sergio Cabello, David Gajser</p><p>For a set $Q$ of points in the plane and a real number $\delta \ge 0$, let
$\mathbb{G}_\delta(Q)$ be the graph defined on $Q$ by connecting each pair of
points at distance at most $\delta$.
</p>
<p>We consider the connectivity of $\mathbb{G}_\delta(Q)$ in the best scenario
when the location of a few of the points is uncertain, but we know for each
uncertain point a line segment that contains it. More precisely, we consider
the following optimization problem: given a set $P$ of $n-k$ points in the
plane and a set $S$ of $k$ line segments in the plane, find the minimum
$\delta\ge 0$ with the property that we can select one point $p_s\in s$ for
each segment $s\in S$ and the corresponding graph $\mathbb{G}_\delta ( P\cup \{
p_s\mid s\in S\})$ is connected. It is known that the problem is NP-hard. We
provide an algorithm to compute exactly an optimal solution in $O(f(k) n \log
n)$ time, for a computable function $f(\cdot)$. This implies that the problem
is FPT when parameterized by $k$. The best previous algorithm is using
$O((k!)^k k^{k+1}\cdot n^{2k})$ time and computes the solution up to fixed
precision.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cabello_S/0/1/0/all/0/1">Sergio Cabello</a>, <a href="http://arxiv.org/find/cs/1/au:+Gajser_D/0/1/0/all/0/1">David Gajser</a></p><p>For a set $Q$ of points in the plane and a real number $\delta \ge 0$, let
$\mathbb{G}_\delta(Q)$ be the graph defined on $Q$ by connecting each pair of
points at distance at most $\delta$.
</p>
<p>We consider the connectivity of $\mathbb{G}_\delta(Q)$ in the best scenario
when the location of a few of the points is uncertain, but we know for each
uncertain point a line segment that contains it. More precisely, we consider
the following optimization problem: given a set $P$ of $n-k$ points in the
plane and a set $S$ of $k$ line segments in the plane, find the minimum
$\delta\ge 0$ with the property that we can select one point $p_s\in s$ for
each segment $s\in S$ and the corresponding graph $\mathbb{G}_\delta ( P\cup \{
p_s\mid s\in S\})$ is connected. It is known that the problem is NP-hard. We
provide an algorithm to compute exactly an optimal solution in $O(f(k) n \log
n)$ time, for a computable function $f(\cdot)$. This implies that the problem
is FPT when parameterized by $k$. The best previous algorithm is using
$O((k!)^k k^{k+1}\cdot n^{2k})$ time and computes the solution up to fixed
precision.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-20T00:30:00Z">Monday, March 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.09855'>High-Dimensional Approximate Nearest Neighbor Search: with Reliable and Efficient Distance Comparison Operations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jianyang Gao, Cheng Long</p><p>Approximate K nearest neighbor (AKNN) search is a fundamental and challenging
problem. We observe that in high-dimensional space, the time consumption of
nearly all AKNN algorithms is dominated by that of the distance comparison
operations (DCOs). For each operation, it scans full dimensions of an object
and thus, runs in linear time wrt the dimensionality. To speed it up, we
propose a randomized algorithm named ADSampling which runs in logarithmic time
wrt to the dimensionality for the majority of DCOs and succeeds with high
probability. In addition, based on ADSampling we develop one general and two
algorithm-specific techniques as plugins to enhance existing AKNN algorithms.
Both theoretical and empirical studies confirm that: (1) our techniques
introduce nearly no accuracy loss and (2) they consistently improve the
efficiency.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianyang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_C/0/1/0/all/0/1">Cheng Long</a></p><p>Approximate K nearest neighbor (AKNN) search is a fundamental and challenging
problem. We observe that in high-dimensional space, the time consumption of
nearly all AKNN algorithms is dominated by that of the distance comparison
operations (DCOs). For each operation, it scans full dimensions of an object
and thus, runs in linear time wrt the dimensionality. To speed it up, we
propose a randomized algorithm named ADSampling which runs in logarithmic time
wrt to the dimensionality for the majority of DCOs and succeeds with high
probability. In addition, based on ADSampling we develop one general and two
algorithm-specific techniques as plugins to enhance existing AKNN algorithms.
Both theoretical and empirical studies confirm that: (1) our techniques
introduce nearly no accuracy loss and (2) they consistently improve the
efficiency.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-20T00:30:00Z">Monday, March 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.09972'>Neighborhood Averaging for Improving Outlier Detectors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jiawei Yang, Susanto Rahardja, Pasi Franti</p><p>We hypothesize that similar objects should have similar outlier scores. To
our knowledge, all existing outlier detectors calculate the outlier score for
each object independently regardless of the outlier scores of the other
objects. Therefore, they do not guarantee that similar objects have similar
outlier scores. To verify our proposed hypothesis, we propose an outlier score
post-processing technique for outlier detectors, called neighborhood
averaging(NA), which pays attention to objects and their neighbors and
guarantees them to have more similar outlier scores than their original scores.
Given an object and its outlier score from any outlier detector, NA modifies
its outlier score by combining it with its k nearest neighbors' scores. We
demonstrate the effectivity of NA by using the well-known k-nearest neighbors
(k-NN). Experimental results show that NA improves all 10 tested baseline
detectors by 13% (from 0.70 to 0.79 AUC) on average evaluated on nine
real-world datasets. Moreover, even outlier detectors that are already based on
k-NN are also improved. The experiments also show that in some applications,
the choice of detector is no more significant when detectors are jointly used
with NA, which may pose a challenge to the generally considered idea that the
data model is the most important factor. We open our code on www.outlierNet.com
for reproducibility.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiawei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahardja_S/0/1/0/all/0/1">Susanto Rahardja</a>, <a href="http://arxiv.org/find/cs/1/au:+Franti_P/0/1/0/all/0/1">Pasi Franti</a></p><p>We hypothesize that similar objects should have similar outlier scores. To
our knowledge, all existing outlier detectors calculate the outlier score for
each object independently regardless of the outlier scores of the other
objects. Therefore, they do not guarantee that similar objects have similar
outlier scores. To verify our proposed hypothesis, we propose an outlier score
post-processing technique for outlier detectors, called neighborhood
averaging(NA), which pays attention to objects and their neighbors and
guarantees them to have more similar outlier scores than their original scores.
Given an object and its outlier score from any outlier detector, NA modifies
its outlier score by combining it with its k nearest neighbors' scores. We
demonstrate the effectivity of NA by using the well-known k-nearest neighbors
(k-NN). Experimental results show that NA improves all 10 tested baseline
detectors by 13% (from 0.70 to 0.79 AUC) on average evaluated on nine
real-world datasets. Moreover, even outlier detectors that are already based on
k-NN are also improved. The experiments also show that in some applications,
the choice of detector is no more significant when detectors are jointly used
with NA, which may pose a challenge to the generally considered idea that the
data model is the most important factor. We open our code on www.outlierNet.com
for reproducibility.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-20T00:30:00Z">Monday, March 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.10034'>A Comparison of Dijkstra's Algorithm Using Fibonacci Heaps, Binary Heaps, and Self-Balancing Binary Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rhyd Lewis</p><p>This paper describes the shortest path problem in weighted graphs and
examines the differences in efficiency that occur when using Dijkstra's
algorithm with a Fibonacci heap, binary heap, and self-balancing binary tree.
Using C++ implementations of these algorithm variants, we find that the fastest
method is not always the one that has the lowest asymptotic complexity. Reasons
for this are discussed and backed with empirical evidence.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lewis_R/0/1/0/all/0/1">Rhyd Lewis</a></p><p>This paper describes the shortest path problem in weighted graphs and
examines the differences in efficiency that occur when using Dijkstra's
algorithm with a Fibonacci heap, binary heap, and self-balancing binary tree.
Using C++ implementations of these algorithm variants, we find that the fastest
method is not always the one that has the lowest asymptotic complexity. Reasons
for this are discussed and backed with empirical evidence.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-20T00:30:00Z">Monday, March 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, March 18
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/'>CÃ©ad MÃ­le GPT</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The gift of Broadscale Linguistic Affinely Regressed Neurally Encoded Yakking By Simplified from &#8220;leprechaun robot&#8221; Neil L. is sentient. As a fantastical creature, that is his most important attribute. Today we ask whether Neil has transited to a lower or higher level of being. Actually, Neil didn&#8217;t show at all&#8212;or didn&#8217;t seem to. For many [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em><i>The gift of Broadscale Linguistic Affinely Regressed Neurally Encoded Yakking</i> </em><br />
<font color="#000000"></p>
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/leprechaunrobotsimplifieddalle/" rel="attachment wp-att-21267"><img data-attachment-id="21267" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/leprechaunrobotsimplifieddalle/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LeprechaunRobotSimplifiedDALLE" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?fit=600%2C600&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?resize=175%2C175&#038;ssl=1" alt="" width="175" height="175" class="alignright wp-image-21267" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?w=1024&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/LeprechaunRobotSimplifiedDALLE.png?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 175px) 100vw, 175px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">By <a href="https://app.simplified.com/">Simplified</a> from &#8220;leprechaun robot&#8221;</font></td>
</tr>
</tbody>
</table>
<p><p>
Neil L. is sentient. As a fantastical creature, that is his most important attribute.</p>
<p>
Today we ask whether Neil has transited to a lower or higher level of being.</p>
<p>
Actually, Neil didn&#8217;t show at all&#8212;or didn&#8217;t seem to. For many years he would visit me past midnight on St. Patrick&#8217;s Eve&#8212;that is in the wee hours of St. Patrick&#8217;s Day itself. I stayed up late again, as did Ken with the NCAA basketball games on&#8212;Princeton scored a huge upset over Arizona. Neil has visited Ken some times when I&#8217;ve been unavailable. But Ken texted me before calling it quits at 1am&#8212;no Neil there either.</p>
<p>
I turned toward my computer to switch it off and took a woozy step. The glow off the monitor became blurry and smoky. Faintly green, I thought. Then whatever I had been writing in LaTeX blinked off and my screen swelled with this:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/ceadgptopen-2/" rel="attachment wp-att-21302"><img data-attachment-id="21302" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/ceadgptopen-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CeadGPTopen-1.png?fit=962%2C227&amp;ssl=1" data-orig-size="962,227" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="CeadGPTopen" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CeadGPTopen-1.png?fit=300%2C71&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CeadGPTopen-1.png?fit=600%2C142&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CeadGPTopen-1.png?resize=481%2C114&#038;ssl=1" alt="" width="481" height="114" class="aligncenter wp-image-21302" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CeadGPTopen-1.png?w=962&amp;ssl=1 962w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CeadGPTopen-1.png?resize=300%2C71&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CeadGPTopen-1.png?resize=768%2C181&amp;ssl=1 768w" sizes="(max-width: 481px) 100vw, 481px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Start of a Chat </H2></p>
<p><p>
A big cursor blinked next to the flowery &#8216;L&#8217;. As I hesitated, a wispy voice from within susurred <i>C&eacute;ad m&iacute;le f&aacute;ilte</i>. The voice was feminine&#8212;not Neil. I recognized it as the traditional St. Patrick&#8217;s Day greeting, literally &#8220;One Hundred Thousand Welcomes&#8221;&#8212;though I had never heard it pronounced in Gaelic and the last word sounded like &#8220;faulty&#8221; to me. </p>
<p>
Not because I felt invited but because I wanted to know, I sat in my chair and typed</p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/lchat1/" rel="attachment wp-att-21272"><img data-attachment-id="21272" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/lchat1/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat1.png?fit=962%2C131&amp;ssl=1" data-orig-size="962,131" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Lchat1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat1.png?fit=300%2C41&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat1.png?fit=600%2C82&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat1.png?resize=481%2C65&#038;ssl=1" alt="" width="481" height="65" class="aligncenter wp-image-21272" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat1.png?w=962&amp;ssl=1 962w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat1.png?resize=300%2C41&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat1.png?resize=768%2C105&amp;ssl=1 768w" sizes="(max-width: 481px) 100vw, 481px" data-recalc-dims="1" /></a></p>
<p>
I wanted to type ! and ? at the same time for the question&#8212;the <a href="https://en.wikipedia.org/wiki/Interrobang">interrobang</a>. The curvy ? reminded me of the my father Jack Lipton&#8217;s <a href="https://shadycharacters.co.uk/2011/04/the-interrobang-part-1/">drawings</a> for the interrobang. I recognized the whole font: <a href="https://en.wikipedia.org/wiki/Century_type_family#Century_Schoolbook">Century Schoolbook</a>, which is found on many computers. Its bold and italic versions were drawn on by <a href="http://luc.devroye.org/fonts-26819.html">Richard Lipton</a> when designing the Benton Modern font for the Boston Globe. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/gchat1/" rel="attachment wp-att-21273"><img data-attachment-id="21273" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/gchat1/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat1.png?fit=962%2C251&amp;ssl=1" data-orig-size="962,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gchat1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat1.png?fit=300%2C78&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat1.png?fit=600%2C157&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat1.png?resize=481%2C125&#038;ssl=1" alt="" width="481" height="125" class="aligncenter wp-image-21273" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat1.png?w=962&amp;ssl=1 962w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat1.png?resize=300%2C78&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat1.png?resize=768%2C200&amp;ssl=1 768w" sizes="(max-width: 481px) 100vw, 481px" data-recalc-dims="1" /></a></p>
<p>
The link went to <a href="https://en.wikipedia.org/wiki/Century_type_family#Digital_variants">this</a> about the font design. Clicking on my name found me, indeed. I replied to correct the record:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/lchat2/" rel="attachment wp-att-21275"><img data-attachment-id="21275" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/lchat2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat2.png?fit=987%2C131&amp;ssl=1" data-orig-size="987,131" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Lchat2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat2.png?fit=300%2C40&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat2.png?fit=600%2C80&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat2.png?resize=481%2C64&#038;ssl=1" alt="" width="481" height="64" class="aligncenter wp-image-21275" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat2.png?w=987&amp;ssl=1 987w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat2.png?resize=300%2C40&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat2.png?resize=768%2C102&amp;ssl=1 768w" sizes="(max-width: 481px) 100vw, 481px" data-recalc-dims="1" /></a></p>
<p>
A big burst came on my screen.</p>
<p>
<p><H2> A Matter of Identity </H2></p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/gchat2-2/" rel="attachment wp-att-21312"><img data-attachment-id="21312" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/gchat2-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat2-1.png?fit=962%2C475&amp;ssl=1" data-orig-size="962,475" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gchat2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat2-1.png?fit=300%2C148&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat2-1.png?fit=600%2C296&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat2-1.png?resize=481%2C237&#038;ssl=1" alt="" width="481" height="237" class="aligncenter wp-image-21312" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat2-1.png?w=962&amp;ssl=1 962w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat2-1.png?resize=300%2C148&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat2-1.png?resize=768%2C379&amp;ssl=1 768w" sizes="(max-width: 481px) 100vw, 481px" data-recalc-dims="1" /></a></p>
<p>
The question made me uncomfortable. Neil L. could be quirky and challenging but he wasn&#8217;t this confrontational. I recalled reading in the Times how Bing&#8217;s chatbot <a href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html">tried</a> to get the reporter to divorce his wife. It felt like Neil&#8212;if this was Neil&#8212;was trying to get me to divorce me from <em>me</em>. </p>
<p>
I remembered that being dogged with Neil had worked before. Plus that pinning down leprechauns&#8212;trapping them&#8212;is the whole game. So pressed on with my first question.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/lchat3b/" rel="attachment wp-att-21305"><img data-attachment-id="21305" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/lchat3b/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat3B.png?fit=987%2C251&amp;ssl=1" data-orig-size="987,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Lchat3B" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat3B.png?fit=300%2C76&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat3B.png?fit=600%2C153&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat3B.png?resize=481%2C125&#038;ssl=1" alt="" width="481" height="125" class="aligncenter wp-image-21305" data-recalc-dims="1" /></a></p>
<p>
The reply came in a different medium:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/neilnotpipe-2/" rel="attachment wp-att-21297"><img data-attachment-id="21297" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/neilnotpipe-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/NeilNotPipe-1.jpg?fit=420%2C328&amp;ssl=1" data-orig-size="420,328" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1679050394&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="NeilNotPipe" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/NeilNotPipe-1.jpg?fit=300%2C234&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/NeilNotPipe-1.jpg?fit=420%2C328&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/NeilNotPipe-1.jpg?resize=280%2C218&#038;ssl=1" alt="" width="280" height="218" class="aligncenter wp-image-21297" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/NeilNotPipe-1.jpg?w=420&amp;ssl=1 420w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/NeilNotPipe-1.jpg?resize=300%2C234&amp;ssl=1 300w" sizes="(max-width: 280px) 100vw, 280px" data-recalc-dims="1" /></a></p>
<p><P><br />
I didn&#8217;t need Google Translate to realize that was &#8220;This is not a pipe&#8221; in Gaelic. It was funny&#8212;but a bot could have done it too, in magpie fashion. I got annoyed.</p>
<blockquote><p><b> </b> <em> Neil&#8212;what I meant was, could you come out and smoke your pipe? Like you usually do<b>!</b>&#8212;<b>?</b> </em>
</p></blockquote>
<p><p>
I spoke this&#8212;I realized that by typing, I had been giving in to this charade. Neil understood me perfectly well but typed his reply.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/gchat3/" rel="attachment wp-att-21281"><img data-attachment-id="21281" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/gchat3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat3.png?fit=952%2C354&amp;ssl=1" data-orig-size="952,354" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gchat3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat3.png?fit=300%2C112&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat3.png?fit=600%2C223&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat3.png?resize=476%2C177&#038;ssl=1" alt="" width="476" height="177" class="aligncenter wp-image-21281" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat3.png?w=952&amp;ssl=1 952w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat3.png?resize=300%2C112&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat3.png?resize=768%2C286&amp;ssl=1 768w" sizes="(max-width: 476px) 100vw, 476px" data-recalc-dims="1" /></a></p>
<p>
In as much as both smokes came from Neil, I guessed no difference. That satisfied me it was Neil. But I still wanted to know why he came this way&#8212;where this was all coming from.</p>
<p>
<p><H2> The Lure of Lore </H2></p>
<p><p>
Since I was asking a question <em>about</em> &#8220;Neil GPT&#8221;&#8212;and asking it <em>of</em> Neil GPT&#8212;I figured I should type it.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/lchat4-2/" rel="attachment wp-att-21290"><img data-attachment-id="21290" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/lchat4-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat4-1.png?fit=884%2C167&amp;ssl=1" data-orig-size="884,167" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Lchat4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat4-1.png?fit=300%2C57&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat4-1.png?fit=600%2C113&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat4-1.png?resize=480%2C80&#038;ssl=1" alt="" width="480" height="80" class="aligncenter wp-image-21290" data-recalc-dims="1" /></a></p>
<p>
I would have also asked the flesh-and-blood Neil whether he or his ilk had any hand in Arizona blowing a 10-point lead with 8 minutes left by going sudden stone cold. The reply was quick, as was my next query:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/gchat4-2/" rel="attachment wp-att-21291"><img data-attachment-id="21291" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/gchat4-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat4-1.png?fit=952%2C637&amp;ssl=1" data-orig-size="952,637" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gchat4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat4-1.png?fit=300%2C201&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat4-1.png?fit=600%2C401&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat4-1.png?resize=476%2C318&#038;ssl=1" alt="" width="476" height="318" class="aligncenter size-full wp-image-21291" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat4-1.png?w=952&amp;ssl=1 952w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat4-1.png?resize=300%2C201&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat4-1.png?resize=768%2C514&amp;ssl=1 768w" sizes="(max-width: 476px) 100vw, 476px" data-recalc-dims="1" /></a></p>
<p>
I don&#8217;t know whether I hit carriage-return before deciding what to type next, but Neil continued otherwise unbidden:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/gchat5/" rel="attachment wp-att-21285"><img data-attachment-id="21285" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/gchat5/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat5.png?fit=952%2C397&amp;ssl=1" data-orig-size="952,397" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gchat5" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat5.png?fit=300%2C125&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat5.png?fit=600%2C250&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat5.png?resize=476%2C198&#038;ssl=1" alt="" width="476" height="198" class="aligncenter size-full wp-image-21285" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat5.png?w=952&amp;ssl=1 952w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat5.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Gchat5.png?resize=768%2C320&amp;ssl=1 768w" sizes="(max-width: 476px) 100vw, 476px" data-recalc-dims="1" /></a></p>
<p>
Oh my. I reeled as I realized that chatbots drawing Internet intake were a whole new sluiceway for leprechaun mischief. Worse, I wondered if lore is the only thing that lasts. &#8220;Ancient Rome is but a name&#8212;the bare name is all we hold&#8221; <a href="https://it.wikipedia.org/wiki/Stat_rosa_pristina_nomine,_nomina_nuda_tenemus">wrote</a> Bernard of Cluny nine hundred years ago, meaning Rome&#8217;s lore. Overcome, I realized I could put this to Neil.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/lchat5/" rel="attachment wp-att-21286"><img data-attachment-id="21286" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/lchat5/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat5.png?fit=987%2C146&amp;ssl=1" data-orig-size="987,146" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Lchat5" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat5.png?fit=300%2C44&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat5.png?fit=600%2C89&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat5.png?resize=481%2C70&#038;ssl=1" alt="" width="481" height="70" class="aligncenter wp-image-21286" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat5.png?w=987&amp;ssl=1 987w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat5.png?resize=300%2C44&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Lchat5.png?resize=768%2C114&amp;ssl=1 768w" sizes="(max-width: 481px) 100vw, 481px" data-recalc-dims="1" /></a></p>
<p>
This time the response came straight to my ears.</p>
<blockquote><p><font color="green" size="+1"><em> Ye ask <b>me</b>, when ye and your friend have spent your whole lives quantifying the power of lore&#8212;whether written in Python or C or whatever language? And ye both have written a textbook that should procure the answer: if <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D+%5Cneq+%5Cmathsf%7BBPP%7D%7D&#038;bg=e8e8e8&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathsf{BQP} &#92;neq &#92;mathsf{BPP}}" class="latex" /> then certainly yes! </em></font>
</p></blockquote>
<p><p>
And with a flash the chat window closed, leaving only this on my screen:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/celticshamrock/" rel="attachment wp-att-21287"><img data-attachment-id="21287" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/17/cead-mile-gpt/celticshamrock/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CelticShamrock.png?fit=300%2C300&amp;ssl=1" data-orig-size="300,300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="CelticShamrock" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CelticShamrock.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CelticShamrock.png?fit=300%2C300&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CelticShamrock.png?resize=200%2C200&#038;ssl=1" alt="" width="200" height="200" class="aligncenter wp-image-21287" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CelticShamrock.png?w=300&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CelticShamrock.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/CelticShamrock.png?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 200px) 100vw, 200px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
We hope you have been having a fun St. Patrick&#8217;s Day. To judge from tonight&#8217;s fairly ridiculous upset of #1 Purdue, so have Neil and friends.</p>
<p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-18T03:39:22Z">Saturday, March 18 2023, 03:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/029'>TR23-029 |  Instance-Wise Hardness versus Randomness Tradeoffs for Arthur-Merlin Protocols | 

	Dieter van Melkebeek, 

	Nicollas Sdroievski</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A fundamental question in computational complexity asks whether probabilistic polynomial-time algorithms can be simulated deterministically with a small overhead in time (the BPP vs. P problem). A corresponding question in the realm of interactive proofs asks whether Arthur-Merlin protocols can be simulated nondeterministically with a small overhead in time (the AM vs. NP problem). Both questions are intricately tied to lower bounds. Prominently, in both settings  blackbox derandomization, i.e., derandomization through pseudo-random generators, has been shown equivalent to lower bounds for decision problems against circuits.

Recently, Chen and Tell (FOCS&#39;21) established near-equivalences in the BPP setting between whitebox derandomization and lower bounds for multi-bit functions against algorithms on almost-all inputs. The key ingredient is a technique to translate hardness into targeted hitting-sets in an instance-wise fashion based on a layered arithmetization of the evaluation of a uniform circuit computing the hard function $f$ on the given instance.

In this paper we develop a corresponding technique for Arthur-Merlin protocols and establish similar near-equivalences in the AM setting. As an example of our results in the hardness to derandomization direction, consider a length-preserving function $f$ computable by a nondeterministic algorithm that runs in time $n^a$. We show that if every Arthur-Merlin protocol that runs in time $n^c$ for $c=O(\log^2 a)$ can only compute $f$ correctly on finitely many inputs, then AM is in NP. Our main technical contribution is the construction of suitable targeted hitting-set generators based on probabilistically checkable proofs for nondeterministic computations. 

As a byproduct of our constructions, we obtain the first result indicating that whitebox derandomization of AM may be equivalent to the existence of targeted hitting-set generators for AM, an issue raised by Goldreich (LNCS, 2011). Byproducts in the average-case setting include the first uniform hardness vs. randomness tradeoffs for AM, as well as an unconditional mild derandomization result for AM.
        
        </div>

        <div class='tr-article-summary'>
        
          
          A fundamental question in computational complexity asks whether probabilistic polynomial-time algorithms can be simulated deterministically with a small overhead in time (the BPP vs. P problem). A corresponding question in the realm of interactive proofs asks whether Arthur-Merlin protocols can be simulated nondeterministically with a small overhead in time (the AM vs. NP problem). Both questions are intricately tied to lower bounds. Prominently, in both settings  blackbox derandomization, i.e., derandomization through pseudo-random generators, has been shown equivalent to lower bounds for decision problems against circuits.

Recently, Chen and Tell (FOCS&#39;21) established near-equivalences in the BPP setting between whitebox derandomization and lower bounds for multi-bit functions against algorithms on almost-all inputs. The key ingredient is a technique to translate hardness into targeted hitting-sets in an instance-wise fashion based on a layered arithmetization of the evaluation of a uniform circuit computing the hard function $f$ on the given instance.

In this paper we develop a corresponding technique for Arthur-Merlin protocols and establish similar near-equivalences in the AM setting. As an example of our results in the hardness to derandomization direction, consider a length-preserving function $f$ computable by a nondeterministic algorithm that runs in time $n^a$. We show that if every Arthur-Merlin protocol that runs in time $n^c$ for $c=O(\log^2 a)$ can only compute $f$ correctly on finitely many inputs, then AM is in NP. Our main technical contribution is the construction of suitable targeted hitting-set generators based on probabilistically checkable proofs for nondeterministic computations. 

As a byproduct of our constructions, we obtain the first result indicating that whitebox derandomization of AM may be equivalent to the existence of targeted hitting-set generators for AM, an issue raised by Goldreich (LNCS, 2011). Byproducts in the average-case setting include the first uniform hardness vs. randomness tradeoffs for AM, as well as an unconditional mild derandomization result for AM.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-18T02:34:40Z">Saturday, March 18 2023, 02:34</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, March 17
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7134'>On overexcitable children</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Update (March 21): After ChatGPT got &#8220;only&#8221; a D on economist Bryan Caplan&#8217;s midterm exam, Bryan bet against any AI getting A&#8217;s on his exams before 2029. A mere three months later, GPT-4 has earned an A on the same exam (having been trained on data that ended before the exam was made public). Though [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Update (March 21): </mark></strong>After ChatGPT got &#8220;only&#8221; a D on economist Bryan Caplan&#8217;s midterm exam, Bryan bet against any AI getting A&#8217;s on his exams before 2029.  A mere three months later, GPT-4 has earned an A on the same exam (having been trained on data that ended before the exam was made public).  Though not yet conceding the bet on a technicality, Bryan has <a href="https://betonit.substack.com/p/gpt-retakes-my-midterm-and-gets-an">publicly admitted that he was wrong</a>, breaking a string of dozens of successful predictions on his part.  As Bryan admirably writes: &#8220;when the answers change, I change my mind.&#8221;  Or as he <a href="https://twitter.com/bryan_caplan/status/1638357324489187328">put it on Twitter</a>:</p>



<blockquote class="wp-block-quote">
<p>AI enthusiasts have cried wolf for decades. GPT-4 is the wolf. I&#8217;ve seen it with my own eyes.</p>
</blockquote>



<p>And now for my own prediction: <em>this</em> is how the adoption of post-GPT AI is going to go, one user at a time having the &#8220;holy shit&#8221; reaction about an AI&#8217;s performance on a task that they personally designed and care about&#8212;leaving, in the end, only a tiny core of hardened ideologues to explain to the rest of us why it&#8217;s all just a parrot trick and none of it counts or matters.</p>



<p><strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Another Update (March 22):</mark></strong> Hereâs <a href="https://www.gatesnotes.com/The-Age-of-AI-Has-Begun">Bill Gates</a>:</p>



<blockquote class="wp-block-quote">
<p>In September, when I met with [OpenAI] again, I watched in awe as they asked GPT, their AI model, 60 multiple-choice questions from the AP Bio examâand it got 59 of them right. Then it wrote outstanding answers to six open-ended questions from the exam. We had an outside expert score the test, and GPT got a 5âthe highest possible score, and the equivalent toÂ <a rel="noreferrer noopener" href="https://apstudents.collegeboard.org/about-ap-scores/ap-score-scale-table" target="_blank">getting an A or A+</a>Â in a college-level biology course.</p>



<p>Once it had aced the test, we asked it a non-scientific question: âWhat do you say to a father with a sick child?â It wrote a thoughtful answer that was probably better than most of us in the room would have given. The whole experience was stunning.</p>



<p>I knew I had just seen the most important advance in technology since the graphical user interface.</p>
</blockquote>



<p>Just another rube whoâs been duped by Clever Hans.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Wilbur and Orville are circumnavigating the Ohio cornfield in their Flyer. Children from the nearby farms have run over to watch, point, and gawk. But their parents know better.</p>



<p>An amusing toy, nothing more. Any talk of these small, brittle, crash-prone devices ferrying passengers across continents is obvious moonshine. One doesnât know whether to laugh or cry that anyone could be so gullible.</p>



<p>Or if they <em>were</em> useful, then mostly for espionage and dropping bombs. Theyâre a negative contribution to the world, made by autistic nerds heedless of the dangers.</p>



<p>Indeed, one shouldnât even say that the toy flies: only that it seems-to-fly, or âflies.â The toy hasnât even scratched the true mystery of how the birds do it, so much more gracefully and with less energy. It sidesteps the mystery. Itâs a scientific dead-end.</p>



<p>Wilbur and Orville havenât even released the details of the toy, for reasons of supposed âcommercial secrecy.â Until they do, how could one possibly know what to make of it?</p>



<p>Wilbur and Orville are greedy, seeking only profit and acclaim. If these toys <em>were</em> to be created â and no one particularly asked for them! â then all of society should have had a stake in the endeavor.</p>



<p>Only the rich will have access to the toy. It will worsen inequality.</p>



<p>Hot-air balloons have existed for more than a century. Even if we restrict to heavier-than-air machines, Langley, Whitehead, and others built perfectly serviceable ones years ago. Or if they didnât, they clearly could have. Thereâs nothing genuinely new here.</p>



<p>Anyway, the reasons for doubt are many, varied, and subtle. But the bottom line is that, if the children only understood what their parents did, they wouldnât be running out to the cornfield to gawk like idiots.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-17T15:30:27Z">Friday, March 17 2023, 15:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.09122'>Minimum $L_\infty$ Hausdorff Distance of Point Sets Under Translation: Generalizing Klee's Measure Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Timothy M. Chan</p><p>We present a (combinatorial) algorithm with running time close to $O(n^d)$
for computing the minimum directed $L_\infty$ Hausdorff distance between two
sets of $n$ points under translations in any constant dimension $d$. This
substantially improves the best previous time bound near $O(n^{5d/4})$ by Chew,
Dor, Efrat, and Kedem from more than twenty years ago. Our solution is obtained
by a new generalization of Chan's algorithm [FOCS'13] for Klee's measure
problem.
</p>
<p>To complement this algorithmic result, we also prove a nearly matching
conditional lower bound close to $\Omega(n^d)$ for combinatorial algorithms,
under the Combinatorial $k$-Clique Hypothesis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1">Timothy M. Chan</a></p><p>We present a (combinatorial) algorithm with running time close to $O(n^d)$
for computing the minimum directed $L_\infty$ Hausdorff distance between two
sets of $n$ points under translations in any constant dimension $d$. This
substantially improves the best previous time bound near $O(n^{5d/4})$ by Chew,
Dor, Efrat, and Kedem from more than twenty years ago. Our solution is obtained
by a new generalization of Chan's algorithm [FOCS'13] for Klee's measure
problem.
</p>
<p>To complement this algorithmic result, we also prove a nearly matching
conditional lower bound close to $\Omega(n^d)$ for combinatorial algorithms,
under the Combinatorial $k$-Clique Hypothesis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-17T00:30:00Z">Friday, March 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.08904'>Process Equivalence Problems as Energy Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benjamin Bisping</p><p>We characterize all common notions of behavioral equivalence by one
6-dimensional energy game, where energies bound capabilities of an attacker
trying to tell processes apart. The defender-winning initial credits determine
exhaustively which preorders and equivalences from the (strong)
linear-time--branching-time spectrum relate processes.
</p>
<p>The time complexity is exponential, which is optimal due to trace equivalence
being covered. This complexity improves drastically on our recent approach for
deciding groups of equivalences where exponential sets of distinguishing HML
formulas are constructed on top of a super-exponential reachability game. In
experiments using the VLTS benchmarks, the algorithm performs on par with the
best similarity algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bisping_B/0/1/0/all/0/1">Benjamin Bisping</a></p><p>We characterize all common notions of behavioral equivalence by one
6-dimensional energy game, where energies bound capabilities of an attacker
trying to tell processes apart. The defender-winning initial credits determine
exhaustively which preorders and equivalences from the (strong)
linear-time--branching-time spectrum relate processes.
</p>
<p>The time complexity is exponential, which is optimal due to trace equivalence
being covered. This complexity improves drastically on our recent approach for
deciding groups of equivalences where exponential sets of distinguishing HML
formulas are constructed on top of a super-exponential reachability game. In
experiments using the VLTS benchmarks, the algorithm performs on par with the
best similarity algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-17T00:30:00Z">Friday, March 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.08937'>Shortest Paths in Portalgons</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Maarten L&#xf6;ffler, Tim Ophelders, Frank Staals, Rodrigo I. Silveira</p><p>Any surface that is intrinsically polyhedral can be represented by a
collection of simple polygons (fragments), glued along pairs of equally long
oriented edges, where each fragment is endowed with the geodesic metric arising
from its Euclidean metric. We refer to such a representation as a portalgon,
and we call two portalgons equivalent if the surfaces they represent are
isometric. We analyze the complexity of shortest paths in portalgons. We call a
fragment happy if any shortest path on the portalgon visits it at most a
constant number of times. A portalgon is happy if all of its fragments are
happy. We present an efficient algorithm to compute shortest paths on happy
portalgons. The number of times that a shortest path visits a fragment is
unbounded in general. We contrast this by showing that the intrinsic Delaunay
triangulation of any polyhedral surface corresponds to a happy portalgon. Since
computing the intrinsic Delaunay triangulation may be inefficient, we provide
an efficient algorithm to compute happy portalgons for a restricted class of
portalgons.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Loffler_M/0/1/0/all/0/1">Maarten L&#xf6;ffler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ophelders_T/0/1/0/all/0/1">Tim Ophelders</a>, <a href="http://arxiv.org/find/cs/1/au:+Staals_F/0/1/0/all/0/1">Frank Staals</a>, <a href="http://arxiv.org/find/cs/1/au:+Silveira_R/0/1/0/all/0/1">Rodrigo I. Silveira</a></p><p>Any surface that is intrinsically polyhedral can be represented by a
collection of simple polygons (fragments), glued along pairs of equally long
oriented edges, where each fragment is endowed with the geodesic metric arising
from its Euclidean metric. We refer to such a representation as a portalgon,
and we call two portalgons equivalent if the surfaces they represent are
isometric. We analyze the complexity of shortest paths in portalgons. We call a
fragment happy if any shortest path on the portalgon visits it at most a
constant number of times. A portalgon is happy if all of its fragments are
happy. We present an efficient algorithm to compute shortest paths on happy
portalgons. The number of times that a shortest path visits a fragment is
unbounded in general. We contrast this by showing that the intrinsic Delaunay
triangulation of any polyhedral surface corresponds to a happy portalgon. Since
computing the intrinsic Delaunay triangulation may be inefficient, we provide
an efficient algorithm to compute happy portalgons for a restricted class of
portalgons.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-17T00:30:00Z">Friday, March 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.09524'>Online and Dynamic Algorithms for Geometric Set Cover and Hitting Set</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arindam Khan, Aditya Lonkar, Saladi Rahul, Aditya Subramanian, Andreas Wiese</p><p>Set cover and hitting set are fundamental problems in combinatorial
optimization which are well-studied in the offline, online, and dynamic
settings. We study the geometric versions of these problems and present new
online and dynamic algorithms for them. In the online version of set cover
(resp. hitting set), $m$ sets (resp.~$n$ points) are give $n$ points (resp.~$m$
sets) arrive online, one-by-one. In the dynamic versions, points (resp. sets)
can arrive as well as depart. Our goal is to maintain a set cover (resp.
hitting set), minimizing the size of the computed solution.
</p>
<p>For online set cover for (axis-parallel) squares of arbitrary sizes, we
present a tight $O(\log n)$-competitive algorithm. In the same setting for
hitting set, we provide a tight $O(\log N)$-competitive algorithm, assuming
that all points have integral coordinates in $[0,N)^{2}$. No online algorithm
had been known for either of these settings, not even for unit squares (apart
from the known online algorithms for arbitrary set systems).
</p>
<p>For both dynamic set cover and hitting set with $d$-dimensional
hyperrectangles, we obtain $(\log m)^{O(d)}$-approximation algorithms with
$(\log m)^{O(d)}$ worst-case update time. This partially answers an open
question posed by Chan et al. [SODA'22]. Previously, no dynamic algorithms with
polylogarithmic update time were known even in the setting of squares (for
either of these problems). Our main technical contributions are an
\emph{extended quad-tree }approach and a \emph{frequency reduction} technique
that reduces geometric set cover instances to instances of general set cover
with bounded frequency.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Arindam Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lonkar_A/0/1/0/all/0/1">Aditya Lonkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahul_S/0/1/0/all/0/1">Saladi Rahul</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_A/0/1/0/all/0/1">Aditya Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiese_A/0/1/0/all/0/1">Andreas Wiese</a></p><p>Set cover and hitting set are fundamental problems in combinatorial
optimization which are well-studied in the offline, online, and dynamic
settings. We study the geometric versions of these problems and present new
online and dynamic algorithms for them. In the online version of set cover
(resp. hitting set), $m$ sets (resp.~$n$ points) are give $n$ points (resp.~$m$
sets) arrive online, one-by-one. In the dynamic versions, points (resp. sets)
can arrive as well as depart. Our goal is to maintain a set cover (resp.
hitting set), minimizing the size of the computed solution.
</p>
<p>For online set cover for (axis-parallel) squares of arbitrary sizes, we
present a tight $O(\log n)$-competitive algorithm. In the same setting for
hitting set, we provide a tight $O(\log N)$-competitive algorithm, assuming
that all points have integral coordinates in $[0,N)^{2}$. No online algorithm
had been known for either of these settings, not even for unit squares (apart
from the known online algorithms for arbitrary set systems).
</p>
<p>For both dynamic set cover and hitting set with $d$-dimensional
hyperrectangles, we obtain $(\log m)^{O(d)}$-approximation algorithms with
$(\log m)^{O(d)}$ worst-case update time. This partially answers an open
question posed by Chan et al. [SODA'22]. Previously, no dynamic algorithms with
polylogarithmic update time were known even in the setting of squares (for
either of these problems). Our main technical contributions are an
\emph{extended quad-tree }approach and a \emph{frequency reduction} technique
that reduces geometric set cover instances to instances of general set cover
with bounded frequency.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-17T00:30:00Z">Friday, March 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.08908'>Online Bipartite Matching in the Probe-Commit Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Allan Borodin, Calum MacRury</p><p>We consider the classical online bipartite matching problem in the
probe-commit model. In this problem, when an online vertex arrives, its edges
must be probed to determine if they exist, based on known edge probabilities. A
probing algorithm must respect commitment, meaning that if a probed edge
exists, it must be used in the matching. Additionally, each online vertex has a
patience constraint which limits the number of probes that can be made to an
online vertex's adjacent edges. We introduce a new configuration linear program
(LP) which we prove is a relaxation of an optimal offline probing algorithm.
Using this LP, we establish the following competitive ratios which depend on
the model used to generate the instance graph, and the arrival order of its
online vertices:
</p>
<p>- In the worst-case instance model, an optimal $1/e$ ratio when the vertices
arrive in uniformly at random (u.a.r.) order.
</p>
<p>- In the known independently distributed (i.d.) instance model, an optimal
$1/2$ ratio when the vertices arrive in adversarial order, and a $1-1/e$ ratio
when the vertices arrive in u.a.r. order.
</p>
<p>The latter two results improve upon the previous best competitive ratio of
$0.46$ due to Brubach et al. (Algorithmica 2020), which only held in the more
restricted known i.i.d. (independent and identically distributed) instance
model. Our $1-1/e$-competitive algorithm matches the best known result for the
prophet secretary matching problem due to Ehsani et al. (SODA 2018). Our
algorithm is efficient and implies a $1-1/e$ approximation ratio for the
special case when the graph is known. This is the offline stochastic matching
problem, and we improve upon the $0.42$ approximation ratio for one-sided
patience due to Pollner et al. (EC 2022), while also generalizing the $1-1/e$
approximation ratio for unbounded patience due to Gamlath et al. (SODA 2019).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Borodin_A/0/1/0/all/0/1">Allan Borodin</a>, <a href="http://arxiv.org/find/cs/1/au:+MacRury_C/0/1/0/all/0/1">Calum MacRury</a></p><p>We consider the classical online bipartite matching problem in the
probe-commit model. In this problem, when an online vertex arrives, its edges
must be probed to determine if they exist, based on known edge probabilities. A
probing algorithm must respect commitment, meaning that if a probed edge
exists, it must be used in the matching. Additionally, each online vertex has a
patience constraint which limits the number of probes that can be made to an
online vertex's adjacent edges. We introduce a new configuration linear program
(LP) which we prove is a relaxation of an optimal offline probing algorithm.
Using this LP, we establish the following competitive ratios which depend on
the model used to generate the instance graph, and the arrival order of its
online vertices:
</p>
<p>- In the worst-case instance model, an optimal $1/e$ ratio when the vertices
arrive in uniformly at random (u.a.r.) order.
</p>
<p>- In the known independently distributed (i.d.) instance model, an optimal
$1/2$ ratio when the vertices arrive in adversarial order, and a $1-1/e$ ratio
when the vertices arrive in u.a.r. order.
</p>
<p>The latter two results improve upon the previous best competitive ratio of
$0.46$ due to Brubach et al. (Algorithmica 2020), which only held in the more
restricted known i.i.d. (independent and identically distributed) instance
model. Our $1-1/e$-competitive algorithm matches the best known result for the
prophet secretary matching problem due to Ehsani et al. (SODA 2018). Our
algorithm is efficient and implies a $1-1/e$ approximation ratio for the
special case when the graph is known. This is the offline stochastic matching
problem, and we improve upon the $0.42$ approximation ratio for one-sided
patience due to Pollner et al. (EC 2022), while also generalizing the $1-1/e$
approximation ratio for unbounded patience due to Gamlath et al. (SODA 2019).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-17T00:30:00Z">Friday, March 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.09086'>Optimal Intervention on Weighted Networks via Edge Centrality</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dongyue Li, Tina Eliassi-Rad, Hongyang R. Zhang</p><p>Suppose there is a spreading process such as an infectious disease
propagating on a graph. How would we reduce the number of affected nodes in the
spreading process? This question appears in recent studies about implementing
mobility interventions on mobility networks (Chang et al. (2021)). A practical
algorithm to reduce infections on unweighted graphs is to remove edges with the
highest edge centrality score (Tong et al. (2012)), which is the product of two
adjacent nodes' eigenscores. However, mobility networks have weighted edges;
Thus, an intervention measure would involve edge-weight reduction besides edge
removal. Motivated by this example, we revisit the problem of minimizing top
eigenvalue(s) on weighted graphs by decreasing edge weights up to a fixed
budget. We observe that the edge centrality score of Tong et al. (2012) is
equal to the gradient of the largest eigenvalue of $WW^{\top}$, where $W$
denotes the weight matrix of the graph. We then present generalized edge
centrality scores as the gradient of the sum of the largest $r$ eigenvalues of
$WW^{\top}$. With this generalization, we design an iterative algorithm to find
the optimal edge-weight reduction to shrink the largest $r$ eigenvalues of
$WW^{\top}$ under a given edge-weight reduction budget. We also extend our
algorithm and its guarantee to time-varying graphs, whose weights evolve over
time. We perform a detailed empirical study to validate our approach. Our
algorithm significantly reduces the number of infections compared with existing
methods on eleven weighted networks. Further, we illustrate several properties
of our algorithm, including the benefit of choosing the rank $r$, fast
convergence to global optimum, and an almost linear runtime per iteration.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongyue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1">Tina Eliassi-Rad</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongyang R. Zhang</a></p><p>Suppose there is a spreading process such as an infectious disease
propagating on a graph. How would we reduce the number of affected nodes in the
spreading process? This question appears in recent studies about implementing
mobility interventions on mobility networks (Chang et al. (2021)). A practical
algorithm to reduce infections on unweighted graphs is to remove edges with the
highest edge centrality score (Tong et al. (2012)), which is the product of two
adjacent nodes' eigenscores. However, mobility networks have weighted edges;
Thus, an intervention measure would involve edge-weight reduction besides edge
removal. Motivated by this example, we revisit the problem of minimizing top
eigenvalue(s) on weighted graphs by decreasing edge weights up to a fixed
budget. We observe that the edge centrality score of Tong et al. (2012) is
equal to the gradient of the largest eigenvalue of $WW^{\top}$, where $W$
denotes the weight matrix of the graph. We then present generalized edge
centrality scores as the gradient of the sum of the largest $r$ eigenvalues of
$WW^{\top}$. With this generalization, we design an iterative algorithm to find
the optimal edge-weight reduction to shrink the largest $r$ eigenvalues of
$WW^{\top}$ under a given edge-weight reduction budget. We also extend our
algorithm and its guarantee to time-varying graphs, whose weights evolve over
time. We perform a detailed empirical study to validate our approach. Our
algorithm significantly reduces the number of infections compared with existing
methods on eleven weighted networks. Further, we illustrate several properties
of our algorithm, including the benefit of choosing the rank $r$, fast
convergence to global optimum, and an almost linear runtime per iteration.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-17T00:30:00Z">Friday, March 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.09205'>Addressing bias in online selection with limited budget of comparisons</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ziyad Benomar, Evgenii Chzhen, Nicolas Schreuder, Vianney Perchet</p><p>Consider a hiring process with candidates coming from different universities.
It is easy to order candidates who have the exact same background, yet it can
be challenging to compare candidates otherwise. The latter case requires
additional assessments, leading to a potentially high total cost for the hiring
organization. Given an assigned budget, what is the optimal strategy to select
the most qualified candidate? In the absence of additional information, we
model the above problem by introducing a new variant of the secretary problem.
Completely ordered candidates, belonging to distinct groups, are arriving in a
sequential manner. The decision maker has access to the partial order of the
candidates within their own group and can request access to the total order of
observed candidates by paying some price. Given a bounded budget of
comparisons, the goal of the decision-maker is to maximize the probability of
selecting the best candidate. We consider a special case of two groups with
stochastic i.i.d.\ group membership. We introduce and analyze a particular
family of algorithms that we called Dynamic Double Threshold (DDT) family,
deriving its asymptotic success probability which, given an optimal choice of
parameter converges rapidly to the theoretical upper bound of $1/e$ as the
comparison budget growth. We provide an optimal non-asymptotic memory-less
algorithm for the above problem and give numerical evidence that it belongs to
the DDT family when the number of candidates is high. We compare theoretically
and numerically the optimal algorithm with a more naive approach that is
directly inspired by the standard single-threshold secretary algorithm. Our
analysis reveals several alluring properties of the optimal algorithm. It
provides a step towards a fairer online selection process in the presence of
unidentifiable biases.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Benomar_Z/0/1/0/all/0/1">Ziyad Benomar</a>, <a href="http://arxiv.org/find/cs/1/au:+Chzhen_E/0/1/0/all/0/1">Evgenii Chzhen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schreuder_N/0/1/0/all/0/1">Nicolas Schreuder</a>, <a href="http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1">Vianney Perchet</a></p><p>Consider a hiring process with candidates coming from different universities.
It is easy to order candidates who have the exact same background, yet it can
be challenging to compare candidates otherwise. The latter case requires
additional assessments, leading to a potentially high total cost for the hiring
organization. Given an assigned budget, what is the optimal strategy to select
the most qualified candidate? In the absence of additional information, we
model the above problem by introducing a new variant of the secretary problem.
Completely ordered candidates, belonging to distinct groups, are arriving in a
sequential manner. The decision maker has access to the partial order of the
candidates within their own group and can request access to the total order of
observed candidates by paying some price. Given a bounded budget of
comparisons, the goal of the decision-maker is to maximize the probability of
selecting the best candidate. We consider a special case of two groups with
stochastic i.i.d.\ group membership. We introduce and analyze a particular
family of algorithms that we called Dynamic Double Threshold (DDT) family,
deriving its asymptotic success probability which, given an optimal choice of
parameter converges rapidly to the theoretical upper bound of $1/e$ as the
comparison budget growth. We provide an optimal non-asymptotic memory-less
algorithm for the above problem and give numerical evidence that it belongs to
the DDT family when the number of candidates is high. We compare theoretically
and numerically the optimal algorithm with a more naive approach that is
directly inspired by the standard single-threshold secretary algorithm. Our
analysis reveals several alluring properties of the optimal algorithm. It
provides a step towards a fairer online selection process in the presence of
unidentifiable biases.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-17T00:30:00Z">Friday, March 17 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/03/16/tcs-talk-wednesday-march-22-christian-coester-university-of-oxford/'>TCS+ talk: Wednesday, March 22 â Christian Coester, University of Oxford</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming March 22nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC: check your timezone!). Christian Coester from University of Oxford will speak about &#8220;The Randomized k-Server Conjecture is False!&#8221; (abstract below). You can reserve a spot as an individual or [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming March 22nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC: <a href="_wp_link_placeholder">check your timezone!</a>). <strong>Christian Coester</strong> from University of Oxford will speak about &#8220;<em>The Randomized k-Server Conjecture is False!</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: The randomized <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-server conjecture, which had been open for over three decades, states that there exists an <img src="https://s0.wp.com/latex.php?latex=O%28%5Clog+k%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28%5Clog+k%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28%5Clog+k%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(&#92;log k)" class="latex" />-competitive randomized algorithm for the k-server problem. In this talk, I will present our recent joint work with SÃ©bastien Bubeck and Yuval Rabani, where we refute this conjecture by giving a lower bound of <img src="https://s0.wp.com/latex.php?latex=%5COmega%28%28%5Clog+k%29%5E2%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5COmega%28%28%5Clog+k%29%5E2%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5COmega%28%28%5Clog+k%29%5E2%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Omega((&#92;log k)^2)" class="latex" />. Our work also settles the competitive ratio of metrical task systems to be <img src="https://s0.wp.com/latex.php?latex=%5CTheta%28%28%5Clog+n%29%5E2%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CTheta%28%28%5Clog+n%29%5E2%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CTheta%28%28%5Clog+n%29%5E2%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Theta((&#92;log n)^2)" class="latex" /> on the hardest metric spaces and <img src="https://s0.wp.com/latex.php?latex=%5CTheta%28%5Clog+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CTheta%28%5Clog+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CTheta%28%5Clog+n%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Theta(&#92;log n)" class="latex" /> on the easiest metric spaces of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> points. In particular, this yields the first improvement over the previous âcoupon collectorâ lower bound since the introduction of the model in 1987.</p></blockquote>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-17T00:27:25Z">Friday, March 17 2023, 00:27</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, March 16
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/03/identities-in-computational-complexity.html'>Identities in Computational Complexity</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Guest post by Josh Grochow</p>

<p>On the birdsite, Jay Cummings tweeted:</p>
<blockquote><p>TOP 5 IDENTITIES OF ALL TIME<br>5. You<br>4. Can't <br>3. Rank<br>2. Identities <br>1. eiÏ + 1 = 0</p>â Jay Cummings (@LongFormMath) February 8, 2023</blockquote> 

<p><br>
And it got me thinking about identities in computational complexity. At first I
thought: how many could there be? 10? After some thought and with some help,
there turn out to be quite a few more than that, and I think they make a pretty
good list!</p>

<p>Rules/comments on the list:</p><p></p>

<p></p><ul><li>Some are relatively simple alternative
characterizations, such as the various definitions of PH; most are pretty
nontrivial theorems.</li><li>I  didn't include existentially quantified oracle
results (such as "there exists A such that PA=NPA"), despite them
being some of my favorite results, because there'd be waaaay too many of those.
Probably thousands? Ask Lance. In some circles he's known as the "oracle
oracle" - as in, he's who you go ask if you want to know if a certain
oracle exists. I did include identities involving oracles
where one side of the identity didn't have an oracle, such
as EXP=NPRKt or AlmostP=BPP (AlmostP is the class of languages
L such that {A : L is in PA} has measure 1).</li><li>I also didn't include some important conditional
equalities, such as "EXP in P/poly iff EXP=MA" or "NP in BPP iff NP=RP". I guess it's not really an "identity" if it's
conditional. Games are only fun if the rules are at least a little constraining!</li><li>There are some surprising containments that either
aren't equalities, or aren't known to be equalities, and I didn't include those
either, despite some of them being very important. For example, BPP in Î£2P,
other depth reduction results (such as the chasms at depth 4 and 3), and Beigel-Tarui/Yao.</li></ul><p></p>

<p></p>

<p></p>

<p></p>

<p>One could teach a class based on a list like this and cover
a lot of good ground, but I think it'd be sad to leave out any lower bounds.
Actually, by my estimate, if you were teaching from "scratch" (say,
starting after an undergrad algorithms class), this list, and all its
implied prerequisite material, is already probably the equivalent of about 3-4
semester-long classes!</p><p></p>

<p> </p>

<p>What other complexity identities did I miss?</p>

<p> </p>

<p>Finally, without further ado, a list of (some) identities in
computational complexity:</p>

<p> </p>

<p>RPâ©coRP=ZPP </p>

<p>CLS=PPADâ©PLS  [from Paul Goldberg @paulwgoldberg]</p>

<p>quasi-poly
Frege =quasi-poly noncommutative formula IPS</p>

<p> </p>

<p>Space classes</p>

<p>PSPACE=NPSPACE </p>

<p>NL=coNL </p>

<p>L=SL</p>

<p>DET=LGapL&nbsp;(see  Update 1)</p>

<p> </p>

<p>Interactive Proofs</p>

<p>NP=PCP(O(log n), 3)</p><p>IP=PSPACE</p><p></p>

<p>AM = MAM = AMAM = ... [From Albert Atserias @atserias]</p>

<p>MIP=NEXP=PCP(poly,poly)</p>

<p> </p>

<p>Alternating Turing machines</p>

<p>Î£k P = â Pik-1 P = NPÎ£k-1 P =
Î£kTIME(poly(n)) [from Lance]</p>

<p>AP=PSPACE</p>

<p>APSPACE=EXP</p>

<p> </p>

<p>Circuit classes within P</p>

<p>NC1=5-PBP</p>

<p>ACC0=branching
programs over solvable monoids</p>

<p>P=AuxPDA</p>

<p>SAC1 = LogCFL [from Michael Levet
@Michael_Levet] </p>

<p>REG = DSPACE(O(1)) = NSPACE(O(1)) [from Levet]</p><p>
REG=DTIME1tape(o(n log n))</p>

<p>ACk = logk time on a CRCW PRAM</p>

<p>Quantum</p><p>QIP=PSPACE</p>

<p>MIP*=CE</p>

<p>QMAlog (1)=BQP [from Martin Schwarz @martin_schwarz]</p>

<p>QMAlog
(poly)=QCMA [ditto]&nbsp;</p><p>
QAC0f =
QNC0f [from Ale `Scinawa' Luongo @scinawa]</p><p>
QMA(k) =
QMA(2) for any k â¥ 2 [from Sarvagya Upadhyay @sarvagya82]</p>

<p> </p>

<p>Algebraic complexity</p>

<p>VP=VNC2 </p>

<p>VDET=VABP=VPs=VPws</p>

<p>VPe=VABP3 </p>

<p>border-VPe=border-VABP2</p>

<p>For bilinear maps, tensor rank=Theta(algebraic circuit size)</p>

<p> </p>

<p>Logical characterizations</p><p>FO=AC0</p><p></p>

<p>AC=NC=FO[poly(log)]</p><p>
âSO=NP</p><p>
P = FO + LFP on ordered structures [thanks to Lance,
and Michael Levet]</p>

<p> </p>

<p>Kolmogorov-random strings as oracles</p>

<p>EXP=NPRKt</p>

<p>PSPACE=ZPPRKS</p>

<p>P=COMPâ©{dtt reducible to RKU} </p>

<p>Almost-classes</p>

<p>AlmostP=BPP </p>

<p>AlmostNP=AM</p>

<p>AlmostPSPACE=BPexp.PSPACE</p>

<p> </p>


Updates
<ol>
    <li>March 17th update, h/t Eric Allender: Using Cook's original definition of DET as problems NC1-reducible to the integer determinant, apparently this equality is not known! See Eric's recent guest column in SIGACT News for details and a $1000-prize related to this question, along with many other interesting open questions.</li>
  
</ol><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><i>Guest post by Josh Grochow</i></p>

<p>On the birdsite, Jay Cummings <a href="https://twitter.com/LongFormMath/status/1623389627880194048" target="&lt;sub&gt;b&lt;/sub&gt;lank">tweeted</a>:</p>
<center><blockquote class="twitter-tweet"><p dir="ltr" lang="en">TOP 5 IDENTITIES OF ALL TIME<br />5. You<br />4. Can't <br />3. Rank<br />2. Identities <br />1. e<sup>iÏ</sup> + 1 = 0</p>â Jay Cummings (@LongFormMath) <a href="https://twitter.com/LongFormMath/status/1623389627880194048?ref&lt;sub&gt;s&lt;/sub&gt;rc=twsrc%5Etfw">February 8, 2023</a></blockquote> <script async="" charset="utf-8" src="https://platform.twitter.com/widgets.js"></script></center>

<p><br />
And it got me thinking about identities in computational complexity. At first I
thought: how many could there be? 10? After some thought and with some help,
there turn out to be quite a few more than that, and I think they make a pretty
good list!<o:p></o:p></p>

<p>Rules/comments on the list:</p><p><o:p></o:p></p>

<p></p><ul style="text-align: left;"><li>Some are relatively simple alternative
characterizations, such as the various definitions of PH; most are pretty
nontrivial theorems.</li><li>I  didn't include existentially quantified oracle
results (such as "there exists A such that P<sup>A</sup>=NP<sup>A</sup>"), despite them
being some of my favorite results, because there'd be waaaay too many of those.
Probably thousands? Ask Lance. In some circles he's known as the "oracle
oracle" - as in, he's who you go ask if you want to know if a certain
oracle exists. I <i>did</i> include identities involving oracles
where one side of the identity didn't have an oracle, such
as EXP=NP<sup>R<sub>Kt</sub></sup> or AlmostP=BPP (AlmostP is the class of languages
L such that {A : L is in P<sup>A</sup>} has measure 1).</li><li>I also didn't include some important conditional
equalities, such as "<a href="http://doi.org/10.1007/BF01200056" target="&lt;sub&gt;b&lt;/sub&gt;lank">EXP in P/poly iff EXP=MA</a>" or "<a href="https://doi.org/10.1016/0022-0000(88)90037-2">NP in BPP iff NP=RP</a>". I guess it's not really an "identity" if it's
conditional. Games are only fun if the rules are at least a little constraining!</li><li>There are some surprising containments that either
aren't equalities, or aren't known to be equalities, and I didn't include those
either, despite some of them being very important. For example, <a href="https://doi.org/10.1016/0020-0190(83)90044-3" target="&lt;sub&gt;b&lt;/sub&gt;lank">BPP in Î£<sub>2</sub>P</a>,
other depth reduction results (such as the <a href="https://doi.org/10.1109/FOCS.2008.32" target="&lt;sub&gt;b&lt;/sub&gt;lank">chasms at depth 4</a> and <a href="https://doi.org/10.1137/140957123" target="&lt;sub&gt;b&lt;/sub&gt;lank">3</a>), and <a href="https://doi.org/10.1007/BF01263423" target="&lt;sub&gt;b&lt;/sub&gt;lank">Beigel-Tarui</a>/<a href="https://doi.ieeecomputersociety.org/10.1109/FSCS.1990.89583" target="&lt;sub&gt;b&lt;/sub&gt;lank">Yao</a>.</li></ul><o:p></o:p><p></p>

<p><o:p></o:p></p>

<p><o:p></o:p></p>

<p><o:p></o:p></p>

<p>One could teach a class based on a list like this and cover
a lot of good ground, but I think it'd be sad to leave out any lower bounds.
Actually, by my estimate, if you were teaching from "scratch" (say,
starting after an undergrad algorithms class), this list, and all its
implied prerequisite material, is already probably the equivalent of about 3-4
semester-long classes!</p><p><o:p></o:p></p>

<p><o:p> </o:p></p>

<p>What other complexity identities did I miss?<o:p></o:p></p>

<p><o:p> </o:p></p>

<p>Finally, without further ado, a list of (some) identities in
computational complexity:<o:p></o:p></p>

<p><o:p> </o:p></p>

<p><a href="https://doi.org/10.1145/800119.803889" target="&lt;sub&gt;b&lt;/sub&gt;lank">RPâ©coRP=ZPP</a> <o:p></o:p></p>

<p><a href="https://dl.acm.org/doi/10.1145/3568163" target="&lt;sub&gt;b&lt;/sub&gt;lank">CLS=PPADâ©PLS</a>  [from Paul Goldberg @paulwgoldberg]<o:p></o:p></p>

<p><a href="https://doi.org/10.1137/16M1107632" target="&lt;sub&gt;b&lt;/sub&gt;lank">quasi-poly
Frege =quasi-poly noncommutative formula IPS</a><o:p></o:p></p>

<p><o:p> </o:p></p>

<p><b>Space classes</b><o:p></o:p></p>

<p><a href="https://doi.org/10.1016%2FS0022-0000%2870%2980006-X" target="&lt;sub&gt;b&lt;/sub&gt;lank">PSPACE=NPSPACE</a> <o:p></o:p></p>

<p><a href="https://en.wikipedia.org/wiki/Immerman%E2%80%93Szelepcs%C3%A9nyi_theorem" target="&lt;sub&gt;b&lt;/sub&gt;lank">NL=coNL</a> <o:p></o:p></p>

<p><a href="https://doi.org/10.1145%2F1391289.1391291" target="&lt;sub&gt;b&lt;/sub&gt;lank">L=SL</a><o:p></o:p></p>

<p><a href="https://complexityzoo.net/Complexity_Zoo:G#gapl" target="&lt;sub&gt;b&lt;/sub&gt;lank">DET=L<sup>GapL</sup></a>&nbsp;(see  <a href="#update1">Update 1</a>)<o:p></o:p></p>

<p><o:p> </o:p></p>

<p><b>Interactive Proofs</b><o:p></o:p></p>

<p><a href="https://en.wikipedia.org/wiki/PCP_theorem#History" target="&lt;sub&gt;b&lt;/sub&gt;lank">NP=PCP(O(log n), 3)</a></p><p><a href="https://en.wikipedia.org/wiki/IP_(complexity)" target="&lt;sub&gt;b&lt;/sub&gt;lank">IP=PSPACE</a></p><p><o:p></o:p></p>

<p><a href="https://doi.org/10.1016/0022-0000(88)90028-1" target="&lt;sub&gt;b&lt;/sub&gt;lank">AM = MAM = AMAM =</a> ... [From Albert Atserias @atserias]<o:p></o:p></p>

<p><a href="https://doi.org/10.1007/BF01200056" target="&lt;sub&gt;b&lt;/sub&gt;lank">MIP=NEXP=PCP(poly,poly)</a><o:p></o:p></p>

<p><o:p> </o:p></p>

<p><b>Alternating Turing machines</b><o:p></o:p></p>

<p><a href="https://doi.org/10.1016/0304-3975(76)90061-X" target="&lt;sub&gt;b&lt;/sub&gt;lank">Î£<sub>k</sub> P = â Pi<sub>k-1</sub> P = NP<sup>Î£<sub>k-1</sub> P</sup> =
Î£<sub>k</sub>TIME(poly(n)</a>) [from Lance]<o:p></o:p></p>

<p><a href="https://dl.acm.org/doi/10.1145/322234.322243">AP=PSPACE</a><o:p></o:p></p>

<p><a href="https://dl.acm.org/doi/10.1145/322234.322243">APSPACE=EXP</a><o:p></o:p></p>

<p><o:p> </o:p></p>

<p><b>Circuit classes within P</b><o:p></o:p></p>

<p><a href="https://doi.org/10.1016%2F0022-0000%2889%2990037-8" target="&lt;sub&gt;b&lt;/sub&gt;lank">NC<sup>1</sup>=5-PBP</a><o:p></o:p></p>

<p><a href="https://doi.org/10.1145/48014.63138" target="&lt;sub&gt;b&lt;/sub&gt;lank">ACC<sup>0</sup>=branching
programs over solvable monoids</a><o:p></o:p></p>

<p><a href="https://doi.org/10.1145/321623.321625" target="&lt;sub&gt;b&lt;/sub&gt;lank">P=AuxPDA</a><o:p></o:p></p>

<p><a href="https://doi.org/10.1016/0022-0000(91)90020-6" target="&lt;sub&gt;b&lt;/sub&gt;lank">SAC<sup>1</sup> = LogCFL</a> [from Michael Levet
@Michael_Levet] <o:p></o:p></p>

<p>REG = DSPACE(O(1)) = NSPACE(O(1)) [from Levet]</p><p>
REG=DTIME<sub>1tape</sub>(o(n log n))<o:p></o:p></p>

<p><a href="https://doi.org/10.1137/0213027">AC<sup>k</sup> = log<sup>k</sup> time on a CRCW PRAM</a><o:p></o:p></p>

<p><b>Quantum</b></p><p><a href="https://doi.org/10.1145/2049697.2049704" target="&lt;sub&gt;b&lt;/sub&gt;lank">QIP=PSPACE</a><o:p></o:p></p>

<p><a href="https://cacm.acm.org/magazines/2021/11/256404-mip-re/fulltext" target="&lt;sub&gt;b&lt;/sub&gt;lank">MIP*=CE</a><o:p></o:p></p>

<p><a href="https://doi.org/10.1007/s00037-005-0194-x" target="&lt;sub&gt;b&lt;/sub&gt;lank">QMA<sub>log</sub> (1)=BQP</a> [from Martin Schwarz @martin_schwarz]<o:p></o:p></p>

<p><a href="https://arxiv.org/abs/1108.0617" target="&lt;sub&gt;b&lt;/sub&gt;lank">QMA<sub>log</sub>
(poly)=QCMA</a> [ditto]&nbsp;</p><p>
<a href="https://doi.org/10.1007/s00037-016-0140-0" target="&lt;sub&gt;b&lt;/sub&gt;lank">QAC<sup>0</sup><sub>f</sub> =
QNC<sup>0</sup><sub>f</sub></a> [from Ale `Scinawa' Luongo @scinawa]</p><p>
<a href="https://doi.org/10.1145/2432622.2432625" target="&lt;sub&gt;b&lt;/sub&gt;lank">QMA(k) =
QMA(2)</a> for any k â¥ 2 [from Sarvagya Upadhyay @sarvagya82]<o:p></o:p></p>

<p><o:p> </o:p></p>

<p><b>Algebraic complexity</b><o:p></o:p></p>

<p><a href="http://doi.org/10.1137/0212043" target="&lt;sub&gt;b&lt;/sub&gt;lank">VP=VNC<sup>2</sup></a> <o:p></o:p></p>

<p><a href="https://doi.org/10.1016/j.jco.2006.09.006" target="&lt;sub&gt;b&lt;/sub&gt;lank">VDET=VABP=VP<sub>s</sub>=VP<sub>ws</sub></a><o:p></o:p></p>

<p><a href="https://doi.org/10.1137/0221006" target="&lt;sub&gt;b&lt;/sub&gt;lank">VP<sub>e</sub>=VABP<sub>3</sub></a> <o:p></o:p></p>

<p><a href="https://doi.org/10.1145/3209663" target="&lt;sub&gt;b&lt;/sub&gt;lank">border-VP<sub>e</sub>=border-VABP<sub>2</sub></a><o:p></o:p></p>

<p>For bilinear maps, tensor rank=Theta(algebraic circuit size)<o:p></o:p></p>

<p><o:p> </o:p></p>

<p><b>Logical characterizations</b></p><p><a href="https://doi.org/10.1007/978-1-4612-0539-5" target="&lt;sub&gt;b&lt;/sub&gt;lank">FO=AC<sup>0</sup></a></p><p><o:p></o:p></p>

<p><a href="https://doi.org/10.1007/978-1-4612-0539-5" target="&lt;sub&gt;b&lt;/sub&gt;lank">AC=NC=FO[poly(log)]</a></p><p>
<a href="https://en.wikipedia.org/wiki/Fagin%27s_theorem" target="&lt;sub&gt;b&lt;/sub&gt;lank"><span style="font-family: &quot;Cambria Math&quot;,serif; mso-bidi-font-family: &quot;Cambria Math&quot;;">â</span>SO=NP</a></p><p>
<a href="https://en.m.wikipedia.org/wiki/Fixed-point_logic#Least&lt;sub&gt;f&lt;/sub&gt;ixed-point&lt;sub&gt;l&lt;/sub&gt;ogic" target="&lt;sub&gt;b&lt;/sub&gt;lank">P = FO + LFP on ordered structures</a> [thanks to Lance,
and Michael Levet]<o:p></o:p></p>

<p><o:p> </o:p></p>

<p><b>Kolmogorov-random strings as oracles</b><o:p></o:p></p>

<p><a href="https://doi.org/10.1137/050628994" target="&lt;sub&gt;b&lt;/sub&gt;lank">EXP=NP<sup>R<sub>Kt</sub></sup></a><o:p></o:p></p>

<p><a href="https://doi.org/10.1137/050628994" target="&lt;sub&gt;b&lt;/sub&gt;lank">PSPACE=ZPP<sup>R<sub>KS</sub></sup></a><o:p></o:p></p>

<p><a href="https://doi.org/10.1016/j.apal.2005.06.003" target="&lt;sub&gt;b&lt;/sub&gt;lank">P=COMPâ©{dtt reducible to R<sub>K</sub>U}</a> <o:p></o:p></p>

<p><b>Almost-classes</b><o:p></o:p></p>

<p><a href="http://dx.doi.org/10.1137/0210008" target="&lt;sub&gt;b&lt;/sub&gt;lank">AlmostP=BPP</a> <o:p></o:p></p>

<p><a href="https://doi.org/10.1016/S0022-0000(05)80043-1" target="&lt;sub&gt;b&lt;/sub&gt;lank">AlmostNP=AM</a><o:p></o:p></p>

<p><a href="https://doi.org/10.1007/s000370050012" target="&lt;sub&gt;b&lt;/sub&gt;lank">AlmostPSPACE=BP<sup>exp</sup>.PSPACE</a><o:p></o:p></p>

<p><o:p> </o:p></p>

<hr />
Updates
<ol>
    <li id="update1">March 17th update, h/t Eric Allender: Using Cook's original definition of DET as problems NC<sup>1</sup>-reducible to the integer determinant, apparently this equality is not known! See Eric's recent <a href="https://dl.acm.org/doi/10.1145/3586165.3586175">guest column in SIGACT News</a> for details and a $1000-prize related to this question, along with many other interesting open questions.</li>
  
</ol><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-16T20:31:00Z">Thursday, March 16 2023, 20:31</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/03/16/some-news-from-a-seminar-in-cambridge/'>Some News from a Seminar in Cambridge</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          On an old problems of ErdÅs (h/t Michael Simkin and Nati Linial) Here is a somewhat mysterious announcement for a combinatorics seminar lecture at Cambridge. Which old problems of ErdÅs are we talking about? Here is a picture from the &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <h3>On an old problems of Erd<strong>Å</strong>s</h3>
<p>(h/t Michael Simkin and Nati Linial)</p>
<p>Here is a somewhat mysterious announcement for a combinatorics seminar lecture at Cambridge.</p>
<p><img loading="lazy" data-attachment-id="24010" data-permalink="https://gilkalai.wordpress.com/2023/03/16/some-news-from-a-seminar-in-cambridge/camb1/" data-orig-file="https://gilkalai.files.wordpress.com/2023/03/camb1.png" data-orig-size="562,258" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Camb1" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/03/camb1.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/03/camb1.png?w=562" class="alignnone size-full wp-image-24010" src="https://gilkalai.files.wordpress.com/2023/03/camb1.png" alt="Camb1" width="562" height="258" srcset="https://gilkalai.files.wordpress.com/2023/03/camb1.png 562w, https://gilkalai.files.wordpress.com/2023/03/camb1.png?w=150&amp;h=69 150w, https://gilkalai.files.wordpress.com/2023/03/camb1.png?w=300&amp;h=138 300w" sizes="(max-width: 562px) 100vw, 562px" /></p>
<p>Which old problems of Erd<strong>Å</strong>s are we talking about? Here is a picture from the seminar itself.</p>
<p>Â </p>
<p><img loading="lazy" data-attachment-id="24013" data-permalink="https://gilkalai.wordpress.com/2023/03/16/some-news-from-a-seminar-in-cambridge/img_1718/" data-orig-file="https://gilkalai.files.wordpress.com/2023/03/img_1718.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IMG_1718" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/03/img_1718.jpg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/03/img_1718.jpg?w=640" class="alignnone  wp-image-24013" src="https://gilkalai.files.wordpress.com/2023/03/img_1718.jpg" alt="IMG_1718" width="422" height="317" srcset="https://gilkalai.files.wordpress.com/2023/03/img_1718.jpg?w=422&amp;h=317 422w, https://gilkalai.files.wordpress.com/2023/03/img_1718.jpg?w=844&amp;h=634 844w, https://gilkalai.files.wordpress.com/2023/03/img_1718.jpg?w=150&amp;h=113 150w, https://gilkalai.files.wordpress.com/2023/03/img_1718.jpg?w=300&amp;h=225 300w, https://gilkalai.files.wordpress.com/2023/03/img_1718.jpg?w=768&amp;h=576 768w" sizes="(max-width: 422px) 100vw, 422px" /></p>
<p>Stay tuned (or try to test your intuition or guess in the comment section.)<span id="more-24009"></span></p>
<p><span style="color: #ff0000"><del>Nothing yet here.</del><br />The paper is now on the arXiv.<br /></span></p>
<h2 class="title mathjax"><a href="https://arxiv.org/abs/2303.09521">An exponential improvement for diagonal Ramsey</a></h2>
<p>Marcelo Campos, Simon Griffiths, Robert Morris, and Julian Sahasrabudhe</p>
<p>The Ramsey number <img src="https://s0.wp.com/latex.php?latex=R%28k%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R%28k%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R%28k%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R(k)" class="latex" /> is the minimum <img src="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n &#92;in &#92;mathbb N" class="latex" /> such that every red-blue colouring of the edges of the complete graph <img src="https://s0.wp.com/latex.php?latex=K_n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K_n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K_n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K_n" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> vertices contains a monochromatic copy of <img src="https://s0.wp.com/latex.php?latex=K_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K_k" class="latex" />. We prove that</p>
<p style="text-align: center"><img src="https://s0.wp.com/latex.php?latex=R%28k%29%5Cle+%284-%5Cepsilon%29%5Ek&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R%28k%29%5Cle+%284-%5Cepsilon%29%5Ek&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R%28k%29%5Cle+%284-%5Cepsilon%29%5Ek&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R(k)&#92;le (4-&#92;epsilon)^k" class="latex" /></p>
<p>for some constant <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cepsilon&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;epsilon" class="latex" />. This is the first exponential improvement over the upper bound of ErdÅs and Szekeres, proved in 1935.</p>


<p></p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-16T19:02:01Z">Thursday, March 16 2023, 19:02</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
