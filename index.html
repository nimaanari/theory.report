<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2022-12-23T07:30:33Z">Friday, December 23 2022, 07:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, December 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11627'>A Graph-Transformational Approach for Proving the Correctness of Reductions between NP-Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hans-J&#xf6;rg Kreowski (University of Bremen), Sabine Kuske (University of Bremen), Aaron Lye (University of Bremen), Aljoscha Windhorst (University of Bremen)</p><p>The complexity class NP of decision problems that can be solved
nondeterministically in polynomial time is of great theoretical and practical
importance where the notion of polynomial-time reductions between NP-problems
is a key concept for the study of NP. As many typical NP-problems are naturally
described as graph problems, they and their reductions are obvious candidates
to be investigated by graph-transformational means. In this paper, we propose
such a graph-transformational approach for proving the correctness of
reductions between NP-problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kreowski_H/0/1/0/all/0/1">Hans-J&#xf6;rg Kreowski</a> (University of Bremen), <a href="http://arxiv.org/find/cs/1/au:+Kuske_S/0/1/0/all/0/1">Sabine Kuske</a> (University of Bremen), <a href="http://arxiv.org/find/cs/1/au:+Lye_A/0/1/0/all/0/1">Aaron Lye</a> (University of Bremen), <a href="http://arxiv.org/find/cs/1/au:+Windhorst_A/0/1/0/all/0/1">Aljoscha Windhorst</a> (University of Bremen)</p><p>The complexity class NP of decision problems that can be solved
nondeterministically in polynomial time is of great theoretical and practical
importance where the notion of polynomial-time reductions between NP-problems
is a key concept for the study of NP. As many typical NP-problems are naturally
described as graph problems, they and their reductions are obvious candidates
to be investigated by graph-transformational means. In this paper, we propose
such a graph-transformational approach for proving the correctness of
reductions between NP-problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-23T01:30:00Z">Friday, December 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11834'>Real-valued affine automata compute beyond Turing machines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Abuzer Yakary&#x131;lmaz</p><p>We show that bounded-error affine finite automata recognize uncountably many
(and so some non-Turing recognizable) languages when using real-valued
transitions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yakaryilmaz_A/0/1/0/all/0/1">Abuzer Yakary&#x131;lmaz</a></p><p>We show that bounded-error affine finite automata recognize uncountably many
(and so some non-Turing recognizable) languages when using real-valued
transitions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-23T01:30:00Z">Friday, December 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11536'>Global Polynomial Level Sets for Numerical Differential Geometry of Smooth Closed Surfaces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sachin K. Thekke Veettil, Gentian Zavalani, Uwe Hernandez Acosta, Ivo F. Sbalzarini, Michael Hecht</p><p>We present a computational scheme that derives a global polynomial level set
parametrisation for smooth closed surfaces from a regular surface-point set and
prove its uniqueness. This enables us to approximate a broad class of smooth
surfaces by affine algebraic varieties. From such a global polynomial level set
parametrisation, differential-geometric quantities like mean and Gauss
curvature can be efficiently and accurately computed. Even
4$^{\text{th}}$-order terms such as the Laplacian of mean curvature are
approximates with high precision. The accuracy performance results in a gain of
computational efficiency, significantly reducing the number of surface points
required compared to classic alternatives that rely on surface meshes or
embedding grids. We mathematically derive and empirically demonstrate the
strengths and the limitations of the present approach, suggesting it to be
applicable to a large number of computational tasks in numerical differential
geometry.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Veettil_S/0/1/0/all/0/1">Sachin K. Thekke Veettil</a>, <a href="http://arxiv.org/find/math/1/au:+Zavalani_G/0/1/0/all/0/1">Gentian Zavalani</a>, <a href="http://arxiv.org/find/math/1/au:+Acosta_U/0/1/0/all/0/1">Uwe Hernandez Acosta</a>, <a href="http://arxiv.org/find/math/1/au:+Sbalzarini_I/0/1/0/all/0/1">Ivo F. Sbalzarini</a>, <a href="http://arxiv.org/find/math/1/au:+Hecht_M/0/1/0/all/0/1">Michael Hecht</a></p><p>We present a computational scheme that derives a global polynomial level set
parametrisation for smooth closed surfaces from a regular surface-point set and
prove its uniqueness. This enables us to approximate a broad class of smooth
surfaces by affine algebraic varieties. From such a global polynomial level set
parametrisation, differential-geometric quantities like mean and Gauss
curvature can be efficiently and accurately computed. Even
4$^{\text{th}}$-order terms such as the Laplacian of mean curvature are
approximates with high precision. The accuracy performance results in a gain of
computational efficiency, significantly reducing the number of surface points
required compared to classic alternatives that rely on surface meshes or
embedding grids. We mathematically derive and empirically demonstrate the
strengths and the limitations of the present approach, suggesting it to be
applicable to a large number of computational tasks in numerical differential
geometry.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-23T01:30:00Z">Friday, December 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11882'>Some Results on Approximability of Minimum Sum Vertex Cover</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aleksa Stankovi&#x107;</p><p>We study the Minimum Sum Vertex Cover problem, which asks for an ordering of
vertices in a graph that minimizes the total cover time of edges. In
particular, n vertices of the graph are visited according to an ordering, and
for each edge this induces the first time it is covered. The goal of the
problem is to find the ordering which minimizes the sum of the cover times over
all edges in the graph. In this work we give the first explicit hardness of
approximation result for Minimum Sum Vertex Cover. In particular, assuming the
Unique Games Conjecture, we show that the Minimum Sum Vertex Cover problem
cannot be approximated within 1.0748. The best approximation ratio for Minimum
Sum Vertex Cover as of now is 16/9, due to a recent work of Bansal, Batra,
Farhadi, and Tetali. We also study Minimum Sum Vertex Cover problem on regular
graphs. In particular, we show that in this case the problem is hard to
approximate within 1.0157. We also revisit an approximation algorithm for
regular graphs outlined in the work of Feige, Lov\'asz, and Tetali, to show
that Minimum Sum Vertex Cover can be approximated within 1.225 on regular
graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Stankovic_A/0/1/0/all/0/1">Aleksa Stankovi&#x107;</a></p><p>We study the Minimum Sum Vertex Cover problem, which asks for an ordering of
vertices in a graph that minimizes the total cover time of edges. In
particular, n vertices of the graph are visited according to an ordering, and
for each edge this induces the first time it is covered. The goal of the
problem is to find the ordering which minimizes the sum of the cover times over
all edges in the graph. In this work we give the first explicit hardness of
approximation result for Minimum Sum Vertex Cover. In particular, assuming the
Unique Games Conjecture, we show that the Minimum Sum Vertex Cover problem
cannot be approximated within 1.0748. The best approximation ratio for Minimum
Sum Vertex Cover as of now is 16/9, due to a recent work of Bansal, Batra,
Farhadi, and Tetali. We also study Minimum Sum Vertex Cover problem on regular
graphs. In particular, we show that in this case the problem is hard to
approximate within 1.0157. We also revisit an approximation algorithm for
regular graphs outlined in the work of Feige, Lov\'asz, and Tetali, to show
that Minimum Sum Vertex Cover can be approximated within 1.225 on regular
graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-23T01:30:00Z">Friday, December 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11408'>Adaptive and Dynamic Multi-Resolution Hashing for Pairwise Summations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lianke Qin, Aravind Reddy, Zhao Song, Zhaozhuo Xu, Danyang Zhuo</p><p>In this paper, we propose Adam-Hash: an adaptive and dynamic multi-resolution
hashing data-structure for fast pairwise summation estimation. Given a data-set
$X \subset \mathbb{R}^d$, a binary function $f:\mathbb{R}^d\times
\mathbb{R}^d\to \mathbb{R}$, and a point $y \in \mathbb{R}^d$, the Pairwise
Summation Estimate $\mathrm{PSE}_X(y) := \frac{1}{|X|} \sum_{x \in X} f(x,y)$.
For any given data-set $X$, we need to design a data-structure such that given
any query point $y \in \mathbb{R}^d$, the data-structure approximately
estimates $\mathrm{PSE}_X(y)$ in time that is sub-linear in $|X|$. Prior works
on this problem have focused exclusively on the case where the data-set is
static, and the queries are independent. In this paper, we design a
hashing-based PSE data-structure which works for the more practical
\textit{dynamic} setting in which insertions, deletions, and replacements of
points are allowed. Moreover, our proposed Adam-Hash is also robust to adaptive
PSE queries, where an adversary can choose query $q_j \in \mathbb{R}^d$
depending on the output from previous queries $q_1, q_2, \dots, q_{j-1}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1">Lianke Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_A/0/1/0/all/0/1">Aravind Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhaozhuo Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_D/0/1/0/all/0/1">Danyang Zhuo</a></p><p>In this paper, we propose Adam-Hash: an adaptive and dynamic multi-resolution
hashing data-structure for fast pairwise summation estimation. Given a data-set
$X \subset \mathbb{R}^d$, a binary function $f:\mathbb{R}^d\times
\mathbb{R}^d\to \mathbb{R}$, and a point $y \in \mathbb{R}^d$, the Pairwise
Summation Estimate $\mathrm{PSE}_X(y) := \frac{1}{|X|} \sum_{x \in X} f(x,y)$.
For any given data-set $X$, we need to design a data-structure such that given
any query point $y \in \mathbb{R}^d$, the data-structure approximately
estimates $\mathrm{PSE}_X(y)$ in time that is sub-linear in $|X|$. Prior works
on this problem have focused exclusively on the case where the data-set is
static, and the queries are independent. In this paper, we design a
hashing-based PSE data-structure which works for the more practical
\textit{dynamic} setting in which insertions, deletions, and replacements of
points are allowed. Moreover, our proposed Adam-Hash is also robust to adaptive
PSE queries, where an adversary can choose query $q_j \in \mathbb{R}^d$
depending on the output from previous queries $q_1, q_2, \dots, q_{j-1}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-23T01:30:00Z">Friday, December 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11653'>Parameterizing Path Partitions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Henning Fernau, Florent Foucaud, Kevin Mann, Utkarsh Padariya, Rajath Rao K.N</p><p>We study the algorithmic complexity of partitioning the vertex set of a given
(di)graph into a small number of paths. The Path Partition problem (PP for
short) has been studied extensively, as it includes Hamiltonian Path as a
special case. However, the natural variants where the paths are required to be
either induced, called Induced Path Partition (IPP for short) or shortest,
called Shortest Path Partition (SPP for short), have received much less
attention. Both problems are known to be NP-complete on undirected graphs; we
strengthen this by showing that they remain so even on planar bipartite
directed acyclic graphs (DAGs), and that SPP remains NP-hard on undirected
bipartite graphs. Furthermore, when parameterized by the natural parameter
"number of paths", both problems are shown to be W[1]-hard on DAGs. We also
show that SPP is in XP both for DAGs and undirected graphs for the same
parameter (while IPP is known to be NP-hard on undirected graphs, even for two
paths). On the positive side, we show that for undirected graphs, both problems
are in FPT when parameterized by the neighborhood diversity of the input graph.
Moreover, when considering the dual parameterization (graph order minus number
of paths), all three variants, IPP, SPP and PP, are shown to be in FPT for
undirected graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fernau_H/0/1/0/all/0/1">Henning Fernau</a>, <a href="http://arxiv.org/find/cs/1/au:+Foucaud_F/0/1/0/all/0/1">Florent Foucaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Mann_K/0/1/0/all/0/1">Kevin Mann</a>, <a href="http://arxiv.org/find/cs/1/au:+Padariya_U/0/1/0/all/0/1">Utkarsh Padariya</a>, <a href="http://arxiv.org/find/cs/1/au:+N_R/0/1/0/all/0/1">Rajath Rao K.N</a></p><p>We study the algorithmic complexity of partitioning the vertex set of a given
(di)graph into a small number of paths. The Path Partition problem (PP for
short) has been studied extensively, as it includes Hamiltonian Path as a
special case. However, the natural variants where the paths are required to be
either induced, called Induced Path Partition (IPP for short) or shortest,
called Shortest Path Partition (SPP for short), have received much less
attention. Both problems are known to be NP-complete on undirected graphs; we
strengthen this by showing that they remain so even on planar bipartite
directed acyclic graphs (DAGs), and that SPP remains NP-hard on undirected
bipartite graphs. Furthermore, when parameterized by the natural parameter
"number of paths", both problems are shown to be W[1]-hard on DAGs. We also
show that SPP is in XP both for DAGs and undirected graphs for the same
parameter (while IPP is known to be NP-hard on undirected graphs, even for two
paths). On the positive side, we show that for undirected graphs, both problems
are in FPT when parameterized by the neighborhood diversity of the input graph.
Moreover, when considering the dual parameterization (graph order minus number
of paths), all three variants, IPP, SPP and PP, are shown to be in FPT for
undirected graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-23T01:30:00Z">Friday, December 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11935'>GraphTango: A Hybrid Representation Format for Efficient Streaming Graph Updates and Analysis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alif Ahmed, Farzana Ahmed Siddique, Kevin Skadron</p><p>Streaming graph processing involves performing updates and analytics on a
time-evolving graph. The underlying representation format largely determines
the throughputs of these updates and analytics phases. Existing formats usually
employ variations of hash tables or adjacency lists. However,
adjacency-list-based approaches perform poorly on heavy-tailed graphs, and the
hash-based approaches suffer on short-tailed graphs. We propose GraphTango, a
hybrid format that provides excellent update and analytics throughput
regardless of the graph's degree distribution. GraphTango switches among three
different formats based on a vertex's degree: i) Low-degree vertices store the
edges directly with the neighborhood metadata, confining accesses to a single
cache line, ii) Medium-degree vertices use adjacency lists, and iii)
High-degree vertices use hash tables as well as adjacency lists. In this case,
adjacency list provides fast traversal during the analytics phase, while the
hash table provides constant-time lookups during the update phase. We further
optimized the performance by designing an open-addressing-based hash table that
fully utilizes every fetched cache line. In addition, we developed a
thread-local lock-free memory pool that allows fast growing/shrinking of the
adjacency lists and hash tables in a multi-threaded environment. We evaluated
GraphTango with the help of the SAGA-Bench framework and compared it with four
other representation formats. On average, GraphTango provides 4.5x higher
insertion throughput, 3.2x higher deletion throughput, and 1.1x higher
analytics throughput over the next best format. Furthermore, we integrated
GraphTango with the state-of-the-art graph processing frameworks DZiG and
RisGraph. Compared to the vanilla DZiG and vanilla RisGraph, [GraphTango +
DZiG] and [GraphTango + RisGraph] reduces the average batch processing time by
2.3x and 1.5x, respectively.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1">Alif Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddique_F/0/1/0/all/0/1">Farzana Ahmed Siddique</a>, <a href="http://arxiv.org/find/cs/1/au:+Skadron_K/0/1/0/all/0/1">Kevin Skadron</a></p><p>Streaming graph processing involves performing updates and analytics on a
time-evolving graph. The underlying representation format largely determines
the throughputs of these updates and analytics phases. Existing formats usually
employ variations of hash tables or adjacency lists. However,
adjacency-list-based approaches perform poorly on heavy-tailed graphs, and the
hash-based approaches suffer on short-tailed graphs. We propose GraphTango, a
hybrid format that provides excellent update and analytics throughput
regardless of the graph's degree distribution. GraphTango switches among three
different formats based on a vertex's degree: i) Low-degree vertices store the
edges directly with the neighborhood metadata, confining accesses to a single
cache line, ii) Medium-degree vertices use adjacency lists, and iii)
High-degree vertices use hash tables as well as adjacency lists. In this case,
adjacency list provides fast traversal during the analytics phase, while the
hash table provides constant-time lookups during the update phase. We further
optimized the performance by designing an open-addressing-based hash table that
fully utilizes every fetched cache line. In addition, we developed a
thread-local lock-free memory pool that allows fast growing/shrinking of the
adjacency lists and hash tables in a multi-threaded environment. We evaluated
GraphTango with the help of the SAGA-Bench framework and compared it with four
other representation formats. On average, GraphTango provides 4.5x higher
insertion throughput, 3.2x higher deletion throughput, and 1.1x higher
analytics throughput over the next best format. Furthermore, we integrated
GraphTango with the state-of-the-art graph processing frameworks DZiG and
RisGraph. Compared to the vanilla DZiG and vanilla RisGraph, [GraphTango +
DZiG] and [GraphTango + RisGraph] reduces the average batch processing time by
2.3x and 1.5x, respectively.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-23T01:30:00Z">Friday, December 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11944'>Bridge Girth: A Unifying Notion in Network Design</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Greg Bodwin, Gary Hoppenworth, Ohad Trabelsi</p><p>A classic 1993 paper by Alth\H{o}fer et al. proved a tight reduction from
spanners, emulators, and distance oracles to the extremal function $\gamma$ of
high-girth graphs. This paper initiated a large body of work in network design,
in which problems are attacked by reduction to $\gamma$ or the analogous
extremal function for other girth concepts. In this paper, we introduce and
study a new girth concept that we call the bridge girth of path systems, and we
show that it can be used to significantly expand and improve this web of
connections between girth problems and network design. We prove two kinds of
results:
</p>
<p>1) We write the maximum possible size of an $n$-node, $p$-path system with
bridge girth $&gt;k$ as $\beta(n, p, k)$, and we write a certain variant for
"ordered" path systems as $\beta^*(n, p, k)$. We identify several arguments in
the literature that implicitly show upper or lower bounds on $\beta, \beta^*$,
and we provide some polynomially improvements to these bounds. In particular,
we construct a tight lower bound for $\beta(n, p, 2)$, and we polynomially
improve the upper bounds for $\beta(n, p, 4)$ and $\beta^*(n, p, \infty)$.
</p>
<p>2) We show that many state-of-the-art results in network design can be
recovered or improved via black-box reductions to $\beta$ or $\beta^*$.
Examples include bounds for distance/reachability preservers, exact hopsets,
shortcut sets, the flow-cut gaps for directed multicut and sparsest cut, an
integrality gap for directed Steiner forest.
</p>
<p>We believe that the concept of bridge girth can lead to a stronger and more
organized map of the research area. Towards this, we leave many open problems,
related to both bridge girth reductions and extremal bounds on the size of path
systems with high bridge girth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bodwin_G/0/1/0/all/0/1">Greg Bodwin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoppenworth_G/0/1/0/all/0/1">Gary Hoppenworth</a>, <a href="http://arxiv.org/find/cs/1/au:+Trabelsi_O/0/1/0/all/0/1">Ohad Trabelsi</a></p><p>A classic 1993 paper by Alth\H{o}fer et al. proved a tight reduction from
spanners, emulators, and distance oracles to the extremal function $\gamma$ of
high-girth graphs. This paper initiated a large body of work in network design,
in which problems are attacked by reduction to $\gamma$ or the analogous
extremal function for other girth concepts. In this paper, we introduce and
study a new girth concept that we call the bridge girth of path systems, and we
show that it can be used to significantly expand and improve this web of
connections between girth problems and network design. We prove two kinds of
results:
</p>
<p>1) We write the maximum possible size of an $n$-node, $p$-path system with
bridge girth $&gt;k$ as $\beta(n, p, k)$, and we write a certain variant for
"ordered" path systems as $\beta^*(n, p, k)$. We identify several arguments in
the literature that implicitly show upper or lower bounds on $\beta, \beta^*$,
and we provide some polynomially improvements to these bounds. In particular,
we construct a tight lower bound for $\beta(n, p, 2)$, and we polynomially
improve the upper bounds for $\beta(n, p, 4)$ and $\beta^*(n, p, \infty)$.
</p>
<p>2) We show that many state-of-the-art results in network design can be
recovered or improved via black-box reductions to $\beta$ or $\beta^*$.
Examples include bounds for distance/reachability preservers, exact hopsets,
shortcut sets, the flow-cut gaps for directed multicut and sparsest cut, an
integrality gap for directed Steiner forest.
</p>
<p>We believe that the concept of bridge girth can lead to a stronger and more
organized map of the research area. Towards this, we leave many open problems,
related to both bridge girth reductions and extremal bounds on the size of path
systems with high bridge girth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-23T01:30:00Z">Friday, December 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11967'>On Differentially Private Counting on Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Kewen Wu</p><p>We study the problem of performing counting queries at different levels in
hierarchical structures while preserving individuals' privacy. We propose a new
error measure for this setting by considering a combination of multiplicative
and additive approximation to the query results. We examine known mechanisms in
differential privacy (DP) and prove their optimality in the pure-DP setting. In
the approximate-DP setting, we design new algorithms achieving significant
improvement over known ones.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1">Badih Ghazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamath_P/0/1/0/all/0/1">Pritish Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Ravi Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1">Pasin Manurangsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kewen Wu</a></p><p>We study the problem of performing counting queries at different levels in
hierarchical structures while preserving individuals' privacy. We propose a new
error measure for this setting by considering a combination of multiplicative
and additive approximation to the query results. We examine known mechanisms in
differential privacy (DP) and prove their optimality in the pure-DP setting. In
the approximate-DP setting, we design new algorithms achieving significant
improvement over known ones.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-23T01:30:00Z">Friday, December 23 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, December 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/22/assistant-associate-or-full-professor-biomedical-image-analysis-and-processing-chancellors-joint-initiative-cse-neurosurgery-at-university-of-california-san-diego-apply-by-february-1-2023/'>Assistant, Associate, or Full Professor Biomedical Image Analysis and Processing – Chancellor’s Joint Initiative: CSE/Neurosurgery at University of California – San Diego (apply by February 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The UC San Diego Department of Computer Science and Engineering (CSE) in partnership with the Department of Neurological Surgery invites applications for a tenure-track faculty position (at any level including Assistant Professor, tenured Associate Professor, and Full Professor) at the intersection of computer vision and neurosurgery. Website: cse.ucsd.edu/administration/human-resources/recruitment/faculty-position/assistant-associate-or-full-professor-1 Email: nherrera@eng.ucsd.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The UC San Diego Department of Computer Science and Engineering (CSE) in partnership with the Department of Neurological Surgery invites applications for a tenure-track faculty position (at any level including Assistant Professor, tenured Associate Professor, and Full Professor) at the intersection of computer vision and neurosurgery.</p>
<p>Website: <a href="https://cse.ucsd.edu/administration/human-resources/recruitment/faculty-position/assistant-associate-or-full-professor-1">https://cse.ucsd.edu/administration/human-resources/recruitment/faculty-position/assistant-associate-or-full-professor-1</a><br />
Email: nherrera@eng.ucsd.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T23:39:51Z">Thursday, December 22 2022, 23:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/22/postdoc-at-university-of-texas-at-austin-apply-by-february-3-2023/'>Postdoc at University of Texas at Austin (apply by February 3, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          UT Austin CS Dept invites applications for a Postdoctoral Fellowship in theoretical computer science for 2023-24 to work with David Zuckerman. Research interests should overlap with his: pseudorandomness, computational complexity, coding theory, and more. Review of applicants begins Jan. 17. Send CV &#38; research statement to email provided, and arrange for three recommendation letters to [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>UT Austin CS Dept invites applications for a Postdoctoral Fellowship in theoretical computer science for 2023-24 to work with David Zuckerman. Research interests should overlap with his: pseudorandomness, computational complexity, coding theory, and more. Review of applicants begins Jan. 17. Send CV &amp; research statement to email provided, and arrange for three recommendation letters to be sent.</p>
<p>Website: <a href="https://www.cs.utexas.edu/~diz/">https://www.cs.utexas.edu/~diz/</a><br />
Email: cyoung@cs.utexas.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T23:33:39Z">Thursday, December 22 2022, 23:33</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/22/postdoctoral-fellow-at-ut-austin-at-university-of-texas-austin-computer-science-apply-by-february-17-2023/'>Postdoctoral Fellow at UT Austin at University of Texas Austin- Computer Science (apply by February 17, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Computer Science at UT Austin invites applications for a Postdoc Fellow in theoretical computer science for the 23-24 AY to work with David Zuckerman. Research interests should overlap with: pseudorandomness, computational complexity, coding theory, and more. Review of applicants begins on Jan.17. Send CV &#38; research statement to email provided, along with 3 arranged letters [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Computer Science at UT Austin invites applications for a Postdoc Fellow in theoretical computer science for the 23-24 AY to work with David Zuckerman. Research interests should overlap with: pseudorandomness, computational complexity, coding theory, and more. Review of applicants begins on Jan.17. Send CV &amp; research statement to email provided, along with 3 arranged letters of recommendation.</p>
<p>Website: <a href="https://www.cs.utexas.edu">https://www.cs.utexas.edu</a><br />
Email: cyoung@cs.utexas.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T15:39:53Z">Thursday, December 22 2022, 15:39</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/22/postdoctoral-research-associate-in-algorithms-for-kidney-exchange-at-university-of-glasgow-apply-by-january-31-2023/'>Postdoctoral Research Associate in Algorithms for Kidney Exchange at University of Glasgow (apply by January 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          To work on the EPSRC-funded KidneyAlgo project: New Algorithms for UK and International Kidney Exchange. This position is available at the University of Glasgow, School of Computing Science, working with David Manlove. The position requires expert knowledge in the areas of algorithm design and analysis and/or operational research and combinatorial optimisation. Website: www.dcs.gla.ac.uk/~davidm/adverts/RA-advert.html Email: david.manlove@glasgow.ac.uk
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>To work on the EPSRC-funded KidneyAlgo project: New Algorithms for UK and International Kidney Exchange. This position is available at the University of Glasgow, School of Computing Science, working with David Manlove. The position requires expert knowledge in the areas of algorithm design and analysis and/or operational research and combinatorial optimisation.</p>
<p>Website: <a href="https://www.dcs.gla.ac.uk/~davidm/adverts/RA-advert.html">https://www.dcs.gla.ac.uk/~davidm/adverts/RA-advert.html</a><br />
Email: david.manlove@glasgow.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T11:46:27Z">Thursday, December 22 2022, 11:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.10582'>Sharp complexity phase transitions generated by entanglement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Soumik Ghosh, Abhinav Deshpande, Dominik Hangleiter, Alexey V. Gorshkov, Bill Fefferman</p><p>Entanglement is one of the physical properties of quantum systems responsible
for the computational hardness of simulating quantum systems. But while the
runtime of specific algorithms, notably tensor network algorithms, explicitly
depends on the amount of entanglement in the system, it is unknown whether this
connection runs deeper and entanglement can also cause inherent,
algorithm-independent complexity. In this work, we quantitatively connect the
entanglement present in certain quantum systems to the computational complexity
of simulating those systems. Moreover, we completely characterize the
entanglement and complexity as a function of a system parameter. Specifically,
we consider the task of simulating single-qubit measurements of $k$--regular
graph states on $n$ qubits. We show that, as the regularity parameter is
increased from $1$ to $n-1$, there is a sharp transition from an easy regime
with low entanglement to a hard regime with high entanglement at $k=3$, and a
transition back to easy and low entanglement at $k=n-3$. As a key technical
result, we prove a duality for the simulation complexity of regular graph
states between low and high regularity.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Ghosh_S/0/1/0/all/0/1">Soumik Ghosh</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Deshpande_A/0/1/0/all/0/1">Abhinav Deshpande</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hangleiter_D/0/1/0/all/0/1">Dominik Hangleiter</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gorshkov_A/0/1/0/all/0/1">Alexey V. Gorshkov</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Fefferman_B/0/1/0/all/0/1">Bill Fefferman</a></p><p>Entanglement is one of the physical properties of quantum systems responsible
for the computational hardness of simulating quantum systems. But while the
runtime of specific algorithms, notably tensor network algorithms, explicitly
depends on the amount of entanglement in the system, it is unknown whether this
connection runs deeper and entanglement can also cause inherent,
algorithm-independent complexity. In this work, we quantitatively connect the
entanglement present in certain quantum systems to the computational complexity
of simulating those systems. Moreover, we completely characterize the
entanglement and complexity as a function of a system parameter. Specifically,
we consider the task of simulating single-qubit measurements of $k$--regular
graph states on $n$ qubits. We show that, as the regularity parameter is
increased from $1$ to $n-1$, there is a sharp transition from an easy regime
with low entanglement to a hard regime with high entanglement at $k=3$, and a
transition back to easy and low entanglement at $k=n-3$. As a key technical
result, we prove a duality for the simulation complexity of regular graph
states between low and high regularity.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T01:30:00Z">Thursday, December 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.10631'>Vexing Vexillological Logic</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kyle Burke, Craig Tennenhouse</p><p>We define a new impartial combinatorial game, Flag Coloring, based on flood
filling. We then generalize to a graph game, and find values for many positions
on two colors. We demonstrate that the generalized game is PSPACE-complete for
two colors or more via a reduction from Avoid True, determine the outcome
classes of games based on real-world flags, and discuss remaining open
problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Burke_K/0/1/0/all/0/1">Kyle Burke</a>, <a href="http://arxiv.org/find/math/1/au:+Tennenhouse_C/0/1/0/all/0/1">Craig Tennenhouse</a></p><p>We define a new impartial combinatorial game, Flag Coloring, based on flood
filling. We then generalize to a graph game, and find values for many positions
on two colors. We demonstrate that the generalized game is PSPACE-complete for
two colors or more via a reduction from Avoid True, determine the outcome
classes of games based on real-world flags, and discuss remaining open
problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T01:30:00Z">Thursday, December 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.10740'>ToL: A Tensor of List-Based Unified Computation Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hongxiao Li, Wanling Gao, Lei Wang, Jianfeng Zhan</p><p>Previous computation models either have equivalent abilities in representing
all computations but fail to provide primitive operators for programming
complex algorithms or lack generalized expression ability to represent
newly-added computations. This article presents a unified computation model
with generalized expression ability and a concise set of primitive operators
for programming high-level algorithms. We propose a unified data abstraction --
Tensor of List, and offer a unified computation model based on Tensor of List,
which we call the ToL model (in short, ToL). ToL introduces five atomic
computations that can represent any elementary computation by finite
composition, ensured with strict formal proof. Based on ToL, we design a
pure-functional language -- ToLang. ToLang provides a concise set of primitive
operators that can be used to program complex big data and AI algorithms. Our
evaluations show ToL has generalized expression ability and a built-in
performance indicator, born with a strictly defined computation metric --
elementary operation count (EOPs), consistent with FLOPs within a small error
range.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongxiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wanling Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_J/0/1/0/all/0/1">Jianfeng Zhan</a></p><p>Previous computation models either have equivalent abilities in representing
all computations but fail to provide primitive operators for programming
complex algorithms or lack generalized expression ability to represent
newly-added computations. This article presents a unified computation model
with generalized expression ability and a concise set of primitive operators
for programming high-level algorithms. We propose a unified data abstraction --
Tensor of List, and offer a unified computation model based on Tensor of List,
which we call the ToL model (in short, ToL). ToL introduces five atomic
computations that can represent any elementary computation by finite
composition, ensured with strict formal proof. Based on ToL, we design a
pure-functional language -- ToLang. ToLang provides a concise set of primitive
operators that can be used to program complex big data and AI algorithms. Our
evaluations show ToL has generalized expression ability and a built-in
performance indicator, born with a strictly defined computation metric --
elementary operation count (EOPs), consistent with FLOPs within a small error
range.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T01:30:00Z">Thursday, December 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.10872'>Is it easier to count communities than find them?</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Cynthia Rush, Fiona Skerman, Alexander S. Wein, Dana Yang</p><p>Random graph models with community structure have been studied extensively in
the literature. For both the problems of detecting and recovering community
structure, an interesting landscape of statistical and computational phase
transitions has emerged. A natural unanswered question is: might it be possible
to infer properties of the community structure (for instance, the number and
sizes of communities) even in situations where actually finding those
communities is believed to be computationally hard? We show the answer is no.
In particular, we consider certain hypothesis testing problems between models
with different community structures, and we show (in the low-degree polynomial
framework) that testing between two options is as hard as finding the
communities.
</p>
<p>In addition, our methods give the first computational lower bounds for
testing between two different `planted' distributions, whereas previous results
have considered testing between a planted distribution and an i.i.d. `null'
distribution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Rush_C/0/1/0/all/0/1">Cynthia Rush</a>, <a href="http://arxiv.org/find/math/1/au:+Skerman_F/0/1/0/all/0/1">Fiona Skerman</a>, <a href="http://arxiv.org/find/math/1/au:+Wein_A/0/1/0/all/0/1">Alexander S. Wein</a>, <a href="http://arxiv.org/find/math/1/au:+Yang_D/0/1/0/all/0/1">Dana Yang</a></p><p>Random graph models with community structure have been studied extensively in
the literature. For both the problems of detecting and recovering community
structure, an interesting landscape of statistical and computational phase
transitions has emerged. A natural unanswered question is: might it be possible
to infer properties of the community structure (for instance, the number and
sizes of communities) even in situations where actually finding those
communities is believed to be computationally hard? We show the answer is no.
In particular, we consider certain hypothesis testing problems between models
with different community structures, and we show (in the low-degree polynomial
framework) that testing between two options is as hard as finding the
communities.
</p>
<p>In addition, our methods give the first computational lower bounds for
testing between two different `planted' distributions, whereas previous results
have considered testing between a planted distribution and an i.i.d. `null'
distribution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T01:30:00Z">Thursday, December 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11191'>Separating MAX 2-AND, MAX DI-CUT and MAX CUT</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Joshua Brakensiek, Neng Huang, Aaron Potechin, Uri Zwick</p><p>Assuming the Unique Games Conjecture (UGC), the best approximation ratio that
can be obtained in polynomial time for the MAX CUT problem is
$\alpha_{\text{CUT}}\simeq 0.87856$, obtained by the celebrated SDP-based
approximation algorithm of Goemans and Williamson. The currently best
approximation algorithm for MAX DI-CUT, i.e., the MAX CUT problem in directed
graphs, achieves a ratio of about $0.87401$, leaving open the question whether
MAX DI-CUT can be approximated as well as MAX CUT. We obtain a slightly
improved algorithm for MAX DI-CUT and a new UGC-hardness for it, showing that
$0.87439\le \alpha_{\text{DI-CUT}}\le 0.87461$, where $\alpha_{\text{DI-CUT}}$
is the best approximation ratio that can be obtained in polynomial time for MAX
DI-CUT under UGC. The new upper bound separates MAX DI-CUT from MAX CUT,
resolving a question raised by Feige and Goemans.
</p>
<p>A natural generalization of MAX DI-CUT is the MAX 2-AND problem in which each
constraint is of the form $z_1\land z_2$, where $z_1$ and $z_2$ are literals,
i.e., variables or their negations. (In MAX DI-CUT each constraint is of the
form $\bar{x}_1\land x_2$, where $x_1$ and $x_2$ are variables.) Austrin
separated MAX 2-AND from MAX CUT by showing that $\alpha_{\text{2AND}} &lt;
0.87435$ and conjectured that MAX 2-AND and MAX DI-CUT have the same
approximation ratio. Our new lower bound on MAX DI-CUT refutes this conjecture,
completing the separation of the three problems MAX 2-AND, MAX DI-CUT and MAX
CUT. We also obtain a new lower bound for MAX 2-AND, showing that
$\alpha_{\text{2AND}}\geq 0.87409$.
</p>
<p>Our upper bound on MAX DI-CUT is achieved via a simple, analytical proof. The
lower bounds on MAX DI-CUT and MAX 2-AND (the new approximation algorithms) use
experimentally-discovered distributions of rounding functions which are then
verified via computer-assisted proofs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brakensiek_J/0/1/0/all/0/1">Joshua Brakensiek</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_N/0/1/0/all/0/1">Neng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Potechin_A/0/1/0/all/0/1">Aaron Potechin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zwick_U/0/1/0/all/0/1">Uri Zwick</a></p><p>Assuming the Unique Games Conjecture (UGC), the best approximation ratio that
can be obtained in polynomial time for the MAX CUT problem is
$\alpha_{\text{CUT}}\simeq 0.87856$, obtained by the celebrated SDP-based
approximation algorithm of Goemans and Williamson. The currently best
approximation algorithm for MAX DI-CUT, i.e., the MAX CUT problem in directed
graphs, achieves a ratio of about $0.87401$, leaving open the question whether
MAX DI-CUT can be approximated as well as MAX CUT. We obtain a slightly
improved algorithm for MAX DI-CUT and a new UGC-hardness for it, showing that
$0.87439\le \alpha_{\text{DI-CUT}}\le 0.87461$, where $\alpha_{\text{DI-CUT}}$
is the best approximation ratio that can be obtained in polynomial time for MAX
DI-CUT under UGC. The new upper bound separates MAX DI-CUT from MAX CUT,
resolving a question raised by Feige and Goemans.
</p>
<p>A natural generalization of MAX DI-CUT is the MAX 2-AND problem in which each
constraint is of the form $z_1\land z_2$, where $z_1$ and $z_2$ are literals,
i.e., variables or their negations. (In MAX DI-CUT each constraint is of the
form $\bar{x}_1\land x_2$, where $x_1$ and $x_2$ are variables.) Austrin
separated MAX 2-AND from MAX CUT by showing that $\alpha_{\text{2AND}} &lt;
0.87435$ and conjectured that MAX 2-AND and MAX DI-CUT have the same
approximation ratio. Our new lower bound on MAX DI-CUT refutes this conjecture,
completing the separation of the three problems MAX 2-AND, MAX DI-CUT and MAX
CUT. We also obtain a new lower bound for MAX 2-AND, showing that
$\alpha_{\text{2AND}}\geq 0.87409$.
</p>
<p>Our upper bound on MAX DI-CUT is achieved via a simple, analytical proof. The
lower bounds on MAX DI-CUT and MAX 2-AND (the new approximation algorithms) use
experimentally-discovered distributions of rounding functions which are then
verified via computer-assisted proofs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T01:30:00Z">Thursday, December 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11247'>Count-Free Weisfeiler--Leman and Group Isomorphism</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nathaniel A. Collins, Michael Levet</p><p>We investigate the power of counting in \textsc{Group Isomorphism}. We first
leverage the count-free variant of the Weisfeiler--Leman Version I algorithm
for groups (Brachter &amp; Schweitzer, LICS 2020) in tandem with limited
non-determinism and limited counting to improve the parallel complexity of
isomorphism testing for several families of groups. In particular, we show the
following:
</p>
<p>- Let $G_{1}$ and $G_{2}$ be class $2$ $p$-groups of exponent $p$ arising
from the CFI and twisted CFI graphs (Cai, F\"urer, &amp; Immerman, Combinatorica
1992) respectively, via Mekler's construction (J. Symb. Log., 1981). If the
base graph $\Gamma_{0}$ is $3$-regular and connected, then we can distinguish
$G_{1}$ from $G_{2}$ in $\beta_{1}\textsf{MAC}^{0}(\textsf{FOLL})$. This
improves the upper bound of $\textsf{TC}^{1}$ from Brachter &amp; Schweitzer
(ibid).
</p>
<p>- Isomorphism testing between an arbitrary group $K$ and a group $G$ with an
Abelian normal Hall subgroup whose complement is an $O(1)$-generated solvable
group with solvability class poly $\log \log n$ is in
$\beta_{1}\textsf{MAC}^{0}(\textsf{FO}($poly $\log \log n))$. This notably
includes instances where the complement is an $O(1)$-generated nilpotent group.
This problem was previously known to be in $\textsf{P}$ (Qiao, Sarma, &amp; Tang,
STACS 2011) and $\textsf{L}$ (Grochow &amp; Levet, arXiv 2022).
</p>
<p>- Isomorphism testing between a direct product of simple groups and an
arbitrary group is in $\beta_{1} \textsf{MAC}^{0}(\textsf{FOLL})$. This problem
was previously shown to be in $\textsf{L}$ (Brachter &amp; Schweitzer, ESA 2022).
</p>
<p>We finally show that the $q$-ary count-free pebble game is unable to
distinguish even Abelian groups. This extends the result of Grochow &amp; Levet
(arXiv 2022), who established the result in the case of $q = 1$. The general
theme is that some counting appears necessary to place \textsc{Group
Isomorphism} into $\textsf{P}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Collins_N/0/1/0/all/0/1">Nathaniel A. Collins</a>, <a href="http://arxiv.org/find/cs/1/au:+Levet_M/0/1/0/all/0/1">Michael Levet</a></p><p>We investigate the power of counting in \textsc{Group Isomorphism}. We first
leverage the count-free variant of the Weisfeiler--Leman Version I algorithm
for groups (Brachter &amp; Schweitzer, LICS 2020) in tandem with limited
non-determinism and limited counting to improve the parallel complexity of
isomorphism testing for several families of groups. In particular, we show the
following:
</p>
<p>- Let $G_{1}$ and $G_{2}$ be class $2$ $p$-groups of exponent $p$ arising
from the CFI and twisted CFI graphs (Cai, F\"urer, &amp; Immerman, Combinatorica
1992) respectively, via Mekler's construction (J. Symb. Log., 1981). If the
base graph $\Gamma_{0}$ is $3$-regular and connected, then we can distinguish
$G_{1}$ from $G_{2}$ in $\beta_{1}\textsf{MAC}^{0}(\textsf{FOLL})$. This
improves the upper bound of $\textsf{TC}^{1}$ from Brachter &amp; Schweitzer
(ibid).
</p>
<p>- Isomorphism testing between an arbitrary group $K$ and a group $G$ with an
Abelian normal Hall subgroup whose complement is an $O(1)$-generated solvable
group with solvability class poly $\log \log n$ is in
$\beta_{1}\textsf{MAC}^{0}(\textsf{FO}($poly $\log \log n))$. This notably
includes instances where the complement is an $O(1)$-generated nilpotent group.
This problem was previously known to be in $\textsf{P}$ (Qiao, Sarma, &amp; Tang,
STACS 2011) and $\textsf{L}$ (Grochow &amp; Levet, arXiv 2022).
</p>
<p>- Isomorphism testing between a direct product of simple groups and an
arbitrary group is in $\beta_{1} \textsf{MAC}^{0}(\textsf{FOLL})$. This problem
was previously shown to be in $\textsf{L}$ (Brachter &amp; Schweitzer, ESA 2022).
</p>
<p>We finally show that the $q$-ary count-free pebble game is unable to
distinguish even Abelian groups. This extends the result of Grochow &amp; Levet
(arXiv 2022), who established the result in the case of $q = 1$. The general
theme is that some counting appears necessary to place \textsc{Group
Isomorphism} into $\textsf{P}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T01:30:00Z">Thursday, December 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.10641'>Coloring in Graph Streams via Deterministic and Adversarially Robust Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sepehr Assadi, Amit Chakrabarti, Prantar Ghosh, Manuel Stoeckl</p><p>In recent years, there has been a growing interest in solving various graph
coloring problems in the streaming model. The initial algorithms in this line
of work are all crucially randomized, raising natural questions about how
important a role randomization plays in streaming graph coloring. A couple of
very recent works have made progress on this question: they prove that
deterministic or even adversarially robust coloring algorithms (that work on
streams whose updates may depend on the algorithm's past outputs) are
considerably weaker than standard randomized ones. However, there is still a
significant gap between the upper and lower bounds for the number of colors
needed (as a function of the maximum degree $\Delta$) for robust coloring and
multipass deterministic coloring. We contribute to this line of work by proving
the following results.
</p>
<p>In the deterministic semi-streaming (i.e., $O(n \cdot \text{polylog } n)$
space) regime, we present an algorithm that achieves a combinatorially optimal
$(\Delta+1)$-coloring using $O(\log{\Delta} \log\log{\Delta})$ passes. This
improves upon the prior $O(\Delta)$-coloring algorithm of Assadi, Chen, and Sun
(STOC 2022) at the cost of only an $O(\log\log{\Delta})$ factor in the number
of passes.
</p>
<p>In the adversarially robust semi-streaming regime, we design an
$O(\Delta^{5/2})$-coloring algorithm that improves upon the previously best
$O(\Delta^{3})$-coloring algorithm of Chakrabarti, Ghosh, and Stoeckl (ITCS
2022). Further, we obtain a smooth colors/space tradeoff that improves upon
another algorithm of the said work: whereas their algorithm uses $O(\Delta^2)$
colors and $O(n\Delta^{1/2})$ space, ours, in particular, achieves
(i)~$O(\Delta^2)$ colors in $O(n\Delta^{1/3})$ space, and
(ii)~$O(\Delta^{7/4})$ colors in $O(n\Delta^{1/2})$ space.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Assadi_S/0/1/0/all/0/1">Sepehr Assadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1">Amit Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_P/0/1/0/all/0/1">Prantar Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoeckl_M/0/1/0/all/0/1">Manuel Stoeckl</a></p><p>In recent years, there has been a growing interest in solving various graph
coloring problems in the streaming model. The initial algorithms in this line
of work are all crucially randomized, raising natural questions about how
important a role randomization plays in streaming graph coloring. A couple of
very recent works have made progress on this question: they prove that
deterministic or even adversarially robust coloring algorithms (that work on
streams whose updates may depend on the algorithm's past outputs) are
considerably weaker than standard randomized ones. However, there is still a
significant gap between the upper and lower bounds for the number of colors
needed (as a function of the maximum degree $\Delta$) for robust coloring and
multipass deterministic coloring. We contribute to this line of work by proving
the following results.
</p>
<p>In the deterministic semi-streaming (i.e., $O(n \cdot \text{polylog } n)$
space) regime, we present an algorithm that achieves a combinatorially optimal
$(\Delta+1)$-coloring using $O(\log{\Delta} \log\log{\Delta})$ passes. This
improves upon the prior $O(\Delta)$-coloring algorithm of Assadi, Chen, and Sun
(STOC 2022) at the cost of only an $O(\log\log{\Delta})$ factor in the number
of passes.
</p>
<p>In the adversarially robust semi-streaming regime, we design an
$O(\Delta^{5/2})$-coloring algorithm that improves upon the previously best
$O(\Delta^{3})$-coloring algorithm of Chakrabarti, Ghosh, and Stoeckl (ITCS
2022). Further, we obtain a smooth colors/space tradeoff that improves upon
another algorithm of the said work: whereas their algorithm uses $O(\Delta^2)$
colors and $O(n\Delta^{1/2})$ space, ours, in particular, achieves
(i)~$O(\Delta^2)$ colors in $O(n\Delta^{1/3})$ space, and
(ii)~$O(\Delta^{7/4})$ colors in $O(n\Delta^{1/2})$ space.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T01:30:00Z">Thursday, December 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.10672'>A polynomial time additive estimate of the permanent using Gaussian fields</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tantrik Mukerji, Wei-Shih Yang</p><p>We present a polynomial-time randomized algorithm for estimating the
permanent of an arbitrary $M \times M$ real matrix $A$ up to an additive error.
We do this by viewing the permanent of $A$ as the expectation of a product of a
centered joint Gaussian random variables whose covariance matrix we call the
Gaussian embedding of $A$. The algorithm outputs the empirical mean $S_{N}$ of
this product after sampling from this multivariate distribution $N$ times. In
particular, after sampling $N$ samples, our algorithm runs in time $O(MN)$ with
failure probability \begin{equation*}
</p>
<p>P(|S_{N}-\text{perm}(A)| &gt; t) \leq \frac{3^{M}}{t^{2}N}\alpha^{2M}
\end{equation*} for $\alpha \geq \|A \|$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Mukerji_T/0/1/0/all/0/1">Tantrik Mukerji</a>, <a href="http://arxiv.org/find/math/1/au:+Yang_W/0/1/0/all/0/1">Wei-Shih Yang</a></p><p>We present a polynomial-time randomized algorithm for estimating the
permanent of an arbitrary $M \times M$ real matrix $A$ up to an additive error.
We do this by viewing the permanent of $A$ as the expectation of a product of a
centered joint Gaussian random variables whose covariance matrix we call the
Gaussian embedding of $A$. The algorithm outputs the empirical mean $S_{N}$ of
this product after sampling from this multivariate distribution $N$ times. In
particular, after sampling $N$ samples, our algorithm runs in time $O(MN)$ with
failure probability \begin{equation*}
</p>
<p>P(|S_{N}-\text{perm}(A)| &gt; t) \leq \frac{3^{M}}{t^{2}N}\alpha^{2M}
\end{equation*} for $\alpha \geq \|A \|$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T01:30:00Z">Thursday, December 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.10775'>Carleman linearization based efficient quantum algorithm for higher order polynomial differential equations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Amit Surana, Abeynaya Gnanasekaran, Tuhin Sahai</p><p>We present an efficient quantum algorithm to simulate nonlinear differential
equations with polynomial vector fields of arbitrary degree on quantum
platforms. Models of physical systems that are governed by ordinary
differential equations (ODEs) or partial differential equation (PDEs) can be
challenging to solve on classical computers due to high dimensionality,
stiffness, nonlinearities, and sensitive dependence to initial conditions. For
sparse $n$-dimensional linear ODEs, quantum algorithms have been developed
which can produce a quantum state proportional to the solution in poly(log(nx))
time using the quantum linear systems algorithm (QLSA). Recently, this
framework was extended to systems of nonlinear ODEs with quadratic polynomial
vector fields by applying Carleman linearization that enables the embedding of
the quadratic system into an approximate linear form. A detailed complexity
analysis was conducted which showed significant computational advantage under
certain conditions. We present an extension of this algorithm to deal with
systems of nonlinear ODEs with $k$-th degree polynomial vector fields for
arbitrary (finite) values of $k$. The steps involve: 1) mapping the $k$-th
degree polynomial ODE to a higher dimensional quadratic polynomial ODE; 2)
applying Carleman linearization to transform the quadratic ODE to an
infinite-dimensional system of linear ODEs; 3) truncating and discretizing the
linear ODE and solving using the forward Euler method and QLSA. Alternatively,
one could apply Carleman linearization directly to the $k$-th degree polynomial
ODE, resulting in a system of infinite-dimensional linear ODEs, and then apply
step 3. This solution route can be computationally more efficient. We present
detailed complexity analysis of the proposed algorithms, prove polynomial
scaling of runtime on $k$ and demonstrate the framework on an example.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Surana_A/0/1/0/all/0/1">Amit Surana</a>, <a href="http://arxiv.org/find/math/1/au:+Gnanasekaran_A/0/1/0/all/0/1">Abeynaya Gnanasekaran</a>, <a href="http://arxiv.org/find/math/1/au:+Sahai_T/0/1/0/all/0/1">Tuhin Sahai</a></p><p>We present an efficient quantum algorithm to simulate nonlinear differential
equations with polynomial vector fields of arbitrary degree on quantum
platforms. Models of physical systems that are governed by ordinary
differential equations (ODEs) or partial differential equation (PDEs) can be
challenging to solve on classical computers due to high dimensionality,
stiffness, nonlinearities, and sensitive dependence to initial conditions. For
sparse $n$-dimensional linear ODEs, quantum algorithms have been developed
which can produce a quantum state proportional to the solution in poly(log(nx))
time using the quantum linear systems algorithm (QLSA). Recently, this
framework was extended to systems of nonlinear ODEs with quadratic polynomial
vector fields by applying Carleman linearization that enables the embedding of
the quadratic system into an approximate linear form. A detailed complexity
analysis was conducted which showed significant computational advantage under
certain conditions. We present an extension of this algorithm to deal with
systems of nonlinear ODEs with $k$-th degree polynomial vector fields for
arbitrary (finite) values of $k$. The steps involve: 1) mapping the $k$-th
degree polynomial ODE to a higher dimensional quadratic polynomial ODE; 2)
applying Carleman linearization to transform the quadratic ODE to an
infinite-dimensional system of linear ODEs; 3) truncating and discretizing the
linear ODE and solving using the forward Euler method and QLSA. Alternatively,
one could apply Carleman linearization directly to the $k$-th degree polynomial
ODE, resulting in a system of infinite-dimensional linear ODEs, and then apply
step 3. This solution route can be computationally more efficient. We present
detailed complexity analysis of the proposed algorithms, prove polynomial
scaling of runtime on $k$ and demonstrate the framework on an example.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T01:30:00Z">Thursday, December 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.11221'>A Nearly Tight Bound for Fitting an Ellipsoid to Gaussian Random Points</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel M. Kane, Ilias Diakonikolas</p><p>We prove that for $c&gt;0$ a sufficiently small universal constant that a random
set of $c d^2/\log^4(d)$ independent Gaussian random points in $\mathbb{R}^d$
lie on a common ellipsoid with high probability. This nearly establishes a
conjecture of~\cite{SaundersonCPW12}, within logarithmic factors. The latter
conjecture has attracted significant attention over the past decade, due to its
connections to machine learning and sum-of-squares lower bounds for certain
statistical problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Kane_D/0/1/0/all/0/1">Daniel M. Kane</a>, <a href="http://arxiv.org/find/math/1/au:+Diakonikolas_I/0/1/0/all/0/1">Ilias Diakonikolas</a></p><p>We prove that for $c&gt;0$ a sufficiently small universal constant that a random
set of $c d^2/\log^4(d)$ independent Gaussian random points in $\mathbb{R}^d$
lie on a common ellipsoid with high probability. This nearly establishes a
conjecture of~\cite{SaundersonCPW12}, within logarithmic factors. The latter
conjecture has attracted significant attention over the past decade, due to its
connections to machine learning and sum-of-squares lower bounds for certain
statistical problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-22T01:30:00Z">Thursday, December 22 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, December 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2022/12/21/fusion-breakthrough-or-increment/'>Fusion Breakthrough or Increment?</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          And could a barrier be lurking? Her DoE page Jennifer Granholm is the U.S. Secretary of Energy in President Joe Biden&#8217;s cabinet. Last week, she said at a press conference: &#8220;Simply put, this is one of the most impressive scientific feats of the 21st century.&#8221; The &#8220;this&#8221; is the achievement by a team at Lawrence [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><font color="#0044cc"><br />
<em>And could a barrier be lurking?</em><br />
<font color="#000000"></p>
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/12/21/fusion-breakthrough-or-increment/s1_granholm_5423/" rel="attachment wp-att-20652"><img data-attachment-id="20652" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/21/fusion-breakthrough-or-increment/s1_granholm_5423/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423.jpg?fit=3451%2C4313&amp;ssl=1" data-orig-size="3451,4313" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;3.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D5&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1613489888&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;105&quot;,&quot;iso&quot;:&quot;64&quot;,&quot;shutter_speed&quot;:&quot;0.005&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="S1_GRANHOLM_5423" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423.jpg?fit=240%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423.jpg?fit=600%2C750&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423-150x150.jpg?resize=115%2C144&#038;ssl=1" alt="" width="115" height="144" class="alignright wp-image-20652" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423.jpg?resize=240%2C300&amp;ssl=1 240w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423.jpg?resize=819%2C1024&amp;ssl=1 819w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423.jpg?resize=768%2C960&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423.jpg?resize=1229%2C1536&amp;ssl=1 1229w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423.jpg?resize=1639%2C2048&amp;ssl=1 1639w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423.jpg?resize=1200%2C1500&amp;ssl=1 1200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/S1_GRANHOLM_5423.jpg?w=1800&amp;ssl=1 1800w" sizes="(max-width: 115px) 100vw, 115px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Her DoE <a href="https://www.energy.gov/person/jennifer-m-granholm">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Jennifer Granholm is the U.S. Secretary of Energy in President Joe Biden&#8217;s cabinet.  </p>
<p>
Last week, she <a href="https://www.politico.com/news/2022/12/13/fusion-breakthrough-doe-energy-sustainability-00073666">said</a> at a press conference: </p>
<blockquote><p><b> </b> <em> &#8220;Simply put, this is one of the most impressive scientific feats of the 21st century.&#8221; </em>
</p></blockquote>
<p>
The &#8220;this&#8221; is the achievement by a team at Lawrence Livermore National Laboratory (LLNL) of <a href="https://en.wikipedia.org/wiki/Fusion_ignition">fusion ignition</a>. This means that the portion of the marginal energy output of the reaction that is directed toward heating the fuel exceeds the amount needed to make and keep it hot, so that the reaction is self-sustaining. The reaction can continue as long as fuel remains.</p>
<p>
The temperature level required is about four times that of the interior of the sun. That is because nearly all the fusion output of the sun goes toward keeping the interior hot. The environment of the LLNL module has more scope for energy to escape. The sun has it easy. Lasers are used to confine and compress the fuel. How the laser input is modulated is our main discussion topic.</p>
<p>
<p><H2> Breaking a Barrier or Just Crossing a Threshold? </H2></p>
<p><p>
Terrestrial fusion has endured many disappointments in the years since the 1970s, when Ken&#8217;s freshman physics class at Princeton toured their <a href="https://en.wikipedia.org/wiki/Tokamak_Fusion_Test_Reactor">Tokamak</a> fusion reactor. Until last year, the output had never reached 3&#37; of the intensity needed for ignition. In 2016, the journal <em>Physics Today</em> published an <a href="https://physicstoday.scitation.org/do/10.1063/PT.5.1076/full/">article</a> admitting that ignition could be beyond reach. It quoted predictions by Stephen Bodner, from when he led a fusion-seeking team at the US Naval Research Laboratory in 1995, that the need to control the reaction&#8212;as a hydrogen bomb need not do&#8212;set barriers on reaching ignition.</p>
<p>
Last year, however, the National Ignition Facility (NIF) at LLNL jumped from under 3&#37; to 70&#37; of the ignition threshold. This left the question of whether further progress would be like the famous difficulty of breaking the <a href="https://en.wikipedia.org/wiki/Sound_barrier">sound barrier</a> for aircraft. It was not. The essence of last week&#8217;s announcement is that the NIF team were able to progress smoothly from 70&#37; to over 150&#37;. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2022/12/21/fusion-breakthrough-or-increment/annouce/" rel="attachment wp-att-20647"><img data-attachment-id="20647" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/21/fusion-breakthrough-or-increment/annouce/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/annouce.jpeg?fit=253%2C199&amp;ssl=1" data-orig-size="253,199" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="annouce" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/annouce.jpeg?fit=253%2C199&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/annouce.jpeg?fit=253%2C199&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/annouce.jpeg?resize=253%2C199&#038;ssl=1" alt="" width="253" height="199" class="aligncenter size-full wp-image-20647" data-recalc-dims="1" /></a></p>
<p><P><br />
Is this a breakthrough? We quote the <a href="https://bigthink.com/the-future/fusion-power-nif-hype-lose-energy/">contrast</a> made by Tom Hartsfield, a PhD physicist and writer for RealClearScience:</p>
<blockquote><p><b> </b> <em> Here we go again. In 2021, the National Ignition Facility (NIF) announced a scientific breakthrough in its pursuit of fusion power technology. One year later, they&#8217;re making another announcement, heralded as &#8220;game-changing,&#8221; &#8220;transformative,&#8221; and &#8220;a moment of history.&#8221; &#8230; This week’s announcement is an increase in fusion energy output, relative to laser energy input, from 70&#37; in 2021 to 154&#37; in 2022. This incremental, possibly incidental, progress toward thermonuclear burn is not a breakthrough. </em>
</p></blockquote>
<p><p>
This gave Ken the image of serenely crossing the event horizon of a large black hole. The traveler feels nothing special according to the standard description in relativity. Part of the recent <a href="https://en.wikipedia.org/wiki/Firewall_(physics)">firewall paradox</a> is that those observing the traveler from outside would see a catastrophe at the horizon. Well, no hint of catastrophe occurred at NIF. So any barriers must be elsewhere than the ignition point.</p>
<p>
<p><H2> The Prior Shot </H2></p>
<p><p>
Now we continue Hartsfield&#8217;s opening to his article, where we broke it at the &#8220;&#8230;&#8221; </p>
<blockquote><p><b> </b> <em> &#8230; But this is not a meaningful breakthrough for practical, commercial fusion power: NIF still drains at least 130 times more energy from the power grid than it produces. </em>
</p></blockquote>
<p><p>
The reason is that the ignition is a two-step process. To quote the LLNL&#8217;s <a href="https://lasers.llnl.gov/about/how-nif-works/anatomy-of-a-nif-shot">page</a> &#8220;Anatomy of a NIF Shot,&#8221; which is linked also by Hartsfield:</p>
<blockquote><p><b> </b> <em> &#8220;When the shot is fired, the NIF capacitor bays deliver 400 megajoules of stored electrical energy to the main laser’s 7,680 flashlamps. In the laser bays, the amplifiers increase the one-joule input from the injection laser to nearly 4 million joules of infrared laser light. In the Target Bay, the final optics assemblies convert the infrared light to about 2 million joules of high-energy ultraviolet light and direct the laser beams to the target at the center of the Target Chamber.&#8221; </em>
</p></blockquote>
<p><p>
Here is our nontechnical way to explain this:</p>
<blockquote><p><b> </b> <em> Suppose I am in the forest and need to have some wood gathered to make a fire. So I gather some wood and then I burn the wood. Say that it lasts one hour. The true measure of the fire should include the cost of gathering the wood. Not just the fact that the fire lasts one hour. </em>
</p></blockquote>
<p><p>
The initial shot is just like gathering the wood:</p>
<ol>
<li>
Energy is used to create a laser pulse. </p>
<li>
The pulse heats the target. </p>
<li>
The target makes output from fusion.
</ol>
<p>
Using Hartsfield&#8217;s numbers, part (1) is about 384 to 400 megajoules (MJ) to create the pulse. The laser pulse (2) heats the target with 2.05MJ. This creates the fusion and (3) releases 3.15MJ. This is why they say it is ignition. But it is still way off since: 	</p>
<p align=center><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++384+%5Cgg+3.15+&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="&#92;displaystyle  384 &#92;gg 3.15 " class="latex" /></p>
<p><H2> An Explodable But Reasonable Analogy </H2></p>
<p><p>
This led us&#8212;well, Ken&#8212;to wonder whether there might be an analogy to the &#8220;prior exchange&#8221; which explains the apparent paradox of quantum <a href="https://en.wikipedia.org/wiki/Superdense_coding">superdense coding</a>. We like the diagram of this in the <a href="https://qiskit.org/textbook/ch-algorithms/superdense-coding.html">treatment</a> by IBM <a href="https://qiskit.org/">Qiskit</a>:</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/12/21/fusion-breakthrough-or-increment/superdenseqiskit/" rel="attachment wp-att-20648"><img data-attachment-id="20648" data-permalink="https://rjlipton.wpcomstaging.com/2022/12/21/fusion-breakthrough-or-increment/superdenseqiskit/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?fit=2224%2C1032&amp;ssl=1" data-orig-size="2224,1032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="superdenseQiskit" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?fit=300%2C139&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?fit=600%2C278&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?resize=556%2C258&#038;ssl=1" alt="" width="556" height="258" class="aligncenter wp-image-20648" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?w=2224&amp;ssl=1 2224w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?resize=300%2C139&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?resize=1024%2C475&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?resize=768%2C356&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?resize=1536%2C713&amp;ssl=1 1536w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?resize=2048%2C950&amp;ssl=1 2048w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?resize=1200%2C557&amp;ssl=1 1200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/12/superdenseQiskit.jpg?w=1800&amp;ssl=1 1800w" sizes="(max-width: 556px) 100vw, 556px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">(We added Pauli gate legend to the diagram.)</FONT>
</td>
</tr>
</table>
<p>
Midway in the diagram, Alice chooses one of four options. Her only interaction with Bob after then is to send him one qubit. Bob is then able to tell which option she chose by measuring that qubit plus one that was previously in his possession. The <em>paradox</em> is Bob&#8217;s apparent gain of two bits of information from the transmission of only one qubit.</p>
<p>
You could say that Alice and Bob have achieved &#8220;information ignition,&#8221; getting two bits out of one after Alice&#8217;s choice. The rub is that this is only possible because of the prior entanglement of their qubits mediated by Charlie. To transmit more information at the apparent <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B2x%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{2x}" class="latex" /> rate, they have to gather more wood from Charlie. There is a hard-and-fast barrier saying this cannot be avoided: Alexander Holevo&#8217;s 1973 <a href="https://en.wikipedia.org/wiki/Holevo's_theorem">theorem</a> bounding the extraction of classical information from quantum states. </p>
<p>
Is there a substantive analogy to the situation with terrestrial fusion? Might there be a barrier to attaining the rate yielding <b>thermonuclear burn</b> needed to surmount the startup energy? Hartsfield pegs this rate at a factor of 1,000 higher, &#8220;100,000&#37;&#8221; in his terms. What we wondered most particularly is whether, under the hood of the quantum field equations governing the behavior of the supercondensed fuel, there might be a transmuted form of the limitation on information output.</p>
<p>
Ten years ago, we created the &#8220;<a href="https://rjlipton.wpcomstaging.com/2012/02/11/introducing-pip/">Pip</a>&#8221; persona as an icon for asking childlike questions. We figured the value of hitting on one novel question that is good would outshine the expenditure of energy on twenty squibs. In this case, however, we can already tell there&#8217;s no mathematically ingrained physical barrier just by thinking of a hydrogen bomb. The analogy goes boom. </p>
<p>
Bodner, now retired, has <a href="https://www.nature.com/articles/d41586-022-04440-7">evidently</a> declined to transfer his previous thoughts of barriers to controlled fusion from ignition to the burn point. He already <a href="https://www.futuretimeline.net/blog/2021/08/20-fusion-energy-future-timeline.htm">stated</a>, after last year&#8217;s breakthrough, that:</p>
<blockquote><p><b> </b> <em> &#8220;It demonstrates to the sceptic that there is nothing fundamentally wrong with the laser fusion concept. It is time for the U.S. to move ahead with a major laser fusion energy program.&#8221; </em>
</p></blockquote>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Do we need to include the gathering step too? Is that important to include in analyzing the whole physical system?</p>
<p><P><br />
[author fix and a word change]</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-21T15:23:47Z">Wednesday, December 21 2022, 15:23</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/12/complexity-year-in-review-2022.html'>Complexity Year in Review 2022</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Complexity result of the year goes to</p><p></p>NP-Hardness of Learning Programs and Partial MCSPby&nbsp;Shuichi Hirahara<p></p><p>Consider the following version of Occam's Razor: find the smallest program consistent with your data. Hirahara shows that solving this problem is randomly hard for NP. The paper also takes a major step to understanding the complexity of the Minimum Circuit Size Problem, a major area of study in computational complexity over the past few years.</p><p>Runner up goes to&nbsp;Maximum Flow and Minimum-Cost Flow in Almost-Linear Time by&nbsp;Li Chen, Rasmus Kyng, Yang P. Liu, Richard Peng, Maximilian Probst Gutenberg and Sushant Sachdeva. The title speaks for itself.</p><p>In the computing world, 2022 has become the year of machine learning taking over. It seemed like almost every week we saw a new ML breakthrough from AlphaTensor, improving on Strassen, to AlphaFold mapping out the structure of nearly every known protein. AI generating new text, pictures and code and playing Diplomacy. Not to mention ChatGPT that will disrupt education and everything else. Enough to almost make us forget the tech layoffs and the downfall of Twitter as we know it.</p><p>We remember Fred Brooks,&nbsp;Juris&nbsp;Hartmanis, Joel Moses, Rolf Niedermeier, Alexander Vardy,&nbsp;Gerhard Woeginger&nbsp;and Fastlane.</p><p>Thanks to our guest posters Boaz Barak, David and Tomas Harris,&nbsp;Jonathan Katz,&nbsp;David Marcus,&nbsp;Jelani Nelson,&nbsp;Prahalad Rajkumar&nbsp;and&nbsp;Aravind Srinivasan.</p><p>Bill and I wish you the best for the holidays and look forward to keeping you informed and entertained with minimal AI assistance.&nbsp;</p><p><br></p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Complexity result of the year goes to</p><p></p><div style="text-align: center;"><a href="https://eccc.weizmann.ac.il/report/2022/119/">NP-Hardness of Learning Programs and Partial MCSP</a></div><div style="text-align: center;">by&nbsp;Shuichi Hirahara</div><p></p><p>Consider the following version of Occam's Razor: find the smallest program consistent with your data. Hirahara shows that solving this problem is randomly hard for NP. The paper also takes a major step to understanding the complexity of the Minimum Circuit Size Problem, a major area of study in computational complexity over the past few years.</p><p>Runner up goes to&nbsp;<a href="https://arxiv.org/abs/2203.00671">Maximum Flow and Minimum-Cost Flow in Almost-Linear Time</a> by&nbsp;Li Chen, Rasmus Kyng, Yang P. Liu, Richard Peng, Maximilian Probst Gutenberg and Sushant Sachdeva. The title speaks for itself.</p><p>In the computing world, 2022 has become the year of machine learning taking over. It seemed like almost every week we saw a new ML breakthrough from <a href="https://blog.computationalcomplexity.org/2022/10/alpha-tensor.html">AlphaTensor</a>, improving on Strassen, to AlphaFold <a href="https://alphafold.ebi.ac.uk/">mapping out the structure</a> of nearly every known protein. AI generating new text, pictures and code and playing <a href="https://ai.facebook.com/blog/cicero-ai-negotiates-persuades-and-cooperates-with-people/">Diplomacy</a>. Not to mention <a href="https://chat.openai.com/chat">ChatGPT</a> that will disrupt education and everything else. Enough to almost make us forget the <a href="https://blog.computationalcomplexity.org/2022/11/fall-jobs-post-2022.html">tech layoffs</a> and the downfall of Twitter as we know it.</p><p>We remember <a href="https://www.nytimes.com/2022/11/23/technology/frederick-p-brooks-jr-dead.html?unlocked_article_code=BBDe9BcCNRyPTgZOHJ9V2JfNmu4pwaczrViNzLvfoMcuWkbMsLHq3nJ56C1wapGpy-67kPhePbn4SbPwD4qMkJbX1lYEMoTf6dw-Ka1jWcVKY-OYPcgOHjHJqBktsPGYnCyjzLRbVA9kTF56ZAvHYE0wfHGmXaaUX_vLuC_s1YylJf7Pgzh_uJQL8hgW-W2WyntDip7F4J3b1xyNMg2sgeLIsii4PJWKhCryHAjlJXrX_0bNWZu_0-jmMKCtEj2kuZJIX18essaURuglVMHDLzyvLsbp7J9rI_gsiDcieRfcTuVXiKNEogK1FUaShtH6cblMHITpEZtFqyrtq5sj1e5GszPzIFw&amp;smid=share-url">Fred</a> <a href="https://blog.computationalcomplexity.org/2021/05/the-mythical-man-month-hen-day-and-cat.html">Brooks</a>,&nbsp;<a href="https://blog.computationalcomplexity.org/2022/07/juris-hartmanis-passed-away-on-july-29.html">Juris</a>&nbsp;<a href="https://blog.computationalcomplexity.org/2022/08/the-godfather-of-complexity.html">Hartmanis</a>, <a href="https://news.mit.edu/2022/joel-moses-institute-professor-emeritus-dies-0531">Joel Moses</a>, <a href="https://www.akt.tu-berlin.de/index.php?id=110570">Rolf Niedermeier</a>, <a href="https://www.itsoc.org/news/alexander-vardy-distinguished-coding-theorist-passed-away">Alexander Vardy</a>,&nbsp;<a href="https://www.utwente.nl/en/eemcs/damut/news/2022/4/541169/in-memoriam-prof.-dr.-gerhard-woeginger">Gerhard Woeginger</a>&nbsp;and <a href="https://www.research.gov/research-web/content/fldecomm">Fastlane</a>.</p><p>Thanks to our guest posters <a href="https://blog.computationalcomplexity.org/2022/01/on-california-math-framework.html">Boaz Barak</a>, <a href="https://blog.computationalcomplexity.org/2022/04/the-roeder-problem-was-solved-before-i.html">David and Tomas Harris</a>,&nbsp;<a href="https://blog.computationalcomplexity.org/2022/08/the-nist-competition-for-post-quantum.html">Jonathan Katz</a>,&nbsp;<a href="https://blog.computationalcomplexity.org/2022/10/does-physics-nobel-prize-winner.html">David</a> <a href="https://blog.computationalcomplexity.org/2022/02/i-will-be-on-instagramif-you-have-two_24.html">Marcus</a>,&nbsp;<a href="https://blog.computationalcomplexity.org/2022/01/on-california-math-framework.html">Jelani Nelson</a>,&nbsp;<a href="https://blog.computationalcomplexity.org/2022/06/guest-post-by-prahalad-rajkumar-advice.html">Prahalad Rajkumar</a>&nbsp;and&nbsp;<a href="https://blog.computationalcomplexity.org/2022/02/belated-happy-80th-allan-borodin.html">Aravind Srinivasan</a>.</p><p>Bill and I wish you the best for the holidays and look forward to keeping you informed and entertained with minimal AI assistance.&nbsp;</p><p><br /></p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-21T13:40:00Z">Wednesday, December 21 2022, 13:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.09826'>Fixed and adaptive landmark sets for finite pseudometric spaces</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jason Cory Brunson, Yara Skaf</p><p>Topological data analysis (TDA) is an expanding field that leverages
principles and tools from algebraic topology to quantify structural features of
data sets or transform them into more manageable forms. As its theoretical
foundations have been developed, TDA has shown promise in extracting useful
information from high-dimensional, noisy, and complex data such as those used
in biomedicine. To operate efficiently, these techniques may employ landmark
samplers, either random or heuristic. The heuristic maxmin procedure obtains a
roughly even distribution of sample points by implicitly constructing a cover
comprising sets of uniform radius. However, issues arise with data that vary in
density or include points with multiplicities, as are common in biomedicine. We
propose an analogous procedure, "lastfirst" based on ranked distances, which
implies a cover comprising sets of uniform cardinality. We first rigorously
define the procedure and prove that it obtains landmarks with desired
properties. We then perform benchmark tests and compare its performance to that
of maxmin, on feature detection and class prediction tasks involving simulated
and real-world biomedical data. Lastfirst is more general than maxmin in that
it can be applied to any data on which arbitrary (and not necessarily
symmetric) pairwise distances can be computed. Lastfirst is more
computationally costly, but our implementation scales at the same rate as
maxmin. We find that lastfirst achieves comparable performance on prediction
tasks and outperforms maxmin on homology detection tasks. Where the numerical
values of similarity measures are not meaningful, as in many biomedical
contexts, lastfirst sampling may also improve interpretability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brunson_J/0/1/0/all/0/1">Jason Cory Brunson</a>, <a href="http://arxiv.org/find/cs/1/au:+Skaf_Y/0/1/0/all/0/1">Yara Skaf</a></p><p>Topological data analysis (TDA) is an expanding field that leverages
principles and tools from algebraic topology to quantify structural features of
data sets or transform them into more manageable forms. As its theoretical
foundations have been developed, TDA has shown promise in extracting useful
information from high-dimensional, noisy, and complex data such as those used
in biomedicine. To operate efficiently, these techniques may employ landmark
samplers, either random or heuristic. The heuristic maxmin procedure obtains a
roughly even distribution of sample points by implicitly constructing a cover
comprising sets of uniform radius. However, issues arise with data that vary in
density or include points with multiplicities, as are common in biomedicine. We
propose an analogous procedure, "lastfirst" based on ranked distances, which
implies a cover comprising sets of uniform cardinality. We first rigorously
define the procedure and prove that it obtains landmarks with desired
properties. We then perform benchmark tests and compare its performance to that
of maxmin, on feature detection and class prediction tasks involving simulated
and real-world biomedical data. Lastfirst is more general than maxmin in that
it can be applied to any data on which arbitrary (and not necessarily
symmetric) pairwise distances can be computed. Lastfirst is more
computationally costly, but our implementation scales at the same rate as
maxmin. We find that lastfirst achieves comparable performance on prediction
tasks and outperforms maxmin on homology detection tasks. Where the numerical
values of similarity measures are not meaningful, as in many biomedical
contexts, lastfirst sampling may also improve interpretability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-21T01:30:00Z">Wednesday, December 21 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.10185'>Reasonable thickness determination for implicit porous sheet structure using persistent homology</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jiacong Yan, Hongwei Lin</p><p>Porous structures are widely used in various industries because of their
excellent properties. Porous surfaces have no thickness and should be thickened
to sheet structures for further fabrication. However, conventional methods for
generating sheet structures are inefficient for porous surfaces because of the
complexity of the internal structures. In this study, we propose a novel method
for generating porous sheet structures directly from point clouds sampled on a
porous surface. The generated sheet structure is represented by an implicit
B-spline function, which ensures smoothness and closure. Moreover, based on the
persistent homology theory, the topology structure of the generated porous
sheet structure can be controlled, and a reasonable range of the uniform
thickness of the sheet structure can be calculated to ensure manufacturability
and pore existence. Finally, the implicitly B-spline represented sheet
structures are sliced directly with the marching squares algorithm, and the
contours can be used for 3D printing. Experimental results show the superiority
of the developed method in efficiency over the traditional methods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jiacong Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongwei Lin</a></p><p>Porous structures are widely used in various industries because of their
excellent properties. Porous surfaces have no thickness and should be thickened
to sheet structures for further fabrication. However, conventional methods for
generating sheet structures are inefficient for porous surfaces because of the
complexity of the internal structures. In this study, we propose a novel method
for generating porous sheet structures directly from point clouds sampled on a
porous surface. The generated sheet structure is represented by an implicit
B-spline function, which ensures smoothness and closure. Moreover, based on the
persistent homology theory, the topology structure of the generated porous
sheet structure can be controlled, and a reasonable range of the uniform
thickness of the sheet structure can be calculated to ensure manufacturability
and pore existence. Finally, the implicitly B-spline represented sheet
structures are sliced directly with the marching squares algorithm, and the
contours can be used for 3D printing. Experimental results show the superiority
of the developed method in efficiency over the traditional methods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-21T01:30:00Z">Wednesday, December 21 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.10247'>Dominance for Containment Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Waseem Akram, Sanjeev Saxena</p><p>In a containment problem, the goal is to preprocess a set of geometric
objects so that, given a geometric query object, we can report all the objects
containing the query object. We consider the containment problem where input
objects are homothetic triangles and the query objects considered are line
segments, circles, and trapezoids with bases parallel to either axis. We show
that this problem can be solved using the 3-d query dominance problem. The
solutions presented can also be extended for higher dimensions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Akram_W/0/1/0/all/0/1">Waseem Akram</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1">Sanjeev Saxena</a></p><p>In a containment problem, the goal is to preprocess a set of geometric
objects so that, given a geometric query object, we can report all the objects
containing the query object. We consider the containment problem where input
objects are homothetic triangles and the query objects considered are line
segments, circles, and trapezoids with bases parallel to either axis. We show
that this problem can be solved using the 3-d query dominance problem. The
solutions presented can also be extended for higher dimensions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-21T01:30:00Z">Wednesday, December 21 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.10433'>Scheduling with Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Woo-Hyung Cho, Shane Henderson, David Shmoys</p><p>There is significant interest in deploying machine learning algorithms for
diagnostic radiology, as modern learning techniques have made it possible to
detect abnormalities in medical images within minutes. While machine-assisted
diagnoses cannot yet reliably replace human reviews of images by a radiologist,
they could inform prioritization rules for determining the order by which to
review patient cases so that patients with time-sensitive conditions could
benefit from early intervention.
</p>
<p>We study this scenario by formulating it as a learning-augmented online
scheduling problem. We are given information about each arriving patient's
urgency level in advance, but these predictions are inevitably error-prone. In
this formulation, we face the challenges of decision making under imperfect
information, and of responding dynamically to prediction error as we observe
better data in real-time. We propose a simple online policy and show that this
policy is in fact the best possible in certain stylized settings. We also
demonstrate that our policy achieves the two desiderata of online algorithms
with predictions: consistency (performance improvement with prediction
accuracy) and robustness (protection against the worst case). We complement our
theoretical findings with empirical evaluations of the policy under settings
that more accurately reflect clinical scenarios in the real world.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cho_W/0/1/0/all/0/1">Woo-Hyung Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Henderson_S/0/1/0/all/0/1">Shane Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Shmoys_D/0/1/0/all/0/1">David Shmoys</a></p><p>There is significant interest in deploying machine learning algorithms for
diagnostic radiology, as modern learning techniques have made it possible to
detect abnormalities in medical images within minutes. While machine-assisted
diagnoses cannot yet reliably replace human reviews of images by a radiologist,
they could inform prioritization rules for determining the order by which to
review patient cases so that patients with time-sensitive conditions could
benefit from early intervention.
</p>
<p>We study this scenario by formulating it as a learning-augmented online
scheduling problem. We are given information about each arriving patient's
urgency level in advance, but these predictions are inevitably error-prone. In
this formulation, we face the challenges of decision making under imperfect
information, and of responding dynamically to prediction error as we observe
better data in real-time. We propose a simple online policy and show that this
policy is in fact the best possible in certain stylized settings. We also
demonstrate that our policy achieves the two desiderata of online algorithms
with predictions: consistency (performance improvement with prediction
accuracy) and robustness (protection against the worst case). We complement our
theoretical findings with empirical evaluations of the policy under settings
that more accurately reflect clinical scenarios in the real world.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-21T01:30:00Z">Wednesday, December 21 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, December 20
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2022/12/20/tree-clique-products.html'>Tree-clique products</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A tree decomposition of a graph is, intuitively, a representation of the graph as a “thickened” tree. It comes from the use of separators in divide-and-conquer algorithms: if a graph can be separated into two smaller subgraphs by the removal of a separator, a small subset of its vertices, then many algorithmic problems can be solved by a recursive algorithm that combines the solutions from those subgraphs. The tree, in the tree decomposition, has a root node that represents the separator at the top level of the recursion, children that represent the separators at the next level, and so on.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A <a href="https://en.wikipedia.org/wiki/Tree_decomposition">tree decomposition</a> of a graph is, intuitively, a representation of the graph as a “thickened” <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">tree</a>. It comes from the use of <a href="https://en.wikipedia.org/wiki/Planar_separator_theorem">separators</a> in <a href="https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm">divide-and-conquer algorithms</a>: if a graph can be separated into two smaller subgraphs by the removal of a separator, a small subset of its vertices, then many algorithmic problems can be solved by a recursive algorithm that combines the solutions from those subgraphs. The tree, in the tree decomposition, has a root node that represents the separator at the top level of the recursion, children that represent the separators at the next level, and so on.</p>

<p>It is tempting but incorrect to imagine that each vertex of the given graph belongs to only a single node of this tree. That would mean that you could “thicken” your tree merely by attaching disjoint sets of graph vertices to the tree nodes, so that each graph edge goes between two vertices at the same node or at adjacent nodes. If you could do this, it would give your graph a special kind of product structure: it would be a subgraph of a <a href="https://en.wikipedia.org/wiki/Strong_product_of_graphs">strong product</a> of a tree and a <a href="https://en.wikipedia.org/wiki/Complete_graph">complete graph</a>, of size roughly equal to the width. You could recover the separators of the separator theorem as the subsets of vertices associated with a single tree node.</p>

<p style="text-align:center"><img src="/blog/assets/2022/tree-clique-product.svg" alt="The strong product of a tree and a complete graph" /></p>

<p>Unfortunately, this kind of tree-clique product structure doesn’t work, at least not with the usual separator theorems and the usual divide-and-conquer algorithms. Instead, each recursive subproblem needs to keep track of how its subgraph is attached to the higher-level separator vertices. That means that these separator vertices are really part of the subgraphs on both sides, rather than being confined to a single node at the root of the decomposition tree. Working out the implications of this leads to the standard notion of a tree decomposition, a tree with non-disjoint “bags” of vertices on each node. Each graph vertex may belong to many bags, but they must form a connected subtree of the whole tree. Each graph edge must have both endpoints together in at least one bag.</p>

<p>A counterexample for a related graph coloring problem, by Linial, Matoušek, Sheffet, and Tardos, “Graph colouring with no large monochromatic components”, <a href="https://doi.org/10.1017/S0963548308009140"><em>Probability &amp; Computing</em> 2008</a>, <a href="https://arxiv.org/abs/math/0703362">arXiv:math/0703362</a>, also shows some of the limitations of the naive tree-clique-product idea. Their example uses a rectangular grid of <span style="white-space:nowrap">dimensions \(n^{1/3}\times n^{2/3}\),</span> with each vertex on the top row of the grid fanning out to another \(n^{1/3}\) vertices in a path of linearly many vertices, and one more vertex attached to everything in this path.</p>

<p style="text-align:center"><img src="/blog/assets/2022/untreeable.svg" alt="Rectangular grid with a vertex attached to its long edge, providing an example of a planar graph " /></p>

<p>It’s planar, so it has a tree decomposition of width (bag size) \(O(\sqrt n)\), but representing it as the subgraph of a tree-clique product requires cliques of <span style="white-space:nowrap">size \(\Omega(n^{2/3})\).</span> If you try to use smaller cliques, then the tree node containing the high-degree vertex cannot include enough grid columns nor enough of the top grid row to separate the rest into pieces of small enough size. Some piece will contain \(\Omega(n^{2/3})\) vertices of the long path. However it is further subdivided, at least two of the subdivisions will be connected to each other through the piece and also through the high-degree vertex, forming a loop that is impossible in a tree. (Linial et al. triangulate the grid and show more strongly that in any product structure involving a small clique the other factor has a triangle, but that is more than we need here.)</p>

<p>This graph does have a tree-clique product structure with cliques of size \(O(n^{2/3})\). By applying the standard planar separator theorem repeatedly, in any planar graph you can find a separator of <span style="white-space:nowrap">size \(O(n^{2/3})\)</span> whose removal partitions the remaining subgraph into components of <span style="white-space:nowrap">size \(O(n^{2/3})\).</span> This can be thought of as a tree-clique product where the tree is a star with the separator as root and all the remaining components as leaf children. In the graph of Linial et al, the separator can be formed from the high-degree vertex, the entire top row of the grid, an evenly-spaced subset of vertices of the long path, and the left column of each square subset of the grid. The components it forms are the remainder of each square subset of the grid, and the remaining paths within the long path. More generally, in any class of graphs with <span style="white-space:nowrap">\(O(\sqrt n)\)-separators,</span> the same idea produces a representation as a subgraph of a clique–star <span style="white-space:nowrap">product \(K_{O(n^{2/3})}\boxtimes K_{1,O(n^{1/3})}\),</span> as David Wood observed in his recent preprint “Product structure of graph classes with strongly sublinear separators”, <a href="https://arxiv.org/abs/2208.10074">arXiv:2208.10074</a>.</p>

<p>Which all brings us to my newest preprint, “Graphs excluding a fixed minor are <span style="white-space:nowrap">\(O(\sqrt n)\)-complete-blowups</span> of a treewidth 4 graph”, with Marc Distel, Vida Dujmović, Robert Hickingbotham, Gwenaël Joret, Pat Morin, Michał Seweryn, and David Wood, <a href="https://arxiv.org/abs/2212.08739">arXiv:2212.08739</a>. It asks: what if you insist on a product structure involving cliques of <span style="white-space:nowrap">size \(O(\sqrt n)\),</span> but you let the other factor be something other than a tree? How well-structured can you make the other factor? As the title says, for graphs in any minor-closed graph family, we can find a representation of the graph as a strong product \(K\boxtimes G\) where \(K\) is a clique of size \(O(\sqrt n)\) and \(G\) has treewidth at most four. The details are messy and use the full strength of a different graph structure theorem, the <a href="https://en.wikipedia.org/wiki/Graph_structure_theorem">theorem of Robertson and Seymour</a> that the graphs in any minor-closed family can be decomposed by separators of bounded size into pieces that are graphs of bounded genus, plus a bounded number of arbitrary “apex” vertices, plus “vortices” of bounded pathwidth attached to a bounded number of faces. See the paper if you want an explanation of that part.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/109550441431571479">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T21:04:00Z">Tuesday, December 20 2022, 21:04</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/20/arc-postdoctoral-fellowship-at-georgia-institute-of-technology-apply-by-january-6-2023/'>ARC Postdoctoral Fellowship at Georgia Institute of Technology (apply by January 6, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Algorithms and Randomness Center at Georgia Tech is seeking multiple postdoctoral fellows starting August 1, 2023. Qualified applicants must possess a PhD in Computer Science, Mathematics, Operations Research or a related field. Please send a CV, research statement, and contacts for three references to arc-postdoc@cc.gatech.edu by January 6, 2023 for full consideration. Website: arc.gatech.edu/post-doc2023 [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Algorithms and Randomness Center at Georgia Tech is seeking multiple postdoctoral fellows starting August 1, 2023. Qualified applicants must possess a PhD in Computer Science, Mathematics, Operations Research or a related field. Please send a CV, research statement, and contacts for three references to arc-postdoc@cc.gatech.edu by January 6, 2023 for full consideration.</p>
<p>Website: <a href="https://arc.gatech.edu/post-doc2023">https://arc.gatech.edu/post-doc2023</a><br />
Email: arc-postdoc@cc.gatech.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T18:42:45Z">Tuesday, December 20 2022, 18:42</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/20/ibm-2023-24-herman-goldstine-memorial-postdoctoral-fellowship-at-ibm-research-apply-by-december-31-2022/'>IBM 2023-24 Herman Goldstine Memorial Postdoctoral Fellowship at IBM Research (apply by December 31, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Mathematical Sciences department of IBM Research invites applications for its 2023–2024 Herman Goldstine Memorial Postdoctoral Fellowship for research in the mathematical and computer sciences. The department provides an atmosphere in which basic research is combined with work on practical applications. Areas of interest include theoretical computer science and optimization. Website: research.ibm.com/goldstine/ Email: gpfellow@ibm.com
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Mathematical Sciences department of IBM Research invites applications for its 2023–2024 Herman Goldstine Memorial Postdoctoral Fellowship for research in the mathematical and computer sciences. The department provides an atmosphere in which basic research is combined with work on practical applications. Areas of interest include theoretical computer science and optimization.</p>
<p>Website: <a href="https://research.ibm.com/goldstine/">https://research.ibm.com/goldstine/</a><br />
Email: gpfellow@ibm.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T15:33:22Z">Tuesday, December 20 2022, 15:33</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.08678'>A super-polynomial quantum advantage for combinatorial optimization problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Niklas Pirnay, Vincent Ulitzsch, Frederik Wilde, Jens Eisert, Jean-Pierre Seifert</p><p>Combinatorial optimization - a field of research addressing problems that
feature strongly in a wealth of practical and industrial contexts - has been
identified as one of the core potential fields of applicability of near-term
quantum computers. It is still unclear, however, to what extent variational
quantum algorithms can actually outperform classical algorithms for this type
of problems. In this work, by resorting to computational learning theory and
cryptographic notions, we prove that fault-tolerant quantum computers feature a
super-polynomial advantage over classical computers in approximating solutions
to combinatorial optimization problems. Specifically, building on seminal work
of Kearns and Valiant, we construct special instances of the integer
programming problem (which in its most general form is NP-complete) that we
prove to be hard-to-approximate classically but give an efficient quantum
algorithm to approximate the optimal solution of those instances, hence showing
a super-polynomial quantum advantage. This result shows that quantum devices
have the power to approximate combinatorial optimization solutions beyond the
reach of classical efficient algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Pirnay_N/0/1/0/all/0/1">Niklas Pirnay</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ulitzsch_V/0/1/0/all/0/1">Vincent Ulitzsch</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wilde_F/0/1/0/all/0/1">Frederik Wilde</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Eisert_J/0/1/0/all/0/1">Jens Eisert</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Seifert_J/0/1/0/all/0/1">Jean-Pierre Seifert</a></p><p>Combinatorial optimization - a field of research addressing problems that
feature strongly in a wealth of practical and industrial contexts - has been
identified as one of the core potential fields of applicability of near-term
quantum computers. It is still unclear, however, to what extent variational
quantum algorithms can actually outperform classical algorithms for this type
of problems. In this work, by resorting to computational learning theory and
cryptographic notions, we prove that fault-tolerant quantum computers feature a
super-polynomial advantage over classical computers in approximating solutions
to combinatorial optimization problems. Specifically, building on seminal work
of Kearns and Valiant, we construct special instances of the integer
programming problem (which in its most general form is NP-complete) that we
prove to be hard-to-approximate classically but give an efficient quantum
algorithm to approximate the optimal solution of those instances, hence showing
a super-polynomial quantum advantage. This result shows that quantum devices
have the power to approximate combinatorial optimization solutions beyond the
reach of classical efficient algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.08709'>On the Complexities of Understanding Matching Mechanisms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yannai A. Gonczarowski, Clayton Thomas</p><p>We study various novel complexity measures for two-sided matching mechanisms,
applied to the popular real-world school choice mechanisms of Deferred
Acceptance (DA) and Top Trading Cycles (TTC). In contrast to typical bounds in
computer science, our metrics are not aimed to capture how hard the mechanisms
are to compute. Rather, they aim to capture certain aspects of the difficulty
of understanding or explaining the mechanisms and their properties.
</p>
<p>First, we study a set of questions regarding the complexity of how one
agent's report can affect other facets of the mechanism. We show that in both
DA and TTC, one agent's report can have a structurally complex effect on the
final matching. Considering how one agent's report can affect another agent's
set of obtainable options, we show that this effect has high complexity for
TTC, but low complexity for DA, showing that one agent can only affect another
in DA in a quantitatively controlled way.
</p>
<p>Second, we study a set of questions about the complexity of communicating
various facets of the outcome matching, after calculating it. We find that when
there are many more students than schools, it is provably harder to
concurrently describe to each student her match in TTC than in DA. In contrast,
we show that the outcomes of TTC and DA are equally hard to jointly verify, and
that all agents' sets of obtainable options are equally hard to describe,
showcasing ways in which the two mechanisms are comparably complex.
</p>
<p>Our results uncover new lenses into how TTC may be more complex than DA. This
stands in contrast with recent results under different models, emphasizing the
richness of the landscape of complexities of matching mechanisms. Our proofs
uncover novel structural properties of TTC and DA, which may be of independent
interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gonczarowski_Y/0/1/0/all/0/1">Yannai A. Gonczarowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_C/0/1/0/all/0/1">Clayton Thomas</a></p><p>We study various novel complexity measures for two-sided matching mechanisms,
applied to the popular real-world school choice mechanisms of Deferred
Acceptance (DA) and Top Trading Cycles (TTC). In contrast to typical bounds in
computer science, our metrics are not aimed to capture how hard the mechanisms
are to compute. Rather, they aim to capture certain aspects of the difficulty
of understanding or explaining the mechanisms and their properties.
</p>
<p>First, we study a set of questions regarding the complexity of how one
agent's report can affect other facets of the mechanism. We show that in both
DA and TTC, one agent's report can have a structurally complex effect on the
final matching. Considering how one agent's report can affect another agent's
set of obtainable options, we show that this effect has high complexity for
TTC, but low complexity for DA, showing that one agent can only affect another
in DA in a quantitatively controlled way.
</p>
<p>Second, we study a set of questions about the complexity of communicating
various facets of the outcome matching, after calculating it. We find that when
there are many more students than schools, it is provably harder to
concurrently describe to each student her match in TTC than in DA. In contrast,
we show that the outcomes of TTC and DA are equally hard to jointly verify, and
that all agents' sets of obtainable options are equally hard to describe,
showcasing ways in which the two mechanisms are comparably complex.
</p>
<p>Our results uncover new lenses into how TTC may be more complex than DA. This
stands in contrast with recent results under different models, emphasizing the
richness of the landscape of complexities of matching mechanisms. Our proofs
uncover novel structural properties of TTC and DA, which may be of independent
interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.09285'>Localizability of the approximation method</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jan Pich</p><p>We use the approximation method of Razborov to analyze the locality barrier
which arose from the investigation of the hardness magnification approach to
complexity lower bounds. Adapting a limitation of the approximation method
obtained by Razborov, we show that in many cases it is not possible to combine
the approximation method with typical (localizable) hardness magnification
theorems to derive strong circuit lower bounds. In particular, one cannot use
the approximation method to derive an extremely strong constant-depth circuit
lower bound and then magnify it to an $NC^1$ lower bound for an explicit
function.
</p>
<p>To prove this we show that lower bounds obtained by the approximation method
are in many cases localizable in the sense that they imply lower bounds for
circuits which are allowed to use arbitrarily powerful oracles with small
fan-in.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pich_J/0/1/0/all/0/1">Jan Pich</a></p><p>We use the approximation method of Razborov to analyze the locality barrier
which arose from the investigation of the hardness magnification approach to
complexity lower bounds. Adapting a limitation of the approximation method
obtained by Razborov, we show that in many cases it is not possible to combine
the approximation method with typical (localizable) hardness magnification
theorems to derive strong circuit lower bounds. In particular, one cannot use
the approximation method to derive an extremely strong constant-depth circuit
lower bound and then magnify it to an $NC^1$ lower bound for an explicit
function.
</p>
<p>To prove this we show that lower bounds obtained by the approximation method
are in many cases localizable in the sense that they imply lower bounds for
circuits which are allowed to use arbitrarily powerful oracles with small
fan-in.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.09029'>SurfaceVoronoi: Efficiently Computing Voronoi Diagrams over Mesh Surfaces with Arbitrary Distance Solvers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shiqing Xin, Pengfei Wang, Rui Xu, Dongming Yan, Shuangmin Chen, Wenping Wang, Caiming Zhang, Changhe Tu,</p><p>In this paper, we propose to compute Voronoi diagrams over mesh surfaces
driven by an arbitrary geodesic distance solver, assuming that the input is a
triangle mesh as well as a collection of sites $P=\{p_i\}_{i=1}^m$ on the
surface. We propose two key techniques to solve this problem. First, as the
partition is determined by minimizing the $m$ distance fields, each of which
rooted at a source site, we suggest keeping one or more distance triples, for
each triangle, that may help determine the Voronoi bisectors when one uses a
mark-and-sweep geodesic algorithm to predict the multi-source distance field.
Second, rather than keep the distance itself at a mesh vertex, we use the
squared distance to characterize the linear change of distance field restricted
in a triangle, which is proved to induce an exact VD when the base surface
reduces to a planar triangle mesh. Specially, our algorithm also supports the
Euclidean distance, which can handle thin-sheet models (e.g. leaf) and runs
faster than the traditional restricted Voronoi diagram~(RVD) algorithm. It is
very extensible to deal with various variants of surface-based Voronoi diagrams
including (1)surface-based power diagram, (2)constrained Voronoi diagram with
curve-type breaklines, and (3)curve-type generators. We conduct extensive
experimental results to validate the ability to approximate the exact VD in
different distance-driven scenarios.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Xin_S/0/1/0/all/0/1">Shiqing Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pengfei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Rui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_D/0/1/0/all/0/1">Dongming Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shuangmin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Caiming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_C/0/1/0/all/0/1">Changhe Tu</a>,</p><p>In this paper, we propose to compute Voronoi diagrams over mesh surfaces
driven by an arbitrary geodesic distance solver, assuming that the input is a
triangle mesh as well as a collection of sites $P=\{p_i\}_{i=1}^m$ on the
surface. We propose two key techniques to solve this problem. First, as the
partition is determined by minimizing the $m$ distance fields, each of which
rooted at a source site, we suggest keeping one or more distance triples, for
each triangle, that may help determine the Voronoi bisectors when one uses a
mark-and-sweep geodesic algorithm to predict the multi-source distance field.
Second, rather than keep the distance itself at a mesh vertex, we use the
squared distance to characterize the linear change of distance field restricted
in a triangle, which is proved to induce an exact VD when the base surface
reduces to a planar triangle mesh. Specially, our algorithm also supports the
Euclidean distance, which can handle thin-sheet models (e.g. leaf) and runs
faster than the traditional restricted Voronoi diagram~(RVD) algorithm. It is
very extensible to deal with various variants of surface-based Voronoi diagrams
including (1)surface-based power diagram, (2)constrained Voronoi diagram with
curve-type breaklines, and (3)curve-type generators. We conduct extensive
experimental results to validate the ability to approximate the exact VD in
different distance-driven scenarios.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.08664'>On the Optimum Scenarios for Single Row Equidistant Facility Layout Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shrouq Gamal, Ahmed A. Hawam, Ahmed M. El-Kassas</p><p>Single Row Equidistant Facility Layout Problem SREFLP is with an NP-Hard
nature to mimic material handling costs along with equally spaced straight-line
facilities layout. Based on literature, it is obvious that efforts of
researchers for solving SREFLP turn from exact methods into release the running
time tracing the principle of the approximate methods in time race, regardless
searching their time complexity release in conjunction with a provable quality
of solutions. This study focuses on Lower bounding LB techniques as an
independent potential solution tool for SREFLP. In particular, Best-known
SREFLP LBs are reported from literature and significantly LBs optimum scenarios
are highlighted. Initially, one gap of the SREFLP bidirectional LB is enhanced.
From the integration between the enhanced LB and the best-known Gilmore-Lawler
GL bounding, a new SREFLP optimum scenario is provided. Further improvements to
GLB lead to guarantee an exact Shipping/Receiving Facility assignment and
propose a conjecture of at most 4/3 approximation scheme for SREFLP.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gamal_S/0/1/0/all/0/1">Shrouq Gamal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hawam_A/0/1/0/all/0/1">Ahmed A. Hawam</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Kassas_A/0/1/0/all/0/1">Ahmed M. El-Kassas</a></p><p>Single Row Equidistant Facility Layout Problem SREFLP is with an NP-Hard
nature to mimic material handling costs along with equally spaced straight-line
facilities layout. Based on literature, it is obvious that efforts of
researchers for solving SREFLP turn from exact methods into release the running
time tracing the principle of the approximate methods in time race, regardless
searching their time complexity release in conjunction with a provable quality
of solutions. This study focuses on Lower bounding LB techniques as an
independent potential solution tool for SREFLP. In particular, Best-known
SREFLP LBs are reported from literature and significantly LBs optimum scenarios
are highlighted. Initially, one gap of the SREFLP bidirectional LB is enhanced.
From the integration between the enhanced LB and the best-known Gilmore-Lawler
GL bounding, a new SREFLP optimum scenario is provided. Further improvements to
GLB lead to guarantee an exact Shipping/Receiving Facility assignment and
propose a conjecture of at most 4/3 approximation scheme for SREFLP.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.08964'>GPU Load Balancing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Muhammad Osama</p><p>Fine-grained workload and resource balancing is the key to high performance
for regular and irregular computations on the GPUs. In this dissertation, we
conduct an extensive survey of existing load-balancing techniques to build an
abstraction that addresses the difficulty of scheduling computations on the
GPU.
</p>
<p>We propose a GPU fine-grained load-balancing abstraction that decouples load
balancing from work processing and aims to support both static and dynamic
schedules with a programmable interface to implement new load-balancing
schedules. Prior to our work, the only way to unleash the GPU's potential on
irregular problems has been to workload-balance through application-specific,
tightly coupled load-balancing techniques. With our open-source framework for
load-balancing, we hope to improve programmers' productivity when developing
irregular-parallel algorithms on the GPU, and also improve the overall
performance characteristics for such applications by allowing a quick path to
experimentation with a variety of existing load-balancing techniques.
</p>
<p>Using our insights from load-balancing irregular workloads, we build
Stream-K, a work-centric parallelization of matrix multiplication (GEMM) and
related computations in dense linear algebra. Whereas contemporary
decompositions are primarily tile-based, our method operates by partitioning an
even share of the aggregate inner loop iterations among physical processing
elements. This provides a near-perfect utilization of computing resources,
regardless of how efficiently the output tiling for any given problem quantizes
across the underlying processing elements. On GPU processors, our Stream-K
parallelization of GEMM produces a peak speedup of up to 14x and 6.7x, and an
average performance response that is both higher and more consistent across 32K
GEMM problem geometries than state-of-the-art math libraries such as CUTLASS
and cuBLAS.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Osama_M/0/1/0/all/0/1">Muhammad Osama</a></p><p>Fine-grained workload and resource balancing is the key to high performance
for regular and irregular computations on the GPUs. In this dissertation, we
conduct an extensive survey of existing load-balancing techniques to build an
abstraction that addresses the difficulty of scheduling computations on the
GPU.
</p>
<p>We propose a GPU fine-grained load-balancing abstraction that decouples load
balancing from work processing and aims to support both static and dynamic
schedules with a programmable interface to implement new load-balancing
schedules. Prior to our work, the only way to unleash the GPU's potential on
irregular problems has been to workload-balance through application-specific,
tightly coupled load-balancing techniques. With our open-source framework for
load-balancing, we hope to improve programmers' productivity when developing
irregular-parallel algorithms on the GPU, and also improve the overall
performance characteristics for such applications by allowing a quick path to
experimentation with a variety of existing load-balancing techniques.
</p>
<p>Using our insights from load-balancing irregular workloads, we build
Stream-K, a work-centric parallelization of matrix multiplication (GEMM) and
related computations in dense linear algebra. Whereas contemporary
decompositions are primarily tile-based, our method operates by partitioning an
even share of the aggregate inner loop iterations among physical processing
elements. This provides a near-perfect utilization of computing resources,
regardless of how efficiently the output tiling for any given problem quantizes
across the underlying processing elements. On GPU processors, our Stream-K
parallelization of GEMM produces a peak speedup of up to 14x and 6.7x, and an
average performance response that is both higher and more consistent across 32K
GEMM problem geometries than state-of-the-art math libraries such as CUTLASS
and cuBLAS.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.09005'>High-Performance Filters For GPUs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hunter McCoy, Steven Hofmeyr, Katherine Yelick, Prashant Pandey</p><p>Filters approximately store a set of items while trading off accuracy for
space-efficiency and can address the limited memory on accelerators, such as
GPUs. However, there is a lack of high-performance and feature-rich GPU filters
as most advancements in filter research has focused on CPUs.
</p>
<p>In this paper, we explore the design space of filters with a goal to develop
massively parallel, high performance, and feature rich filters for GPUs. We
evaluate various filter designs in terms of performance, usability, and
supported features and identify two filter designs that offer the right trade
off in terms of performance, features, and usability.
</p>
<p>We present two new GPU-based filters, the TCF and GQF, that can be employed
in various high performance data analytics applications. The TCF is a set
membership filter and supports faster inserts and queries, whereas the GQF
supports counting which comes at an additional performance cost. Both the GQF
and TCF provide point and bulk insertion API and are designed to exploit the
massive parallelism in the GPU without sacrificing usability and necessary
features. The TCF and GQF are up to $4.4\times$ and $1.4\times$ faster than the
previous GPU filters in our benchmarks and at the same time overcome the
fundamental constraints in performance and usability in current GPU filters.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+McCoy_H/0/1/0/all/0/1">Hunter McCoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmeyr_S/0/1/0/all/0/1">Steven Hofmeyr</a>, <a href="http://arxiv.org/find/cs/1/au:+Yelick_K/0/1/0/all/0/1">Katherine Yelick</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_P/0/1/0/all/0/1">Prashant Pandey</a></p><p>Filters approximately store a set of items while trading off accuracy for
space-efficiency and can address the limited memory on accelerators, such as
GPUs. However, there is a lack of high-performance and feature-rich GPU filters
as most advancements in filter research has focused on CPUs.
</p>
<p>In this paper, we explore the design space of filters with a goal to develop
massively parallel, high performance, and feature rich filters for GPUs. We
evaluate various filter designs in terms of performance, usability, and
supported features and identify two filter designs that offer the right trade
off in terms of performance, features, and usability.
</p>
<p>We present two new GPU-based filters, the TCF and GQF, that can be employed
in various high performance data analytics applications. The TCF is a set
membership filter and supports faster inserts and queries, whereas the GQF
supports counting which comes at an additional performance cost. Both the GQF
and TCF provide point and bulk insertion API and are designed to exploit the
massive parallelism in the GPU without sacrificing usability and necessary
features. The TCF and GQF are up to $4.4\times$ and $1.4\times$ faster than the
previous GPU filters in our benchmarks and at the same time overcome the
fundamental constraints in performance and usability in current GPU filters.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.09165'>Unconstrained Traveling Tournament Problem is APX-complete</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Salomon Bendayan, Joseph Cheriyan, Kevin K.H. Cheung</p><p>We show that the Unconstrained Traveling Tournament Problem (UTTP) is
APX-complete by presenting an L-reduction from a version of metric (1,2)-TSP to
UTTP.
</p>
<p>Keywords: Traveling Tournament Problem, APX-complete, Approximation
algorithms, Traveling Salesman Problem
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bendayan_S/0/1/0/all/0/1">Salomon Bendayan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheriyan_J/0/1/0/all/0/1">Joseph Cheriyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheung_K/0/1/0/all/0/1">Kevin K.H. Cheung</a></p><p>We show that the Unconstrained Traveling Tournament Problem (UTTP) is
APX-complete by presenting an L-reduction from a version of metric (1,2)-TSP to
UTTP.
</p>
<p>Keywords: Traveling Tournament Problem, APX-complete, Approximation
algorithms, Traveling Salesman Problem
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.09270'>The One-Inclusion Graph Algorithm is not Always Optimal</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ishaq Aden-Ali, Yeshwanth Cherapanamjeri, Abhishek Shetty, Nikita Zhivotovskiy</p><p>The one-inclusion graph algorithm of Haussler, Littlestone, and Warmuth
achieves an optimal in-expectation risk bound in the standard PAC
classification setup. In one of the first COLT open problems, Warmuth
conjectured that this prediction strategy always implies an optimal high
probability bound on the risk, and hence is also an optimal PAC algorithm. We
refute this conjecture in the strongest sense: for any practically interesting
Vapnik-Chervonenkis class, we provide an in-expectation optimal one-inclusion
graph algorithm whose high probability risk bound cannot go beyond that implied
by Markov's inequality. Our construction of these poorly performing
one-inclusion graph algorithms uses Varshamov-Tenengolts error correcting
codes.
</p>
<p>Our negative result has several implications. First, it shows that the same
poor high-probability performance is inherited by several recent prediction
strategies based on generalizations of the one-inclusion graph algorithm.
Second, our analysis shows yet another statistical problem that enjoys an
estimator that is provably optimal in expectation via a leave-one-out argument,
but fails in the high-probability regime. This discrepancy occurs despite the
boundedness of the binary loss for which arguments based on concentration
inequalities often provide sharp high probability risk bounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aden_Ali_I/0/1/0/all/0/1">Ishaq Aden-Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Cherapanamjeri_Y/0/1/0/all/0/1">Yeshwanth Cherapanamjeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shetty_A/0/1/0/all/0/1">Abhishek Shetty</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhivotovskiy_N/0/1/0/all/0/1">Nikita Zhivotovskiy</a></p><p>The one-inclusion graph algorithm of Haussler, Littlestone, and Warmuth
achieves an optimal in-expectation risk bound in the standard PAC
classification setup. In one of the first COLT open problems, Warmuth
conjectured that this prediction strategy always implies an optimal high
probability bound on the risk, and hence is also an optimal PAC algorithm. We
refute this conjecture in the strongest sense: for any practically interesting
Vapnik-Chervonenkis class, we provide an in-expectation optimal one-inclusion
graph algorithm whose high probability risk bound cannot go beyond that implied
by Markov's inequality. Our construction of these poorly performing
one-inclusion graph algorithms uses Varshamov-Tenengolts error correcting
codes.
</p>
<p>Our negative result has several implications. First, it shows that the same
poor high-probability performance is inherited by several recent prediction
strategies based on generalizations of the one-inclusion graph algorithm.
Second, our analysis shows yet another statistical problem that enjoys an
estimator that is provably optimal in expectation via a leave-one-out argument,
but fails in the high-probability regime. This discrepancy occurs despite the
boundedness of the binary loss for which arguments based on concentration
inequalities often provide sharp high probability risk bounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.09316'>Lower bound on the running time of Pop-Stack Sorting on a random permutation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lyuben Lichev</p><p>Pop-Stack Sorting is an algorithm that takes a permutation as an input and
sorts its elements. It consists of several steps. At one step, the algorithm
reads the permutation it has to process from left to right and reverses each of
its maximal decreasing subsequences of consecutive elements. It terminates at
the first step that outputs the identity permutation.
</p>
<p>In this note, we answer a question of Defant on the running time of Pop-Stack
Sorting on the uniform random permutation $\sigma_n$. More precisely, we show
that there is a constant $c &gt; 0.5$ such that asymptotically almost surely, the
algorithm needs at least $cn$ steps to terminate on $\sigma_n$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Lichev_L/0/1/0/all/0/1">Lyuben Lichev</a></p><p>Pop-Stack Sorting is an algorithm that takes a permutation as an input and
sorts its elements. It consists of several steps. At one step, the algorithm
reads the permutation it has to process from left to right and reverses each of
its maximal decreasing subsequences of consecutive elements. It terminates at
the first step that outputs the identity permutation.
</p>
<p>In this note, we answer a question of Defant on the running time of Pop-Stack
Sorting on the uniform random permutation $\sigma_n$. More precisely, we show
that there is a constant $c &gt; 0.5$ such that asymptotically almost surely, the
algorithm needs at least $cn$ steps to terminate on $\sigma_n$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.09348'>Excluding Single-Crossing Matching Minors in Bipartite Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Archontia C. Giannopoulou, Dimitrios M. Thilikos, Sebastian Wiederrecht</p><p>\noindent By a seminal result of Valiant, computing the permanent of
$(0,1)$-matrices is, in general, $\#\mathsf{P}$-hard. In 1913 P\'olya asked for
which $(0,1)$-matrices $A$ it is possible to change some signs such that the
permanent of $A$ equals the determinant of the resulting matrix. In 1975,
Little showed these matrices to be exactly the biadjacency matrices of
bipartite graphs excluding $K_{3,3}$ as a \{matching minor}. This was turned
into a polynomial time algorithm by McCuaig, Robertson, Seymour, and Thomas in
1999. However, the relation between the exclusion of some matching minor in a
bipartite graph and the tractability of the permanent extends beyond $K_{3,3}.$
Recently it was shown that the exclusion of any planar bipartite graph as a
matching minor yields a class of bipartite graphs on which the {permanent} of
the corresponding $(0,1)$-matrices can be computed efficiently. In this paper
we unify the two results above into a single, more general result in the style
of the celebrated structure theorem for single-crossing-minor-free graphs. We
identify a class of bipartite graphs strictly generalising planar bipartite
graphs and $K_{3,3}$ which includes infinitely many non-Pfaffian graphs. The
exclusion of any member of this class as a matching minor yields a structure
that allows for the efficient evaluation of the permanent. Moreover, we show
that the evaluation of the permanent remains $\#\mathsf{P}$-hard on bipartite
graphs which exclude $K_{5,5}$ as a matching minor. This establishes a first
computational lower bound for the problem of counting perfect matchings on
matching minor closed classes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Giannopoulou_A/0/1/0/all/0/1">Archontia C. Giannopoulou</a>, <a href="http://arxiv.org/find/math/1/au:+Thilikos_D/0/1/0/all/0/1">Dimitrios M. Thilikos</a>, <a href="http://arxiv.org/find/math/1/au:+Wiederrecht_S/0/1/0/all/0/1">Sebastian Wiederrecht</a></p><p>\noindent By a seminal result of Valiant, computing the permanent of
$(0,1)$-matrices is, in general, $\#\mathsf{P}$-hard. In 1913 P\'olya asked for
which $(0,1)$-matrices $A$ it is possible to change some signs such that the
permanent of $A$ equals the determinant of the resulting matrix. In 1975,
Little showed these matrices to be exactly the biadjacency matrices of
bipartite graphs excluding $K_{3,3}$ as a \{matching minor}. This was turned
into a polynomial time algorithm by McCuaig, Robertson, Seymour, and Thomas in
1999. However, the relation between the exclusion of some matching minor in a
bipartite graph and the tractability of the permanent extends beyond $K_{3,3}.$
Recently it was shown that the exclusion of any planar bipartite graph as a
matching minor yields a class of bipartite graphs on which the {permanent} of
the corresponding $(0,1)$-matrices can be computed efficiently. In this paper
we unify the two results above into a single, more general result in the style
of the celebrated structure theorem for single-crossing-minor-free graphs. We
identify a class of bipartite graphs strictly generalising planar bipartite
graphs and $K_{3,3}$ which includes infinitely many non-Pfaffian graphs. The
exclusion of any member of this class as a matching minor yields a structure
that allows for the efficient evaluation of the permanent. Moreover, we show
that the evaluation of the permanent remains $\#\mathsf{P}$-hard on bipartite
graphs which exclude $K_{5,5}$ as a matching minor. This establishes a first
computational lower bound for the problem of counting perfect matchings on
matching minor closed classes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-20T01:30:00Z">Tuesday, December 20 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, December 19
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/183'>TR22-183 |  New Lower Bounds and Derandomization for ACC, and a Derandomization-centric View on the Algorithmic Method | 

	Lijie Chen</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this paper, we obtain several new results on lower bounds and derandomization for ACC^0 circuits (constant-depth circuits consisting of AND/OR/MOD_m gates for a fixed constant m, a frontier class in circuit complexity):
		
1. We prove that any polynomial-time Merlin-Arthur proof system with an ACC^0 verifier (denoted by MA_{ACC^0}) can be simulated by a nondeterministic proof system with quasi-polynomial running time and polynomial proof length on infinitely many input lengths. This improves the previous simulation by [Chen, Lyu, and Williams, FOCS 2020], which requires both quasi-polynomial running time and proof length.
			
2. We show that MA_{ACC^0} cannot be computed by fixed-polynomial-size ACC^0 circuits, and our hard languages are hard on a sufficiently dense set of input lengths.
			
3. We show that NEXP (nondeterministic exponential-time) does not have ACC^0 circuits of sub-half-exponential size, improving the previous sub-third-exponential size lower bound for NEXP against ACC^0 by [Williams, J. ACM 2014].
	
Combining our first and second results gives a conceptually simpler and derandomization-centric proof of the recent breakthrough result NQP = \NTIME[2^{polylog(n)}] is not in ACC^0 by [Murray and Williams, SICOMP 2020]: Instead of going through an easy witness lemma as they did, we first prove an ACC^0 lower bound for a subclass of MA, and then derandomize that subclass into NQP, while retaining its hardness against ACC^0. 
		
Moreover, since our derandomization of MA_{ACC^0} achieves a polynomial proof length, we indeed prove that nondeterministic quasi-polynomial-time with n^{omega(1)} nondeterminism bits (denoted as NTIMEGUESS[2^{polylog(n)},n^{omega(1)}]) has no poly(n)-size ACC^0 circuits, giving a new proof of a result by Vyas. Combining with a win-win argument based on randomized encodings from [Chen and Ren, STOC 2020], we also prove that NTIMEGUESS[2^{polylog(n)},n^{omega(1)}] cannot be (1/2+1/poly(n))-approximated by poly(n)-size ACC^0 circuits, improving the recent strongly average-case lower bounds for NQP against ACC^0 by [Chen and Ren, STOC 2020].
		
One interesting technical ingredient behind our second result is the construction of a PSPACE-complete language that is paddable, downward self-reducible, same-length checkable, and weakly error correctable. Moreover, all its reducibility properties have corresponding AC^0[2] non-adaptive oracle circuits. Our construction builds and improves upon similar constructions from [Trevisan and Vadhan, Complexity 2007] and [Chen, FOCS 2019], which all require at least TC^0 oracle circuits for implementing these properties.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In this paper, we obtain several new results on lower bounds and derandomization for ACC^0 circuits (constant-depth circuits consisting of AND/OR/MOD_m gates for a fixed constant m, a frontier class in circuit complexity):
		
1. We prove that any polynomial-time Merlin-Arthur proof system with an ACC^0 verifier (denoted by MA_{ACC^0}) can be simulated by a nondeterministic proof system with quasi-polynomial running time and polynomial proof length on infinitely many input lengths. This improves the previous simulation by [Chen, Lyu, and Williams, FOCS 2020], which requires both quasi-polynomial running time and proof length.
			
2. We show that MA_{ACC^0} cannot be computed by fixed-polynomial-size ACC^0 circuits, and our hard languages are hard on a sufficiently dense set of input lengths.
			
3. We show that NEXP (nondeterministic exponential-time) does not have ACC^0 circuits of sub-half-exponential size, improving the previous sub-third-exponential size lower bound for NEXP against ACC^0 by [Williams, J. ACM 2014].
	
Combining our first and second results gives a conceptually simpler and derandomization-centric proof of the recent breakthrough result NQP = \NTIME[2^{polylog(n)}] is not in ACC^0 by [Murray and Williams, SICOMP 2020]: Instead of going through an easy witness lemma as they did, we first prove an ACC^0 lower bound for a subclass of MA, and then derandomize that subclass into NQP, while retaining its hardness against ACC^0. 
		
Moreover, since our derandomization of MA_{ACC^0} achieves a polynomial proof length, we indeed prove that nondeterministic quasi-polynomial-time with n^{omega(1)} nondeterminism bits (denoted as NTIMEGUESS[2^{polylog(n)},n^{omega(1)}]) has no poly(n)-size ACC^0 circuits, giving a new proof of a result by Vyas. Combining with a win-win argument based on randomized encodings from [Chen and Ren, STOC 2020], we also prove that NTIMEGUESS[2^{polylog(n)},n^{omega(1)}] cannot be (1/2+1/poly(n))-approximated by poly(n)-size ACC^0 circuits, improving the recent strongly average-case lower bounds for NQP against ACC^0 by [Chen and Ren, STOC 2020].
		
One interesting technical ingredient behind our second result is the construction of a PSPACE-complete language that is paddable, downward self-reducible, same-length checkable, and weakly error correctable. Moreover, all its reducibility properties have corresponding AC^0[2] non-adaptive oracle circuits. Our construction builds and improves upon similar constructions from [Trevisan and Vadhan, Complexity 2007] and [Chen, FOCS 2019], which all require at least TC^0 oracle circuits for implementing these properties.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-19T21:47:54Z">Monday, December 19 2022, 21:47</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://lucatrevisan.wordpress.com/2022/12/19/postdoc-positions-for-2023-24/'>Postdoc Positions for 2023-24</a></h3>
        <p class='tr-article-feed'>from <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I am looking for three postdoctoral fellows for the next academic year to work with me at Bocconi. The positions offer an internationally competitive salary (up to 65,000 Euro per year, tax-free, plus relocation assistance and travel allowance), in a &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I am looking for three postdoctoral fellows for the next academic year to work with me at Bocconi. </p>



<p>The positions offer an internationally competitive salary (up to 65,000 Euro per year, tax-free, plus relocation assistance and travel allowance), in a wonderful location. The <strong>strict</strong> application deadline is <strong>January 31, 2023</strong>. Each position is for one year, renewable to a second year.</p>



<p>Among the topics that I am interested in are spectral graph theory, average-case complexity, “applications” of semidefinite programming, random processes on networks, approximation algorithms, pseudorandomness and combinatorial constructions.</p>



<p>Please contact me if you are interested in these positions and you would like more information.</p>



<p>To apply, go to <strong><a href="https://jobmarket.unibocconi.eu/?type=a&amp;urlBack=/wps/wcm/connect/Bocconi/SitoPubblico_IT/Albero+di+navigazione/Home/docenti+e+ricerca/docenti/Reclutamento+docenti/Concorsi/Assegni+di+Ricerca/">this link</a></strong>, and then look for the opening for 3 positions dated December 6, 2022, like the one below (unfortunately there isn&#8217;t a perma-link to the application form):</p>



<p> </p>



<figure class="wp-block-image size-large"><a href="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023.png"><img data-attachment-id="4657" data-permalink="https://lucatrevisan.wordpress.com/2022/12/19/postdoc-positions-for-2023-24/postdoc-call-2023/" data-orig-file="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023.png" data-orig-size="988,889" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="postdoc-call-2023" data-image-description="" data-image-caption="" data-medium-file="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023.png?w=300" data-large-file="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023.png?w=584" src="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023.png?w=988" alt="" class="wp-image-4657" srcset="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023.png 988w, https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023.png?w=150 150w, https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023.png?w=300 300w, https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023.png?w=768 768w" sizes="(max-width: 988px) 100vw, 988px" /></a></figure>



<p>Bocconi&#8217;s Computing Sciences department has a sizable theory group, that includes <a href="https://laurasanita.github.io/">Laura Sanità</a>, who works on optimization and approximation algorithms, <a href="https://www.alonrosen.net/">Alon Rosen</a>, who works on the foundations of cryptography, <a href="https://elias.ba30.eu/">Marek Elias</a>, who works on online optimization, and <a href="https://andcelli.github.io/">Andrea Celli</a>, who works on algorithmic game theory. Next year, <a href="https://adampolak.github.io/">Adam Polak</a> who works on fine-grained complexity and analysis of algorithms, will also join us.</p>



<p>Speaking of Alon Rosen, he is also recruiting postdocs for the next academic year, and he has two open positions, that you can find at the same link looking for two positions dated December 14 with an application deadline of February 28:</p>



<figure class="wp-block-image size-large"><a href="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023-alon.png"><img data-attachment-id="4659" data-permalink="https://lucatrevisan.wordpress.com/2022/12/19/postdoc-positions-for-2023-24/postdoc-call-2023-alon/" data-orig-file="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023-alon.png" data-orig-size="2079,1395" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="postdoc-call-2023-alon" data-image-description="" data-image-caption="" data-medium-file="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023-alon.png?w=300" data-large-file="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023-alon.png?w=584" src="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023-alon.png?w=1024" alt="" class="wp-image-4659" srcset="https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023-alon.png?w=1024 1024w, https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023-alon.png?w=2048 2048w, https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023-alon.png?w=150 150w, https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023-alon.png?w=300 300w, https://lucatrevisan.files.wordpress.com/2022/12/postdoc-call-2023-alon.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure>
<p class="authors">By luca</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-19T17:18:05Z">Monday, December 19 2022, 17:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2022/12/19/alefs-corner-2/'>Alef’s Corner</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
           
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p></p>


<p><img loading="lazy" data-attachment-id="23657" data-permalink="https://gilkalai.wordpress.com/alef88/" data-orig-file="https://gilkalai.files.wordpress.com/2022/12/alef88.png" data-orig-size="2100,2100" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="alef88" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/12/alef88.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/12/alef88.png?w=640" class="alignnone size-full wp-image-23657" src="https://gilkalai.files.wordpress.com/2022/12/alef88.png" alt="alef88" width="2100" height="2100" srcset="https://gilkalai.files.wordpress.com/2022/12/alef88.png 2100w, https://gilkalai.files.wordpress.com/2022/12/alef88.png?w=150&amp;h=150 150w, https://gilkalai.files.wordpress.com/2022/12/alef88.png?w=300&amp;h=300 300w, https://gilkalai.files.wordpress.com/2022/12/alef88.png?w=768&amp;h=768 768w, https://gilkalai.files.wordpress.com/2022/12/alef88.png?w=1024&amp;h=1024 1024w" sizes="(max-width: 2100px) 100vw, 2100px" /></p>
<p> </p><p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-19T16:19:19Z">Monday, December 19 2022, 16:19</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/12/19/junior-professor-at-university-of-cologne-apply-by-january-31-2023/'>Junior professor at University of Cologne (apply by January 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The department Mathematics/Computer Science seeks to strengthen its competences in the field of efficient algorithms. Possible but not exclusive research areas include randomized algorithms, approximation algorithms, sublinear algorithms and computational geometry. The position is for 3 years with a possibility of extension of another 3 years after a positive evaluation. Website: berufungen.uni-koeln.de/?lang=en Email: mnf-berufungen@uni-koeln.de
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The department Mathematics/Computer Science seeks to strengthen its competences in the field of efficient algorithms. Possible but not exclusive research areas include randomized algorithms, approximation algorithms, sublinear algorithms and computational geometry.</p>
<p>The position is for 3 years with a possibility of extension of another 3 years after a positive evaluation.</p>
<p>Website: <a href="https://berufungen.uni-koeln.de/?lang=en">https://berufungen.uni-koeln.de/?lang=en</a><br />
Email: mnf-berufungen@uni-koeln.de</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-19T12:37:15Z">Monday, December 19 2022, 12:37</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://blog.computationalcomplexity.org/2022/12/voter-suppression-harvard-style.html'>Voter Suppression, Harvard Style</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p><br></p><p>The following appeared on Harry Lewis's blog, here,&nbsp;hence it is written in his voice, though it is a co-authored. You'll see why later.&nbsp; I then have some comments on it.&nbsp;</p><p>------------------------------------------</p><p>Voter Suppression, Harvard-Style</p><p>(This piece is jointly authored by Harry Lewis (Harvard) and Bill Gasarch</p><p>(University of Maryland at College Park). Harry was Bill's PhD Advisor.)</p><p>There are elections in Hong Kong, but to get on the ballot you have to be nominated by a committee controlled by Beijing government.</p><p>Elections for the Harvard Board of Overseers—one of Harvard’s two governing bodies—are almost as well-controlled. A Harvard Alumni Association (HAA) nominating committee curates a slate of candidates, from which alumni make their selections.</p><p>But an alternative route to get on the Harvard ballot exists, at least in theory. So-called “petition” candidates have always been rare—but after several climate activists were elected in 2020, the rules were changed to make it even harder. Among other things, the number of petitions to get on the ballot was raised by a factor of fifteen, to more than three thousand.</p><p>This year, noted civil libertarian Harvey Silverglate, concerned about freedom of expression at Harvard, is trying to make it onto the ballot.</p><p>The authors are computer scientists. We are neither technologically naïve nor afraid of computers. Harry has long been concerned about issues of student freedom and Harvard governance, and suggested to Bill, Harry’s sometime PhD student, that he sign Silverglate’s petition. This is an account of Bill’s trip through the resulting electronic purgatory.</p><p>To add your name, you have to fill out a web form. To access the web form, you need a HarvardKey. To get a HarvardKey, you have to fill out another web form. So far, so good.</p><p>The HarvardKey web form wanted Bill’s 10-digit HAA ID, which he was told to find on the address sticker of his copy of a recent Harvard Magazine (sent to all alumni). Bill had one handy, so he looked and found … a 9-digit number. He tried entering that number—no luck. He noticed it began with three 0s, and tried adding a fourth—that did not work either.</p><p>The web form had a number to call. Someone answered, and said some information would be needed before dealing with digits. Name (fine). Year of degree (fine). MIDDLE name (well, fine, though no one but Bill’s mother ever used it, and only when indignant). Date of birth (well, OK, but now we’re getting into territory we don’t casually reveal any more). When he got his MASTER’s degree. Bill did not know—that’s just something Harvard gives en route to the PhD. Turned out he actually didn’t need to know, an estimate was good enough. The person on the phone gave him his HAA ID, which bore no relation to the number on his address sticker.</p><p>Let’s pause there. Some people never call tech support because they have never found it helpful to do so. Any such person with a 9-digit address sticker number could not participate in the petition process.</p><p>Bill entered his HAA ID and received an error message saying that … KEY-5003 was missing. Happily, Bill had kept the support person on the phone (this was not his first rodeo).</p><p>Missing KEY-5003 turned out to mean that Harvard did not have his email address. He supplied it and was told he would get an email confirmation later in the day.</p><p>He did get an email later in the day. It listed eleven steps to claim his HarvardKey. Step 6 was to wait for a confirming email (he thought this WAS the confirming email), but after step 5 the system told him he was not in the system and it could not continue.</p><p>Another call to a support line. No, Bill was told, he has to wait 24 hours to get his email address updated, and would not get a confirming email. Just try tomorrow. Like the email said. Except that it didn’t say that, nor had the person he spoke to on the previous call.</p><p>Bill waited 24 hours and tried again, and got a little further through the eleven steps—and then was told to wait ANOTHER 24 hours for the account to activate.</p><p>24 hours later he tried again, from home, and failed again. Then he went to his office and succeeded—no clue why.</p><p>Now finally he got to the petition, which required Bill’s graduation year—and Silverglate’s­­, which Bill found but shouldn’t have been needed since this petition was specific to Silverglate.</p><p>Three days and two phone calls to sign the petition. To be fair, the people Bill spoke to on the phone were kind and helpful. Probably they themselves were struggling with the systems.</p><p>And we knew already that HAA is technologically challenged. A few weeks ago, it abruptly announced that it could no longer handle email forwarding. After alumni blowback, it just as abruptly announced that it would NOT end its forwarding service—oddly, while cautioning that the service was unlikely ever to work very well.</p><p>When election officials want to suppress the vote somewhere, they under-resource the voting process, forcing voters to cross town and wait in long lines. What happened to Bill is so comical that it is hard to imagine that the specifics were intentional. On the other hand, under-resourcing the petitioning process, allowing it to be so defective, misinformed, and hard to use that many people won’t exercise their franchise—isn’t that a form of voter suppression?</p><p>Why not be true to Harvard’s motto, Veritas, and just post on the web, For the alumni to choose the Overseers is an anachronism. Today’s alumni voters can’t be trusted to do it wisely. Since we can’t get rid of this system, we are going to make it all but impossible to nominate by petition. Try if you wish, but if you do, abandon all hope, ye who enter here.</p><p>-------------------------</p><p>I originally emailed Harry what I had to do to sign the petition with my point being</p><p>`Yes, I am a luddite but that has NOTHING TO DO with why I am having a problem.''</p><p>(I had meant to do a blog on that topic. I may still.)</p><p>Harry saw this for what it was- Voter Suppression. He wrote the Op-Ed using my story and made me a co-author. (We have never published together so it amused me that our first pub together would be 37 years after he was my advisor- perhaps a record. Does having a joint blog post count?) What is above is basically that Op-Ed (I think the version Harry submitted omitted that my mom is the only one who uses my middle name.)&nbsp;</p><p>He submitted this as an Op-Ed to three places sequentially.&nbsp;</p><p>1) The New York Times turned us down (not a surprise) by not even acknowledging it had been submitted (really?).</p><p>2) The Boston Globe turned us down (a surprise).</p><p>3) The Harvard Crimson turned us down (a shock!).</p><p>Voter Suppression followed by censorship.</p><p>AND back to the original issue: Harvey does not have enough people on the petition yet. I urge you to READ Harry Lewis's post on Harvey&nbsp;here&nbsp;and IF you are a Harvard Alumni AND you agree that Harvey would be a good overseer THEN sign the petition. Or at least try.</p><br><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><br /></p><p>The following appeared on Harry Lewis's blog, <a href="http://harry-lewis.blogspot.com/2022/12/voter-suppression-harvard-style.html">here</a>,&nbsp;hence it is written in his voice, though it is a co-authored. You'll see why later.&nbsp; I then have some comments on it.&nbsp;</p><p>------------------------------------------</p><p>Voter Suppression, Harvard-Style</p><p>(This piece is jointly authored by Harry Lewis (Harvard) and Bill Gasarch</p><p>(University of Maryland at College Park). Harry was Bill's PhD Advisor.)</p><p>There are elections in Hong Kong, but to get on the ballot you have to be nominated by a committee controlled by Beijing government.</p><p>Elections for the Harvard Board of Overseers—one of Harvard’s two governing bodies—are almost as well-controlled. A Harvard Alumni Association (HAA) nominating committee curates a slate of candidates, from which alumni make their selections.</p><p>But an alternative route to get on the Harvard ballot exists, at least in theory. So-called “petition” candidates have always been rare—but after several climate activists were elected in 2020, the rules were changed to make it even harder. Among other things, the number of petitions to get on the ballot was raised by a factor of fifteen, to more than three thousand.</p><p>This year, noted civil libertarian Harvey Silverglate, concerned about freedom of expression at Harvard, is trying to make it onto the ballot.</p><p>The authors are computer scientists. We are neither technologically naïve nor afraid of computers. Harry has long been concerned about issues of student freedom and Harvard governance, and suggested to Bill, Harry’s sometime PhD student, that he sign Silverglate’s petition. This is an account of Bill’s trip through the resulting electronic purgatory.</p><p>To add your name, you have to fill out a web form. To access the web form, you need a HarvardKey. To get a HarvardKey, you have to fill out another web form. So far, so good.</p><p>The HarvardKey web form wanted Bill’s 10-digit HAA ID, which he was told to find on the address sticker of his copy of a recent Harvard Magazine (sent to all alumni). Bill had one handy, so he looked and found … a 9-digit number. He tried entering that number—no luck. He noticed it began with three 0s, and tried adding a fourth—that did not work either.</p><p>The web form had a number to call. Someone answered, and said some information would be needed before dealing with digits. Name (fine). Year of degree (fine). MIDDLE name (well, fine, though no one but Bill’s mother ever used it, and only when indignant). Date of birth (well, OK, but now we’re getting into territory we don’t casually reveal any more). When he got his MASTER’s degree. Bill did not know—that’s just something Harvard gives en route to the PhD. Turned out he actually didn’t need to know, an estimate was good enough. The person on the phone gave him his HAA ID, which bore no relation to the number on his address sticker.</p><p>Let’s pause there. Some people never call tech support because they have never found it helpful to do so. Any such person with a 9-digit address sticker number could not participate in the petition process.</p><p>Bill entered his HAA ID and received an error message saying that … KEY-5003 was missing. Happily, Bill had kept the support person on the phone (this was not his first rodeo).</p><p>Missing KEY-5003 turned out to mean that Harvard did not have his email address. He supplied it and was told he would get an email confirmation later in the day.</p><p>He did get an email later in the day. It listed eleven steps to claim his HarvardKey. Step 6 was to wait for a confirming email (he thought this WAS the confirming email), but after step 5 the system told him he was not in the system and it could not continue.</p><p>Another call to a support line. No, Bill was told, he has to wait 24 hours to get his email address updated, and would not get a confirming email. Just try tomorrow. Like the email said. Except that it didn’t say that, nor had the person he spoke to on the previous call.</p><p>Bill waited 24 hours and tried again, and got a little further through the eleven steps—and then was told to wait ANOTHER 24 hours for the account to activate.</p><p>24 hours later he tried again, from home, and failed again. Then he went to his office and succeeded—no clue why.</p><p>Now finally he got to the petition, which required Bill’s graduation year—and Silverglate’s­­, which Bill found but shouldn’t have been needed since this petition was specific to Silverglate.</p><p>Three days and two phone calls to sign the petition. To be fair, the people Bill spoke to on the phone were kind and helpful. Probably they themselves were struggling with the systems.</p><p>And we knew already that HAA is technologically challenged. A few weeks ago, it abruptly announced that it could no longer handle email forwarding. After alumni blowback, it just as abruptly announced that it would NOT end its forwarding service—oddly, while cautioning that the service was unlikely ever to work very well.</p><p>When election officials want to suppress the vote somewhere, they under-resource the voting process, forcing voters to cross town and wait in long lines. What happened to Bill is so comical that it is hard to imagine that the specifics were intentional. On the other hand, under-resourcing the petitioning process, allowing it to be so defective, misinformed, and hard to use that many people won’t exercise their franchise—isn’t that a form of voter suppression?</p><p>Why not be true to Harvard’s motto, Veritas, and just post on the web, <i>For the alumni to choose the</i> <i>Overseers is an anachronism. Today’s alumni voters can’t be trusted to do it wisely. Since we can’t get</i> <i>rid of this system, we are going to make it all but impossible to nominate by petition. Try if you wish, but if you do, abandon all hope, ye who enter here.</i></p><p>-------------------------</p><p>I originally emailed Harry what I had to do to sign the petition with my point being</p><p>`Yes, I am a luddite but that has NOTHING TO DO with why I am having a problem.''</p><p>(I had meant to do a blog on that topic. I may still.)</p><p>Harry saw this for what it was- Voter Suppression. He wrote the Op-Ed using my story and made me a co-author. (We have never published together so it amused me that our first pub together would be 37 years after he was my advisor- perhaps a record. Does having a joint blog post count?) What is above is basically that Op-Ed (I think the version Harry submitted omitted that my mom is the only one who uses my middle name.)&nbsp;</p><p>He submitted this as an Op-Ed to three places sequentially.&nbsp;</p><p>1) The New York Times turned us down (not a surprise) by not even acknowledging it had been submitted (really?).</p><p>2) The Boston Globe turned us down (a surprise).</p><p>3) The Harvard Crimson turned us down (a shock!).</p><p>Voter Suppression followed by censorship.</p><p>AND back to the original issue: Harvey does not have enough people on the petition yet. I urge you to READ Harry Lewis's post on Harvey&nbsp;<a href="http://harry-lewis.blogspot.com/2022/11/harvard-alumni-sign-harvey-silverglates.html">here</a>&nbsp;and IF you are a Harvard Alumni AND you agree that Harvey would be a good overseer THEN sign the petition. Or at least try.</p><div><br /></div><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-19T05:12:00Z">Monday, December 19 2022, 05:12</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.08397'>Criticality of $AC^0$ formulae</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Prahladh Harsha, Tulasi mohan Molli, Ashutosh Shankar</p><p>Rossman [In \emph{Proc.\ $34$th Comput.\ Complexity Conf.}, 2019] introduced
the notion of \emph{criticality}. The criticality of a Boolean function $f
\colon \zo^n \to \zo$ is the minimum $\lambda \geq 1$ such that for all
positive integers $t$, \[ \Pr_{\brho \sim
\calR_p}\left[\DT_{\depth}(f|_{\brho}) \geq t\right] \leq (p\lambda)^t. \]
\hastad's celebrated switching lemma shows that the criticality of any $k$-DNF
is at most $O(k)$. Subsequent improvements to correlation bounds of
$\AC^0$-circuits against parity showed that the criticality of any
$\AC^0$-\emph{circuit} of size $S$ and depth $d+1$ is at most $O(\log S)^d$ and
any \emph{regular} $\AC^0$-\emph{formula} of size $S$ and depth $d+1$ is at
most $O(\frac1d \cdot \log S)^d$. We strengthen these results by showing that
the criticality of \emph{any} $\AC^0$-formula (not necessarily regular) of size
$S$ and depth $d+1$ is at most $O(\frac{\log S}{d})^d$, resolving a conjecture
due to Rossman.
</p>
<p>This result also implies Rossman's optimal lower bound on the size of any
depth-$d$ $\AC^0$-formula computing parity [Comput.\ Complexity,
27(2):209--223, 2018.]. Our result implies tight correlation bounds against
parity, tight Fourier concentration results and improved \#SAT algorithm for
$\AC^0$-formulae.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Harsha_P/0/1/0/all/0/1">Prahladh Harsha</a>, <a href="http://arxiv.org/find/cs/1/au:+Molli_T/0/1/0/all/0/1">Tulasi mohan Molli</a>, <a href="http://arxiv.org/find/cs/1/au:+Shankar_A/0/1/0/all/0/1">Ashutosh Shankar</a></p><p>Rossman [In \emph{Proc.\ $34$th Comput.\ Complexity Conf.}, 2019] introduced
the notion of \emph{criticality}. The criticality of a Boolean function $f
\colon \zo^n \to \zo$ is the minimum $\lambda \geq 1$ such that for all
positive integers $t$, \[ \Pr_{\brho \sim
\calR_p}\left[\DT_{\depth}(f|_{\brho}) \geq t\right] \leq (p\lambda)^t. \]
\hastad's celebrated switching lemma shows that the criticality of any $k$-DNF
is at most $O(k)$. Subsequent improvements to correlation bounds of
$\AC^0$-circuits against parity showed that the criticality of any
$\AC^0$-\emph{circuit} of size $S$ and depth $d+1$ is at most $O(\log S)^d$ and
any \emph{regular} $\AC^0$-\emph{formula} of size $S$ and depth $d+1$ is at
most $O(\frac1d \cdot \log S)^d$. We strengthen these results by showing that
the criticality of \emph{any} $\AC^0$-formula (not necessarily regular) of size
$S$ and depth $d+1$ is at most $O(\frac{\log S}{d})^d$, resolving a conjecture
due to Rossman.
</p>
<p>This result also implies Rossman's optimal lower bound on the size of any
depth-$d$ $\AC^0$-formula computing parity [Comput.\ Complexity,
27(2):209--223, 2018.]. Our result implies tight correlation bounds against
parity, tight Fourier concentration results and improved \#SAT algorithm for
$\AC^0$-formulae.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-19T01:30:00Z">Monday, December 19 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2212.08559'>Grothendieck inequalities characterize converses to the polynomial method</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jop Bri&#xeb;t, Francisco Escudero Guti&#xe9;rrez, Sander Gribling</p><p>A surprising 'converse to the polynomial method' of Aaronson et al. (CCC'16)
shows that any bounded quadratic polynomial can be computed exactly in
expectation by a 1-query algorithm up to a universal multiplicative factor
related to the famous Grothendieck constant. Here we show that such a result
does not generalize to quartic polynomials and 2-query algorithms, even when we
allow for additive approximations. We also show that the additive approximation
implied by their result is tight for bounded bilinear forms, which gives a new
characterization of the Grothendieck constant in terms of 1-query quantum
algorithms. Along the way we provide reformulations of the completely bounded
norm of a form, and its dual norm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Briet_J/0/1/0/all/0/1">Jop Bri&#xeb;t</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gutierrez_F/0/1/0/all/0/1">Francisco Escudero Guti&#xe9;rrez</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gribling_S/0/1/0/all/0/1">Sander Gribling</a></p><p>A surprising 'converse to the polynomial method' of Aaronson et al. (CCC'16)
shows that any bounded quadratic polynomial can be computed exactly in
expectation by a 1-query algorithm up to a universal multiplicative factor
related to the famous Grothendieck constant. Here we show that such a result
does not generalize to quartic polynomials and 2-query algorithms, even when we
allow for additive approximations. We also show that the additive approximation
implied by their result is tight for bounded bilinear forms, which gives a new
characterization of the Grothendieck constant in terms of 1-query quantum
algorithms. Along the way we provide reformulations of the completely bounded
norm of a form, and its dual norm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-12-19T01:30:00Z">Monday, December 19 2022, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
