<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2022-11-10T10:40:17Z">Thursday, November 10 2022, 10:40</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, November 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.05069'>Basis for a vector space generated by Hamiltonian time paths in a complete time graph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Malay Dutta, Anjana K. Mahanta</p><p>In this paper we introduce the notion of a complete time graph of order n. We
define time paths and Hamiltonian time paths in a complete time graph. Each
Hamiltonian time path (htp) is associated with some permutation p of the
integers 1 to n. The characteristic function of this path forms a vector in the
vector space of rational-valued functions on the set of edges of the compete
time graph. We will consider the vector space generated by these functions. The
main result in this paper is to determine the dimension of this vector space
for n greater than or equal to 5. We also give an algorithm with its complexity
for the construction of a basis in this vector space.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dutta_M/0/1/0/all/0/1">Malay Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahanta_A/0/1/0/all/0/1">Anjana K. Mahanta</a></p><p>In this paper we introduce the notion of a complete time graph of order n. We
define time paths and Hamiltonian time paths in a complete time graph. Each
Hamiltonian time path (htp) is associated with some permutation p of the
integers 1 to n. The characteristic function of this path forms a vector in the
vector space of rational-valued functions on the set of edges of the compete
time graph. We will consider the vector space generated by these functions. The
main result in this paper is to determine the dimension of this vector space
for n greater than or equal to 5. We also give an algorithm with its complexity
for the construction of a basis in this vector space.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04797'>Shortest Cycles With Monotone Submodular Costs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fedor V. Fomin, Petr A. Golovach, Tuukka Korhonen, Daniel Lokshtanov, Giannos Stamoulis</p><p>We introduce the following submodular generalization of the Shortest Cycle
problem. For a nonnegative monotone submodular cost function $f$ defined on the
edges (or the vertices) of an undirected graph $G$, we seek for a cycle $C$ in
$G$ of minimum cost $\textsf{OPT}=f(C)$. We give an algorithm that given an
$n$-vertex graph $G$, parameter $\varepsilon &gt; 0$, and the function $f$
represented by an oracle, in time $n^{\mathcal{O}(\log 1/\varepsilon)}$ finds a
cycle $C$ in $G$ with $f(C)\leq (1+\varepsilon)\cdot \textsf{OPT}$. This is in
sharp contrast with the non-approximability of the closely related Monotone
Submodular Shortest $(s,t)$-Path problem, which requires exponentially many
queries to the oracle for finding an $n^{2/3-\varepsilon}$-approximation [Goel
et al., FOCS 2009]. We complement our algorithm with a matching lower bound. We
show that for every $\varepsilon &gt; 0$, obtaining a
$(1+\varepsilon)$-approximation requires at least $n^{\Omega(\log 1/
\varepsilon)}$ queries to the oracle. When the function $f$ is integer-valued,
our algorithm yields that a cycle of cost $\textsf{OPT}$ can be found in time
$n^{\mathcal{O}(\log \textsf{OPT})}$. In particular, for
$\textsf{OPT}=n^{\mathcal{O}(1)}$ this gives a quasipolynomial-time algorithm
computing a cycle of minimum submodular cost. Interestingly, while a
quasipolynomial-time algorithm often serves as a good indication that a
polynomial time complexity could be achieved, we show a lower bound that
$n^{\mathcal{O}(\log n)}$ queries are required even when $\textsf{OPT} =
\mathcal{O}(n)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fomin_F/0/1/0/all/0/1">Fedor V. Fomin</a>, <a href="http://arxiv.org/find/cs/1/au:+Golovach_P/0/1/0/all/0/1">Petr A. Golovach</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_T/0/1/0/all/0/1">Tuukka Korhonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lokshtanov_D/0/1/0/all/0/1">Daniel Lokshtanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Stamoulis_G/0/1/0/all/0/1">Giannos Stamoulis</a></p><p>We introduce the following submodular generalization of the Shortest Cycle
problem. For a nonnegative monotone submodular cost function $f$ defined on the
edges (or the vertices) of an undirected graph $G$, we seek for a cycle $C$ in
$G$ of minimum cost $\textsf{OPT}=f(C)$. We give an algorithm that given an
$n$-vertex graph $G$, parameter $\varepsilon &gt; 0$, and the function $f$
represented by an oracle, in time $n^{\mathcal{O}(\log 1/\varepsilon)}$ finds a
cycle $C$ in $G$ with $f(C)\leq (1+\varepsilon)\cdot \textsf{OPT}$. This is in
sharp contrast with the non-approximability of the closely related Monotone
Submodular Shortest $(s,t)$-Path problem, which requires exponentially many
queries to the oracle for finding an $n^{2/3-\varepsilon}$-approximation [Goel
et al., FOCS 2009]. We complement our algorithm with a matching lower bound. We
show that for every $\varepsilon &gt; 0$, obtaining a
$(1+\varepsilon)$-approximation requires at least $n^{\Omega(\log 1/
\varepsilon)}$ queries to the oracle. When the function $f$ is integer-valued,
our algorithm yields that a cycle of cost $\textsf{OPT}$ can be found in time
$n^{\mathcal{O}(\log \textsf{OPT})}$. In particular, for
$\textsf{OPT}=n^{\mathcal{O}(1)}$ this gives a quasipolynomial-time algorithm
computing a cycle of minimum submodular cost. Interestingly, while a
quasipolynomial-time algorithm often serves as a good indication that a
polynomial time complexity could be achieved, we show a lower bound that
$n^{\mathcal{O}(\log n)}$ queries are required even when $\textsf{OPT} =
\mathcal{O}(n)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04506'>On the cut-query complexity of approximating max-cut</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Orestis Plevrakis, Seyoon Ragavan, S. Matthew Weinberg</p><p>We consider the problem of query-efficient global max-cut on a weighted
undirected graph in the value oracle model examined by [RSW18]. This model
arises as a natural special case of submodular function maximization: on query
$S \subseteq V$, the oracle returns the total weight of the cut between $S$ and
$V \backslash S$.
</p>
<p>For most constants $c \in (0,1]$, we nail down the query complexity of
achieving a $c$-approximation, for both deterministic and randomized algorithms
(up to logarithmic factors). Analogously to general submodular function
maximization in the same model, we observe a phase transition at $c = 1/2$: we
design a deterministic algorithm for global $c$-approximate max-cut in $O(\log
n)$ queries for any $c &lt; 1/2$, and show that any randomized algorithm requires
$\tilde{\Omega}(n)$ queries to find a $c$-approximate max-cut for any $c &gt;
1/2$. Additionally, we show that any deterministic algorithm requires
$\Omega(n^2)$ queries to find an exact max-cut (enough to learn the entire
graph), and develop a $\tilde{O}(n)$-query randomized $c$-approximation for any
$c &lt; 1$.
</p>
<p>Our approach provides two technical contributions that may be of independent
interest. One is a query-efficient sparsifier for undirected weighted graphs
(prior work of [RSW18] holds only for unweighted graphs). Another is an
extension of the cut dimension to rule out approximation (prior work of
[GPRW20] introducing the cut dimension only rules out exact solutions).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Plevrakis_O/0/1/0/all/0/1">Orestis Plevrakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Ragavan_S/0/1/0/all/0/1">Seyoon Ragavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinberg_S/0/1/0/all/0/1">S. Matthew Weinberg</a></p><p>We consider the problem of query-efficient global max-cut on a weighted
undirected graph in the value oracle model examined by [RSW18]. This model
arises as a natural special case of submodular function maximization: on query
$S \subseteq V$, the oracle returns the total weight of the cut between $S$ and
$V \backslash S$.
</p>
<p>For most constants $c \in (0,1]$, we nail down the query complexity of
achieving a $c$-approximation, for both deterministic and randomized algorithms
(up to logarithmic factors). Analogously to general submodular function
maximization in the same model, we observe a phase transition at $c = 1/2$: we
design a deterministic algorithm for global $c$-approximate max-cut in $O(\log
n)$ queries for any $c &lt; 1/2$, and show that any randomized algorithm requires
$\tilde{\Omega}(n)$ queries to find a $c$-approximate max-cut for any $c &gt;
1/2$. Additionally, we show that any deterministic algorithm requires
$\Omega(n^2)$ queries to find an exact max-cut (enough to learn the entire
graph), and develop a $\tilde{O}(n)$-query randomized $c$-approximation for any
$c &lt; 1$.
</p>
<p>Our approach provides two technical contributions that may be of independent
interest. One is a query-efficient sparsifier for undirected weighted graphs
(prior work of [RSW18] holds only for unweighted graphs). Another is an
extension of the cut dimension to rule out approximation (prior work of
[GPRW20] introducing the cut dimension only rules out exact solutions).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04601'>Universal Sorting: Finding a DAG using Priced Comparisons</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mayank Goswami, Riko Jacob</p><p>We resolve two open problems in sorting with priced information, introduced
by [Charikar, Fagin, Guruswami, Kleinberg, Raghavan, Sahai (CFGKRS), STOC
2000]. In this setting, different comparisons have different (potentially
infinite) costs. The goal is to sort with small competitive ratio (algorithmic
cost divided by cheapest proof).
</p>
<p>1) When all costs are in $\{0,1,n,\infty\}$, we give an algorithm that has
$\widetilde{O}(n^{3/4})$ competitive ratio. Our algorithm generalizes the
algorithms for generalized sorting (all costs are either $1$ or $\infty$), a
version initiated by [Huang, Kannan, Khanna, FOCS 2011] and addressed recently
by [Kuszmaul, Narayanan, FOCS 2021].
</p>
<p>2) We answer the problem of bichromatic sorting posed by [CFGKRS]: The input
is split into $A$ and $B$, and $A-A$ and $B-B$ comparisons are more expensive
than an $A-B$ comparisons. We give a randomized algorithm with a O(polylog n)
competitive ratio.
</p>
<p>These results are obtained by introducing the universal sorting problem,
which generalizes the existing framework in two important ways. We remove the
promise of a directed Hamiltonian path in the DAG of all comparisons. Instead,
we require that an algorithm outputs the transitive reduction of the DAG. For
bichromatic sorting, when $A-A$ and $B-B$ comparisons cost $\infty$, this
generalizes the well-known nuts and bolts problem. We initiate an
instance-based study of the universal sorting problem. Our definition of
instance-optimality is inherently more algorithmic than that of the competitive
ratio in that we compare the cost of a candidate algorithm to the cost of the
optimal instance-aware algorithm. This unifies existing lower bounds, and opens
up the possibility of an $O(1)$-instance optimal algorithm for the bichromatic
version.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Goswami_M/0/1/0/all/0/1">Mayank Goswami</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacob_R/0/1/0/all/0/1">Riko Jacob</a></p><p>We resolve two open problems in sorting with priced information, introduced
by [Charikar, Fagin, Guruswami, Kleinberg, Raghavan, Sahai (CFGKRS), STOC
2000]. In this setting, different comparisons have different (potentially
infinite) costs. The goal is to sort with small competitive ratio (algorithmic
cost divided by cheapest proof).
</p>
<p>1) When all costs are in $\{0,1,n,\infty\}$, we give an algorithm that has
$\widetilde{O}(n^{3/4})$ competitive ratio. Our algorithm generalizes the
algorithms for generalized sorting (all costs are either $1$ or $\infty$), a
version initiated by [Huang, Kannan, Khanna, FOCS 2011] and addressed recently
by [Kuszmaul, Narayanan, FOCS 2021].
</p>
<p>2) We answer the problem of bichromatic sorting posed by [CFGKRS]: The input
is split into $A$ and $B$, and $A-A$ and $B-B$ comparisons are more expensive
than an $A-B$ comparisons. We give a randomized algorithm with a O(polylog n)
competitive ratio.
</p>
<p>These results are obtained by introducing the universal sorting problem,
which generalizes the existing framework in two important ways. We remove the
promise of a directed Hamiltonian path in the DAG of all comparisons. Instead,
we require that an algorithm outputs the transitive reduction of the DAG. For
bichromatic sorting, when $A-A$ and $B-B$ comparisons cost $\infty$, this
generalizes the well-known nuts and bolts problem. We initiate an
instance-based study of the universal sorting problem. Our definition of
instance-optimality is inherently more algorithmic than that of the competitive
ratio in that we compare the cost of a candidate algorithm to the cost of the
optimal instance-aware algorithm. This unifies existing lower bounds, and opens
up the possibility of an $O(1)$-instance optimal algorithm for the bichromatic
version.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04627'>Computing (1+epsilon)-Approximate Degeneracy in Sublinear Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Valerie King, Alex Thomo, Quinton Yong</p><p>The problem of finding the degeneracy of a graph is a subproblem of the
k-core decomposition problem. In this paper, we present a (1 +
epsilon)-approximate solution to the degeneracy problem which runs in O(n log
n) time, sublinear in the input size for dense graphs, by sampling a small
number of neighbors adjacent to high degree nodes. Our algorithm can also be
extended to an O(n log n) time solution to the k-core decomposition problem.
This improves upon the method by Bhattacharya et al., which implies a (4 +
epsilon)-approximate ~O(n) solution to the degeneracy problem, and our
techniques are similar to other sketching methods which use sublinear space for
k-core and degeneracy. We prove theoretical guarantees of our algorithm and
provide optimizations, which improve the running time of our algorithm in
practice. Experiments on massive real-world web graphs show that our algorithm
performs significantly faster than previous methods for computing degeneracy,
including the 2022 exact degeneracy algorithm by Li et al.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+King_V/0/1/0/all/0/1">Valerie King</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomo_A/0/1/0/all/0/1">Alex Thomo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yong_Q/0/1/0/all/0/1">Quinton Yong</a></p><p>The problem of finding the degeneracy of a graph is a subproblem of the
k-core decomposition problem. In this paper, we present a (1 +
epsilon)-approximate solution to the degeneracy problem which runs in O(n log
n) time, sublinear in the input size for dense graphs, by sampling a small
number of neighbors adjacent to high degree nodes. Our algorithm can also be
extended to an O(n log n) time solution to the k-core decomposition problem.
This improves upon the method by Bhattacharya et al., which implies a (4 +
epsilon)-approximate ~O(n) solution to the degeneracy problem, and our
techniques are similar to other sketching methods which use sublinear space for
k-core and degeneracy. We prove theoretical guarantees of our algorithm and
provide optimizations, which improve the running time of our algorithm in
practice. Experiments on massive real-world web graphs show that our algorithm
performs significantly faster than previous methods for computing degeneracy,
including the 2022 exact degeneracy algorithm by Li et al.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04639'>A 4/3-Approximation Algorithm for Half-Integral Cycle Cut Instances of the TSP</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Billy Jin, Nathan Klein, David P. Williamson</p><p>A long-standing conjecture for the traveling salesman problem (TSP) states
that the integrality gap of the standard linear programming relaxation of the
TSP is at most 4/3. Despite significant efforts, the conjecture remains open.
</p>
<p>We consider the half-integral case, in which the LP has solution values in
$\{0, 1/2, 1\}$. Such instances have been conjectured to be the most difficult
instances for the overall four-thirds conjecture. Karlin, Klein, and Oveis
Gharan, in a breakthrough result, were able to show that in the half-integral
case, the integrality gap is at most 1.49993. This result led to the first
significant progress on the overall conjecture in decades; the same authors
showed the integrality gap is at most $1.5- 10^{-36}$ in the non-half-integral
case. For the half-integral case, the current best-known ratio is 1.4983, a
result by Gupta et al.
</p>
<p>With the improvements on the 3/2 bound remaining very incremental even in the
half-integral case, we turn the question around and look for a large class of
half-integral instances for which we can prove that the 4/3 conjecture is
correct.
</p>
<p>The previous works on the half-integral case perform induction on a hierarchy
of critical tight sets in the support graph of the LP solution, in which some
of the sets correspond to "cycle cuts" and the others to "degree cuts". We show
that if all the sets in the hierarchy correspond to cycle cuts, then we can
find a distribution of tours whose expected cost is at most 4/3 times the value
of the half-integral LP solution; sampling from the distribution gives us a
randomized 4/3-approximation algorithm. We note that the known bad cases for
the integrality gap have a gap of 4/3 and have a half-integral LP solution in
which all the critical tight sets in the hierarchy are cycle cuts; thus our
result is tight.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1">Billy Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_N/0/1/0/all/0/1">Nathan Klein</a>, <a href="http://arxiv.org/find/cs/1/au:+Williamson_D/0/1/0/all/0/1">David P. Williamson</a></p><p>A long-standing conjecture for the traveling salesman problem (TSP) states
that the integrality gap of the standard linear programming relaxation of the
TSP is at most 4/3. Despite significant efforts, the conjecture remains open.
</p>
<p>We consider the half-integral case, in which the LP has solution values in
$\{0, 1/2, 1\}$. Such instances have been conjectured to be the most difficult
instances for the overall four-thirds conjecture. Karlin, Klein, and Oveis
Gharan, in a breakthrough result, were able to show that in the half-integral
case, the integrality gap is at most 1.49993. This result led to the first
significant progress on the overall conjecture in decades; the same authors
showed the integrality gap is at most $1.5- 10^{-36}$ in the non-half-integral
case. For the half-integral case, the current best-known ratio is 1.4983, a
result by Gupta et al.
</p>
<p>With the improvements on the 3/2 bound remaining very incremental even in the
half-integral case, we turn the question around and look for a large class of
half-integral instances for which we can prove that the 4/3 conjecture is
correct.
</p>
<p>The previous works on the half-integral case perform induction on a hierarchy
of critical tight sets in the support graph of the LP solution, in which some
of the sets correspond to "cycle cuts" and the others to "degree cuts". We show
that if all the sets in the hierarchy correspond to cycle cuts, then we can
find a distribution of tours whose expected cost is at most 4/3 times the value
of the half-integral LP solution; sampling from the distribution gives us a
randomized 4/3-approximation algorithm. We note that the known bad cases for
the integrality gap have a gap of 4/3 and have a half-integral LP solution in
which all the critical tight sets in the hierarchy are cycle cuts; thus our
result is tight.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04643'>Faster Walsh-Hadamard Transform and Matrix Multiplication over Finite Fields using Lookup Tables</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Josh Alman</p><p>We use lookup tables to design faster algorithms for important algebraic
problems over finite fields. These faster algorithms, which only use arithmetic
operations and lookup table operations, may help to explain the difficulty of
determining the complexities of these important problems. Our results over a
constant-sized finite field are as follows.
</p>
<p>The Walsh-Hadamard transform of a vector of length $N$ can be computed using
$O(N \log N / \log \log N)$ bit operations. This generalizes to any transform
defined as a Kronecker power of a fixed matrix. By comparison, the Fast
Walsh-Hadamard transform (similar to the Fast Fourier transform) uses $O(N \log
N)$ arithmetic operations, which is believed to be optimal up to constant
factors.
</p>
<p>Any algebraic algorithm for multiplying two $N \times N$ matrices using
$O(N^\omega)$ operations can be converted into an algorithm using $O(N^\omega /
(\log N)^{\omega/2 - 1})$ bit operations. For example, Strassen's algorithm can
be converted into an algorithm using $O(N^{2.81} / (\log N)^{0.4})$ bit
operations. It remains an open problem with practical implications to determine
the smallest constant $c$ such that Strassen's algorithm can be implemented to
use $c \cdot N^{2.81} + o(N^{2.81})$ arithmetic operations; using a lookup
table allows one to save a super-constant factor in bit operations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alman_J/0/1/0/all/0/1">Josh Alman</a></p><p>We use lookup tables to design faster algorithms for important algebraic
problems over finite fields. These faster algorithms, which only use arithmetic
operations and lookup table operations, may help to explain the difficulty of
determining the complexities of these important problems. Our results over a
constant-sized finite field are as follows.
</p>
<p>The Walsh-Hadamard transform of a vector of length $N$ can be computed using
$O(N \log N / \log \log N)$ bit operations. This generalizes to any transform
defined as a Kronecker power of a fixed matrix. By comparison, the Fast
Walsh-Hadamard transform (similar to the Fast Fourier transform) uses $O(N \log
N)$ arithmetic operations, which is believed to be optimal up to constant
factors.
</p>
<p>Any algebraic algorithm for multiplying two $N \times N$ matrices using
$O(N^\omega)$ operations can be converted into an algorithm using $O(N^\omega /
(\log N)^{\omega/2 - 1})$ bit operations. For example, Strassen's algorithm can
be converted into an algorithm using $O(N^{2.81} / (\log N)^{0.4})$ bit
operations. It remains an open problem with practical implications to determine
the smallest constant $c$ such that Strassen's algorithm can be implemented to
use $c \cdot N^{2.81} + o(N^{2.81})$ arithmetic operations; using a lookup
table allows one to save a super-constant factor in bit operations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04674'>Lipschitz Continuous Algorithms for Graph Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Soh Kumabe, Yuichi Yoshida</p><p>It has been widely observed in the machine learning community that a small
perturbation to the input can cause a large change in the prediction of a
trained model, and such phenomena have been intensively studied in the machine
learning community under the name of adversarial attacks. Because graph
algorithms also are widely used for decision making and knowledge discovery, it
is important to design graph algorithms that are robust against adversarial
attacks. In this study, we consider the Lipschitz continuity of algorithms as a
robustness measure and initiate a systematic study of the Lipschitz continuity
of algorithms for (weighted) graph problems.
</p>
<p>Depending on how we embed the output solution to a metric space, we can think
of several Lipschitzness notions. We mainly consider the one that is invariant
under scaling of weights, and we provide Lipschitz continuous algorithms and
lower bounds for the minimum spanning tree problem, the shortest path problem,
and the maximum weight matching problem. In particular, our shortest path
algorithm is obtained by first designing an algorithm for unweighted graphs
that are robust against edge contractions and then applying it to the
unweighted graph constructed from the original weighted graph.
</p>
<p>Then, we consider another Lipschitzness notion induced by a natural mapping
that maps the output solution to its characteristic vector. It turns out that
no Lipschitz continuous algorithm exists for this Lipschitz notion, and we
instead design algorithms with bounded pointwise Lipschitz constants for the
minimum spanning tree problem and the maximum weight bipartite matching
problem. Our algorithm for the latter problem is based on an LP relaxation with
entropy regularization.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kumabe_S/0/1/0/all/0/1">Soh Kumabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshida_Y/0/1/0/all/0/1">Yuichi Yoshida</a></p><p>It has been widely observed in the machine learning community that a small
perturbation to the input can cause a large change in the prediction of a
trained model, and such phenomena have been intensively studied in the machine
learning community under the name of adversarial attacks. Because graph
algorithms also are widely used for decision making and knowledge discovery, it
is important to design graph algorithms that are robust against adversarial
attacks. In this study, we consider the Lipschitz continuity of algorithms as a
robustness measure and initiate a systematic study of the Lipschitz continuity
of algorithms for (weighted) graph problems.
</p>
<p>Depending on how we embed the output solution to a metric space, we can think
of several Lipschitzness notions. We mainly consider the one that is invariant
under scaling of weights, and we provide Lipschitz continuous algorithms and
lower bounds for the minimum spanning tree problem, the shortest path problem,
and the maximum weight matching problem. In particular, our shortest path
algorithm is obtained by first designing an algorithm for unweighted graphs
that are robust against edge contractions and then applying it to the
unweighted graph constructed from the original weighted graph.
</p>
<p>Then, we consider another Lipschitzness notion induced by a natural mapping
that maps the output solution to its characteristic vector. It turns out that
no Lipschitz continuous algorithm exists for this Lipschitz notion, and we
instead design algorithms with bounded pointwise Lipschitz constants for the
minimum spanning tree problem and the maximum weight bipartite matching
problem. Our algorithm for the latter problem is based on an LP relaxation with
entropy regularization.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04685'>Tight Bounds for Vertex Connectivity in Dynamic Streams</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sepehr Assadi, Vihan Shah</p><p>We present a streaming algorithm for the vertex connectivity problem in
dynamic streams with a (nearly) optimal space bound: for any $n$-vertex graph
$G$ and any integer $k \geq 1$, our algorithm with high probability outputs
whether or not $G$ is $k$-vertex-connected in a single pass using
$\widetilde{O}(k n)$ space.
</p>
<p>Our upper bound matches the known $\Omega(k n)$ lower bound for this problem
even in insertion-only streams -- which we extend to multi-pass algorithms in
this paper -- and closes one of the last remaining gaps in our understanding of
dynamic versus insertion-only streams. Our result is obtained via a novel
analysis of the previous best dynamic streaming algorithm of Guha, McGregor,
and Tench [PODS 2015] who obtained an $\widetilde{O}(k^2 n)$ space algorithm
for this problem. This also gives a model-independent algorithm for computing a
"certificate" of $k$-vertex-connectivity as a union of $O(k^2\log{n})$ spanning
forests, each on a random subset of $O(n/k)$ vertices, which may be of
independent interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Assadi_S/0/1/0/all/0/1">Sepehr Assadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_V/0/1/0/all/0/1">Vihan Shah</a></p><p>We present a streaming algorithm for the vertex connectivity problem in
dynamic streams with a (nearly) optimal space bound: for any $n$-vertex graph
$G$ and any integer $k \geq 1$, our algorithm with high probability outputs
whether or not $G$ is $k$-vertex-connected in a single pass using
$\widetilde{O}(k n)$ space.
</p>
<p>Our upper bound matches the known $\Omega(k n)$ lower bound for this problem
even in insertion-only streams -- which we extend to multi-pass algorithms in
this paper -- and closes one of the last remaining gaps in our understanding of
dynamic versus insertion-only streams. Our result is obtained via a novel
analysis of the previous best dynamic streaming algorithm of Guha, McGregor,
and Tench [PODS 2015] who obtained an $\widetilde{O}(k^2 n)$ space algorithm
for this problem. This also gives a model-independent algorithm for computing a
"certificate" of $k$-vertex-connectivity as a union of $O(k^2\log{n})$ spanning
forests, each on a random subset of $O(n/k)$ vertices, which may be of
independent interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04920'>On the distance-edge-monitoring numbers of graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chengxu Yang, Ralf Klasing, Yaping Mao, Xingchao Deng</p><p>Foucaud et al. [Discrete Appl. Math. 319 (2022), 424-438] recently introduced
and initiated the study of a new graph-theoretic concept in the area of network
monitoring. For a set $M$ of vertices and an edge $e$ of a graph $G$, let $P(M,
e)$ be the set of pairs $(x, y)$ with a vertex $x$ of $M$ and a vertex $y$ of
$V(G)$ such that $d_G(x, y)\neq d_{G-e}(x, y)$. For a vertex $x$, let $EM(x)$
be the set of edges $e$ such that there exists a vertex $v$ in $G$ with $(x, v)
\in P(\{x\}, e)$. A set $M$ of vertices of a graph $G$ is
distance-edge-monitoring set if every edge $e$ of $G$ is monitored by some
vertex of $M$, that is, the set $P(M, e)$ is nonempty. The
distance-edge-monitoring number of a graph $G$, denoted by $dem(G)$, is defined
as the smallest size of distance-edge-monitoring sets of $G$. The vertices of
$M$ represent distance probes in a network modeled by $G$; when the edge $e$
fails, the distance from $x$ to $y$ increases, and thus we are able to detect
the failure. It turns out that not only we can detect it, but we can even
correctly locate the failing edge. In this paper, we continue the study of
\emph{distance-edge-monitoring sets}. In particular, we give upper and lower
bounds of $P(M,e)$, $EM(x)$, $dem(G)$, respectively, and extremal graphs
attaining the bounds are characterized. We also characterize the graphs with
$dem(G)=3$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Yang_C/0/1/0/all/0/1">Chengxu Yang</a>, <a href="http://arxiv.org/find/math/1/au:+Klasing_R/0/1/0/all/0/1">Ralf Klasing</a>, <a href="http://arxiv.org/find/math/1/au:+Mao_Y/0/1/0/all/0/1">Yaping Mao</a>, <a href="http://arxiv.org/find/math/1/au:+Deng_X/0/1/0/all/0/1">Xingchao Deng</a></p><p>Foucaud et al. [Discrete Appl. Math. 319 (2022), 424-438] recently introduced
and initiated the study of a new graph-theoretic concept in the area of network
monitoring. For a set $M$ of vertices and an edge $e$ of a graph $G$, let $P(M,
e)$ be the set of pairs $(x, y)$ with a vertex $x$ of $M$ and a vertex $y$ of
$V(G)$ such that $d_G(x, y)\neq d_{G-e}(x, y)$. For a vertex $x$, let $EM(x)$
be the set of edges $e$ such that there exists a vertex $v$ in $G$ with $(x, v)
\in P(\{x\}, e)$. A set $M$ of vertices of a graph $G$ is
distance-edge-monitoring set if every edge $e$ of $G$ is monitored by some
vertex of $M$, that is, the set $P(M, e)$ is nonempty. The
distance-edge-monitoring number of a graph $G$, denoted by $dem(G)$, is defined
as the smallest size of distance-edge-monitoring sets of $G$. The vertices of
$M$ represent distance probes in a network modeled by $G$; when the edge $e$
fails, the distance from $x$ to $y$ increases, and thus we are able to detect
the failure. It turns out that not only we can detect it, but we can even
correctly locate the failing edge. In this paper, we continue the study of
\emph{distance-edge-monitoring sets}. In particular, we give upper and lower
bounds of $P(M,e)$, $EM(x)$, $dem(G)$, respectively, and extremal graphs
attaining the bounds are characterized. We also characterize the graphs with
$dem(G)=3$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04938'>Combinatorics of Reduced Ordered Binary Decision Diagrams: Application to uniform random sampling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julien Cl&#xe9;ment, Antoine Genitrini</p><p>Since three decades binary decision diagrams, representing efficiently
Boolean functions, are widely used, in many distinct contexts like model
verification, machine learning. The most famous variant, called reduced ordered
binary decision diagram (ROBDD for short), can be viewed as the result of a
compaction procedure on the full decision tree. In this paper we aim at
computing the exact distribution of the Boolean functions in $k$~variables
according to the ROBDD size, where the ROBDD size is equal to the size of the
underlying directed acyclic graph (DAG) structure. Recall the number of Boolean
functions is equal to $2^{2^k}$, which is of double exponential growth; hence a
combinatorial explosion is to be expected. The maximal size of a ROBDD with $k$
variables is $M_k \sim 2^k / k$ and thus, the support of the ROBDD size
distribution is also of length $M_k$, making $M_k$ a natural complexity unit
for our problem. In this paper, we develop the first polynomial algorithm to
derive the distribution of the Boolean functions with respect to their ROBDD
sizes. The algorithm is essentially quartic in $M_k$ for the time complexity
and quadratic for the space complexity. The main obstacle is to take into
account dependencies inside the DAG structure, and we propose a new
combinatorial counting procedure reminiscent of the inclusion-exclusion
principle. As a by-product, we present an efficient polynomial unranking
algorithm for ROBDDs, which in turn yields a uniform random sampler over the
set of ROBDDs of a given size or of a given profile. This is a great
improvement to the uniform sampler over the set of all Boolean functions in $k$
variables. Indeed, due to the Shannon effect, the uniform distribution over
Boolean functions is heavily biased to extremely complex functions, with near
maximal ROBDD size, thus preventing to sample small ROBDDs
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Clement_J/0/1/0/all/0/1">Julien Cl&#xe9;ment</a>, <a href="http://arxiv.org/find/cs/1/au:+Genitrini_A/0/1/0/all/0/1">Antoine Genitrini</a></p><p>Since three decades binary decision diagrams, representing efficiently
Boolean functions, are widely used, in many distinct contexts like model
verification, machine learning. The most famous variant, called reduced ordered
binary decision diagram (ROBDD for short), can be viewed as the result of a
compaction procedure on the full decision tree. In this paper we aim at
computing the exact distribution of the Boolean functions in $k$~variables
according to the ROBDD size, where the ROBDD size is equal to the size of the
underlying directed acyclic graph (DAG) structure. Recall the number of Boolean
functions is equal to $2^{2^k}$, which is of double exponential growth; hence a
combinatorial explosion is to be expected. The maximal size of a ROBDD with $k$
variables is $M_k \sim 2^k / k$ and thus, the support of the ROBDD size
distribution is also of length $M_k$, making $M_k$ a natural complexity unit
for our problem. In this paper, we develop the first polynomial algorithm to
derive the distribution of the Boolean functions with respect to their ROBDD
sizes. The algorithm is essentially quartic in $M_k$ for the time complexity
and quadratic for the space complexity. The main obstacle is to take into
account dependencies inside the DAG structure, and we propose a new
combinatorial counting procedure reminiscent of the inclusion-exclusion
principle. As a by-product, we present an efficient polynomial unranking
algorithm for ROBDDs, which in turn yields a uniform random sampler over the
set of ROBDDs of a given size or of a given profile. This is a great
improvement to the uniform sampler over the set of all Boolean functions in $k$
variables. Indeed, due to the Shannon effect, the uniform distribution over
Boolean functions is heavily biased to extremely complex functions, with near
maximal ROBDD size, thus preventing to sample small ROBDDs
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04981'>Sampling an Edge in $O(n/\sqrt{m} + \log \varepsilon^{-1})$ Time via Bernoulli Trial Simulation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Talya Eden, Shyam Narayanan, Jakub T&#x11b;tek</p><p>Sampling edges from a graph in sublinear time is a fundamental problem and a
powerful subroutine for designing sublinear-time algorithms. Suppose we have
access to the vertices of the graph and know a constant-factor approximation to
the number of edges. An algorithm for pointwise $\varepsilon$-approximate edge
sampling with complexity $O(n/\sqrt{\varepsilon m})$ has been given by Eden and
Rosenbaum [SOSA 2018]. This has been later improved by T\v{e}tek and Thorup
[STOC 2022] to $O(n \log(\varepsilon^{-1})/\sqrt{m})$. At the same time,
$\Omega(n/\sqrt{m})$ time is necessary. We close the problem, under the
assumption of knowing $m$ up to a constant factor, for all but very dense
graphs by giving an algorithm with complexity $O(n/\sqrt{m} + \log
\varepsilon^{-1})$.
</p>
<p>Our algorithm is based on a new technique that we call \emph{Bernoulli trial
simulation}. We believe this technique could also be useful for other problems.
</p>
<p>Given access to trials of the form $Bern(p)$, this technique allows us to
simulate a Bernoulli trial $Bern(f(p) \pm \varepsilon)$ (without knowing $p$),
in time complexity $O(\log \varepsilon^{-1})$ for some functions $f$. We
specifically use this for $f(p) = 1/(2p)$ for $p \geq 2/3$. Therefore, we can
perform rejection sampling, without the algorithm having to know the desired
rejection probability. We conjecture Bernoulli trial simulation for $f(p) =
1/(2p)$ can be done exactly in expected $O(1)$ samples. This would lead to an
exact algorithm for sampling an edge with complexity $O(n/\sqrt{m})$,
completely resolving the problem of sampling an edge, again assuming rough
knowledge of $m$. We consider the problem of removing this assumption to be an
interesting open problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Eden_T/0/1/0/all/0/1">Talya Eden</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1">Shyam Narayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tetek_J/0/1/0/all/0/1">Jakub T&#x11b;tek</a></p><p>Sampling edges from a graph in sublinear time is a fundamental problem and a
powerful subroutine for designing sublinear-time algorithms. Suppose we have
access to the vertices of the graph and know a constant-factor approximation to
the number of edges. An algorithm for pointwise $\varepsilon$-approximate edge
sampling with complexity $O(n/\sqrt{\varepsilon m})$ has been given by Eden and
Rosenbaum [SOSA 2018]. This has been later improved by T\v{e}tek and Thorup
[STOC 2022] to $O(n \log(\varepsilon^{-1})/\sqrt{m})$. At the same time,
$\Omega(n/\sqrt{m})$ time is necessary. We close the problem, under the
assumption of knowing $m$ up to a constant factor, for all but very dense
graphs by giving an algorithm with complexity $O(n/\sqrt{m} + \log
\varepsilon^{-1})$.
</p>
<p>Our algorithm is based on a new technique that we call \emph{Bernoulli trial
simulation}. We believe this technique could also be useful for other problems.
</p>
<p>Given access to trials of the form $Bern(p)$, this technique allows us to
simulate a Bernoulli trial $Bern(f(p) \pm \varepsilon)$ (without knowing $p$),
in time complexity $O(\log \varepsilon^{-1})$ for some functions $f$. We
specifically use this for $f(p) = 1/(2p)$ for $p \geq 2/3$. Therefore, we can
perform rejection sampling, without the algorithm having to know the desired
rejection probability. We conjecture Bernoulli trial simulation for $f(p) =
1/(2p)$ can be done exactly in expected $O(1)$ samples. This would lead to an
exact algorithm for sampling an edge with complexity $O(n/\sqrt{m})$,
completely resolving the problem of sampling an edge, again assuming rough
knowledge of $m$. We consider the problem of removing this assumption to be an
interesting open problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04986'>Fast and Scalable Channels in Kotlin Coroutines</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nikita Koval, Dan Alistarh, Roman Elizarov</p><p>Asynchronous programming has gained significant popularity over the last
decade: support for this programming pattern is available in many popular
languages via libraries and native language implementations, typically in the
form of coroutines or the async/await construct. Instead of programming via
shared memory, this concept assumes implicit synchronization through message
passing. The key data structure enabling such communication is the rendezvous
channel. Roughly, a rendezvous channel is a blocking queue of size zero, so
both send(e) and receive() operations wait for each other, performing a
rendezvous when they meet. To optimize the message passing pattern, channels
are usually equipped with a fixed-size buffer, so send(e)-s do not suspend and
put elements into the buffer until its capacity is exceeded. This primitive is
known as a buffered channel.
</p>
<p>This paper presents a fast and scalable algorithm for both rendezvous and
buffered channels. Similarly to modern queues, our solution is based on an
infinite array with two positional counters for send(e) and receive()
operations, leveraging the unconditional Fetch-And-Add instruction to update
them. Yet, the algorithm requires non-trivial modifications of this classic
pattern, in order to support the full channel semantics, such as buffering and
cancellation of waiting requests. We compare the performance of our solution to
that of the Kotlin implementation, as well as against other academic proposals,
showing up to 9.8x speedup. To showcase its expressiveness and performance, we
also integrated the proposed algorithm into the standard Kotlin Coroutines
library, replacing the previous channel implementations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Koval_N/0/1/0/all/0/1">Nikita Koval</a>, <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a>, <a href="http://arxiv.org/find/cs/1/au:+Elizarov_R/0/1/0/all/0/1">Roman Elizarov</a></p><p>Asynchronous programming has gained significant popularity over the last
decade: support for this programming pattern is available in many popular
languages via libraries and native language implementations, typically in the
form of coroutines or the async/await construct. Instead of programming via
shared memory, this concept assumes implicit synchronization through message
passing. The key data structure enabling such communication is the rendezvous
channel. Roughly, a rendezvous channel is a blocking queue of size zero, so
both send(e) and receive() operations wait for each other, performing a
rendezvous when they meet. To optimize the message passing pattern, channels
are usually equipped with a fixed-size buffer, so send(e)-s do not suspend and
put elements into the buffer until its capacity is exceeded. This primitive is
known as a buffered channel.
</p>
<p>This paper presents a fast and scalable algorithm for both rendezvous and
buffered channels. Similarly to modern queues, our solution is based on an
infinite array with two positional counters for send(e) and receive()
operations, leveraging the unconditional Fetch-And-Add instruction to update
them. Yet, the algorithm requires non-trivial modifications of this classic
pattern, in order to support the full channel semantics, such as buffering and
cancellation of waiting requests. We compare the performance of our solution to
that of the Kotlin implementation, as well as against other academic proposals,
showing up to 9.8x speedup. To showcase its expressiveness and performance, we
also integrated the proposed algorithm into the standard Kotlin Coroutines
library, replacing the previous channel implementations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04994'>A Nearly Time-Optimal Distributed Approximation of Minimum Cost $k$-Edge-Connected Spanning Subgraph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michal Dory, Mohsen Ghaffari</p><p>The minimum-cost $k$-edge-connected spanning subgraph ($k$-ECSS) problem is a
generalization and strengthening of the well-studied minimum-cost spanning tree
(MST) problem. While the round complexity of distributedly computing the latter
has been well-understood, the former remains mostly open, especially as soon as
$k\geq 3$.
</p>
<p>In this paper, we present the first distributed algorithm that computes an
approximation of $k$-ECSS in sublinear time for general $k$. Concretely, we
describe a randomized distributed algorithm that, in
$\tilde{O}(k(D+k\sqrt{n}))$ rounds, computes a $k$-edge-connected spanning
subgraph whose cost is within an $O(\log n\log k)$ factor of optimal. Here, $n$
and $D$ denote the number of vertices and diameter of the graph, respectively.
This time complexity is nearly optimal for any $k=poly(\log n)$, almost
matching an $\tilde{\Omega}(D+\sqrt{n/k})$ lower bound. Our algorithm is the
first to achieve a sublinear round complexity for $k\geq 3$. We note that this
case is considerably more challenging than the well-studied and well-understood
$k=1$ case -- better known as MST -- and the closely related $k=2$ case.
</p>
<p>Our algorithm is based on reducing the $k$-ECSS problem to $k$ set cover
instances, in which we gradually augment the connectivity of the spanning
subgraph. To solve each set cover instance, we combine new structural
observations on minimum cuts with graph sketching ideas. One key ingredient in
our algorithm is a novel structural lemma that allows us to compress the
information about all minimum cuts in a graph into a succinct representation,
which is computed in a decentralized fashion. We hope that this succinct
representation may find applications in other computational settings or for
other problems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dory_M/0/1/0/all/0/1">Michal Dory</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a></p><p>The minimum-cost $k$-edge-connected spanning subgraph ($k$-ECSS) problem is a
generalization and strengthening of the well-studied minimum-cost spanning tree
(MST) problem. While the round complexity of distributedly computing the latter
has been well-understood, the former remains mostly open, especially as soon as
$k\geq 3$.
</p>
<p>In this paper, we present the first distributed algorithm that computes an
approximation of $k$-ECSS in sublinear time for general $k$. Concretely, we
describe a randomized distributed algorithm that, in
$\tilde{O}(k(D+k\sqrt{n}))$ rounds, computes a $k$-edge-connected spanning
subgraph whose cost is within an $O(\log n\log k)$ factor of optimal. Here, $n$
and $D$ denote the number of vertices and diameter of the graph, respectively.
This time complexity is nearly optimal for any $k=poly(\log n)$, almost
matching an $\tilde{\Omega}(D+\sqrt{n/k})$ lower bound. Our algorithm is the
first to achieve a sublinear round complexity for $k\geq 3$. We note that this
case is considerably more challenging than the well-studied and well-understood
$k=1$ case -- better known as MST -- and the closely related $k=2$ case.
</p>
<p>Our algorithm is based on reducing the $k$-ECSS problem to $k$ set cover
instances, in which we gradually augment the connectivity of the spanning
subgraph. To solve each set cover instance, we combine new structural
observations on minimum cuts with graph sketching ideas. One key ingredient in
our algorithm is a novel structural lemma that allows us to compress the
information about all minimum cuts in a graph into a succinct representation,
which is computed in a decentralized fashion. We hope that this succinct
representation may find applications in other computational settings or for
other problems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.05006'>Almost Tight Error Bounds on Differentially Private Continual Counting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Monika Henzinger, Jalaj Upadhyay, Sarvagya Upadhyay</p><p>The first large-scale deployment of private federated learning uses
differentially private counting in the continual release model as a subroutine
(Google AI blog titled "Federated Learning with Formal Differential Privacy
Guarantees"). In this case, a concrete bound on the error is very relevant to
reduce the privacy parameter. The standard mechanism for continual counting is
the binary mechanism. We present a novel mechanism and show that its mean
squared error is both asymptotically optimal and a factor 10 smaller than the
error of the binary mechanism. We also show that the constants in our analysis
are almost tight by giving non-asymptotic lower and upper bounds that differ
only in the constants of lower-order terms. Our algorithm is a matrix mechanism
for the counting matrix and takes constant time per release. We also use our
explicit factorization of the counting matrix to give an upper bound on the
excess risk of the private learning algorithm of Denisov et al. (NeurIPS 2022).
Our lower bound for any continual counting mechanism is the first tight lower
bound on continual counting under approximate differential privacy. It is
achieved using a new lower bound on a certain factorization norm, denoted by
$\gamma_F(\cdot)$, in terms of the singular values of the matrix. In
particular, we show that for any complex matrix, $A \in \mathbb{C}^{m \times
n}$, \[ \gamma_F(A) \geq \frac{1}{\sqrt{m}}\|A\|_1, \] where $\|\cdot \|$
denotes the Schatten-1 norm.
</p>
<p>We believe this technique will be useful in proving lower bounds for a larger
class of linear queries. To illustrate the power of this technique, we show the
first lower bound on the mean squared error for answering parity queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Upadhyay_J/0/1/0/all/0/1">Jalaj Upadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1">Sarvagya Upadhyay</a></p><p>The first large-scale deployment of private federated learning uses
differentially private counting in the continual release model as a subroutine
(Google AI blog titled "Federated Learning with Formal Differential Privacy
Guarantees"). In this case, a concrete bound on the error is very relevant to
reduce the privacy parameter. The standard mechanism for continual counting is
the binary mechanism. We present a novel mechanism and show that its mean
squared error is both asymptotically optimal and a factor 10 smaller than the
error of the binary mechanism. We also show that the constants in our analysis
are almost tight by giving non-asymptotic lower and upper bounds that differ
only in the constants of lower-order terms. Our algorithm is a matrix mechanism
for the counting matrix and takes constant time per release. We also use our
explicit factorization of the counting matrix to give an upper bound on the
excess risk of the private learning algorithm of Denisov et al. (NeurIPS 2022).
Our lower bound for any continual counting mechanism is the first tight lower
bound on continual counting under approximate differential privacy. It is
achieved using a new lower bound on a certain factorization norm, denoted by
$\gamma_F(\cdot)$, in terms of the singular values of the matrix. In
particular, we show that for any complex matrix, $A \in \mathbb{C}^{m \times
n}$, \[ \gamma_F(A) \geq \frac{1}{\sqrt{m}}\|A\|_1, \] where $\|\cdot \|$
denotes the Schatten-1 norm.
</p>
<p>We believe this technique will be useful in proving lower bounds for a larger
class of linear queries. To illustrate the power of this technique, we show the
first lower bound on the mean squared error for answering parity queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.05053'>On Minimizing Tardy Processing Time, Max-Min Skewed Convolution, and Triangular Structured ILPs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kim-Manuel Klein, Adam Polak, Lars Rohwedder</p><p>The starting point of this paper is the problem of scheduling $n$ jobs with
processing times and due dates on a single machine so as to minimize the total
processing time of tardy jobs, i.e., $1||\sum p_j U_j$. This problem was
identified by Bringmann et al.~(Algorithmica 2022) as a natural
subquadratic-time special case of the classic $1||\sum w_j U_j$ problem, which
likely requires time quadratic in the total processing time $P$, because of a
fine-grained lower bound. Bringmann et al.~obtain their $\tilde{O}(P^{7/4})$
time scheduling algorithm through a new variant of convolution, dubbed Max-Min
Skewed Convolution, which they solve in $\tilde{O}(n^{7/4})$ time. Our main
technical contribution is a faster and simpler convolution algorithm running in
$\tilde{O}(n^{5/3})$ time. It implies an $\tilde{O}(P^{5/3})$ time algorithm
for \problem, but may also be of independent interest.
</p>
<p>Inspired by recent developments for the Subset Sum and Knapsack problems, we
study $1||\sum p_j U_j$ parameterized by the maximum job processing time
$p_{\max}$. With proximity techniques borrowed from integer linear programming
(ILP), we show structural properties of the problem that, coupled with a new
dynamic programming formulation, lead to an $\tilde{O}(n+p_{\max}^3)$ time
algorithm. Moreover, in the setting with multiple machines, we use similar
techniques to get an $n \cdot p_{\max}^{O(m)}$ time algorithm for $Pm||\sum p_j
U_j$.
</p>
<p>Finally, we point out that the considered problems exhibit a particular
triangular block structure in the constraint matrices of their ILP
formulations. In light of recent ILP research, a question that arises is
whether one can devise a generic algorithm for such a class of ILPs. We give a
negative answer to this question: we show that already a slight generalization
of the structure of the scheduling ILP leads to a strongly NP-hard problem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Klein_K/0/1/0/all/0/1">Kim-Manuel Klein</a>, <a href="http://arxiv.org/find/cs/1/au:+Polak_A/0/1/0/all/0/1">Adam Polak</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohwedder_L/0/1/0/all/0/1">Lars Rohwedder</a></p><p>The starting point of this paper is the problem of scheduling $n$ jobs with
processing times and due dates on a single machine so as to minimize the total
processing time of tardy jobs, i.e., $1||\sum p_j U_j$. This problem was
identified by Bringmann et al.~(Algorithmica 2022) as a natural
subquadratic-time special case of the classic $1||\sum w_j U_j$ problem, which
likely requires time quadratic in the total processing time $P$, because of a
fine-grained lower bound. Bringmann et al.~obtain their $\tilde{O}(P^{7/4})$
time scheduling algorithm through a new variant of convolution, dubbed Max-Min
Skewed Convolution, which they solve in $\tilde{O}(n^{7/4})$ time. Our main
technical contribution is a faster and simpler convolution algorithm running in
$\tilde{O}(n^{5/3})$ time. It implies an $\tilde{O}(P^{5/3})$ time algorithm
for \problem, but may also be of independent interest.
</p>
<p>Inspired by recent developments for the Subset Sum and Knapsack problems, we
study $1||\sum p_j U_j$ parameterized by the maximum job processing time
$p_{\max}$. With proximity techniques borrowed from integer linear programming
(ILP), we show structural properties of the problem that, coupled with a new
dynamic programming formulation, lead to an $\tilde{O}(n+p_{\max}^3)$ time
algorithm. Moreover, in the setting with multiple machines, we use similar
techniques to get an $n \cdot p_{\max}^{O(m)}$ time algorithm for $Pm||\sum p_j
U_j$.
</p>
<p>Finally, we point out that the considered problems exhibit a particular
triangular block structure in the constraint matrices of their ILP
formulations. In light of recent ILP research, a question that arises is
whether one can devise a generic algorithm for such a class of ILPs. We give a
negative answer to this question: we show that already a slight generalization
of the structure of the scheduling ILP leads to a strongly NP-hard problem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-10T01:30:00Z">Thursday, November 10 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, November 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/146'>TR22-146 |  Interactive Coding with Small Memory | 

	Raghuvansh Saxena, 

	Klim Efremenko, 

	Bernhard Haeupler, 

	Yael Tauman Kalai, 

	Gillat Kol, 

	Nicolas Resch</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this work, we design an interactive coding scheme that converts any two party interactive protocol $\Pi$ into another interactive protocol $\Pi&#39;$, such that even if errors are introduced during the execution of $\Pi&#39;$, the parties are able to determine what the outcome of running $\Pi$ would be in an error-free setting.  
		
Importantly, our scheme preserves the space complexity of the protocol, in addition to the communication and computational complexities. Specifically, if the protocol $\Pi$ has communication complexity $T$, computational complexity $t$, and space complexity $s$, the resulting protocol $\Pi&#39;$ is resilient to a constant $\epsilon &gt; 0$ fraction of adversarial errors, and has communication complexity approaching $T$ as $\epsilon$ approaches $0$, $\mathrm{poly}(t)$, and space complexity $\mathcal{O}(s \log T)$.
		
Prior to this work, all known interactive coding schemes required the parties to use at least $\Omega(T)$ space, as the parties were required to remember the transcript of the conversation thus far, or considered weaker error models.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In this work, we design an interactive coding scheme that converts any two party interactive protocol $\Pi$ into another interactive protocol $\Pi&#39;$, such that even if errors are introduced during the execution of $\Pi&#39;$, the parties are able to determine what the outcome of running $\Pi$ would be in an error-free setting.  
		
Importantly, our scheme preserves the space complexity of the protocol, in addition to the communication and computational complexities. Specifically, if the protocol $\Pi$ has communication complexity $T$, computational complexity $t$, and space complexity $s$, the resulting protocol $\Pi&#39;$ is resilient to a constant $\epsilon &gt; 0$ fraction of adversarial errors, and has communication complexity approaching $T$ as $\epsilon$ approaches $0$, $\mathrm{poly}(t)$, and space complexity $\mathcal{O}(s \log T)$.
		
Prior to this work, all known interactive coding schemes required the parties to use at least $\Omega(T)$ space, as the parties were required to remember the transcript of the conversation thus far, or considered weaker error models.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T23:07:33Z">Wednesday, November 09 2022, 23:07</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/09/postdoc-at-foundations-of-data-science-institute-fodsi-apply-by-december-15-2022/'>POSTDOC at FOUNDATIONS OF DATA SCIENCE INSTITUTE (FODSI) (apply by December 15, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Foundations of Data Science Institute (FODSI), funded by the National Science Foundation TRIPODS program, is announcing a competitive postdoctoral fellowship. Multiple positions are available. FODSI is a collaboration between UC Berkeley and MIT, partnering with Boston University, Northeastern University, Harvard University, Howard University and Bryn Mawr College. Website: academicjobsonline.org/ajo/jobs/23541 Email: indyk@mit.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Foundations of Data Science Institute (FODSI), funded by the National Science Foundation TRIPODS program, is announcing a competitive postdoctoral fellowship. Multiple positions are available. FODSI is a collaboration between UC Berkeley and MIT, partnering with Boston University, Northeastern University, Harvard University, Howard University and Bryn Mawr College.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/23541">https://academicjobsonline.org/ajo/jobs/23541</a><br />
Email: indyk@mit.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T20:30:55Z">Wednesday, November 09 2022, 20:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/09/postdoc-at-university-of-waterloo-apply-by-december-10-2022/'>Postdoc at University of Waterloo (apply by December 10, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Algorithms &#38; Complexity group at the University of Waterloo is offering postdoctoral positions starting in the Fall of 2023. We seek candidates from all areas of theoretical computer science. Interested applicants should have their CV, research statement, and three recommendation letters emailed to theory.waterloo@gmail.com. Applications are due December 10th. Website: algcomp.uwaterloo.ca/positions/ Email: theory.waterloo@gmail.com
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Algorithms &amp; Complexity group at the University of Waterloo is offering postdoctoral positions starting in the Fall of 2023. We seek candidates from all areas of theoretical computer science.</p>
<p>Interested applicants should have their CV, research statement, and three recommendation letters emailed to theory.waterloo@gmail.com. Applications are due December 10th.</p>
<p>Website: <a href="https://algcomp.uwaterloo.ca/positions/">https://algcomp.uwaterloo.ca/positions/</a><br />
Email: theory.waterloo@gmail.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T19:56:36Z">Wednesday, November 09 2022, 19:56</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2022/145'>TR22-145 |  Revisiting Time-Space Tradeoffs for Function Inversion | 

	Alexander Golovnev, 

	Siyao Guo, 

	Spencer Peters, 

	Noah Stephens-Davidowitz</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study the black-box function inversion problem, which is the problem of finding $x \in [N]$ such that $f(x) = y$, given as input some challenge point $y$ in the image of a function $f : [N] \to [N]$, using $T$ oracle queries to $f$ and preprocessed advice $\sigma \in \{0,1\}^S$ depending on $f$. We prove a number of new results about this problem, as follows.

1. We show an algorithm that works for any $T$ and $S$ satisfying $T S^2 \cdot \max\{S,T\} = \widetilde{\Theta}(N^3)$. In the important setting when $S &lt; T$, this improves on the celebrated algorithm of Fiat and Naor [STOC, 1991], which requires $T S^3 \geq N^3$. E.g., Fiat and Naor&#39;s algorithm is only non-trivial for $S \gg N^{2/3}$, while our algorithm gives a non-trivial tradeoff for any $S \gg N^{1/2}$. (Our algorithm and analysis are quite simple. As a consequence of this, we also give a self-contained and simple proof of Fiat and Naor&#39;s original result, with certain optimizations left out for simplicity.)

2. We show a non-adaptive algorithm (i.e., an algorithm whose $i$th query $x_i$ is chosen based entirely on $\sigma$ and $y$, and not on the $f(x_1),\ldots, f(x_{i-1})$) that works for any $T$ and $S$ satisfying $S = \Theta(N \log(N/T))$ giving the first non-trivial non-adaptive algorithm for this problem. E.g., setting $T = N/ \mathrm{poly\,log}(N)$ gives $S = \Theta(N \log \log N)$. This answers a question due to Corrigan-Gibbs and Kogan [TCC, 2019], who asked whether it was possible for a non-adaptive algorithm to work with parameters $T$ and $S$ satisfying $T + S/\log N &lt; o(N)$. We also observe that our non-adaptive algorithm is what we call a guess-and-check algorithm, that is, it is non-adaptive and its final output is always one of the oracle queries $x_1,\ldots, x_T$. For guess-and-check algorithms, we prove a matching lower bound, therefore completely characterizing the achievable parameters $(S,T)$ for this natural class of algorithms. (Corrigan-Gibbs and Kogan showed that any such lower bound for arbitrary non-adaptive algorithms would imply new circuit lower bounds.) 

3. We show equivalence between function inversion and a natural decision version of the problem in both the worst case and the average case, and similarly for functions $f : [N] \to [M]$ with different ranges.


All of the above results are most naturally described in a model with shared randomness (i.e., random coins shared between the preprocessing algorithm and the online algorithm). However, as an additional contribution, we show (using a technique from communication complexity due to Newman [IPL, 1991]) how to generically convert any algorithm that uses shared randomness into one that does not.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study the black-box function inversion problem, which is the problem of finding $x \in [N]$ such that $f(x) = y$, given as input some challenge point $y$ in the image of a function $f : [N] \to [N]$, using $T$ oracle queries to $f$ and preprocessed advice $\sigma \in \{0,1\}^S$ depending on $f$. We prove a number of new results about this problem, as follows.

1. We show an algorithm that works for any $T$ and $S$ satisfying $T S^2 \cdot \max\{S,T\} = \widetilde{\Theta}(N^3)$. In the important setting when $S &lt; T$, this improves on the celebrated algorithm of Fiat and Naor [STOC, 1991], which requires $T S^3 \geq N^3$. E.g., Fiat and Naor&#39;s algorithm is only non-trivial for $S \gg N^{2/3}$, while our algorithm gives a non-trivial tradeoff for any $S \gg N^{1/2}$. (Our algorithm and analysis are quite simple. As a consequence of this, we also give a self-contained and simple proof of Fiat and Naor&#39;s original result, with certain optimizations left out for simplicity.)

2. We show a non-adaptive algorithm (i.e., an algorithm whose $i$th query $x_i$ is chosen based entirely on $\sigma$ and $y$, and not on the $f(x_1),\ldots, f(x_{i-1})$) that works for any $T$ and $S$ satisfying $S = \Theta(N \log(N/T))$ giving the first non-trivial non-adaptive algorithm for this problem. E.g., setting $T = N/ \mathrm{poly\,log}(N)$ gives $S = \Theta(N \log \log N)$. This answers a question due to Corrigan-Gibbs and Kogan [TCC, 2019], who asked whether it was possible for a non-adaptive algorithm to work with parameters $T$ and $S$ satisfying $T + S/\log N &lt; o(N)$. We also observe that our non-adaptive algorithm is what we call a guess-and-check algorithm, that is, it is non-adaptive and its final output is always one of the oracle queries $x_1,\ldots, x_T$. For guess-and-check algorithms, we prove a matching lower bound, therefore completely characterizing the achievable parameters $(S,T)$ for this natural class of algorithms. (Corrigan-Gibbs and Kogan showed that any such lower bound for arbitrary non-adaptive algorithms would imply new circuit lower bounds.) 

3. We show equivalence between function inversion and a natural decision version of the problem in both the worst case and the average case, and similarly for functions $f : [N] \to [M]$ with different ranges.


All of the above results are most naturally described in a model with shared randomness (i.e., random coins shared between the preprocessing algorithm and the online algorithm). However, as an additional contribution, we show (using a technique from communication complexity due to Newman [IPL, 1991]) how to generically convert any algorithm that uses shared randomness into one that does not.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T17:55:48Z">Wednesday, November 09 2022, 17:55</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04025'>Complexity of directed Steiner path packing problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuefang Sun</p><p>For a digraph $D=(V(D), A(D))$, and a set $S\subseteq V(D)$ with $r\in S$ and
$|S|\geq 2$, a directed $(S, r)$-Steiner path or, simply, an $(S, r)$-path is a
directed path $P$ started at $r$ with $S\subseteq V(P)$. Two $(S, r)$-paths are
said to be arc-disjoint if they have no common arc. Two arc-disjoint $(S,
r)$-paths are said to be internally disjoint if the set of common vertices of
them is exactly $S$. Let $\kappa^p_{S,r}(D)$ (resp. $\lambda^p_{S,r}(D)$) be
the maximum number of internally disjoint (resp. arc-disjoint) $(S, r)$-paths
in $D$.
</p>
<p>In this paper, we study the complexity for $\kappa^p_{S,r}(D)$ and
$\lambda^p_{S,r}(D)$. When both $k\geq 2, \ell\geq 1$ are fixed integers, we
show that the problem of deciding whether $\kappa^p_{S,r}(D) \geq \ell$ for an
Eulerian digraph $D$ is NP-complete, where $r\in S\subseteq V(D)$ and $|S|=k$.
However, when we consider the class of symmetric digraphs, the problem becomes
polynomial-time solvable. We also show that the problem of deciding whether
$\lambda^p_{S,r}(D) \geq \ell$ for a given digraph $D$ is NP-complete, where
$r\in S\subseteq V(D)$ and $|S|=k$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1">Yuefang Sun</a></p><p>For a digraph $D=(V(D), A(D))$, and a set $S\subseteq V(D)$ with $r\in S$ and
$|S|\geq 2$, a directed $(S, r)$-Steiner path or, simply, an $(S, r)$-path is a
directed path $P$ started at $r$ with $S\subseteq V(P)$. Two $(S, r)$-paths are
said to be arc-disjoint if they have no common arc. Two arc-disjoint $(S,
r)$-paths are said to be internally disjoint if the set of common vertices of
them is exactly $S$. Let $\kappa^p_{S,r}(D)$ (resp. $\lambda^p_{S,r}(D)$) be
the maximum number of internally disjoint (resp. arc-disjoint) $(S, r)$-paths
in $D$.
</p>
<p>In this paper, we study the complexity for $\kappa^p_{S,r}(D)$ and
$\lambda^p_{S,r}(D)$. When both $k\geq 2, \ell\geq 1$ are fixed integers, we
show that the problem of deciding whether $\kappa^p_{S,r}(D) \geq \ell$ for an
Eulerian digraph $D$ is NP-complete, where $r\in S\subseteq V(D)$ and $|S|=k$.
However, when we consider the class of symmetric digraphs, the problem becomes
polynomial-time solvable. We also show that the problem of deciding whether
$\lambda^p_{S,r}(D) \geq \ell$ for a given digraph $D$ is NP-complete, where
$r\in S\subseteq V(D)$ and $|S|=k$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04032'>Non-existence of a short algorithm for multiplication of $3\times3$ matrices with group $S_4\times S_3$, II</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vladimir P. Burichenko</p><p>It is proved that there is no an algorithm for multiplication of $3\times3$
matrices of multiplicative length $\leq23$ that is invariant under a certain
group isomorphic to $S_4\times S_3$. The proof makes use of description of the
orbits of this group on decomposable tensors in the tensor cube $(M_3({\mathbb
C}))^{\otimes3}$ which was obtained earlier.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Burichenko_V/0/1/0/all/0/1">Vladimir P. Burichenko</a></p><p>It is proved that there is no an algorithm for multiplication of $3\times3$
matrices of multiplicative length $\leq23$ that is invariant under a certain
group isomorphic to $S_4\times S_3$. The proof makes use of description of the
orbits of this group on decomposable tensors in the tensor cube $(M_3({\mathbb
C}))^{\otimes3}$ which was obtained earlier.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04420'>Computational indistinguishability and boson sampling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Georgios M. Nikolopoulos</p><p>We introduce a computational problem of distinguishing between the output of
an ideal coarse-grained boson sampler and the output of a true random number
generator, as a resource for cryptographic schemes, which are secure against
computationally unbounded adversaries. Moreover, we define a cryptographic
setting for the implementation of such schemes, including message encryption
and authentication, as well as entity authentication.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Nikolopoulos_G/0/1/0/all/0/1">Georgios M. Nikolopoulos</a></p><p>We introduce a computational problem of distinguishing between the output of
an ideal coarse-grained boson sampler and the output of a true random number
generator, as a resource for cryptographic schemes, which are secure against
computationally unbounded adversaries. Moreover, we define a cryptographic
setting for the implementation of such schemes, including message encryption
and authentication, as well as entity authentication.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03877'>The Need for Seed (in the abstract Tile Assembly Model)</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Andrew Alseth, Matthew J. Patitz</p><p>In the abstract Tile Assembly Model (aTAM) square tiles self-assemble,
autonomously binding via glues on their edges, to form structures. Algorithmic
aTAM systems can be designed in which the patterns of tile attachments are
forced to follow the execution of targeted algorithms. Such systems have been
proven to be computationally universal as well as intrinsically universal (IU),
a notion borrowed and adapted from cellular automata showing that a single tile
set exists which is capable of simulating all aTAM systems (FOCS 2012). The
input to an algorithmic aTAM system can be provided in a variety of ways, with
a common method being via the ``seed'' assembly, which is a pre-formed assembly
from which all growth propagates. In this paper we present a series of results
which investigate the the trade-offs of using seeds consisting of a single
tile, versus those containing multiple tiles. We show that arbitrary systems
with multi-tile seeds cannot be converted to functionally equivalent systems
with single-tile seeds without using a scale factor &gt; 1. We prove tight bounds
on the scale factor required, and also present a construction which uses a
large scale factor but an optimal number of unique tile types. That
construction is then used to develop a construction that performs simultaneous
simulation of all aTAM systems in parallel, as well as to display a connection
to other tile-based self-assembly models via the notion of intrinsic
universality.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alseth_A/0/1/0/all/0/1">Andrew Alseth</a>, <a href="http://arxiv.org/find/cs/1/au:+Patitz_M/0/1/0/all/0/1">Matthew J. Patitz</a></p><p>In the abstract Tile Assembly Model (aTAM) square tiles self-assemble,
autonomously binding via glues on their edges, to form structures. Algorithmic
aTAM systems can be designed in which the patterns of tile attachments are
forced to follow the execution of targeted algorithms. Such systems have been
proven to be computationally universal as well as intrinsically universal (IU),
a notion borrowed and adapted from cellular automata showing that a single tile
set exists which is capable of simulating all aTAM systems (FOCS 2012). The
input to an algorithmic aTAM system can be provided in a variety of ways, with
a common method being via the ``seed'' assembly, which is a pre-formed assembly
from which all growth propagates. In this paper we present a series of results
which investigate the the trade-offs of using seeds consisting of a single
tile, versus those containing multiple tiles. We show that arbitrary systems
with multi-tile seeds cannot be converted to functionally equivalent systems
with single-tile seeds without using a scale factor &gt; 1. We prove tight bounds
on the scale factor required, and also present a construction which uses a
large scale factor but an optimal number of unique tile types. That
construction is then used to develop a construction that performs simultaneous
simulation of all aTAM systems in parallel, as well as to display a connection
to other tile-based self-assembly models via the notion of intrinsic
universality.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03891'>A deterministic near-linear time approximation scheme for geometric transportation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kyle Fox (1), Jiashuai Lu (1) ((1) The University of Texas at Dallas)</p><p>Given a set of points $P = (P^+ \sqcup P^-) \subset \mathbb{R}^d$ for some
constant $d$ and a supply function $\mu:P\to \mathbb{R}$ such that $\mu(p) &gt;
0~\forall p \in P^+$, $\mu(p) &lt; 0~\forall p \in P^-$, and $\sum_{p\in
P}{\mu(p)} = 0$, the geometric transportation problem asks one to find a
transportation map $\tau: P^+\times P^-\to \mathbb{R}_{\ge 0}$ such that
$\sum_{q\in P^-}{\tau(p, q)} = \mu(p)~\forall p \in P^+$, $\sum_{p\in
P^+}{\tau(p, q)} = -\mu(q)~ \forall q \in P^-$, and the weighted sum of
Euclidean distances for the pairs $\sum_{(p,q)\in P^+\times P^-}\tau(p, q)\cdot
||q-p||_2$ is minimized. We present the first deterministic algorithm that
computes, in near-linear time, a transportation map whose cost is within a $(1
+ \varepsilon)$ factor of optimal. More precisely, our algorithm runs in
$O(n\varepsilon^{-(d+2)}\log^5{n}\log{\log{n}})$ time for any constant
$\varepsilon &gt; 0$. While a randomized $n\varepsilon^{-O(d)}\log^{O(d)}{n}$ time
algorithm was discovered in the last few years, all previously known
deterministic $(1 + \varepsilon)$-approximation algorithms run in
$\Omega(n^{3/2})$ time. A similar situation existed for geometric bipartite
matching, the special case of geometric transportation where all supplies are
unit, until a deterministic $n\varepsilon^{-O(d)}\log^{O(d)}{n}$ time $(1 +
\varepsilon)$-approximation algorithm was presented at STOC 2022. Surprisingly,
our result is not only a generalization of the bipartite matching one to
arbitrary instances of geometric transportation, but it also reduces the
running time for all previously known $(1 + \varepsilon)$-approximation
algorithms, randomized or deterministic, even for geometric bipartite matching,
by removing the dependence on the dimension $d$ from the exponent in the
running time's polylog.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fox_K/0/1/0/all/0/1">Kyle Fox</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiashuai Lu</a> (1) ((1) The University of Texas at Dallas)</p><p>Given a set of points $P = (P^+ \sqcup P^-) \subset \mathbb{R}^d$ for some
constant $d$ and a supply function $\mu:P\to \mathbb{R}$ such that $\mu(p) &gt;
0~\forall p \in P^+$, $\mu(p) &lt; 0~\forall p \in P^-$, and $\sum_{p\in
P}{\mu(p)} = 0$, the geometric transportation problem asks one to find a
transportation map $\tau: P^+\times P^-\to \mathbb{R}_{\ge 0}$ such that
$\sum_{q\in P^-}{\tau(p, q)} = \mu(p)~\forall p \in P^+$, $\sum_{p\in
P^+}{\tau(p, q)} = -\mu(q)~ \forall q \in P^-$, and the weighted sum of
Euclidean distances for the pairs $\sum_{(p,q)\in P^+\times P^-}\tau(p, q)\cdot
||q-p||_2$ is minimized. We present the first deterministic algorithm that
computes, in near-linear time, a transportation map whose cost is within a $(1
+ \varepsilon)$ factor of optimal. More precisely, our algorithm runs in
$O(n\varepsilon^{-(d+2)}\log^5{n}\log{\log{n}})$ time for any constant
$\varepsilon &gt; 0$. While a randomized $n\varepsilon^{-O(d)}\log^{O(d)}{n}$ time
algorithm was discovered in the last few years, all previously known
deterministic $(1 + \varepsilon)$-approximation algorithms run in
$\Omega(n^{3/2})$ time. A similar situation existed for geometric bipartite
matching, the special case of geometric transportation where all supplies are
unit, until a deterministic $n\varepsilon^{-O(d)}\log^{O(d)}{n}$ time $(1 +
\varepsilon)$-approximation algorithm was presented at STOC 2022. Surprisingly,
our result is not only a generalization of the bipartite matching one to
arbitrary instances of geometric transportation, but it also reduces the
running time for all previously known $(1 + \varepsilon)$-approximation
algorithms, randomized or deterministic, even for geometric bipartite matching,
by removing the dependence on the dimension $d$ from the exponent in the
running time's polylog.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03859'>From approximate to exact integer programming</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Dadush, Friedrich Eisenbrand, Thomas Rothvoss</p><p>Approximate integer programming is the following: For a convex body $K
\subseteq \mathbb{R}^n$, either determine whether $K \cap \mathbb{Z}^n$ is
empty, or find an integer point in the convex body scaled by $2$ from its
center of gravity $c$. Approximate integer programming can be solved in time
$2^{O(n)}$ while the fastest known methods for exact integer programming run in
time $2^{O(n)} \cdot n^n$. So far, there are no efficient methods for integer
programming known that are based on approximate integer programming. Our main
contribution are two such methods, each yielding novel complexity results.
</p>
<p>First, we show that an integer point $x^* \in (K \cap \mathbb{Z}^n)$ can be
found in time $2^{O(n)}$, provided that the remainders of each component $x_i^*
\mod{\ell}$ for some arbitrarily fixed $\ell \geq 5(n+1)$ of $x^*$ are given.
The algorithm is based on a cutting-plane technique, iteratively halving the
volume of the feasible set. The cutting planes are determined via approximate
integer programming. Enumeration of the possible remainders gives a
$2^{O(n)}n^n$ algorithm for general integer programming. This matches the
current best bound of an algorithm by Dadush (2012) that is considerably more
involved. Our algorithm also relies on a new asymmetric approximate
Carath\'eodory theorem that might be of interest on its own.
</p>
<p>Our second method concerns integer programming problems in equation-standard
form $Ax = b, 0 \leq x \leq u, \, x \in \mathbb{Z}^n$ . Such a problem can be
reduced to the solution of $\prod_i O(\log u_i +1)$ approximate integer
programming problems. This implies, for example that knapsack or subset-sum
problems with polynomial variable range $0 \leq x_i \leq p(n)$ can be solved in
time $(\log n)^{O(n)}$. For these problems, the best running time so far was
$n^n \cdot 2^{O(n)}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Dadush_D/0/1/0/all/0/1">Daniel Dadush</a>, <a href="http://arxiv.org/find/math/1/au:+Eisenbrand_F/0/1/0/all/0/1">Friedrich Eisenbrand</a>, <a href="http://arxiv.org/find/math/1/au:+Rothvoss_T/0/1/0/all/0/1">Thomas Rothvoss</a></p><p>Approximate integer programming is the following: For a convex body $K
\subseteq \mathbb{R}^n$, either determine whether $K \cap \mathbb{Z}^n$ is
empty, or find an integer point in the convex body scaled by $2$ from its
center of gravity $c$. Approximate integer programming can be solved in time
$2^{O(n)}$ while the fastest known methods for exact integer programming run in
time $2^{O(n)} \cdot n^n$. So far, there are no efficient methods for integer
programming known that are based on approximate integer programming. Our main
contribution are two such methods, each yielding novel complexity results.
</p>
<p>First, we show that an integer point $x^* \in (K \cap \mathbb{Z}^n)$ can be
found in time $2^{O(n)}$, provided that the remainders of each component $x_i^*
\mod{\ell}$ for some arbitrarily fixed $\ell \geq 5(n+1)$ of $x^*$ are given.
The algorithm is based on a cutting-plane technique, iteratively halving the
volume of the feasible set. The cutting planes are determined via approximate
integer programming. Enumeration of the possible remainders gives a
$2^{O(n)}n^n$ algorithm for general integer programming. This matches the
current best bound of an algorithm by Dadush (2012) that is considerably more
involved. Our algorithm also relies on a new asymmetric approximate
Carath\'eodory theorem that might be of interest on its own.
</p>
<p>Our second method concerns integer programming problems in equation-standard
form $Ax = b, 0 \leq x \leq u, \, x \in \mathbb{Z}^n$ . Such a problem can be
reduced to the solution of $\prod_i O(\log u_i +1)$ approximate integer
programming problems. This implies, for example that knapsack or subset-sum
problems with polynomial variable range $0 \leq x_i \leq p(n)$ can be solved in
time $(\log n)^{O(n)}$. For these problems, the best running time so far was
$n^n \cdot 2^{O(n)}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03874'>Nearly optimal independence oracle algorithms for edge estimation in hypergraphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Holger Dell, John Lapinskas, Kitty Meeks</p><p>We study a query model of computation in which an n-vertex k-hypergraph can
be accessed only via its independence oracle or via its colourful independence
oracle, and each oracle query may incur a cost depending on the size of the
query. In each of these models, we obtain oracle algorithms to approximately
count the hypergraph's edges, and we unconditionally prove that no oracle
algorithm for this problem can have significantly smaller worst-case oracle
cost than our algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dell_H/0/1/0/all/0/1">Holger Dell</a>, <a href="http://arxiv.org/find/cs/1/au:+Lapinskas_J/0/1/0/all/0/1">John Lapinskas</a>, <a href="http://arxiv.org/find/cs/1/au:+Meeks_K/0/1/0/all/0/1">Kitty Meeks</a></p><p>We study a query model of computation in which an n-vertex k-hypergraph can
be accessed only via its independence oracle or via its colourful independence
oracle, and each oracle query may incur a cost depending on the size of the
query. In each of these models, we obtain oracle algorithms to approximately
count the hypergraph's edges, and we unconditionally prove that no oracle
algorithm for this problem can have significantly smaller worst-case oracle
cost than our algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03917'>On the amortized complexity of approximate counting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ishaq Aden-Ali, Yanjun Han, Jelani Nelson, Huacheng Yu</p><p>Naively storing a counter up to value $n$ would require $\Omega(\log n)$ bits
of memory. Nelson and Yu [NY22], following work of [Morris78], showed that if
the query answers need only be $(1+\epsilon)$-approximate with probability at
least $1 - \delta$, then $O(\log\log n + \log\log(1/\delta) +
\log(1/\epsilon))$ bits suffice, and in fact this bound is tight. Morris'
original motivation for studying this problem though, as well as modern
applications, require not only maintaining one counter, but rather $k$ counters
for $k$ large. This motivates the following question: for $k$ large, can $k$
counters be simultaneously maintained using asymptotically less memory than $k$
times the cost of an individual counter? That is to say, does this problem
benefit from an improved {\it amortized} space complexity bound?
</p>
<p>We answer this question in the negative. Specifically, we prove a lower bound
for nearly the full range of parameters showing that, in terms of memory usage,
there is no asymptotic benefit possible via amortization when storing multiple
counters. Our main proof utilizes a certain notion of "information cost"
recently introduced by Braverman, Garg and Woodruff in FOCS 2020 to prove lower
bounds for streaming algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aden_Ali_I/0/1/0/all/0/1">Ishaq Aden-Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yanjun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Nelson_J/0/1/0/all/0/1">Jelani Nelson</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Huacheng Yu</a></p><p>Naively storing a counter up to value $n$ would require $\Omega(\log n)$ bits
of memory. Nelson and Yu [NY22], following work of [Morris78], showed that if
the query answers need only be $(1+\epsilon)$-approximate with probability at
least $1 - \delta$, then $O(\log\log n + \log\log(1/\delta) +
\log(1/\epsilon))$ bits suffice, and in fact this bound is tight. Morris'
original motivation for studying this problem though, as well as modern
applications, require not only maintaining one counter, but rather $k$ counters
for $k$ large. This motivates the following question: for $k$ large, can $k$
counters be simultaneously maintained using asymptotically less memory than $k$
times the cost of an individual counter? That is to say, does this problem
benefit from an improved {\it amortized} space complexity bound?
</p>
<p>We answer this question in the negative. Specifically, we prove a lower bound
for nearly the full range of parameters showing that, in terms of memory usage,
there is no asymptotic benefit possible via amortization when storing multiple
counters. Our main proof utilizes a certain notion of "information cost"
recently introduced by Braverman, Garg and Woodruff in FOCS 2020 to prove lower
bounds for streaming algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04117'>Computing better approximate pure Nash equilibria in cut games via semidefinite programming</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ioannis Caragiannis, Zhile Jiang</p><p>Cut games are among the most fundamental strategic games in algorithmic game
theory. It is well-known that computing an exact pure Nash equilibrium in these
games is PLS-hard, so research has focused on computing approximate equilibria.
We present a polynomial-time algorithm that computes $2.7371$-approximate pure
Nash equilibria in cut games. This is the first improvement to the previously
best-known bound of $3$, due to the work of Bhalgat, Chakraborty, and Khanna
from EC 2010. Our algorithm is based on a general recipe proposed by
Caragiannis, Fanelli, Gravin, and Skopalik from FOCS 2011 and applied on
several potential games since then. The first novelty of our work is the
introduction of a phase that can identify subsets of players who can
simultaneously improve their utilities considerably. This is done via
semidefinite programming and randomized rounding. In particular, a negative
objective value to the semidefinite program guarantees that no such
considerable improvement is possible for a given set of players. Otherwise,
randomized rounding of the SDP solution is used to identify a set of players
who can simultaneously improve their strategies considerably and allows the
algorithm to make progress. The way rounding is performed is another important
novelty of our work. Here, we exploit an idea that dates back to a paper by
Feige and Goemans from 1995, but we take it to an extreme that has not been
analyzed before.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Caragiannis_I/0/1/0/all/0/1">Ioannis Caragiannis</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhile Jiang</a></p><p>Cut games are among the most fundamental strategic games in algorithmic game
theory. It is well-known that computing an exact pure Nash equilibrium in these
games is PLS-hard, so research has focused on computing approximate equilibria.
We present a polynomial-time algorithm that computes $2.7371$-approximate pure
Nash equilibria in cut games. This is the first improvement to the previously
best-known bound of $3$, due to the work of Bhalgat, Chakraborty, and Khanna
from EC 2010. Our algorithm is based on a general recipe proposed by
Caragiannis, Fanelli, Gravin, and Skopalik from FOCS 2011 and applied on
several potential games since then. The first novelty of our work is the
introduction of a phase that can identify subsets of players who can
simultaneously improve their utilities considerably. This is done via
semidefinite programming and randomized rounding. In particular, a negative
objective value to the semidefinite program guarantees that no such
considerable improvement is possible for a given set of players. Otherwise,
randomized rounding of the SDP solution is used to identify a set of players
who can simultaneously improve their strategies considerably and allows the
algorithm to make progress. The way rounding is performed is another important
novelty of our work. Here, we exploit an idea that dates back to a paper by
Feige and Goemans from 1995, but we take it to an extreme that has not been
analyzed before.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04278'>Tight Complexity Bounds for Counting Generalized Dominating Sets in Bounded-Treewidth Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jacob Focke, D&#xe1;niel Marx, Fionn Mc Inerney, Daniel Neuen, Govind S. Sankar, Philipp Schepper, Philip Wellnitz</p><p>We investigate how efficiently a well-studied family of domination-type
problems can be solved on bounded-treewidth graphs. For sets $\sigma,\rho$ of
non-negative integers, a $(\sigma,\rho)$-set of a graph $G$ is a set $S$ of
vertices such that $|N(u)\cap S|\in \sigma$ for every $u\in S$, and $|N(v)\cap
S|\in \rho$ for every $v\not\in S$. The problem of finding a
$(\sigma,\rho)$-set (of a certain size) unifies standard problems such as
Independent Set, Dominating Set, Independent Dominating Set, and many others.
</p>
<p>For all pairs of finite or cofinite sets $(\sigma,\rho)$, we determine (under
standard complexity assumptions) the best possible value $c_{\sigma,\rho}$ such
that there is an algorithm that counts $(\sigma,\rho)$-sets in time
$c_{\sigma,\rho}^{\sf tw}\cdot n^{O(1)}$ (if a tree decomposition of width
${\sf tw}$ is given in the input). For example, for the Exact Independent
Dominating Set problem (also known as Perfect Code) corresponding to
$\sigma=\{0\}$ and $\rho=\{1\}$, we improve the $3^{\sf tw}\cdot n^{O(1)}$
algorithm of [van Rooij, 2020] to $2^{\sf tw}\cdot n^{O(1)}$.
</p>
<p>Despite the unusually delicate definition of $c_{\sigma,\rho}$, we show that
our algorithms are most likely optimal, i.e., for any pair $(\sigma, \rho)$ of
finite or cofinite sets where the problem is non-trivial, and any
$\varepsilon&gt;0$, a $(c_{\sigma,\rho}-\varepsilon)^{\sf tw}\cdot
n^{O(1)}$-algorithm counting the number of $(\sigma,\rho)$-sets would violate
the Counting Strong Exponential-Time Hypothesis (#SETH). For finite sets
$\sigma$ and $\rho$, our lower bounds also extend to the decision version,
showing that our algorithms are optimal in this setting as well. In contrast,
for many cofinite sets, we show that further significant improvements for the
decision and optimization versions are possible using the technique of
representative sets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Focke_J/0/1/0/all/0/1">Jacob Focke</a>, <a href="http://arxiv.org/find/cs/1/au:+Marx_D/0/1/0/all/0/1">D&#xe1;niel Marx</a>, <a href="http://arxiv.org/find/cs/1/au:+Inerney_F/0/1/0/all/0/1">Fionn Mc Inerney</a>, <a href="http://arxiv.org/find/cs/1/au:+Neuen_D/0/1/0/all/0/1">Daniel Neuen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankar_G/0/1/0/all/0/1">Govind S. Sankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Schepper_P/0/1/0/all/0/1">Philipp Schepper</a>, <a href="http://arxiv.org/find/cs/1/au:+Wellnitz_P/0/1/0/all/0/1">Philip Wellnitz</a></p><p>We investigate how efficiently a well-studied family of domination-type
problems can be solved on bounded-treewidth graphs. For sets $\sigma,\rho$ of
non-negative integers, a $(\sigma,\rho)$-set of a graph $G$ is a set $S$ of
vertices such that $|N(u)\cap S|\in \sigma$ for every $u\in S$, and $|N(v)\cap
S|\in \rho$ for every $v\not\in S$. The problem of finding a
$(\sigma,\rho)$-set (of a certain size) unifies standard problems such as
Independent Set, Dominating Set, Independent Dominating Set, and many others.
</p>
<p>For all pairs of finite or cofinite sets $(\sigma,\rho)$, we determine (under
standard complexity assumptions) the best possible value $c_{\sigma,\rho}$ such
that there is an algorithm that counts $(\sigma,\rho)$-sets in time
$c_{\sigma,\rho}^{\sf tw}\cdot n^{O(1)}$ (if a tree decomposition of width
${\sf tw}$ is given in the input). For example, for the Exact Independent
Dominating Set problem (also known as Perfect Code) corresponding to
$\sigma=\{0\}$ and $\rho=\{1\}$, we improve the $3^{\sf tw}\cdot n^{O(1)}$
algorithm of [van Rooij, 2020] to $2^{\sf tw}\cdot n^{O(1)}$.
</p>
<p>Despite the unusually delicate definition of $c_{\sigma,\rho}$, we show that
our algorithms are most likely optimal, i.e., for any pair $(\sigma, \rho)$ of
finite or cofinite sets where the problem is non-trivial, and any
$\varepsilon&gt;0$, a $(c_{\sigma,\rho}-\varepsilon)^{\sf tw}\cdot
n^{O(1)}$-algorithm counting the number of $(\sigma,\rho)$-sets would violate
the Counting Strong Exponential-Time Hypothesis (#SETH). For finite sets
$\sigma$ and $\rho$, our lower bounds also extend to the decision version,
showing that our algorithms are optimal in this setting as well. In contrast,
for many cofinite sets, we show that further significant improvements for the
decision and optimization versions are possible using the technique of
representative sets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04385'>Why we couldn't prove SETH hardness of the Closest Vector Problem for even norms, and of the Subset Sum Problem!</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Divesh Aggarwal, Rajendra Kumar</p><p>Recent work [BGS17,ABGS19] has shown SETH hardness of some constant factor
approximate CVP in the $\ell_p$ norm for any $p$ that is not an even integer.
This result was shown by giving a Karp reduction from $k$-SAT on $n$ variables
to approximate CVP on a lattice of rank $n$. In this work, we show a barrier
towards proving a similar result for CVP in the $\ell_p$ norm where $p$ is an
even integer. We show that for any $c, c'&gt;0$, if for every $k &gt; 0$, there
exists an efficient reduction that maps a $k$-SAT instance on $n$ variables to
a $(1+exp(-n^c)))$-CVP instance for a lattice of rank at most $n^{c'}$ in the
Euclidean norm, then $\mathsf{coNP} \subset \mathsf{NP/Poly}$. We prove a
similar result for $(1+exp(-n^c)))$-CVP for all even norms under a mild
additional promise that the ratio of the distance of the target from the
lattice and the shortest non-zero vector in the lattice is bounded by
$exp(n^{O(1)})$.
</p>
<p>Furthermore, we show that for any $c,c' &gt; 0$, and any even integer $p$, if
for every $k &gt; 0$, there exists an efficient reduction that maps a $k$-SAT
instance on $n$ variables to a $(1+exp(-n^c)))$-$SVP_p$ instance for a lattice
of rank at most $n^{c'}$, then $\mathsf{coNP} \subset \mathsf{NP/Poly}$. The
result for SVP does not require any additional promise.
</p>
<p>While prior results have indicated that lattice problems in the $\ell_2$ norm
(Euclidean norm) are easier than lattice problems in other norms, this is the
first result that shows a separation between these problems.
</p>
<p>We achieve this by using a result by Dell and van Melkebeek [JACM, 2014] on
the impossibility of the existence of a reduction that compresses an arbitrary
$k$-SAT instance into a string of length $\mathcal{O}(n^{k-\epsilon})$ for any
$\epsilon&gt;0$. In addition to CVP, we also show that the same result holds for
the Subset-Sum problem using similar techniques.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_D/0/1/0/all/0/1">Divesh Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Rajendra Kumar</a></p><p>Recent work [BGS17,ABGS19] has shown SETH hardness of some constant factor
approximate CVP in the $\ell_p$ norm for any $p$ that is not an even integer.
This result was shown by giving a Karp reduction from $k$-SAT on $n$ variables
to approximate CVP on a lattice of rank $n$. In this work, we show a barrier
towards proving a similar result for CVP in the $\ell_p$ norm where $p$ is an
even integer. We show that for any $c, c'&gt;0$, if for every $k &gt; 0$, there
exists an efficient reduction that maps a $k$-SAT instance on $n$ variables to
a $(1+exp(-n^c)))$-CVP instance for a lattice of rank at most $n^{c'}$ in the
Euclidean norm, then $\mathsf{coNP} \subset \mathsf{NP/Poly}$. We prove a
similar result for $(1+exp(-n^c)))$-CVP for all even norms under a mild
additional promise that the ratio of the distance of the target from the
lattice and the shortest non-zero vector in the lattice is bounded by
$exp(n^{O(1)})$.
</p>
<p>Furthermore, we show that for any $c,c' &gt; 0$, and any even integer $p$, if
for every $k &gt; 0$, there exists an efficient reduction that maps a $k$-SAT
instance on $n$ variables to a $(1+exp(-n^c)))$-$SVP_p$ instance for a lattice
of rank at most $n^{c'}$, then $\mathsf{coNP} \subset \mathsf{NP/Poly}$. The
result for SVP does not require any additional promise.
</p>
<p>While prior results have indicated that lattice problems in the $\ell_2$ norm
(Euclidean norm) are easier than lattice problems in other norms, this is the
first result that shows a separation between these problems.
</p>
<p>We achieve this by using a result by Dell and van Melkebeek [JACM, 2014] on
the impossibility of the existence of a reduction that compresses an arbitrary
$k$-SAT instance into a string of length $\mathcal{O}(n^{k-\epsilon})$ for any
$\epsilon&gt;0$. In addition to CVP, we also show that the same result holds for
the Subset-Sum problem using similar techniques.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04439'>Sampling from convex sets with a cold start using multiscale decompositions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hariharan Narayanan, Amit Rajaraman, Piyush Srivastava</p><p>A standard approach to sample approximately uniformly from a convex body
$K\subseteq\mathbb{R}^n$ is to run a random walk within $K$. The requirement is
that from a suitable initial distribution, the distribution of the walk comes
close to the uniform distribution $\pi_K$ on $K$ after a number of steps
polynomial in $n$ and the aspect ratio $R/r$ (here, $K$ is assumed to contain a
ball of radius $r$ and to be contained in a ball of radius $R$).
</p>
<p>Proofs of rapid mixing of such walks often require the probability density
$\eta_0$ of the initial distribution with respect to $\pi_K$ to be at most
$\mathrm{poly}(n)$: this is called a "warm start". Achieving a warm start often
requires non-trivial pre-processing before starting the random walk. This
motivates proving rapid mixing from a "cold start", wherein $\eta_0$ can be as
high as $\exp(\mathrm{poly}(n))$. Unlike warm starts, a cold start is usually
trivial to achieve. However, a random walks need not mix rapidly from a cold
start: an example being the well-known "ball walk". On the other hand, Lov\'asz
and Vempala proved that the "hit-and-run" random walk mixes rapidly from a cold
start. For the related coordinate hit-and-run (CHR) walk, which has been found
to be promising in computational experiments, rapid mixing from a warm start
was proved only recently but the question of rapid mixing from a cold start
remained open.
</p>
<p>We construct a family of random walks inspired by classical decompositions of
subsets of $\mathbb{R}^n$ into countably many axis-aligned dyadic cubes. We
show that even with a cold start, the mixing times of these walks are bounded
by a polynomial in $n$ and the aspect ratio. Our main technical ingredient is
an isoperimetric inequality for $K$ for a metric that magnifies distances
between points close to the boundary of $K$. As a corollary, we show that the
CHR walk also mixes rapidly from a cold start.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Narayanan_H/0/1/0/all/0/1">Hariharan Narayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajaraman_A/0/1/0/all/0/1">Amit Rajaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_P/0/1/0/all/0/1">Piyush Srivastava</a></p><p>A standard approach to sample approximately uniformly from a convex body
$K\subseteq\mathbb{R}^n$ is to run a random walk within $K$. The requirement is
that from a suitable initial distribution, the distribution of the walk comes
close to the uniform distribution $\pi_K$ on $K$ after a number of steps
polynomial in $n$ and the aspect ratio $R/r$ (here, $K$ is assumed to contain a
ball of radius $r$ and to be contained in a ball of radius $R$).
</p>
<p>Proofs of rapid mixing of such walks often require the probability density
$\eta_0$ of the initial distribution with respect to $\pi_K$ to be at most
$\mathrm{poly}(n)$: this is called a "warm start". Achieving a warm start often
requires non-trivial pre-processing before starting the random walk. This
motivates proving rapid mixing from a "cold start", wherein $\eta_0$ can be as
high as $\exp(\mathrm{poly}(n))$. Unlike warm starts, a cold start is usually
trivial to achieve. However, a random walks need not mix rapidly from a cold
start: an example being the well-known "ball walk". On the other hand, Lov\'asz
and Vempala proved that the "hit-and-run" random walk mixes rapidly from a cold
start. For the related coordinate hit-and-run (CHR) walk, which has been found
to be promising in computational experiments, rapid mixing from a warm start
was proved only recently but the question of rapid mixing from a cold start
remained open.
</p>
<p>We construct a family of random walks inspired by classical decompositions of
subsets of $\mathbb{R}^n$ into countably many axis-aligned dyadic cubes. We
show that even with a cold start, the mixing times of these walks are bounded
by a polynomial in $n$ and the aspect ratio. Our main technical ingredient is
an isoperimetric inequality for $K$ for a metric that magnifies distances
between points close to the boundary of $K$. As a corollary, we show that the
CHR walk also mixes rapidly from a cold start.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03830'>Further Improvements on Approximating the Uniform Cost-Distance Steiner Tree Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Stephan Held, Yannik Kyle Dustin Spitzley</p><p>In this paper, we consider the Uniform Cost-Distance Steiner Tree Problem in
metric spaces, a generalization of the well-known Steiner tree problem.
Cost-distance Steiner trees minimize the sum of the total length and the
weighted path lengths from a dedicated root to the other terminals, which have
a weight to penalize the path length. They are applied when the tree is
intended for signal transmission, e.g. in chip design or telecommunication
networks, and the signal speed through the tree has to be considered besides
the total length. Constant factor approximation algorithms for the uniform
cost-distance Steiner tree problem have been known since the first mentioning
of the problem by Meyerson, Munagala, and Plotkin. Recently, the approximation
factor was improved from 2.87 to 2.39 by Khazraei and Held. We refine their
approach further and reduce the approximation factor down to 2.15.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Held_S/0/1/0/all/0/1">Stephan Held</a>, <a href="http://arxiv.org/find/cs/1/au:+Spitzley_Y/0/1/0/all/0/1">Yannik Kyle Dustin Spitzley</a></p><p>In this paper, we consider the Uniform Cost-Distance Steiner Tree Problem in
metric spaces, a generalization of the well-known Steiner tree problem.
Cost-distance Steiner trees minimize the sum of the total length and the
weighted path lengths from a dedicated root to the other terminals, which have
a weight to penalize the path length. They are applied when the tree is
intended for signal transmission, e.g. in chip design or telecommunication
networks, and the signal speed through the tree has to be considered besides
the total length. Constant factor approximation algorithms for the uniform
cost-distance Steiner tree problem have been known since the first mentioning
of the problem by Meyerson, Munagala, and Plotkin. Recently, the approximation
factor was improved from 2.87 to 2.39 by Khazraei and Held. We refine their
approach further and reduce the approximation factor down to 2.15.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03883'>Approximating Nash Social Welfare by Matching and Local Search</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jugal Garg, Edin Husi&#x107;, Wenzheng Li, L&#xe1;szl&#xf3; A. V&#xe9;gh, Jan Vondr&#xe1;k</p><p>For any $\varepsilon&gt;0$, we give a simple, deterministic
$(6+\varepsilon)$-approximation algorithm for the Nash social welfare (NSW)
problem under submodular valuations. The previous best approximation factor was
$380$ via a randomized algorithm. We also consider the asymmetric variant of
the problem, where the objective is to maximize the weighted geometric mean of
agents' valuations, and give an $(\omega + 2 +\varepsilon) e$-approximation if
the ratio between the largest weight and the average weight is at most
$\omega$.
</p>
<p>We also show that the $1/2$-EFX envy-freeness property can be attained
simultaneously with a constant-factor approximation. More precisely, we can
find an allocation in polynomial time which is both $1/2$-EFX and a
$(12+\varepsilon)$-approximation to the symmetric NSW problem under submodular
valuations. The previous best approximation factor under $1/2$-EFX was linear
in the number of agents.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Garg_J/0/1/0/all/0/1">Jugal Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Husic_E/0/1/0/all/0/1">Edin Husi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenzheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Vegh_L/0/1/0/all/0/1">L&#xe1;szl&#xf3; A. V&#xe9;gh</a>, <a href="http://arxiv.org/find/cs/1/au:+Vondrak_J/0/1/0/all/0/1">Jan Vondr&#xe1;k</a></p><p>For any $\varepsilon&gt;0$, we give a simple, deterministic
$(6+\varepsilon)$-approximation algorithm for the Nash social welfare (NSW)
problem under submodular valuations. The previous best approximation factor was
$380$ via a randomized algorithm. We also consider the asymmetric variant of
the problem, where the objective is to maximize the weighted geometric mean of
agents' valuations, and give an $(\omega + 2 +\varepsilon) e$-approximation if
the ratio between the largest weight and the average weight is at most
$\omega$.
</p>
<p>We also show that the $1/2$-EFX envy-freeness property can be attained
simultaneously with a constant-factor approximation. More precisely, we can
find an allocation in polynomial time which is both $1/2$-EFX and a
$(12+\varepsilon)$-approximation to the symmetric NSW problem under submodular
valuations. The previous best approximation factor under $1/2$-EFX was linear
in the number of agents.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03893'>Query Complexity of the Metric Steiner Tree Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yu Chen, Sanjeev Khanna, Zihan Tan</p><p>We study the query complexity of the metric Steiner Tree problem, where we
are given an $n \times n$ metric on a set $V$ of vertices along with a set $T
\subseteq V$ of $k$ terminals, and the goal is to find a tree of minimum cost
that contains all terminals in $T$. The query complexity for the related
minimum spanning tree (MST) problem is well-understood: for any fixed
$\varepsilon &gt; 0$, one can estimate the MST cost to within a
$(1+\varepsilon)$-factor using only $\tilde{O}(n)$ queries, and this is known
to be tight. This implies that a $(2 + \varepsilon)$-approximate estimate of
Steiner Tree cost can be obtained with $\tilde{O}(k)$ queries by simply
applying the MST cost estimation algorithm on the metric induced by the
terminals.
</p>
<p>Our first result shows that any (randomized) algorithm that estimates the
Steiner Tree cost to within a $(5/3 - \varepsilon)$-factor requires
$\Omega(n^2)$ queries, even if $k$ is a constant. This lower bound is in sharp
contrast to an upper bound of $O(nk)$ queries for computing a
$(5/3)$-approximate Steiner Tree, which follows from previous work by Du and
Zelikovsky.
</p>
<p>Our second main result, and the main technical contribution of this work, is
a sublinear query algorithm for estimating the Steiner Tree cost to within a
strictly better-than-$2$ factor, with query complexity $\tilde{O}(n^{12/7} +
n^{6/7}\cdot k)=\tilde{O}(n^{13/7})=o(n^2)$. We complement this result by
showing an $\tilde{\Omega}(n + k^{6/5})$ query lower bound for any algorithm
that estimates Steiner Tree cost to a strictly better than $2$ factor. Thus
$\tilde{\Omega}(n^{6/5})$ queries are needed to just beat $2$-approximation
when $k = \Omega(n)$; a sharp contrast to MST cost estimation where a
$(1+o(1))$-approximate estimate of cost is achievable with only $\tilde{O}(n)$
queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Khanna_S/0/1/0/all/0/1">Sanjeev Khanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zihan Tan</a></p><p>We study the query complexity of the metric Steiner Tree problem, where we
are given an $n \times n$ metric on a set $V$ of vertices along with a set $T
\subseteq V$ of $k$ terminals, and the goal is to find a tree of minimum cost
that contains all terminals in $T$. The query complexity for the related
minimum spanning tree (MST) problem is well-understood: for any fixed
$\varepsilon &gt; 0$, one can estimate the MST cost to within a
$(1+\varepsilon)$-factor using only $\tilde{O}(n)$ queries, and this is known
to be tight. This implies that a $(2 + \varepsilon)$-approximate estimate of
Steiner Tree cost can be obtained with $\tilde{O}(k)$ queries by simply
applying the MST cost estimation algorithm on the metric induced by the
terminals.
</p>
<p>Our first result shows that any (randomized) algorithm that estimates the
Steiner Tree cost to within a $(5/3 - \varepsilon)$-factor requires
$\Omega(n^2)$ queries, even if $k$ is a constant. This lower bound is in sharp
contrast to an upper bound of $O(nk)$ queries for computing a
$(5/3)$-approximate Steiner Tree, which follows from previous work by Du and
Zelikovsky.
</p>
<p>Our second main result, and the main technical contribution of this work, is
a sublinear query algorithm for estimating the Steiner Tree cost to within a
strictly better-than-$2$ factor, with query complexity $\tilde{O}(n^{12/7} +
n^{6/7}\cdot k)=\tilde{O}(n^{13/7})=o(n^2)$. We complement this result by
showing an $\tilde{\Omega}(n + k^{6/5})$ query lower bound for any algorithm
that estimates Steiner Tree cost to a strictly better than $2$ factor. Thus
$\tilde{\Omega}(n^{6/5})$ queries are needed to just beat $2$-approximation
when $k = \Omega(n)$; a sharp contrast to MST cost estimation where a
$(1+o(1))$-approximate estimate of cost is achievable with only $\tilde{O}(n)$
queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03916'>Streaming beyond sketching for Maximum Directed Cut</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Raghuvansh R. Saxena, Noah Singer, Madhu Sudan, Santhoshini Velusamy</p><p>We give an $\widetilde{O}(\sqrt{n})$-space single-pass $0.483$-approximation
streaming algorithm for estimating the maximum directed cut size
($\textsf{Max-DICUT}$) in a directed graph on $n$ vertices. This improves over
an $O(\log n)$-space $4/9 &lt; 0.45$ approximation algorithm due to Chou,
Golovnev, Velusamy (FOCS 2020), which was known to be optimal for
$o(\sqrt{n})$-space algorithms.
</p>
<p>$\textsf{Max-DICUT}$ is a special case of a constraint satisfaction problem
(CSP). In this broader context, our work gives the first CSP for which
algorithms with $\widetilde{O}(\sqrt{n})$ space can provably outperform
$o(\sqrt{n})$-space algorithms on general instances. Previously, this was shown
in the restricted case of bounded-degree graphs in a previous work of the
authors (SODA 2023). Prior to that work, the only algorithms for any CSP were
based on generalizations of the $O(\log n)$-space algorithm for
$\textsf{Max-DICUT}$, and were in particular so-called "sketching" algorithms.
In this work, we demonstrate that more sophisticated streaming algorithms can
outperform these algorithms even on general instances.
</p>
<p>Our algorithm constructs a "snapshot" of the graph and then applies a result
of Feige and Jozeph (Algorithmica, 2015) to approximately estimate the
$\textsf{Max-DICUT}$ value from this snapshot. Constructing this snapshot is
easy for bounded-degree graphs and the main contribution of our work is to
construct this snapshot in the general setting. This involves some delicate
sampling methods as well as a host of "continuity" results on the
$\textsf{Max-DICUT}$ behaviour in graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Saxena_R/0/1/0/all/0/1">Raghuvansh R. Saxena</a>, <a href="http://arxiv.org/find/cs/1/au:+Singer_N/0/1/0/all/0/1">Noah Singer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudan_M/0/1/0/all/0/1">Madhu Sudan</a>, <a href="http://arxiv.org/find/cs/1/au:+Velusamy_S/0/1/0/all/0/1">Santhoshini Velusamy</a></p><p>We give an $\widetilde{O}(\sqrt{n})$-space single-pass $0.483$-approximation
streaming algorithm for estimating the maximum directed cut size
($\textsf{Max-DICUT}$) in a directed graph on $n$ vertices. This improves over
an $O(\log n)$-space $4/9 &lt; 0.45$ approximation algorithm due to Chou,
Golovnev, Velusamy (FOCS 2020), which was known to be optimal for
$o(\sqrt{n})$-space algorithms.
</p>
<p>$\textsf{Max-DICUT}$ is a special case of a constraint satisfaction problem
(CSP). In this broader context, our work gives the first CSP for which
algorithms with $\widetilde{O}(\sqrt{n})$ space can provably outperform
$o(\sqrt{n})$-space algorithms on general instances. Previously, this was shown
in the restricted case of bounded-degree graphs in a previous work of the
authors (SODA 2023). Prior to that work, the only algorithms for any CSP were
based on generalizations of the $O(\log n)$-space algorithm for
$\textsf{Max-DICUT}$, and were in particular so-called "sketching" algorithms.
In this work, we demonstrate that more sophisticated streaming algorithms can
outperform these algorithms even on general instances.
</p>
<p>Our algorithm constructs a "snapshot" of the graph and then applies a result
of Feige and Jozeph (Algorithmica, 2015) to approximately estimate the
$\textsf{Max-DICUT}$ value from this snapshot. Constructing this snapshot is
easy for bounded-degree graphs and the main contribution of our work is to
construct this snapshot in the general setting. This involves some delicate
sampling methods as well as a host of "continuity" results on the
$\textsf{Max-DICUT}$ behaviour in graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03963'>Fast Algorithms for $\ell_p$-Regression</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Deeksha Adil, Rasmus Kyng, Richard Peng, Sushant Sachdeva</p><p>The $\ell_p$-norm regression problem is a classic problem in optimization
with wide ranging applications in machine learning and theoretical computer
science. The goal is to compute $x^{\star} =\arg\min_{Ax=b}\|x\|_p^p$, where
$x^{\star}\in \mathbb{R}^n, A\in \mathbb{R}^{d\times n},b \in \mathbb{R}^d$ and
$d\leq n$. Efficient high-accuracy algorithms for the problem have been
challenging both in theory and practice and the state of the art algorithms
require $poly(p)\cdot n^{\frac{1}{2}-\frac{1}{p}}$ linear system solves for
$p\geq 2$. In this paper, we provide new algorithms for $\ell_p$-regression
(and a more general formulation of the problem) that obtain a high-accuracy
solution in $O(p n^{\frac{(p-2)}{(3p-2)}})$ linear system solves. We further
propose a new inverse maintenance procedure that speeds-up our algorithm to
$\widetilde{O}(n^{\omega})$ total runtime, where $O(n^{\omega})$ denotes the
running time for multiplying $n \times n$ matrices. Additionally, we give the
first Iteratively Reweighted Least Squares (IRLS) algorithm that is guaranteed
to converge to an optimum in a few iterations. Our IRLS algorithm has shown
exceptional practical performance, beating the currently available
implementations in MATLAB/CVX by 10-50x.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Adil_D/0/1/0/all/0/1">Deeksha Adil</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyng_R/0/1/0/all/0/1">Rasmus Kyng</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1">Richard Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachdeva_S/0/1/0/all/0/1">Sushant Sachdeva</a></p><p>The $\ell_p$-norm regression problem is a classic problem in optimization
with wide ranging applications in machine learning and theoretical computer
science. The goal is to compute $x^{\star} =\arg\min_{Ax=b}\|x\|_p^p$, where
$x^{\star}\in \mathbb{R}^n, A\in \mathbb{R}^{d\times n},b \in \mathbb{R}^d$ and
$d\leq n$. Efficient high-accuracy algorithms for the problem have been
challenging both in theory and practice and the state of the art algorithms
require $poly(p)\cdot n^{\frac{1}{2}-\frac{1}{p}}$ linear system solves for
$p\geq 2$. In this paper, we provide new algorithms for $\ell_p$-regression
(and a more general formulation of the problem) that obtain a high-accuracy
solution in $O(p n^{\frac{(p-2)}{(3p-2)}})$ linear system solves. We further
propose a new inverse maintenance procedure that speeds-up our algorithm to
$\widetilde{O}(n^{\omega})$ total runtime, where $O(n^{\omega})$ denotes the
running time for multiplying $n \times n$ matrices. Additionally, we give the
first Iteratively Reweighted Least Squares (IRLS) algorithm that is guaranteed
to converge to an optimum in a few iterations. Our IRLS algorithm has shown
exceptional practical performance, beating the currently available
implementations in MATLAB/CVX by 10-50x.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03975'>Optimal Smoothed Analysis and Quantitative Universality for the Smallest Singular Value of Random Matrices</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haoyu Wang</p><p>The smallest singular value and condition number play important roles in
numerical linear algebra and the analysis of algorithms. In numerical analysis
with randomness, many previous works make Gaussian assumptions, which are not
general enough to reflect the arbitrariness of the input. To overcome this
drawback, we prove the first quantitative universality for the smallest
singular value and condition number of random matrices.
</p>
<p>Moreover, motivated by the study of smoothed analysis that random
perturbation makes deterministic matrices well-conditioned, we consider an
analog for random matrices. For a random matrix perturbed by independent
Gaussian noise, we show that this matrix quickly becomes approximately
Gaussian. In particular, we derive an optimal smoothed analysis for random
matrices in terms of a sharp Gaussian approximation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1">Haoyu Wang</a></p><p>The smallest singular value and condition number play important roles in
numerical linear algebra and the analysis of algorithms. In numerical analysis
with randomness, many previous works make Gaussian assumptions, which are not
general enough to reflect the arbitrariness of the input. To overcome this
drawback, we prove the first quantitative universality for the smallest
singular value and condition number of random matrices.
</p>
<p>Moreover, motivated by the study of smoothed analysis that random
perturbation makes deterministic matrices well-conditioned, we consider an
analog for random matrices. For a random matrix perturbed by independent
Gaussian noise, we show that this matrix quickly becomes approximately
Gaussian. In particular, we derive an optimal smoothed analysis for random
matrices in terms of a sharp Gaussian approximation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03995'>Computing palindromes on a trie in linear time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Takuya Mieno, Mitsuru Funakoshi, Shunsuke Inenaga</p><p>A trie $\mathcal{T}$ is a rooted tree such that each edge is labeled by a
single character from the alphabet, and the labels of out-going edges from the
same node are mutually distinct. Given a trie $\mathcal{T}$ with $n$ edges, we
show how to compute all distinct palindromes and all maximal palindromes on
$\mathcal{T}$ in $O(n)$ time, in the case of integer alphabets of size
polynomial in $n$.This improves the state-of-the-art $O(n \log h)$-time
algorithms by Funakoshi et al. [PCS 2019], where $h$ is the height of
$\mathcal{T}$. Using our new algorithms, the eertree with suffix links for a
given trie $\mathcal{T}$ can readily be obtained in $O(n)$ time. Further, our
trie-based $O(n)$-space data structure allows us to report all distinct
palindromes and maximal palindromes in a query string represented in the trie
$\mathcal{T}$, in output optimal time. This is an improvement over an existing
(na\"ive) solution that precomputes and stores all distinct palindromes and
maximal palindromes for each and every string in the trie $\mathcal{T}$
separately, using a total $O(n^2)$ preprocessing time and space, and reports
them in output optimal time upon query.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mieno_T/0/1/0/all/0/1">Takuya Mieno</a>, <a href="http://arxiv.org/find/cs/1/au:+Funakoshi_M/0/1/0/all/0/1">Mitsuru Funakoshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Inenaga_S/0/1/0/all/0/1">Shunsuke Inenaga</a></p><p>A trie $\mathcal{T}$ is a rooted tree such that each edge is labeled by a
single character from the alphabet, and the labels of out-going edges from the
same node are mutually distinct. Given a trie $\mathcal{T}$ with $n$ edges, we
show how to compute all distinct palindromes and all maximal palindromes on
$\mathcal{T}$ in $O(n)$ time, in the case of integer alphabets of size
polynomial in $n$.This improves the state-of-the-art $O(n \log h)$-time
algorithms by Funakoshi et al. [PCS 2019], where $h$ is the height of
$\mathcal{T}$. Using our new algorithms, the eertree with suffix links for a
given trie $\mathcal{T}$ can readily be obtained in $O(n)$ time. Further, our
trie-based $O(n)$-space data structure allows us to report all distinct
palindromes and maximal palindromes in a query string represented in the trie
$\mathcal{T}$, in output optimal time. This is an improvement over an existing
(na\"ive) solution that precomputes and stores all distinct palindromes and
maximal palindromes for each and every string in the trie $\mathcal{T}$
separately, using a total $O(n^2)$ preprocessing time and space, and reports
them in output optimal time upon query.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.03997'>A Simple Algorithm for Online Decision Making</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rui Chen, Oktay Gunluk, Andrea Lodi, Guanyi Wang</p><p>Motivated by recent progress on online linear programming (OLP), we study the
online decision making problem (ODMP) as a natural generalization of OLP. In
ODMP, there exists a single decision maker who makes a series of decisions
spread out over a total of $T$ time stages. At each time stage, the decision
maker makes a decision based on information obtained up to that point without
seeing into the future. The task of the decision maker is to maximize the
accumulated reward while overall meeting some predetermined $m$-dimensional
long-term goal (linking) constraints. ODMP significantly broadens the modeling
framework of OLP by allowing more general feasible regions (for local and goal
constraints) potentially involving both discreteness and nonlinearity in each
local decision making problem.
</p>
<p>We propose a Fenchel dual-based online algorithm for ODMP. At each time
stage, the proposed algorithm requires solving a potentially nonconvex
optimization problem over the local feasible set and a convex optimization
problem over the goal set. Under the uniform random permutation model, we show
that our algorithm achieves $O(\sqrt{mT})$ constraint violation
deterministically in meeting the long-term goals, and $O(\sqrt{m\log
m}\sqrt{T})$ competitive difference in expected reward with respect to the
optimal offline decisions. We also extend our results to the grouped random
permutation model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Chen_R/0/1/0/all/0/1">Rui Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Gunluk_O/0/1/0/all/0/1">Oktay Gunluk</a>, <a href="http://arxiv.org/find/math/1/au:+Lodi_A/0/1/0/all/0/1">Andrea Lodi</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_G/0/1/0/all/0/1">Guanyi Wang</a></p><p>Motivated by recent progress on online linear programming (OLP), we study the
online decision making problem (ODMP) as a natural generalization of OLP. In
ODMP, there exists a single decision maker who makes a series of decisions
spread out over a total of $T$ time stages. At each time stage, the decision
maker makes a decision based on information obtained up to that point without
seeing into the future. The task of the decision maker is to maximize the
accumulated reward while overall meeting some predetermined $m$-dimensional
long-term goal (linking) constraints. ODMP significantly broadens the modeling
framework of OLP by allowing more general feasible regions (for local and goal
constraints) potentially involving both discreteness and nonlinearity in each
local decision making problem.
</p>
<p>We propose a Fenchel dual-based online algorithm for ODMP. At each time
stage, the proposed algorithm requires solving a potentially nonconvex
optimization problem over the local feasible set and a convex optimization
problem over the goal set. Under the uniform random permutation model, we show
that our algorithm achieves $O(\sqrt{mT})$ constraint violation
deterministically in meeting the long-term goals, and $O(\sqrt{m\log
m}\sqrt{T})$ competitive difference in expected reward with respect to the
optimal offline decisions. We also extend our results to the grouped random
permutation model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04024'>Comparing Two Counting Methods for Estimating the Probabilities of Strings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ayaka Takamoto, Mitsuo Yoshida, Kyoji Umemura</p><p>There are two methods for counting the number of occurrences of a string in
another large string. One is to count the number of places where the string is
found. The other is to determine how many pieces of string can be extracted
without overlapping. The difference between the two becomes apparent when the
string is part of a periodic pattern. This research reports that the difference
is significant in estimating the occurrence probability of a pattern.
</p>
<p>In this study, the strings used in the experiments are approximated from
time-series data. The task involves classifying strings by estimating the
probability or computing the information quantity. First, the frequencies of
all substrings of a string are computed. Each counting method may sometimes
produce different frequencies for an identical string. Second, the probability
of the most probable segmentation is selected. The probability of the string is
the product of all probabilities of substrings in the selected segmentation.
The classification results demonstrate that the difference in counting methods
is statistically significant, and that the method without overlapping is
better.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Takamoto_A/0/1/0/all/0/1">Ayaka Takamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshida_M/0/1/0/all/0/1">Mitsuo Yoshida</a>, <a href="http://arxiv.org/find/cs/1/au:+Umemura_K/0/1/0/all/0/1">Kyoji Umemura</a></p><p>There are two methods for counting the number of occurrences of a string in
another large string. One is to count the number of places where the string is
found. The other is to determine how many pieces of string can be extracted
without overlapping. The difference between the two becomes apparent when the
string is part of a periodic pattern. This research reports that the difference
is significant in estimating the occurrence probability of a pattern.
</p>
<p>In this study, the strings used in the experiments are approximated from
time-series data. The task involves classifying strings by estimating the
probability or computing the information quantity. First, the frequencies of
all substrings of a string are computed. Each counting method may sometimes
produce different frequencies for an identical string. Second, the probability
of the most probable segmentation is selected. The probability of the string is
the product of all probabilities of substrings in the selected segmentation.
The classification results demonstrate that the difference in counting methods
is statistically significant, and that the method without overlapping is
better.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04112'>Improved Pattern-Avoidance Bounds for Greedy BSTs via Matrix Decomposition</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Parinya Chalermsook, Manoj Gupta, Wanchote Jiamjitrak, Nidia Obscura Acosta, Akash Pareek, Sorrachai Yingchareonthawornchai</p><p>Greedy BST (or simply Greedy) is an online self-adjusting binary search tree
defined in the geometric view ([Lucas, 1988; Munro, 2000; Demaine, Harmon,
Iacono, Kane, Patrascu, SODA 2009). Along with Splay trees (Sleator, Tarjan
1985), Greedy is considered the most promising candidate for being dynamically
optimal, i.e., starting with any initial tree, their access costs on any
sequence is conjectured to be within $O(1)$ factor of the offline optimal.
However, in the past four decades, the question has remained elusive even for
highly restricted input.
</p>
<p>In this paper, we prove new bounds on the cost of Greedy in the ''pattern
avoidance'' regime. Our new results include:
</p>
<p>The (preorder) traversal conjecture for Greedy holds up to a factor of
$O(2^{\alpha(n)})$, improving upon the bound of $2^{\alpha(n)^{O(1)}}$ in
(Chalermsook et al., FOCS 2015). This is the best known bound obtained by any
online BSTs.
</p>
<p>We settle the postorder traversal conjecture for Greedy.
</p>
<p>The deque conjecture for Greedy holds up to a factor of $O(\alpha(n))$,
improving upon the bound $2^{O(\alpha(n))}$ in (Chalermsook, et al., WADS
2015).
</p>
<p>The split conjecture holds for Greedy up to a factor of $O(2^{\alpha(n)})$.
</p>
<p>Key to all these results is to partition (based on the input structures) the
execution log of Greedy into several simpler-to-analyze subsets for which
classical forbidden submatrix bounds can be leveraged. Finally, we show the
applicability of this technique to handle a class of increasingly complex
pattern-avoiding input sequences, called $k$-increasing sequences.
</p>
<p>As a bonus, we discover a new class of permutation matrices whose extremal
bounds are polynomially bounded. This gives a partial progress on an open
question by Jacob Fox (2013).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chalermsook_P/0/1/0/all/0/1">Parinya Chalermsook</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Manoj Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiamjitrak_W/0/1/0/all/0/1">Wanchote Jiamjitrak</a>, <a href="http://arxiv.org/find/cs/1/au:+Acosta_N/0/1/0/all/0/1">Nidia Obscura Acosta</a>, <a href="http://arxiv.org/find/cs/1/au:+Pareek_A/0/1/0/all/0/1">Akash Pareek</a>, <a href="http://arxiv.org/find/cs/1/au:+Yingchareonthawornchai_S/0/1/0/all/0/1">Sorrachai Yingchareonthawornchai</a></p><p>Greedy BST (or simply Greedy) is an online self-adjusting binary search tree
defined in the geometric view ([Lucas, 1988; Munro, 2000; Demaine, Harmon,
Iacono, Kane, Patrascu, SODA 2009). Along with Splay trees (Sleator, Tarjan
1985), Greedy is considered the most promising candidate for being dynamically
optimal, i.e., starting with any initial tree, their access costs on any
sequence is conjectured to be within $O(1)$ factor of the offline optimal.
However, in the past four decades, the question has remained elusive even for
highly restricted input.
</p>
<p>In this paper, we prove new bounds on the cost of Greedy in the ''pattern
avoidance'' regime. Our new results include:
</p>
<p>The (preorder) traversal conjecture for Greedy holds up to a factor of
$O(2^{\alpha(n)})$, improving upon the bound of $2^{\alpha(n)^{O(1)}}$ in
(Chalermsook et al., FOCS 2015). This is the best known bound obtained by any
online BSTs.
</p>
<p>We settle the postorder traversal conjecture for Greedy.
</p>
<p>The deque conjecture for Greedy holds up to a factor of $O(\alpha(n))$,
improving upon the bound $2^{O(\alpha(n))}$ in (Chalermsook, et al., WADS
2015).
</p>
<p>The split conjecture holds for Greedy up to a factor of $O(2^{\alpha(n)})$.
</p>
<p>Key to all these results is to partition (based on the input structures) the
execution log of Greedy into several simpler-to-analyze subsets for which
classical forbidden submatrix bounds can be leveraged. Finally, we show the
applicability of this technique to handle a class of increasingly complex
pattern-avoiding input sequences, called $k$-increasing sequences.
</p>
<p>As a bonus, we discover a new class of permutation matrices whose extremal
bounds are polynomially bounded. This gives a partial progress on an open
question by Jacob Fox (2013).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04145'>Prophet Inequality: Order selection beats random order</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Archit Bubna, Ashish Chiplunkar</p><p>In the prophet inequality problem, a gambler faces a sequence of items
arriving online with values drawn independently from known distributions. On
seeing an item, the gambler must choose whether to accept its value as her
reward and quit the game, or reject it and continue. The gambler's aim is to
maximize her expected reward relative to the expected maximum of the values of
all items. Since the seminal work of Krengel and Sucheston (1977,1978), a tight
bound of 1/2 has been known for this competitive ratio in the setting where the
items arrive in an adversarial order. However, the optimum ratio still remains
unknown in the order selection setting, where the gambler selects the arrival
order, as well as in prophet secretary, where the items arrive in a random
order. Moreover, it is not even known whether a separation exists between the
two settings.
</p>
<p>In this paper, we show that the power of order selection allows the gambler
to guarantee a strictly better competitive ratio than if the items arrive
randomly. For the order selection setting, we identify an instance for which
Peng and Tang's (FOCS'22) state-of-the-art algorithm performs no better than
their claimed competitive ratio of (approximately) 0.7251, thus illustrating
the need for an improved approach. We therefore extend their design and provide
a more general algorithm design framework which allows the use of a different
time-dependent threshold function for each item, as opposed to the common
threshold function employed by Peng and Tang's algorithm. We use this framework
to show that Peng and Tang's ratio can be beaten, by designing a
0.7258-competitive algorithm. For the random order setting, we improve upon
Correa, Saona and Ziliotto's (SODA'19) 0.732-hardness result to show a hardness
of 0.7254 for general algorithms, thus establishing a separation between the
order selection and random order settings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bubna_A/0/1/0/all/0/1">Archit Bubna</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiplunkar_A/0/1/0/all/0/1">Ashish Chiplunkar</a></p><p>In the prophet inequality problem, a gambler faces a sequence of items
arriving online with values drawn independently from known distributions. On
seeing an item, the gambler must choose whether to accept its value as her
reward and quit the game, or reject it and continue. The gambler's aim is to
maximize her expected reward relative to the expected maximum of the values of
all items. Since the seminal work of Krengel and Sucheston (1977,1978), a tight
bound of 1/2 has been known for this competitive ratio in the setting where the
items arrive in an adversarial order. However, the optimum ratio still remains
unknown in the order selection setting, where the gambler selects the arrival
order, as well as in prophet secretary, where the items arrive in a random
order. Moreover, it is not even known whether a separation exists between the
two settings.
</p>
<p>In this paper, we show that the power of order selection allows the gambler
to guarantee a strictly better competitive ratio than if the items arrive
randomly. For the order selection setting, we identify an instance for which
Peng and Tang's (FOCS'22) state-of-the-art algorithm performs no better than
their claimed competitive ratio of (approximately) 0.7251, thus illustrating
the need for an improved approach. We therefore extend their design and provide
a more general algorithm design framework which allows the use of a different
time-dependent threshold function for each item, as opposed to the common
threshold function employed by Peng and Tang's algorithm. We use this framework
to show that Peng and Tang's ratio can be beaten, by designing a
0.7258-competitive algorithm. For the random order setting, we improve upon
Correa, Saona and Ziliotto's (SODA'19) 0.732-hardness result to show a hardness
of 0.7254 for general algorithms, thus establishing a separation between the
order selection and random order settings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04217'>Deterministic Incremental APSP with Polylogarithmic Update Time and Stretch</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sebastian Forster, Yasamin Nazari, Maximilian Probst Gutenberg</p><p>We provide the first deterministic data structure that given a weighted
undirected graph undergoing edge insertions, processes each update with
polylogarithmic amortized update time and answers queries for the distance
between any pair of vertices in the current graph with a polylogarithmic
approximation in $O(\log \log n)$ time.
</p>
<p>Prior to this work, no data structure was known for partially dynamic graphs,
i.e., graphs undergoing either edge insertions or deletions, with less than
$n^{o(1)}$ update time except for dense graphs, even when allowing
randomization against oblivious adversaries or considering only single-source
distances.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Forster_S/0/1/0/all/0/1">Sebastian Forster</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazari_Y/0/1/0/all/0/1">Yasamin Nazari</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutenberg_M/0/1/0/all/0/1">Maximilian Probst Gutenberg</a></p><p>We provide the first deterministic data structure that given a weighted
undirected graph undergoing edge insertions, processes each update with
polylogarithmic amortized update time and answers queries for the distance
between any pair of vertices in the current graph with a polylogarithmic
approximation in $O(\log \log n)$ time.
</p>
<p>Prior to this work, no data structure was known for partially dynamic graphs,
i.e., graphs undergoing either edge insertions or deletions, with less than
$n^{o(1)}$ update time except for dense graphs, even when allowing
randomization against oblivious adversaries or considering only single-source
distances.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04338'>Extracting and Pre-Processing Event Logs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dirk Fahland</p><p>Event data is the basis for all process mining analysis. Most process mining
techniques assume their input to be an event log. However, event data is rarely
recorded in an event log format, but has to be extracted from raw data. Event
log extraction itself is an act of modeling as the analyst has to consciously
choose which features of the raw data are used for describing which behavior of
which entities. Being aware of these choices and subtle but important
differences in concepts such as trace, case, activity, event, table, and log is
crucial for mastering advanced process mining analyses.
</p>
<p>This text provides fundamental concepts and formalizations and discusses
design decisions in event log extraction from a raw event table and for event
log pre-processing. It is intended as study material for an advanced lecture in
a process mining course.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fahland_D/0/1/0/all/0/1">Dirk Fahland</a></p><p>Event data is the basis for all process mining analysis. Most process mining
techniques assume their input to be an event log. However, event data is rarely
recorded in an event log format, but has to be extracted from raw data. Event
log extraction itself is an act of modeling as the analyst has to consciously
choose which features of the raw data are used for describing which behavior of
which entities. Being aware of these choices and subtle but important
differences in concepts such as trace, case, activity, event, table, and log is
crucial for mastering advanced process mining analyses.
</p>
<p>This text provides fundamental concepts and formalizations and discusses
design decisions in event log extraction from a raw event table and for event
log pre-processing. It is intended as study material for an advanced lecture in
a process mining course.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04402'>Summation Problem Revisited -- More Robust Computation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vaclav Skala</p><p>Numerical data processing is a key task across different fields of computer
technology use. However, even simple summation of values is not precise due to
the floating point representation use. This paper presents a practical
algorithm for summation of values convenient for medium and large data sets.
The proposed algorithm is simple, easy to implement. Its computational
complexity is O(N) in the contrary of the Exact Sign Summation Algorithm (ESSA)
approach with O(N^2) run-time complexity. The proposed algorithm is especially
convenient for cases when exponent data differ significantly and many small
values are summed with higher values
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Skala_V/0/1/0/all/0/1">Vaclav Skala</a></p><p>Numerical data processing is a key task across different fields of computer
technology use. However, even simple summation of values is not precise due to
the floating point representation use. This paper presents a practical
algorithm for summation of values convenient for medium and large data sets.
The proposed algorithm is simple, easy to implement. Its computational
complexity is O(N) in the contrary of the Exact Sign Summation Algorithm (ESSA)
approach with O(N^2) run-time complexity. The proposed algorithm is especially
convenient for cases when exponent data differ significantly and many small
values are summed with higher values
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04444'>A Local Search-Based Approach for Set Covering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anupam Gupta, Euiwoong Lee, Jason Li</p><p>In the Set Cover problem, we are given a set system with each set having a
weight, and we want to find a collection of sets that cover the universe,
whilst having low total weight. There are several approaches known (based on
greedy approaches, relax-and-round, and dual-fitting) that achieve a $H_k
\approx \ln k + O(1)$ approximation for this problem, where the size of each
set is bounded by $k$. Moreover, getting a $\ln k - O(\ln \ln k)$ approximation
is hard.
</p>
<p>Where does the truth lie? Can we close the gap between the upper and lower
bounds? An improvement would be particularly interesting for small values of
$k$, which are often used in reductions between Set Cover and other
combinatorial optimization problems.
</p>
<p>We consider a non-oblivious local-search approach: to the best of our
knowledge this gives the first $H_k$-approximation for Set Cover using an
approach based on local-search. Our proof fits in one page, and gives a
integrality gap result as well. Refining our approach by considering larger
moves and an optimized potential function gives an $(H_k - \Omega(\log^2
k)/k)$-approximation, improving on the previous bound of $(H_k -
\Omega(1/k^8))$ (\emph{R.\ Hassin and A.\ Levin, SICOMP '05}) based on a
modified greedy algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Anupam Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1">Euiwoong Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jason Li</a></p><p>In the Set Cover problem, we are given a set system with each set having a
weight, and we want to find a collection of sets that cover the universe,
whilst having low total weight. There are several approaches known (based on
greedy approaches, relax-and-round, and dual-fitting) that achieve a $H_k
\approx \ln k + O(1)$ approximation for this problem, where the size of each
set is bounded by $k$. Moreover, getting a $\ln k - O(\ln \ln k)$ approximation
is hard.
</p>
<p>Where does the truth lie? Can we close the gap between the upper and lower
bounds? An improvement would be particularly interesting for small values of
$k$, which are often used in reductions between Set Cover and other
combinatorial optimization problems.
</p>
<p>We consider a non-oblivious local-search approach: to the best of our
knowledge this gives the first $H_k$-approximation for Set Cover using an
approach based on local-search. Our proof fits in one page, and gives a
integrality gap result as well. Refining our approach by considering larger
moves and an optimized potential function gives an $(H_k - \Omega(\log^2
k)/k)$-approximation, improving on the previous bound of $(H_k -
\Omega(1/k^8))$ (\emph{R.\ Hassin and A.\ Levin, SICOMP '05}) based on a
modified greedy algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2211.04458'>Computing Square Colorings on Bounded-Treewidth and Planar Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Akanksha Agrawal, D&#xe1;niel Marx, Daniel Neuen, Jasper Slusallek</p><p>A square coloring of a graph $G$ is a coloring of the square $G^2$ of $G$,
that is, a coloring of the vertices of $G$ such that any two vertices that are
at distance at most $2$ in $G$ receive different colors. We investigate the
complexity of finding a square coloring with a given number of $q$ colors. We
show that the problem is polynomial-time solvable on graphs of bounded
treewidth by presenting an algorithm with running time $n^{2^{\operatorname{tw}
+ 4}+O(1)}$ for graphs of treewidth at most $\operatorname{tw}$. The somewhat
unusual exponent $2^{\operatorname{tw}}$ in the running time is essentially
optimal: we show that for any $\epsilon&gt;0$, there is no algorithm with running
time $f(\operatorname{tw})n^{(2-\epsilon)^{\operatorname{tw}}}$ unless the
Exponential-Time Hypothesis (ETH) fails.
</p>
<p>We also show that the square coloring problem is NP-hard on planar graphs for
any fixed number $q \ge 4$ of colors. Our main algorithmic result is showing
that the problem (when the number of colors $q$ is part of the input) can be
solved in subexponential time $2^{O(n^{2/3}\log n)}$ on planar graphs. The
result follows from the combination of two algorithms. If the number $q$ of
colors is small ($\le n^{1/3}$), then we can exploit a treewidth bound on the
square of the graph to solve the problem in time $2^{O(\sqrt{qn}\log n)}$. If
the number of colors is large ($\ge n^{1/3}$), then an algorithm based on
protrusion decompositions and building on our result for the bounded-treewidth
case solves the problem in time $2^{O(n\log n/q)}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Akanksha Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Marx_D/0/1/0/all/0/1">D&#xe1;niel Marx</a>, <a href="http://arxiv.org/find/cs/1/au:+Neuen_D/0/1/0/all/0/1">Daniel Neuen</a>, <a href="http://arxiv.org/find/cs/1/au:+Slusallek_J/0/1/0/all/0/1">Jasper Slusallek</a></p><p>A square coloring of a graph $G$ is a coloring of the square $G^2$ of $G$,
that is, a coloring of the vertices of $G$ such that any two vertices that are
at distance at most $2$ in $G$ receive different colors. We investigate the
complexity of finding a square coloring with a given number of $q$ colors. We
show that the problem is polynomial-time solvable on graphs of bounded
treewidth by presenting an algorithm with running time $n^{2^{\operatorname{tw}
+ 4}+O(1)}$ for graphs of treewidth at most $\operatorname{tw}$. The somewhat
unusual exponent $2^{\operatorname{tw}}$ in the running time is essentially
optimal: we show that for any $\epsilon&gt;0$, there is no algorithm with running
time $f(\operatorname{tw})n^{(2-\epsilon)^{\operatorname{tw}}}$ unless the
Exponential-Time Hypothesis (ETH) fails.
</p>
<p>We also show that the square coloring problem is NP-hard on planar graphs for
any fixed number $q \ge 4$ of colors. Our main algorithmic result is showing
that the problem (when the number of colors $q$ is part of the input) can be
solved in subexponential time $2^{O(n^{2/3}\log n)}$ on planar graphs. The
result follows from the combination of two algorithms. If the number $q$ of
colors is small ($\le n^{1/3}$), then we can exploit a treewidth bound on the
square of the graph to solve the problem in time $2^{O(\sqrt{qn}\log n)}$. If
the number of colors is large ($\ge n^{1/3}$), then an algorithm based on
protrusion decompositions and building on our result for the bounded-treewidth
case solves the problem in time $2^{O(n\log n/q)}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-09T01:30:00Z">Wednesday, November 09 2022, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, November 08
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/08/full-time-tenure-track-assistant-professor-position-in-theoretical-computing-science-at-department-of-computing-science-university-of-alberta-apply-by-january-15-2023/'>Full-Time Tenure-Track Assistant Professor Position in Theoretical Computing Science at Department of Computing Science, University of Alberta (apply by January 15, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We are looking for a tenure-track Assistant Professor in Theoretical Computing Science. Areas of interest include: Data structures and Algorithms Streaming, Sketching, and Big Data Algorithms Computational Complexity Algorithmic Economy/Game theory and Mechanism Design Approximation Algorithms Online Algorithms Discrete Optimization Theoretical Aspects of Parallel and Distributed Computing Website: www.careers.ualberta.ca/Competition/A104848950/ Email: cs.ea@ualberta.ca
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>We are looking for a tenure-track Assistant Professor in Theoretical Computing Science. Areas of interest include:</p>
<p>Data structures and Algorithms<br />
Streaming, Sketching, and Big Data Algorithms<br />
Computational Complexity<br />
Algorithmic Economy/Game theory and Mechanism Design<br />
Approximation Algorithms<br />
Online Algorithms<br />
Discrete Optimization<br />
Theoretical Aspects of Parallel and Distributed Computing</p>
<p>Website: <a href="https://www.careers.ualberta.ca/Competition/A104848950/">https://www.careers.ualberta.ca/Competition/A104848950/</a><br />
Email: cs.ea@ualberta.ca</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T22:26:24Z">Tuesday, November 08 2022, 22:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2022/11/08/faculty-at-george-mason-university-apply-by-december-2-2022/'>faculty at George Mason University (apply by December 2, 2022)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Department of Computer Science Multiple Open-Rank, Tenure-Track Faculty Positions The George Mason University Department of Computer Science, within the College of Engineering and Computing (CEC), invites applications for multiple tenure-track or tenured faculty positions beginning Fall 2023. Website: jobs.gmu.edu/postings/55808 Email: gordon@gmu.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Department of Computer Science<br />
Multiple Open-Rank, Tenure-Track Faculty Positions</p>
<p>The George Mason University Department of Computer Science, within the College of Engineering and Computing (CEC), invites applications for multiple tenure-track or tenured faculty positions beginning Fall 2023.</p>
<p>Website: <a href="https://jobs.gmu.edu/postings/55808">https://jobs.gmu.edu/postings/55808</a><br />
Email: gordon@gmu.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2022-11-08T19:44:58Z">Tuesday, November 08 2022, 19:44</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
