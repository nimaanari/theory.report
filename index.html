<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-02-17T04:37:09Z">Friday, February 17 2023, 04:37</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, February 17
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/17/postdoc-at-yale-university-apply-by-february-28-2023/'>Postdoc at Yale University (apply by February 28, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Applications are solicited for a postdoctoral position at Yale in the broad areas of Theoretical Computer Science, Optimization, or Machine Learning including (but not limited to) applications to Fairness and Privacy. Applicants should have an exceptional math background and a proven record. They should have their CV, research statement, and three letters emailed directly to [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Applications are solicited for a postdoctoral position at Yale in the broad areas of Theoretical Computer Science, Optimization, or Machine Learning including (but not limited to) applications to Fairness and Privacy. Applicants should have an exceptional math background and a proven record. They should have their CV, research statement, and three letters emailed directly to Nisheeth Vishnoi</p>
<p>Website: <a href="http://www.cs.yale.edu/homes/vishnoi/Home.html">http://www.cs.yale.edu/homes/vishnoi/Home.html</a><br />
Email: nisheeth.vishnoi@gmail.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-17T01:44:02Z">Friday, February 17 2023, 01:44</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.08083'>The Computational Complexity of Quantum Determinants</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shih-Han Hung, En-Jui Kuo</p><p>In this work, we study the computational complexity of quantum determinants,
a $q$-deformation of matrix permanents: Given a complex number $q$ on the unit
circle in the complex plane and an $n\times n$ matrix $X$, the $q$-permanent of
$X$ is defined as $$\mathrm{Per}_q(X) = \sum_{\sigma\in S_n}
q^{\ell(\sigma)}X_{1,\sigma(1)}\ldots X_{n,\sigma(n)},$$ where $\ell(\sigma)$
is the inversion number of permutation $\sigma$ in the symmetric group $S_n$ on
$n$ elements. The function family generalizes determinant and permanent, which
correspond to the cases $q=-1$ and $q=1$ respectively.
</p>
<p>For worst-case hardness, by Liouville's approximation theorem and facts from
algebraic number theory, we show that for primitive $m$-th root of unity $q$
for odd prime power $m=p^k$, exactly computing $q$-permanent is
$\mathsf{Mod}_p\mathsf{P}$-hard. This implies that an efficient algorithm for
computing $q$-permanent results in a collapse of the polynomial hierarchy.
Next, we show that computing $q$-permanent can be achieved using an oracle that
approximates to within a polynomial multiplicative error and a membership
oracle for a finite set of algebraic integers. From this, an efficient
approximation algorithm would also imply a collapse of the polynomial
hierarchy. By random self-reducibility, computing $q$-permanent remains to be
hard for a wide range of distributions satisfying a property called the strong
autocorrelation property. Specifically, this is proved via a reduction from
$1$-permanent to $q$-permanent for $O(1/n^2)$ points $z$ on the unit circle.
Since the family of permanent functions shares common algebraic structure,
various techniques developed for the hardness of permanent can be generalized
to $q$-permanents.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hung_S/0/1/0/all/0/1">Shih-Han Hung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_E/0/1/0/all/0/1">En-Jui Kuo</a></p><p>In this work, we study the computational complexity of quantum determinants,
a $q$-deformation of matrix permanents: Given a complex number $q$ on the unit
circle in the complex plane and an $n\times n$ matrix $X$, the $q$-permanent of
$X$ is defined as $$\mathrm{Per}_q(X) = \sum_{\sigma\in S_n}
q^{\ell(\sigma)}X_{1,\sigma(1)}\ldots X_{n,\sigma(n)},$$ where $\ell(\sigma)$
is the inversion number of permutation $\sigma$ in the symmetric group $S_n$ on
$n$ elements. The function family generalizes determinant and permanent, which
correspond to the cases $q=-1$ and $q=1$ respectively.
</p>
<p>For worst-case hardness, by Liouville's approximation theorem and facts from
algebraic number theory, we show that for primitive $m$-th root of unity $q$
for odd prime power $m=p^k$, exactly computing $q$-permanent is
$\mathsf{Mod}_p\mathsf{P}$-hard. This implies that an efficient algorithm for
computing $q$-permanent results in a collapse of the polynomial hierarchy.
Next, we show that computing $q$-permanent can be achieved using an oracle that
approximates to within a polynomial multiplicative error and a membership
oracle for a finite set of algebraic integers. From this, an efficient
approximation algorithm would also imply a collapse of the polynomial
hierarchy. By random self-reducibility, computing $q$-permanent remains to be
hard for a wide range of distributions satisfying a property called the strong
autocorrelation property. Specifically, this is proved via a reduction from
$1$-permanent to $q$-permanent for $O(1/n^2)$ points $z$ on the unit circle.
Since the family of permanent functions shares common algebraic structure,
various techniques developed for the hardness of permanent can be generalized
to $q$-permanents.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-17T01:30:00Z">Friday, February 17 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.08420'>The Complexity of Graph Exploration Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Janosch Fuchs, Christoph Gr&#xfc;ne, Tom Jan&#xdf;en</p><p>The graph exploration problem asks a searcher to explore an unknown graph.
This problem can be interpreted as the online version of the Traveling Salesman
Problem. The treasure hunt problem is the corresponding online version of the
shortest s-t-path problem. It asks the searcher to find a specific vertex in an
unknown graph at which a treasure is hidden.
</p>
<p>Recently, the analysis of the impact of a priori knowledge is of interest. In
graph problems, one form of a priori knowledge is a map of the graph. We survey
the graph exploration and treasure hunt problem with an unlabeled map, which is
an isomorphic copy of the graph, that is provided to the searcher. We formulate
decision variants of both problems by interpreting the online problems as a
game between the online algorithm (the searcher) and the adversary. The map,
however, is not controllable by the adversary. The question is, whether the
searcher is able to explore the graph fully or find the treasure for all
possible decisions of the adversary.
</p>
<p>We prove the PSPACE-completeness of these games, whereby we analyze the
variations which ask for the mere existence of a tour through the graph or path
to the treasure and the variations that include costs. Additionally, we analyze
the complexity of related problems that ask for a tour in the graph or a s-t
path.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fuchs_J/0/1/0/all/0/1">Janosch Fuchs</a>, <a href="http://arxiv.org/find/cs/1/au:+Grune_C/0/1/0/all/0/1">Christoph Gr&#xfc;ne</a>, <a href="http://arxiv.org/find/cs/1/au:+Janssen_T/0/1/0/all/0/1">Tom Jan&#xdf;en</a></p><p>The graph exploration problem asks a searcher to explore an unknown graph.
This problem can be interpreted as the online version of the Traveling Salesman
Problem. The treasure hunt problem is the corresponding online version of the
shortest s-t-path problem. It asks the searcher to find a specific vertex in an
unknown graph at which a treasure is hidden.
</p>
<p>Recently, the analysis of the impact of a priori knowledge is of interest. In
graph problems, one form of a priori knowledge is a map of the graph. We survey
the graph exploration and treasure hunt problem with an unlabeled map, which is
an isomorphic copy of the graph, that is provided to the searcher. We formulate
decision variants of both problems by interpreting the online problems as a
game between the online algorithm (the searcher) and the adversary. The map,
however, is not controllable by the adversary. The question is, whether the
searcher is able to explore the graph fully or find the treasure for all
possible decisions of the adversary.
</p>
<p>We prove the PSPACE-completeness of these games, whereby we analyze the
variations which ask for the mere existence of a tour through the graph or path
to the treasure and the variations that include costs. Additionally, we analyze
the complexity of related problems that ask for a tour in the graph or a s-t
path.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-17T01:30:00Z">Friday, February 17 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.08182'>Maximum Independent Set when excluding an induced minor: $K_1 + tK_2$ and $tC_3 \uplus C_4$</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: &#xc9;douard Bonnet, Julien Duron, Colin Geniet, St&#xe9;phan Thomass&#xe9;, Alexandra Wesolek</p><p>Dallard, Milani\v{c}, and \v{S}torgel [arXiv '22] ask if for every class
excluding a fixed planar graph $H$ as an induced minor, Maximum Independent Set
can be solved in polynomial time, and show that this is indeed the case when
$H$ is any planar complete bipartite graph, or the 5-vertex clique minus one
edge, or minus two disjoint edges. A positive answer would constitute a
far-reaching generalization of the state-of-the-art, when we currently do not
know if a polynomial-time algorithm exists when $H$ is the 7-vertex path.
Relaxing tractability to the existence of a quasipolynomial-time algorithm, we
know substantially more. Indeed, quasipolynomial-time algorithms were recently
obtained for the $t$-vertex cycle, $C_t$ [Gartland et al., STOC '21] and the
disjoint union of $t$ triangles, $tC_3$ [Bonamy et al., SODA '23].
</p>
<p>We give, for every integer $t$, a polynomial-time algorithm running in
$n^{O(t^5)}$ when $H$ is the friendship graph $K_1 + tK_2$ ($t$ disjoint edges
plus a vertex fully adjacent to them), and a quasipolynomial-time algorithm
running in $n^{O(t^2 \log n)+t^{O(1)}}$ when $H$ is $tC_3 \uplus C_4$ (the
disjoint union of $t$ triangles and a 4-vertex cycle). The former extends a
classical result on graphs excluding $tK_2$ as an induced subgraph [Alekseev,
DAM '07], while the latter extends Bonamy et al.'s result.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1">&#xc9;douard Bonnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Duron_J/0/1/0/all/0/1">Julien Duron</a>, <a href="http://arxiv.org/find/cs/1/au:+Geniet_C/0/1/0/all/0/1">Colin Geniet</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomasse_S/0/1/0/all/0/1">St&#xe9;phan Thomass&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Wesolek_A/0/1/0/all/0/1">Alexandra Wesolek</a></p><p>Dallard, Milani\v{c}, and \v{S}torgel [arXiv '22] ask if for every class
excluding a fixed planar graph $H$ as an induced minor, Maximum Independent Set
can be solved in polynomial time, and show that this is indeed the case when
$H$ is any planar complete bipartite graph, or the 5-vertex clique minus one
edge, or minus two disjoint edges. A positive answer would constitute a
far-reaching generalization of the state-of-the-art, when we currently do not
know if a polynomial-time algorithm exists when $H$ is the 7-vertex path.
Relaxing tractability to the existence of a quasipolynomial-time algorithm, we
know substantially more. Indeed, quasipolynomial-time algorithms were recently
obtained for the $t$-vertex cycle, $C_t$ [Gartland et al., STOC '21] and the
disjoint union of $t$ triangles, $tC_3$ [Bonamy et al., SODA '23].
</p>
<p>We give, for every integer $t$, a polynomial-time algorithm running in
$n^{O(t^5)}$ when $H$ is the friendship graph $K_1 + tK_2$ ($t$ disjoint edges
plus a vertex fully adjacent to them), and a quasipolynomial-time algorithm
running in $n^{O(t^2 \log n)+t^{O(1)}}$ when $H$ is $tC_3 \uplus C_4$ (the
disjoint union of $t$ triangles and a 4-vertex cycle). The former extends a
classical result on graphs excluding $tK_2$ as an induced subgraph [Alekseev,
DAM '07], while the latter extends Bonamy et al.'s result.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-17T01:30:00Z">Friday, February 17 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.08234'>Sample-Based Online Generalized Assignment Problem with Unknown Poisson Arrivals</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zihao Li, Hao Wang, Zhenzhen Yan</p><p>We study an edge-weighted online stochastic \emph{Generalized Assignment
Problem} with \emph{unknown} Poisson arrivals. In this model, we consider a
bipartite graph that contains offline bins and online items, where each offline
bin is associated with a $D$-dimensional capacity vector and each online item
is with a $D$-dimensional demand vector. Online arrivals are sampled from a set
of online item types which follow independent but not necessarily identical
Poisson processes. The arrival rate for each Poisson process is unknown. Each
online item will either be packed into an offline bin which will deduct the
allocated bin's capacity vector and generate a reward, or be rejected. The
decision should be made immediately and irrevocably upon its arrival. Our goal
is to maximize the total reward of the allocation without violating the
capacity constraints.
</p>
<p>We provide a sample-based multi-phase algorithm by utilizing both
pre-existing offline data (named historical data) and sequentially revealed
online data. We establish its performance guarantee measured by a competitive
ratio. In a simplified setting where $D=1$ and all capacities and demands are
equal to $1$, we prove that the ratio depends on the number of historical data
size and the minimum number of arrivals for each online item type during the
planning horizon, from which we analyze the effect of the historical data size
and the Poisson arrival model on the algorithm's performance. We further
generalize the algorithm to the general multidimensional and multi-demand
setting, and present its parametric performance guarantee. The effect of the
capacity's (demand's) dimension on the algorithm's performance is further
analyzed based on the established parametric form. Finally, we demonstrate the
effectiveness of our algorithms numerically.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zihao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhenzhen Yan</a></p><p>We study an edge-weighted online stochastic \emph{Generalized Assignment
Problem} with \emph{unknown} Poisson arrivals. In this model, we consider a
bipartite graph that contains offline bins and online items, where each offline
bin is associated with a $D$-dimensional capacity vector and each online item
is with a $D$-dimensional demand vector. Online arrivals are sampled from a set
of online item types which follow independent but not necessarily identical
Poisson processes. The arrival rate for each Poisson process is unknown. Each
online item will either be packed into an offline bin which will deduct the
allocated bin's capacity vector and generate a reward, or be rejected. The
decision should be made immediately and irrevocably upon its arrival. Our goal
is to maximize the total reward of the allocation without violating the
capacity constraints.
</p>
<p>We provide a sample-based multi-phase algorithm by utilizing both
pre-existing offline data (named historical data) and sequentially revealed
online data. We establish its performance guarantee measured by a competitive
ratio. In a simplified setting where $D=1$ and all capacities and demands are
equal to $1$, we prove that the ratio depends on the number of historical data
size and the minimum number of arrivals for each online item type during the
planning horizon, from which we analyze the effect of the historical data size
and the Poisson arrival model on the algorithm's performance. We further
generalize the algorithm to the general multidimensional and multi-demand
setting, and present its parametric performance guarantee. The effect of the
capacity's (demand's) dimension on the algorithm's performance is further
analyzed based on the established parametric form. Finally, we demonstrate the
effectiveness of our algorithms numerically.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-17T01:30:00Z">Friday, February 17 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.08432'>Incremental $(1-\epsilon)$-approximate dynamic matching in $O(poly(1/\epsilon))$ update time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Joakim Blikstad, Peter Kiss</p><p>In the dynamic approximate maximum bipartite matching problem we are given
bipartite graph $G$ undergoing updates and our goal is to maintain a matching
of $G$ which is large compared the maximum matching size $\mu(G)$. We define a
dynamic matching algorithm to be $\alpha$ (respectively $(\alpha,
\beta)$)-approximate if it maintains matching $M$ such that at all times $|M |
\geq \mu(G) \cdot \alpha$ (respectively $|M| \geq \mu(G) \cdot \alpha -
\beta$).
</p>
<p>We present the first deterministic $(1-\epsilon )$-approximate dynamic
matching algorithm with $O(poly(\epsilon ^{-1}))$ amortized update time for
graphs undergoing edge insertions. Previous solutions either required
super-constant [Gupta FSTTCS'14, Bhattacharya-Kiss-Saranurak SODA'23] or
exponential in $1/\epsilon $
[Grandoni-Leonardi-Sankowski-Schwiegelshohn-Solomon SODA'19] update time. Our
implementation is arguably simpler than the mentioned algorithms and its
description is self contained. Moreover, we show that if we allow for additive
$(1, \epsilon \cdot n)$-approximation our algorithm seamlessly extends to also
handle vertex deletions, on top of edge insertions. This makes our algorithm
one of the few small update time algorithms for $(1-\epsilon )$-approximate
dynamic matching allowing for updates both increasing and decreasing the
maximum matching size of $G$ in a fully dynamic manner.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blikstad_J/0/1/0/all/0/1">Joakim Blikstad</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiss_P/0/1/0/all/0/1">Peter Kiss</a></p><p>In the dynamic approximate maximum bipartite matching problem we are given
bipartite graph $G$ undergoing updates and our goal is to maintain a matching
of $G$ which is large compared the maximum matching size $\mu(G)$. We define a
dynamic matching algorithm to be $\alpha$ (respectively $(\alpha,
\beta)$)-approximate if it maintains matching $M$ such that at all times $|M |
\geq \mu(G) \cdot \alpha$ (respectively $|M| \geq \mu(G) \cdot \alpha -
\beta$).
</p>
<p>We present the first deterministic $(1-\epsilon )$-approximate dynamic
matching algorithm with $O(poly(\epsilon ^{-1}))$ amortized update time for
graphs undergoing edge insertions. Previous solutions either required
super-constant [Gupta FSTTCS'14, Bhattacharya-Kiss-Saranurak SODA'23] or
exponential in $1/\epsilon $
[Grandoni-Leonardi-Sankowski-Schwiegelshohn-Solomon SODA'19] update time. Our
implementation is arguably simpler than the mentioned algorithms and its
description is self contained. Moreover, we show that if we allow for additive
$(1, \epsilon \cdot n)$-approximation our algorithm seamlessly extends to also
handle vertex deletions, on top of edge insertions. This makes our algorithm
one of the few small update time algorithms for $(1-\epsilon )$-approximate
dynamic matching allowing for updates both increasing and decreasing the
maximum matching size of $G$ in a fully dynamic manner.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-17T01:30:00Z">Friday, February 17 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.08507'>The Scope of Multicalibration: Characterizing Multicalibration via Property Elicitation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Georgy Noarov, Aaron Roth</p><p>We make a connection between multicalibration and property elicitation and
show that (under mild technical conditions) it is possible to produce a
multicalibrated predictor for a continuous scalar distributional property
$\Gamma$ if and only if $\Gamma$ is elicitable.
</p>
<p>On the negative side, we show that for non-elicitable continuous properties
there exist simple data distributions on which even the true distributional
predictor is not calibrated. On the positive side, for elicitable $\Gamma$, we
give simple canonical algorithms for the batch and the online adversarial
setting, that learn a $\Gamma$-multicalibrated predictor. This generalizes past
work on multicalibrated means and quantiles, and in fact strengthens existing
online quantile multicalibration results.
</p>
<p>To further counter-weigh our negative result, we show that if a property
$\Gamma^1$ is not elicitable by itself, but is elicitable conditionally on
another elicitable property $\Gamma^0$, then there is a canonical algorithm
that jointly multicalibrates $\Gamma^1$ and $\Gamma^0$; this generalizes past
work on mean-moment multicalibration.
</p>
<p>Finally, as applications of our theory, we provide novel algorithmic and
impossibility results for fair (multicalibrated) risk assessment.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Noarov_G/0/1/0/all/0/1">Georgy Noarov</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1">Aaron Roth</a></p><p>We make a connection between multicalibration and property elicitation and
show that (under mild technical conditions) it is possible to produce a
multicalibrated predictor for a continuous scalar distributional property
$\Gamma$ if and only if $\Gamma$ is elicitable.
</p>
<p>On the negative side, we show that for non-elicitable continuous properties
there exist simple data distributions on which even the true distributional
predictor is not calibrated. On the positive side, for elicitable $\Gamma$, we
give simple canonical algorithms for the batch and the online adversarial
setting, that learn a $\Gamma$-multicalibrated predictor. This generalizes past
work on multicalibrated means and quantiles, and in fact strengthens existing
online quantile multicalibration results.
</p>
<p>To further counter-weigh our negative result, we show that if a property
$\Gamma^1$ is not elicitable by itself, but is elicitable conditionally on
another elicitable property $\Gamma^0$, then there is a canonical algorithm
that jointly multicalibrates $\Gamma^1$ and $\Gamma^0$; this generalizes past
work on mean-moment multicalibration.
</p>
<p>Finally, as applications of our theory, we provide novel algorithmic and
impossibility results for fair (multicalibrated) risk assessment.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-17T01:30:00Z">Friday, February 17 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, February 16
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/012'>TR23-012 |  Linear threshold functions in decision lists, decision trees, and depth-2 circuits | 

	Yogesh Dahiya, 

	Vignesh K, 

	Meena Mahajan, 

	Karteek Sreenivasaiah</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We show that polynomial-size constant-rank linear decision trees (LDTs) can be converted to polynomial-size depth-2 threshold circuits LTF$\circ$LTF. An intermediate construct is polynomial-size decision lists that query a conjunction of a constant number of linear threshold functions (LTFs); we show that these are equivalent to polynomial-size exact linear decision lists (ELDLs) i.e. decision lists querying exact threshold functions (ELTFs).
        
        </div>

        <div class='tr-article-summary'>
        
          
          We show that polynomial-size constant-rank linear decision trees (LDTs) can be converted to polynomial-size depth-2 threshold circuits LTF$\circ$LTF. An intermediate construct is polynomial-size decision lists that query a conjunction of a constant number of linear threshold functions (LTFs); we show that these are equivalent to polynomial-size exact linear decision lists (ELDLs) i.e. decision lists querying exact threshold functions (ELTFs).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T17:40:03Z">Thursday, February 16 2023, 17:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/blurry-jpeg-or-frozen-concentrate.html'>Blurry JPEG or Frozen Concentrate</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <br>♦<br>Ted Chiang in a recent New Yorker article&nbsp;likened ChatGPT to a blurry JPEG, i.e. a "lossy compression" of the web. It's a good article but the analogy isn't quite right, there's a different kind of compression happening. Think of all human written knowledge as a random example of what could have been generated and we remove the randomness, like water is removed to make concentrated orange juice. We then add water (or randomness) to get back some version of the original.&nbsp;<p>Lossless compression, like gzip, gives a compressed version of some data with the ability to reconstruct it exactly. It corresponds nicely to Kolmogorov complexity where K(x) is the smallest program p that generates the string x. p is a lossless compression of x.</p><p>Lossy compression, like JPEG, often allows much higher compression but with some error. In Kolmogorov terms you are trading off the size of the program p and some error function between x and the output of p. Most compression programs for pictures, music and video use algorithms designed for the specific medium. You can also use machine learning to get lossy compression by training both the compression and decompression algorithms.</p><p>Lossy compression tries to recreate the original picture. Generative AI, like ChatGPT, takes a different approach. Let's consider Wikipedia as this is the example used by Chiang. For any specific topic, there are many different ways to write a Wikipedia article, as good as or better than the article that currently exists. ChatGPT doesn't need to recreate anything close to the original article, just one that explains topic well. What we want is a description of a program p that corresponds to a set of possible Wikipedia articles, of which the real article is a random example of this set. An ideal version of ChatGPT would choose a random article from this set. Dall-E, generative AI for art, works a similar way, creating art that is a random example of what art might have been.&nbsp;</p><p>In terms of Kolmogorov complexity, this corresponds to the Kolmogorov Structure Function, basically the smallest program p such that p describes a set S of size m that contains x. with |p| + log m ≈ K(x). The string x is just a random element of S, you can get a string like it by picking an element of S at random.</p><p>There is no recursive algorithm that will find p and we also need to limit ourselves to p that are computationally efficient, which means that generative AI algorithms may never be ideal and will sometimes make mistakes. That doesn't mean we shouldn't use them just that we need to be wary of their limitations. As the saying goes "All models are wrong, but some are useful".</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <br /><div class="separator" style="clear: both; text-align: center;"><div style="text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjFWYEsU8iLa-qrh1JXkPsV0W4SvWaTRKsYl4N-8t3kLiJUjTRwoWKvNjYslR7cpPiXeMad1g5X-Vc-W9qNFUFpLkmsEsZkyM02kFcFxznkqvzrfp9oQCJQccOg0MwLL15ApWYl4txJrFsxSa_alw1jZA4qRcYIc0QMggk6O2wdPRdyHESCPw/s1327/s-l1600.jpg"><img border="0" data-original-height="742" data-original-width="1327" height="179" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjFWYEsU8iLa-qrh1JXkPsV0W4SvWaTRKsYl4N-8t3kLiJUjTRwoWKvNjYslR7cpPiXeMad1g5X-Vc-W9qNFUFpLkmsEsZkyM02kFcFxznkqvzrfp9oQCJQccOg0MwLL15ApWYl4txJrFsxSa_alw1jZA4qRcYIc0QMggk6O2wdPRdyHESCPw/s320/s-l1600.jpg" width="320" /></a></div><br /></div>Ted Chiang in a recent <a href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web">New Yorker article</a>&nbsp;likened ChatGPT to a blurry JPEG, i.e. a "lossy compression" of the web. It's a good article but the analogy isn't quite right, there's a different kind of compression happening. Think of all human written knowledge as a random example of what could have been generated and we remove the randomness, like water is removed to make concentrated orange juice. We then add water (or randomness) to get back some version of the original.&nbsp;<p>Lossless compression, like gzip, gives a compressed version of some data with the ability to reconstruct it exactly. It corresponds nicely to Kolmogorov complexity where K(x) is the smallest program p that generates the string x. p is a lossless compression of x.</p><p>Lossy compression, like JPEG, often allows much higher compression but with some error. In Kolmogorov terms you are trading off the size of the program p and some error function between x and the output of p. Most compression programs for pictures, music and video use algorithms designed for the specific medium. You can also use machine learning to get lossy compression by training both the compression and decompression algorithms.</p><p>Lossy compression tries to recreate the original picture. Generative AI, like ChatGPT, takes a different approach. Let's consider Wikipedia as this is the example used by Chiang. For any specific topic, there are many different ways to write a Wikipedia article, as good as or better than the article that currently exists. ChatGPT doesn't need to recreate anything close to the original article, just one that explains topic well. What we want is a description of a program p that corresponds to a set of possible Wikipedia articles, of which the real article is a random example of this set. An ideal version of ChatGPT would choose a random article from this set. Dall-E, generative AI for art, works a similar way, creating art that is a random example of what art might have been.&nbsp;</p><p>In terms of Kolmogorov complexity, this corresponds to the <a href="https://doi-org.ezproxy.gl.iit.edu/10.1109/SFCS.2002.1182000">Kolmogorov Structure Function</a>, basically the smallest program p such that p describes a set S of size m that contains x. with |p| + log m ≈ K(x). The string x is just a random element of S, you can get a string like it by picking an element of S at random.</p><p>There is no recursive algorithm that will find p and we also need to limit ourselves to p that are computationally efficient, which means that generative AI algorithms may never be ideal and will sometimes make mistakes. That doesn't mean we shouldn't use them just that we need to be wary of their limitations. As the <a href="https://en.wikipedia.org/wiki/All_models_are_wrong">saying</a> goes "All models are wrong, but some are useful".</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T15:19:00Z">Thursday, February 16 2023, 15:19</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7032'>Statement of Jewish scientists opposing the &#8220;judicial reform&#8221; in Israel</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Today, Dana and I unhesitatingly join a group of Jewish scientists around the world (see the full current list of signatories here, including Ed Witten, Steven Pinker, Manuel Blum, Shafi Goldwasser, Judea Pearl, Lenny Susskind, and several hundred more) who&#8217;ve released the following statement: As Jewish scientists within the global science community, we have all [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Today, Dana and I unhesitatingly join a group of Jewish scientists around the world (<a href="https://sites.google.com/view/scientistsletter/signatories">see the full current list of signatories here</a>, including Ed Witten, Steven Pinker, Manuel Blum, Shafi Goldwasser, Judea Pearl, Lenny Susskind, and several hundred more) who&#8217;ve <a href="https://sites.google.com/view/scientistsletter/statement">released the following statement</a>:</p>



<blockquote class="wp-block-quote">
<p>As Jewish scientists within the global science community, we have all felt great satisfaction and taken pride in Israel’s many remarkable accomplishments.  We support and value the State of Israel, its pluralistic society, and its vibrant culture.  Many of us have friends, family, and scientific collaborators in Israel, and have visited often.  The strong connections we feel are based both on our collective Jewish identity as well as on our shared values of democracy, pluralism, and human rights. We support Israel’s right to live in peace among its neighbors. Many of us have stood firmly against calls for boycotts of Israeli academic institutions.</p>



<p>Our support of Israel now compels us to speak up vigorously against incipient changes to Israel&#8217;s core governmental structure, as put forward by Justice Minister Levin, that will eviscerate Israel&#8217;s judiciary and impede its critical oversight function.&nbsp; Such imbalance and unchecked authority invite corruption and abuse, and stifle the healthy interplay of core state institutions.&nbsp; History has shown that this leads to oppression of the defenseless and the abrogation of human rights.&nbsp; Along with hundreds of thousands of Israeli citizens who have taken to the streets in protest, we call upon the Israeli government to step back from this precipice and retract the proposed legislation.</p>



<p>Science today is driven by collaborations which bring together scholars of diverse backgrounds from across the globe. Funding, communication and cooperation on an international scale are essential aspects of the modern scientific enterprise, hence our extended community regards pluralism, secular and broad education, protection of rights for women and minorities, and societal stability guaranteed by the rule of law as non-negotiable virtues.&nbsp; The consequences of Israel abandoning any of these essential principles would surely be grave, and would provoke a rift with the international scientific community.&nbsp; In addition to significantly increasing the threat of academic, trade, and diplomatic boycotts, Israel risks a “brain drain” of its best scientists and engineers. It takes decades to establish scientific and academic excellence, but only a moment to destroy them. We fear that the unprecedented erosion of judiciary independence in Israel will set back the Israeli scientific enterprise for generations to come.</p>



<p>Our Jewish heritage forcefully emphasizes both justice and jurisprudence. Israel must endeavor to serve as a “light unto the nations,” by steadfastly holding to core democratic values – so clearly expressed in its own Declaration of Independence – which protect and nurture all of Israel’s inhabitants and which justify its membership in the community of democratic nations.</p>



<p></p>
</blockquote>



<p>Those unaware of what&#8217;s happening in Israel can read about it <a href="https://en.wikipedia.org/wiki/2023_Israeli_judicial_reform">here</a>.  If you don&#8217;t want to wade through the details, suffice it say that all seven living former Attorneys General of Israel, including those appointed by Netanyahu himself, strongly oppose the &#8220;judicial reforms.&#8221;  The president of Israel&#8217;s Bar Association says that &#8220;this war is the most important we&#8217;ve had in the country&#8217;s 75 years of existence&#8221; and calls on all Israelis to take to the streets.  Even Alan Dershowitz, controversial author of <em>The Case for Israel</em>, says he&#8217;d do the same if there.  It&#8217;s hard to find <em>any</em> thoughtful person, of any political persuasion, who sees this act as anything other than the naked and illiberal power grab that it is.</p>



<p>Though I endorse every word of the scientists&#8217; statement above, maybe I&#8217;ll add a few words of my own.</p>



<p>Jewish scientists of the early 20th century, reacting against the discrimination they faced in Europe, were heavily involved in the creation of the State of Israel.  The most notable were Einstein (of course), who helped found the Hebrew University of Jerusalem, and Einstein&#8217;s friend <a href="https://en.wikipedia.org/wiki/Chaim_Weizmann">Chaim Weizmann</a>, founder of the <a href="https://en.wikipedia.org/wiki/Weizmann_Institute_of_Science">Weizmann Institute of Science</a>, where Dana studied.  In Theodor Herzl&#8217;s 1902 novel <em><a href="https://en.wikipedia.org/wiki/The_Old_New_Land">Altneuland</a></em> (<a href="https://www.jewishvirtuallibrary.org/quot-altneuland-quot-theodor-herzl">full text</a>)&#8212;remarkable as one of history&#8217;s few pieces of utopian fiction to serve later as a (semi-)successful blueprint for reality&#8212;Herzl imagines the future democratic, pluralistic Israel welcoming a steamship full of the world&#8217;s great scientists and intellectuals, who come to witness the new state&#8217;s accomplishments in science and engineering and agriculture.  But, you see, this only happens after a climactic scene in Israel&#8217;s parliament, in which the supporters of liberalism and Enlightenment defeat a reactionary faction that wants Israel to become a Jewish theocracy that excludes Arabs and other non-Jews.</p>



<p>Today, despite all the tragedies and triumphs of the intervening 120 years that Herzl couldn&#8217;t have foreseen, it&#8217;s clear that the climactic conflict of <em>Altneuland</em> is playing out for real.  This time, alas, the supporters (just barely) lack the votes in the Knesset.  Through sheer numerical force, Netanyahu almost certainly <em>will</em> push through the power to dismiss judges and rulings he doesn&#8217;t like, and thereafter rule by decree like Hungary&#8217;s Orban or Turkey&#8217;s Erdogan.  He will use this power to trample minority rights, give free rein to the craziest West Bank settlers, and shield himself and his ministers from accountability for their breathtaking corruption.  And then, perhaps, Israel&#8217;s Supreme Court will strike down Netanyahu&#8217;s power grab as contrary to &#8220;Basic Law,&#8221; and then the Netanyahu coalition will strike down the Supreme Court&#8217;s action, and in a country that still lacks a constitution, it&#8217;s unclear how such an impasse could be resolved except through violence and thuggery.  And thus Netanyahu, who calls himself &#8220;the protector of Israel,&#8221; will go down in history as the destroyer of the Israel that the founders envisioned.</p>



<p>Einstein and Weizmann have been gone for 70 years.  Maybe no one like them still exists.  So it falls to the Jewish scientists of today, inadequate though they are, to say what Einstein and Weizmann, and Herzl and Ben-Gurion, would&#8217;ve said about the current proceedings had they been alive.  Any other Jewish scientist who agrees should <a href="https://sites.google.com/view/scientistsletter/sign-the-statement">sign our statement here</a>.  Of course, those living in Israel should join our many friends there on the streets!  And, while this is our special moral responsibility&#8212;maybe, with 1% probability, some wavering Knesset member actually cares what we think?&#8212;I hope and trust that other statements will be organized that are open to Gentiles and non-scientists and anyone concerned about Israel&#8217;s future.</p>



<p>As a lifelong Zionist, <em>this is not what I signed up for</em>.  If Netanyahu succeeds in his plan to gut Israel&#8217;s judiciary and end the state&#8217;s pluralistic and liberal-democratic character, then I&#8217;ll continue to support the Israel that once existed and that might, we hope, someday exist again.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T10:00:00Z">Thursday, February 16 2023, 10:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/02/15/tcs-talk-wednesday-february-22-jinyoung-park-nyu-courant-institute/'>TCS+ talk: Wednesday, February 22 — Jinyoung Park, NYU/Courant Institute</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, February 22th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Jinyoung Park from NYU/Courant Institute will speak about &#8220;Thresholds&#8221; (abstract below). You can reserve a spot as an individual or a group to join us live by signing [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, February 22th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Jinyoung Park</strong> from NYU/Courant Institute will speak about &#8220;<em>Thresholds</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: For a finite set <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" />, a family <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{F}" class="latex" /> of subsets of <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> is said to be increasing if any set <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> that contains <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{F}" class="latex" /> is also in <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{F}" class="latex" />. The <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />-biased product measure of <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathcal{F}" class="latex" /> increases as <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> increases from 0 to 1, and often exhibits a drastic change around a specific value, which is called a &#8220;threshold.&#8221; Thresholds of increasing families have been of great historical interest and a central focus of the study of random discrete structures (e.g. random graphs and hypergraphs), with estimation of thresholds for specific properties the subject of some of the most challenging work in the area. In 2006, Jeff Kahn and Gil Kalai conjectured that a natural (and often easy to calculate) lower bound <img src="https://s0.wp.com/latex.php?latex=q%28%5Cmathcal%7BF%7D%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q%28%5Cmathcal%7BF%7D%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%28%5Cmathcal%7BF%7D%29&#038;bg=fff&#038;fg=444444&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q(&#92;mathcal{F})" class="latex" /> (which we refer to as the “expectation-threshold”) for the threshold is in fact never far from its actual value. A positive answer to this conjecture enables one to narrow down the location of thresholds for any increasing properties in a tiny window. In particular, this easily implies several previously very difficult results in probabilistic combinatorics such as thresholds for perfect hypergraph matchings (Johansson–Kahn–Vu) and bounded-degree spanning trees (Montgomery). In this talk, I will present recent progress on this topic.</p>
<p>Based on joint work with Keith Frankston, Jeff Kahn, Bhargav Narayanan, and Huy Tuan Pham.</p></blockquote>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T03:34:16Z">Thursday, February 16 2023, 03:34</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07326'>Characterisation of the Set of Ground States of Uniformly Chaotic Finite-Range Lattice Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: L&#xe9;o Gayral, Mathieu Sablik, Siamak Taati</p><p>Chaotic dependence on temperature refers to the phenomenon of divergence of
Gibbs measures as the temperature approaches a certain value. Models with
chaotic behaviour near zero temperature have multiple ground states, none of
which are stable. We study the class of uniformly chaotic models, that is,
those in which, as the temperature goes to zero, every choice of Gibbs measures
accumulates on the entire set of ground states. We characterise the possible
sets of ground states of uniformly chaotic finite-range models up to computable
homeomorphisms.
</p>
<p>Namely, we show that the set of ground states of every model with
finite-range and rational-valued interactions is topologically closed and
connected, and belongs to the class $\Pi_2$ of the arithmetical hierarchy.
Conversely, every $\Pi_2$-computable, topologically closed and connected set of
probability measures can be encoded (via a computable homeomorphism) as the set
of ground states of a uniformly chaotic two-dimensional model with finite-range
rational-valued interactions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math-ph/1/au:+Gayral_L/0/1/0/all/0/1">L&#xe9;o Gayral</a>, <a href="http://arxiv.org/find/math-ph/1/au:+Sablik_M/0/1/0/all/0/1">Mathieu Sablik</a>, <a href="http://arxiv.org/find/math-ph/1/au:+Taati_S/0/1/0/all/0/1">Siamak Taati</a></p><p>Chaotic dependence on temperature refers to the phenomenon of divergence of
Gibbs measures as the temperature approaches a certain value. Models with
chaotic behaviour near zero temperature have multiple ground states, none of
which are stable. We study the class of uniformly chaotic models, that is,
those in which, as the temperature goes to zero, every choice of Gibbs measures
accumulates on the entire set of ground states. We characterise the possible
sets of ground states of uniformly chaotic finite-range models up to computable
homeomorphisms.
</p>
<p>Namely, we show that the set of ground states of every model with
finite-range and rational-valued interactions is topologically closed and
connected, and belongs to the class $\Pi_2$ of the arithmetical hierarchy.
Conversely, every $\Pi_2$-computable, topologically closed and connected set of
probability measures can be encoded (via a computable homeomorphism) as the set
of ground states of a uniformly chaotic two-dimensional model with finite-range
rational-valued interactions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07409'>Quantum Learning Theory Beyond Batch Binary Classification</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Preetham Mohan, Ambuj Tewari</p><p>Arunachalam and De Wolf (2018) showed that the sample complexity of quantum
batch learning of boolean functions, in the realizable and agnostic settings,
has the same form and order as the corresponding classical sample complexities.
In this paper, we extend this, ostensibly surprising, message to batch
multiclass learning, online boolean learning, and online multiclass learning.
For our online learning results, we first consider an adaptive adversary
variant of the classical model of Dawid and Tewari (2022). Then, we introduce
the first (to the best of our knowledge) model of online learning with quantum
examples.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mohan_P/0/1/0/all/0/1">Preetham Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tewari_A/0/1/0/all/0/1">Ambuj Tewari</a></p><p>Arunachalam and De Wolf (2018) showed that the sample complexity of quantum
batch learning of boolean functions, in the realizable and agnostic settings,
has the same form and order as the corresponding classical sample complexities.
In this paper, we extend this, ostensibly surprising, message to batch
multiclass learning, online boolean learning, and online multiclass learning.
For our online learning results, we first consider an adaptive adversary
variant of the classical model of Dawid and Tewari (2022). Then, we introduce
the first (to the best of our knowledge) model of online learning with quantum
examples.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07649'>A Complication for the Many Worlds Theory</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Samuel Epstein</p><p>The Many Worlds Theory and the Independence Postulate are in conflict, as
shown through the existence of a finite experiment that measures the spin of a
large number of electrons. After the experiment there are branches of positive
probability which contain forbidden sequences that break the Independence
Postulate.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1">Samuel Epstein</a></p><p>The Many Worlds Theory and the Independence Postulate are in conflict, as
shown through the existence of a finite experiment that measures the spin of a
large number of electrons. After the experiment there are branches of positive
probability which contain forbidden sequences that break the Independence
Postulate.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07423'>Two-sided convexity testing with certificates</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adrian Dumitrescu</p><p>We revisit the problem of property testing for convex position for point sets
in $\mathbb{R}^d$. Our results draw from previous ideas of Czumaj, Sohler, and
Ziegler (ESA 2000). First, the algorithm is redesigned and its analysis is
revised for correctness. Second, its functionality is expanded by
(i)~exhibiting both negative and positive certificates along with the convexity
determination, and (ii)~significantly extending the input range for moderate
and higher dimensions. The behavior of the randomized tester is as follows:
(i)~if $P$ is in convex position, it accepts; (ii)~if $P$ is far from convex
position, with probability at least $2/3$, it rejects and outputs a
$(d+2)$-point witness of non-convexity as a negative certificate; (iiii)~if $P$
is close to convex position, with probability at least $2/3$, it accepts and
outputs an approximation of the largest subset in convex position. The
algorithm examines a sublinear number of points and runs in subquadratic time
for every dimension $d$ (and is faster in low dimensions).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dumitrescu_A/0/1/0/all/0/1">Adrian Dumitrescu</a></p><p>We revisit the problem of property testing for convex position for point sets
in $\mathbb{R}^d$. Our results draw from previous ideas of Czumaj, Sohler, and
Ziegler (ESA 2000). First, the algorithm is redesigned and its analysis is
revised for correctness. Second, its functionality is expanded by
(i)~exhibiting both negative and positive certificates along with the convexity
determination, and (ii)~significantly extending the input range for moderate
and higher dimensions. The behavior of the randomized tester is as follows:
(i)~if $P$ is in convex position, it accepts; (ii)~if $P$ is far from convex
position, with probability at least $2/3$, it rejects and outputs a
$(d+2)$-point witness of non-convexity as a negative certificate; (iiii)~if $P$
is close to convex position, with probability at least $2/3$, it accepts and
outputs an approximation of the largest subset in convex position. The
algorithm examines a sublinear number of points and runs in subquadratic time
for every dimension $d$ (and is faster in low dimensions).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07747'>Polar Zonohedra Edge-Unfold to Nets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Joseph O&#x27;Rourke</p><p>This note proves that every polar zonohedron has an edge-unfolding to a
non-overlapping net.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+ORourke_J/0/1/0/all/0/1">Joseph O&#x27;Rourke</a></p><p>This note proves that every polar zonohedron has an edge-unfolding to a
non-overlapping net.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07768'>Combinatorial Depth Measures for Hyperplane Arrangements</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Patrick Schnider, Pablo Sober&#xf3;n</p><p>Regression depth, introduced by Rousseeuw and Hubert in 1999, is a notion
that measures how good of a regression hyperplane a given query hyperplane is
with respect to a set of data points. Under projective duality, this can be
interpreted as a depth measure for query points with respect to an arrangement
of data hyperplanes. The study of depth measures for query points with respect
to a set of data points has a long history, and many such depth measures have
natural counterparts in the setting of hyperplane arrangements. For example,
regression depth is the counterpart of Tukey depth. Motivated by this, we study
general families of depth measures for hyperplane arrangements and show that
all of them must have a deep point. Along the way we prove a Tverberg-type
theorem for hyperplane arrangements, giving a positive answer to a conjecture
by Rousseeuw and Hubert from 1999. We also get three new proofs of the
centerpoint theorem for regression depth, all of which are either stronger or
more general than the original proof by Amenta, Bern, Eppstein, and Teng.
Finally, we prove a version of the center transversal theorem for regression
depth.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Schnider_P/0/1/0/all/0/1">Patrick Schnider</a>, <a href="http://arxiv.org/find/cs/1/au:+Soberon_P/0/1/0/all/0/1">Pablo Sober&#xf3;n</a></p><p>Regression depth, introduced by Rousseeuw and Hubert in 1999, is a notion
that measures how good of a regression hyperplane a given query hyperplane is
with respect to a set of data points. Under projective duality, this can be
interpreted as a depth measure for query points with respect to an arrangement
of data hyperplanes. The study of depth measures for query points with respect
to a set of data points has a long history, and many such depth measures have
natural counterparts in the setting of hyperplane arrangements. For example,
regression depth is the counterpart of Tukey depth. Motivated by this, we study
general families of depth measures for hyperplane arrangements and show that
all of them must have a deep point. Along the way we prove a Tverberg-type
theorem for hyperplane arrangements, giving a positive answer to a conjecture
by Rousseeuw and Hubert from 1999. We also get three new proofs of the
centerpoint theorem for regression depth, all of which are either stronger or
more general than the original proof by Amenta, Bern, Eppstein, and Teng.
Finally, we prove a version of the center transversal theorem for regression
depth.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07425'>Bandit Social Learning: Exploration under Myopic Behavior</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kiarash Banihashem, MohammadTaghi Hajiaghayi, Suho Shin, Aleksandrs Slivkins</p><p>We study social learning dynamics where the agents collectively follow a
simple multi-armed bandit protocol. Agents arrive sequentially, choose arms and
receive associated rewards. Each agent observes the full history (arms and
rewards) of the previous agents, and there are no private signals. While
collectively the agents face exploration-exploitation tradeoff, each agent acts
myopically, without regards to exploration. Motivating scenarios concern
reviews and ratings on online platforms.
</p>
<p>We allow a wide range of myopic behaviors that are consistent with
(parameterized) confidence intervals, including the "unbiased" behavior as well
as various behaviorial biases. While extreme versions of these behaviors
correspond to well-known bandit algorithms, we prove that more moderate
versions lead to stark exploration failures, and consequently to regret rates
that are linear in the number of agents. We provide matching upper bounds on
regret by analyzing "moderately optimistic" agents.
</p>
<p>As a special case of independent interest, we obtain a general result on
failure of the greedy algorithm in multi-armed bandits. This is the first such
result in the literature, to the best of our knowledge
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Banihashem_K/0/1/0/all/0/1">Kiarash Banihashem</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1">MohammadTaghi Hajiaghayi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Suho Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1">Aleksandrs Slivkins</a></p><p>We study social learning dynamics where the agents collectively follow a
simple multi-armed bandit protocol. Agents arrive sequentially, choose arms and
receive associated rewards. Each agent observes the full history (arms and
rewards) of the previous agents, and there are no private signals. While
collectively the agents face exploration-exploitation tradeoff, each agent acts
myopically, without regards to exploration. Motivating scenarios concern
reviews and ratings on online platforms.
</p>
<p>We allow a wide range of myopic behaviors that are consistent with
(parameterized) confidence intervals, including the "unbiased" behavior as well
as various behaviorial biases. While extreme versions of these behaviors
correspond to well-known bandit algorithms, we prove that more moderate
versions lead to stark exploration failures, and consequently to regret rates
that are linear in the number of agents. We provide matching upper bounds on
regret by analyzing "moderately optimistic" agents.
</p>
<p>As a special case of independent interest, we obtain a general result on
failure of the greedy algorithm in multi-armed bandits. This is the first such
result in the literature, to the best of our knowledge
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07429'>Dual Graph Multitask Framework for Imbalanced Delivery Time Estimation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lei Zhang, Mingliang Wang, Xin Zhou, Xingyu Wu, Yiming Cao, Yonghui Xu, Lizhen Cui, Zhiqi Shen</p><p>Delivery Time Estimation (DTE) is a crucial component of the e-commerce
supply chain that predicts delivery time based on merchant information, sending
address, receiving address, and payment time. Accurate DTE can boost platform
revenue and reduce customer complaints and refunds. However, the imbalanced
nature of industrial data impedes previous models from reaching satisfactory
prediction performance. Although imbalanced regression methods can be applied
to the DTE task, we experimentally find that they improve the prediction
performance of low-shot data samples at the sacrifice of overall performance.
To address the issue, we propose a novel Dual Graph Multitask framework for
imbalanced Delivery Time Estimation (DGM-DTE). Our framework first classifies
package delivery time as head and tail data. Then, a dual graph-based model is
utilized to learn representations of the two categories of data. In particular,
DGM-DTE re-weights the embedding of tail data by estimating its kernel density.
We fuse two graph-based representations to capture both high- and low-shot data
representations. Experiments on real-world Taobao logistics datasets
demonstrate the superior performance of DGM-DTE compared to baselines.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingliang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xingyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yiming Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yonghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1">Lizhen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zhiqi Shen</a></p><p>Delivery Time Estimation (DTE) is a crucial component of the e-commerce
supply chain that predicts delivery time based on merchant information, sending
address, receiving address, and payment time. Accurate DTE can boost platform
revenue and reduce customer complaints and refunds. However, the imbalanced
nature of industrial data impedes previous models from reaching satisfactory
prediction performance. Although imbalanced regression methods can be applied
to the DTE task, we experimentally find that they improve the prediction
performance of low-shot data samples at the sacrifice of overall performance.
To address the issue, we propose a novel Dual Graph Multitask framework for
imbalanced Delivery Time Estimation (DGM-DTE). Our framework first classifies
package delivery time as head and tail data. Then, a dual graph-based model is
utilized to learn representations of the two categories of data. In particular,
DGM-DTE re-weights the embedding of tail data by estimating its kernel density.
We fuse two graph-based representations to capture both high- and low-shot data
representations. Experiments on real-world Taobao logistics datasets
demonstrate the superior performance of DGM-DTE compared to baselines.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07627'>LP-Duality Theory and the Cores of Games</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vijay V. Vazirani</p><p>LP-duality theory has played a central role in the study of the core, right
from its early days to the present time. The 1971 paper of Shapley and Shubik,
which gave a characterization of the core of the assignment game, has been a
paradigm-setting work in this regard. However, despite extensive follow-up
work, basic gaps still remain. We address these gaps using the following
building blocks from LP-duality theory:
</p>
<p>1). Total unimodularity (TUM).
</p>
<p>2). Complementary slackness conditions and strict complementarity.
</p>
<p>TUM plays a vital role in the Shapley-Shubik theorem. We define several
generalizations of the assignment game whose LP-formulations admit TUM; using
the latter, we characterize their cores. The Hoffman-Kruskal game is the most
general of these. Its applications include matching students to schools and
medical residents to hospitals, and its core imputations provide a way of
enforcing constraints arising naturally in these applications: encouraging
diversity and discouraging over-representation.
</p>
<p>Complementarity enables us to prove new properties of core imputations of the
assignment game and its generalizations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Vazirani_V/0/1/0/all/0/1">Vijay V. Vazirani</a></p><p>LP-duality theory has played a central role in the study of the core, right
from its early days to the present time. The 1971 paper of Shapley and Shubik,
which gave a characterization of the core of the assignment game, has been a
paradigm-setting work in this regard. However, despite extensive follow-up
work, basic gaps still remain. We address these gaps using the following
building blocks from LP-duality theory:
</p>
<p>1). Total unimodularity (TUM).
</p>
<p>2). Complementary slackness conditions and strict complementarity.
</p>
<p>TUM plays a vital role in the Shapley-Shubik theorem. We define several
generalizations of the assignment game whose LP-formulations admit TUM; using
the latter, we characterize their cores. The Hoffman-Kruskal game is the most
general of these. Its applications include matching students to schools and
medical residents to hospitals, and its core imputations provide a way of
enforcing constraints arising naturally in these applications: encouraging
diversity and discouraging over-representation.
</p>
<p>Complementarity enables us to prove new properties of core imputations of the
assignment game and its generalizations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07657'>Dynamic Flows with Time-Dependent Capacities</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thomas Bl&#xe4;sius, Adrian Feilhauer, Jannik Westenfelder</p><p>Dynamic network flows, sometimes called flows over time, extend the notion of
network flows to include a transit time for each edge. While Ford and Fulkerson
showed that certain dynamic flow problems can be solved via a reduction to
static flows, many advanced models considering congestion and time-dependent
networks result in NP-hard problems. To increase understanding of these
advanced dynamic flow settings we study the structural and computational
complexity of the canonical extensions that have time-dependent capacities or
time-dependent transit times.
</p>
<p>If the considered time interval is finite, we show that already a single edge
changing capacity or transit time once makes the dynamic flow problem weakly
NP-hard. In case of infinite considered time, one change in transit time or two
changes in capacity make the problem weakly NP-hard. For just one capacity
change, we conjecture that the problem can be solved in polynomial time.
Additionally, we show the structural property that dynamic cuts and flows can
become exponentially complex in the above settings where the problem is
NP-hard. We further show that, despite the duality between cuts and flows,
their complexities can be exponentially far apart.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blasius_T/0/1/0/all/0/1">Thomas Bl&#xe4;sius</a>, <a href="http://arxiv.org/find/cs/1/au:+Feilhauer_A/0/1/0/all/0/1">Adrian Feilhauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Westenfelder_J/0/1/0/all/0/1">Jannik Westenfelder</a></p><p>Dynamic network flows, sometimes called flows over time, extend the notion of
network flows to include a transit time for each edge. While Ford and Fulkerson
showed that certain dynamic flow problems can be solved via a reduction to
static flows, many advanced models considering congestion and time-dependent
networks result in NP-hard problems. To increase understanding of these
advanced dynamic flow settings we study the structural and computational
complexity of the canonical extensions that have time-dependent capacities or
time-dependent transit times.
</p>
<p>If the considered time interval is finite, we show that already a single edge
changing capacity or transit time once makes the dynamic flow problem weakly
NP-hard. In case of infinite considered time, one change in transit time or two
changes in capacity make the problem weakly NP-hard. For just one capacity
change, we conjecture that the problem can be solved in polynomial time.
Additionally, we show the structural property that dynamic cuts and flows can
become exponentially complex in the above settings where the problem is
NP-hard. We further show that, despite the duality between cuts and flows,
their complexities can be exponentially far apart.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07666'>Forbidden Patterns in Temporal Graphs Resulting from Encounters in a Corridor</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michel Habib, Minh-Hang Nguyen, Mika&#xeb;l Rabie, Laurent Viennot</p><p>In this paper, we study temporal graphs arising from mobility models where
some agents move in a space and where edges appear each time two agents meet.
We propose a rather natural one-dimensional model. If each pair of agents meets
exactly once, we get a temporal clique where each possible edge appears exactly
once. By ordering the edges according to meeting times, we get a subset of the
temporal cliques. We introduce the first notion of of forbidden patterns in
temporal graphs, which leads to a characterization of this class of graphs. We
provide, thanks to classical combinatorial results, the number of such cliques
for a given number of agents. We consider specific cases where some of the
nodes are frozen, and again provide a characterization by forbidden patterns.
We give a forbidden pattern when we allow multiple crossings between agents,
and leave open the question of a characterization in this situation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Habib_M/0/1/0/all/0/1">Michel Habib</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1">Minh-Hang Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabie_M/0/1/0/all/0/1">Mika&#xeb;l Rabie</a>, <a href="http://arxiv.org/find/cs/1/au:+Viennot_L/0/1/0/all/0/1">Laurent Viennot</a></p><p>In this paper, we study temporal graphs arising from mobility models where
some agents move in a space and where edges appear each time two agents meet.
We propose a rather natural one-dimensional model. If each pair of agents meets
exactly once, we get a temporal clique where each possible edge appears exactly
once. By ordering the edges according to meeting times, we get a subset of the
temporal cliques. We introduce the first notion of of forbidden patterns in
temporal graphs, which leads to a characterization of this class of graphs. We
provide, thanks to classical combinatorial results, the number of such cliques
for a given number of agents. We consider specific cases where some of the
nodes are frozen, and again provide a characterization by forbidden patterns.
We give a forbidden pattern when we allow multiple crossings between agents,
and leave open the question of a characterization in this situation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07771'>Fully dynamic clustering and diversity maximization in doubling metrics</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paolo Pellizzoni, Andrea Pietracaprina, Geppino Pucci</p><p>We present approximation algorithms for some variants of center-based
clustering and related problems in the fully dynamic setting, where the
pointset evolves through an arbitrary sequence of insertions and deletions.
Specifically, we target the following problems: $k$-center (with and without
outliers), matroid-center, and diversity maximization. All algorithms employ a
coreset-based strategy and rely on the use of the cover tree data structure,
which we crucially augment to maintain, at any time, some additional
information enabling the efficient extraction of the solution for the specific
problem. For all of the aforementioned problems our algorithms yield
$(\alpha+\varepsilon)$-approximations, where $\alpha$ is the best known
approximation attainable in polynomial time in the standard off-line setting
(except for $k$-center with $z$ outliers where $\alpha = 2$ but we get a
$(3+\varepsilon)$-approximation) and $\varepsilon&gt;0$ is a user-provided
accuracy parameter. The analysis of the algorithms is performed in terms of the
doubling dimension of the underlying metric. Remarkably, and unlike previous
works, the data structure and the running times of the insertion and deletion
procedures do not depend in any way on the accuracy parameter $\varepsilon$
and, for the two $k$-center variants, on the parameter $k$. For spaces of
bounded doubling dimension, the running times are dramatically smaller than
those that would be required to compute solutions on the entire pointset from
scratch. To the best of our knowledge, ours are the first solutions for the
matroid-center and diversity maximization problems in the fully dynamic
setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pellizzoni_P/0/1/0/all/0/1">Paolo Pellizzoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietracaprina_A/0/1/0/all/0/1">Andrea Pietracaprina</a>, <a href="http://arxiv.org/find/cs/1/au:+Pucci_G/0/1/0/all/0/1">Geppino Pucci</a></p><p>We present approximation algorithms for some variants of center-based
clustering and related problems in the fully dynamic setting, where the
pointset evolves through an arbitrary sequence of insertions and deletions.
Specifically, we target the following problems: $k$-center (with and without
outliers), matroid-center, and diversity maximization. All algorithms employ a
coreset-based strategy and rely on the use of the cover tree data structure,
which we crucially augment to maintain, at any time, some additional
information enabling the efficient extraction of the solution for the specific
problem. For all of the aforementioned problems our algorithms yield
$(\alpha+\varepsilon)$-approximations, where $\alpha$ is the best known
approximation attainable in polynomial time in the standard off-line setting
(except for $k$-center with $z$ outliers where $\alpha = 2$ but we get a
$(3+\varepsilon)$-approximation) and $\varepsilon&gt;0$ is a user-provided
accuracy parameter. The analysis of the algorithms is performed in terms of the
doubling dimension of the underlying metric. Remarkably, and unlike previous
works, the data structure and the running times of the insertion and deletion
procedures do not depend in any way on the accuracy parameter $\varepsilon$
and, for the two $k$-center variants, on the parameter $k$. For spaces of
bounded doubling dimension, the running times are dramatically smaller than
those that would be required to compute solutions on the entire pointset from
scratch. To the best of our knowledge, ours are the first solutions for the
matroid-center and diversity maximization problems in the fully dynamic
setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07800'>An Efficient B-tree Implementation for Memory-Constrained Embedded Systems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nadir Ould-Khessal, Scott Fazackerley, Ramon Lawrence (University of British Columbia)</p><p>Embedded devices collect and process significant amounts of data in a variety
of applications including environmental monitoring, industrial automation and
control, and other Internet of Things (IoT) applications. Storing data
efficiently is critically important, especially when the device must perform
local processing on the data. The most widely used data structure for high
performance query and insert is the B-tree. However, existing implementations
consume too much memory for small embedded devices and often rely on operating
system support. This work presents an extremely memory efficient implementation
of B-trees for embedded devices that functions on the smallest devices and does
not require an operating system. Experimental results demonstrate that the
B-tree implementation can run on devices with as little as 4 KB of RAM while
efficiently processing thousands of records.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ould_Khessal_N/0/1/0/all/0/1">Nadir Ould-Khessal</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazackerley_S/0/1/0/all/0/1">Scott Fazackerley</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawrence_R/0/1/0/all/0/1">Ramon Lawrence</a> (University of British Columbia)</p><p>Embedded devices collect and process significant amounts of data in a variety
of applications including environmental monitoring, industrial automation and
control, and other Internet of Things (IoT) applications. Storing data
efficiently is critically important, especially when the device must perform
local processing on the data. The most widely used data structure for high
performance query and insert is the B-tree. However, existing implementations
consume too much memory for small embedded devices and often rely on operating
system support. This work presents an extremely memory efficient implementation
of B-trees for embedded devices that functions on the smallest devices and does
not require an operating system. Experimental results demonstrate that the
B-tree implementation can run on devices with as little as 4 KB of RAM while
efficiently processing thousands of records.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07821'>Perfect Sampling of $q$-Spin Systems on $\mathbb Z^2$ via Weak Spatial Mixing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Konrad Anand, Mark Jerrum</p><p>We present a perfect marginal sampler of the unique Gibbs measure of a spin
system on $\mathbb Z^2$. The algorithm is an adaptation of a previous `lazy
depth-first' approach by the authors, but relaxes the requirement of strong
spatial mixing to weak. It exploits a classical result in statistical physics
relating weak spatial mixing on $\mathbb Z^2$ to strong spatial mixing on
squares. When the spin system exhibits weak spatial mixing, the run-time of our
sampler is linear in the size of sample. Applications of note are the
ferromagnetic Potts model at supercritical temperatures, and the ferromagnetic
Ising model with consistent non-zero external field at any non-zero
temperature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Anand_K/0/1/0/all/0/1">Konrad Anand</a>, <a href="http://arxiv.org/find/cs/1/au:+Jerrum_M/0/1/0/all/0/1">Mark Jerrum</a></p><p>We present a perfect marginal sampler of the unique Gibbs measure of a spin
system on $\mathbb Z^2$. The algorithm is an adaptation of a previous `lazy
depth-first' approach by the authors, but relaxes the requirement of strong
spatial mixing to weak. It exploits a classical result in statistical physics
relating weak spatial mixing on $\mathbb Z^2$ to strong spatial mixing on
squares. When the spin system exhibits weak spatial mixing, the run-time of our
sampler is linear in the size of sample. Applications of note are the
ferromagnetic Potts model at supercritical temperatures, and the ferromagnetic
Ising model with consistent non-zero external field at any non-zero
temperature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T01:30:00Z">Thursday, February 16 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gradientscience.org/dataset-interfaces/'>Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation</a></h3>
        <p class='tr-article-feed'>from <a href='https://gradientscience.org/'>Gradient Science</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          

<!--  -->
<!--  -->









<!--  -->
<!-- 
 -->
<!--  -->


<!--  -->
<!-- chart.js -->


<p>

    Paper



   Code

<br></p>

<p>
Evaluating model reliability under a distribution shift that we do not have samples from is challenging. Our new work introduces dataset interfaces: a scalable framework that synthesizes counterfactual examples for a given dataset under user-specified shifts.
</p>

<p>Suppose that we want to deploy an ImageNet-trained classifier to identify objects in image scenes (such as dogs, plates, chairs, etc). Ideally, we would like this model to perform reliably in a variety of contexts, including under distribution shift: for example, changes in background, object pose, or data pipeline that are underrepresented in the training dataset. How can we ensure that our model will perform well in such cases?</p>

<p>As a concrete example, consider checking that our model reliably identifies plates captured in unexpected locations (such as “in the desert” or “in the grass”). A natural way to do that is to acquire counterfactual examples: images that conform to the training distribution except for a specified change. In our example scenario, such counterfactual examples correspond to images of plates that are located in the grass but otherwise match the ImageNet distribution in terms of style, lighting, camera angle, etc.</p>

<p>How can we procure such images? One common approach is to query an image search engine, such as Google or Bing:</p>

<p>♦
♦</p>

<p>Unfortunately, while the search engine does yield images of plates, they don’t quite capture the desired distribution shift. Image search gives us images of  “plates in the desert” on white backgrounds, not the desert! And rather than plates on grass, we get grass on plates!</p>

<p>It appears such specific queries are simply too challenging for search engines. So, let’s take a different approach. What if, instead, we use a text-to-image generative model, such as Stable Diffusion, DALL-E 2, or Imagen? These models, which generate photorealistic images conditioned on text, can generate never-before-seen scenes , like avocado-shaped chairs. Would such generative models fare much better? Let’s query one of them—Stable Diffusion—with the name of the class (e.g., “A photo of a plate in the grass.”). Here is what we get:</p>

<p>♦</p>

<p>Nice! The synthesized photos convincingly portray plates on grassy backgrounds, as desired.</p>

<p>However, something unexpected happens: when we evaluate our ImageNet-trained classifier on these images, it achieves a paltry accuracy of only 2%! Is the grassy background really such a catastrophic failure for our model?</p>

<p>Turns out: prompting Stable Diffusion with the class name “plate” introduces a confounding shift. Specifically, while ImageNet plates usually contain food, the plates generated by Stable Diffusion are almost entirely empty. Thus, our ImageNet-trained classifier fails even when generating plates with no (specified) shift—we get 5% accuracy even when we evaluate our model on images generated with the prompt “a photo of a plate”!</p>

<p>♦</p>

<p>Can we then find a way to capture such rare shifts (e.g. “plate in the grass”) while still properly generating objects matching those found in the original distribution (e.g. the kinds of plates found in ImageNet)?</p>

Dataset Interfaces

<p>This is where dataset interfaces, our new framework that scalably synthesizes counterfactual examples for a given dataset under user-specified shifts, comes in.</p>

<p>Our framework still uses text-to-image generative models (we use Stable Diffusion) to synthesize such counterfactual examples. However, as seen above, we need a much more precise way to capture underlying concepts (classes) than just prompting such a model with the class name. To this end, we leverage textual inversion, a technique that aids in generating objects that are difficult to express with standard, human-language prompts. In textual inversion, we use a set of images containing a desired visual concept to learn a new “word” (token) S* meant to represent the concept whenever used in a prompt. Then, we can use this token in place of the class name in prompts to generate images more closely aligned to the objects as captured in the original dataset of interest (in our case, ImageNet).</p>

<p>Now, to construct our dataset interface, we run textual inversion on images of each class in the input dataset separately, learning a corresponding class token Sc for each. Then, by incorporating these tokens into our prompts, we can generate images that more closely match the corresponding class (as represented in the input dataset) under specified shifts. For example, to generate an image of a dog on the beach, we can use the prompt: “A photo of a Sdog on the beach.” Below is an overview of our approach.</p>

<p>♦</p>

     An overview of our framework. For each class in the input dataset, we use textual inversion to learn a custom token (in the text space of a text-to-image diffusion model) that captures the distribution of the corresponding class. We can scalably generate counterfactual examples by incorporating these tokens in natural language prompts.


ImageNet*

<p>To demonstrate our framework in action, we create ImageNet, a dataset interface for the ImageNet dataset. As we see below, ImageNet-generated images match those of ImageNet much more closely than images generated by just prompting Stable Diffusion with the class name.
♦</p>

     Examples of real images from ImageNet (top) and images generated either by prompting Stable Diffusion with the corresponding class name (middle) or by using our dataset interface. ImageNet* (bottom). For each class, there is a visual mismatch between the images from ImageNet and the images generated by the class name. ImageNet* avoids this discrepancy by more closely matching the original distribution. 

<p>Now that we are able to match the original distribution, we can create proper counterfactual examples. Specifically, we use ImageNet* to generate a benchmark for distribution shift robustness of counterfactual examples for 23 shifts, including changes in background, weather, lighting, style, attributes, and co-occurrence. Here are some of the resulting images:</p>



<p>You can find the corresponding benchmark here. We also release the original ImageNet* tokens here—we are excited to see what kind of shifts people can capture with them!</p>

Model Debugging
<p>Now, with a dataset interface (such as ImageNet*) in hand, how can we diagnose model failures? Let’s return to our example of evaluating an ImageNet-trained classifier’s performance on “plates in the grass.” Recall that when we prompted Stable Diffusion with the class name, we introduced a confounding shift of emptiness, and the classifier’s accuracy dropped to 2%.</p>

<p>Let’s apply now dataset interfaces to try and disentangle these two shifts. To this end, we use ImageNet* to generate counterfactual examples of “plates in the grass” and “empty plates” separately. We find that our classifier’s accuracy only slightly drops on plates in the grass, from 90% to 75%. However, on empty plates, our classifier’s performance severely degrades to 6%!
♦</p>

<p>So, indeed, it was the emptiness—not the grassy background—that was the cause of the catastrophic performance drop that we observed. Since dataset interfaces generate images that closely match the input distribution, we can test these distribution shifts in isolation without worrying about such hidden confounding shifts.</p>

A shift-centric perspective on robustness
<p>Beyond helping us surface individual model failures, dataset interfaces enable a new, broader perspective on model robustness.</p>

<p>Many previous works have studied how different types of models are able to handle distribution shifts. However, these works are only able to study one, or a handful of distribution shifts at a time. By harnessing the capabilities of dataset interfaces, we can compare the behavior of a wide range of (23) shifts all at once, yielding a new view on robustness.</p>

<p>To understand how a given distribution shift impacts different models, we can first collect a set of ImageNet models and evaluate them on images that reflect that shift. We then can plot each model’s in-distribution accuracy against its performance on images under this shift (see below for two examples): each point represents one model. 
♦</p>

<p>Looking at the plot above, we see that these two shifts, “in the water” and studio lighting”, exhibit different behavior! While both lead to the same average drop in performance,  “in-distribution” accuracy improvements generally correspond to larger accuracy increases on “in the water” images than “in studio lighting” images. We can quantify this difference by looking at the slope of the line fit to the model accuracies on the plot (the higher the slope, the more benefit we gain from improved models).</p>

<p>Motivated by this difference,  we can categorize the behavior of each shift in our benchmark based on two criteria:</p>
<ul>
  <li>Absolute impact: the shift’s overall severity, measured as the average drop in accuracy due to the distribution shift.</li>
  <li>ID/OOD slope: the degree to which in-distribution accuracy translates to improvement on the images under the distribution shift, measured as the slope of the plot described above
♦</li>
</ul>

<p>As our first plot suggested, different types of shifts manifest different behaviors. For example, even though “in the forest” and “at dusk” have similar absolute impacts, “in the water” has a higher ID/OOD slope. Thus, while improving in-distribution performance translates to better accuracy on “in the forest” images, the model’s behavior on “at dusk” images is much more static. In general, we find that shifts based on lighting have lower ID/OOD slope than those based on background. The above is just an example of how our framework enables one to study not only how a given distribution shift impacts different models but also how different distribution shifts vary in terms of their impact on such models.</p>

Conclusion
<p>In this post, we introduce dataset interfaces: a framework which allows users to scalably synthesize counterfactual examples with fine-grained controls. Our framework generates images that match key aspects of the input dataset’s distribution, enabling us to test distribution shifts in isolation. Also, thanks to its scalability, dataset interfaces allow users to evaluate a wide array of shifts.</p>


















    var img_root = "gradientscience.org/assets/dataset-interfaces/demo_images/"
    var shifts = [
        "and_a_flower", "in_the_grass",	"in_the_snow",	
        "pencil_sketch", "in_the_beach", "in_the_fog",		
        "in_the_rain",	"oil_painting",	"studio_lighting", 
        "at_night", "in_bright_sunlight",  "in_the_forest",
        ];
    var classes = [
        "goldfinch", 'german shepherd', "snail", 
        'eagle', "arctic fox", "monarch butterfly", 
        'hamster', 'panda', 'backpack', 
        "broom", "desk", "scooter",
         "teapot", "street sign", "pineapple", "pizza"]
    var classes_map = {
        "goldfinch": 11, "snail": 113, 'eagle': 22, 'german shepherd': 235,
        "arctic fox": 279, "monarch butterfly": 323, 'hamster': 333,
        'panda': 388, 'backpack': 414, "broom": 462, "desk": 526,
        "scooter": 670, "teapot": 849, "street sign": 919,
        "pineapple": 953, "pizza": 963,
    };
    make_thumbnail_plot('bias_examples_widget', img_root, shifts, classes, classes_map);

        
        </div>

        <div class='tr-article-summary'>
        
          
          <meta charset="utf-8" />

<!-- <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> -->
<!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"> -->

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous" />

<link rel="stylesheet" type="text/css" href="https://gradientscience.org/assets/css/style.css" />

<link rel="stylesheet" href="https://gradientscience.org/assets/multilabel/style.css" />

<link rel="stylesheet" type="text/css" href="https://gradientscience.org/assets/dataset-interfaces/style.css" />

<!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css"> -->
<!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script> -->
<!-- <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script> -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha384-tsQFqpEReu7ZLhBV2VZlAu7zcOV+rXbYlF2cqB8txI/8aZajjp4Bqd+V6D5IgvKT" crossorigin="anonymous"></script>

<!-- <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css"> -->
<!-- chart.js -->
<script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>

<p><a class="bbutton" style="float: left; width: 45%;" href="https://arxiv.org/abs/2302.07865">
<i class="fas fa-file-pdf"></i>
    Paper
</a>
<a class="bbutton" style="float: left; width: 45%;" href="https://github.com/MadryLab/dataset-interfaces">
<i class="fab fa-github"></i>
   Code
</a>
<br /></p>

<p><i>
Evaluating model reliability under a distribution shift that we do not have samples from is challenging. Our <a href="https://arxiv.org/abs/2302.07865">new work</a> introduces dataset interfaces: a scalable framework that synthesizes counterfactual examples for a given dataset under user-specified shifts.
</i></p>

<p>Suppose that we want to deploy an ImageNet-trained classifier to identify objects in image scenes (such as dogs, plates, chairs, etc). Ideally, we would like this model to perform reliably in a variety of contexts, including under <i>distribution shift</i>: for example, changes in background, object pose, or data pipeline that are underrepresented in the training dataset. How can we ensure that our model will perform well in such cases?</p>

<p>As a concrete example, consider checking that our model reliably identifies plates captured in unexpected locations (such as “in the desert” or “in the grass”). A natural way to do that is to acquire <i>counterfactual examples</i>: images that conform to the training distribution except for a specified change. In our example scenario, such counterfactual examples correspond to images of plates that are located in the grass but otherwise match the ImageNet distribution in terms of style, lighting, camera angle, etc.</p>

<p>How can we procure such images? One <a href="https://github.com/HaohanWang/ImageNet-Sketch">common</a> <a href="https://github.com/hendrycks/imagenet-r">approach</a> is to query an image search engine, such as Google or Bing:</p>

<p><img alt="plates in the desert" src="/assets/dataset-interfaces/plate_on_the_desert.png" style="width:100%" />
<img alt="plates in the grass" src="/assets/dataset-interfaces/plate_in_the_grass_screenshot.png" style="width:100%" /></p>

<p>Unfortunately, while the search engine does yield images of plates, they don’t quite capture the desired distribution shift. Image search gives us images of  “plates in the desert” on white backgrounds, not the desert! And rather than plates on grass, we get grass on plates!</p>

<p>It appears such specific queries are simply too challenging for search engines. So, let’s take a different approach. What if, instead, we use a text-to-image generative model, such as <a href="https://arxiv.org/abs/2112.10752">Stable Diffusion</a>, <a href="https://openai.com/dall-e-2/">DALL-E 2</a>, or <a href="https://imagen.research.google/">Imagen</a>? These models, which generate photorealistic images conditioned on text, can generate never-before-seen scenes , like <a href="https://www.technologyreview.com/2021/01/05/1015754/avocado-armchair-future-ai-openai-deep-learning-nlp-gpt3-computer-vision-common-sense/">avocado-shaped chairs</a>. Would such generative models fare much better? Let’s query one of them—Stable Diffusion—with the name of the class (e.g., “A photo of a plate in the grass.”). Here is what we get:</p>

<p><img alt="plates in the grass SD" src="/assets/dataset-interfaces/plate_in_grass.png" style="width:100%" /></p>

<p>Nice! The synthesized photos convincingly portray plates on grassy backgrounds, as desired.</p>

<p>However, something unexpected happens: when we evaluate our ImageNet-trained classifier on these images, it achieves a paltry accuracy of only 2%! Is the grassy background really such a catastrophic failure for our model?</p>

<p>Turns out: prompting Stable Diffusion with the class name “plate” introduces a <i>confounding</i> shift. Specifically, while ImageNet plates usually contain food, the plates generated by Stable Diffusion are almost entirely empty. Thus, our ImageNet-trained classifier fails even when generating plates with no (specified) shift—we get 5% accuracy even when we evaluate our model on images generated with the prompt “a photo of a plate”!</p>

<p><img alt="empty stable diffusion" src="/assets/dataset-interfaces/bing_plates_comparison.png" style="width:80%" /></p>

<p>Can we then find a way to capture such rare shifts (e.g. “plate in the grass”) while still properly generating objects matching those found in the original distribution (e.g. the kinds of plates found in ImageNet)?</p>

<h2 id="dataset-interfaces">Dataset Interfaces</h2>

<p>This is where <i>dataset interfaces</i>, our new framework that scalably synthesizes counterfactual examples for a given dataset under user-specified shifts, comes in.</p>

<p>Our framework still uses text-to-image generative models (we use Stable Diffusion) to synthesize such counterfactual examples. However, as seen above, we need a much more precise way to capture underlying concepts (classes) than just prompting such a model with the class name. To this end, we leverage <i><a href="https://arxiv.org/abs/2208.01618">textual inversion</a></i>, a technique that aids in generating objects that are difficult to express with standard, human-language prompts. In textual inversion, we use a set of images containing a desired visual concept to learn a new “word” (token) S<sub>*</sub> meant to represent the concept whenever used in a prompt. Then, we can use this token in place of the class name in prompts to generate images more closely aligned to the objects as captured in the original dataset of interest (in our case, ImageNet).</p>

<p>Now, to construct our dataset interface, we run textual inversion on images of each class in the input dataset separately, learning a corresponding class token Sc for each. Then, by incorporating these tokens into our prompts, we can generate images that more closely match the corresponding class (as represented in the input dataset) under specified shifts. For example, to generate an image of a dog on the beach, we can use the prompt: “A photo of a S<sub>dog</sub> on the beach.” Below is an overview of our approach.</p>

<p><img alt="empty stable diffusion" src="/assets/dataset-interfaces/methods_figure.png" style="width:100%" /></p>
<div class="footnote">
     An overview of our framework. For each class in the input dataset, we use textual inversion to learn a custom token (in the text space of a text-to-image diffusion model) that captures the distribution of the corresponding class. We can scalably generate counterfactual examples by incorporating these tokens in natural language prompts.
</div>

<h2 id="imagenet">ImageNet*</h2>

<p>To demonstrate our framework in action, we create ImageNet<em>, a dataset interface for the ImageNet dataset. As we see below, ImageNet</em>-generated images match those of ImageNet much more closely than images generated by just prompting Stable Diffusion with the class name.
<img alt="empty stable diffusion" src="/assets/dataset-interfaces/tweet_mismatch_figure.png" style="width:100%" /></p>
<div class="footnote">
     Examples of real images from ImageNet (top) and images generated either by prompting Stable Diffusion with the corresponding class name (middle) or by using our dataset interface. ImageNet* (bottom). For each class, there is a visual mismatch between the images from ImageNet and the images generated by the class name. ImageNet* avoids this discrepancy by more closely matching the original distribution. 
</div>
<p>Now that we are able to match the original distribution, we can create proper counterfactual examples. Specifically, we use ImageNet* to generate a benchmark for distribution shift robustness of counterfactual examples for 23 shifts, including changes in background, weather, lighting, style, attributes, and co-occurrence. Here are some of the resulting images:</p>

<div id="bias_examples_widget" style="overflow:auto; text-align: center"></div>

<p>You can find the corresponding benchmark <a href="https://huggingface.co/datasets/madrylab/imagenet-star">here</a>. We also release the original ImageNet* tokens <a href="https://huggingface.co/datasets/madrylab/imagenet-star-tokens">here</a>—we are excited to see what kind of shifts people can capture with them!</p>

<h2 id="model-debugging">Model Debugging</h2>
<p>Now, with a dataset interface (such as ImageNet*) in hand, how can we diagnose model failures? Let’s return to our example of evaluating an ImageNet-trained classifier’s performance on “plates in the grass.” Recall that when we prompted Stable Diffusion with the class name, we introduced a confounding shift of emptiness, and the classifier’s accuracy dropped to 2%.</p>

<p>Let’s apply now dataset interfaces to try and disentangle these two shifts. To this end, we use ImageNet* to generate counterfactual examples of “plates in the grass” and “empty plates” separately. We find that our classifier’s accuracy only slightly drops on plates in the grass, from 90% to 75%. However, on empty plates, our classifier’s performance severely degrades to 6%!
<img alt="empty stable diffusion" src="/assets/dataset-interfaces/ImageNet*_plates.png" style="width:100%" /></p>

<p>So, indeed, it was the emptiness—not the grassy background—that was the cause of the catastrophic performance drop that we observed. Since dataset interfaces generate images that closely match the input distribution, we can test these distribution shifts in isolation without worrying about such hidden confounding shifts.</p>

<h2 id="a-shift-centric-perspective-on-robustness">A shift-centric perspective on robustness</h2>
<p>Beyond helping us surface individual model failures, dataset interfaces enable a new, broader perspective on model robustness.</p>

<p><a href="https://arxiv.org/abs/2007.00644">Many</a> <a href="https://arxiv.org/abs/2107.04649">previous</a> <a href="https://arxiv.org/pdf/1902.10811.pdf">works</a> have studied how different types of models are able to handle distribution shifts. However, these works are only able to study one, or a handful of distribution shifts at a time. By harnessing the capabilities of dataset interfaces, we can compare the behavior of a wide range of (23) shifts all at once, yielding a new view on robustness.</p>

<p>To understand how a given distribution shift impacts different models, we can first collect a set of ImageNet models and evaluate them on images that reflect that shift. We then can plot each model’s in-distribution accuracy against its performance on images under this shift (see below for two examples): each point represents one model. 
<img alt="empty stable diffusion" src="/assets/dataset-interfaces/on_the_line_figure.png" style="width:100%" /></p>

<p>Looking at the plot above, we see that these two shifts, “in the water” and studio lighting”, exhibit different behavior! While both lead to the same average drop in performance,  “in-distribution” accuracy improvements generally correspond to larger accuracy increases on “in the water” images than “in studio lighting” images. We can quantify this difference by looking at the slope of the line fit to the model accuracies on the plot (the higher the slope, the more benefit we gain from improved models).</p>

<p>Motivated by this difference,  we can categorize the behavior of each shift in our benchmark based on two criteria:</p>
<ul>
  <li><strong>Absolute impact</strong>: the shift’s overall severity, measured as the average drop in accuracy due to the distribution shift.</li>
  <li><strong>ID/OOD slope</strong>: the degree to which in-distribution accuracy translates to improvement on the images under the distribution shift, measured as the slope of the plot described above
<img alt="empty stable diffusion" src="/assets/dataset-interfaces/evaluation_figure.png" style="width:100%" /></li>
</ul>

<p>As our first plot suggested, different types of shifts manifest different behaviors. For example, even though “in the forest” and “at dusk” have similar absolute impacts, “in the water” has a higher ID/OOD slope. Thus, while improving in-distribution performance translates to better accuracy on “in the forest” images, the model’s behavior on “at dusk” images is much more static. In general, we find that shifts based on lighting have lower ID/OOD slope than those based on background. The above is just an example of how our framework enables one to study not only how a given distribution shift impacts different models but also how different distribution shifts vary in terms of their impact on such models.</p>

<h2 id="conclusion">Conclusion</h2>
<p>In this post, we introduce dataset interfaces: a framework which allows users to scalably synthesize counterfactual examples with fine-grained controls. Our framework generates images that match key aspects of the input dataset’s distribution, enabling us to test distribution shifts in isolation. Also, thanks to its scalability, dataset interfaces allow users to evaluate a wide array of shifts.</p>

<script src="https://gradientscience.org/assets/scripts/onload.js"></script>

<script src="https://cdn.jsdelivr.net/gh/nicolaspanel/numjs@0.15.1/dist/numjs.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/mathjs@6.6.0/dist/math.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

<script src="https://gradientscience.org/assets/dataset-interfaces/thumbnail_plot.js"></script>

<script>
    var img_root = "https://gradientscience.org/assets/dataset-interfaces/demo_images/"
    var shifts = [
        "and_a_flower", "in_the_grass",	"in_the_snow",	
        "pencil_sketch", "in_the_beach", "in_the_fog",		
        "in_the_rain",	"oil_painting",	"studio_lighting", 
        "at_night", "in_bright_sunlight",  "in_the_forest",
        ];
    var classes = [
        "goldfinch", 'german shepherd', "snail", 
        'eagle', "arctic fox", "monarch butterfly", 
        'hamster', 'panda', 'backpack', 
        "broom", "desk", "scooter",
         "teapot", "street sign", "pineapple", "pizza"]
    var classes_map = {
        "goldfinch": 11, "snail": 113, 'eagle': 22, 'german shepherd': 235,
        "arctic fox": 279, "monarch butterfly": 323, 'hamster': 333,
        'panda': 388, 'backpack': 414, "broom": 462, "desk": 526,
        "scooter": 670, "teapot": 849, "street sign": 919,
        "pineapple": 953, "pizza": 963,
    };
    make_thumbnail_plot('bias_examples_widget', img_root, shifts, classes, classes_map);
</script>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-16T00:00:00Z">Thursday, February 16 2023, 00:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, February 15
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/02/15/linkage-partly-from.html'>Linkage partly from Barbados</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Hedra Zoo (\(\mathbb{M}\)), like the Online Encyclopedia of Integer Sequences, but for sequences of polyhedra rather than sequences of integers.
        
        </div>

        <div class='tr-article-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://sforcey.github.io/sf34/hedra.htm">Hedra Zoo</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109794057137669490">\(\mathbb{M}\)</a>),</span> like the Online Encyclopedia of Integer Sequences, but for sequences of polyhedra rather than sequences of integers.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@Danpiker/109773012543776299">Mathematical 3d prints by Dan Piker</a>: Morin’s surface, Boy’s surface, a Klein bottle, and a puzzle based on a 3d Pythagorean tiling.</p>
  </li>
  <li>
    <p><a href="https://www.flickr.com/photos/tactom/8471902275/">Origami tessellation torus</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@monsoon0/109800312114130835">\(\mathbb{M}\)</a>),</span> by Tomohiro Tachi.</p>
  </li>
  <li>
    <p><a href="https://discrete-notes.github.io/crossing-number">Low crossing numbers</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109810071945968761">\(\mathbb{M}\)</a>),</span> blog post on <a href="https://doi.org/10.4230/LIPIcs.SoCG.2021.28">a SoCG 21 paper by Mónika Csikós and Nabil H. Mustafa</a>. Given points and a family of shapes containing subsets of them, the goal is to connect the points by a matching, path, or spanning tree so that no shape has its boundary crossed by many edges. Many geometric set families have these structures and this paper shows how to find it faster than was previously known.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Quoridor">Quoridor</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109815696566120005">\(\mathbb{M}\)</a>),</span> a game with simple abstract rules that lead to an interesting mix of strategy and tactics, in which you often have to balance the future effects of a move on your own progress versus its effects on your opponent.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=lthHMDXbP30">Knotty analog oscilloscope art</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@henryseg/109809898659918995">\(\mathbb{M}\)</a>),</span> video by Henry Segerman with Matthias Goerner.</p>
  </li>
  <li>
    <p>It’s not every day that I (and many other Mathstodon users) <a href="https://www.nytimes.com/2023/02/07/science/puzzles-rectangles-mathematics.html">get mentioned in the <em>New York Times</em></a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@phonner/109826175739500354">\(\mathbb{M}\)</a>)!</span> The context is an article by Siobhan Roberts on partitioning rectangles into similar rectangles.</p>
  </li>
  <li>
    <p><a href="https://cs.utdallas.edu/SOCG23/socg.html">The list of accepted papers at SoCG’23</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109830669758019190">\(\mathbb{M}\)</a>),</span> the 39th International Symposium on Computational Geometry, next June in Dallas, is now online. I have one in the list; I’ll post in more detail on it once I have a preprint version ready. <a href="/blog/2022/09/21/counting-paths-convex.html">One of my earlier posts</a> is related and <a href="/blog/2022/08/22/permuted-points-interest.html">another post</a> was a lemma that I ended up not using.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=F_43oTnTXiw">Beware the Runge spikes</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@standupmaths/109819371159314006">\(\mathbb{M}\)</a>)!</span> Matt Parker on the Runge phenomenon, in which interpolating through more data points can make the quality of interpolation worse. Sadly, no mention of the <a href="https://en.wikipedia.org/wiki/Witch_of_Agnesi">Witch of Agnesi</a>.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/mathematicians-complete-quest-to-build-spherical-cubes-20230210/"><em>Quanta</em> on low-surface-area convex polytopes that tile high-dimensional space by integer translations</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@QuantaMagazine@mstdn.social/109841124938979652">\(\mathbb{M}\)</a>).</span> Based on “<a href="https://arxiv.org/abs/2301.02862">An integer parallelotope with small surface area</a>” by Assaf Naor and Oded Regev.</p>
  </li>
  <li>
    <p>I just returned from a week-long workshop at the Bellairs Research Institute in Barbados, my first since the pandemic started <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109849258853460072">\(\mathbb{M}\)</a>).</span> This time, Bellairs double-booked us with another workshop, so we met in Seabourne House and its ocean-view garden instead of the usual picnic table area. This worked surprisingly well, especially for the morning sessions. The photo below shows some of this area; <a href="https://www.ics.uci.edu/~eppstein/pix/seabourne/">the full gallery</a> has a few other shots of architectural details.</p>

    <p><img src="https://www.ics.uci.edu/~eppstein/pix/seabourne/CommonRoom-m.jpg" alt="Seabourne House, Bellairs Research Institute, Holetown, Barbados" style="border-style:solid;border-color:black" /></p>
  </li>
  <li>
    <p><a href="https://i.stack.imgur.com/k61In.png">Three unit regular tetrahedra pack neatly into a unit cube</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@uzulim/109742191472459313">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://3quarksdaily.com/3quarksdaily/2023/02/some-comments-on-writing-popular-mathematics.html">John Allen Paulos on writing popular mathematics</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109858684384756666">\(\mathbb{M}\)</a>),</span> and Bertrand Russell’s other paradox, on the impossibility of combining intelligibility and precision.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@aperiodical/109800517387277782">What can mathematicians do</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@aperiodical/109800517387277782">\(\mathbb{M}\)</a>)?</span> Recordings of ten talks by disabled mathematicians.</p>
  </li>
  <li>
    <p><a href="https://scottaaronson.blog/?p=7028">Scott Aaronson on the shortsightedness of xenophobia</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109872087293449471">\(\mathbb{M}\)</a>),</span> triggered by the denial of a visa to a would-have-been-incoming doctoral student from China.</p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T18:37:00Z">Wednesday, February 15 2023, 18:37</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/011'>TR23-011 |  Half-duplex communication complexity with adversary?  can be less than the classical communication complexity | 

	Nikolay Vereshchagin, 

	Mikhail Dektiarev</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Half-duplex communication complexity with adversary was defined in [Hoover, K., Impagliazzo, R., Mihajlin, I., Smal, A. V. Half-Duplex Communication Complexity, ISAAC 2018.] Half-duplex communication protocols generalize classical protocols defined by Andrew Yao in [Yao, A. C.-C. Some Complexity Questions Related to Distributive Computing (Preliminary Report), STOC 1979]. It has been  unknown so far whether the communication complexities defined by these models are different or not. In the present paper we answer this question: we exhibit a function whose half-duplex communication complexity with adversary is strictly less than the classical communication complexity.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Half-duplex communication complexity with adversary was defined in [Hoover, K., Impagliazzo, R., Mihajlin, I., Smal, A. V. Half-Duplex Communication Complexity, ISAAC 2018.] Half-duplex communication protocols generalize classical protocols defined by Andrew Yao in [Yao, A. C.-C. Some Complexity Questions Related to Distributive Computing (Preliminary Report), STOC 1979]. It has been  unknown so far whether the communication complexities defined by these models are different or not. In the present paper we answer this question: we exhibit a function whose half-duplex communication complexity with adversary is strictly less than the classical communication complexity.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T16:19:34Z">Wednesday, February 15 2023, 16:19</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06717'>The Subgraph Isomorphism Problem for Port Graphs and Quantum Circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Luca Mondada, Pablo Andr&#xe9;s-Mart&#xed;nez</p><p>We study a variant of the subgraph isomorphism problem that is of high
interest to the quantum computing community. Our results give an algorithm to
perform pattern matching in quantum circuits for many patterns simultaneously,
independently of the number of patterns. After a pre-computation step in which
the patterns are compiled into a decision tree, the running time is linear in
the size of the input quantum circuit.
</p>
<p>More generally, we consider connected port graphs, in which every edge $e$
incident to $v$ has a label $L_v(e)$ unique in $v$. Jiang and Bunke showed that
the subgraph isomorphism problem $H \subseteq G$ for such graphs can be solved
in time $O(|V(G)| \cdot |V(H)|)$. We show that if in addition the graphs are
directed acyclic, then the subgraph isomorphism problem can be solved for an
unbounded number of patterns simultaneously. We enumerate all $m$ pattern
matches in time $O(P)^{P+3/2} \cdot |V(G)| + O(m)$, where $P$ is the number of
vertices of the largest pattern. In the case of quantum circuits, we can
express the bound obtained in terms of the maximum number of qubits $N$ and
depth $\delta$ of the patterns : $O(N)^{N + 1/2} \cdot \delta \log \delta \cdot
|V(G)| + O(m)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Mondada_L/0/1/0/all/0/1">Luca Mondada</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Andres_Martinez_P/0/1/0/all/0/1">Pablo Andr&#xe9;s-Mart&#xed;nez</a></p><p>We study a variant of the subgraph isomorphism problem that is of high
interest to the quantum computing community. Our results give an algorithm to
perform pattern matching in quantum circuits for many patterns simultaneously,
independently of the number of patterns. After a pre-computation step in which
the patterns are compiled into a decision tree, the running time is linear in
the size of the input quantum circuit.
</p>
<p>More generally, we consider connected port graphs, in which every edge $e$
incident to $v$ has a label $L_v(e)$ unique in $v$. Jiang and Bunke showed that
the subgraph isomorphism problem $H \subseteq G$ for such graphs can be solved
in time $O(|V(G)| \cdot |V(H)|)$. We show that if in addition the graphs are
directed acyclic, then the subgraph isomorphism problem can be solved for an
unbounded number of patterns simultaneously. We enumerate all $m$ pattern
matches in time $O(P)^{P+3/2} \cdot |V(G)| + O(m)$, where $P$ is the number of
vertices of the largest pattern. In the case of quantum circuits, we can
express the bound obtained in terms of the maximum number of qubits $N$ and
depth $\delta$ of the patterns : $O(N)^{N + 1/2} \cdot \delta \log \delta \cdot
|V(G)| + O(m)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06984'>Towards Optimal Depth-Reductions for Algebraic Formulas</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Herv&#xe9; Fournier, Nutan Limaye, Guillaume Malod, Srikanth Srinivasan, S&#xe9;bastien Tavenas</p><p>Classical results of Brent, Kuck and Maruyama (IEEE Trans. Computers 1973)
and Brent (JACM 1974) show that any algebraic formula of size s can be
converted to one of depth O(log s) with only a polynomial blow-up in size. In
this paper, we consider a fine-grained version of this result depending on the
degree of the polynomial computed by the algebraic formula. Given a homogeneous
algebraic formula of size s computing a polynomial P of degree d, we show that
P can also be computed by an (unbounded fan-in) algebraic formula of depth
O(log d) and size poly(s). Our proof shows that this result also holds in the
highly restricted setting of monotone, non-commutative algebraic formulas. This
improves on previous results in the regime when d is small (i.e., d&lt;&lt;s). In
particular, for the setting of d=O(log s), along with a result of Raz (STOC
2010, JACM 2013), our result implies the same depth reduction even for
inhomogeneous formulas. This is particularly interesting in light of recent
algebraic formula lower bounds, which work precisely in this ``low-degree" and
``low-depth" setting. We also show that these results cannot be improved in the
monotone setting, even for commutative formulas.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fournier_H/0/1/0/all/0/1">Herv&#xe9; Fournier</a>, <a href="http://arxiv.org/find/cs/1/au:+Limaye_N/0/1/0/all/0/1">Nutan Limaye</a>, <a href="http://arxiv.org/find/cs/1/au:+Malod_G/0/1/0/all/0/1">Guillaume Malod</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1">Srikanth Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tavenas_S/0/1/0/all/0/1">S&#xe9;bastien Tavenas</a></p><p>Classical results of Brent, Kuck and Maruyama (IEEE Trans. Computers 1973)
and Brent (JACM 1974) show that any algebraic formula of size s can be
converted to one of depth O(log s) with only a polynomial blow-up in size. In
this paper, we consider a fine-grained version of this result depending on the
degree of the polynomial computed by the algebraic formula. Given a homogeneous
algebraic formula of size s computing a polynomial P of degree d, we show that
P can also be computed by an (unbounded fan-in) algebraic formula of depth
O(log d) and size poly(s). Our proof shows that this result also holds in the
highly restricted setting of monotone, non-commutative algebraic formulas. This
improves on previous results in the regime when d is small (i.e., d&lt;&lt;s). In
particular, for the setting of d=O(log s), along with a result of Raz (STOC
2010, JACM 2013), our result implies the same depth reduction even for
inhomogeneous formulas. This is particularly interesting in light of recent
algebraic formula lower bounds, which work precisely in this ``low-degree" and
``low-depth" setting. We also show that these results cannot be improved in the
monotone setting, even for commutative formulas.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07049'>Multilevel Objective-Function-Free Optimization with an Application to Neural Networks Training</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: S. Gratton, A. Kopanicakova, Ph. L. Toint</p><p>A class of multi-level algorithms for unconstrained nonlinear optimization is
presented which does not require the evaluation of the objective function. The
class contains the momentum-less AdaGrad method as a particular (single-level)
instance. The choice of avoiding the evaluation of the objective function is
intended to make the algorithms of the class less sensitive to noise, while the
multi-level feature aims at reducing their computational cost. The evaluation
complexity of these algorithms is analyzed and their behaviour in the presence
of noise is then illustrated in the context of training deep neural networks
for supervised learning applications.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gratton_S/0/1/0/all/0/1">S. Gratton</a>, <a href="http://arxiv.org/find/math/1/au:+Kopanicakova_A/0/1/0/all/0/1">A. Kopanicakova</a>, <a href="http://arxiv.org/find/math/1/au:+Toint_P/0/1/0/all/0/1">Ph. L. Toint</a></p><p>A class of multi-level algorithms for unconstrained nonlinear optimization is
presented which does not require the evaluation of the objective function. The
class contains the momentum-less AdaGrad method as a particular (single-level)
instance. The choice of avoiding the evaluation of the objective function is
intended to make the algorithms of the class less sensitive to noise, while the
multi-level feature aims at reducing their computational cost. The evaluation
complexity of these algorithms is analyzed and their behaviour in the presence
of noise is then illustrated in the context of training deep neural networks
for supervised learning applications.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07063'>Bounds on Depth of Decision Trees Derived from Decision Rule Systems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kerven Durdymyradov, Mikhail Moshkov</p><p>Systems of decision rules and decision trees are widely used as a means for
knowledge representation, as classifiers, and as algorithms. They are among the
most interpretable models for classifying and representing knowledge. The study
of relationships between these two models is an important task of computer
science. It is easy to transform a decision tree into a decision rule system.
The inverse transformation is a more difficult task. In this paper, we study
unimprovable upper and lower bounds on the minimum depth of decision trees
derived from decision rule systems depending on the various parameters of these
systems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Durdymyradov_K/0/1/0/all/0/1">Kerven Durdymyradov</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshkov_M/0/1/0/all/0/1">Mikhail Moshkov</a></p><p>Systems of decision rules and decision trees are widely used as a means for
knowledge representation, as classifiers, and as algorithms. They are among the
most interpretable models for classifying and representing knowledge. The study
of relationships between these two models is an important task of computer
science. It is easy to transform a decision tree into a decision rule system.
The inverse transformation is a more difficult task. In this paper, we study
unimprovable upper and lower bounds on the minimum depth of decision trees
derived from decision rule systems depending on the various parameters of these
systems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07090'>A Complete Expressiveness Hierarchy for Subgraph GNNs via Subgraph Weisfeiler-Lehman Tests</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bohang Zhang, Guhao Feng, Yiheng Du, Di He, Liwei Wang</p><p>Recently, subgraph GNNs have emerged as an important direction for developing
expressive graph neural networks (GNNs). While numerous architectures have been
proposed, so far there is still a limited understanding of how various design
paradigms differ in terms of expressive power, nor is it clear what design
principle achieves maximal expressiveness with minimal architectural
complexity. Targeting these fundamental questions, this paper conducts a
systematic study of general node-based subgraph GNNs through the lens of
Subgraph Weisfeiler-Lehman Tests (SWL). Our central result is to build a
complete hierarchy of SWL with strictly growing expressivity. Concretely, we
prove that any node-based subgraph GNN falls into one of the six SWL
equivalence classes, among which $\mathsf{SSWL}$ achieves the maximal
expressive power. We also study how these equivalence classes differ in terms
of their practical expressiveness such as encoding graph distance and
biconnectivity. In addition, we give a tight expressivity upper bound of all
SWL algorithms by establishing a close relation with localized versions of
Folklore WL tests (FWL). Overall, our results provide insights into the power
of existing subgraph GNNs, guide the design of new architectures, and point out
their limitations by revealing an inherent gap with the 2-FWL test. Finally,
experiments on the ZINC benchmark demonstrate that $\mathsf{SSWL}$-inspired
subgraph GNNs can significantly outperform prior architectures despite great
simplicity.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bohang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_G/0/1/0/all/0/1">Guhao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yiheng Du</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Di He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a></p><p>Recently, subgraph GNNs have emerged as an important direction for developing
expressive graph neural networks (GNNs). While numerous architectures have been
proposed, so far there is still a limited understanding of how various design
paradigms differ in terms of expressive power, nor is it clear what design
principle achieves maximal expressiveness with minimal architectural
complexity. Targeting these fundamental questions, this paper conducts a
systematic study of general node-based subgraph GNNs through the lens of
Subgraph Weisfeiler-Lehman Tests (SWL). Our central result is to build a
complete hierarchy of SWL with strictly growing expressivity. Concretely, we
prove that any node-based subgraph GNN falls into one of the six SWL
equivalence classes, among which $\mathsf{SSWL}$ achieves the maximal
expressive power. We also study how these equivalence classes differ in terms
of their practical expressiveness such as encoding graph distance and
biconnectivity. In addition, we give a tight expressivity upper bound of all
SWL algorithms by establishing a close relation with localized versions of
Folklore WL tests (FWL). Overall, our results provide insights into the power
of existing subgraph GNNs, guide the design of new architectures, and point out
their limitations by revealing an inherent gap with the 2-FWL test. Finally,
experiments on the ZINC benchmark demonstrate that $\mathsf{SSWL}$-inspired
subgraph GNNs can significantly outperform prior architectures despite great
simplicity.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06776'>Minimum-link $C$-Oriented Paths Visiting a Sequence of Regions in the Plane</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kerem Geva, Matthew J. Katz, Joseph S. B. Mitchell, Eli Packer</p><p>Let $E=\{e_1,\ldots,e_n\}$ be a set of $C$-oriented disjoint segments in the
plane, where $C$ is a given finite set of orientations that spans the plane,
and let $s$ and $t$ be two points. %(We also require that for each orientation
in $C$, its opposite orientation is also in $C$.) We seek a minimum-link
$C$-oriented tour of $E$, that is, a polygonal path $\pi$ from $s$ to $t$ that
visits the segments of $E$ in order, such that, the orientations of its edges
are in $C$ and their number is minimum. We present an algorithm for computing
such a tour in $O(|C|^2 \cdot n^2)$ time. This problem already captures most of
the difficulties occurring in the study of the more general problem, in which
$E$ is a set of not-necessarily-disjoint $C$-oriented polygons.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Geva_K/0/1/0/all/0/1">Kerem Geva</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_M/0/1/0/all/0/1">Matthew J. Katz</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_J/0/1/0/all/0/1">Joseph S. B. Mitchell</a>, <a href="http://arxiv.org/find/cs/1/au:+Packer_E/0/1/0/all/0/1">Eli Packer</a></p><p>Let $E=\{e_1,\ldots,e_n\}$ be a set of $C$-oriented disjoint segments in the
plane, where $C$ is a given finite set of orientations that spans the plane,
and let $s$ and $t$ be two points. %(We also require that for each orientation
in $C$, its opposite orientation is also in $C$.) We seek a minimum-link
$C$-oriented tour of $E$, that is, a polygonal path $\pi$ from $s$ to $t$ that
visits the segments of $E$ in order, such that, the orientations of its edges
are in $C$ and their number is minimum. We present an algorithm for computing
such a tour in $O(|C|^2 \cdot n^2)$ time. This problem already captures most of
the difficulties occurring in the study of the more general problem, in which
$E$ is a set of not-necessarily-disjoint $C$-oriented polygons.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07051'>Adversarial Path Planning for Optimal Camera Positioning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Gaia Carenini, Alexandre Duplessis</p><p>The use of visual sensors is flourishing, driven among others by the several
applications in detection and prevention of crimes or dangerous events. While
the problem of optimal camera placement for total coverage has been solved for
a decade or so, that of the arrangement of cameras maximizing the recognition
of objects "in-transit" is still open. The objective of this paper is to attack
this problem by providing an adversarial method of proven optimality based on
the resolution of Hamilton-Jacobi equations. The problem is attacked by first
assuming the perspective of an adversary, i.e. computing explicitly the path
minimizing the probability of detection and the quality of reconstruction.
Building on this result, we introduce an optimality measure for camera
configurations and perform a simulated annealing algorithm to find the optimal
camera placement.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1">Gaia Carenini</a>, <a href="http://arxiv.org/find/cs/1/au:+Duplessis_A/0/1/0/all/0/1">Alexandre Duplessis</a></p><p>The use of visual sensors is flourishing, driven among others by the several
applications in detection and prevention of crimes or dangerous events. While
the problem of optimal camera placement for total coverage has been solved for
a decade or so, that of the arrangement of cameras maximizing the recognition
of objects "in-transit" is still open. The objective of this paper is to attack
this problem by providing an adversarial method of proven optimality based on
the resolution of Hamilton-Jacobi equations. The problem is attacked by first
assuming the perspective of an adversary, i.e. computing explicitly the path
minimizing the probability of detection and the quality of reconstruction.
Building on this result, we introduce an optimality measure for camera
configurations and perform a simulated annealing algorithm to find the optimal
camera placement.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06616'>Tensor Networks or Decision Diagrams? Guidelines for Classical Quantum Circuit Simulation</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lukas Burgholzer, Alexander Ploier, Robert Wille</p><p>Classically simulating quantum circuits is crucial when developing or testing
quantum algorithms. Due to the underlying exponential complexity, efficient
data structures are key for performing such simulations. To this end, tensor
networks and decision diagrams have independently been developed with differing
perspectives, terminologies, and backgrounds in mind. Although this left
designers with two complementary data structures for quantum circuit
simulation, thus far it remains unclear which one is the better choice for a
given use case. In this work, we (1) consider how these techniques approach
classical quantum circuit simulation, and (2) examine their (dis)similarities
with regard to their most applicable abstraction level, the desired simulation
output, the impact of the computation order, and the ease of distributing the
workload. As a result, we provide guidelines for when to better use tensor
networks and when to better use decision diagrams in classical quantum circuit
simulation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Burgholzer_L/0/1/0/all/0/1">Lukas Burgholzer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ploier_A/0/1/0/all/0/1">Alexander Ploier</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wille_R/0/1/0/all/0/1">Robert Wille</a></p><p>Classically simulating quantum circuits is crucial when developing or testing
quantum algorithms. Due to the underlying exponential complexity, efficient
data structures are key for performing such simulations. To this end, tensor
networks and decision diagrams have independently been developed with differing
perspectives, terminologies, and backgrounds in mind. Although this left
designers with two complementary data structures for quantum circuit
simulation, thus far it remains unclear which one is the better choice for a
given use case. In this work, we (1) consider how these techniques approach
classical quantum circuit simulation, and (2) examine their (dis)similarities
with regard to their most applicable abstraction level, the desired simulation
output, the impact of the computation order, and the ease of distributing the
workload. As a result, we provide guidelines for when to better use tensor
networks and when to better use decision diagrams in classical quantum circuit
simulation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06737'>Detection-Recovery Gap for Planted Dense Cycles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Cheng Mao, Alexander S. Wein, Shenduo Zhang</p><p>Planted dense cycles are a type of latent structure that appears in many
applications, such as small-world networks in social sciences and sequence
assembly in computational biology. We consider a model where a dense cycle with
expected bandwidth $n \tau$ and edge density $p$ is planted in an
Erd\H{o}s-R\'enyi graph $G(n,q)$. We characterize the computational thresholds
for the associated detection and recovery problems for the class of low-degree
polynomial algorithms. In particular, a gap exists between the two thresholds
in a certain regime of parameters. For example, if $n^{-3/4} \ll \tau \ll
n^{-1/2}$ and $p = C q = \Theta(1)$ for a constant $C&gt;1$, the detection problem
is computationally easy while the recovery problem is hard for low-degree
algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Mao_C/0/1/0/all/0/1">Cheng Mao</a>, <a href="http://arxiv.org/find/math/1/au:+Wein_A/0/1/0/all/0/1">Alexander S. Wein</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_S/0/1/0/all/0/1">Shenduo Zhang</a></p><p>Planted dense cycles are a type of latent structure that appears in many
applications, such as small-world networks in social sciences and sequence
assembly in computational biology. We consider a model where a dense cycle with
expected bandwidth $n \tau$ and edge density $p$ is planted in an
Erd\H{o}s-R\'enyi graph $G(n,q)$. We characterize the computational thresholds
for the associated detection and recovery problems for the class of low-degree
polynomial algorithms. In particular, a gap exists between the two thresholds
in a certain regime of parameters. For example, if $n^{-3/4} \ll \tau \ll
n^{-1/2}$ and $p = C q = \Theta(1)$ for a constant $C&gt;1$, the detection problem
is computationally easy while the recovery problem is hard for low-degree
algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06760'>Random Majority Opinion Diffusion: Stabilization Time, Absorbing States, and Influential Nodes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ahad N. Zehmakan</p><p>Consider a graph G with n nodes and m edges, which represents a social
network, and assume that initially each node is blue or white. In each round,
all nodes simultaneously update their color to the most frequent color in their
neighborhood. This is called the Majority Model (MM) if a node keeps its color
in case of a tie and the Random Majority Model (RMM) if it chooses blue with
probability 1/2 and white otherwise.
</p>
<p>We prove that there are graphs for which RMM needs exponentially many rounds
to reach a stable configuration in expectation, and such a configuration can
have exponentially many states (i.e., colorings). This is in contrast to MM,
which is known to always reach a stable configuration with one or two states in
$O(m)$ rounds. For the special case of a cycle graph C_n, we prove the stronger
and tight bounds of $\lceil n/2\rceil-1$ and $O(n^2)$ in MM and RMM,
respectively. Furthermore, we show that the number of stable colorings in MM on
C_n is equal to $\Theta(\Phi^n)$, where $\Phi = (1+\sqrt{5})/2$ is the golden
ratio, while it is equal to 2 for RMM.
</p>
<p>We also study the minimum size of a winning set, which is a set of nodes
whose agreement on a color in the initial coloring enforces the process to end
in a coloring where all nodes share that color. We present tight bounds on the
minimum size of a winning set for both MM and RMM.
</p>
<p>Furthermore, we analyze our models for a random initial coloring, where each
node is colored blue independently with some probability $p$ and white
otherwise. Using some martingale analysis and counting arguments, we prove that
the expected final number of blue nodes is respectively equal to
$(2p^2-p^3)n/(1-p+p^2)$ and pn in MM and RMM on a cycle graph C_n.
</p>
<p>Finally, we conduct some experiments which complement our theoretical
findings and also lead to the proposal of some intriguing open problems and
conjectures to be tackled in future work.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zehmakan_A/0/1/0/all/0/1">Ahad N. Zehmakan</a></p><p>Consider a graph G with n nodes and m edges, which represents a social
network, and assume that initially each node is blue or white. In each round,
all nodes simultaneously update their color to the most frequent color in their
neighborhood. This is called the Majority Model (MM) if a node keeps its color
in case of a tie and the Random Majority Model (RMM) if it chooses blue with
probability 1/2 and white otherwise.
</p>
<p>We prove that there are graphs for which RMM needs exponentially many rounds
to reach a stable configuration in expectation, and such a configuration can
have exponentially many states (i.e., colorings). This is in contrast to MM,
which is known to always reach a stable configuration with one or two states in
$O(m)$ rounds. For the special case of a cycle graph C_n, we prove the stronger
and tight bounds of $\lceil n/2\rceil-1$ and $O(n^2)$ in MM and RMM,
respectively. Furthermore, we show that the number of stable colorings in MM on
C_n is equal to $\Theta(\Phi^n)$, where $\Phi = (1+\sqrt{5})/2$ is the golden
ratio, while it is equal to 2 for RMM.
</p>
<p>We also study the minimum size of a winning set, which is a set of nodes
whose agreement on a color in the initial coloring enforces the process to end
in a coloring where all nodes share that color. We present tight bounds on the
minimum size of a winning set for both MM and RMM.
</p>
<p>Furthermore, we analyze our models for a random initial coloring, where each
node is colored blue independently with some probability $p$ and white
otherwise. Using some martingale analysis and counting arguments, we prove that
the expected final number of blue nodes is respectively equal to
$(2p^2-p^3)n/(1-p+p^2)$ and pn in MM and RMM on a cycle graph C_n.
</p>
<p>Finally, we conduct some experiments which complement our theoretical
findings and also lead to the proposal of some intriguing open problems and
conjectures to be tackled in future work.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06832'>Improved Learning-Augmented Algorithms for the Multi-Option Ski Rental Problem via Best-Possible Competitive Analysis</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yongho Shin, Changyeol Lee, Gukryeol Lee, Hyung-Chan An</p><p>In this paper, we present improved learning-augmented algorithms for the
multi-option ski rental problem. Learning-augmented algorithms take ML
predictions as an added part of the input and incorporates these predictions in
solving the given problem. Due to their unique strength that combines the power
of ML predictions with rigorous performance guarantees, they have been
extensively studied in the context of online optimization problems. Even though
ski rental problems are one of the canonical problems in the field of online
optimization, only deterministic algorithms were previously known for
multi-option ski rental, with or without learning augmentation. We present the
first randomized learning-augmented algorithm for this problem, surpassing
previous performance guarantees given by deterministic algorithms. Our
learning-augmented algorithm is based on a new, provably best-possible
randomized competitive algorithm for the problem. Our results are further
complemented by lower bounds for deterministic and randomized algorithms, and
computational experiments evaluating our algorithms' performance improvements.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1">Yongho Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Changyeol Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gukryeol Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+An_H/0/1/0/all/0/1">Hyung-Chan An</a></p><p>In this paper, we present improved learning-augmented algorithms for the
multi-option ski rental problem. Learning-augmented algorithms take ML
predictions as an added part of the input and incorporates these predictions in
solving the given problem. Due to their unique strength that combines the power
of ML predictions with rigorous performance guarantees, they have been
extensively studied in the context of online optimization problems. Even though
ski rental problems are one of the canonical problems in the field of online
optimization, only deterministic algorithms were previously known for
multi-option ski rental, with or without learning augmentation. We present the
first randomized learning-augmented algorithm for this problem, surpassing
previous performance guarantees given by deterministic algorithms. Our
learning-augmented algorithm is based on a new, provably best-possible
randomized competitive algorithm for the problem. Our results are further
complemented by lower bounds for deterministic and randomized algorithms, and
computational experiments evaluating our algorithms' performance improvements.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06846'>Scheduling Coflows for Minimizing the Makespan in Identical Parallel Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jun Chen, Chi-Yeh Chen</p><p>With the development of technology, parallel computing applications have been
commonly executed in large data centers. These parallel computing applications
include the computation phase and communication phase, and work is completed by
repeatedly executing these two phases. However, due to the ever-increasing
computing demands, large data centers are burdened with massive communication
demands. Coflow is a recently proposed networking abstraction to capture
communication patterns in data-parallel computing frameworks. This paper
focuses on the coflow scheduling problem in identical parallel networks, where
the goal is to minimize makespan, the maximum completion time of coflows. The
coflow scheduling problem in huge data center is considered one of the most
significant $NP$-hard problems. In this paper, coflow can be considered as
either a divisible or an indivisible case. Distinct flows in a divisible coflow
can be transferred through different network cores, while those in an
indivisible coflow can only be transferred through the same network core. In
the divisible coflow scheduling problem, this paper proposes a
$(3-\tfrac{2}{m})$-approximation algorithm, and a
$(\tfrac{8}{3}-\tfrac{2}{3m})$-approximation algorithm, where $m$ is the number
of network cores. In the indivisible coflow scheduling problem, this paper
proposes a $(2m)$-approximation algorithm. Finally, we simulate our proposed
algorithm and Weaver's [Huang \textit{et al.}, In 2020 IEEE International
Parallel and Distributed Processing Symposium (IPDPS), pages 1071-1081, 2020.]
and compare the performance of our algorithms with that of Weaver's.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chi-Yeh Chen</a></p><p>With the development of technology, parallel computing applications have been
commonly executed in large data centers. These parallel computing applications
include the computation phase and communication phase, and work is completed by
repeatedly executing these two phases. However, due to the ever-increasing
computing demands, large data centers are burdened with massive communication
demands. Coflow is a recently proposed networking abstraction to capture
communication patterns in data-parallel computing frameworks. This paper
focuses on the coflow scheduling problem in identical parallel networks, where
the goal is to minimize makespan, the maximum completion time of coflows. The
coflow scheduling problem in huge data center is considered one of the most
significant $NP$-hard problems. In this paper, coflow can be considered as
either a divisible or an indivisible case. Distinct flows in a divisible coflow
can be transferred through different network cores, while those in an
indivisible coflow can only be transferred through the same network core. In
the divisible coflow scheduling problem, this paper proposes a
$(3-\tfrac{2}{m})$-approximation algorithm, and a
$(\tfrac{8}{3}-\tfrac{2}{3m})$-approximation algorithm, where $m$ is the number
of network cores. In the indivisible coflow scheduling problem, this paper
proposes a $(2m)$-approximation algorithm. Finally, we simulate our proposed
algorithm and Weaver's [Huang \textit{et al.}, In 2020 IEEE International
Parallel and Distributed Processing Symposium (IPDPS), pages 1071-1081, 2020.]
and compare the performance of our algorithms with that of Weaver's.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06878'>Distributed Symmetry Breaking on Power Graphs via Sparsification</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yannic Maus, Saku Peltonen, Jara Uitto</p><p>In this paper, we present efficient distributed algorithms for classical
symmetry breaking problems, maximal independent sets (MIS) and ruling sets, in
power graphs. We work in the standard CONGEST model of distributed message
passing, where the communication network is abstracted as a graph $G$.
Typically, the problem instance in CONGEST is identical to the communication
network $G$, that is, we perform the symmetry breaking in $G$. In this work, we
consider a setting where the problem instance corresponds to a power graph
$G^k$, where each node of the communication network $G$ is connected to all of
its $k$-hop neighbors. Our main contribution is a deterministic polylogarithmic
time algorithm for computing $k$-ruling sets of $G^k$, which (for $k&gt;1$)
improves exponentially on the current state-of-the-art runtimes. The main
technical ingredient for this result is a deterministic sparsification
procedure which may be of independent interest. On top of being a natural
family of problems, ruling sets (in power graphs) are well-motivated through
their applications in the powerful shattering framework [BEPS JACM'16, Ghaffari
SODA'19] (and others). We present randomized algorithms for computing maximal
independent sets and ruling sets of $G^k$ in essentially the same time as they
can be computed in $G$. We also revisit the shattering algorithm for MIS [BEPS
JACM'16] and present different approaches for the post-shattering phase. Our
solutions are algorithmically and analytically simpler (also in the LOCAL
model) than existing solutions and obtain the same runtime as [Ghaffari
SODA'16].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Maus_Y/0/1/0/all/0/1">Yannic Maus</a>, <a href="http://arxiv.org/find/cs/1/au:+Peltonen_S/0/1/0/all/0/1">Saku Peltonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Uitto_J/0/1/0/all/0/1">Jara Uitto</a></p><p>In this paper, we present efficient distributed algorithms for classical
symmetry breaking problems, maximal independent sets (MIS) and ruling sets, in
power graphs. We work in the standard CONGEST model of distributed message
passing, where the communication network is abstracted as a graph $G$.
Typically, the problem instance in CONGEST is identical to the communication
network $G$, that is, we perform the symmetry breaking in $G$. In this work, we
consider a setting where the problem instance corresponds to a power graph
$G^k$, where each node of the communication network $G$ is connected to all of
its $k$-hop neighbors. Our main contribution is a deterministic polylogarithmic
time algorithm for computing $k$-ruling sets of $G^k$, which (for $k&gt;1$)
improves exponentially on the current state-of-the-art runtimes. The main
technical ingredient for this result is a deterministic sparsification
procedure which may be of independent interest. On top of being a natural
family of problems, ruling sets (in power graphs) are well-motivated through
their applications in the powerful shattering framework [BEPS JACM'16, Ghaffari
SODA'19] (and others). We present randomized algorithms for computing maximal
independent sets and ruling sets of $G^k$ in essentially the same time as they
can be computed in $G$. We also revisit the shattering algorithm for MIS [BEPS
JACM'16] and present different approaches for the post-shattering phase. Our
solutions are algorithmically and analytically simpler (also in the LOCAL
model) than existing solutions and obtain the same runtime as [Ghaffari
SODA'16].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06889'>Worst Case and Probabilistic Analysis of the 2-Opt Algorithm for the TSP</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Matthias Englert, Heiko R&#xf6;glin, Berthold V&#xf6;cking</p><p>2-Opt is probably the most basic local search heuristic for the TSP. This
heuristic achieves amazingly good results on real world Euclidean instances
both with respect to running time and approximation ratio. There are numerous
experimental studies on the performance of 2-Opt. However, the theoretical
knowledge about this heuristic is still very limited. Not even its worst case
running time on 2-dimensional Euclidean instances was known so far. We clarify
this issue by presenting, for every $p\in\mathbb{N}$, a family of $L_p$
instances on which 2-Opt can take an exponential number of steps.
</p>
<p>Previous probabilistic analyses were restricted to instances in which $n$
points are placed uniformly at random in the unit square $[0,1]^2$. We consider
a more advanced model in which the points can be placed independently according
to general distributions on $[0,1]^d$, for an arbitrary $d\ge 2$. In
particular, we allow different distributions for different points. We study the
expected number of local improvements in terms of the number $n$ of points and
the maximal density $\phi$ of the probability distributions. We show an upper
bound on the expected length of any 2-Opt improvement path of
$\tilde{O}(n^{4+1/3}\cdot\phi^{8/3})$. When starting with an initial tour
computed by an insertion heuristic, the upper bound on the expected number of
steps improves even to $\tilde{O}(n^{4+1/3-1/d}\cdot\phi^{8/3})$. If the
distances are measured according to the Manhattan metric, then the expected
number of steps is bounded by $\tilde{O}(n^{4-1/d}\cdot\phi)$. In addition, we
prove an upper bound of $O(\sqrt[d]{\phi})$ on the expected approximation
factor with respect to all $L_p$ metrics.
</p>
<p>Let us remark that our probabilistic analysis covers as special cases the
uniform input model with $\phi=1$ and a smoothed analysis with Gaussian
perturbations of standard deviation $\sigma$ with $\phi\sim1/\sigma^d$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Englert_M/0/1/0/all/0/1">Matthias Englert</a>, <a href="http://arxiv.org/find/cs/1/au:+Roglin_H/0/1/0/all/0/1">Heiko R&#xf6;glin</a>, <a href="http://arxiv.org/find/cs/1/au:+Vocking_B/0/1/0/all/0/1">Berthold V&#xf6;cking</a></p><p>2-Opt is probably the most basic local search heuristic for the TSP. This
heuristic achieves amazingly good results on real world Euclidean instances
both with respect to running time and approximation ratio. There are numerous
experimental studies on the performance of 2-Opt. However, the theoretical
knowledge about this heuristic is still very limited. Not even its worst case
running time on 2-dimensional Euclidean instances was known so far. We clarify
this issue by presenting, for every $p\in\mathbb{N}$, a family of $L_p$
instances on which 2-Opt can take an exponential number of steps.
</p>
<p>Previous probabilistic analyses were restricted to instances in which $n$
points are placed uniformly at random in the unit square $[0,1]^2$. We consider
a more advanced model in which the points can be placed independently according
to general distributions on $[0,1]^d$, for an arbitrary $d\ge 2$. In
particular, we allow different distributions for different points. We study the
expected number of local improvements in terms of the number $n$ of points and
the maximal density $\phi$ of the probability distributions. We show an upper
bound on the expected length of any 2-Opt improvement path of
$\tilde{O}(n^{4+1/3}\cdot\phi^{8/3})$. When starting with an initial tour
computed by an insertion heuristic, the upper bound on the expected number of
steps improves even to $\tilde{O}(n^{4+1/3-1/d}\cdot\phi^{8/3})$. If the
distances are measured according to the Manhattan metric, then the expected
number of steps is bounded by $\tilde{O}(n^{4-1/d}\cdot\phi)$. In addition, we
prove an upper bound of $O(\sqrt[d]{\phi})$ on the expected approximation
factor with respect to all $L_p$ metrics.
</p>
<p>Let us remark that our probabilistic analysis covers as special cases the
uniform input model with $\phi=1$ and a smoothed analysis with Gaussian
perturbations of standard deviation $\sigma$ with $\phi\sim1/\sigma^d$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.06983'>Grouped Domination Parameterized by Vertex Cover, Twin Cover, and Beyond</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tesshu Hanaka, Hirotaka Ono, Yota Otachi, Saeki Uda</p><p>A dominating set $S$ of graph $G$ is called an $r$-grouped dominating set if
$S$ can be partitioned into $S_1,S_2,\ldots,S_k$ such that the size of each
unit $S_i$ is $r$ and the subgraph of $G$ induced by $S_i$ is connected. The
concept of $r$-grouped dominating sets generalizes several well-studied
variants of dominating sets with requirements for connected component sizes,
such as the ordinary dominating sets ($r=1$), paired dominating sets ($r=2$),
and connected dominating sets ($r$ is arbitrary and $k=1$). In this paper, we
investigate the computational complexity of $r$-Grouped Dominating Set, which
is the problem of deciding whether a given graph has an $r$-grouped dominating
set with at most $k$ units. For general $r$, the problem is hard to solve in
various senses because the hardness of the connected dominating set is
inherited. We thus focus on the case in which $r$ is a constant or a parameter,
but we see that the problem for every fixed $r&gt;0$ is still hard to solve. From
the hardness, we consider the parameterized complexity concerning well-studied
graph structural parameters. We first see that it is fixed-parameter tractable
for $r$ and treewidth, because the condition of $r$-grouped domination for a
constant $r$ can be represented as monadic second-order logic (mso2). This is
good news, but the running time is not practical. We then design an
$O^*(\min\{(2\tau(r+1))^{\tau},(2\tau)^{2\tau}\})$-time algorithm for general
$r\ge 2$, where $\tau$ is the twin cover number, which is a parameter between
vertex cover number and clique-width. For paired dominating set and trio
dominating set, i.e., $r \in \{2,3\}$, we can speed up the algorithm, whose
running time becomes $O^*((r+1)^\tau)$. We further argue the relationship
between FPT results and graph parameters, which draws the parameterized
complexity landscape of $r$-Grouped Dominating Set.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hanaka_T/0/1/0/all/0/1">Tesshu Hanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Ono_H/0/1/0/all/0/1">Hirotaka Ono</a>, <a href="http://arxiv.org/find/cs/1/au:+Otachi_Y/0/1/0/all/0/1">Yota Otachi</a>, <a href="http://arxiv.org/find/cs/1/au:+Uda_S/0/1/0/all/0/1">Saeki Uda</a></p><p>A dominating set $S$ of graph $G$ is called an $r$-grouped dominating set if
$S$ can be partitioned into $S_1,S_2,\ldots,S_k$ such that the size of each
unit $S_i$ is $r$ and the subgraph of $G$ induced by $S_i$ is connected. The
concept of $r$-grouped dominating sets generalizes several well-studied
variants of dominating sets with requirements for connected component sizes,
such as the ordinary dominating sets ($r=1$), paired dominating sets ($r=2$),
and connected dominating sets ($r$ is arbitrary and $k=1$). In this paper, we
investigate the computational complexity of $r$-Grouped Dominating Set, which
is the problem of deciding whether a given graph has an $r$-grouped dominating
set with at most $k$ units. For general $r$, the problem is hard to solve in
various senses because the hardness of the connected dominating set is
inherited. We thus focus on the case in which $r$ is a constant or a parameter,
but we see that the problem for every fixed $r&gt;0$ is still hard to solve. From
the hardness, we consider the parameterized complexity concerning well-studied
graph structural parameters. We first see that it is fixed-parameter tractable
for $r$ and treewidth, because the condition of $r$-grouped domination for a
constant $r$ can be represented as monadic second-order logic (mso2). This is
good news, but the running time is not practical. We then design an
$O^*(\min\{(2\tau(r+1))^{\tau},(2\tau)^{2\tau}\})$-time algorithm for general
$r\ge 2$, where $\tau$ is the twin cover number, which is a parameter between
vertex cover number and clique-width. For paired dominating set and trio
dominating set, i.e., $r \in \{2,3\}$, we can speed up the algorithm, whose
running time becomes $O^*((r+1)^\tau)$. We further argue the relationship
between FPT results and graph parameters, which draws the parameterized
complexity landscape of $r$-Grouped Dominating Set.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07029'>Advances on Strictly $\Delta$-Modular IPs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Martin N&#xe4;gele, Christian N&#xf6;bel, Richard Santiago, Rico Zenklusen</p><p>There has been significant work recently on integer programs (IPs)
$\min\{c^\top x \colon Ax\leq b,\,x\in \mathbb{Z}^n\}$ with a constraint marix
$A$ with bounded subdeterminants. This is motivated by a well-known conjecture
claiming that, for any constant $\Delta\in \mathbb{Z}_{&gt;0}$, $\Delta$-modular
IPs are efficiently solvable, which are IPs where the constraint matrix $A\in
\mathbb{Z}^{m\times n}$ has full column rank and all $n\times n$ minors of $A$
are within $\{-\Delta, \dots, \Delta\}$. Previous progress on this question, in
particular for $\Delta=2$, relies on algorithms that solve an important special
case, namely strictly $\Delta$-modular IPs, which further restrict the $n\times
n$ minors of $A$ to be within $\{-\Delta, 0, \Delta\}$. Even for $\Delta=2$,
such problems include well-known combinatorial optimization problems like the
minimum odd/even cut problem. The conjecture remains open even for strictly
$\Delta$-modular IPs. Prior advances were restricted to prime $\Delta$, which
allows for employing strong number-theoretic results.
</p>
<p>In this work, we make first progress beyond the prime case by presenting
techniques not relying on such strong number-theoretic prime results. In
particular, our approach implies that there is a randomized algorithm to check
feasibility of strictly $\Delta$-modular IPs in strongly polynomial time if
$\Delta\leq4$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nagele_M/0/1/0/all/0/1">Martin N&#xe4;gele</a>, <a href="http://arxiv.org/find/cs/1/au:+Nobel_C/0/1/0/all/0/1">Christian N&#xf6;bel</a>, <a href="http://arxiv.org/find/cs/1/au:+Santiago_R/0/1/0/all/0/1">Richard Santiago</a>, <a href="http://arxiv.org/find/cs/1/au:+Zenklusen_R/0/1/0/all/0/1">Rico Zenklusen</a></p><p>There has been significant work recently on integer programs (IPs)
$\min\{c^\top x \colon Ax\leq b,\,x\in \mathbb{Z}^n\}$ with a constraint marix
$A$ with bounded subdeterminants. This is motivated by a well-known conjecture
claiming that, for any constant $\Delta\in \mathbb{Z}_{&gt;0}$, $\Delta$-modular
IPs are efficiently solvable, which are IPs where the constraint matrix $A\in
\mathbb{Z}^{m\times n}$ has full column rank and all $n\times n$ minors of $A$
are within $\{-\Delta, \dots, \Delta\}$. Previous progress on this question, in
particular for $\Delta=2$, relies on algorithms that solve an important special
case, namely strictly $\Delta$-modular IPs, which further restrict the $n\times
n$ minors of $A$ to be within $\{-\Delta, 0, \Delta\}$. Even for $\Delta=2$,
such problems include well-known combinatorial optimization problems like the
minimum odd/even cut problem. The conjecture remains open even for strictly
$\Delta$-modular IPs. Prior advances were restricted to prime $\Delta$, which
allows for employing strong number-theoretic results.
</p>
<p>In this work, we make first progress beyond the prime case by presenting
techniques not relying on such strong number-theoretic prime results. In
particular, our approach implies that there is a randomized algorithm to check
feasibility of strictly $\Delta$-modular IPs in strongly polynomial time if
$\Delta\leq4$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07168'>Arc-Flags Meet Trip-Based Public Transit Routing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ernestine Gro&#xdf;mann, Jonas Sauer, Christian Schulz, Patrick Steil</p><p>We present Arc-Flag TB, a journey planning algorithm for public transit
networks which combines Trip-Based Public Transit Routing (TB) with the
Arc-Flags speedup technique. Compared to previous attempts to apply Arc-Flags
to public transit networks, which saw limited success, our approach uses
stronger pruning rules to reduce the search space. Our experiments show that
Arc-Flag TB achieves a speedup of up to two orders of magnitude over TB,
offering query times of less than a millisecond even on large countrywide
networks. Compared to the state-of-the-art speedup technique Trip-Based Public
Transit Routing Using Condensed Search Trees (TB-CST), our algorithm achieves
similar query times but requires significantly less additional memory. Other
state-of-the-art algorithms which achieve even faster query times, e.g., Public
Transit Labeling, require enormous memory usage. In contrast, Arc-Flag TB
offers a tradeoff between query performance and memory usage due to the fact
that the number of regions in the network partition required by our algorithm
is a configurable parameter. We also identify an issue in the transfer
precomputation of TB that affects both TB-CST and Arc-Flag TB, leading to
incorrect answers for some queries. This has not been previously recognized by
the author of TB-CST. We provide discussion on how to resolve this issue in the
future. Currently, Arc-Flag TB answers 1-6% of queries incorrectly, compared to
over 20% for TB-CST on some networks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grossmann_E/0/1/0/all/0/1">Ernestine Gro&#xdf;mann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sauer_J/0/1/0/all/0/1">Jonas Sauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schulz_C/0/1/0/all/0/1">Christian Schulz</a>, <a href="http://arxiv.org/find/cs/1/au:+Steil_P/0/1/0/all/0/1">Patrick Steil</a></p><p>We present Arc-Flag TB, a journey planning algorithm for public transit
networks which combines Trip-Based Public Transit Routing (TB) with the
Arc-Flags speedup technique. Compared to previous attempts to apply Arc-Flags
to public transit networks, which saw limited success, our approach uses
stronger pruning rules to reduce the search space. Our experiments show that
Arc-Flag TB achieves a speedup of up to two orders of magnitude over TB,
offering query times of less than a millisecond even on large countrywide
networks. Compared to the state-of-the-art speedup technique Trip-Based Public
Transit Routing Using Condensed Search Trees (TB-CST), our algorithm achieves
similar query times but requires significantly less additional memory. Other
state-of-the-art algorithms which achieve even faster query times, e.g., Public
Transit Labeling, require enormous memory usage. In contrast, Arc-Flag TB
offers a tradeoff between query performance and memory usage due to the fact
that the number of regions in the network partition required by our algorithm
is a configurable parameter. We also identify an issue in the transfer
precomputation of TB that affects both TB-CST and Arc-Flag TB, leading to
incorrect answers for some queries. This has not been previously recognized by
the author of TB-CST. We provide discussion on how to resolve this issue in the
future. Currently, Arc-Flag TB answers 1-6% of queries incorrectly, compared to
over 20% for TB-CST on some networks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07235'>Compressibility-Aware Quantum Algorithms on Strings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Gibney, Sharma V. Thankachan</p><p>Sublinear time quantum algorithms have been established for many fundamental
problems on strings. This work demonstrates that new, faster quantum algorithms
can be designed when the string is highly compressible. We focus on two popular
and theoretically significant compression algorithms -- the Lempel-Ziv77
algorithm (LZ77) and the Run-length-encoded Burrows-Wheeler Transform (RL-BWT),
and obtain the results below.
</p>
<p>We first provide a quantum algorithm running in $\tilde{O}(\sqrt{zn})$ time
for finding the LZ77 factorization of an input string $T[1..n]$ with $z$
factors. Combined with multiple existing results, this yields an
$\tilde{O}(\sqrt{rn})$ time quantum algorithm for finding the RL-BWT encoding
with $r$ BWT runs. Note that $r = \tilde{\Theta}(z)$. We complement these
results with lower bounds proving that our algorithms are optimal (up to
polylog factors).
</p>
<p>Next, we study the problem of compressed indexing, where we provide a
$\tilde{O}(\sqrt{rn})$ time quantum algorithm for constructing a recently
designed $\tilde{O}(r)$ space structure with equivalent capabilities as the
suffix tree. This data structure is then applied to numerous problems to obtain
sublinear time quantum algorithms when the input is highly compressible. For
example, we show that the longest common substring of two strings of total
length $n$ can be computed in $\tilde{O}(\sqrt{zn})$ time, where $z$ is the
number of factors in the LZ77 factorization of their concatenation. This beats
the best known $\tilde{O}(n^\frac{2}{3})$ time quantum algorithm when $z$ is
sufficiently small.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gibney_D/0/1/0/all/0/1">Daniel Gibney</a>, <a href="http://arxiv.org/find/cs/1/au:+Thankachan_S/0/1/0/all/0/1">Sharma V. Thankachan</a></p><p>Sublinear time quantum algorithms have been established for many fundamental
problems on strings. This work demonstrates that new, faster quantum algorithms
can be designed when the string is highly compressible. We focus on two popular
and theoretically significant compression algorithms -- the Lempel-Ziv77
algorithm (LZ77) and the Run-length-encoded Burrows-Wheeler Transform (RL-BWT),
and obtain the results below.
</p>
<p>We first provide a quantum algorithm running in $\tilde{O}(\sqrt{zn})$ time
for finding the LZ77 factorization of an input string $T[1..n]$ with $z$
factors. Combined with multiple existing results, this yields an
$\tilde{O}(\sqrt{rn})$ time quantum algorithm for finding the RL-BWT encoding
with $r$ BWT runs. Note that $r = \tilde{\Theta}(z)$. We complement these
results with lower bounds proving that our algorithms are optimal (up to
polylog factors).
</p>
<p>Next, we study the problem of compressed indexing, where we provide a
$\tilde{O}(\sqrt{rn})$ time quantum algorithm for constructing a recently
designed $\tilde{O}(r)$ space structure with equivalent capabilities as the
suffix tree. This data structure is then applied to numerous problems to obtain
sublinear time quantum algorithms when the input is highly compressible. For
example, we show that the longest common substring of two strings of total
length $n$ can be computed in $\tilde{O}(\sqrt{zn})$ time, where $z$ is the
number of factors in the LZ77 factorization of their concatenation. This beats
the best known $\tilde{O}(n^\frac{2}{3})$ time quantum algorithm when $z$ is
sufficiently small.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.07263'>Interpolation Learning With Minimum Description Length</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Naren Sarayu Manoj, Nathan Srebro</p><p>We prove that the Minimum Description Length learning rule exhibits tempered
overfitting. We obtain tempered agnostic finite sample learning guarantees and
characterize the asymptotic behavior in the presence of random label noise.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Manoj_N/0/1/0/all/0/1">Naren Sarayu Manoj</a>, <a href="http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1">Nathan Srebro</a></p><p>We prove that the Minimum Description Length learning rule exhibits tempered
overfitting. We obtain tempered agnostic finite sample learning guarantees and
characterize the asymptotic behavior in the presence of random label noise.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-15T01:30:00Z">Wednesday, February 15 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, February 14
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/14/visiting-assistant-professor-in-computer-science-at-claremont-mckenna-college-apply-by-march-1-2023/'>Visiting Assistant Professor in Computer Science at Claremont McKenna College (apply by March 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The candidate must have a demonstrated ability in research or industry experience and be able to maintain the highest standards of excellence in teaching. While all areas of CS are welcome to apply, extra consideration will be given to those able to teach machine learning courses. The teaching load is five courses per year. This [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The candidate must have a demonstrated ability in research or industry experience and be able to maintain the highest standards of excellence in teaching. While all areas of CS are welcome to apply, extra consideration will be given to those able to teach machine learning courses. The teaching load is five courses per year. This is a two-year, non-tenure track position, beginning July 1, 2023.</p>
<p>Website: <a href="https://webapps.cmc.edu/jobs/faculty/faculty_opening_detail.php?PostingID=17006">https://webapps.cmc.edu/jobs/faculty/faculty_opening_detail.php?PostingID=17006</a><br />
Email: sarah.cannon@cmc.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T22:27:26Z">Tuesday, February 14 2023, 22:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7028'>Visas for Chinese students: US shoots itself in the foot again</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Coming out of blog-hiatus for some important stuff, today, tomorrow, and the rest of the week. Something distressing happened to me yesterday for the first time, but I fear not the last. We (UT Austin) admitted a PhD student from China who I know to be excellent, and who wanted to work with me. That [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Coming out of blog-hiatus for some important stuff, today, tomorrow, and the rest of the week.</p>



<p>Something distressing happened to me yesterday for the first time, but I fear not the last.  We (UT Austin) admitted a PhD student from China who I know to be excellent, and who wanted to work with me. That student, alas, has had to decline our offer of admission, because he&#8217;s been denied a US visa under Section 212(A)(3)(a)(i), which &#8220;prohibits the issuance of a visa to anyone who seeks to enter the United States to violate or evade any law prohibiting the export from the United States of goods, technology, or sensitive information.&#8221;  Quantum computing, you see, is now a &#8220;prohibited technology.&#8221;</p>



<p>This visa denial is actually one that the American embassy in Beijing only just now got around to issuing, from when the student applied for a US visa <em>a year and a half ago,</em> to come visit me for a semester as an undergrad.  For context, the last time I had an undergrad from China visit me for a semester, back in 2016, the undergrad&#8217;s name was <a href="https://www.mit.edu/~lijieche/">Lijie Chen</a>.  Lijie just finished his PhD at MIT under Ryan Williams and is now one of the superstars of theoretical computer science.  Anyway, in Fall 2021 I got an inquiry from a Chinese student who bowled me over the same way Lijie had, so I invited him to spend a semester with my group in Austin.  This time, alas, the student never heard back when he applied for a visa, and was therefore unable to come.  He ended up doing an excellent research project with me anyway, working remotely from China, checking in by Zoom, and even participating in our research group meetings (which were on Zoom anyway because of the pandemic).</p>



<p>Anyway, for reasons too complicated to explain, this previous denial means that the student would almost certainly be denied for a <em>new</em> visa to come to the US to do a PhD in quantum computing.  (Unless some immigration lawyer reading this can suggest a way out!)  The student is not sure what he&#8217;s going to do next, but it might involve staying in China, or applying in Europe, or applying in the US again after a year but without mentioning the word &#8220;quantum.&#8221;</p>



<p>It should go without saying, to anyone reading this, that the student wants to do basic research in quantum complexity theory that&#8217;s <em>extraordinarily</em> unlikely to have any direct military or economic importance … just like my own research! <img decoding="async" loading="lazy" height="16" width="16" src="https://static.xx.fbcdn.net/images/emoji.php/v9/ta5/1.5/16/1f642.png" alt="&#x1f642;"> And it should also go without saying that, if the US really wanted to strike a blow against authoritarianism in Beijing, then it could hardly do better than to hand out visas to every Chinese STEM student and researcher who wanted to come here.  Yes, some would return to China with their new skills, but a great many would choose to stay in the US &#8230; <em>if we let them</em>.</p>



<p>And I’ve pointed all this out to a Republican Congressman, and to people in the military and intelligence agencies, when they asked me “what else the US can do to win the quantum computing race against China?”  And I’ll continue to say it to anyone who asks.  The Congressman, incidentally, even said that he privately agreed with me, but that the issue was politically difficult.  I wonder: is there anyone in power in the US, in either party, who <em>doesn&#8217;t</em> privately agree that opening the gates to China&#8217;s STEM talent would be a win/win proposition for the US &#8230; <em>including for the US&#8217;s national security</em>?  If so, who are these people?  Is this just a naked-emperor situation, where everyone in Congress fears to raise the issue because they fear backlash from someone else, but the someone else is actually thinking the same way?</p>



<p>And to any American who says, &#8220;yeah, but China totally deserves it, because of that spy balloon, and their threats against Taiwan, and all the spying they do with TikTok&#8221;&#8212;I mean, like, imagine if someone tried to get back at the US government for the Iraq War or for CIA psyops or whatever else by punishing <em>you</em>, by curtailing <em>your</em> academic dreams.  It would make exactly as much sense.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T22:18:42Z">Tuesday, February 14 2023, 22:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/010'>TR23-010 |  Sum-of-Squares Lower Bounds for the Minimum Circuit Size Problem | 

	Per Austrin, 

	Kilian Risse</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We prove lower bounds for the Minimum Circuit Size Problem (MCSP) in the Sum-of-Squares (SoS) proof system.  Our main result is that for every Boolean function $f: \{0,1\}^n \rightarrow \{0,1\}$, SoS requires degree $\Omega(s^{1-\epsilon})$ to prove that $f$ does not have circuits of size $s$ (for any $s &gt; \text{poly}(n)$).  As a corollary we obtain that there are no low degree SoS proofs of the statement $\text{NP} \not \subseteq \text{P/poly}$.

We also show that for any $0 &lt; \alpha &lt; 1$ there are Boolean functions with circuit complexity larger than $2^{n^{\alpha}}$ but SoS requires size $2^{2^{\Omega(n^{\alpha})}}$ to prove this. In addition we prove analogous results on the minimum monotone circuit size for monotone Boolean slice functions.

Our approach is quite general.  Namely, we show that if a proof system $Q$ has strong enough constraint satisfaction problem lower bounds that only depend on good expansion of the constraint-variable incidence graph and, furthermore, $Q$ is expressive enough that variables can be substituted by local Boolean functions, then the MCSP problem is hard for $Q$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We prove lower bounds for the Minimum Circuit Size Problem (MCSP) in the Sum-of-Squares (SoS) proof system.  Our main result is that for every Boolean function $f: \{0,1\}^n \rightarrow \{0,1\}$, SoS requires degree $\Omega(s^{1-\epsilon})$ to prove that $f$ does not have circuits of size $s$ (for any $s &gt; \text{poly}(n)$).  As a corollary we obtain that there are no low degree SoS proofs of the statement $\text{NP} \not \subseteq \text{P/poly}$.

We also show that for any $0 &lt; \alpha &lt; 1$ there are Boolean functions with circuit complexity larger than $2^{n^{\alpha}}$ but SoS requires size $2^{2^{\Omega(n^{\alpha})}}$ to prove this. In addition we prove analogous results on the minimum monotone circuit size for monotone Boolean slice functions.

Our approach is quite general.  Namely, we show that if a proof system $Q$ has strong enough constraint satisfaction problem lower bounds that only depend on good expansion of the constraint-variable incidence graph and, furthermore, $Q$ is expressive enough that variables can be substituted by local Boolean functions, then the MCSP problem is hard for $Q$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-14T19:22:46Z">Tuesday, February 14 2023, 19:22</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
