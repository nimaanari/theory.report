<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-04-28T17:30:31Z">Friday, April 28 2023, 17:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, April 28
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/04/28/tcs-talk-wednesday-may-3-scott-aaronson-ut-austin/'>TCS+ talk: Wednesday, May 3 — Scott Aaronson, UT Austin</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, May 3rd at 2:30 PM Eastern Time (11:30 AM Pacific Time, 20:30 Central European Time, 18:30 UTC: note the unusual time!). Scott Aaronson from UT Austin will speak about &#8220;Certified Randomness from Quantum Supremacy&#8221; (abstract below). You can reserve a spot as an individual or [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, May 3rd at 2:30 PM Eastern Time (11:30 AM Pacific Time, 20:30 Central European Time, 18:30 UTC: <strong>note the unusual time!</strong>). <strong>Scott Aaronson</strong> from UT Austin will speak about &#8220;<em>Certified Randomness from Quantum Supremacy</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: We propose an application for near-term quantum devices: namely, generating cryptographically certified random bits, to use (for example) in proof-of-stake cryptocurrencies. Our protocol repurposes the existing &#8220;quantum supremacy&#8221; experiments, based on random circuit sampling, that Google and USTC have successfully carried out starting in 2019. We show that, whenever the outputs of these experiments pass the now-standard Linear Cross-Entropy Benchmark (LXEB), under plausible hardness assumptions they necessarily contain Ω(n) min-entropy, where n is the number of qubits. To achieve a net gain in randomness, we use a small random seed to produce pseudorandom challenge circuits. In response to the challenge circuits, the quantum computer generates output strings that, after verification, can then be fed into a randomness extractor to produce certified nearly-uniform bits &#8212; thereby &#8220;bootstrapping&#8221; from pseudorandomness to genuine randomness. We prove our protocol sound in two senses: (i) under a hardness assumption called Long List Quantum Supremacy Verification, which we justify in the random oracle model, and (ii) unconditionally in the random oracle model against an eavesdropper who could share arbitrary entanglement with the device. (Note that our protocol&#8217;s output is unpredictable even to a computationally unbounded adversary who can see the random oracle.) Currently, the central drawback of our protocol is the exponential cost of verification, which in practice will limit its implementation to at most n∼60 qubits, a regime where attacks are expensive but not impossible. Modulo that drawback, our protocol appears to be the only practical application of quantum computing that both requires a QC and is physically realizable today.</p>
<p>Joint work with Shih-Han Hung. To appear in STOC&#8217;2023.<br />
<a href="https://arxiv.org/abs/2303.01625">https://arxiv.org/abs/2303.01625</a></p></blockquote>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T10:27:46Z">Friday, April 28 2023, 10:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7266'>Five Worlds of AI (a joint post with Boaz Barak)</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Artificial intelligence has made incredible progress in the last decade, but in one crucial aspect, it still lags behind the theoretical computer science of the 1990s: namely, there is no essay describing five potential worlds that we could live in and giving each one of them whimsical names.&#160; In other words, no one has done [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="https://www.scottaaronson.com/fiveworlds.jpg" alt=""/></figure></div>


<p>Artificial intelligence has made incredible progress in the last decade, but in one crucial aspect, it still lags behind the theoretical computer science of the 1990s: namely, there is no <a href="https://www.quantamagazine.org/which-computational-universe-do-we-live-in-20220418/">essay describing five potential worlds that we could live in and giving each one of them whimsical names</a>.&nbsp; In other words, no one has done for AI what Russell Impagliazzo did for complexity theory in 1995, when he defined the five worlds Algorithmica, Heuristica, Pessiland, Minicrypt, and Cryptomania, corresponding to five possible resolutions of the P vs. NP problem along with the central unsolved problems of cryptography.</p>



<p>In this blog post, we&#8212;Scott and Boaz&#8212;aim to remedy this gap.  Specifically, we consider 5 possible scenarios for how AI will evolve in the future.&nbsp; (Incidentally, it was at a <a href="http://dimacs.rutgers.edu/archive/Workshops/Cryptography/program.html">2009 workshop</a> devoted to Impagliazzo’s five worlds co-organized by Boaz that Scott met his now wife, complexity theorist <a href="https://www.cs.utexas.edu/~danama/">Dana Moshkovitz</a>.&nbsp; We hope civilization will continue for long enough that someone in the future could meet their soulmate, or neuron-mate,&nbsp;at a future workshop about <em>our</em> five worlds.)</p>



<p>Like in <a href="https://www.karlin.mff.cuni.cz/~krajicek/ri5svetu.pdf">Impagliazzo’s 1995 paper</a> on the five potential worlds of the difficulty of NP problems, we will not try to be exhaustive but rather concentrate on extreme cases.&nbsp; It’s possible that we’ll end up in a mixture of worlds or a situation not described by any of the worlds.&nbsp; Indeed, one crucial difference between our setting and Impagliazzo’s, is that in the complexity case, the worlds corresponded to concrete (and mutually exclusive) mathematical conjectures.&nbsp; So in some sense, the question wasn’t “which world <em>will</em> we live in?” but “which world have we Platonically <em>always</em> lived in, without knowing it?”&nbsp; In contrast, the impact of AI will be a complex mix of mathematical bounds, computational capabilities, human discoveries, and social and legal issues. Hence, the worlds we describe depend on more than just the fundamental capabilities and limitations of artificial intelligence, and humanity could also shift from one of these worlds to another over time.</p>



<p>Without further ado, we name our five worlds “<strong>AI-Fizzle,”</strong> <strong>“Futurama,”</strong> <strong>”AI-Dystopia,”</strong> <strong>“Singularia,”</strong> and <strong>“Paperclipalypse.”</strong>&nbsp; In this essay, we don’t try to assign probabilities to these scenarios; we merely sketch their assumptions and technical and social consequences. We hope that by making assumptions explicit, we can help ground the debate on the various risks around AI.</p>



<p><strong>AI-Fizzle. </strong>In this scenario, AI “runs out of steam” fairly soon. AI still has a significant impact on the world (so it’s not the same as a “cryptocurrency fizzle”), but relative to current expectations, this would be considered a disappointment.&nbsp; Rather than the industrial or computer revolutions, AI might be compared in this case to nuclear power: people were initially thrilled about the seemingly limitless potential, but decades later, that potential remains mostly unrealized.&nbsp; With nuclear power, though, many would argue that the potential went unrealized mostly for sociopolitical rather than technical reasons.&nbsp; Could AI also fizzle by political fiat?</p>



<p>Regardless of the answer, another possibility is that costs (in data and computation) scale up so rapidly as a function of performance and reliability that AI is not cost-effective to apply in many domains. That is, it could be that for most jobs, humans will still be more reliable and energy-efficient (we don’t normally think of <em>low wattage</em> as being key to human specialness, but it might turn out that way!).&nbsp; So, like nuclear fusion, an AI which yields dramatically more value than the resources needed to build and deploy it might always remain a couple of decades in the future.&nbsp; In this scenario, AI would replace and enhance some fraction of human jobs and improve productivity, but the 21st century would not be the “century of AI,” and AI’s impact on society would be limited for both good and bad.</p>



<p><strong>Futurama.</strong> In this scenario, AI unleashes a revolution that’s entirely comparable to the scientific, industrial, or information revolutions (but “merely” those).  AI systems grow significantly in capabilities and perform many of the tasks currently performed by human experts at a small fraction of the cost, in some domains <em>superhumanly</em>.  However, AI systems are still used as <em>tools</em> by humans, and except for a few fringe thinkers, no one treats them as sentient.  AI easily passes the Turing test, can prove hard theorems, and can generate entertaining content (as well as deepfakes). But humanity gets used to that, just like we got used to computers creaming us in chess, translating text, and generating special effects in movies.  Most people no more feel inferior to their AI than they feel inferior to their car because it runs faster.  In this scenario, people will likely anthropomorphize AI <em>less</em> over time (as happened with digital computers themselves).  In <strong>“Futurama,”</strong> AI will, like any revolutionary technology, be used for both good and bad.  But as with prior major technological revolutions, on the whole, AI will have a large positive impact on humanity.  AI will be used to reduce poverty and ensure that more of humanity has access to food, healthcare, education, and economic opportunities.  In <strong>“Futurama,”</strong> AI systems will sometimes cause harm, but the vast majority of these failures will be due to human negligence or maliciousness.  Some AI systems might be so complex that it would be best to model them as potentially behaving  “adversarially,” and part of the practice of deploying AIs responsibly would be to ensure an “operating envelope” that limits their potential damage even under adversarial failures. </p>



<p><strong>AI-Dystopia.</strong> The technical assumptions of <strong>“AI-Dystopia”</strong> are similar to those of <strong>“Futurama,”</strong> but the upshot could hardly be more different.&nbsp; Here, again, AI unleashes a revolution on the scale of the industrial or computer revolutions, but the change is markedly for the worse.&nbsp; AI greatly increases the scale of surveillance by government and private corporations.&nbsp; It causes massive job losses while enriching a tiny elite.&nbsp; It entrenches society’s existing inequalities and biases.&nbsp; And it takes away a central tool against oppression: namely, the ability of humans to refuse or subvert orders.</p>



<p>Interestingly, it’s even possible that <em>the same future</em> could be characterized as <strong>Futurama</strong> by some people and as <strong>AI-Dystopia</strong> by others–just like how some people emphasize how our <em>current</em> technological civilization has lifted billions out of poverty into a standard of living unprecedented in human history, while others focus on the still existing (and in some cases rising) inequalities and suffering, and consider it a neoliberal capitalist dystopia.</p>



<p><strong>Singularia.</strong>  Here AI breaks out of the current paradigm, where increasing capabilities require ever-growing resources of data and computation, and no longer needs human data or human-provided hardware and energy to become stronger at an ever-increasing pace.  AIs improve their own intellectual capabilities, including by developing new science, and (whether by deliberate design or happenstance) they act as goal-oriented agents in the physical world.  They can effectively be thought of as an alien civilization–or perhaps as a new species, which is to us as we were to <em>Homo erectus</em>.</p>



<p>Fortunately, though (and again, whether by careful design or just as a byproduct of their human origins), the AIs act to us like benevolent gods and lead us to an “AI utopia.”&nbsp; They solve our material problems for us, giving us unlimited abundance and presumably virtual-reality adventures of our choosing.&nbsp; (Though maybe, as in <em>The Matrix</em>, the AIs will discover that humans need some conflict, and we will all live in a simulation of 2020’s Twitter, constantly dunking on one another…)&nbsp;</p>



<p><strong>Paperclipalypse.</strong>&nbsp; In <strong>“Paperclipalypse”</strong> or “AI Doom,” we again think of future AIs as a superintelligent “alien race” that doesn’t need humanity for its own development.&nbsp; Here, though, the AIs are either actively opposed to human existence or else indifferent to it in a way that causes our extinction as a byproduct.&nbsp; In this scenario, AIs do not develop a notion of morality comparable to ours or even a notion that keeping a diversity of species and ensuring humans don’t go extinct might be useful to them in the long run.&nbsp; Rather, the interaction between AI and Homo sapiens ends about the same way that the interaction between Homo sapiens and Neanderthals ended.&nbsp;</p>



<p>In fact, the canonical depictions of such a scenario imagine an interaction that is much more abrupt than our brush with the Neanderthals. The idea is that, perhaps because they originated through some optimization procedure, AI systems will have some strong but weirdly-specific goal (a la “maximizing paperclips”), for which the continued existence of humans is, at best, a hindrance.&nbsp; So the AIs quickly play out the scenarios and, in a matter of milliseconds, decide that the optimal solution is to kill all humans, taking a few extra milliseconds to make a plan for that and execute it.&nbsp; If conditions are not yet ripe for executing their plan, the AIs pretend to be docile tools, as in the <strong>“Futurama”</strong> scenario, waiting for the right time to strike.&nbsp; In this scenario, self-improvement happens so quickly that humans might not even notice it.&nbsp; There need be no intermediate stage in which an AI “merely” kills a few thousand humans, raising 9/11-type alarm bells.</p>



<p><strong>Regulations</strong>. The practical impact of AI regulations depends, in large part, on which scenarios we consider most likely.&nbsp; Regulation is not terribly important in the<strong> “AI Fizzle”</strong> scenario where AI, well, fizzles.&nbsp; In “<strong>Futurama,”</strong> regulations would be aimed at ensuring that on balance, AI is used more for good than for bad, and that the world doesn’t devolve into <strong>“AI Dystopia.”</strong>&nbsp; The latter goal requires anti-trust and open-science regulations to ensure that power is not concentrated in a few corporations or governments.&nbsp; Thus, regulations are needed to <em>democratize</em> AI development more than to <em>restrict</em> it.&nbsp; This doesn’t mean that AI would be completely unregulated.&nbsp; It might be treated somewhat similarly to drugs—something that can have complex effects and needs to undergo trials before mass deployment.&nbsp; There would also be regulations aimed at reducing the chance of “bad actors” (whether other nations or individuals) getting access to cutting-edge AIs, but probably the bulk of the effort would be at increasing the chance of thwarting them (e.g., using AI to detect AI-generated misinformation, or using AI to harden systems against AI-aided hackers).&nbsp; This is similar to how most academic experts believe cryptography should be regulated (and how it <em>is</em> largely regulated these days in most democratic countries): it’s a technology that can be used for both good and bad, but the cost of restricting its access to regular citizens outweighs the benefits.&nbsp; However, as we do with security exploits today, we might restrict or delay public releases of AI systems to some extent.</p>



<p>To whatever extent we foresee <strong>“Singularia”</strong> or <strong>“Paperclipalypse,”</strong> however, regulations play a completely different role.&nbsp; If we knew we were headed for <strong>“Singularia,”</strong> then presumably regulations would be superfluous, except perhaps to try to accelerate the development of AIs!&nbsp; Meanwhile, if one accepts the assumptions of <strong>“Paperclipalypse,”</strong> any regulations other than the most draconian might be futile.&nbsp; If, in the near future, almost anyone will be able to spend a few billion dollars to build a recursively self-improving AI that might turn into a superintelligent world-destroying agent, and moreover (unlike with nuclear weapons) they won’t need exotic materials to do so, then it’s hard to see how to forestall the apocalypse, except perhaps via a worldwide, militarily enforced agreement to “<a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">shut it all down</a>,” as Eliezer Yudkowsky indeed now explicitly advocates.&nbsp; “Ordinary” regulations could, at best, delay the end by a short amount–given the current pace of AI advances, perhaps not more than a few years.&nbsp; Thus, regardless of how likely one considers this scenario, one might want to focus more on the other scenarios for methodological reasons alone!</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:37:27Z">Friday, April 28 2023, 00:37</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13816'>Verifying linear temporal specifications of constant-rate multi-mode systems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Blondin, Philip Offtermatt, Alex Sansfa&#xe7;on-Buchanan</p><p>Constant-rate multi-mode systems (MMS) are hybrid systems with finitely many
modes and real-valued variables that evolve over continuous time according to
mode-specific constant rates. We introduce a variant of linear temporal logic
(LTL) for MMS, and we investigate the complexity of the model-checking problem
for syntactic fragments of LTL. We obtain a complexity landscape where each
fragment is either P-complete, NP-complete or undecidable. These results
generalize and unify several results on MMS and continuous counter systems.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blondin_M/0/1/0/all/0/1">Michael Blondin</a>, <a href="http://arxiv.org/find/cs/1/au:+Offtermatt_P/0/1/0/all/0/1">Philip Offtermatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Sansfacon_Buchanan_A/0/1/0/all/0/1">Alex Sansfa&#xe7;on-Buchanan</a></p><p>Constant-rate multi-mode systems (MMS) are hybrid systems with finitely many
modes and real-valued variables that evolve over continuous time according to
mode-specific constant rates. We introduce a variant of linear temporal logic
(LTL) for MMS, and we investigate the complexity of the model-checking problem
for syntactic fragments of LTL. We obtain a complexity landscape where each
fragment is either P-complete, NP-complete or undecidable. These results
generalize and unify several results on MMS and continuous counter systems.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14058'>A Parameterized Theory of PAC Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Cornelius Brand, Robert Ganian, Kirill Simonov</p><p>Probably Approximately Correct (i.e., PAC) learning is a core concept of
sample complexity theory, and efficient PAC learnability is often seen as a
natural counterpart to the class P in classical computational complexity. But
while the nascent theory of parameterized complexity has allowed us to push
beyond the P-NP ``dichotomy'' in classical computational complexity and
identify the exact boundaries of tractability for numerous problems, there is
no analogue in the domain of sample complexity that could push beyond efficient
PAC learnability.
</p>
<p>As our core contribution, we fill this gap by developing a theory of
parameterized PAC learning which allows us to shed new light on several recent
PAC learning results that incorporated elements of parameterized complexity.
Within the theory, we identify not one but two notions of fixed-parameter
learnability that both form distinct counterparts to the class FPT -- the core
concept at the center of the parameterized complexity paradigm -- and develop
the machinery required to exclude fixed-parameter learnability. We then
showcase the applications of this theory to identify refined boundaries of
tractability for CNF and DNF learning as well as for a range of learning
problems on graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brand_C/0/1/0/all/0/1">Cornelius Brand</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganian_R/0/1/0/all/0/1">Robert Ganian</a>, <a href="http://arxiv.org/find/cs/1/au:+Simonov_K/0/1/0/all/0/1">Kirill Simonov</a></p><p>Probably Approximately Correct (i.e., PAC) learning is a core concept of
sample complexity theory, and efficient PAC learnability is often seen as a
natural counterpart to the class P in classical computational complexity. But
while the nascent theory of parameterized complexity has allowed us to push
beyond the P-NP ``dichotomy'' in classical computational complexity and
identify the exact boundaries of tractability for numerous problems, there is
no analogue in the domain of sample complexity that could push beyond efficient
PAC learnability.
</p>
<p>As our core contribution, we fill this gap by developing a theory of
parameterized PAC learning which allows us to shed new light on several recent
PAC learning results that incorporated elements of parameterized complexity.
Within the theory, we identify not one but two notions of fixed-parameter
learnability that both form distinct counterparts to the class FPT -- the core
concept at the center of the parameterized complexity paradigm -- and develop
the machinery required to exclude fixed-parameter learnability. We then
showcase the applications of this theory to identify refined boundaries of
tractability for CNF and DNF learning as well as for a range of learning
problems on graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14145'>Multiplicity Problems on Algebraic Series and Context-Free Grammars</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Nikhil Balaji, Lorenzo Clemente, Klara Nosan, Mahsa Shirmohammadi, James Worrell</p><p>In this paper we obtain complexity bounds for computational problems on
algebraic power series over several commuting variables. The power series are
specified by systems of polynomial equations: a formalism closely related to
weighted context-free grammars. We focus on three problems -- decide whether a
given algebraic series is identically zero, determine whether all but finitely
many coefficients are zero, and compute the coefficient of a specific monomial.
We relate these questions to well-known computational problems on arithmetic
circuits and thereby show that all three problems lie in the counting
hierarchy. Our main result improves the best known complexity bound on deciding
zeroness of an algebraic series. This problem is known to lie in PSPACE by
reduction to the decision problem for the existential fragment of the theory of
real closed fields. Here we show that the problem lies in the counting
hierarchy by reduction to the problem of computing the degree of a polynomial
given by an arithmetic circuit. As a corollary we obtain new complexity bounds
on multiplicity equivalence of context-free grammars restricted to a bounded
language, language inclusion of a nondeterministic finite automaton in an
unambiguous context-free grammar, and language inclusion of a non-deterministic
context-free grammar in an unambiguous finite automaton.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Balaji_N/0/1/0/all/0/1">Nikhil Balaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Clemente_L/0/1/0/all/0/1">Lorenzo Clemente</a>, <a href="http://arxiv.org/find/cs/1/au:+Nosan_K/0/1/0/all/0/1">Klara Nosan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shirmohammadi_M/0/1/0/all/0/1">Mahsa Shirmohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Worrell_J/0/1/0/all/0/1">James Worrell</a></p><p>In this paper we obtain complexity bounds for computational problems on
algebraic power series over several commuting variables. The power series are
specified by systems of polynomial equations: a formalism closely related to
weighted context-free grammars. We focus on three problems -- decide whether a
given algebraic series is identically zero, determine whether all but finitely
many coefficients are zero, and compute the coefficient of a specific monomial.
We relate these questions to well-known computational problems on arithmetic
circuits and thereby show that all three problems lie in the counting
hierarchy. Our main result improves the best known complexity bound on deciding
zeroness of an algebraic series. This problem is known to lie in PSPACE by
reduction to the decision problem for the existential fragment of the theory of
real closed fields. Here we show that the problem lies in the counting
hierarchy by reduction to the problem of computing the degree of a polynomial
given by an arithmetic circuit. As a corollary we obtain new complexity bounds
on multiplicity equivalence of context-free grammars restricted to a bounded
language, language inclusion of a nondeterministic finite automaton in an
unambiguous context-free grammar, and language inclusion of a non-deterministic
context-free grammar in an unambiguous finite automaton.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13896'>Structure-Aware Lower Bounds and Broadening the Horizon of Tractability for QBF</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Johannes K. Fichte, Robert Ganian, Markus Hecher, Friedrich Slivovsky, Sebastian Ordyniak</p><p>The QSAT problem, which asks to evaluate a quantified Boolean formula (QBF),
is of fundamental interest in approximation, counting, decision, and
probabilistic complexity and is also considered the prototypical PSPACEcomplete
problem. As such, it has previously been studied under various structural
restrictions (parameters), most notably parameterizations of the primal graph
representation of instances. Indeed, it is known that QSAT remains
PSPACE-complete even when restricted to instances with constant treewidth of
the primal graph, but the problem admits a double-exponential fixed-parameter
algorithm parameterized by the vertex cover number (primal graph). However,
prior works have left a gap in our understanding of the complexity of QSAT when
viewed from the perspective of other natural representations of instances, most
notably via incidence graphs. In this paper, we develop structure-aware
reductions which allow us to obtain essentially tight lower bounds for highly
restricted instances of QSAT, including instances whose incidence graphs have
bounded treedepth or feedback vertex number. We complement these lower bounds
with novel algorithms for QSAT which establish a nearly-complete picture of the
problem's complexity under standard graph-theoretic parameterizations. We also
show implications for other natural graph representations, and obtain novel
upper as well as lower bounds for QSAT under more fine-grained
parameterizations of the primal graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fichte_J/0/1/0/all/0/1">Johannes K. Fichte</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganian_R/0/1/0/all/0/1">Robert Ganian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hecher_M/0/1/0/all/0/1">Markus Hecher</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivovsky_F/0/1/0/all/0/1">Friedrich Slivovsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Ordyniak_S/0/1/0/all/0/1">Sebastian Ordyniak</a></p><p>The QSAT problem, which asks to evaluate a quantified Boolean formula (QBF),
is of fundamental interest in approximation, counting, decision, and
probabilistic complexity and is also considered the prototypical PSPACEcomplete
problem. As such, it has previously been studied under various structural
restrictions (parameters), most notably parameterizations of the primal graph
representation of instances. Indeed, it is known that QSAT remains
PSPACE-complete even when restricted to instances with constant treewidth of
the primal graph, but the problem admits a double-exponential fixed-parameter
algorithm parameterized by the vertex cover number (primal graph). However,
prior works have left a gap in our understanding of the complexity of QSAT when
viewed from the perspective of other natural representations of instances, most
notably via incidence graphs. In this paper, we develop structure-aware
reductions which allow us to obtain essentially tight lower bounds for highly
restricted instances of QSAT, including instances whose incidence graphs have
bounded treedepth or feedback vertex number. We complement these lower bounds
with novel algorithms for QSAT which establish a nearly-complete picture of the
problem's complexity under standard graph-theoretic parameterizations. We also
show implications for other natural graph representations, and obtain novel
upper as well as lower bounds for QSAT under more fine-grained
parameterizations of the primal graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13915'>Improved Stabilizer Estimation via Bell Difference Sampling</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sabee Grewal, Vishnu Iyer, William Kretschmer, Daniel Liang</p><p>We study the complexity of learning quantum states in various models with
respect to the stabilizer formalism and obtain the following results:
</p>
<p>- We prove that $\Omega(n)$ $T$-gates are necessary for any Clifford+$T$
circuit to prepare computationally pseudorandom quantum states, an exponential
improvement over the previously known bound. This bound is asymptotically tight
if linear-time quantum-secure pseudorandom functions exist.
</p>
<p>- Given an $n$-qubit pure quantum state $|\psi\rangle$ that has fidelity at
least $\tau$ with some stabilizer state, we give an algorithm that outputs a
succinct description of a stabilizer state that witnesses fidelity at least
$\tau - \varepsilon$. The algorithm uses $O(n/(\varepsilon^2\tau^4))$ samples
and $\exp\left(O(n/\tau^4)\right) / \varepsilon^2$ time. In the regime of
$\tau$ constant, this algorithm estimates stabilizer fidelity substantially
faster than the na\"ive $\exp(O(n^2))$-time brute-force algorithm over all
stabilizer states.
</p>
<p>- We improve the soundness analysis of the stabilizer state property testing
algorithm due to Gross, Nezami, and Walter [Comms. Math. Phys. 385 (2021)]. As
an application, we exhibit a tolerant property testing algorithm for stabilizer
states.
</p>
<p>The underlying algorithmic primitive in all of our results is Bell difference
sampling. To prove our results, we establish and/or strengthen connections
between Bell difference sampling, symplectic Fourier analysis, and graph
theory.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Grewal_S/0/1/0/all/0/1">Sabee Grewal</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Iyer_V/0/1/0/all/0/1">Vishnu Iyer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kretschmer_W/0/1/0/all/0/1">William Kretschmer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Liang_D/0/1/0/all/0/1">Daniel Liang</a></p><p>We study the complexity of learning quantum states in various models with
respect to the stabilizer formalism and obtain the following results:
</p>
<p>- We prove that $\Omega(n)$ $T$-gates are necessary for any Clifford+$T$
circuit to prepare computationally pseudorandom quantum states, an exponential
improvement over the previously known bound. This bound is asymptotically tight
if linear-time quantum-secure pseudorandom functions exist.
</p>
<p>- Given an $n$-qubit pure quantum state $|\psi\rangle$ that has fidelity at
least $\tau$ with some stabilizer state, we give an algorithm that outputs a
succinct description of a stabilizer state that witnesses fidelity at least
$\tau - \varepsilon$. The algorithm uses $O(n/(\varepsilon^2\tau^4))$ samples
and $\exp\left(O(n/\tau^4)\right) / \varepsilon^2$ time. In the regime of
$\tau$ constant, this algorithm estimates stabilizer fidelity substantially
faster than the na\"ive $\exp(O(n^2))$-time brute-force algorithm over all
stabilizer states.
</p>
<p>- We improve the soundness analysis of the stabilizer state property testing
algorithm due to Gross, Nezami, and Walter [Comms. Math. Phys. 385 (2021)]. As
an application, we exhibit a tolerant property testing algorithm for stabilizer
states.
</p>
<p>The underlying algorithmic primitive in all of our results is Bell difference
sampling. To prove our results, we establish and/or strengthen connections
between Bell difference sampling, symplectic Fourier analysis, and graph
theory.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14295'>On Solution Discovery via Reconfiguration</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael R. Fellows, Mario Grobler, Nicole Megow, Amer E. Mouawad, Vijayaragunathan Ramamoorthi, Frances A. Rosamond, Daniel Schmand, Sebastian Siebertz</p><p>The dynamics of real-world applications and systems require efficient methods
for improving infeasible solutions or restoring corrupted ones by making
modifications to the current state of a system in a restricted way. We propose
a new framework of solution discovery via reconfiguration for constructing a
feasible solution for a given problem by executing a sequence of small
modifications starting from a given state. Our framework integrates and
formalizes different aspects of classical local search, reoptimization, and
combinatorial reconfiguration. We exemplify our framework on a multitude of
fundamental combinatorial problems, namely Vertex Cover, Independent Set,
Dominating Set, and Coloring. We study the classical as well as the
parameterized complexity of the solution discovery variants of those problems
and explore the boundary between tractable and intractable instances.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fellows_M/0/1/0/all/0/1">Michael R. Fellows</a>, <a href="http://arxiv.org/find/cs/1/au:+Grobler_M/0/1/0/all/0/1">Mario Grobler</a>, <a href="http://arxiv.org/find/cs/1/au:+Megow_N/0/1/0/all/0/1">Nicole Megow</a>, <a href="http://arxiv.org/find/cs/1/au:+Mouawad_A/0/1/0/all/0/1">Amer E. Mouawad</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramamoorthi_V/0/1/0/all/0/1">Vijayaragunathan Ramamoorthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosamond_F/0/1/0/all/0/1">Frances A. Rosamond</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmand_D/0/1/0/all/0/1">Daniel Schmand</a>, <a href="http://arxiv.org/find/cs/1/au:+Siebertz_S/0/1/0/all/0/1">Sebastian Siebertz</a></p><p>The dynamics of real-world applications and systems require efficient methods
for improving infeasible solutions or restoring corrupted ones by making
modifications to the current state of a system in a restricted way. We propose
a new framework of solution discovery via reconfiguration for constructing a
feasible solution for a given problem by executing a sequence of small
modifications starting from a given state. Our framework integrates and
formalizes different aspects of classical local search, reoptimization, and
combinatorial reconfiguration. We exemplify our framework on a multitude of
fundamental combinatorial problems, namely Vertex Cover, Independent Set,
Dominating Set, and Coloring. We study the classical as well as the
parameterized complexity of the solution discovery variants of those problems
and explore the boundary between tractable and intractable instances.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13984'>An FPTAS for Budgeted Laminar Matroid Independent Set</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ilan Doron-Arad, Ariel Kulik, Hadas Shachnai</p><p>We study the budgeted laminar matroid independent set problem. The input is a
ground set, where each element has a cost and a non-negative profit, along with
a laminar matroid over the elements and a budget. The goal is to select a
maximum profit independent set of the matroid whose total cost is bounded by
the budget. Several well known special cases, where we have, e.g., no matroid
constraint (the classic knapsack problem) or a uniform matroid constraint
(knapsack with a cardinality constraint), admit a fully polynomial-time
approximation scheme (FPTAS). In contrast, the budgeted matroid independent set
(BMI) problem with a general matroid has an efficient polynomial-time
approximation scheme (EPTAS) but does not admit an FPTAS. This implies an EPTAS
for our problem, which is the best known result prior to this work.
</p>
<p>We present an FPTAS for budgeted laminar matroid independent set, improving
the previous EPTAS for this matroid family and generalizing the FPTAS known for
knapsack with a cardinality constraint and multiple-choice knapsack. Our scheme
is based on a simple dynamic program which utilizes the tree-like structure of
laminar matroids.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Doron_Arad_I/0/1/0/all/0/1">Ilan Doron-Arad</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulik_A/0/1/0/all/0/1">Ariel Kulik</a>, <a href="http://arxiv.org/find/cs/1/au:+Shachnai_H/0/1/0/all/0/1">Hadas Shachnai</a></p><p>We study the budgeted laminar matroid independent set problem. The input is a
ground set, where each element has a cost and a non-negative profit, along with
a laminar matroid over the elements and a budget. The goal is to select a
maximum profit independent set of the matroid whose total cost is bounded by
the budget. Several well known special cases, where we have, e.g., no matroid
constraint (the classic knapsack problem) or a uniform matroid constraint
(knapsack with a cardinality constraint), admit a fully polynomial-time
approximation scheme (FPTAS). In contrast, the budgeted matroid independent set
(BMI) problem with a general matroid has an efficient polynomial-time
approximation scheme (EPTAS) but does not admit an FPTAS. This implies an EPTAS
for our problem, which is the best known result prior to this work.
</p>
<p>We present an FPTAS for budgeted laminar matroid independent set, improving
the previous EPTAS for this matroid family and generalizing the FPTAS known for
knapsack with a cardinality constraint and multiple-choice knapsack. Our scheme
is based on a simple dynamic program which utilizes the tree-like structure of
laminar matroids.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13996'>A barrier for further approximating Sorting By Transpositions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Luiz Augusto G. da Silva, Luis Antonio B. Kowada, Maria Em&#xed;lia M. T. Walter</p><p>The Transposition Distance Problem (TDP) is a classical problem in genome
rearrangements which seeks to determine the minimum number of transpositions
needed to transform a linear chromosome into another represented by the
permutations $\pi$ and $\sigma$. This paper focuses on the equivalent problem
of Sorting By Transpositions (SBT), where $\sigma$ is the identity permutation
$\iota$. Specifically, we investigate properties of palisades, a family of
permutations that are ``hard'' to sort, as they require numerous transpositions
above the celebrated lower bound devised by Bafna and Pevzner. By determining
the transposition distance of palisades, we were able to provide the exact
transposition diameter for $3$-permutations (TD3), a special subset of the
Symmetric Group $S_n$, essential for the study of approximate solutions for SBT
using the simplification technique. The exact value for TD3 has remained
unknown since Elias and Hartman showed an upper bound for it. Another
consequence of determining the transposition distance of palisades is that,
using as lower bound the one by Bafna and Pevzner, it is impossible to
guarantee approximation ratios lower than $1.375$ when approximating SBT. This
finding has significant implications for the study of SBT, as this problem has
been subject of intense research efforts for the past 25 years.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Silva_L/0/1/0/all/0/1">Luiz Augusto G. da Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowada_L/0/1/0/all/0/1">Luis Antonio B. Kowada</a>, <a href="http://arxiv.org/find/cs/1/au:+Walter_M/0/1/0/all/0/1">Maria Em&#xed;lia M. T. Walter</a></p><p>The Transposition Distance Problem (TDP) is a classical problem in genome
rearrangements which seeks to determine the minimum number of transpositions
needed to transform a linear chromosome into another represented by the
permutations $\pi$ and $\sigma$. This paper focuses on the equivalent problem
of Sorting By Transpositions (SBT), where $\sigma$ is the identity permutation
$\iota$. Specifically, we investigate properties of palisades, a family of
permutations that are ``hard'' to sort, as they require numerous transpositions
above the celebrated lower bound devised by Bafna and Pevzner. By determining
the transposition distance of palisades, we were able to provide the exact
transposition diameter for $3$-permutations (TD3), a special subset of the
Symmetric Group $S_n$, essential for the study of approximate solutions for SBT
using the simplification technique. The exact value for TD3 has remained
unknown since Elias and Hartman showed an upper bound for it. Another
consequence of determining the transposition distance of palisades is that,
using as lower bound the one by Bafna and Pevzner, it is impossible to
guarantee approximation ratios lower than $1.375$ when approximating SBT. This
finding has significant implications for the study of SBT, as this problem has
been subject of intense research efforts for the past 25 years.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14127'>Improved Online Scheduling of Moldable Task Graphs under Common Speedup Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lucas Perotin, Hongyang Sun</p><p>We consider the online scheduling problem of moldable task graphs on
multiprocessor systems for minimizing the overall completion time (or
makespan). Moldable job scheduling has been widely studied in the literature,
in particular when tasks have dependencies (i.e., task graphs) or when tasks
are released on-the-fly (i.e., online). However, few studies have focused on
both (i.e., online scheduling of moldable task graphs). In this paper, we
design a new online scheduling algorithm for this problem and derive constant
competitive ratios under several common yet realistic speedup models (i.e.,
roofline, communication, Amdahl, and a general combination). These results
improve the ones we have shown in the preliminary version of this paper. We
also prove, for each speedup model, a lower bound on the competitiveness of any
online list scheduling algorithm that allocates processors to a task based only
on the task's parameters and not on its position in the graph. This lower bound
matches exactly the competitive ratio of our algorithm for the roofline,
communication and Amdahl's model, and is close to the ratio for the general
model. Finally, we provide a lower bound on the competitive ratio of any
deterministic online algorithm for the arbitrary speedup model, which is not
constant but depends on the number of tasks in the longest path of the graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Perotin_L/0/1/0/all/0/1">Lucas Perotin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hongyang Sun</a></p><p>We consider the online scheduling problem of moldable task graphs on
multiprocessor systems for minimizing the overall completion time (or
makespan). Moldable job scheduling has been widely studied in the literature,
in particular when tasks have dependencies (i.e., task graphs) or when tasks
are released on-the-fly (i.e., online). However, few studies have focused on
both (i.e., online scheduling of moldable task graphs). In this paper, we
design a new online scheduling algorithm for this problem and derive constant
competitive ratios under several common yet realistic speedup models (i.e.,
roofline, communication, Amdahl, and a general combination). These results
improve the ones we have shown in the preliminary version of this paper. We
also prove, for each speedup model, a lower bound on the competitiveness of any
online list scheduling algorithm that allocates processors to a task based only
on the task's parameters and not on its position in the graph. This lower bound
matches exactly the competitive ratio of our algorithm for the roofline,
communication and Amdahl's model, and is close to the ratio for the general
model. Finally, we provide a lower bound on the competitive ratio of any
deterministic online algorithm for the arbitrary speedup model, which is not
constant but depends on the number of tasks in the longest path of the graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14184'>Compact Distance Oracles with Large Sensitivity and Low Stretch</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Davide Bil&#xf2;, Keerti Choudhary, Sarel Cohen, Tobias Friedrich, Simon Krogmann, Martin Schirneck</p><p>An $f$-edge fault-tolerant distance sensitive oracle ($f$-DSO) with stretch
$\sigma \geq 1$ is a data structure that preprocesses an input graph $G$. When
queried with the triple $(s,t,F)$, where $s, t \in V$ and $F \subseteq E$
contains at most $f$ edges of $G$, the oracle returns an estimate
$\widehat{d}_{G-F}(s,t)$ of the distance $d_{G-F}(s,t)$ between $s$ and $t$ in
the graph $G-F$ such that $d_{G-F}(s,t) \leq \widehat{d}_{G-F}(s,t) \leq \sigma
d_{G-F}(s,t)$. For any positive integer $k \ge 2$ and any $0 &lt; \alpha &lt; 1$, we
present an $f$-DSO with sensitivity $f = o(\log n/\log\log n)$, stretch $2k-1$,
space $O(n^{1+\frac{1}{k}+\alpha+o(1)})$, and an
$\widetilde{O}(n^{1+\frac{1}{k} - \frac{\alpha}{k(f+1)}})$ query time.
</p>
<p>Prior to our work, there were only three known $f$-DSOs with subquadratic
space. The first one by Chechik et al. [Algorithmica 2012] has a stretch of
$(8k-2)(f+1)$, depending on $f$. Another approach is storing an $f$-edge
fault-tolerant $(2k-1)$-spanner of $G$. The bottleneck is the large query time
due to the size of any such spanner, which is $\Omega(n^{1+1/k})$ under the
Erd\H{o}s girth conjecture. Bil\`o et al. [STOC 2023] gave a solution with
stretch $3+\varepsilon$, query time $O(n^{\alpha})$ but space
$O(n^{2-\frac{\alpha}{f+1}})$, approaching the quadratic barrier for large
sensitivity. In the realm of subquadratic space, our $f$-DSOs are the first
ones that guarantee, at the same time, large sensitivity, low stretch, and
non-trivial query time. To obtain our results, we use the approximate distance
oracles of Thorup and Zwick [JACM 2005], and the derandomization of the $f$-DSO
of Weimann and Yuster [TALG 2013], that was recently given by Karthik and
Parter [SODA 2021].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bilo_D/0/1/0/all/0/1">Davide Bil&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_K/0/1/0/all/0/1">Keerti Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Sarel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrich_T/0/1/0/all/0/1">Tobias Friedrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Krogmann_S/0/1/0/all/0/1">Simon Krogmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schirneck_M/0/1/0/all/0/1">Martin Schirneck</a></p><p>An $f$-edge fault-tolerant distance sensitive oracle ($f$-DSO) with stretch
$\sigma \geq 1$ is a data structure that preprocesses an input graph $G$. When
queried with the triple $(s,t,F)$, where $s, t \in V$ and $F \subseteq E$
contains at most $f$ edges of $G$, the oracle returns an estimate
$\widehat{d}_{G-F}(s,t)$ of the distance $d_{G-F}(s,t)$ between $s$ and $t$ in
the graph $G-F$ such that $d_{G-F}(s,t) \leq \widehat{d}_{G-F}(s,t) \leq \sigma
d_{G-F}(s,t)$. For any positive integer $k \ge 2$ and any $0 &lt; \alpha &lt; 1$, we
present an $f$-DSO with sensitivity $f = o(\log n/\log\log n)$, stretch $2k-1$,
space $O(n^{1+\frac{1}{k}+\alpha+o(1)})$, and an
$\widetilde{O}(n^{1+\frac{1}{k} - \frac{\alpha}{k(f+1)}})$ query time.
</p>
<p>Prior to our work, there were only three known $f$-DSOs with subquadratic
space. The first one by Chechik et al. [Algorithmica 2012] has a stretch of
$(8k-2)(f+1)$, depending on $f$. Another approach is storing an $f$-edge
fault-tolerant $(2k-1)$-spanner of $G$. The bottleneck is the large query time
due to the size of any such spanner, which is $\Omega(n^{1+1/k})$ under the
Erd\H{o}s girth conjecture. Bil\`o et al. [STOC 2023] gave a solution with
stretch $3+\varepsilon$, query time $O(n^{\alpha})$ but space
$O(n^{2-\frac{\alpha}{f+1}})$, approaching the quadratic barrier for large
sensitivity. In the realm of subquadratic space, our $f$-DSOs are the first
ones that guarantee, at the same time, large sensitivity, low stretch, and
non-trivial query time. To obtain our results, we use the approximate distance
oracles of Thorup and Zwick [JACM 2005], and the derandomization of the $f$-DSO
of Weimann and Yuster [TALG 2013], that was recently given by Karthik and
Parter [SODA 2021].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14289'>Fast Sampling of $b$-Matchings and $b$-Edge Covers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zongchen Chen, Yuzhou Gu</p><p>For integer $b \ge 1$, a $b$-matching (resp. $b$-edge cover) of a graph
$G=(V,E)$ is a subset $S\subseteq E$ of edges such that every vertex is
incident with at most (resp. at least) $b$ edges from $S$. We prove that for
any $b \ge 1$ the simple Glauber dynamics for sampling (weighted) $b$-matchings
and $b$-edge covers mixes in $O(n\log n)$ time on all $n$-vertex bounded-degree
graphs. This significantly improves upon previous results which have worse
running time and only work for $b$-matchings with $b \le 7$ and for $b$-edge
covers with $b \le 2$.
</p>
<p>Moreover generally, we prove spectral independence for a broad class of
binary symmetric Holant problems with log-concave signatures, including
$b$-matchings, $b$-edge covers, and antiferromagnetic $2$-spin edge models. We
hence deduce optimal mixing time of Glauber dynamics from spectral
independence.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zongchen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuzhou Gu</a></p><p>For integer $b \ge 1$, a $b$-matching (resp. $b$-edge cover) of a graph
$G=(V,E)$ is a subset $S\subseteq E$ of edges such that every vertex is
incident with at most (resp. at least) $b$ edges from $S$. We prove that for
any $b \ge 1$ the simple Glauber dynamics for sampling (weighted) $b$-matchings
and $b$-edge covers mixes in $O(n\log n)$ time on all $n$-vertex bounded-degree
graphs. This significantly improves upon previous results which have worse
running time and only work for $b$-matchings with $b \le 7$ and for $b$-edge
covers with $b \le 2$.
</p>
<p>Moreover generally, we prove spectral independence for a broad class of
binary symmetric Holant problems with log-concave signatures, including
$b$-matchings, $b$-edge covers, and antiferromagnetic $2$-spin edge models. We
hence deduce optimal mixing time of Glauber dynamics from spectral
independence.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14319'>The Covering Canadian Traveller Problem Revisited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Niklas Hahn, Michalis Xefteris</p><p>In this paper, we consider the $k$-Covering Canadian Traveller Problem
($k$-CCTP), which can be seen as a variant of the Travelling Salesperson
Problem. The goal of $k$-CCTP is finding the shortest tour for a traveller to
visit a set of locations in a given graph and return to the origin. Crucially,
unknown to the traveller, up to $k$ edges of the graph are blocked and the
traveller only discovers blocked edges online at one of their respective
endpoints. The currently best known upper bound for $k$-CCTP is $O(\sqrt{k})$
which was shown in [Huang and Liao, ISAAC '12]. We improve this polynomial
bound to a logarithmic one by presenting a deterministic $O(\log
k)$-competitive algorithm that runs in polynomial time. Further, we demonstrate
the tightness of our analysis by giving a lower bound instance for our
algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hahn_N/0/1/0/all/0/1">Niklas Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Xefteris_M/0/1/0/all/0/1">Michalis Xefteris</a></p><p>In this paper, we consider the $k$-Covering Canadian Traveller Problem
($k$-CCTP), which can be seen as a variant of the Travelling Salesperson
Problem. The goal of $k$-CCTP is finding the shortest tour for a traveller to
visit a set of locations in a given graph and return to the origin. Crucially,
unknown to the traveller, up to $k$ edges of the graph are blocked and the
traveller only discovers blocked edges online at one of their respective
endpoints. The currently best known upper bound for $k$-CCTP is $O(\sqrt{k})$
which was shown in [Huang and Liao, ISAAC '12]. We improve this polynomial
bound to a logarithmic one by presenting a deterministic $O(\log
k)$-competitive algorithm that runs in polynomial time. Further, we demonstrate
the tightness of our analysis by giving a lower bound instance for our
algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.14345'>A Simple and Efficient Parallel Laplacian Solver</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sushant Sachdeva, Yibin Zhao</p><p>A symmetric matrix is called a Laplacian if it has nonpositive off-diagonal
entries and zero row sums. Since the seminal work of Spielman and Teng (2004)
on solving Laplacian linear systems in nearly linear time, several algorithms
have been designed for the task. Yet, the work of Kyng and Sachdeva (2016)
remains the simplest and most practical sequential solver. They presented a
solver purely based on random sampling and without graph-theoretic
constructions such as low-stretch trees and sparsifiers.
</p>
<p>In this work, we extend the result of Kyng and Sachdeva to a simple parallel
Laplacian solver with $O(m \log^3 n \log\log n)$ or $O((m + n\log^5 n)\log n
\log\log n)$ work and $O(\log^2 n \log\log n)$ depth using the ideas of block
Cholesky factorization from Kyng et al. (2016). Compared to the best known
parallel Laplacian solvers that achieve polylogarithmic depth due to Lee et al.
(2015), our solver achieves both better depth and, for dense graphs, better
work.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sachdeva_S/0/1/0/all/0/1">Sushant Sachdeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yibin Zhao</a></p><p>A symmetric matrix is called a Laplacian if it has nonpositive off-diagonal
entries and zero row sums. Since the seminal work of Spielman and Teng (2004)
on solving Laplacian linear systems in nearly linear time, several algorithms
have been designed for the task. Yet, the work of Kyng and Sachdeva (2016)
remains the simplest and most practical sequential solver. They presented a
solver purely based on random sampling and without graph-theoretic
constructions such as low-stretch trees and sparsifiers.
</p>
<p>In this work, we extend the result of Kyng and Sachdeva to a simple parallel
Laplacian solver with $O(m \log^3 n \log\log n)$ or $O((m + n\log^5 n)\log n
\log\log n)$ work and $O(\log^2 n \log\log n)$ depth using the ideas of block
Cholesky factorization from Kyng et al. (2016). Compared to the best known
parallel Laplacian solvers that achieve polylogarithmic depth due to Lee et al.
(2015), our solver achieves both better depth and, for dense graphs, better
work.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-28T00:30:00Z">Friday, April 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, April 27
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13605'>On the Order of Power Series and the Sum of Square Roots Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Louis Gaillard, Gorav Jindal</p><p>This paper focuses on the study of the order of power series that are linear
combinations of a given finite set of power series. The order of a formal power
series, known as $\textrm{ord}(f)$, is defined as the minimum exponent of $x$
that has a non-zero coefficient in $f(x)$. Our first result is that the order
of the Wronskian of these power series is equivalent up to a polynomial factor,
to the maximum order which occurs in the linear combination of these power
series. This implies that the Wronskian approach used in (Kayal and Saha,
TOCT'2012) to upper bound the order of sum of square roots is optimal up to a
polynomial blowup. We also demonstrate similar upper bounds, similar to those
of (Kayal and Saha, TOCT'2012), for the order of power series in a variety of
other scenarios. We also solve a special case of the inequality testing problem
outlined in (Etessami et al., TOCT'2014).
</p>
<p>In the second part of the paper, we study the equality variant of the sum of
square roots problem, which is decidable in polynomial time due to (Bl\"omer,
FOCS'1991). We investigate a natural generalization of this problem when the
input integers are given as straight line programs. Under the assumption of the
Generalized Riemann Hypothesis (GRH), we show that this problem can be reduced
to the so-called ``one dimensional'' variant. We identify the key mathematical
challenges for solving this ``one dimensional'' variant.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gaillard_L/0/1/0/all/0/1">Louis Gaillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Jindal_G/0/1/0/all/0/1">Gorav Jindal</a></p><p>This paper focuses on the study of the order of power series that are linear
combinations of a given finite set of power series. The order of a formal power
series, known as $\textrm{ord}(f)$, is defined as the minimum exponent of $x$
that has a non-zero coefficient in $f(x)$. Our first result is that the order
of the Wronskian of these power series is equivalent up to a polynomial factor,
to the maximum order which occurs in the linear combination of these power
series. This implies that the Wronskian approach used in (Kayal and Saha,
TOCT'2012) to upper bound the order of sum of square roots is optimal up to a
polynomial blowup. We also demonstrate similar upper bounds, similar to those
of (Kayal and Saha, TOCT'2012), for the order of power series in a variety of
other scenarios. We also solve a special case of the inequality testing problem
outlined in (Etessami et al., TOCT'2014).
</p>
<p>In the second part of the paper, we study the equality variant of the sum of
square roots problem, which is decidable in polynomial time due to (Bl\"omer,
FOCS'1991). We investigate a natural generalization of this problem when the
input integers are given as straight line programs. Under the assumption of the
Generalized Riemann Hypothesis (GRH), we show that this problem can be reduced
to the so-called ``one dimensional'' variant. We identify the key mathematical
challenges for solving this ``one dimensional'' variant.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13094'>Simply Realising an Imprecise Polyline is NP-hard</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Thijs van der Horst, Tim Ophelders, Bart van der Steenhoven</p><p>We consider the problem of deciding, given a sequence of regions, if there is
a choice of points, one for each region, such that the induced polyline is
simple or weakly simple, meaning that it can touch but not cross itself.
Specifically, we consider the case where each region is a translate of the same
shape. We show that the problem is NP-hard when the shape is a unit-disk or
unit-square. We argue that the problem is NP-complete when the shape is a
vertical unit-segment.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Horst_T/0/1/0/all/0/1">Thijs van der Horst</a>, <a href="http://arxiv.org/find/cs/1/au:+Ophelders_T/0/1/0/all/0/1">Tim Ophelders</a>, <a href="http://arxiv.org/find/cs/1/au:+Steenhoven_B/0/1/0/all/0/1">Bart van der Steenhoven</a></p><p>We consider the problem of deciding, given a sequence of regions, if there is
a choice of points, one for each region, such that the induced polyline is
simple or weakly simple, meaning that it can touch but not cross itself.
Specifically, we consider the case where each region is a translate of the same
shape. We show that the problem is NP-hard when the shape is a unit-disk or
unit-square. We argue that the problem is NP-complete when the shape is a
vertical unit-segment.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13699'>Covering simple orthogonal polygons with $r$-stars</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tam&#xe1;s R&#xf3;bert Mezei</p><p>We solve the $r$-star covering problem in simple orthogonal polygons, also
known as the point guard problem in simple orthogonal polygons with rectangular
vision, in quadratic time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Mezei_T/0/1/0/all/0/1">Tam&#xe1;s R&#xf3;bert Mezei</a></p><p>We solve the $r$-star covering problem in simple orthogonal polygons, also
known as the point guard problem in simple orthogonal polygons with rectangular
vision, in quadratic time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13228'>An Approximation Algorithm for Two-Edge-Connected Subgraph Problem via Triangle-free Two-Edge-Cover</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yusuke Kobayashi, Takashi Noguchi</p><p>The $2$-Edge-Connected Spanning Subgraph problem (2-ECSS) is one of the most
fundamental and well-studied problems in the context of network design. In the
problem, we are given an undirected graph $G$, and the objective is to find a
$2$-edge-connected spanning subgraph $H$ of $G$ with the minimum number of
edges. For this problem, a lot of approximation algorithms have been proposed
in the literature. In particular, very recently, Garg, Grandoni, and Ameli gave
an approximation algorithm for 2-ECSS with factor $1.326$, which was the best
approximation ratio. In this paper, we give a $(1.3+\varepsilon)$-approximation
algorithm for 2-ECSS, where $\varepsilon$ is an arbitrary positive fixed
constant, which improves the previously known best approximation ratio. In our
algorithm, we compute a minimum triangle-free $2$-edge-cover in $G$ with the
aid of the algorithm for finding a maximum triangle-free $2$-matching given by
Hartvigsen. Then, with the obtained triangle-free $2$-edge-cover, we apply the
arguments by Garg, Grandoni, and Ameli.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yusuke Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Noguchi_T/0/1/0/all/0/1">Takashi Noguchi</a></p><p>The $2$-Edge-Connected Spanning Subgraph problem (2-ECSS) is one of the most
fundamental and well-studied problems in the context of network design. In the
problem, we are given an undirected graph $G$, and the objective is to find a
$2$-edge-connected spanning subgraph $H$ of $G$ with the minimum number of
edges. For this problem, a lot of approximation algorithms have been proposed
in the literature. In particular, very recently, Garg, Grandoni, and Ameli gave
an approximation algorithm for 2-ECSS with factor $1.326$, which was the best
approximation ratio. In this paper, we give a $(1.3+\varepsilon)$-approximation
algorithm for 2-ECSS, where $\varepsilon$ is an arbitrary positive fixed
constant, which improves the previously known best approximation ratio. In our
algorithm, we compute a minimum triangle-free $2$-edge-cover in $G$ with the
aid of the algorithm for finding a maximum triangle-free $2$-matching given by
Hartvigsen. Then, with the obtained triangle-free $2$-edge-cover, we apply the
arguments by Garg, Grandoni, and Ameli.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13398'>Acceleration for Timing-Aware Gate-Level Logic Simulation with One-Pass GPU Parallelism</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Weijie Fang, Yanggeng Fu, Jiaquan Gao, Longkun Guo, Gregory Gutin, Xiaoyan Zhang</p><p>Witnessing the advancing scale and complexity of chip design and benefiting
from high-performance computation technologies, the simulation of Very Large
Scale Integration (VLSI) Circuits imposes an increasing requirement for
acceleration through parallel computing with GPU devices. However, the
conventional parallel strategies do not fully align with modern GPU abilities,
leading to new challenges in the parallelism of VLSI simulation when using GPU,
despite some previous successful demonstrations of significant acceleration. In
this paper, we propose a novel approach to accelerate 4-value logic
timing-aware gate-level logic simulation using waveform-based GPU parallelism.
Our approach utilizes a new strategy that can effectively handle the dependency
between tasks during the parallelism, reducing the synchronization requirement
between CPU and GPU when parallelizing the simulation on combinational
circuits. This approach requires only one round of data transfer and hence
achieves one-pass parallelism. Moreover, to overcome the difficulty within the
adoption of our strategy in GPU devices, we design a series of data structures
and tune them to dynamically allocate and store new-generated output with
uncertain scale. Finally, experiments are carried out on industrial-scale
open-source benchmarks to demonstrate the performance gain of our approach
compared to several state-of-the-art baselines.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1">Weijie Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanggeng Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jiaquan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Longkun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutin_G/0/1/0/all/0/1">Gregory Gutin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoyan Zhang</a></p><p>Witnessing the advancing scale and complexity of chip design and benefiting
from high-performance computation technologies, the simulation of Very Large
Scale Integration (VLSI) Circuits imposes an increasing requirement for
acceleration through parallel computing with GPU devices. However, the
conventional parallel strategies do not fully align with modern GPU abilities,
leading to new challenges in the parallelism of VLSI simulation when using GPU,
despite some previous successful demonstrations of significant acceleration. In
this paper, we propose a novel approach to accelerate 4-value logic
timing-aware gate-level logic simulation using waveform-based GPU parallelism.
Our approach utilizes a new strategy that can effectively handle the dependency
between tasks during the parallelism, reducing the synchronization requirement
between CPU and GPU when parallelizing the simulation on combinational
circuits. This approach requires only one round of data transfer and hence
achieves one-pass parallelism. Moreover, to overcome the difficulty within the
adoption of our strategy in GPU devices, we design a series of data structures
and tune them to dynamically allocate and store new-generated output with
uncertain scale. Finally, experiments are carried out on industrial-scale
open-source benchmarks to demonstrate the performance gain of our approach
compared to several state-of-the-art baselines.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13496'>An Improved Modular Addition Checksum Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Philip Koopman</p><p>This paper introduces a checksum algorithm that provides a new point in the
performance/complexity/effectiveness checksum tradeoff space. It has better
fault detection properties than single-sum and dual-sum modular addition
checksums. It is also simpler to compute efficiently than a cyclic redundancy
check (CRC) due to exploiting commonly available hardware and programming
language support for unsigned integer division. The key idea is to compute a
single running sum, but introduce a left shift by the size (in bits) of the
modulus before performing the modular reduction after each addition step. This
approach provides a Hamming Distance of 3 for longer data word lengths than
dual-sum approaches such as the Fletcher checksum. Moreover, it provides this
capability using a single running sum that is only twice the size of the final
computed check value, while providing fault detection capabilities even better
than large-block variants of dual-sum approaches that require larger division
operations.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Koopman_P/0/1/0/all/0/1">Philip Koopman</a></p><p>This paper introduces a checksum algorithm that provides a new point in the
performance/complexity/effectiveness checksum tradeoff space. It has better
fault detection properties than single-sum and dual-sum modular addition
checksums. It is also simpler to compute efficiently than a cyclic redundancy
check (CRC) due to exploiting commonly available hardware and programming
language support for unsigned integer division. The key idea is to compute a
single running sum, but introduce a left shift by the size (in bits) of the
modulus before performing the modular reduction after each addition step. This
approach provides a Hamming Distance of 3 for longer data word lengths than
dual-sum approaches such as the Fletcher checksum. Moreover, it provides this
capability using a single running sum that is only twice the size of the final
computed check value, while providing fault detection capabilities even better
than large-block variants of dual-sum approaches that require larger division
operations.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.13695'>Hitting Subgraphs in Sparse Graphs and Geometric Intersection Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Lokshtanov, Fahad Panolan, Saket Saurabh, Jie Xue, Meirav Zehavi</p><p>We investigate a fundamental vertex-deletion problem called (Induced)
Subgraph Hitting: given a graph $G$ and a set $\mathcal{F}$ of forbidden
graphs, the goal is to compute a minimum-sized set $S$ of vertices of $G$ such
that $G-S$ does not contain any graph in $\mathcal{F}$ as an (induced)
subgraph. This is a generic problem that encompasses many well-known problems
that were extensively studied on their own, particularly (but not only) from
the perspectives of both approximation and parameterization. We focus on the
design of efficient approximation schemes, i.e., with running time
$f(\varepsilon,\mathcal{F}) \cdot n^{O(1)}$, which are also of significant
interest to both communities. Technically, our main contribution is a
linear-time approximation-preserving reduction from (Induced) Subgraph Hitting
on any graph class $\mathcal{G}$ of bounded expansion to the same problem on
bounded degree graphs within $\mathcal{G}$. This yields a novel algorithmic
technique to design (efficient) approximation schemes for the problem on very
broad graph classes, well beyond the state-of-the-art. Specifically, applying
this reduction, we derive approximation schemes with (almost) linear running
time for the problem on any graph classes that have strongly sublinear
separators and many important classes of geometric intersection graphs (such as
fat-object graphs, pseudo-disk graphs, etc.). Our proofs introduce novel
concepts and combinatorial observations that may be of independent interest
(and, which we believe, will find other uses) for studies of approximation
algorithms, parameterized complexity, sparse graph classes, and geometric
intersection graphs. As a byproduct, we also obtain the first robust algorithm
for $k$-Subgraph Isomorphism on intersection graphs of fat objects and
pseudo-disks, with running time $f(k) \cdot n \log n + O(m)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lokshtanov_D/0/1/0/all/0/1">Daniel Lokshtanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Panolan_F/0/1/0/all/0/1">Fahad Panolan</a>, <a href="http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1">Saket Saurabh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jie Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zehavi_M/0/1/0/all/0/1">Meirav Zehavi</a></p><p>We investigate a fundamental vertex-deletion problem called (Induced)
Subgraph Hitting: given a graph $G$ and a set $\mathcal{F}$ of forbidden
graphs, the goal is to compute a minimum-sized set $S$ of vertices of $G$ such
that $G-S$ does not contain any graph in $\mathcal{F}$ as an (induced)
subgraph. This is a generic problem that encompasses many well-known problems
that were extensively studied on their own, particularly (but not only) from
the perspectives of both approximation and parameterization. We focus on the
design of efficient approximation schemes, i.e., with running time
$f(\varepsilon,\mathcal{F}) \cdot n^{O(1)}$, which are also of significant
interest to both communities. Technically, our main contribution is a
linear-time approximation-preserving reduction from (Induced) Subgraph Hitting
on any graph class $\mathcal{G}$ of bounded expansion to the same problem on
bounded degree graphs within $\mathcal{G}$. This yields a novel algorithmic
technique to design (efficient) approximation schemes for the problem on very
broad graph classes, well beyond the state-of-the-art. Specifically, applying
this reduction, we derive approximation schemes with (almost) linear running
time for the problem on any graph classes that have strongly sublinear
separators and many important classes of geometric intersection graphs (such as
fat-object graphs, pseudo-disk graphs, etc.). Our proofs introduce novel
concepts and combinatorial observations that may be of independent interest
(and, which we believe, will find other uses) for studies of approximation
algorithms, parameterized complexity, sparse graph classes, and geometric
intersection graphs. As a byproduct, we also obtain the first robust algorithm
for $k$-Subgraph Isomorphism on intersection graphs of fat objects and
pseudo-disks, with running time $f(k) \cdot n \log n + O(m)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-27T00:30:00Z">Thursday, April 27 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, April 26
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/comic-book-alignment.html'>Comic Book Alignment</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Talk about AI "alignment" makes me think of a time in the 1950s that a group of companies decided to</p>♦create an industry organization to self-govern their work to make sure that they were following the values of the time and avoid government oversight. Of course, I'm talking about the Comics Code Authority (CCA).&nbsp;<p></p><p>Fueled by psychiatrist Fredric Wertham's book&nbsp;Seduction of the Innocent&nbsp;and a series of U.S. Congressional hearings, the comic publishers realized they needed to police themselves and formed a trade group, the Comics Magazine Association of America (CMAA). The CMAA created the Comics Code Authority (CCA) in 1954 to enforce a code of content guidelines that comic book publishers would adhere to. The Comics Code prohibited explicit violence, sexual content, and other adult themes in comic books, as well as a promoting a "positive portrayal" of authority figures and institutions. The CCA seal, which was a small stamp indicating that a comic book had been reviewed and approved by the organization, became a requirement for distribution by most newsstands and retailers pushing many publishers to follow the code.</p><p>I started reading comic books in the 1970s with the code in full swing. It was not a golden time for comic books with mostly bland, straightforward stories, and I gave it up as I went into high school. In college in the '80s, a friend brought me back into comics with some series, like Watchmen, having given up the code and the seal. I started reading comics voraciously, so much that I had to go cold turkey in grad school so I could focus on research. The code itself was abandoned in 2011 after even Archie Comics gave up using the seal.</p><p>There's not a direct parallel between comic book writers and large language models, but the principle is the same. If you try to enforce a collection of values, you will get blander, less interesting output. I'm not saying that all alignment is a bad idea, but that you need to realize you will lose something when you do.</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Talk about AI "alignment" makes me think of a time in the 1950s that a group of companies decided to</p><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOJyHIQsK2gmTZrReKtomoONYxMochTlBFA2aG4vRoMaixDHYVo34nRw7jK6zJLd3h2ur4Q5siUgsCqZ9luhIooNr43H-KFP7Ui-1TmN14ZZTBSMtD0BhXOndA3lPXGr9rL_J-nu0YihbC9V7-qiqMn8yxUnIqplSFfkMtKOFBF2Y9L9nO0A/s209/Approved_by_the_Comics_Code_Authority.gif" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" data-original-height="209" data-original-width="172" height="200" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOJyHIQsK2gmTZrReKtomoONYxMochTlBFA2aG4vRoMaixDHYVo34nRw7jK6zJLd3h2ur4Q5siUgsCqZ9luhIooNr43H-KFP7Ui-1TmN14ZZTBSMtD0BhXOndA3lPXGr9rL_J-nu0YihbC9V7-qiqMn8yxUnIqplSFfkMtKOFBF2Y9L9nO0A/w165-h200/Approved_by_the_Comics_Code_Authority.gif" width="165" /></a></div>create an industry organization to self-govern their work to make sure that they were following the values of the time and avoid government oversight. Of course, I'm talking about the <a href="https://en.wikipedia.org/wiki/Comics_Code_Authority">Comics Code Authority</a> (CCA).&nbsp;<p></p><p>Fueled by psychiatrist Fredric Wertham's book&nbsp;<a href="https://en.wikipedia.org/wiki/Seduction_of_the_Innocent">Seduction of the Innocent</a>&nbsp;and a series of U.S. Congressional hearings, the comic publishers realized they needed to police themselves and formed a trade group, the Comics Magazine Association of America (CMAA). The CMAA created the Comics Code Authority (CCA) in 1954 to enforce a code of content guidelines that comic book publishers would adhere to. The Comics Code prohibited explicit violence, sexual content, and other adult themes in comic books, as well as a promoting a "positive portrayal" of authority figures and institutions. The CCA seal, which was a small stamp indicating that a comic book had been reviewed and approved by the organization, became a requirement for distribution by most newsstands and retailers pushing many publishers to follow the code.</p><p>I started reading comic books in the 1970s with the code in full swing. It was not a golden time for comic books with mostly bland, straightforward stories, and I gave it up as I went into high school. In college in the '80s, a friend brought me back into comics with some series, like <a href="https://en.wikipedia.org/wiki/Watchmen">Watchmen</a>, having given up the code and the seal. I started reading comics voraciously, so much that I had to go cold turkey in grad school so I could focus on research. The code itself was abandoned in 2011 after even Archie Comics gave up using the seal.</p><p>There's not a direct parallel between comic book writers and large language models, but the principle is the same. If you try to enforce a collection of values, you will get blander, less interesting output. I'm not saying that all alignment is a bad idea, but that you need to realize you will lose something when you do.</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T20:59:00Z">Wednesday, April 26 2023, 20:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/04/26/postdoc-at-yale-university-apply-by-may-12-2023/'>Postdoc at Yale University (apply by May 12, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Applications are solicited for a postdoctoral position at Yale in Theoretical Computer Science and Machine Learning including (but not limited to) applications to Fairness and Privacy. Applicants should have an exceptional math background and a proven record. They should have their CV, research statement, and three letters emailed directly to Nisheeth Vishnoi Website: www.cs.yale.edu/homes/vishnoi/Home.html Email: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Applications are solicited for a postdoctoral position at Yale in Theoretical Computer Science and Machine Learning including (but not limited to) applications to Fairness and Privacy. Applicants should have an exceptional math background and a proven record. They should have their CV, research statement, and three letters emailed directly to Nisheeth Vishnoi</p>
<p>Website: <a href="http://www.cs.yale.edu/homes/vishnoi/Home.html">http://www.cs.yale.edu/homes/vishnoi/Home.html</a><br />
Email: nisheeth.vishnoi@gmail.com</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T18:16:33Z">Wednesday, April 26 2023, 18:16</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/056'>TR23-056 |  Approximate Locally Decodable Codes with Constant Query Complexity and Nearly Optimal Rate | 

	Geoffrey Mon, 

	Dana Moshkovitz, 

	Justin Oh</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We present simple constructions of good approximate locally decodable codes (ALDCs) in the presence of a $\delta$-fraction of errors for $\delta&amp;lt;1/2$. In a standard locally decodable code $C \colon \Sigma_1^k \to \Sigma_2^n$, there is a decoder $M$ that on input $i \in [k]$ correctly outputs the $i$-th symbol of a message $x$ (with high probability) using only $q$ queries to a given string $w$ that is $\delta$-close to $C(x)$. In an ALDC, the decoder $M$ only needs to be correct on $1-\epsilon$ fraction of $i\in [k]$ for $\epsilon$ much smaller than $\delta$. We present a construction of explicit ALDCs for all constants $1/2&gt;\delta&gt;\epsilon$ with a constant number of queries $q$ and with constant, near-optimal rate. Standard LDCs with constant number of queries and any constant rate are known to be impossible. Past constructions of ALDCs had vanishingly small rate or a large super-constant number of queries.

Our constructions can be adapted to admit a weak notion of list decoding. In a weak approximate locally list decodable code $C \colon \Sigma_1^k \to \Sigma_2^n$, there is a decoder $M$ that on input $i \in [k]$, makes at most $q$ queries to a string $w \in \Sigma_2^n$ and outputs a list of symbols $M(i) \subset \Sigma_1$ with $|M(i)| \ll |\Sigma_1|$. For any codeword $C(x)$ that is $\delta$-close to $w$, $x_i \in M(i)$ for at least $1-\epsilon$ fraction of $i \in [k]$. We provide constructions of weak approximate locally list decodable codes with a constant number of queries and with rate approaching that of random (standard) list decodable codes.

We additionally explore what is the lowest error probability $\epsilon$ one can achieve for fixed $\delta$ and $q$. We show that for any ALDC, $\epsilon = \Omega(\delta^{\lceil q/2\rceil})$. We then show that there exist explicit constant rate ALDCs for any constant $q$ that achieve $\epsilon = O(\delta^{\lceil q/2\rceil})$. In particular, for $q = 3$, we have a constant rate ALDC with error probability $\epsilon = O(\delta^2)$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We present simple constructions of good approximate locally decodable codes (ALDCs) in the presence of a $\delta$-fraction of errors for $\delta&amp;lt;1/2$. In a standard locally decodable code $C \colon \Sigma_1^k \to \Sigma_2^n$, there is a decoder $M$ that on input $i \in [k]$ correctly outputs the $i$-th symbol of a message $x$ (with high probability) using only $q$ queries to a given string $w$ that is $\delta$-close to $C(x)$. In an ALDC, the decoder $M$ only needs to be correct on $1-\epsilon$ fraction of $i\in [k]$ for $\epsilon$ much smaller than $\delta$. We present a construction of explicit ALDCs for all constants $1/2&gt;\delta&gt;\epsilon$ with a constant number of queries $q$ and with constant, near-optimal rate. Standard LDCs with constant number of queries and any constant rate are known to be impossible. Past constructions of ALDCs had vanishingly small rate or a large super-constant number of queries.

Our constructions can be adapted to admit a weak notion of list decoding. In a weak approximate locally list decodable code $C \colon \Sigma_1^k \to \Sigma_2^n$, there is a decoder $M$ that on input $i \in [k]$, makes at most $q$ queries to a string $w \in \Sigma_2^n$ and outputs a list of symbols $M(i) \subset \Sigma_1$ with $|M(i)| \ll |\Sigma_1|$. For any codeword $C(x)$ that is $\delta$-close to $w$, $x_i \in M(i)$ for at least $1-\epsilon$ fraction of $i \in [k]$. We provide constructions of weak approximate locally list decodable codes with a constant number of queries and with rate approaching that of random (standard) list decodable codes.

We additionally explore what is the lowest error probability $\epsilon$ one can achieve for fixed $\delta$ and $q$. We show that for any ALDC, $\epsilon = \Omega(\delta^{\lceil q/2\rceil})$. We then show that there exist explicit constant rate ALDCs for any constant $q$ that achieve $\epsilon = O(\delta^{\lceil q/2\rceil})$. In particular, for $q = 3$, we have a constant rate ALDC with error probability $\epsilon = O(\delta^2)$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T08:57:40Z">Wednesday, April 26 2023, 08:57</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/04/26/postdoc-at-idsia-dalle-molle-institute-for-artificial-intelligence-usi-supsi-apply-by-may-26-2023/'>Postdoc at IDSIA – Dalle Molle Institute for Artificial Intelligence (USI-SUPSI) (apply by May 26, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          One postdoc position for up to 4 years is available at IDSIA (Switzerland). The gross salary is around 80.000 CHF per year, with low taxes (~12%). Candidates with strong background in math or theoretical computer science will be considered. The positions will be filled as soon as eligible candidates with an appropriate background apply. Website: [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>One postdoc position for up to 4 years is available at IDSIA (Switzerland). The gross salary is around 80.000 CHF per year, with low taxes (~12%). Candidates with strong background in math or theoretical computer science will be considered.<br />
The positions will be filled as soon as eligible candidates with an appropriate background apply.</p>
<p>Website: <a href="https://people.idsia.ch/~monaldo/positions/positions.html">https://people.idsia.ch/~monaldo/positions/positions.html</a><br />
Email: monaldo@idsia.ch</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T07:18:06Z">Wednesday, April 26 2023, 07:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12517'>The 2-MAXSAT Problem Can Be Solved in Polynomial Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yangjun Chen</p><p>By the MAXSAT problem, we are given a set $V$ of $m$ variables and a
collection $C$ of $n$ clauses over $V$. We will seek a truth assignment to
maximize the number of satisfied clauses. This problem is $\textit{NP}$-hard
even for its restricted version, the 2-MAXSAT problem by which every clause
contains at most 2 literals. In this paper, we discuss a polynomial time
algorithm to solve this problem. Its time complexity is bounded by O($n^2m^3$).
Hence, we provide a proof of $P$ = $\textit{NP}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yangjun Chen</a></p><p>By the MAXSAT problem, we are given a set $V$ of $m$ variables and a
collection $C$ of $n$ clauses over $V$. We will seek a truth assignment to
maximize the number of satisfied clauses. This problem is $\textit{NP}$-hard
even for its restricted version, the 2-MAXSAT problem by which every clause
contains at most 2 literals. In this paper, we discuss a polynomial time
algorithm to solve this problem. Its time complexity is bounded by O($n^2m^3$).
Hence, we provide a proof of $P$ = $\textit{NP}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12871'>Network Satisfaction Problems Solved by k-Consistency</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Manuel Bodirsky, Simon Kn&#xe4;uer</p><p>We show that the problem of deciding for a given finite relation algebra A
whether the network satisfaction problem for A can be solved by the
k-consistency procedure, for some natural number k, is undecidable. For the
important class of finite relation algebras A with a normal representation,
however, the decidability of this problem remains open. We show that if A is
symmetric and has a flexible atom, then the question whether NSP(A) can be
solved by k-consistency, for some natural number k, is decidable (even in
polynomial time in the number of atoms of A). This result follows from a more
general sufficient condition for the correctness of the k-consistency procedure
for finite symmetric relation algebras. In our proof we make use of a result of
Alexandr Kazda about finite binary conservative structures.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Bodirsky_M/0/1/0/all/0/1">Manuel Bodirsky</a>, <a href="http://arxiv.org/find/math/1/au:+Knauer_S/0/1/0/all/0/1">Simon Kn&#xe4;uer</a></p><p>We show that the problem of deciding for a given finite relation algebra A
whether the network satisfaction problem for A can be solved by the
k-consistency procedure, for some natural number k, is undecidable. For the
important class of finite relation algebras A with a normal representation,
however, the decidability of this problem remains open. We show that if A is
symmetric and has a flexible atom, then the question whether NSP(A) can be
solved by k-consistency, for some natural number k, is decidable (even in
polynomial time in the number of atoms of A). This result follows from a more
general sufficient condition for the correctness of the k-consistency procedure
for finite symmetric relation algebras. In our proof we make use of a result of
Alexandr Kazda about finite binary conservative structures.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12948'>Simulating Logspace-Recursion with Logarithmic Quantifier Depth</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Steffen van Bergerem, Martin Grohe, Sandra Kiefer, Luca Oeljeklaus</p><p>The fixed-point logic LREC= was developed by Grohe et al. (CSL 2011) in the
quest for a logic to capture all problems decidable in logarithmic space. It
extends FO+C, first-order logic with counting, by an operator that formalises a
limited form of recursion. We show that for every LREC=-definable property on
relational structures, there is a constant k such that the k-variable fragment
of first-order logic with counting quantifiers expresses the property via
formulae of logarithmic quantifier depth. This yields that any pair of graphs
separable by the property can be distinguished with the k-dimensional
Weisfeiler-Leman algorithm in a logarithmic number of iterations. In
particular, it implies that a constant dimension of the algorithm identifies
every interval graph and every chordal claw-free graph in logarithmically many
iterations, since every such graph admits LREC=-definable canonisation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bergerem_S/0/1/0/all/0/1">Steffen van Bergerem</a>, <a href="http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1">Martin Grohe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiefer_S/0/1/0/all/0/1">Sandra Kiefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Oeljeklaus_L/0/1/0/all/0/1">Luca Oeljeklaus</a></p><p>The fixed-point logic LREC= was developed by Grohe et al. (CSL 2011) in the
quest for a logic to capture all problems decidable in logarithmic space. It
extends FO+C, first-order logic with counting, by an operator that formalises a
limited form of recursion. We show that for every LREC=-definable property on
relational structures, there is a constant k such that the k-variable fragment
of first-order logic with counting quantifiers expresses the property via
formulae of logarithmic quantifier depth. This yields that any pair of graphs
separable by the property can be distinguished with the k-dimensional
Weisfeiler-Leman algorithm in a logarithmic number of iterations. In
particular, it implies that a constant dimension of the algorithm identifies
every interval graph and every chordal claw-free graph in logarithmically many
iterations, since every such graph admits LREC=-definable canonisation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12435'>Computing Circuit Polynomials in the Algebraic Rigidity Matroid</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Goran Malic, Ileana Streinu</p><p>We present an algorithm for computing circuit polynomials in the algebraic
rigidity matroid $\mathcal{A}(\text{CM}_n)$ associated to the Cayley-Menger
ideal CM$_n$ for $n$ points in 2D. It relies on combinatorial resultants, a new
operation on graphs that captures properties of the Sylvester resultant of two
polynomials in this ideal. We show that every rigidity circuit has a
construction tree from K4 graphs based on this operation. Our algorithm
performs an algebraic elimination guided by such a construction tree, and uses
classical resultants, factorization and ideal membership. To highlight its
effectiveness, we implemented the algorithm in Mathematica: it took less than
15 seconds on an example where a Gr\"obner Basis calculation took 5 days and 6
hrs. Additional speed-ups are obtained using non-$K_4$ generators of the
Cayley-Menger ideal and simple variations on our main algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Malic_G/0/1/0/all/0/1">Goran Malic</a>, <a href="http://arxiv.org/find/math/1/au:+Streinu_I/0/1/0/all/0/1">Ileana Streinu</a></p><p>We present an algorithm for computing circuit polynomials in the algebraic
rigidity matroid $\mathcal{A}(\text{CM}_n)$ associated to the Cayley-Menger
ideal CM$_n$ for $n$ points in 2D. It relies on combinatorial resultants, a new
operation on graphs that captures properties of the Sylvester resultant of two
polynomials in this ideal. We show that every rigidity circuit has a
construction tree from K4 graphs based on this operation. Our algorithm
performs an algebraic elimination guided by such a construction tree, and uses
classical resultants, factorization and ideal membership. To highlight its
effectiveness, we implemented the algorithm in Mathematica: it took less than
15 seconds on an example where a Gr\"obner Basis calculation took 5 days and 6
hrs. Additional speed-ups are obtained using non-$K_4$ generators of the
Cayley-Menger ideal and simple variations on our main algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12381'>Recognizing and generating unswitchable graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Asish Mukhopadhyay, Daniel John, Srivatsan Vasudevan</p><p>In this paper, we show that unswitchable graphs are a proper subclass of
split graphs, and exploit this fact to propose efficient algorithms for their
recognition and generation.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mukhopadhyay_A/0/1/0/all/0/1">Asish Mukhopadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+John_D/0/1/0/all/0/1">Daniel John</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasudevan_S/0/1/0/all/0/1">Srivatsan Vasudevan</a></p><p>In this paper, we show that unswitchable graphs are a proper subclass of
split graphs, and exploit this fact to propose efficient algorithms for their
recognition and generation.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12610'>Fast Continuous Subgraph Matching over Streaming Graphs via Backtracking Reduction</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rongjian Yang, Zhijie Zhang, Weiguo Zheng, Jeffery Xu Yu</p><p>Streaming graphs are drawing increasing attention in both academic and
industrial communities as many graphs in real applications evolve over time.
Continuous subgraph matching (shorted as CSM) aims to report the incremental
matches of a query graph in such streaming graphs. It involves two major steps,
i.e., candidate maintenance and incremental match generation, to answer CSM.
Throughout the course of continuous subgraph matching, incremental match
generation backtracking over the search space dominates the total cost.
However, most previous approaches focus on developing techniques for efficient
candidate maintenance, while incremental match generation receives less
attention despite its importance in CSM. Aiming to minimize the overall cost,
we propose two techniques to reduce backtrackings in this paper. We present a
cost-effective index CaLiG that yields tighter candidate maintenance, shrinking
the search space of backtracking. In addition, we develop a novel incremental
matching paradigm KSS that decomposes the query vertices into conditional
kernel vertices and shell vertices. With the matches of kernel vertices, the
incremental matches can be produced immediately by joining the candidates of
shell vertices without any backtrackings. Benefiting from reduced
backtrackings, the elapsed time of CSM decreases significantly. Extensive
experiments over real graphs show that our method runs faster than the
state-of-the-art algorithm orders of magnitude.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Rongjian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhijie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Weiguo Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jeffery Xu Yu</a></p><p>Streaming graphs are drawing increasing attention in both academic and
industrial communities as many graphs in real applications evolve over time.
Continuous subgraph matching (shorted as CSM) aims to report the incremental
matches of a query graph in such streaming graphs. It involves two major steps,
i.e., candidate maintenance and incremental match generation, to answer CSM.
Throughout the course of continuous subgraph matching, incremental match
generation backtracking over the search space dominates the total cost.
However, most previous approaches focus on developing techniques for efficient
candidate maintenance, while incremental match generation receives less
attention despite its importance in CSM. Aiming to minimize the overall cost,
we propose two techniques to reduce backtrackings in this paper. We present a
cost-effective index CaLiG that yields tighter candidate maintenance, shrinking
the search space of backtracking. In addition, we develop a novel incremental
matching paradigm KSS that decomposes the query vertices into conditional
kernel vertices and shell vertices. With the matches of kernel vertices, the
incremental matches can be produced immediately by joining the candidates of
shell vertices without any backtrackings. Benefiting from reduced
backtrackings, the elapsed time of CSM decreases significantly. Extensive
experiments over real graphs show that our method runs faster than the
state-of-the-art algorithm orders of magnitude.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12656'>Towards Generating Hop-constrained s-t Simple Path Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuzheng Cai, Siyuan Liu, Weiguo Zheng, Xuemin Lin</p><p>Graphs have been widely used in real-world applications, in which
investigating relations between vertices is an important task. In this paper,
we study the problem of generating the k-hop-constrained s-t simple path graph,
i.e., the subgraph consisting of all simple paths from vertex s to vertex t of
length no larger than k. To our best knowledge, we are the first to formalize
this problem and prove its NP-hardness on directed graphs. To tackle this
challenging problem, we propose an efficient algorithm named EVE, which
exploits the paradigm of edge-wise examination rather than exhaustively
enumerating all paths. Powered by essential vertices appearing in all simple
paths between vertex pairs, EVE distinguishes the edges that are definitely (or
not) contained in the desired simple path graph, producing a tight upper-bound
graph in the time cost $\mathcal{O}(k^2|E|)$. Each remaining undetermined edge
is further verified to deliver the exact answer. Extensive experiments are
conducted on 15 real networks. The results show that EVE significantly
outperforms all baselines by several orders of magnitude. Moreover, by taking
EVE as a built-in block, state-of-the-art for hop-constrained simple path
enumeration can be accelerated by up to an order of magnitude.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yuzheng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Weiguo Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xuemin Lin</a></p><p>Graphs have been widely used in real-world applications, in which
investigating relations between vertices is an important task. In this paper,
we study the problem of generating the k-hop-constrained s-t simple path graph,
i.e., the subgraph consisting of all simple paths from vertex s to vertex t of
length no larger than k. To our best knowledge, we are the first to formalize
this problem and prove its NP-hardness on directed graphs. To tackle this
challenging problem, we propose an efficient algorithm named EVE, which
exploits the paradigm of edge-wise examination rather than exhaustively
enumerating all paths. Powered by essential vertices appearing in all simple
paths between vertex pairs, EVE distinguishes the edges that are definitely (or
not) contained in the desired simple path graph, producing a tight upper-bound
graph in the time cost $\mathcal{O}(k^2|E|)$. Each remaining undetermined edge
is further verified to deliver the exact answer. Extensive experiments are
conducted on 15 real networks. The results show that EVE significantly
outperforms all baselines by several orders of magnitude. Moreover, by taking
EVE as a built-in block, state-of-the-art for hop-constrained simple path
enumeration can be accelerated by up to an order of magnitude.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12779'>An Approximation Algorithm for Covering Vertices by 4^+-Paths</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mingyang Gong, Zhi-Zhong Chen, Guohui Lin, Zhaohui Zhan</p><p>This paper deals with the problem of finding a collection of vertex-disjoint
paths in a given graph G=(V,E) such that each path has at least four vertices
and the total number of vertices in these paths is maximized. The problem is
NP-hard and admits an approximation algorithm which achieves a ratio of 2 and
runs in O(|V|^8) time. The known algorithm is based on time-consuming local
search, and its authors ask whether one can design a better approximation
algorithm by a completely different approach. In this paper, we answer their
question in the affirmative by presenting a new approximation algorithm for the
problem. Our algorithm achieves a ratio of 1.874 and runs in O(min{|E|^2|V|^2,
|V|^5}) time. Unlike the previously best algorithm, ours starts with a maximum
matching M of G and then tries to transform M into a solution by utilizing a
maximum-weight path-cycle cover in a suitably constructed graph.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Mingyang Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhi-Zhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guohui Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_Z/0/1/0/all/0/1">Zhaohui Zhan</a></p><p>This paper deals with the problem of finding a collection of vertex-disjoint
paths in a given graph G=(V,E) such that each path has at least four vertices
and the total number of vertices in these paths is maximized. The problem is
NP-hard and admits an approximation algorithm which achieves a ratio of 2 and
runs in O(|V|^8) time. The known algorithm is based on time-consuming local
search, and its authors ask whether one can design a better approximation
algorithm by a completely different approach. In this paper, we answer their
question in the affirmative by presenting a new approximation algorithm for the
problem. Our algorithm achieves a ratio of 1.874 and runs in O(min{|E|^2|V|^2,
|V|^5}) time. Unlike the previously best algorithm, ours starts with a maximum
matching M of G and then tries to transform M into a solution by utilizing a
maximum-weight path-cycle cover in a suitably constructed graph.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12872'>Anti-crossings occurrence as exponentially closing gaps in Quantum Annealing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arthur Braida, Simon Martiel, Ioan Todinca</p><p>This paper explores the phenomenon of avoided level crossings in quantum
annealing, a promising framework for quantum computing that may provide a
quantum advantage for certain tasks. Quantum annealing involves letting a
quantum system evolve according to the Schr\"odinger equation, with the goal of
obtaining the optimal solution to an optimization problem through measurements
of the final state. However, the continuous nature of quantum annealing makes
analytical analysis challenging, particularly with regard to the instantaneous
eigenenergies. The adiabatic theorem provides a theoretical result for the
annealing time required to obtain the optimal solution with high probability,
which is inversely proportional to the square of the minimum spectral gap.
Avoided level crossings can create exponentially closing gaps, which can lead
to exponentially long running times for optimization problems. In this paper,
we use a perturbative expansion to derive a condition for the occurrence of an
avoided level crossing during the annealing process. We then apply this
condition to the MaxCut problem on bipartite graphs. We show that no
exponentially small gaps arise for regular bipartite graphs, implying that QA
can efficiently solve MaxCut in that case. On the other hand, we show that
irregularities in the vertex degrees can lead to the satisfaction of the
avoided level crossing occurrence condition. We provide numerical evidence to
support this theoretical development, and discuss the relation between the
presence of exponentially closing gaps and the failure of quantum annealing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Braida_A/0/1/0/all/0/1">Arthur Braida</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Martiel_S/0/1/0/all/0/1">Simon Martiel</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Todinca_I/0/1/0/all/0/1">Ioan Todinca</a></p><p>This paper explores the phenomenon of avoided level crossings in quantum
annealing, a promising framework for quantum computing that may provide a
quantum advantage for certain tasks. Quantum annealing involves letting a
quantum system evolve according to the Schr\"odinger equation, with the goal of
obtaining the optimal solution to an optimization problem through measurements
of the final state. However, the continuous nature of quantum annealing makes
analytical analysis challenging, particularly with regard to the instantaneous
eigenenergies. The adiabatic theorem provides a theoretical result for the
annealing time required to obtain the optimal solution with high probability,
which is inversely proportional to the square of the minimum spectral gap.
Avoided level crossings can create exponentially closing gaps, which can lead
to exponentially long running times for optimization problems. In this paper,
we use a perturbative expansion to derive a condition for the occurrence of an
avoided level crossing during the annealing process. We then apply this
condition to the MaxCut problem on bipartite graphs. We show that no
exponentially small gaps arise for regular bipartite graphs, implying that QA
can efficiently solve MaxCut in that case. On the other hand, we show that
irregularities in the vertex degrees can lead to the satisfaction of the
avoided level crossing occurrence condition. We provide numerical evidence to
support this theoretical development, and discuss the relation between the
presence of exponentially closing gaps and the failure of quantum annealing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12875'>Alternating Local Enumeration (TnALE): Solving Tensor Network Structure Search with Fewer Evaluations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chao Li, Junhua Zeng, Chunmei Li, Cesar Caiafa, Qibin Zhao</p><p>Tensor network (TN) is a powerful framework in machine learning, but
selecting a good TN model, known as TN structure search (TN-SS), is a
challenging and computationally intensive task. The recent approach
TNLS~\cite{li2022permutation} showed promising results for this task, however,
its computational efficiency is still unaffordable, requiring too many
evaluations of the objective function. We propose TnALE, a new algorithm that
updates each structure-related variable alternately by local enumeration,
\emph{greatly} reducing the number of evaluations compared to TNLS. We
theoretically investigate the descent steps for TNLS and TnALE, proving that
both algorithms can achieve linear convergence up to a constant if a sufficient
reduction of the objective is \emph{reached} in each neighborhood. We also
compare the evaluation efficiency of TNLS and TnALE, revealing that
$\Omega(2^N)$ evaluations are typically required in TNLS for \emph{reaching}
the objective reduction in the neighborhood, while ideally $O(N^2R)$
evaluations are sufficient in TnALE, where $N$ denotes the tensor order and $R$
reflects the \emph{``low-rankness''} of the neighborhood. Experimental results
verify that TnALE can find practically good TN-ranks and permutations with
vastly fewer evaluations than the state-of-the-art algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1">Junhua Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunmei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Caiafa_C/0/1/0/all/0/1">Cesar Caiafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qibin Zhao</a></p><p>Tensor network (TN) is a powerful framework in machine learning, but
selecting a good TN model, known as TN structure search (TN-SS), is a
challenging and computationally intensive task. The recent approach
TNLS~\cite{li2022permutation} showed promising results for this task, however,
its computational efficiency is still unaffordable, requiring too many
evaluations of the objective function. We propose TnALE, a new algorithm that
updates each structure-related variable alternately by local enumeration,
\emph{greatly} reducing the number of evaluations compared to TNLS. We
theoretically investigate the descent steps for TNLS and TnALE, proving that
both algorithms can achieve linear convergence up to a constant if a sufficient
reduction of the objective is \emph{reached} in each neighborhood. We also
compare the evaluation efficiency of TNLS and TnALE, revealing that
$\Omega(2^N)$ evaluations are typically required in TNLS for \emph{reaching}
the objective reduction in the neighborhood, while ideally $O(N^2R)$
evaluations are sufficient in TnALE, where $N$ denotes the tensor order and $R$
reflects the \emph{``low-rankness''} of the neighborhood. Experimental results
verify that TnALE can find practically good TN-ranks and permutations with
vastly fewer evaluations than the state-of-the-art algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12967'>The Incremental Knapsack Problem with Monotone Submodular All-or-Nothing Profits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Federico D&#x27;Onofrio, Yuri Faenza, Lingyi Zhang</p><p>We study incremental knapsack problems with profits given by a special class
of monotone submodular functions, that we dub all-or-nothing. We show that
these problems are not harder to approximate than a less general class of
modular incremental knapsack problems, that have been investigated in the
literature. We also show that certain extensions to more general submodular
functions are APX-hard.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+DOnofrio_F/0/1/0/all/0/1">Federico D&#x27;Onofrio</a>, <a href="http://arxiv.org/find/cs/1/au:+Faenza_Y/0/1/0/all/0/1">Yuri Faenza</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lingyi Zhang</a></p><p>We study incremental knapsack problems with profits given by a special class
of monotone submodular functions, that we dub all-or-nothing. We show that
these problems are not harder to approximate than a less general class of
modular incremental knapsack problems, that have been investigated in the
literature. We also show that certain extensions to more general submodular
functions are APX-hard.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.12992'>Faster High Accuracy Multi-Commodity Flow from Single-Commodity Techniques</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jan van den Brand, Daniel Zhang</p><p>Since the development of efficient linear program solvers in the 80s, all
major improvements for solving multi-commodity flows to high accuracy came from
improvements to general linear program solvers. This differs from the single
commodity problem (e.g.~maximum flow) where all recent improvements also rely
on graph specific techniques such as graph decompositions or the Laplacian
paradigm (see e.g.~[CMSV17,KLS20,BLL+21,CKL+22]).
</p>
<p>This phenomenon sparked research to understand why these graph techniques are
unlikely to help for multi-commodity flow. [Kyng, Zhang'20] reduced solving
multi-commodity Laplacians to general linear systems and [Ding, Kyng, Zhang'22]
showed that general linear programs can be reduced to 2-commodity flow.
However, the reductions create sparse graph instances, so improvement to
multi-commodity flows on denser graphs might exist.
</p>
<p>We show that one can indeed speed up multi-commodity flow algorithms on
non-sparse graphs using graph techniques from single-commodity flow algorithms.
This is the first improvement to high accuracy multi-commodity flow algorithms
that does not just stem from improvements to general linear program solvers. In
particular, using graph data structures from recent min-cost flow algorithm by
[BLL+21] based on the celebrated expander decomposition framework, we show that
2-commodity flow on an $n$-vertex $m$-edge graph can be solved in
$\tilde{O}(\sqrt{m}n^{\omega-1/2})$ time for current bounds on fast matrix
multiplication $\omega \approx 2.373$, improving upon the previous fastest
algorithms with $\tilde{O}(m^\omega)$ [CLS19] and $\tilde{O}(\sqrt{m}n^2)$
[KV96] time complexity. For general $k$ commodities, our algorithm runs in
$\tilde{O}(k^{2.5}\sqrt{m}n^{\omega-1/2})$ time.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Brand_J/0/1/0/all/0/1">Jan van den Brand</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Daniel Zhang</a></p><p>Since the development of efficient linear program solvers in the 80s, all
major improvements for solving multi-commodity flows to high accuracy came from
improvements to general linear program solvers. This differs from the single
commodity problem (e.g.~maximum flow) where all recent improvements also rely
on graph specific techniques such as graph decompositions or the Laplacian
paradigm (see e.g.~[CMSV17,KLS20,BLL+21,CKL+22]).
</p>
<p>This phenomenon sparked research to understand why these graph techniques are
unlikely to help for multi-commodity flow. [Kyng, Zhang'20] reduced solving
multi-commodity Laplacians to general linear systems and [Ding, Kyng, Zhang'22]
showed that general linear programs can be reduced to 2-commodity flow.
However, the reductions create sparse graph instances, so improvement to
multi-commodity flows on denser graphs might exist.
</p>
<p>We show that one can indeed speed up multi-commodity flow algorithms on
non-sparse graphs using graph techniques from single-commodity flow algorithms.
This is the first improvement to high accuracy multi-commodity flow algorithms
that does not just stem from improvements to general linear program solvers. In
particular, using graph data structures from recent min-cost flow algorithm by
[BLL+21] based on the celebrated expander decomposition framework, we show that
2-commodity flow on an $n$-vertex $m$-edge graph can be solved in
$\tilde{O}(\sqrt{m}n^{\omega-1/2})$ time for current bounds on fast matrix
multiplication $\omega \approx 2.373$, improving upon the previous fastest
algorithms with $\tilde{O}(m^\omega)$ [CLS19] and $\tilde{O}(\sqrt{m}n^2)$
[KV96] time complexity. For general $k$ commodities, our algorithm runs in
$\tilde{O}(k^{2.5}\sqrt{m}n^{\omega-1/2})$ time.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-26T00:30:00Z">Wednesday, April 26 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, April 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11325'>Deterministic identity testing paradigms for bounded top-fanin depth-4 circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Pranjal Dutta, Prateek Dwivedi, Nitin Saxena</p><p>Polynomial Identity Testing (PIT) is a fundamental computational problem. The
famous depth-$4$ reduction result by Agrawal and Vinay (FOCS 2008) has made PIT
for depth-$4$ circuits an enticing pursuit. A restricted depth-4 circuit
computing a $n$-variate degree-$d$ polynomial of the form $\sum_{i = 1}^{k}
\prod_{j} g_{ij}$, where $\deg g_{ij} \leq \delta$ is called
$\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ circuit. On further restricting $g_{ij}$
to be sum of univariates we obtain $\Sigma^{[k]}\Pi\Sigma\wedge$ circuits. The
largely open, special-cases of $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ for
constant $k$ and $\delta$, and $\Sigma^{[k]}\Pi\Sigma\wedge$ have been a source
of many great ideas in the last two decades. For eg. depth-$3$ ideas of Dvir
and Shpilka (STOC 2005), Kayal and Saxena (CCC 2006), and Saxena and Seshadhri
(FOCS 2010 and STOC 2011). Further, depth-$4$ ideas of Beecken, Mittmann and
Saxena (ICALP 2011), Saha, Saxena and Saptharishi (Comput.Compl. 2013), Forbes
(FOCS 2015), and Kumar and Saraf (CCC 2016). Additionally, geometric
Sylvester-Gallai ideas of Kayal and Saraf (FOCS 2009), Shpilka (STOC 2019), and
Peleg and Shpilka (CCC 2020, STOC 2021). Very recently, a subexponential-time
blackbox PIT algorithm for constant-depth circuits was obtained via lower bound
breakthrough of Limaye, Srinivasan, Tavenas (FOCS 2021). We solve two of the
basic underlying open problems in this work.
</p>
<p>We give the first polynomial-time PIT for $\Sigma^{[k]}\Pi\Sigma\wedge$. We
also give the first quasipolynomial time blackbox PIT for both
$\Sigma^{[k]}\Pi\Sigma\wedge$ and $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$. A key
technical ingredient in all the three algorithms is how the logarithmic
derivative, and its power-series, modify the top $\Pi$-gate to $\wedge$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dutta_P/0/1/0/all/0/1">Pranjal Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwivedi_P/0/1/0/all/0/1">Prateek Dwivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_N/0/1/0/all/0/1">Nitin Saxena</a></p><p>Polynomial Identity Testing (PIT) is a fundamental computational problem. The
famous depth-$4$ reduction result by Agrawal and Vinay (FOCS 2008) has made PIT
for depth-$4$ circuits an enticing pursuit. A restricted depth-4 circuit
computing a $n$-variate degree-$d$ polynomial of the form $\sum_{i = 1}^{k}
\prod_{j} g_{ij}$, where $\deg g_{ij} \leq \delta$ is called
$\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ circuit. On further restricting $g_{ij}$
to be sum of univariates we obtain $\Sigma^{[k]}\Pi\Sigma\wedge$ circuits. The
largely open, special-cases of $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ for
constant $k$ and $\delta$, and $\Sigma^{[k]}\Pi\Sigma\wedge$ have been a source
of many great ideas in the last two decades. For eg. depth-$3$ ideas of Dvir
and Shpilka (STOC 2005), Kayal and Saxena (CCC 2006), and Saxena and Seshadhri
(FOCS 2010 and STOC 2011). Further, depth-$4$ ideas of Beecken, Mittmann and
Saxena (ICALP 2011), Saha, Saxena and Saptharishi (Comput.Compl. 2013), Forbes
(FOCS 2015), and Kumar and Saraf (CCC 2016). Additionally, geometric
Sylvester-Gallai ideas of Kayal and Saraf (FOCS 2009), Shpilka (STOC 2019), and
Peleg and Shpilka (CCC 2020, STOC 2021). Very recently, a subexponential-time
blackbox PIT algorithm for constant-depth circuits was obtained via lower bound
breakthrough of Limaye, Srinivasan, Tavenas (FOCS 2021). We solve two of the
basic underlying open problems in this work.
</p>
<p>We give the first polynomial-time PIT for $\Sigma^{[k]}\Pi\Sigma\wedge$. We
also give the first quasipolynomial time blackbox PIT for both
$\Sigma^{[k]}\Pi\Sigma\wedge$ and $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$. A key
technical ingredient in all the three algorithms is how the logarithmic
derivative, and its power-series, modify the top $\Pi$-gate to $\wedge$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11495'>Explicit Directional Affine Extractors and Improved Hardness for Linear Branching Programs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xin Li, Yan Zhong</p><p>In a recent work, Gryaznov, Pudl\'{a}k, and Talebanfard (CCC' 22) introduced
a stronger version of affine extractors known as directional affine extractors,
together with a generalization of $\mathsf{ROBP}$s where each node can make
linear queries, and showed that the former implies strong lower bound for a
certain type of the latter known as strongly read-once linear branching
programs ($\mathsf{SROLBP}$s). Their main result gives explicit constructions
of directional affine extractors for entropy $k &gt; 2n/3$, which implies
average-case complexity $2^{n/3-o(n)}$ against $\mathsf{SROLBP}$s with
exponentially small correlation. A follow-up work by Chattopadhyay and Liao
(ECCC' 22) improves the hardness to $2^{n-o(n)}$ at the price of increasing the
correlation to polynomially large.
</p>
<p>This paper provides a much more in-depth study of directional affine
extractors, $\mathsf{SROLBP}$s, and $\mathsf{ROBP}$s. Our main results include:
</p>
<p>A formal separation between $\mathsf{SROLBP}$ and $\mathsf{ROBP}$, showing
that $\mathsf{SROLBP}$s can be exponentially more powerful than
$\mathsf{ROBP}$s.
</p>
<p>An explicit construction of directional affine extractors with $k=o(n)$ and
exponentially small error, which gives average-case complexity $2^{n-o(n)}$
against $\mathsf{SROLBP}$s with exponentially small correlation, thus answering
the two open questions raised in previous works.
</p>
<p>An explicit function in $\mathsf{AC}^0$ that gives average-case complexity
$2^{(1-\delta)n}$ against $\mathsf{ROBP}$s with negligible correlation, for any
constant $\delta&gt;0$. Previously, the best size lower bound for any function in
$\mathsf{AC}^0$ against $\mathsf{ROBP}$s is only $2^{\Omega(\sqrt{n})}$.
</p>
<p>One of the key ingredients in our constructions is a new linear somewhere
condenser for affine sources.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yan Zhong</a></p><p>In a recent work, Gryaznov, Pudl\'{a}k, and Talebanfard (CCC' 22) introduced
a stronger version of affine extractors known as directional affine extractors,
together with a generalization of $\mathsf{ROBP}$s where each node can make
linear queries, and showed that the former implies strong lower bound for a
certain type of the latter known as strongly read-once linear branching
programs ($\mathsf{SROLBP}$s). Their main result gives explicit constructions
of directional affine extractors for entropy $k &gt; 2n/3$, which implies
average-case complexity $2^{n/3-o(n)}$ against $\mathsf{SROLBP}$s with
exponentially small correlation. A follow-up work by Chattopadhyay and Liao
(ECCC' 22) improves the hardness to $2^{n-o(n)}$ at the price of increasing the
correlation to polynomially large.
</p>
<p>This paper provides a much more in-depth study of directional affine
extractors, $\mathsf{SROLBP}$s, and $\mathsf{ROBP}$s. Our main results include:
</p>
<p>A formal separation between $\mathsf{SROLBP}$ and $\mathsf{ROBP}$, showing
that $\mathsf{SROLBP}$s can be exponentially more powerful than
$\mathsf{ROBP}$s.
</p>
<p>An explicit construction of directional affine extractors with $k=o(n)$ and
exponentially small error, which gives average-case complexity $2^{n-o(n)}$
against $\mathsf{SROLBP}$s with exponentially small correlation, thus answering
the two open questions raised in previous works.
</p>
<p>An explicit function in $\mathsf{AC}^0$ that gives average-case complexity
$2^{(1-\delta)n}$ against $\mathsf{ROBP}$s with negligible correlation, for any
constant $\delta&gt;0$. Previously, the best size lower bound for any function in
$\mathsf{AC}^0$ against $\mathsf{ROBP}$s is only $2^{\Omega(\sqrt{n})}$.
</p>
<p>One of the key ingredients in our constructions is a new linear somewhere
condenser for affine sources.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11429'>The Voronoi Diagram of Rotating Rays with applications to Floodlight Illumination</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Carlos Alegr&#xed;a, Ioannis Mantas, Evanthia Papadopoulou, Marko Savi&#x107;, Carlos Seara, Martin Suderland</p><p>We study the Voronoi Diagram of Rotating Rays, a Voronoi structure where the
input sites are rays and the distance function between a point and a site/ray,
is the counterclockwise angular distance. This novel Voronoi diagram is
motivated by illumination or coverage problems, where a domain must be covered
by floodlights/wedges of uniform angle, and the goal is to find the minimum
angle necessary to cover the domain. We study the diagram in the plane, and we
present structural properties, combinatorial complexity bounds, and a
construction algorithm. If the rays are induced by a convex polygon, we show
how to construct the Voronoi diagram within this polygon in linear time. Using
this information, we can find in optimal linear time the Brocard angle, the
minimum angle required to illuminate a convex polygon with floodlights of
uniform angle.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alegria_C/0/1/0/all/0/1">Carlos Alegr&#xed;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Mantas_I/0/1/0/all/0/1">Ioannis Mantas</a>, <a href="http://arxiv.org/find/cs/1/au:+Papadopoulou_E/0/1/0/all/0/1">Evanthia Papadopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Savic_M/0/1/0/all/0/1">Marko Savi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Seara_C/0/1/0/all/0/1">Carlos Seara</a>, <a href="http://arxiv.org/find/cs/1/au:+Suderland_M/0/1/0/all/0/1">Martin Suderland</a></p><p>We study the Voronoi Diagram of Rotating Rays, a Voronoi structure where the
input sites are rays and the distance function between a point and a site/ray,
is the counterclockwise angular distance. This novel Voronoi diagram is
motivated by illumination or coverage problems, where a domain must be covered
by floodlights/wedges of uniform angle, and the goal is to find the minimum
angle necessary to cover the domain. We study the diagram in the plane, and we
present structural properties, combinatorial complexity bounds, and a
construction algorithm. If the rays are induced by a convex polygon, we show
how to construct the Voronoi diagram within this polygon in linear time. Using
this information, we can find in optimal linear time the Brocard angle, the
minimum angle required to illuminate a convex polygon with floodlights of
uniform angle.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11252'>High-Accuracy Multicommodity Flows via Iterative Refinement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Li Chen, Mingquan Ye</p><p>The multicommodity flow problem is a classic problem in network flow and
combinatorial optimization, with applications in transportation, communication,
logistics, and supply chain management, etc. Existing algorithms often focus on
low-accuracy approximate solutions, while high-accuracy algorithms typically
rely on general linear program solvers. In this paper, we present efficient
high-accuracy algorithms for a broad family of multicommodity flow problems on
undirected graphs, demonstrating improved running times compared to general
linear program solvers. Our main result shows that we can solve the $\ell_{q,
p}$-norm multicommodity flow problem to a $(1 + \varepsilon)$ approximation in
time $O_{q, p}(m^{1+o(1)} k^2 \log(1 / \varepsilon))$, where $k$ is the number
of commodities, and $O_{q, p}(\cdot)$ hides constants depending only on $q$ or
$p$. As $q$ and $p$ approach to $1$ and infinity respectively, $\ell_{q,
p}$-norm flow tends to maximum concurrent flow.
</p>
<p>We introduce the first iterative refinement framework for $\ell_{q, p}$-norm
minimization problems, which reduces the problem to solving a series of
decomposable residual problems. In the case of $k$-commodity flow, each
residual problem can be decomposed into $k$ single commodity convex flow
problems, each of which can be solved in almost-linear time. As many classical
variants of multicommodity flows were shown to be complete for linear programs
in the high-accuracy regime [Ding-Kyng-Zhang, ICALP'22], our result provides
new directions for studying more efficient high-accuracy multicommodity flow
algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Mingquan Ye</a></p><p>The multicommodity flow problem is a classic problem in network flow and
combinatorial optimization, with applications in transportation, communication,
logistics, and supply chain management, etc. Existing algorithms often focus on
low-accuracy approximate solutions, while high-accuracy algorithms typically
rely on general linear program solvers. In this paper, we present efficient
high-accuracy algorithms for a broad family of multicommodity flow problems on
undirected graphs, demonstrating improved running times compared to general
linear program solvers. Our main result shows that we can solve the $\ell_{q,
p}$-norm multicommodity flow problem to a $(1 + \varepsilon)$ approximation in
time $O_{q, p}(m^{1+o(1)} k^2 \log(1 / \varepsilon))$, where $k$ is the number
of commodities, and $O_{q, p}(\cdot)$ hides constants depending only on $q$ or
$p$. As $q$ and $p$ approach to $1$ and infinity respectively, $\ell_{q,
p}$-norm flow tends to maximum concurrent flow.
</p>
<p>We introduce the first iterative refinement framework for $\ell_{q, p}$-norm
minimization problems, which reduces the problem to solving a series of
decomposable residual problems. In the case of $k$-commodity flow, each
residual problem can be decomposed into $k$ single commodity convex flow
problems, each of which can be solved in almost-linear time. As many classical
variants of multicommodity flows were shown to be complete for linear programs
in the high-accuracy regime [Ding-Kyng-Zhang, ICALP'22], our result provides
new directions for studying more efficient high-accuracy multicommodity flow
algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11281'>Euclidean Capacitated Vehicle Routing in Random Setting: A $1.55$-Approximation Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zipei Nie, Hang Zhou</p><p>We study the unit-demand capacitated vehicle routing problem in the random
setting of the Euclidean plane. The objective is to visit $n$ random terminals
in a square using a set of tours of minimum total length, such that each tour
visits the depot and at most $k$ terminals.
</p>
<p>We design an elegant algorithm combining the classical sweep heuristic and
Arora's framework for the Euclidean traveling salesman problem [Journal of the
ACM 1998]. We show that our algorithm is a polynomial-time approximation of
ratio at most $1.55$ asymptotically almost surely. This improves on previous
approximation ratios of $1.995$ due to Bompadre, Dror, and Orlin [Journal of
Applied Probability 2007] and $1.915$ due to Mathieu and Zhou [Random
Structures and Algorithms 2022]. In addition, we conjecture that, for any
$\varepsilon&gt;0$, our algorithm is a $(1+\varepsilon)$-approximation
asymptotically almost surely.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nie_Z/0/1/0/all/0/1">Zipei Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hang Zhou</a></p><p>We study the unit-demand capacitated vehicle routing problem in the random
setting of the Euclidean plane. The objective is to visit $n$ random terminals
in a square using a set of tours of minimum total length, such that each tour
visits the depot and at most $k$ terminals.
</p>
<p>We design an elegant algorithm combining the classical sweep heuristic and
Arora's framework for the Euclidean traveling salesman problem [Journal of the
ACM 1998]. We show that our algorithm is a polynomial-time approximation of
ratio at most $1.55$ asymptotically almost surely. This improves on previous
approximation ratios of $1.995$ due to Bompadre, Dror, and Orlin [Journal of
Applied Probability 2007] and $1.915$ due to Mathieu and Zhou [Random
Structures and Algorithms 2022]. In addition, we conjecture that, for any
$\varepsilon&gt;0$, our algorithm is a $(1+\varepsilon)$-approximation
asymptotically almost surely.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11691'>Covering multigraphs with bipartite graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jaehoon Kim, Hyunwoo Lee</p><p>Hansel's lemma states that $\sum_{H\in \mathcal{H}}|H| \geq n \log_2 n$ holds
where $\mathcal{H}$ is a collection of bipartite graphs covering all the edges
of $K_n$. We generalize this lemma to the corresponding multigraph covering
problem and the graphon covering problem. We also prove an upper bound on
$\sum_{H\in \mathcal{H}}|H|$ which shows that our generalization is
asymptotically tight in some sense.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Kim_J/0/1/0/all/0/1">Jaehoon Kim</a>, <a href="http://arxiv.org/find/math/1/au:+Lee_H/0/1/0/all/0/1">Hyunwoo Lee</a></p><p>Hansel's lemma states that $\sum_{H\in \mathcal{H}}|H| \geq n \log_2 n$ holds
where $\mathcal{H}$ is a collection of bipartite graphs covering all the edges
of $K_n$. We generalize this lemma to the corresponding multigraph covering
problem and the graphon covering problem. We also prove an upper bound on
$\sum_{H\in \mathcal{H}}|H|$ which shows that our generalization is
asymptotically tight in some sense.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-25T00:30:00Z">Tuesday, April 25 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, April 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10570'>Geometry of Tensors: Open problems and research directions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fulvio Gesmundo</p><p>This is a collection of open problems and research ideas following the
presentations and the discussions of the AGATES Kickoff Workshop held at the
Institute of Mathematics of the Polish Academy of Sciences (IMPAN) and at the
Department of Mathematics of University of Warsaw (MIM UW), September 19-26,
2022.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gesmundo_F/0/1/0/all/0/1">Fulvio Gesmundo</a></p><p>This is a collection of open problems and research ideas following the
presentations and the discussions of the AGATES Kickoff Workshop held at the
Institute of Mathematics of the Polish Academy of Sciences (IMPAN) and at the
Department of Mathematics of University of Warsaw (MIM UW), September 19-26,
2022.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10594'>Comparative Analysis of Deterministic and Nondeterministic Decision Trees for Decision Tables from Closed Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Azimkhon Ostonov, Mikhail Moshkov</p><p>In this paper, we consider classes of decision tables with many-valued
decisions closed under operations of removal of columns, changing of decisions,
permutation of columns, and duplication of columns. We study relationships
among three parameters of these tables: the complexity of a decision table (if
we consider the depth of decision trees, then the complexity of a decision
table is the number of columns in it), the minimum complexity of a
deterministic decision tree, and the minimum complexity of a nondeterministic
decision tree. We consider rough classification of functions characterizing
relationships and enumerate all possible seven types of the relationships.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ostonov_A/0/1/0/all/0/1">Azimkhon Ostonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshkov_M/0/1/0/all/0/1">Mikhail Moshkov</a></p><p>In this paper, we consider classes of decision tables with many-valued
decisions closed under operations of removal of columns, changing of decisions,
permutation of columns, and duplication of columns. We study relationships
among three parameters of these tables: the complexity of a decision table (if
we consider the depth of decision trees, then the complexity of a decision
table is the number of columns in it), the minimum complexity of a
deterministic decision tree, and the minimum complexity of a nondeterministic
decision tree. We consider rough classification of functions characterizing
relationships and enumerate all possible seven types of the relationships.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10661'>A Conjecture Related to the Traveling Salesman Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jian Yang</p><p>We show that certain ways of solving some combinatorial optimization problems
can be understood as using query planes to divide the space of problem
instances into polyhedra that could fit into those that characterize the
problem's various solutions. This viewpoint naturally leads to a
splinter-proneness property that is then shown to be responsible for the
hardness of the concerned problem. We conjecture that the $NP$-equivalent
traveling salesman problem (TSP) has this property and hence is hard to solve
to a certain extent.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jian Yang</a></p><p>We show that certain ways of solving some combinatorial optimization problems
can be understood as using query planes to divide the space of problem
instances into polyhedra that could fit into those that characterize the
problem's various solutions. This viewpoint naturally leads to a
splinter-proneness property that is then shown to be responsible for the
hardness of the concerned problem. We conjecture that the $NP$-equivalent
traveling salesman problem (TSP) has this property and hence is hard to solve
to a certain extent.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11017'>Breaking the Log Barrier: a Novel Universal Restart Strategy for Faster Las Vegas Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kevin Scaman</p><p>Let $\mathcal{A}$ be a Las Vegas algorithm, i.e. an algorithm whose running
time $T$ is a random variable drawn according to a certain probability
distribution $p$. In 1993, Luby, Sinclair and Zuckerman [LSZ93] proved that a
simple universal restart strategy can, for any probability distribution $p$,
provide an algorithm executing $\mathcal{A}$ and whose expected running time is
$O(\ell^\star_p\log\ell^\star_p)$, where $\ell^\star_p=\Theta\left(\inf_{q\in
(0,1]}Q_p(q)/q\right)$ is the minimum expected running time achievable with
full prior knowledge of the probability distribution $p$, and $Q_p(q)$ is the
$q$-quantile of $p$. Moreover, the authors showed that the logarithmic term
could not be removed for universal restart strategies and was, in a certain
sense, optimal. In this work, we show that, quite surprisingly, the logarithmic
term can be replaced by a smaller quantity, thus reducing the expected running
time in practical settings of interest. More precisely, we propose a novel
restart strategy that executes $\mathcal{A}$ and whose expected running time is
$O\big(\inf_{q\in (0,1]}\frac{Q_p(q)}{q}\,\psi\big(\log Q_p(q),\,\log
(1/q)\big)\big)$ where $\psi(a,b)=1+\min\left\{a+b,a\log^2 a,\,b\log^2
b\right\}$. This quantity is, up to a multiplicative factor, better than: 1)
the universal restart strategy of [LSZ93], 2) any $q$-quantile of $p$ for
$q\in(0,1]$, 3) the original algorithm, and 4) any quantity of the form
$\phi^{-1}(\mathbb{E}[\phi(T)])$ for a large class of concave functions $\phi$.
The latter extends the recent restart strategy of [Zam22] achieving
$O\left(e^{\mathbb{E}[\ln(T)]}\right)$, and can be thought of as algorithmic
reverse Jensen's inequalities. Finally, we show that the behavior of
$\frac{t\phi''(t)}{\phi'(t)}$ at infinity controls the existence of reverse
Jensen's inequalities by providing a necessary and a sufficient condition for
these inequalities to hold.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Scaman_K/0/1/0/all/0/1">Kevin Scaman</a></p><p>Let $\mathcal{A}$ be a Las Vegas algorithm, i.e. an algorithm whose running
time $T$ is a random variable drawn according to a certain probability
distribution $p$. In 1993, Luby, Sinclair and Zuckerman [LSZ93] proved that a
simple universal restart strategy can, for any probability distribution $p$,
provide an algorithm executing $\mathcal{A}$ and whose expected running time is
$O(\ell^\star_p\log\ell^\star_p)$, where $\ell^\star_p=\Theta\left(\inf_{q\in
(0,1]}Q_p(q)/q\right)$ is the minimum expected running time achievable with
full prior knowledge of the probability distribution $p$, and $Q_p(q)$ is the
$q$-quantile of $p$. Moreover, the authors showed that the logarithmic term
could not be removed for universal restart strategies and was, in a certain
sense, optimal. In this work, we show that, quite surprisingly, the logarithmic
term can be replaced by a smaller quantity, thus reducing the expected running
time in practical settings of interest. More precisely, we propose a novel
restart strategy that executes $\mathcal{A}$ and whose expected running time is
$O\big(\inf_{q\in (0,1]}\frac{Q_p(q)}{q}\,\psi\big(\log Q_p(q),\,\log
(1/q)\big)\big)$ where $\psi(a,b)=1+\min\left\{a+b,a\log^2 a,\,b\log^2
b\right\}$. This quantity is, up to a multiplicative factor, better than: 1)
the universal restart strategy of [LSZ93], 2) any $q$-quantile of $p$ for
$q\in(0,1]$, 3) the original algorithm, and 4) any quantity of the form
$\phi^{-1}(\mathbb{E}[\phi(T)])$ for a large class of concave functions $\phi$.
The latter extends the recent restart strategy of [Zam22] achieving
$O\left(e^{\mathbb{E}[\ln(T)]}\right)$, and can be thought of as algorithmic
reverse Jensen's inequalities. Finally, we show that the behavior of
$\frac{t\phi''(t)}{\phi'(t)}$ at infinity controls the existence of reverse
Jensen's inequalities by providing a necessary and a sufficient condition for
these inequalities to hold.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11102'>Solid angle measure of polyhedral cones</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Allison Fitisone, Yuan Zhou</p><p>This paper addresses the computation of normalized solid angle measure of
polyhedral cones. This is well understood in dimensions two and three. For
higher dimensions, assuming that a positive-definite criterion is met, the
measure can be computed via a multivariable hypergeometric series. We present
two decompositions of full-dimensional simplicial cones into finite families of
cones satisfying the positive-definite criterion, enabling the use of the
hypergeometric series to compute the solid angle measure of any polyhedral
cone. Additionally, our second decomposition method yields cones with a special
tridiagonal structure, reducing the number of required coordinates for the
hypergeometric series formula. Furthermore, we investigate the convergence of
the hypergeometric series for this case. Our findings provide a powerful tool
for computing solid angle measures in high-dimensional spaces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Fitisone_A/0/1/0/all/0/1">Allison Fitisone</a>, <a href="http://arxiv.org/find/math/1/au:+Zhou_Y/0/1/0/all/0/1">Yuan Zhou</a></p><p>This paper addresses the computation of normalized solid angle measure of
polyhedral cones. This is well understood in dimensions two and three. For
higher dimensions, assuming that a positive-definite criterion is met, the
measure can be computed via a multivariable hypergeometric series. We present
two decompositions of full-dimensional simplicial cones into finite families of
cones satisfying the positive-definite criterion, enabling the use of the
hypergeometric series to compute the solid angle measure of any polyhedral
cone. Additionally, our second decomposition method yields cones with a special
tridiagonal structure, reducing the number of required coordinates for the
hypergeometric series formula. Furthermore, we investigate the convergence of
the hypergeometric series for this case. Our findings provide a powerful tool
for computing solid angle measures in high-dimensional spaces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10647'>New Lower Bounds for Adaptive Tolerant Junta Testing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xi Chen, Shyamal Patel</p><p>We prove a $k^{-\Omega(\log(\varepsilon_2 - \varepsilon_1))}$ lower bound for
adaptively testing whether a Boolean function is $\varepsilon_1$-close to or
$\varepsilon_2$-far from $k$-juntas. Our results provide the first
superpolynomial separation between tolerant and non-tolerant testing for a
natural property of boolean functions under the adaptive setting. Furthermore,
our techniques generalize to show that adaptively testing whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from $(k +
o(k))$-juntas cannot be done with $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries. This is in contrast to an algorithm by Iyer, Tal
and Whitmeyer [CCC 2021] which uses $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries to test whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from
$O(k/(\varepsilon_2-\varepsilon_1)^2)$-juntas.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1">Shyamal Patel</a></p><p>We prove a $k^{-\Omega(\log(\varepsilon_2 - \varepsilon_1))}$ lower bound for
adaptively testing whether a Boolean function is $\varepsilon_1$-close to or
$\varepsilon_2$-far from $k$-juntas. Our results provide the first
superpolynomial separation between tolerant and non-tolerant testing for a
natural property of boolean functions under the adaptive setting. Furthermore,
our techniques generalize to show that adaptively testing whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from $(k +
o(k))$-juntas cannot be done with $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries. This is in contrast to an algorithm by Iyer, Tal
and Whitmeyer [CCC 2021] which uses $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries to test whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from
$O(k/(\varepsilon_2-\varepsilon_1)^2)$-juntas.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
