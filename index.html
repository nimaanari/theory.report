<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-04-24T21:30:32Z">Monday, April 24 2023, 21:30</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, April 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10570'>Geometry of Tensors: Open problems and research directions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fulvio Gesmundo</p><p>This is a collection of open problems and research ideas following the
presentations and the discussions of the AGATES Kickoff Workshop held at the
Institute of Mathematics of the Polish Academy of Sciences (IMPAN) and at the
Department of Mathematics of University of Warsaw (MIM UW), September 19-26,
2022.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gesmundo_F/0/1/0/all/0/1">Fulvio Gesmundo</a></p><p>This is a collection of open problems and research ideas following the
presentations and the discussions of the AGATES Kickoff Workshop held at the
Institute of Mathematics of the Polish Academy of Sciences (IMPAN) and at the
Department of Mathematics of University of Warsaw (MIM UW), September 19-26,
2022.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10594'>Comparative Analysis of Deterministic and Nondeterministic Decision Trees for Decision Tables from Closed Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Azimkhon Ostonov, Mikhail Moshkov</p><p>In this paper, we consider classes of decision tables with many-valued
decisions closed under operations of removal of columns, changing of decisions,
permutation of columns, and duplication of columns. We study relationships
among three parameters of these tables: the complexity of a decision table (if
we consider the depth of decision trees, then the complexity of a decision
table is the number of columns in it), the minimum complexity of a
deterministic decision tree, and the minimum complexity of a nondeterministic
decision tree. We consider rough classification of functions characterizing
relationships and enumerate all possible seven types of the relationships.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ostonov_A/0/1/0/all/0/1">Azimkhon Ostonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshkov_M/0/1/0/all/0/1">Mikhail Moshkov</a></p><p>In this paper, we consider classes of decision tables with many-valued
decisions closed under operations of removal of columns, changing of decisions,
permutation of columns, and duplication of columns. We study relationships
among three parameters of these tables: the complexity of a decision table (if
we consider the depth of decision trees, then the complexity of a decision
table is the number of columns in it), the minimum complexity of a
deterministic decision tree, and the minimum complexity of a nondeterministic
decision tree. We consider rough classification of functions characterizing
relationships and enumerate all possible seven types of the relationships.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10661'>A Conjecture Related to the Traveling Salesman Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jian Yang</p><p>We show that certain ways of solving some combinatorial optimization problems
can be understood as using query planes to divide the space of problem
instances into polyhedra that could fit into those that characterize the
problem's various solutions. This viewpoint naturally leads to a
splinter-proneness property that is then shown to be responsible for the
hardness of the concerned problem. We conjecture that the $NP$-equivalent
traveling salesman problem (TSP) has this property and hence is hard to solve
to a certain extent.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jian Yang</a></p><p>We show that certain ways of solving some combinatorial optimization problems
can be understood as using query planes to divide the space of problem
instances into polyhedra that could fit into those that characterize the
problem's various solutions. This viewpoint naturally leads to a
splinter-proneness property that is then shown to be responsible for the
hardness of the concerned problem. We conjecture that the $NP$-equivalent
traveling salesman problem (TSP) has this property and hence is hard to solve
to a certain extent.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11017'>Breaking the Log Barrier: a Novel Universal Restart Strategy for Faster Las Vegas Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kevin Scaman</p><p>Let $\mathcal{A}$ be a Las Vegas algorithm, i.e. an algorithm whose running
time $T$ is a random variable drawn according to a certain probability
distribution $p$. In 1993, Luby, Sinclair and Zuckerman [LSZ93] proved that a
simple universal restart strategy can, for any probability distribution $p$,
provide an algorithm executing $\mathcal{A}$ and whose expected running time is
$O(\ell^\star_p\log\ell^\star_p)$, where $\ell^\star_p=\Theta\left(\inf_{q\in
(0,1]}Q_p(q)/q\right)$ is the minimum expected running time achievable with
full prior knowledge of the probability distribution $p$, and $Q_p(q)$ is the
$q$-quantile of $p$. Moreover, the authors showed that the logarithmic term
could not be removed for universal restart strategies and was, in a certain
sense, optimal. In this work, we show that, quite surprisingly, the logarithmic
term can be replaced by a smaller quantity, thus reducing the expected running
time in practical settings of interest. More precisely, we propose a novel
restart strategy that executes $\mathcal{A}$ and whose expected running time is
$O\big(\inf_{q\in (0,1]}\frac{Q_p(q)}{q}\,\psi\big(\log Q_p(q),\,\log
(1/q)\big)\big)$ where $\psi(a,b)=1+\min\left\{a+b,a\log^2 a,\,b\log^2
b\right\}$. This quantity is, up to a multiplicative factor, better than: 1)
the universal restart strategy of [LSZ93], 2) any $q$-quantile of $p$ for
$q\in(0,1]$, 3) the original algorithm, and 4) any quantity of the form
$\phi^{-1}(\mathbb{E}[\phi(T)])$ for a large class of concave functions $\phi$.
The latter extends the recent restart strategy of [Zam22] achieving
$O\left(e^{\mathbb{E}[\ln(T)]}\right)$, and can be thought of as algorithmic
reverse Jensen's inequalities. Finally, we show that the behavior of
$\frac{t\phi''(t)}{\phi'(t)}$ at infinity controls the existence of reverse
Jensen's inequalities by providing a necessary and a sufficient condition for
these inequalities to hold.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Scaman_K/0/1/0/all/0/1">Kevin Scaman</a></p><p>Let $\mathcal{A}$ be a Las Vegas algorithm, i.e. an algorithm whose running
time $T$ is a random variable drawn according to a certain probability
distribution $p$. In 1993, Luby, Sinclair and Zuckerman [LSZ93] proved that a
simple universal restart strategy can, for any probability distribution $p$,
provide an algorithm executing $\mathcal{A}$ and whose expected running time is
$O(\ell^\star_p\log\ell^\star_p)$, where $\ell^\star_p=\Theta\left(\inf_{q\in
(0,1]}Q_p(q)/q\right)$ is the minimum expected running time achievable with
full prior knowledge of the probability distribution $p$, and $Q_p(q)$ is the
$q$-quantile of $p$. Moreover, the authors showed that the logarithmic term
could not be removed for universal restart strategies and was, in a certain
sense, optimal. In this work, we show that, quite surprisingly, the logarithmic
term can be replaced by a smaller quantity, thus reducing the expected running
time in practical settings of interest. More precisely, we propose a novel
restart strategy that executes $\mathcal{A}$ and whose expected running time is
$O\big(\inf_{q\in (0,1]}\frac{Q_p(q)}{q}\,\psi\big(\log Q_p(q),\,\log
(1/q)\big)\big)$ where $\psi(a,b)=1+\min\left\{a+b,a\log^2 a,\,b\log^2
b\right\}$. This quantity is, up to a multiplicative factor, better than: 1)
the universal restart strategy of [LSZ93], 2) any $q$-quantile of $p$ for
$q\in(0,1]$, 3) the original algorithm, and 4) any quantity of the form
$\phi^{-1}(\mathbb{E}[\phi(T)])$ for a large class of concave functions $\phi$.
The latter extends the recent restart strategy of [Zam22] achieving
$O\left(e^{\mathbb{E}[\ln(T)]}\right)$, and can be thought of as algorithmic
reverse Jensen's inequalities. Finally, we show that the behavior of
$\frac{t\phi''(t)}{\phi'(t)}$ at infinity controls the existence of reverse
Jensen's inequalities by providing a necessary and a sufficient condition for
these inequalities to hold.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11102'>Solid angle measure of polyhedral cones</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Allison Fitisone, Yuan Zhou</p><p>This paper addresses the computation of normalized solid angle measure of
polyhedral cones. This is well understood in dimensions two and three. For
higher dimensions, assuming that a positive-definite criterion is met, the
measure can be computed via a multivariable hypergeometric series. We present
two decompositions of full-dimensional simplicial cones into finite families of
cones satisfying the positive-definite criterion, enabling the use of the
hypergeometric series to compute the solid angle measure of any polyhedral
cone. Additionally, our second decomposition method yields cones with a special
tridiagonal structure, reducing the number of required coordinates for the
hypergeometric series formula. Furthermore, we investigate the convergence of
the hypergeometric series for this case. Our findings provide a powerful tool
for computing solid angle measures in high-dimensional spaces.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Fitisone_A/0/1/0/all/0/1">Allison Fitisone</a>, <a href="http://arxiv.org/find/math/1/au:+Zhou_Y/0/1/0/all/0/1">Yuan Zhou</a></p><p>This paper addresses the computation of normalized solid angle measure of
polyhedral cones. This is well understood in dimensions two and three. For
higher dimensions, assuming that a positive-definite criterion is met, the
measure can be computed via a multivariable hypergeometric series. We present
two decompositions of full-dimensional simplicial cones into finite families of
cones satisfying the positive-definite criterion, enabling the use of the
hypergeometric series to compute the solid angle measure of any polyhedral
cone. Additionally, our second decomposition method yields cones with a special
tridiagonal structure, reducing the number of required coordinates for the
hypergeometric series formula. Furthermore, we investigate the convergence of
the hypergeometric series for this case. Our findings provide a powerful tool
for computing solid angle measures in high-dimensional spaces.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10647'>New Lower Bounds for Adaptive Tolerant Junta Testing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xi Chen, Shyamal Patel</p><p>We prove a $k^{-\Omega(\log(\varepsilon_2 - \varepsilon_1))}$ lower bound for
adaptively testing whether a Boolean function is $\varepsilon_1$-close to or
$\varepsilon_2$-far from $k$-juntas. Our results provide the first
superpolynomial separation between tolerant and non-tolerant testing for a
natural property of boolean functions under the adaptive setting. Furthermore,
our techniques generalize to show that adaptively testing whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from $(k +
o(k))$-juntas cannot be done with $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries. This is in contrast to an algorithm by Iyer, Tal
and Whitmeyer [CCC 2021] which uses $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries to test whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from
$O(k/(\varepsilon_2-\varepsilon_1)^2)$-juntas.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1">Shyamal Patel</a></p><p>We prove a $k^{-\Omega(\log(\varepsilon_2 - \varepsilon_1))}$ lower bound for
adaptively testing whether a Boolean function is $\varepsilon_1$-close to or
$\varepsilon_2$-far from $k$-juntas. Our results provide the first
superpolynomial separation between tolerant and non-tolerant testing for a
natural property of boolean functions under the adaptive setting. Furthermore,
our techniques generalize to show that adaptively testing whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from $(k +
o(k))$-juntas cannot be done with $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries. This is in contrast to an algorithm by Iyer, Tal
and Whitmeyer [CCC 2021] which uses $\textsf{poly} (k, (\varepsilon_2 -
\varepsilon_1)^{-1})$ queries to test whether a function is
$\varepsilon_1$-close to a $k$-junta or $\varepsilon_2$-far from
$O(k/(\varepsilon_2-\varepsilon_1)^2)$-juntas.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10848'>How Well Does the Metropolis Algorithm Cope With Local Optima?</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benjamin Doerr, Taha El Ghazi El Houssaini, Amirhossein Rajabi, Carsten Wit</p><p>The Metropolis algorithm (MA) is a classic stochastic local search heuristic.
It avoids getting stuck in local optima by occasionally accepting inferior
solutions. To better and in a rigorous manner understand this ability, we
conduct a mathematical runtime analysis of the MA on the CLIFF benchmark. Apart
from one local optimum, cliff functions are monotonically increasing towards
the global optimum. Consequently, to optimize a cliff function, the MA only
once needs to accept an inferior solution. Despite seemingly being an ideal
benchmark for the MA to profit from its main working principle, our
mathematical runtime analysis shows that this hope does not come true. Even
with the optimal temperature (the only parameter of the MA), the MA optimizes
most cliff functions less efficiently than simple elitist evolutionary
algorithms (EAs), which can only leave the local optimum by generating a
superior solution possibly far away. This result suggests that our
understanding of why the MA is often very successful in practice is not yet
complete. Our work also suggests to equip the MA with global mutation
operators, an idea supported by our preliminary experiments.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1">Benjamin Doerr</a>, <a href="http://arxiv.org/find/cs/1/au:+Houssaini_T/0/1/0/all/0/1">Taha El Ghazi El Houssaini</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajabi_A/0/1/0/all/0/1">Amirhossein Rajabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wit_C/0/1/0/all/0/1">Carsten Wit</a></p><p>The Metropolis algorithm (MA) is a classic stochastic local search heuristic.
It avoids getting stuck in local optima by occasionally accepting inferior
solutions. To better and in a rigorous manner understand this ability, we
conduct a mathematical runtime analysis of the MA on the CLIFF benchmark. Apart
from one local optimum, cliff functions are monotonically increasing towards
the global optimum. Consequently, to optimize a cliff function, the MA only
once needs to accept an inferior solution. Despite seemingly being an ideal
benchmark for the MA to profit from its main working principle, our
mathematical runtime analysis shows that this hope does not come true. Even
with the optimal temperature (the only parameter of the MA), the MA optimizes
most cliff functions less efficiently than simple elitist evolutionary
algorithms (EAs), which can only leave the local optimum by generating a
superior solution possibly far away. This result suggests that our
understanding of why the MA is often very successful in practice is not yet
complete. Our work also suggests to equip the MA with global mutation
operators, an idea supported by our preliminary experiments.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10962'>Faster Prefix-Sorting Algorithms for Deterministic Finite Automata</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sung-Hwan Kim, Francisco Olivares, Nicola Prezza</p><p>Sorting is a fundamental algorithmic pre-processing technique which often
allows to represent data more compactly and, at the same time, speeds up search
queries on it. In this paper, we focus on the well-studied problem of sorting
and indexing string sets. Since the introduction of suffix trees in 1973,
dozens of suffix sorting algorithms have been described in the literature. In
2017, these techniques were extended to sets of strings described by means of
finite automata: the theory of Wheeler graphs [Gagie et al., TCS'17] introduced
automata whose states can be totally-sorted according to the co-lexicographic
(co-lex in the following) order of the prefixes of words accepted by the
automaton. More recently, in [Cotumaccio, Prezza, SODA'21] it was shown how to
extend these ideas to arbitrary automata by means of partial co-lex orders.
This work showed that a co-lex order of minimum width (thus optimizing search
query times) on deterministic finite automata (DFAs) can be computed in $O(m^2
+ n^{5/2})$ time, $m$ being the number of transitions and $n$ the number of
states of the input DFA.
</p>
<p>In this paper, we exhibit new combinatorial properties of the minimum-width
co-lex order of DFAs and exploit them to design faster prefix sorting
algorithms. In particular, we describe two algorithms sorting arbitrary DFAs in
$O(mn)$ and $O(n^2\log n)$ time, respectively, and an algorithm sorting acyclic
DFAs in $O(m\log n)$ time. Within these running times, all algorithms compute
also a smallest chain partition of the partial order (required to index the
DFA). We present an experiment result to show that an optimized implementation
of the $O(n^2\log n)$-time algorithm exhibits a nearly-linear behaviour on
large deterministic pan-genomic graphs and is thus also of practical interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sung-Hwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Olivares_F/0/1/0/all/0/1">Francisco Olivares</a>, <a href="http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1">Nicola Prezza</a></p><p>Sorting is a fundamental algorithmic pre-processing technique which often
allows to represent data more compactly and, at the same time, speeds up search
queries on it. In this paper, we focus on the well-studied problem of sorting
and indexing string sets. Since the introduction of suffix trees in 1973,
dozens of suffix sorting algorithms have been described in the literature. In
2017, these techniques were extended to sets of strings described by means of
finite automata: the theory of Wheeler graphs [Gagie et al., TCS'17] introduced
automata whose states can be totally-sorted according to the co-lexicographic
(co-lex in the following) order of the prefixes of words accepted by the
automaton. More recently, in [Cotumaccio, Prezza, SODA'21] it was shown how to
extend these ideas to arbitrary automata by means of partial co-lex orders.
This work showed that a co-lex order of minimum width (thus optimizing search
query times) on deterministic finite automata (DFAs) can be computed in $O(m^2
+ n^{5/2})$ time, $m$ being the number of transitions and $n$ the number of
states of the input DFA.
</p>
<p>In this paper, we exhibit new combinatorial properties of the minimum-width
co-lex order of DFAs and exploit them to design faster prefix sorting
algorithms. In particular, we describe two algorithms sorting arbitrary DFAs in
$O(mn)$ and $O(n^2\log n)$ time, respectively, and an algorithm sorting acyclic
DFAs in $O(m\log n)$ time. Within these running times, all algorithms compute
also a smallest chain partition of the partial order (required to index the
DFA). We present an experiment result to show that an optimized implementation
of the $O(n^2\log n)$-time algorithm exhibits a nearly-linear behaviour on
large deterministic pan-genomic graphs and is thus also of practical interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10995'>Solving the List Coloring Problem through a Branch-and-Price algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mauro Lucci, Daniel Severin, Graciela Nasini</p><p>In this work, we present a branch-and-price algorithm to solve the weighted
version of the List Coloring Problem, based on a vertex cover formulation by
stable sets. This problem is interesting for its applications and also for the
many other problems that it generalizes, including the well-known Graph
Coloring Problem. With the introduction of the concept of indistinguishable
colors, some theoretical results are presented which are later incorporated
into the algorithm. We propose two branching strategies based on others for the
Graph Coloring Problem, the first is an adaptation of the one used by Mehrotra
and Trick in their pioneering branch-and-price algorithm, and the other is
inspired by the one used by M\'endez-D\'iaz and Zabala in their branch-and-cut
algorithm. The rich structure of this problem makes both branching strategies
robust. Extended computation experimentation on a wide variety of instances
shows the effectiveness of this approach and evidences the different behaviors
that the algorithm can have according to the structure of each type of
instance.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lucci_M/0/1/0/all/0/1">Mauro Lucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Severin_D/0/1/0/all/0/1">Daniel Severin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasini_G/0/1/0/all/0/1">Graciela Nasini</a></p><p>In this work, we present a branch-and-price algorithm to solve the weighted
version of the List Coloring Problem, based on a vertex cover formulation by
stable sets. This problem is interesting for its applications and also for the
many other problems that it generalizes, including the well-known Graph
Coloring Problem. With the introduction of the concept of indistinguishable
colors, some theoretical results are presented which are later incorporated
into the algorithm. We propose two branching strategies based on others for the
Graph Coloring Problem, the first is an adaptation of the one used by Mehrotra
and Trick in their pioneering branch-and-price algorithm, and the other is
inspired by the one used by M\'endez-D\'iaz and Zabala in their branch-and-cut
algorithm. The rich structure of this problem makes both branching strategies
robust. Extended computation experimentation on a wide variety of instances
shows the effectiveness of this approach and evidences the different behaviors
that the algorithm can have according to the structure of each type of
instance.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.11012'>Learned Monotone Minimal Perfect Hashing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Paolo Ferragina, Hans-Peter Lehmann, Peter Sanders, Giorgio Vinciguerra</p><p>A Monotone Minimal Perfect Hash Function (MMPHF) constructed on a set S of
keys is a function that maps each key in S to its rank. On keys not in S, the
function returns an arbitrary value. Applications range from databases, search
engines, data encryption, to pattern-matching algorithms.
</p>
<p>In this paper, we describe LeMonHash, a new technique for constructing MMPHFs
for integers. The core idea of LeMonHash is surprisingly simple and effective:
we learn a monotone mapping from keys to their rank via an error-bounded
piecewise linear model (the PGM-index), and then we solve the collisions that
might arise among keys mapping to the same rank estimate by associating small
integers with them in a retrieval data structure (BuRR). On synthetic random
datasets, LeMonHash needs 35% less space than the next best competitor, while
achieving about 16 times faster queries. On real-world datasets, the space
usage is very close to or much better than the best competitors, while
achieving up to 19 times faster queries than the next larger competitor. As far
as the construction of LeMonHash is concerned, we get an improvement by a
factor of up to 2, compared to the competitor with the next best space usage.
</p>
<p>We also investigate the case of keys being variable-length strings,
introducing the so-called LeMonHash-VL: it needs space within 10% of the best
competitors while achieving up to 3 times faster queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ferragina_P/0/1/0/all/0/1">Paolo Ferragina</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehmann_H/0/1/0/all/0/1">Hans-Peter Lehmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanders_P/0/1/0/all/0/1">Peter Sanders</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinciguerra_G/0/1/0/all/0/1">Giorgio Vinciguerra</a></p><p>A Monotone Minimal Perfect Hash Function (MMPHF) constructed on a set S of
keys is a function that maps each key in S to its rank. On keys not in S, the
function returns an arbitrary value. Applications range from databases, search
engines, data encryption, to pattern-matching algorithms.
</p>
<p>In this paper, we describe LeMonHash, a new technique for constructing MMPHFs
for integers. The core idea of LeMonHash is surprisingly simple and effective:
we learn a monotone mapping from keys to their rank via an error-bounded
piecewise linear model (the PGM-index), and then we solve the collisions that
might arise among keys mapping to the same rank estimate by associating small
integers with them in a retrieval data structure (BuRR). On synthetic random
datasets, LeMonHash needs 35% less space than the next best competitor, while
achieving about 16 times faster queries. On real-world datasets, the space
usage is very close to or much better than the best competitors, while
achieving up to 19 times faster queries than the next larger competitor. As far
as the construction of LeMonHash is concerned, we get an improvement by a
factor of up to 2, compared to the competitor with the next best space usage.
</p>
<p>We also investigate the case of keys being variable-length strings,
introducing the so-called LeMonHash-VL: it needs space within 10% of the best
competitors while achieving up to 3 times faster queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-24T00:30:00Z">Monday, April 24 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, April 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/thoughts-on-gordon-moore.html'>Thoughts on Gordon Moore</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>&nbsp;Gordon Moore passed away on March 24, 2023. He was 94 years old.&nbsp;</p><p>He is best known for the article&nbsp;</p><p><br></p><p>Cramming more components onto integrated circuits.&nbsp;</p><p>It appeared in the magazine Electronics (it is now defunct), Volume 38, No. 8, April 19, 1965. Do you need to track it down in the basement of your library. No. Its&nbsp;here&nbsp;and here.&nbsp;I wonder if Moore would have predicted that his article would be available easily over 50 years later. Or is it? Link rot is a serious problem so you might want to download it to your local files. Note that the first link is some sort of official version and the second version is my local version. Not clear which link will rot first. The article also has an addition which is an interview with Moore that was done later.</p><p>In the article Moore said that the number of components-per-circuit (I think that means chip) will double every year. Moore credits Dave House with modifying it to `doubling every 18 months' and Carver Mead with calling it `Moore's Law'.&nbsp; Later it came to be quoted as computer SPEED would double every 18 months. We will take this to be Moore's Law in this blog post.&nbsp;</p><p>Is Moore's law dead? Browsing Google the answer seems to be that it is slowing down but not dead yet. (IDEA for a comedy sketch: Redo the Monty Python Dead Parrot sketch about the death of Moore's law.)&nbsp;</p><p>If Moore had 1 penny in April 1965 and it doubled every 18 months then how rich would he be now? How rich was he in April 2022? Compare the two numbers.&nbsp;</p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>&nbsp;Gordon Moore passed away on March 24, 2023. He was 94 years old.&nbsp;</p><p>He is best known for the article&nbsp;</p><p><br /></p><p><i>Cramming more components onto integrated circuits.&nbsp;</i></p><p>It appeared in the magazine Electronics (it is now defunct), Volume 38, No. 8, April 19, 1965. Do you need to track it down in the basement of your library. No. Its&nbsp;<a href="https://hasler.ece.gatech.edu/Published_papers/Technology_overview/gordon_moore_1965_article.pdf">here</a>&nbsp;and <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/gmoore.pdf">here</a>.&nbsp;I wonder if Moore would have predicted that his article would be available easily over 50 years later. Or is it? Link rot is a serious problem so you might want to download it to your local files. Note that the first link is some sort of official version and the second version is my local version. Not clear which link will rot first. The article also has an addition which is an interview with Moore that was done later.</p><p>In the article Moore said that the number of components-per-circuit (I think that means chip) will double every year. Moore credits Dave House with modifying it to `doubling every 18 months' and Carver Mead with calling it `Moore's Law'.&nbsp; Later it came to be quoted as computer SPEED would double every 18 months. We will take this to be Moore's Law in this blog post.&nbsp;</p><p>Is Moore's law dead? Browsing Google the answer seems to be that it is slowing down but not dead yet. (IDEA for a comedy sketch: Redo the Monty Python Dead Parrot sketch about the death of Moore's law.)&nbsp;</p><p>If Moore had 1 penny in April 1965 and it doubled every 18 months then how rich would he be now? How rich was he in April 2022? Compare the two numbers.&nbsp;</p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-23T20:05:00Z">Sunday, April 23 2023, 20:05</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, April 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/'>Some Rice News</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Lydia Kavraki is the Noah Harding Professor of Computer Science at Rice University. She is also professor of Bioengineering, professor of Electrical and Computer Engineering, and professor of Mechanical Engineering at Rice. She is the current Director of the Ken Kennedy Institute for Information Technology at Rice. Today we congratulate her on being elected to [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Lydia Kavraki is the Noah Harding Professor of Computer Science at Rice University. She is also professor of Bioengineering, professor of Electrical and Computer Engineering, and professor of Mechanical Engineering at Rice. She is the current Director of the <a href="https://kenkennedy.rice.edu">Ken Kennedy Institute for Information Technology</a> at Rice. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/lk2/" rel="attachment wp-att-21504"><img data-attachment-id="21504" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/lk2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?fit=192%2C241&amp;ssl=1" data-orig-size="192,241" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="lk2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?fit=192%2C241&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?fit=192%2C241&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/lk2.jpeg?resize=192%2C241&#038;ssl=1" alt="" width="192" height="241" class="aligncenter size-full wp-image-21504" data-recalc-dims="1" /></a></p>
<p>
Today we congratulate her on being elected to the American Academy of Arts and Sciences (<a href="https://www.amacad.org">AAAS</a>). </p>
<p>
Kavraki has multiple other affiliations listed on her <a href="https://www.cs.rice.edu/~kavraki/">home page</a>, including her own <a href="https://www.kavrakilab.org/">laboratory</a> on computational robotics and biomedicine. Now with AAAS, she acquires one more. It is enough to make us wonder whether her growth-of-affiliations function per year is additive or multiplicative. </p>
<p>
If the latter, then it would call to mind the story of rice grains on a chessboard. The emperor thinks it would be trivial to grant a reward of one grain of rice on the first square, two on the second square, four on the third square, eight on the fourth, and so on. It does not take many doublings for the number of grains to grow far in excess of this picture:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/rice/" rel="attachment wp-att-21494"><img data-attachment-id="21494" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/rice/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?fit=302%2C167&amp;ssl=1" data-orig-size="302,167" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rice" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?fit=300%2C166&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?fit=302%2C167&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?resize=302%2C167&#038;ssl=1" alt="" width="302" height="167" class="aligncenter size-full wp-image-21494" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?w=302&amp;ssl=1 302w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/rice.jpeg?resize=300%2C167&amp;ssl=1 300w" sizes="(max-width: 302px) 100vw, 302px" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Brief Roadmap to Her Work </H2></p>
<p><p>
Suppose a chess queen has outstretched arms that made it difficult to move her on a board without knocking over other pieces. We will require her to make a legal move in chess, but not necessarily take the direct route to her destination square. If a roundabout route through a less-crowded area of the board can get her safely to her goal, we will allow our player to move her that way. Naturally, the player could be a robot arm that can picture the whole board but may only slide the queen, not hoist her vertically to hop her to a square.</p>
<p>
What&#8217;s the best way in practice to find a route, if one exists? We could try all possible paths, but here is where the grains-of-rice factor comes in. This is not because there are many squares, but because the queen&#8217;s arms may leave her little wiggle room on a square. She may have to shimmy to get by the nose of an enemy knight, but then find herself unable to twist around a chain of pawns. To avoid such backtracks, we&#8217;d need to make a roadmap of the entire board not in the space of squares, but in the possible <em>configuration space</em> of the queen, given the positioning of other pieces as obstacles. That space can be too large to map exhaustively.</p>
<p>
In work with her PhD adviser Jean-Clause Latombe and others, Kavraki was the guiding force in discovering that random sampling of the configuration space almost always efficiently finds a route when one exists. The sampling grows progressively longer transitions between configurations that the queen is able to make, and proclaims success when the goal configuration is connected to the origin. Then a deterministic shortest-path algorithm can be run on the resulting graph&#8212;a manageable subset of the whole configuration space&#8212;to find an optimal route through that graph. By the nature of physical space, this is usually optimum overall.</p>
<p>
Kavraki&#8217;s <a href="https://en.wikipedia.org/wiki/Probabilistic_roadmap">probabilistic roadmap</a> <em>paradigm</em> extends to many other settings besides moving robots. In biomedicine it applies to how a drug molecule can be designed to maximize its expectation of finding configurations that will combat a pathogen. Her 2017 ACM Athena Lecturer Award <a href="https://www.acm.org/articles/bulletins/2017/april/athena-2017-kavraki">citation</a> notes how her work has found paths into &#8220;an impressively wide range of areas.&#8221;</p>
<p>
<p><H2> Ken Kennedy&#8217;s Institute </H2></p>
<p><p>
Rice University is one of the top university especially when we look at its computer science <a href="https://csweb.rice.edu">program</a>. This historically was thanks to Ken Kennedy who sadly died years ago on 2007 February 7th. Ken was one of the world&#8217;s foremost experts on high-performance computing. He attended Rice University, receiving a B.A. in mathematics (summa cum laude) in 1967. He pursued graduate studies at New York University, where he earned a M.S. in mathematics in 1969 and a Ph.D. in computer science in 1971. Then he returned to Rice.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/kk-2/" rel="attachment wp-att-21495"><img data-attachment-id="21495" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/kk-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?fit=140%2C158&amp;ssl=1" data-orig-size="140,158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kk" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?fit=140%2C158&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?fit=140%2C158&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kk.jpeg?resize=140%2C158&#038;ssl=1" alt="" width="140" height="158" class="aligncenter size-full wp-image-21495" data-recalc-dims="1" /></a></p>
<p>
Rice president David Leebron said: </p>
<blockquote><p>
&#8220;In Ken Kennedy, Rice has lost one of its great intellectual leaders and a great human being.  [He] early on realized the power of computers to address real problems that confront people and the Earth. Ken leaves a great legacy for Rice and for mankind. He will be missed.&#8221;
</p></blockquote>
<p><a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/owls2/" rel="attachment wp-att-21496"><img data-attachment-id="21496" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/owls2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?fit=253%2C199&amp;ssl=1" data-orig-size="253,199" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="owls2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?fit=253%2C199&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?fit=253%2C199&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/owls2.jpeg?resize=253%2C199&#038;ssl=1" alt="" width="253" height="199" class="aligncenter size-full wp-image-21496" data-recalc-dims="1" /></a></p>
<p>
<p><H2> Previous Leader </H2></p>
<p>
<p>
A previous leader of the Kennedy Institute is Moshe Vardi, an old friend whose work we first covered <a href="https://rjlipton.wpcomstaging.com/2011/07/28/logic-in-action/">here</a> and whom we&#8217;ve mentioned numerous times since, including about <a href="https://rjlipton.wpcomstaging.com/2020/09/10/hybrid-versus-remote-teaching/">teaching</a> during the pandemic. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/mv2/" rel="attachment wp-att-21499"><img data-attachment-id="21499" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/mv2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?fit=240%2C240&amp;ssl=1" data-orig-size="240,240" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mv2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?fit=240%2C240&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?fit=240%2C240&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?resize=160%2C160&#038;ssl=1" alt="" width="160" height="160" class="aligncenter wp-image-21499" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?w=240&amp;ssl=1 240w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/mv2.jpeg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 160px) 100vw, 160px" data-recalc-dims="1" /></a></p>
<p>
He also has a bunch of titles, including Professor of Computer Science, University Professor, the Karen Ostrum George Professor in Computational Engineering, and Distinguished Service Professor&#8212;but more notable is that he <a href="https://www.cs.rice.edu/~vardi/long-bio.html">has</a> even more honorary doctorates than affiliations:</p>
<blockquote>
<p>
He holds honorary doctorates from the University of Saarland, Germany, the University of Orleans in France, UFRGS in Brazil, the University of Liege in Belgium, the Technical University of Vienna, Austria, the University of Edinburgh in Scotland, the University of Grenoble-Alpes, and Gothenburg University in Sweden.
</p></blockquote>
<p>
<p>
<p><H2> AAAS </H2></p>
<p><p>
David Oxtoby is the current President of the American Academy of Arts and <a href="https://www.amacad.org">Sciences</a>. In his annoucement of the new class he says:</p>
<blockquote><p><b> </b> <em></p>
<p>
The very first class of members elected to the Academy in 1781 included Benjamin Franklin and George Washington, and today I&#8217;m pleased to announce the new members elected to the American Academy of Arts and Sciences this year.<br />
</em>
</p></blockquote>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/do/" rel="attachment wp-att-21500"><img data-attachment-id="21500" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/22/some-rice-news/do/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?fit=216%2C233&amp;ssl=1" data-orig-size="216,233" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="do" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?fit=216%2C233&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?fit=216%2C233&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/do.jpeg?resize=144%2C158&#038;ssl=1" alt="" width="144" height="158" class="aligncenter wp-image-21500" data-recalc-dims="1" /></a></p>
<p><p>
The new computer science electees are listed <a href="https://www.amacad.org/new-members-2023">here</a> and include several others we know well and whose work we have covered. We list Kavraki again in case this list is taken as &#8220;the&#8221; list.</p>
<ul>
<p><li>
Michael Franklin <a href="https://cs.uchicago.edu/people/michael-franklin/">MF</a>, University of Chicago </p>
<p><li>
Xuedong Huang <a href="https://www.microsoft.com/en-us/research/people/xdh/">XH</a>, Microsoft Corporation</p>
<p><li>
Piotr Indyk <a href="https://people.csail.mit.edu/indyk/">PI</a>, Massachusetts Institute of Technology</p>
<p><li>
Lydia Kavraki <a href="https://www.cs.rice.edu/~kavraki/">LK</a>, Rice University</p>
<p><li>
Marta Kwiatkowska <a href="https://www.trinity.ox.ac.uk/people/marta-kwiatkowska">MK</a>, University of Oxford (international honorary member)</p>
<p><li>
Maja Mataric <a href="https://viterbi.usc.edu/directory/faculty/Mataric/Maja">MM</a>, University of Southern California Viterbi School of Engineering</p>
<p><li>
Kathryn McKinley <a href="https://thenewstack.io/google-cloud-engineer-kathryn-s-mckinley-on-leadership-mentoring-garbage-collection-and-rust/">KM</a>, Google LLC</p>
<p><li>
Gordon Plotkin (IHM) <a href="https://www.research.ed.ac.uk/en/persons/gordon-plotkin">GP</a>, University of Edinburgh</p>
<p><li>
Moti Yung <a href="https://www.researchgate.net/profile/Moti-Yung">MY</a>, Google LLC</p>
</ul>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Our congratulations again to all those just elected. </p>
<p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-22T15:22:28Z">Saturday, April 22 2023, 15:22</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, April 21
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10106'>No Where to Go But High: A Perspective on High Dimensional Expanders</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Roy Gotlib, Tali Kaufman</p><p>"No Where to go but in" is a well known statement of Osho. Osho meant to say
that the answers to all our questions should be obtained by looking into
ourselves. In a paraphrase to Osho's statement we say "No Where to go but
high". This meant to demonstrate that for various seemingly unrelated topics
and questions the only way to get significant progress is via the prism of a
new philosophy (new field) called high dimensional expansion. In this note we
give an introduction \footnote{This introduction reflects the authors'
interests and by no mean claim to represent the field in a through way} to the
high dimensional expansion philosophy, and how it has been useful recently in
obtaining progress in various questions in seemingly unrelated fields.
</p>
<p>This exposition is dedicated to the memory of my mother, Sarah Kaufman, who
was always trying to understand the reason why things behave in a certain way.
It is also dedicated to the memory of my father Eliezer Kaufman.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Gotlib_R/0/1/0/all/0/1">Roy Gotlib</a>, <a href="http://arxiv.org/find/math/1/au:+Kaufman_T/0/1/0/all/0/1">Tali Kaufman</a></p><p>"No Where to go but in" is a well known statement of Osho. Osho meant to say
that the answers to all our questions should be obtained by looking into
ourselves. In a paraphrase to Osho's statement we say "No Where to go but
high". This meant to demonstrate that for various seemingly unrelated topics
and questions the only way to get significant progress is via the prism of a
new philosophy (new field) called high dimensional expansion. In this note we
give an introduction \footnote{This introduction reflects the authors'
interests and by no mean claim to represent the field in a through way} to the
high dimensional expansion philosophy, and how it has been useful recently in
obtaining progress in various questions in seemingly unrelated fields.
</p>
<p>This exposition is dedicated to the memory of my mother, Sarah Kaufman, who
was always trying to understand the reason why things behave in a certain way.
It is also dedicated to the memory of my father Eliezer Kaufman.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09990'>Reconfiguration of 3D Pivoting Modular Robots</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hugo A. Akitaya, Frederick Stock</p><p>We study a new model of 3-dimensional modular self-reconfigurable robots
Rhombic Dodecahedral (RD). By extending results on the 2D analog of this model
we characterize the free space requirements for a pivoting move and investigate
the $\textit{reconfiguration problem}$, that is, given two configurations $s$
and $t$ is there a sequence of moves that transforms $s$ into $t$? We show
reconfiguration is PSPACE-hard for RD modules in a restricted pivoting model.
In a more general model, we show that RD configurations are not universally
reconfigurable despite the fact that their 2D analog is [Akitaya et al., SoCG
2021]. Additionally, we present a new class of RD configurations that we call
$\textit{super-rigid}$. Such a configuration remains rigid even as a subset of
any larger configuration, which does not exist in the 2D setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Akitaya_H/0/1/0/all/0/1">Hugo A. Akitaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Stock_F/0/1/0/all/0/1">Frederick Stock</a></p><p>We study a new model of 3-dimensional modular self-reconfigurable robots
Rhombic Dodecahedral (RD). By extending results on the 2D analog of this model
we characterize the free space requirements for a pivoting move and investigate
the $\textit{reconfiguration problem}$, that is, given two configurations $s$
and $t$ is there a sequence of moves that transforms $s$ into $t$? We show
reconfiguration is PSPACE-hard for RD modules in a restricted pivoting model.
In a more general model, we show that RD configurations are not universally
reconfigurable despite the fact that their 2D analog is [Akitaya et al., SoCG
2021]. Additionally, we present a new class of RD configurations that we call
$\textit{super-rigid}$. Such a configuration remains rigid even as a subset of
any larger configuration, which does not exist in the 2D setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10028'>Minimizing the Size of the Uncertainty Regions for Centers of Moving Entities</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: William Evans, Seyed Ali Tabatabaee</p><p>In this paper, we study the problems of computing the 1-center, centroid, and
1-median of objects moving with bounded speed in Euclidean space. We can
acquire the exact location of only a constant number of objects (usually one)
per unit time, but for every other object, its set of potential locations,
called the object's uncertainty region, grows subject only to the speed limit.
As a result, the center of the objects may be at several possible locations,
called the center's uncertainty region. For each of these center problems, we
design query strategies to minimize the size of the center's uncertainty region
and compare its performance to an optimal query strategy that knows the
trajectories of the objects, but must still query to reduce their uncertainty.
For the static case of the 1-center problem in R^1, we show an algorithm that
queries four objects per unit time and works as well as the optimal algorithm
with one query per unit time. For the general case of the 1-center problem in
R^1, the centroid problem in R^d, and the 1-median problem in R^1, we prove
that the Round-robin scheduling algorithm is the best possible competitive
algorithm. For the center of mass problem in R^d, we provide an O(log
n)-competitive algorithm. In addition, for the general case of the 1-center
problem in R^d (d &gt;= 2), we argue that no algorithm can guarantee a bounded
competitive ratio against the optimal algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Evans_W/0/1/0/all/0/1">William Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabatabaee_S/0/1/0/all/0/1">Seyed Ali Tabatabaee</a></p><p>In this paper, we study the problems of computing the 1-center, centroid, and
1-median of objects moving with bounded speed in Euclidean space. We can
acquire the exact location of only a constant number of objects (usually one)
per unit time, but for every other object, its set of potential locations,
called the object's uncertainty region, grows subject only to the speed limit.
As a result, the center of the objects may be at several possible locations,
called the center's uncertainty region. For each of these center problems, we
design query strategies to minimize the size of the center's uncertainty region
and compare its performance to an optimal query strategy that knows the
trajectories of the objects, but must still query to reduce their uncertainty.
For the static case of the 1-center problem in R^1, we show an algorithm that
queries four objects per unit time and works as well as the optimal algorithm
with one query per unit time. For the general case of the 1-center problem in
R^1, the centroid problem in R^d, and the 1-median problem in R^1, we prove
that the Round-robin scheduling algorithm is the best possible competitive
algorithm. For the center of mass problem in R^d, we provide an O(log
n)-competitive algorithm. In addition, for the general case of the 1-center
problem in R^d (d &gt;= 2), we argue that no algorithm can guarantee a bounded
competitive ratio against the optimal algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10078'>High-Performance and Flexible Parallel Algorithms for Semisort and Related Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiaojun Dong, Yunshu Wu, Zhongqi Wang, Laxman Dhulipala, Yan Gu, Yihan Sun</p><p>Semisort is a fundamental algorithmic primitive widely used in the design and
analysis of efficient parallel algorithms. It takes input as an array of
records and a function extracting a \emph{key} per record, and reorders them so
that records with equal keys are contiguous. Since many applications only
require collecting equal values, but not fully sorting the input, semisort is
broadly applicable, e.g., in string algorithms, graph analytics, and geometry
processing, among many other domains. However, despite dozens of recent papers
that use semisort in their theoretical analysis and the existence of an
asymptotically optimal parallel semisort algorithm, most implementations of
these parallel algorithms choose to implement semisort by using comparison or
integer sorting in practice, due to potential performance issues in existing
semisort implementations.
</p>
<p>In this paper, we revisit the semisort problem, with the goal of achieving a
high-performance parallel semisort implementation with a flexible interface.
Our approach can easily extend to two related problems, \emph{histogram} and
\emph{collect-reduce}. Our algorithms achieve strong speedups in practice, and
importantly, outperform state-of-the-art parallel sorting and semisorting
methods for almost all settings we tested, with varying input sizes,
distribution, and key types. We also test two important applications with
real-world data, and show that our algorithms improve the performance over
existing approaches. We believe that many other parallel algorithm
implementations can be accelerated using our results.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaojun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yunshu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1">Laxman Dhulipala</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yihan Sun</a></p><p>Semisort is a fundamental algorithmic primitive widely used in the design and
analysis of efficient parallel algorithms. It takes input as an array of
records and a function extracting a \emph{key} per record, and reorders them so
that records with equal keys are contiguous. Since many applications only
require collecting equal values, but not fully sorting the input, semisort is
broadly applicable, e.g., in string algorithms, graph analytics, and geometry
processing, among many other domains. However, despite dozens of recent papers
that use semisort in their theoretical analysis and the existence of an
asymptotically optimal parallel semisort algorithm, most implementations of
these parallel algorithms choose to implement semisort by using comparison or
integer sorting in practice, due to potential performance issues in existing
semisort implementations.
</p>
<p>In this paper, we revisit the semisort problem, with the goal of achieving a
high-performance parallel semisort implementation with a flexible interface.
Our approach can easily extend to two related problems, \emph{histogram} and
\emph{collect-reduce}. Our algorithms achieve strong speedups in practice, and
importantly, outperform state-of-the-art parallel sorting and semisorting
methods for almost all settings we tested, with varying input sizes,
distribution, and key types. We also test two important applications with
real-world data, and show that our algorithms improve the performance over
existing approaches. We believe that many other parallel algorithm
implementations can be accelerated using our results.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10350'>Polylog-Competitive Algorithms for Dynamic Balanced Graph Partitioning for Ring Demands</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Harald R&#xe4;cke, Stefan Schmid, Ruslan Zabrodin</p><p>The performance of many large-scale and data-intensive distributed systems
critically depends on the capacity of the interconnecting network. This paper
is motivated by the vision of self-adjusting infrastructures whose resources
can be adjusted according to the workload they currently serve, in a
demand-aware manner. Such dynamic adjustments can be exploited to improve
network utilization and hence performance, by dynamically moving frequently
interacting communication partners closer, e.g., collocating them in the same
server or datacenter rack.
</p>
<p>In particular, we revisit the online balanced graph partitioning problem
which captures the fundamental tradeoff between the benefits and costs of
dynamically collocating communication partners. The demand is modelled as a
sequence $\sigma$ (revealed in an online manner) of communication requests
between $n$ processes, each of which is running on one of the $\ell$ servers.
Each server has capacity $k=n/\ell$, hence, the processes have to be scheduled
in a balanced manner across the servers. A request incurs cost $1$, if the
requested processes are located on different servers, otherwise the cost is 0.
A process can be migrated to a different server at cost $1$.
</p>
<p>This paper presents the first online algorithm for online balanced graph
partitioning achieving a polylogarithmic competitive ratio for the fundamental
case of ring communication patterns. Specifically, our main contribution is a
$O(\log^3 n)$-competitive randomized online algorithm for this problem. We
further present a randomized online algorithm which is $O(\log^2
n)$-competitive when compared to a static optimal solution. Our two results
rely on different algorithms and techniques and hence are of independent
interest.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Racke_H/0/1/0/all/0/1">Harald R&#xe4;cke</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Zabrodin_R/0/1/0/all/0/1">Ruslan Zabrodin</a></p><p>The performance of many large-scale and data-intensive distributed systems
critically depends on the capacity of the interconnecting network. This paper
is motivated by the vision of self-adjusting infrastructures whose resources
can be adjusted according to the workload they currently serve, in a
demand-aware manner. Such dynamic adjustments can be exploited to improve
network utilization and hence performance, by dynamically moving frequently
interacting communication partners closer, e.g., collocating them in the same
server or datacenter rack.
</p>
<p>In particular, we revisit the online balanced graph partitioning problem
which captures the fundamental tradeoff between the benefits and costs of
dynamically collocating communication partners. The demand is modelled as a
sequence $\sigma$ (revealed in an online manner) of communication requests
between $n$ processes, each of which is running on one of the $\ell$ servers.
Each server has capacity $k=n/\ell$, hence, the processes have to be scheduled
in a balanced manner across the servers. A request incurs cost $1$, if the
requested processes are located on different servers, otherwise the cost is 0.
A process can be migrated to a different server at cost $1$.
</p>
<p>This paper presents the first online algorithm for online balanced graph
partitioning achieving a polylogarithmic competitive ratio for the fundamental
case of ring communication patterns. Specifically, our main contribution is a
$O(\log^3 n)$-competitive randomized online algorithm for this problem. We
further present a randomized online algorithm which is $O(\log^2
n)$-competitive when compared to a static optimal solution. Our two results
rely on different algorithms and techniques and hence are of independent
interest.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10414'>How the Move Acceptance Hyper-Heuristic Copes With Local Optima: Drastic Differences Between Jumps and Cliffs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Benjamin Doerr, Arthur Dremaux, Johannes Lutzeyer, Aur&#xe9;lien Stumpf</p><p>In recent work, Lissovoi, Oliveto, and Warwicker (Artificial Intelligence
(2023)) proved that the Move Acceptance Hyper-Heuristic (MAHH) leaves the local
optimum of the multimodal cliff benchmark with remarkable efficiency. With its
$O(n^3)$ runtime, for almost all cliff widths $d,$ the MAHH massively
outperforms the $\Theta(n^d)$ runtime of simple elitist evolutionary algorithms
(EAs). For the most prominent multimodal benchmark, the jump functions, the
given runtime estimates of $O(n^{2m} m^{-\Theta(m)})$ and
$\Omega(2^{\Omega(m)})$, for gap size $m \ge 2$, are far apart and the real
performance of MAHH is still an open question.
</p>
<p>In this work, we resolve this question. We prove that for any choice of the
MAHH selection parameter~$p$, the expected runtime of the MAHH on a jump
function with gap size $m = o(n^{1/2})$ is at least $\Omega(n^{2m-1} /
(2m-1)!)$. This renders the MAHH much slower than simple elitist evolutionary
algorithms with their typical $O(n^m)$ runtime.
</p>
<p>We also show that the MAHH with the global bit-wise mutation operator instead
of the local one-bit operator optimizes jump functions in time $O(\min\{m
n^m,\frac{n^{2m-1}}{m!\Omega(m)^{m-2}}\})$, essentially the minimum of the
optimization times of the $(1+1)$ EA and the MAHH. This suggests that combining
several ways to cope with local optima can be a fruitful approach.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1">Benjamin Doerr</a>, <a href="http://arxiv.org/find/cs/1/au:+Dremaux_A/0/1/0/all/0/1">Arthur Dremaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Lutzeyer_J/0/1/0/all/0/1">Johannes Lutzeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpf_A/0/1/0/all/0/1">Aur&#xe9;lien Stumpf</a></p><p>In recent work, Lissovoi, Oliveto, and Warwicker (Artificial Intelligence
(2023)) proved that the Move Acceptance Hyper-Heuristic (MAHH) leaves the local
optimum of the multimodal cliff benchmark with remarkable efficiency. With its
$O(n^3)$ runtime, for almost all cliff widths $d,$ the MAHH massively
outperforms the $\Theta(n^d)$ runtime of simple elitist evolutionary algorithms
(EAs). For the most prominent multimodal benchmark, the jump functions, the
given runtime estimates of $O(n^{2m} m^{-\Theta(m)})$ and
$\Omega(2^{\Omega(m)})$, for gap size $m \ge 2$, are far apart and the real
performance of MAHH is still an open question.
</p>
<p>In this work, we resolve this question. We prove that for any choice of the
MAHH selection parameter~$p$, the expected runtime of the MAHH on a jump
function with gap size $m = o(n^{1/2})$ is at least $\Omega(n^{2m-1} /
(2m-1)!)$. This renders the MAHH much slower than simple elitist evolutionary
algorithms with their typical $O(n^m)$ runtime.
</p>
<p>We also show that the MAHH with the global bit-wise mutation operator instead
of the local one-bit operator optimizes jump functions in time $O(\min\{m
n^m,\frac{n^{2m-1}}{m!\Omega(m)^{m-2}}\})$, essentially the minimum of the
optimization times of the $(1+1)$ EA and the MAHH. This suggests that combining
several ways to cope with local optima can be a fruitful approach.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.10524'>Learning Narrow One-Hidden-Layer ReLU Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sitan Chen, Zehao Dou, Surbhi Goel, Adam R Klivans, Raghu Meka</p><p>We consider the well-studied problem of learning a linear combination of $k$
ReLU activations with respect to a Gaussian distribution on inputs in $d$
dimensions. We give the first polynomial-time algorithm that succeeds whenever
$k$ is a constant. All prior polynomial-time learners require additional
assumptions on the network, such as positive combining coefficients or the
matrix of hidden weight vectors being well-conditioned.
</p>
<p>Our approach is based on analyzing random contractions of higher-order moment
tensors. We use a multi-scale analysis to argue that sufficiently close neurons
can be collapsed together, sidestepping the conditioning issues present in
prior work. This allows us to design an iterative procedure to discover
individual neurons.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sitan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zehao Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1">Surbhi Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1">Adam R Klivans</a>, <a href="http://arxiv.org/find/cs/1/au:+Meka_R/0/1/0/all/0/1">Raghu Meka</a></p><p>We consider the well-studied problem of learning a linear combination of $k$
ReLU activations with respect to a Gaussian distribution on inputs in $d$
dimensions. We give the first polynomial-time algorithm that succeeds whenever
$k$ is a constant. All prior polynomial-time learners require additional
assumptions on the network, such as positive combining coefficients or the
matrix of hidden weight vectors being well-conditioned.
</p>
<p>Our approach is based on analyzing random contractions of higher-order moment
tensors. We use a multi-scale analysis to argue that sufficiently close neurons
can be collapsed together, sidestepping the conditioning issues present in
prior work. This allows us to design an iterative procedure to discover
individual neurons.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-21T00:30:00Z">Friday, April 21 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, April 20
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/055'>TR23-055 |  On Approximability of Satisfiable $k$-CSPs: II | 

	Amey Bhangale, 

	Subhash Khot, 

	Dor Minzer</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Let $\Sigma$ be an alphabet and $\mu$ be a distribution on $\Sigma^k$ for some $k \geq 2$. Let $\alpha &gt; 0$ be the minimum probability of a tuple in the support of $\mu$ (denoted by $supp(\mu)$). Here, the support of $\mu$ is the set of all tuples in $\Sigma^k$ that have a positive probability mass under $\mu$. We treat the parameters $\Sigma, k, \mu, \alpha$ as fixed and constant.

We say that the distribution $\mu$ has a  linear embedding if there exist an Abelian group $G$ (with the identity element $0_G$) and mappings $\sigma_i : \Sigma \rightarrow G$, $1 \leq i \leq k$, such that  at least one of the mappings is non-constant and for every $(a_1, a_2, \ldots, a_k)\in supp(\mu)$, $\sum_{i=1}^k \sigma_i(a_i) = 0_G$. In [Bhangale-Khot-Minzer, STOC 2022], the authors asked the following analytical question.

Let $f_i: \Sigma^n\rightarrow [-1,1]$ be bounded functions, such that at least one of the functions $f_i$ essentially has degree at least $d$, meaning that the Fourier mass of $f_i$ on terms of degree less than $d$ is negligible, say at most $\delta$. In particular, $|\mathbb{E}[f_i]| \leq \delta$. The Fourier representation is w.r.t. the marginal of $\mu$ on the $i^{th}$ co-ordinate, denoted $(\Sigma, \mu_i)$. If $\mu$ has no linear embedding (over any Abelian group), then is it necessarily the case that

$$|\mathbb{E}_{(x_1, x_2, \ldots, x_k)\sim \mu^{\otimes n}}[f_1(x_1)f_2(x_2)\cdots f_k(x_k)]   = o_{d, \delta}(1),$$

where the right hand side $\to 0$ as the degree $d \to \infty$  and $\delta \to 0$?


In this paper, we answer this analytical question fully and in the affirmative for $k=3$. We also show the following two applications of the result.

1. The first application is related to hardness of approximation. Using the reduction from [Bhangale-Khot-Minzer, STOC 2022], we show that for every $3$-ary predicate $P:\Sigma^3 \to \{0,1\}$ such that $P$ has no linear embedding, an SDP integrality gap instance of a $P$-CSP instance with gap $(1,s)$ can be translated into a dictatorship test with completeness $1$ and soundness $s+o(1)$, under certain additional conditions on the instance.

2. The second application is related to additive combinatorics. We show that if the distribution $\mu$ on $\Sigma^3$ has no linear embedding, marginals of $\mu$ are uniform on $\Sigma$, and $(a,a,a)\in supp(\mu)$ for every $a\in \Sigma$, then every large enough subset of $\Sigma^n$ contains a triple $(x_1, x_2,x_3)$ from $\mu^{\otimes n}$ (and in fact a significant density of such triples).
        
        </div>

        <div class='tr-article-summary'>
        
          
          Let $\Sigma$ be an alphabet and $\mu$ be a distribution on $\Sigma^k$ for some $k \geq 2$. Let $\alpha &gt; 0$ be the minimum probability of a tuple in the support of $\mu$ (denoted by $supp(\mu)$). Here, the support of $\mu$ is the set of all tuples in $\Sigma^k$ that have a positive probability mass under $\mu$. We treat the parameters $\Sigma, k, \mu, \alpha$ as fixed and constant.

We say that the distribution $\mu$ has a  linear embedding if there exist an Abelian group $G$ (with the identity element $0_G$) and mappings $\sigma_i : \Sigma \rightarrow G$, $1 \leq i \leq k$, such that  at least one of the mappings is non-constant and for every $(a_1, a_2, \ldots, a_k)\in supp(\mu)$, $\sum_{i=1}^k \sigma_i(a_i) = 0_G$. In [Bhangale-Khot-Minzer, STOC 2022], the authors asked the following analytical question.

Let $f_i: \Sigma^n\rightarrow [-1,1]$ be bounded functions, such that at least one of the functions $f_i$ essentially has degree at least $d$, meaning that the Fourier mass of $f_i$ on terms of degree less than $d$ is negligible, say at most $\delta$. In particular, $|\mathbb{E}[f_i]| \leq \delta$. The Fourier representation is w.r.t. the marginal of $\mu$ on the $i^{th}$ co-ordinate, denoted $(\Sigma, \mu_i)$. If $\mu$ has no linear embedding (over any Abelian group), then is it necessarily the case that

$$|\mathbb{E}_{(x_1, x_2, \ldots, x_k)\sim \mu^{\otimes n}}[f_1(x_1)f_2(x_2)\cdots f_k(x_k)]   = o_{d, \delta}(1),$$

where the right hand side $\to 0$ as the degree $d \to \infty$  and $\delta \to 0$?


In this paper, we answer this analytical question fully and in the affirmative for $k=3$. We also show the following two applications of the result.

1. The first application is related to hardness of approximation. Using the reduction from [Bhangale-Khot-Minzer, STOC 2022], we show that for every $3$-ary predicate $P:\Sigma^3 \to \{0,1\}$ such that $P$ has no linear embedding, an SDP integrality gap instance of a $P$-CSP instance with gap $(1,s)$ can be translated into a dictatorship test with completeness $1$ and soundness $s+o(1)$, under certain additional conditions on the instance.

2. The second application is related to additive combinatorics. We show that if the distribution $\mu$ on $\Sigma^3$ has no linear embedding, marginals of $\mu$ are uniform on $\Sigma$, and $(a,a,a)\in supp(\mu)$ for every $a\in \Sigma$, then every large enough subset of $\Sigma^n$ contains a triple $(x_1, x_2,x_3)$ from $\mu^{\otimes n}$ (and in fact a significant density of such triples).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T22:00:35Z">Thursday, April 20 2023, 22:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/054'>TR23-054 |  On Approximability of Satisfiable $k$-CSPs: III | 

	Amey Bhangale, 

	Subhash Khot, 

	Dor Minzer</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this paper we study functions on the Boolean hypercube that have the property that after applying certain random restrictions, the restricted function is correlated to a linear function with non-negligible probability. If the given function is correlated with a linear function then this property clearly holds. Furthermore, the property also holds for low-degree functions as low-degree functions become a constant function under a random restriction with a non-negligible probability. We show that this essentially is the only possible reason.  More specifically, we show that the function must be correlated to a product of a linear function and a low-degree function. One of the main motivations of studying this question comes from the recent work of the authors [Bhangale, Khot and Minzer, STOC 2021] towards understanding approximability of satisfiable Constraint Satisfaction Problems.

Towards proving our structural theorem, we analyze a $2$-query direct product test for the table $F: {[n]\choose qn} \rightarrow \{0,1\}^{qn}$ where $q\in (0,1)$. We show that, for every constant $\varepsilon&gt;0$, if the test passes with probability $\varepsilon&gt;0$, then there is a global function such that for at least $\delta(\varepsilon)$ fraction of sets, the global function agrees with the given table on {\em all except $\alpha(\varepsilon)$ many locations}. The novelty of this result lies in the fact that $\alpha(\varepsilon)$ is independent of the set sizes. Prior to our work, such a conclusion (in fact, a stronger conclusion with $\alpha = 0$) was shown in [Dinur-Filmus-Harsha, SODA 2019] albeit when the test accepts with probability $1-\varepsilon$ for a small constant $\varepsilon&gt;0$. The setting of parameters in our direct product tests is fundamentally different compared to [Dinur-Goldenberg, FOCS 2008], [Impagliazzo-Kabanets-Wigderson, SIAM Journal of Computing 2012], [Dinur-Steurer, CCC 2014], [Dinur-Filmus-Harsha, SODA 2019]  and hence our analysis involves new techniques, including the use of the small-set expansion property of graphs defined on multi-slices. Such expansion property was recently shown in [Braverman-Khot-Lifshitz-Minzer, FOCS 2022].

As one application of our structural result, we give a $4$-query linearity test under the $p$-biased distribution. More specifically, for any $p\in (\frac{1}{3},\frac{2}{3})$, we give a test that queries a given function $f: \{0,1\}^n \rightarrow \{0,1\}$ at $4$ locations, where the marginal distribution of each query is $\mu_p^{\otimes n}$. The test has perfect completeness and soundness $\frac{1}{2}+\varepsilon$ -- in other words, for every constant $\varepsilon&gt;0$,  if the test passes with probability at least $\frac{1}{2}+\varepsilon$, then the function $f$ is correlated to a linear function under the $\mu_p^{\otimes n}$ measure. This qualitatively improves the results on the linearity testing under the $p$-biased distribution from the previous work [Kopparty-Saraf, APPROX/RANDOM 2009] and [Dinur-Filmus-Harsha, SODA 2019] in which the authors studied the test with soundness $1-\varepsilon$.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In this paper we study functions on the Boolean hypercube that have the property that after applying certain random restrictions, the restricted function is correlated to a linear function with non-negligible probability. If the given function is correlated with a linear function then this property clearly holds. Furthermore, the property also holds for low-degree functions as low-degree functions become a constant function under a random restriction with a non-negligible probability. We show that this essentially is the only possible reason.  More specifically, we show that the function must be correlated to a product of a linear function and a low-degree function. One of the main motivations of studying this question comes from the recent work of the authors [Bhangale, Khot and Minzer, STOC 2021] towards understanding approximability of satisfiable Constraint Satisfaction Problems.

Towards proving our structural theorem, we analyze a $2$-query direct product test for the table $F: {[n]\choose qn} \rightarrow \{0,1\}^{qn}$ where $q\in (0,1)$. We show that, for every constant $\varepsilon&gt;0$, if the test passes with probability $\varepsilon&gt;0$, then there is a global function such that for at least $\delta(\varepsilon)$ fraction of sets, the global function agrees with the given table on {\em all except $\alpha(\varepsilon)$ many locations}. The novelty of this result lies in the fact that $\alpha(\varepsilon)$ is independent of the set sizes. Prior to our work, such a conclusion (in fact, a stronger conclusion with $\alpha = 0$) was shown in [Dinur-Filmus-Harsha, SODA 2019] albeit when the test accepts with probability $1-\varepsilon$ for a small constant $\varepsilon&gt;0$. The setting of parameters in our direct product tests is fundamentally different compared to [Dinur-Goldenberg, FOCS 2008], [Impagliazzo-Kabanets-Wigderson, SIAM Journal of Computing 2012], [Dinur-Steurer, CCC 2014], [Dinur-Filmus-Harsha, SODA 2019]  and hence our analysis involves new techniques, including the use of the small-set expansion property of graphs defined on multi-slices. Such expansion property was recently shown in [Braverman-Khot-Lifshitz-Minzer, FOCS 2022].

As one application of our structural result, we give a $4$-query linearity test under the $p$-biased distribution. More specifically, for any $p\in (\frac{1}{3},\frac{2}{3})$, we give a test that queries a given function $f: \{0,1\}^n \rightarrow \{0,1\}$ at $4$ locations, where the marginal distribution of each query is $\mu_p^{\otimes n}$. The test has perfect completeness and soundness $\frac{1}{2}+\varepsilon$ -- in other words, for every constant $\varepsilon&gt;0$,  if the test passes with probability at least $\frac{1}{2}+\varepsilon$, then the function $f$ is correlated to a linear function under the $\mu_p^{\otimes n}$ measure. This qualitatively improves the results on the linearity testing under the $p$-biased distribution from the previous work [Kopparty-Saraf, APPROX/RANDOM 2009] and [Dinur-Filmus-Harsha, SODA 2019] in which the authors studied the test with soundness $1-\varepsilon$.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T22:00:22Z">Thursday, April 20 2023, 22:00</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/health-tech.html'>Health Tech</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p></p>â¦<br>On Tuesday, at the behest of an alumnus, I spent the afternoon at HIMSS, a large health tech conference being held at the big convention center in Chicago. When I think of Health Tech, I imagine fancy medical devices, but most of the exhibitors were focused on software solutions.<p></p><p>Cybersecurity had the biggest theme area, no surprise given the devasting role ransomware has had on some hospital chains. The second largest theme area focused on Interoperability. Just a few years ago, the vast majority of medical data is transferred via fax. A few companies, like Epic Systems, dominate the electronic health records space and don't share nicely. There's a relatively new standard,&nbsp;FHIR, for transferring medical data, making it easily accessible via APIs while keeping it secure. Hopefully, we can finally kill off the fax machines in doctors offices. Patient Engagement was the other big theme area.</p><p>Of course the big discussion topics are about how AI will change health care. For example, the advances in electronic records have led to doctors spending far too much time entering data instead of seeing patients. AI could make data entry quick, easier or perhaps even unnecessary. Also AI could help provide functionality for triage and initial diagnoses, helping to extend the capabilities in a staff-limited environment and help bring down health-care costs. Many of the exhibited software systems boasted about using AI but it won't be until next year's meeting that we see the true integration of large-language models into health care technology.</p><p>Many of the challenges of technology in health care carry over to higher education. We don't generally use faxes, but why do we send transcripts by PDFs? Health and student data share similar privacy and security challenges, why can't we develop a FHIR-like system for higher education? Cybersecurity and Patient&nbsp;Student Engagement challenges loom large for universities as well.&nbsp;</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p></p><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhyGNMicDXyUD2rOs44Tlkus5rR0BF-8qwueFzOJQdXm6L_eaGZ3V9blhL9X1Viqg01o_gl-YkkgkE7wwPWfbJlN9q0HJU8RpEJIw6iVauLUFPD-c_iK0645ZzXrpgVAuDHASeM1X7zFcBn3YQyHIPJrRKsPIw6Rj0VYGzzY4yZbmRwQ9rwIQ/s4080/PXL_20230418_180451901.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="3072" data-original-width="4080" height="301" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhyGNMicDXyUD2rOs44Tlkus5rR0BF-8qwueFzOJQdXm6L_eaGZ3V9blhL9X1Viqg01o_gl-YkkgkE7wwPWfbJlN9q0HJU8RpEJIw6iVauLUFPD-c_iK0645ZzXrpgVAuDHASeM1X7zFcBn3YQyHIPJrRKsPIw6Rj0VYGzzY4yZbmRwQ9rwIQ/w400-h301/PXL_20230418_180451901.jpg" width="400" /></a></div><br />On Tuesday, at the behest of an alumnus, I spent the afternoon at <a href="https://www.himss.org/global-conference">HIMSS</a>, a large health tech conference being held at the big convention center in Chicago. When I think of Health Tech, I imagine fancy medical devices, but most of the exhibitors were focused on software solutions.<p></p><p>Cybersecurity had the biggest theme area, no surprise given the devasting role ransomware has had on some hospital chains. The second largest theme area focused on Interoperability. Just a few years ago, the vast majority of medical data is transferred via fax. A few companies, like Epic Systems, dominate the electronic health records space and don't share nicely. There's a relatively new standard,&nbsp;<a href="https://en.wikipedia.org/wiki/Fast_Healthcare_Interoperability_Resources">FHIR</a>, for transferring medical data, making it easily accessible via APIs while keeping it secure. Hopefully, we can finally kill off the fax machines in doctors offices. Patient Engagement was the other big theme area.</p><p>Of course the big discussion topics are about how AI will change health care. For example, the advances in electronic records have led to doctors spending far too much time entering data instead of seeing patients. AI could make data entry quick, easier or perhaps even unnecessary. Also AI could help provide functionality for triage and initial diagnoses, helping to extend the capabilities in a staff-limited environment and help bring down health-care costs. Many of the exhibited software systems boasted about using AI but it won't be until next year's meeting that we see the true integration of large-language models into health care technology.</p><p>Many of the challenges of technology in health care carry over to higher education. We don't generally use faxes, but why do we send transcripts by PDFs? Health and student data share similar privacy and security challenges, why can't we develop a FHIR-like system for higher education? Cybersecurity and <strike>Patient</strike>&nbsp;Student Engagement challenges loom large for universities as well.&nbsp;</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T21:30:00Z">Thursday, April 20 2023, 21:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/053'>TR23-053 |  Proof Simulation via Round-based Strategy Extraction for QBF | 

	Leroy Chew</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The proof complexity of Quantified Boolean Formulas (QBF) relates to both QBF solving and OBF certification. One method to p-simulate a QBF proof system is by formalising the soundness of its strategy extraction in propositional logic. In this work we illustrate how to use extended QBF Frege to simulate LD-Q(Drrs)-Res, a proof system that combines conflict driven clause learning with dependency schemes, using such a method.
The round-based technique is the most common way to show a QBF proof system has strategy extraction, originally shown for Q-resolution and later used for LD-Q-Resolution, LQU-Resolution, expansion based systems and dependency-scheme based systems. Many of these proof systems were already shown to be simulated by extended QBF Frege, but simulation had to use a specialised local strategy extraction technique. Here we simulate the remaining systems, by formalising the soundness of LD-Q(Drrs)-Res&#39;s round-based strategy extraction in propositional logic. This is a positive result for certification, and further suggests the feasibility of using Extended QU-Resolution or QRAT to certify QCDCL solvers.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The proof complexity of Quantified Boolean Formulas (QBF) relates to both QBF solving and OBF certification. One method to p-simulate a QBF proof system is by formalising the soundness of its strategy extraction in propositional logic. In this work we illustrate how to use extended QBF Frege to simulate LD-Q(Drrs)-Res, a proof system that combines conflict driven clause learning with dependency schemes, using such a method.
The round-based technique is the most common way to show a QBF proof system has strategy extraction, originally shown for Q-resolution and later used for LD-Q-Resolution, LQU-Resolution, expansion based systems and dependency-scheme based systems. Many of these proof systems were already shown to be simulated by extended QBF Frege, but simulation had to use a specialised local strategy extraction technique. Here we simulate the remaining systems, by formalising the soundness of LD-Q(Drrs)-Res&#39;s round-based strategy extraction in propositional logic. This is a positive result for certification, and further suggests the feasibility of using Extended QU-Resolution or QRAT to certify QCDCL solvers.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T05:02:11Z">Thursday, April 20 2023, 05:02</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/052'>TR23-052 |  Limits of CDCL Learning via Merge Resolution | 

	Marc Vinyals, 

	Chunxiao Li, 

	Noah Fleming, 

	Antonina Kolokolova, 

	Vijay Ganesh</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In their seminal work, Atserias et al. and independently Pipatsrisawat and Darwiche in 2009 showed that CDCL solvers can simulate resolution proofs with polynomial overhead. However, previous work does not address the tightness of the simulation, i.e., the question of how large this overhead needs to be. In this paper, we address this question by focusing on an important property of proofs generated by CDCL solvers that employ standard learning schemes, namely that the derivation of a learned clause has at least one inference where a literal appears in both premises (aka, a merge literal). Specifically, we show that proofs of this kind can simulate resolution proofs with at most a linear overhead, but there also exist formulas where such overhead is necessary or, more precisely, that there exist formulas with resolution proofs of linear length that require quadratic CDCL proofs.
        
        </div>

        <div class='tr-article-summary'>
        
          
          In their seminal work, Atserias et al. and independently Pipatsrisawat and Darwiche in 2009 showed that CDCL solvers can simulate resolution proofs with polynomial overhead. However, previous work does not address the tightness of the simulation, i.e., the question of how large this overhead needs to be. In this paper, we address this question by focusing on an important property of proofs generated by CDCL solvers that employ standard learning schemes, namely that the derivation of a learned clause has at least one inference where a literal appears in both premises (aka, a merge literal). Specifically, we show that proofs of this kind can simulate resolution proofs with at most a linear overhead, but there also exist formulas where such overhead is necessary or, more precisely, that there exist formulas with resolution proofs of linear length that require quadratic CDCL proofs.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T04:59:40Z">Thursday, April 20 2023, 04:59</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/051'>TR23-051 |  QCDCL vs QBF Resolution: Further Insights | 

	Benjamin BÃ¶hm, 

	Olaf Beyersdorff</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We continue the investigation on the relations of QCDCL and QBF resolution systems. In particular, we introduce QCDCL versions that tightly characterise QU-Resolution and (a slight variant of) long-distance Q-Resolution. We show that most QCDCL variants - parameterised by different policies for decisions, unit propagations and reductions --  lead to incomparable systems for almost all choices of these policies.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We continue the investigation on the relations of QCDCL and QBF resolution systems. In particular, we introduce QCDCL versions that tightly characterise QU-Resolution and (a slight variant of) long-distance Q-Resolution. We show that most QCDCL variants - parameterised by different policies for decisions, unit propagations and reductions --  lead to incomparable systems for almost all choices of these policies.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T04:57:52Z">Thursday, April 20 2023, 04:57</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09422'>Limits of CDCL Learning via Merge Resolution</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marc Vinyals, Chunxiao Li, Noah Fleming, Antonina Kolokolova, Vijay Ganesh</p><p>In their seminal work, Atserias et al. and independently Pipatsrisawat and
Darwiche in 2009 showed that CDCL solvers can simulate resolution proofs with
polynomial overhead. However, previous work does not address the tightness of
the simulation, i.e., the question of how large this overhead needs to be. In
this paper, we address this question by focusing on an important property of
proofs generated by CDCL solvers that employ standard learning schemes, namely
that the derivation of a learned clause has at least one inference where a
literal appears in both premises (aka, a merge literal). Specifically, we show
that proofs of this kind can simulate resolution proofs with at most a linear
overhead, but there also exist formulas where such overhead is necessary or,
more precisely, that there exist formulas with resolution proofs of linear
length that require quadratic CDCL proofs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Vinyals_M/0/1/0/all/0/1">Marc Vinyals</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunxiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleming_N/0/1/0/all/0/1">Noah Fleming</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolokolova_A/0/1/0/all/0/1">Antonina Kolokolova</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganesh_V/0/1/0/all/0/1">Vijay Ganesh</a></p><p>In their seminal work, Atserias et al. and independently Pipatsrisawat and
Darwiche in 2009 showed that CDCL solvers can simulate resolution proofs with
polynomial overhead. However, previous work does not address the tightness of
the simulation, i.e., the question of how large this overhead needs to be. In
this paper, we address this question by focusing on an important property of
proofs generated by CDCL solvers that employ standard learning schemes, namely
that the derivation of a learned clause has at least one inference where a
literal appears in both premises (aka, a merge literal). Specifically, we show
that proofs of this kind can simulate resolution proofs with at most a linear
overhead, but there also exist formulas where such overhead is necessary or,
more precisely, that there exist formulas with resolution proofs of linear
length that require quadratic CDCL proofs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09216'>Higher-dimensional subdiagram matching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Amar Hadzihasanovic, Diana Kessler</p><p>Higher-dimensional rewriting is founded on a duality of rewrite systems and
cell complexes, connecting computational mathematics to higher categories and
homotopy theory: the two sides of a rewrite rule are two halves of the boundary
of an (n+1)-cell, which are diagrams of n-cells. We study higher-dimensional
diagram rewriting as a mechanism of computation, focussing on the matching
problem for rewritable subdiagrams within the combinatorial framework of
diagrammatic sets. We provide an algorithm for subdiagram matching in arbitrary
dimensions, based on new results on layerings of diagrams, and derive upper
bounds on its time complexity. We show that these superpolynomial bounds can be
improved to polynomial bounds under certain acyclicity conditions, and that
these conditions hold in general for diagrams up to dimension 3. We discuss the
challenges that arise in dimension 4.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Hadzihasanovic_A/0/1/0/all/0/1">Amar Hadzihasanovic</a>, <a href="http://arxiv.org/find/math/1/au:+Kessler_D/0/1/0/all/0/1">Diana Kessler</a></p><p>Higher-dimensional rewriting is founded on a duality of rewrite systems and
cell complexes, connecting computational mathematics to higher categories and
homotopy theory: the two sides of a rewrite rule are two halves of the boundary
of an (n+1)-cell, which are diagrams of n-cells. We study higher-dimensional
diagram rewriting as a mechanism of computation, focussing on the matching
problem for rewritable subdiagrams within the combinatorial framework of
diagrammatic sets. We provide an algorithm for subdiagram matching in arbitrary
dimensions, based on new results on layerings of diagrams, and derive upper
bounds on its time complexity. We show that these superpolynomial bounds can be
improved to polynomial bounds under certain acyclicity conditions, and that
these conditions hold in general for diagrams up to dimension 3. We discuss the
challenges that arise in dimension 4.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09217'>New Subset Selection Algorithms for Low Rank Approximation: Offline and Online</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David P. Woodruff, Taisuke Yasuda</p><p>Subset selection for the rank $k$ approximation of an $n\times d$ matrix $A$
offers improvements in the interpretability of matrices, as well as a variety
of computational savings. This problem is well-understood when the error
measure is the Frobenius norm, with various tight algorithms known even in
challenging models such as the online model, where an algorithm must select the
column subset irrevocably when the columns arrive one by one. In contrast, for
other matrix losses, optimal trade-offs between the subset size and
approximation quality have not been settled, even in the offline setting. We
give a number of results towards closing these gaps.
</p>
<p>In the offline setting, we achieve nearly optimal bicriteria algorithms in
two settings. First, we remove a $\sqrt k$ factor from a result of [SWZ19] when
the loss function is any entrywise loss with an approximate triangle inequality
and at least linear growth. Our result is tight for the $\ell_1$ loss. We give
a similar improvement for entrywise $\ell_p$ losses for $p&gt;2$, improving a
previous distortion of $k^{1-1/p}$ to $k^{1/2-1/p}$. Our results come from a
technique which replaces the use of a well-conditioned basis with a slightly
larger spanning set for which any vector can be expressed as a linear
combination with small Euclidean norm. We show that this technique also gives
the first oblivious $\ell_p$ subspace embeddings for $1&lt;p&lt;2$ with $\tilde
O(d^{1/p})$ distortion, which is nearly optimal and closes a long line of work.
</p>
<p>In the online setting, we give the first online subset selection algorithm
for $\ell_p$ subspace approximation and entrywise $\ell_p$ low rank
approximation by implementing sensitivity sampling online, which is challenging
due to the sequential nature of sensitivity sampling. Our main technique is an
online algorithm for detecting when an approximately optimal subspace changes
substantially.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a>, <a href="http://arxiv.org/find/cs/1/au:+Yasuda_T/0/1/0/all/0/1">Taisuke Yasuda</a></p><p>Subset selection for the rank $k$ approximation of an $n\times d$ matrix $A$
offers improvements in the interpretability of matrices, as well as a variety
of computational savings. This problem is well-understood when the error
measure is the Frobenius norm, with various tight algorithms known even in
challenging models such as the online model, where an algorithm must select the
column subset irrevocably when the columns arrive one by one. In contrast, for
other matrix losses, optimal trade-offs between the subset size and
approximation quality have not been settled, even in the offline setting. We
give a number of results towards closing these gaps.
</p>
<p>In the offline setting, we achieve nearly optimal bicriteria algorithms in
two settings. First, we remove a $\sqrt k$ factor from a result of [SWZ19] when
the loss function is any entrywise loss with an approximate triangle inequality
and at least linear growth. Our result is tight for the $\ell_1$ loss. We give
a similar improvement for entrywise $\ell_p$ losses for $p&gt;2$, improving a
previous distortion of $k^{1-1/p}$ to $k^{1/2-1/p}$. Our results come from a
technique which replaces the use of a well-conditioned basis with a slightly
larger spanning set for which any vector can be expressed as a linear
combination with small Euclidean norm. We show that this technique also gives
the first oblivious $\ell_p$ subspace embeddings for $1&lt;p&lt;2$ with $\tilde
O(d^{1/p})$ distortion, which is nearly optimal and closes a long line of work.
</p>
<p>In the online setting, we give the first online subset selection algorithm
for $\ell_p$ subspace approximation and entrywise $\ell_p$ low rank
approximation by implementing sensitivity sampling online, which is challenging
due to the sequential nature of sensitivity sampling. Our main technique is an
online algorithm for detecting when an approximately optimal subspace changes
substantially.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09281'>Optimal Eigenvalue Approximation via Sketching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: William Swartworth, David P. Woodruff</p><p>Given a symmetric matrix $A$, we show from the simple sketch $GAG^T$, where
$G$ is a Gaussian matrix with $k = O(1/\epsilon^2)$ rows, that there is a
procedure for approximating all eigenvalues of $A$ simultaneously to within
$\epsilon \|A\|_F$ additive error with large probability. Unlike the work of
(Andoni, Nguyen, SODA, 2013), we do not require that $A$ is positive
semidefinite and therefore we can recover sign information about the spectrum
as well. Our result also significantly improves upon the sketching dimension of
recent work for this problem (Needell, Swartworth, Woodruff FOCS 2022), and in
fact gives optimal sketching dimension. Our proof develops new properties of
singular values of $GA$ for a $k \times n$ Gaussian matrix $G$ and an $n \times
n$ matrix $A$ which may be of independent interest. Additionally we achieve
tight bounds in terms of matrix-vector queries. Our sketch can be computed
using $O(1/\epsilon^2)$ matrix-vector multiplies, and by improving on lower
bounds for the so-called rank estimation problem, we show that this number is
optimal even for adaptive matrix-vector queries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Swartworth_W/0/1/0/all/0/1">William Swartworth</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a></p><p>Given a symmetric matrix $A$, we show from the simple sketch $GAG^T$, where
$G$ is a Gaussian matrix with $k = O(1/\epsilon^2)$ rows, that there is a
procedure for approximating all eigenvalues of $A$ simultaneously to within
$\epsilon \|A\|_F$ additive error with large probability. Unlike the work of
(Andoni, Nguyen, SODA, 2013), we do not require that $A$ is positive
semidefinite and therefore we can recover sign information about the spectrum
as well. Our result also significantly improves upon the sketching dimension of
recent work for this problem (Needell, Swartworth, Woodruff FOCS 2022), and in
fact gives optimal sketching dimension. Our proof develops new properties of
singular values of $GA$ for a $k \times n$ Gaussian matrix $G$ and an $n \times
n$ matrix $A$ which may be of independent interest. Additionally we achieve
tight bounds in terms of matrix-vector queries. Our sketch can be computed
using $O(1/\epsilon^2)$ matrix-vector multiplies, and by improving on lower
bounds for the so-called rank estimation problem, we show that this number is
optimal even for adaptive matrix-vector queries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09283'>Sliding Block Hashing (Slick) -- Basic Algorithmic Ideas</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hans-Peter Lehmann, Peter Sanders, Stefan Walzer</p><p>We present {\bf Sli}ding Blo{\bf ck} Hashing (Slick), a simple hash table
data structure that combines high performance with very good space efficiency.
This preliminary report outlines avenues for analysis and implementation that
we intend to pursue.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lehmann_H/0/1/0/all/0/1">Hans-Peter Lehmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanders_P/0/1/0/all/0/1">Peter Sanders</a>, <a href="http://arxiv.org/find/cs/1/au:+Walzer_S/0/1/0/all/0/1">Stefan Walzer</a></p><p>We present {\bf Sli}ding Blo{\bf ck} Hashing (Slick), a simple hash table
data structure that combines high performance with very good space efficiency.
This preliminary report outlines avenues for analysis and implementation that
we intend to pursue.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09321'>A New Deterministic Algorithm for Fully Dynamic All-Pairs Shortest Paths</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julia Chuzhoy, Ruimin Zhang</p><p>We study the fully dynamic All-Pairs Shortest Paths (APSP) problem in
undirected edge-weighted graphs. Given an $n$-vertex graph $G$ with
non-negative edge lengths, that undergoes an online sequence of edge insertions
and deletions, the goal is to support approximate distance queries and
shortest-path queries. We provide a deterministic algorithm for this problem,
that, for a given precision parameter $\epsilon$, achieves approximation factor
$(\log\log n)^{2^{O(1/\epsilon^3)}}$, and has amortized update time
$O(n^{\epsilon}\log L)$ per operation, where $L$ is the ratio of longest to
shortest edge length. Query time for distance-query is
$O(2^{O(1/\epsilon)}\cdot \log n\cdot \log\log L)$, and query time for
shortest-path query is $O(|E(P)|+2^{O(1/\epsilon)}\cdot \log n\cdot \log\log
L)$, where $P$ is the path that the algorithm returns. To the best of our
knowledge, even allowing any $o(n)$-approximation factor, no adaptive-update
algorithms with better than $\Theta(m)$ amortized update time and better than
$\Theta(n)$ query time were known prior to this work. We also note that our
guarantees are stronger than the best current guarantees for APSP in
decremental graphs in the adaptive-adversary setting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chuzhoy_J/0/1/0/all/0/1">Julia Chuzhoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruimin Zhang</a></p><p>We study the fully dynamic All-Pairs Shortest Paths (APSP) problem in
undirected edge-weighted graphs. Given an $n$-vertex graph $G$ with
non-negative edge lengths, that undergoes an online sequence of edge insertions
and deletions, the goal is to support approximate distance queries and
shortest-path queries. We provide a deterministic algorithm for this problem,
that, for a given precision parameter $\epsilon$, achieves approximation factor
$(\log\log n)^{2^{O(1/\epsilon^3)}}$, and has amortized update time
$O(n^{\epsilon}\log L)$ per operation, where $L$ is the ratio of longest to
shortest edge length. Query time for distance-query is
$O(2^{O(1/\epsilon)}\cdot \log n\cdot \log\log L)$, and query time for
shortest-path query is $O(|E(P)|+2^{O(1/\epsilon)}\cdot \log n\cdot \log\log
L)$, where $P$ is the path that the algorithm returns. To the best of our
knowledge, even allowing any $o(n)$-approximation factor, no adaptive-update
algorithms with better than $\Theta(m)$ amortized update time and better than
$\Theta(n)$ query time were known prior to this work. We also note that our
guarantees are stronger than the best current guarantees for APSP in
decremental graphs in the adaptive-adversary setting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09331'>Provably-Efficient and Internally-Deterministic Parallel Union-Find</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Fedorov, Diba Hashemi, Giorgi Nadiradze, Dan Alistarh</p><p>Determining the degree of inherent parallelism in classical sequential
algorithms and leveraging it for fast parallel execution is a key topic in
parallel computing, and detailed analyses are known for a wide range of
classical algorithms. In this paper, we perform the first such analysis for the
fundamental Union-Find problem, in which we are given a graph as a sequence of
edges, and must maintain its connectivity structure under edge additions. We
prove that classic sequential algorithms for this problem are
well-parallelizable under reasonable assumptions, addressing a conjecture by
[Blelloch, 2017]. More precisely, we show via a new potential argument that,
under uniform random edge ordering, parallel union-find operations are unlikely
to interfere: $T$ concurrent threads processing the graph in parallel will
encounter memory contention $O(T^2 \cdot \log |V| \cdot \log |E|)$ times in
expectation, where $|E|$ and $|V|$ are the number of edges and nodes in the
graph, respectively. We leverage this result to design a new parallel
Union-Find algorithm that is both internally deterministic, i.e., its results
are guaranteed to match those of a sequential execution, but also
work-efficient and scalable, as long as the number of threads $T$ is
$O(|E|^{\frac{1}{3} - \varepsilon})$, for an arbitrarily small constant
$\varepsilon &gt; 0$, which holds for most large real-world graphs. We present
lower bounds which show that our analysis is close to optimal, and experimental
results suggesting that the performance cost of internal determinism is
limited.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fedorov_A/0/1/0/all/0/1">Alexander Fedorov</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_D/0/1/0/all/0/1">Diba Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadiradze_G/0/1/0/all/0/1">Giorgi Nadiradze</a>, <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a></p><p>Determining the degree of inherent parallelism in classical sequential
algorithms and leveraging it for fast parallel execution is a key topic in
parallel computing, and detailed analyses are known for a wide range of
classical algorithms. In this paper, we perform the first such analysis for the
fundamental Union-Find problem, in which we are given a graph as a sequence of
edges, and must maintain its connectivity structure under edge additions. We
prove that classic sequential algorithms for this problem are
well-parallelizable under reasonable assumptions, addressing a conjecture by
[Blelloch, 2017]. More precisely, we show via a new potential argument that,
under uniform random edge ordering, parallel union-find operations are unlikely
to interfere: $T$ concurrent threads processing the graph in parallel will
encounter memory contention $O(T^2 \cdot \log |V| \cdot \log |E|)$ times in
expectation, where $|E|$ and $|V|$ are the number of edges and nodes in the
graph, respectively. We leverage this result to design a new parallel
Union-Find algorithm that is both internally deterministic, i.e., its results
are guaranteed to match those of a sequential execution, but also
work-efficient and scalable, as long as the number of threads $T$ is
$O(|E|^{\frac{1}{3} - \varepsilon})$, for an arbitrarily small constant
$\varepsilon &gt; 0$, which holds for most large real-world graphs. We present
lower bounds which show that our analysis is close to optimal, and experimental
results suggesting that the performance cost of internal determinism is
limited.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09445'>Randomly punctured Reed--Solomon codes achieve list-decoding capacity over linear-sized fields</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Omar Alrabiah, Venkatesan Guruswami, Ray Li</p><p>Reed--Solomon codes are a classic family of error-correcting codes consisting
of evaluations of low-degree polynomials over a finite field on some sequence
of distinct field elements. They are widely known for their optimal
unique-decoding capabilities, but their list-decoding capabilities are not
fully understood. Given the prevalence of Reed-Solomon codes, a fundamental
question in coding theory is determining if Reed--Solomon codes can optimally
achieve list-decoding capacity.
</p>
<p>A recent breakthrough by Brakensiek, Gopi, and Makam, established that
Reed--Solomon codes are combinatorially list-decodable all the way to capacity.
However, their results hold for randomly-punctured Reed--Solomon codes over an
exponentially large field size $2^{O(n)}$, where $n$ is the block length of the
code. A natural question is whether Reed--Solomon codes can still achieve
capacity over smaller fields. Recently, Guo and Zhang showed that Reed--Solomon
codes are list-decodable to capacity with field size $O(n^2)$. We show that
Reed--Solomon codes are list-decodable to capacity with linear field size
$O(n)$, which is optimal up to the constant factor. We also give evidence that
the ratio between the alphabet size $q$ and code length $n$ cannot be bounded
by an absolute constant.
</p>
<p>Our proof is based on the proof of Guo and Zhang, and additionally exploits
symmetries of reduced intersection matrices. With our proof, which maintains a
hypergraph perspective of the list-decoding problem, we include an alternate
presentation of ideas of Brakensiek, Gopi, and Makam that more directly
connects the list-decoding problem to the GM-MDS theorem via a hypergraph
orientation theorem.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alrabiah_O/0/1/0/all/0/1">Omar Alrabiah</a>, <a href="http://arxiv.org/find/cs/1/au:+Guruswami_V/0/1/0/all/0/1">Venkatesan Guruswami</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ray Li</a></p><p>Reed--Solomon codes are a classic family of error-correcting codes consisting
of evaluations of low-degree polynomials over a finite field on some sequence
of distinct field elements. They are widely known for their optimal
unique-decoding capabilities, but their list-decoding capabilities are not
fully understood. Given the prevalence of Reed-Solomon codes, a fundamental
question in coding theory is determining if Reed--Solomon codes can optimally
achieve list-decoding capacity.
</p>
<p>A recent breakthrough by Brakensiek, Gopi, and Makam, established that
Reed--Solomon codes are combinatorially list-decodable all the way to capacity.
However, their results hold for randomly-punctured Reed--Solomon codes over an
exponentially large field size $2^{O(n)}$, where $n$ is the block length of the
code. A natural question is whether Reed--Solomon codes can still achieve
capacity over smaller fields. Recently, Guo and Zhang showed that Reed--Solomon
codes are list-decodable to capacity with field size $O(n^2)$. We show that
Reed--Solomon codes are list-decodable to capacity with linear field size
$O(n)$, which is optimal up to the constant factor. We also give evidence that
the ratio between the alphabet size $q$ and code length $n$ cannot be bounded
by an absolute constant.
</p>
<p>Our proof is based on the proof of Guo and Zhang, and additionally exploits
symmetries of reduced intersection matrices. With our proof, which maintains a
hypergraph perspective of the list-decoding problem, we include an alternate
presentation of ideas of Brakensiek, Gopi, and Makam that more directly
connects the list-decoding problem to the GM-MDS theorem via a hypergraph
orientation theorem.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09654'>Uniform Generation of Temporal Graphs with Given Degrees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Allendorf</p><p>Uniform sampling from the set $\mathcal{G}(\mathbf{d})$ of graphs with a
given degree-sequence $\mathbf{d} = (d_1, \dots, d_n) \in \mathbb N^n$ is a
classical problem in the study of random graphs. We consider an analogue for
temporal graphs in which the edges are labeled with integer timestamps. The
input to this generation problem is a tuple $\mathbf{D} = (\mathbf{d}, T) \in
\mathbb N^n \times \mathbb N_{&gt;0}$ and the task is to output a uniform random
sample from the set $\mathcal{G}(\mathbf{D})$ of temporal graphs with
degree-sequence $\mathbf{d}$ and timestamps in the interval $[1, T]$. By
allowing repeated edges with distinct timestamps, $\mathcal{G}(\mathbf{D})$ can
be non-empty even if $\mathcal{G}(\mathbf{d})$ is, and as a consequence,
existing algorithms are difficult to apply.
</p>
<p>We describe an algorithm for this generation problem which runs in expected
time $O(M)$ if $\Delta^{2+\epsilon} = O(M)$ for some constant $\epsilon &gt; 0$
and $T - \Delta = \Omega(T)$ where $M = \sum_i d_i$ and $\Delta = \max_i d_i$.
Our algorithm applies the switching method of McKay and Wormald $[1]$ to
temporal graphs: we first generate a random temporal multigraph and then remove
self-loops and duplicated edges with switching operations which rewire the
edges in a degree-preserving manner.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Allendorf_D/0/1/0/all/0/1">Daniel Allendorf</a></p><p>Uniform sampling from the set $\mathcal{G}(\mathbf{d})$ of graphs with a
given degree-sequence $\mathbf{d} = (d_1, \dots, d_n) \in \mathbb N^n$ is a
classical problem in the study of random graphs. We consider an analogue for
temporal graphs in which the edges are labeled with integer timestamps. The
input to this generation problem is a tuple $\mathbf{D} = (\mathbf{d}, T) \in
\mathbb N^n \times \mathbb N_{&gt;0}$ and the task is to output a uniform random
sample from the set $\mathcal{G}(\mathbf{D})$ of temporal graphs with
degree-sequence $\mathbf{d}$ and timestamps in the interval $[1, T]$. By
allowing repeated edges with distinct timestamps, $\mathcal{G}(\mathbf{D})$ can
be non-empty even if $\mathcal{G}(\mathbf{d})$ is, and as a consequence,
existing algorithms are difficult to apply.
</p>
<p>We describe an algorithm for this generation problem which runs in expected
time $O(M)$ if $\Delta^{2+\epsilon} = O(M)$ for some constant $\epsilon &gt; 0$
and $T - \Delta = \Omega(T)$ where $M = \sum_i d_i$ and $\Delta = \max_i d_i$.
Our algorithm applies the switching method of McKay and Wormald $[1]$ to
temporal graphs: we first generate a random temporal multigraph and then remove
self-loops and duplicated edges with switching operations which rewire the
edges in a degree-preserving manner.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09666'>List Defective Colorings: Distributed Algorithms and Applications</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marc Fuchs, Fabian Kuhn</p><p>The distributed coloring problem is at the core of the area of distributed
graph algorithms and it is a problem that has seen tremendous progress over the
last few years. Much of the remarkable recent progress on deterministic
distributed coloring algorithms is based on two main tools: a) defective
colorings in which every node of a given color can have a limited number of
neighbors of the same color and b) list coloring, a natural generalization of
the standard coloring problem that naturally appears when colorings are
computed in different stages and one has to extend a previously computed
partial coloring to a full coloring.
</p>
<p>In this paper, we introduce \emph{list defective colorings}, which can be
seen as a generalization of these two coloring variants. Essentially, in a list
defective coloring instance, each node $v$ is given a list of colors
$x_{v,1},\dots,x_{v,p}$ together with a list of defects $d_{v,1},\dots,d_{v,p}$
such that if $v$ is colored with color $x_{v, i}$, it is allowed to have at
most $d_{v, i}$ neighbors with color $x_{v, i}$.
</p>
<p>We highlight the important role of list defective colorings by showing that
faster list defective coloring algorithms would directly lead to faster
deterministic $(\Delta+1)$-coloring algorithms in the LOCAL model. Further, we
extend a recent distributed list coloring algorithm by Maus and Tonoyan [DISC
'20]. Slightly simplified, we show that if for each node $v$ it holds that
$\sum_{i=1}^p \big(d_{v,i}+1)^2 &gt; \mathrm{deg}_G^2(v)\cdot polylog\Delta$ then
this list defective coloring instance can be solved in a
communication-efficient way in only $O(\log\Delta)$ communication rounds. This
leads to the first deterministic $(\Delta+1)$-coloring algorithm in the
standard CONGEST model with a time complexity of $O(\sqrt{\Delta}\cdot polylog
\Delta+\log^* n)$, matching the best time complexity in the LOCAL model up to a
$polylog\Delta$ factor.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fuchs_M/0/1/0/all/0/1">Marc Fuchs</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhn_F/0/1/0/all/0/1">Fabian Kuhn</a></p><p>The distributed coloring problem is at the core of the area of distributed
graph algorithms and it is a problem that has seen tremendous progress over the
last few years. Much of the remarkable recent progress on deterministic
distributed coloring algorithms is based on two main tools: a) defective
colorings in which every node of a given color can have a limited number of
neighbors of the same color and b) list coloring, a natural generalization of
the standard coloring problem that naturally appears when colorings are
computed in different stages and one has to extend a previously computed
partial coloring to a full coloring.
</p>
<p>In this paper, we introduce \emph{list defective colorings}, which can be
seen as a generalization of these two coloring variants. Essentially, in a list
defective coloring instance, each node $v$ is given a list of colors
$x_{v,1},\dots,x_{v,p}$ together with a list of defects $d_{v,1},\dots,d_{v,p}$
such that if $v$ is colored with color $x_{v, i}$, it is allowed to have at
most $d_{v, i}$ neighbors with color $x_{v, i}$.
</p>
<p>We highlight the important role of list defective colorings by showing that
faster list defective coloring algorithms would directly lead to faster
deterministic $(\Delta+1)$-coloring algorithms in the LOCAL model. Further, we
extend a recent distributed list coloring algorithm by Maus and Tonoyan [DISC
'20]. Slightly simplified, we show that if for each node $v$ it holds that
$\sum_{i=1}^p \big(d_{v,i}+1)^2 &gt; \mathrm{deg}_G^2(v)\cdot polylog\Delta$ then
this list defective coloring instance can be solved in a
communication-efficient way in only $O(\log\Delta)$ communication rounds. This
leads to the first deterministic $(\Delta+1)$-coloring algorithm in the
standard CONGEST model with a time complexity of $O(\sqrt{\Delta}\cdot polylog
\Delta+\log^* n)$, matching the best time complexity in the LOCAL model up to a
$polylog\Delta$ factor.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09743'>The Price of Explainability for Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anupam Gupta, Madhusudhan Reddy Pittu, Ola Svensson, Rachel Yuan</p><p>Given a set of points in $d$-dimensional space, an explainable clustering is
one where the clusters are specified by a tree of axis-aligned threshold cuts.
Dasgupta et al. (ICML 2020) posed the question of the price of explainability:
the worst-case ratio between the cost of the best explainable clusterings to
that of the best clusterings.
</p>
<p>We show that the price of explainability for $k$-medians is at most
$1+H_{k-1}$; in fact, we show that the popular Random Thresholds algorithm has
exactly this price of explanability, matching the known lower bound
constructions. We complement our tight analysis of this particular algorithm by
constructing instances where the price of explanability (using any algorithm)
is at least $(1-o(1)) \ln k$, showing that our result is best possible, up to
lower-order terms. We also improve the price of explanability for the $k$-means
problem to $O(k \ln \ln k)$ from the previous $O(k \ln k)$, considerably
closing the gap to the lower bounds of $\Omega(k)$.
</p>
<p>Finally, we study the algorithmic question of finding the best explainable
clustering: We show that explainable $k$-medians and $k$-means cannot be
approximated better than $O(\ln k)$, under standard complexity-theoretic
conjectures. This essentially settles the approximability of explainable
$k$-medians and leaves open the intriguing possibility to get significantly
better approximation algorithms for $k$-means than its price of explainability.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Anupam Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Pittu_M/0/1/0/all/0/1">Madhusudhan Reddy Pittu</a>, <a href="http://arxiv.org/find/cs/1/au:+Svensson_O/0/1/0/all/0/1">Ola Svensson</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1">Rachel Yuan</a></p><p>Given a set of points in $d$-dimensional space, an explainable clustering is
one where the clusters are specified by a tree of axis-aligned threshold cuts.
Dasgupta et al. (ICML 2020) posed the question of the price of explainability:
the worst-case ratio between the cost of the best explainable clusterings to
that of the best clusterings.
</p>
<p>We show that the price of explainability for $k$-medians is at most
$1+H_{k-1}$; in fact, we show that the popular Random Thresholds algorithm has
exactly this price of explanability, matching the known lower bound
constructions. We complement our tight analysis of this particular algorithm by
constructing instances where the price of explanability (using any algorithm)
is at least $(1-o(1)) \ln k$, showing that our result is best possible, up to
lower-order terms. We also improve the price of explanability for the $k$-means
problem to $O(k \ln \ln k)$ from the previous $O(k \ln k)$, considerably
closing the gap to the lower bounds of $\Omega(k)$.
</p>
<p>Finally, we study the algorithmic question of finding the best explainable
clustering: We show that explainable $k$-medians and $k$-means cannot be
approximated better than $O(\ln k)$, under standard complexity-theoretic
conjectures. This essentially settles the approximability of explainable
$k$-medians and leaves open the intriguing possibility to get significantly
better approximation algorithms for $k$-means than its price of explainability.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09774'>Nearly Work-Efficient Parallel DFS in Undirected Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Ghaffari, Christoph Grunau, Jiahao Qu</p><p>We present the first parallel depth-first search algorithm for undirected
graphs that has near-linear work and sublinear depth. Concretely, in any
$n$-node $m$-edge undirected graph, our algorithm computes a DFS in
$\tilde{O}(\sqrt{n})$ depth and using $\tilde{O}(m+n)$ work. All prior work
either required $\Omega(n)$ depth, and thus were essentially sequential, or
needed a high $poly(n)$ work and thus were far from being work-efficient.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1">Christoph Grunau</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_J/0/1/0/all/0/1">Jiahao Qu</a></p><p>We present the first parallel depth-first search algorithm for undirected
graphs that has near-linear work and sublinear depth. Concretely, in any
$n$-node $m$-edge undirected graph, our algorithm computes a DFS in
$\tilde{O}(\sqrt{n})$ depth and using $\tilde{O}(m+n)$ work. All prior work
either required $\Omega(n)$ depth, and thus were essentially sequential, or
needed a high $poly(n)$ work and thus were far from being work-efficient.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09791'>Temporal Betweenness Centrality on Shortest Paths</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mehdi Naima, Matthieu Latapy, Cl&#xe9;mence Magnien</p><p>Betweenness centrality measure assesses the importance of nodes in a graph
and has been used in a variety of contexts. Betweenness centrality has also
been extended to temporal graphs. Temporal graphs have edges that bear labels
according to the time of the interactions between the nodes. Betweenness
centrality has been extended to the temporal graph settings, and the notion of
paths has been extended to temporal paths. Recent results by Bu{\ss} et al. and
Rymar et al. showed that the betweenness centrality of all nodes in a temporal
graph can be computed in O(n^3 T^2) or O(n^2 m T^2 ), where T is the number of
time units, m the number of temporal edges and n the number of nodes. In this
paper, we improve the running time analysis of these previous approaches to
compute the betweenness centrality of all nodes in a temporal graph. We give an
algorithm that runs in O(n m T + n^2 T ).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Naima_M/0/1/0/all/0/1">Mehdi Naima</a>, <a href="http://arxiv.org/find/cs/1/au:+Latapy_M/0/1/0/all/0/1">Matthieu Latapy</a>, <a href="http://arxiv.org/find/cs/1/au:+Magnien_C/0/1/0/all/0/1">Cl&#xe9;mence Magnien</a></p><p>Betweenness centrality measure assesses the importance of nodes in a graph
and has been used in a variety of contexts. Betweenness centrality has also
been extended to temporal graphs. Temporal graphs have edges that bear labels
according to the time of the interactions between the nodes. Betweenness
centrality has been extended to the temporal graph settings, and the notion of
paths has been extended to temporal paths. Recent results by Bu{\ss} et al. and
Rymar et al. showed that the betweenness centrality of all nodes in a temporal
graph can be computed in O(n^3 T^2) or O(n^2 m T^2 ), where T is the number of
time units, m the number of temporal edges and n the number of nodes. In this
paper, we improve the running time analysis of these previous approaches to
compute the betweenness centrality of all nodes in a temporal graph. We give an
algorithm that runs in O(n m T + n^2 T ).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.09844'>Coloring Fast with Broadcasts</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Maxime Flin, Mohsen Ghaffari, Magn&#xfa;s M. Halld&#xf3;rsson, Fabian Kuhn, Alexandre Nolin</p><p>We present an $O(\log^3\log n)$-round distributed algorithm for the
$(\Delta+1)$-coloring problem, where each node broadcasts only one $O(\log
n)$-bit message per round to its neighbors. Previously, the best such
broadcast-based algorithm required $O(\log n)$ rounds. If $\Delta \in
\Omega(\log^{3} n)$, our algorithm runs in $O(\log^* n)$ rounds. Our
algorithm's round complexity matches state-of-the-art in the much more powerful
CONGEST model [Halld\'orsson et al., STOC'21 &amp; PODC'22], where each node sends
one different message to each of its neighbors, thus sending up to
$\Theta(n\log n)$ bits per round. This is the best complexity known, even if
message sizes are unbounded.
</p>
<p>Our algorithm is simple enough to be implemented in even weaker models: we
can achieve the same $O(\log^3\log n)$ round complexity if each node reads its
received messages in a streaming fashion, using only $O(\log^3 n)$-bit memory.
Therefore, we hope that our algorithm opens the road for adopting the recent
exciting progress on sublogarithmic-time distributed $(\Delta+1)$-coloring
algorithms in a wider range of (theoretical or practical) settings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Flin_M/0/1/0/all/0/1">Maxime Flin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Halldorsson_M/0/1/0/all/0/1">Magn&#xfa;s M. Halld&#xf3;rsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhn_F/0/1/0/all/0/1">Fabian Kuhn</a>, <a href="http://arxiv.org/find/cs/1/au:+Nolin_A/0/1/0/all/0/1">Alexandre Nolin</a></p><p>We present an $O(\log^3\log n)$-round distributed algorithm for the
$(\Delta+1)$-coloring problem, where each node broadcasts only one $O(\log
n)$-bit message per round to its neighbors. Previously, the best such
broadcast-based algorithm required $O(\log n)$ rounds. If $\Delta \in
\Omega(\log^{3} n)$, our algorithm runs in $O(\log^* n)$ rounds. Our
algorithm's round complexity matches state-of-the-art in the much more powerful
CONGEST model [Halld\'orsson et al., STOC'21 &amp; PODC'22], where each node sends
one different message to each of its neighbors, thus sending up to
$\Theta(n\log n)$ bits per round. This is the best complexity known, even if
message sizes are unbounded.
</p>
<p>Our algorithm is simple enough to be implemented in even weaker models: we
can achieve the same $O(\log^3\log n)$ round complexity if each node reads its
received messages in a streaming fashion, using only $O(\log^3 n)$-bit memory.
Therefore, we hope that our algorithm opens the road for adopting the recent
exciting progress on sublogarithmic-time distributed $(\Delta+1)$-coloring
algorithms in a wider range of (theoretical or practical) settings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-20T00:30:00Z">Thursday, April 20 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, April 19
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/04/19/mathematics-of-the-impossible-chapter-9-log-depth-circuits/'>Mathematics of the impossible, Chapter 9, Log-depth circuits</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this chapter we investigate circuits of logarithmic depth. Again, several surprises lay ahead, including a solution to the teaser in Chapter 1! Let us begin slowly with some basic properties of these circuits so as to get familiar with them. The next exercise shows that circuits of depth for a constant also have power [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>In this chapter we investigate circuits of logarithmic depth. Again, several surprises lay ahead, including a solution to the teaser in Chapter <a href="#x1-180001">1<!--tex4ht:ref: chap:A-teaser --></a>!</p>
<p style="text-align:justify">   Let us begin slowly with some basic properties of these circuits so as to get familiar with them. The next exercise shows that circuits of depth <img src="https://s0.wp.com/latex.php?latex=d%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d&#92;log n" class="latex" /> for a constant <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> also have power size, so we donât need to bound the size separately.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-101001r1"></a> <b>Exercise</b> 9.1.  </span>A circuit of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> has size <img src="https://s0.wp.com/latex.php?latex=%5Cle+c%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c^{d}" class="latex" /> without loss of generality.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The next exercises shows how to compute several simple functions by log-depth circuits.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-101002r2"></a> <b>Exercise</b> 9.2.  </span>Prove that the Or, And, and Parity functions on <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits have circuits of depth <img src="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log n" class="latex" />.</p>
<p style="text-align:justify">   Prove that any <img src="https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f: &#92;{0,1&#92;}^n &#92;to &#92;{0,1&#92;} " class="latex" /> computable by an AltCkt of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=s%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;ge n" class="latex" /> is also computable by a circuit of depth <img src="https://s0.wp.com/latex.php?latex=cd%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cd%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cd%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cd&#92;log s" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=s%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s^{c}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Next, let us relate these circuits to branching programs. The upshot is that circuits of logarithmic depth are a special case of power-size branching programs, and the latter are a special case of circuits of log-square depth.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-101003r1"></a> <b>Theorem</b> 9.1.  </span>Directed reachability has circuits of depth <img src="https://s0.wp.com/latex.php?latex=c%5Clog+%5E%7B2%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+%5E%7B2%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+%5E%7B2%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log ^{2}n" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{c}" class="latex" />. In particular, the same holds for any function in NL, and any function with power-size branching programs.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">                                                                                                                                                                                        <b>Proof</b>.&nbsp;</span>On input a graph <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="u" class="latex" /> nodes and two nodes <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />, let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be the <img src="https://s0.wp.com/latex.php?latex=u%5Ctimes+u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=u%5Ctimes+u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=u%5Ctimes+u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="u&#92;times u" class="latex" /> transition matrix corresponding to <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=M_%7Bi%2Cj%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7Bi%2Cj%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7Bi%2Cj%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{i,j}=1" class="latex" /> iff edge <img src="https://s0.wp.com/latex.php?latex=j%5Cto+i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j%5Cto+i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j%5Cto+i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j&#92;to i" class="latex" /> is in <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G" class="latex" />.</p>
<p style="text-align:justify">   Transition matrices are multiplied as normal matrices, except that â<img src="https://s0.wp.com/latex.php?latex=%2B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%2B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%2B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="+" class="latex" />â is replaced with â<img src="https://s0.wp.com/latex.php?latex=%5Cvee+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cvee+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cvee+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;vee " class="latex" />,â which suffices to know connectivity. To answer directed reachability we compute entry <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=M%5E%7Bu%7Dv&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%5E%7Bu%7Dv&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%5E%7Bu%7Dv&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M^{u}v" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="v" class="latex" /> has a <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> corresponding to <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> everywhere else. (We can modify the graph to add a self-loop on node <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> so that we can reach <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> in exactly <img src="https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="u" class="latex" /> steps iff we reach <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> in any number of steps.)</p>
<p style="text-align:justify">   Computing <img src="https://s0.wp.com/latex.php?latex=M%5E%7Bu%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%5E%7Bu%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%5E%7Bu%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M^{u}" class="latex" /> can be done by squaring <img src="https://s0.wp.com/latex.php?latex=c%5Clog+u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log u" class="latex" /> times <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />. Each squaring can be done in depth <img src="https://s0.wp.com/latex.php?latex=c%5Clog+u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log u" class="latex" />, by Exercise <a href="#x1-101002r2">9.2<!--tex4ht:ref: xca:Or-log-depth --></a>. This establishes the first claim, since <img src="https://s0.wp.com/latex.php?latex=u%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=u%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=u%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="u&#92;le n" class="latex" />.</p>
<p style="text-align:justify">   The âin particularâ follows because those functions can be reduced to directed reachability efficiently. <b>QED</b></p>
</div>
<p style="text-align:justify">   Conversely, we have the following.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-101004r2"></a> <b>Theorem</b> 9.2.  </span>Any  function  <img src="https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f: &#92;{0,1&#92;}^n &#92;to &#92;{0,1&#92;} " class="latex" />  computed  by  a  circuit  of  depth  <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />  can  be  computed  by  a branching program of size <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{d}" class="latex" />.</p>
<p style="text-align:justify">   In particular, functions computed by circuits of logarithmic depth can be computed by branching programs of power size.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Later in this chapter we will prove a stronger and much less obvious result.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>We proceed by induction on the depth of the circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. If the depth is <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> is either a constant or an input bit, and a branching program of size <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> is available by definition.</p>
<p style="text-align:justify">   Suppose the circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> has the form <img src="https://s0.wp.com/latex.php?latex=C_%7B1%7D%5Cwedge+C_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7B1%7D%5Cwedge+C_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7B1%7D%5Cwedge+C_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{1}&#92;wedge C_{2}" class="latex" />. By induction, <img src="https://s0.wp.com/latex.php?latex=C_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{1}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=C_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{2}" class="latex" /> have branching programs <img src="https://s0.wp.com/latex.php?latex=B_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B_{1}" class="latex" />and <img src="https://s0.wp.com/latex.php?latex=B_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B_{2}" class="latex" /> each of size <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{d-1}" class="latex" />. A branching program <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> of size <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{d}" class="latex" /> is obtained by rewiring the edges leading to states labelled <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=B_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B_{1}" class="latex" /> to the start state of <img src="https://s0.wp.com/latex.php?latex=B_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B_{2}" class="latex" />. The start state of <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> is the start state of <img src="https://s0.wp.com/latex.php?latex=B_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B_{1}" class="latex" />. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-101005r3"></a> <b>Exercise</b> 9.3.  </span>Finish the proof by analyzing the case <img src="https://s0.wp.com/latex.php?latex=C%3DC_%7B1%7D%5Cvee+C_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3DC_%7B1%7D%5Cvee+C_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3DC_%7B1%7D%5Cvee+C_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C=C_{1}&#92;vee C_{2}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-101006r1"></a> <b>Definition</b> 9.1.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{i}" class="latex" /> is the class of functions <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D%5E%2A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:&#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;}^* " class="latex" /> computable by circuits that have depth <img src="https://s0.wp.com/latex.php?latex=a%5Clog+%5E%7Bi%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%5Clog+%5E%7Bi%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%5Clog+%5E%7Bi%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#92;log ^{i}n" class="latex" /> and size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{a}" class="latex" />, for some constant <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a" class="latex" />. The circuits are uniform if they can be computed in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {L}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The class <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{0}" class="latex" /> is also of great interest. It can be more simply defined as the class of functions where each output bit depends on a constant number of input bits. We will see many surprising useful things that can be computed in this class.</p>
<p style="text-align:justify">   The previous results give, for uniform circuits:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNC%7D%5E%7B0%7D%5Csubseteq+%5Ctext+%7B%5Censuremath+%7B%5Ctext+%7BNC%7D%5E%7B1%7D%5Csubseteq+%7D%7D%5Ctext+%7BL%7D%5Csubseteq+%5Ctext+%7BNL%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B2%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B3%7D%5Csubseteq+%5Ccdots+%5Csubseteq+%5Ctext+%7BP%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNC%7D%5E%7B0%7D%5Csubseteq+%5Ctext+%7B%5Censuremath+%7B%5Ctext+%7BNC%7D%5E%7B1%7D%5Csubseteq+%7D%7D%5Ctext+%7BL%7D%5Csubseteq+%5Ctext+%7BNL%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B2%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B3%7D%5Csubseteq+%5Ccdots+%5Csubseteq+%5Ctext+%7BP%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNC%7D%5E%7B0%7D%5Csubseteq+%5Ctext+%7B%5Censuremath+%7B%5Ctext+%7BNC%7D%5E%7B1%7D%5Csubseteq+%7D%7D%5Ctext+%7BL%7D%5Csubseteq+%5Ctext+%7BNL%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B2%7D%5Csubseteq+%5Ctext+%7BNC%7D%5E%7B3%7D%5Csubseteq+%5Ccdots+%5Csubseteq+%5Ctext+%7BP%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {NC}^{0}&#92;subseteq &#92;text {&#92;ensuremath {&#92;text {NC}^{1}&#92;subseteq }}&#92;text {L}&#92;subseteq &#92;text {NL}&#92;subseteq &#92;text {NC}^{2}&#92;subseteq &#92;text {NC}^{3}&#92;subseteq &#92;cdots &#92;subseteq &#92;text {P}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   The only inclusion known to be strict is the first one:</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-101007r4"></a> <b>Exercise</b> 9.4.  </span>Prove that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B0%7D%5Cne+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B0%7D%5Cne+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B0%7D%5Cne+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{0}&#92;ne &#92;text {NC}^{1}" class="latex" />. (Mostly to practice definitions.)</p>
<p style="text-align:justify">
</div>
<h3 class="sectionHead"><span class="titlemark">9.1   </span> <a id="x1-1020009.1"></a>The power of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{1}" class="latex" />: Arithmetic</h3>
<p style="text-align:justify">In this section we illustrate the power of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{1}" class="latex" /> by showing that the same basic arithmetic which we saw is doable in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {L}" class="latex" /> (Theorem <a href="#x1-83001r5">7.5<!--tex4ht:ref: thm:arithmetic-L --></a>) can in fact be done in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{1}" class="latex" /> as well.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-102001r3"></a> <b>Theorem</b> 9.3.  </span> The following problems are in NC<img src="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^{1}" class="latex" />:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-102003x1">Addition of two input integers.</li>
<li class="enumerate" id="x1-102005x2">Iterated addition: Addition of any number of input integers.</li>
<li class="enumerate" id="x1-102007x3">Multiplication of two input integers.</li>
<li class="enumerate" id="x1-102009x4">Iterated multiplication: Multiplication of any number of input integers.</li>
<li class="enumerate" id="x1-102011x5">Division of two integers.</li>
</ol>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-102012r5"></a> <b>Exercise</b> 9.5.  </span>Prove Item 1.&nbsp;in Theorem <a href="#x1-102001r3">9.3<!--tex4ht:ref: thm:arithmetic-NC1 --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Iterated addition is surprisingly non-trivial. We canât use the methods from the proof of Theorem <a href="#x1-83001r5">7.5<!--tex4ht:ref: thm:arithmetic-L --></a>. Instead, we rely on a new and very clever technique.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Item 2.&nbsp;in Theorem <a href="#x1-102001r3">9.3<!--tex4ht:ref: thm:arithmetic-NC1 --></a>.</b>.&nbsp;</span> We use â2-out-of-3:â Given 3 integers <img src="https://s0.wp.com/latex.php?latex=X%2CY%2CZ&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X%2CY%2CZ&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X%2CY%2CZ&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X,Y,Z" class="latex" />, we compute 2 integers <img src="https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A,B" class="latex" /> such that</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+X%2BY%2BZ%3DA%2BB%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+X%2BY%2BZ%3DA%2BB%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+X%2BY%2BZ%3DA%2BB%2C+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} X+Y+Z=A+B, &#92;end{aligned}" class="latex" /></div>
<p>where each bit of <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> only depends on three bits, one from <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" />, one from <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" />, and one from <img src="https://s0.wp.com/latex.php?latex=Z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Z" class="latex" />. Thus <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> can be computed in NC<img src="https://s0.wp.com/latex.php?latex=%5E%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^{0}" class="latex" />.</p>
<p style="text-align:justify">   If we can do this, then to compute iterated addition we construct a tree of logarithmic depth to reduce the original sum to a sum <img src="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2" class="latex" /> terms, which we add as in Item 1.</p>
<p style="text-align:justify">   Hereâs how it works. Note <img src="https://s0.wp.com/latex.php?latex=X_%7Bi%7D%2BY_%7Bi%7D%2BZ_%7Bi%7D%5Cleq+3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X_%7Bi%7D%2BY_%7Bi%7D%2BZ_%7Bi%7D%5Cleq+3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X_%7Bi%7D%2BY_%7Bi%7D%2BZ_%7Bi%7D%5Cleq+3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X_{i}+Y_{i}+Z_{i}&#92;leq 3" class="latex" />. We let <img src="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A_{i}" class="latex" /> be the least significant bit of this sum, and <img src="https://s0.wp.com/latex.php?latex=B_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B_{i+1}" class="latex" /> the most significant one. Note that <img src="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A_{i}" class="latex" /> is the XOR <img src="https://s0.wp.com/latex.php?latex=X_%7Bi%7D%2BY_%7Bi%7D%2BZ_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X_%7Bi%7D%2BY_%7Bi%7D%2BZ_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X_%7Bi%7D%2BY_%7Bi%7D%2BZ_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X_{i}+Y_{i}+Z_{i}" class="latex" />, while <img src="https://s0.wp.com/latex.php?latex=B_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B_{i+1}" class="latex" /> is the majority of <img src="https://s0.wp.com/latex.php?latex=X_%7Bi%7D%2CY_%7Bi%7D%2CZ_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X_%7Bi%7D%2CY_%7Bi%7D%2CZ_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X_%7Bi%7D%2CY_%7Bi%7D%2CZ_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X_{i},Y_{i},Z_{i}" class="latex" />. <b>QED</b></p>
</div>
<p style="text-align:justify">   The following corollary will also be used to solve the teaser in Chapter <a href="#x1-180001">1<!--tex4ht:ref: chap:A-teaser --></a>.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-102013r1"></a> <b>Corollary</b> 9.1.  </span>Majority is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NC}^{1}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-102014r6"></a>                                                                                                                                                                                     <b>Exercise</b> 9.6.  </span>Prove it.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-102015r7"></a> <b>Exercise</b> 9.7.  </span>Prove Item 3.&nbsp;in Theorem <a href="#x1-102001r3">9.3<!--tex4ht:ref: thm:arithmetic-NC1 --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Next we turn to iterated multiplication. The idea is to follow the proof for L in section&nbsp;<a href="#x1-830007.2.1">7.2.1<!--tex4ht:ref: subsec:Arithmetic-in-L --></a>. We shall use CRR again. The problem is that we still had to perform iterated multiplication, albeit only in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7Bp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7Bp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7Bp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {Z}_{p}" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=p%5Cle+n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%5Cle+n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%5Cle+n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p&#92;le n^{c}" class="latex" />. One more mathematical result is useful now:</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-102016r4"></a> <b>Theorem</b> 9.4.  </span>If <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> is a prime then <img src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb+%7BZ%7D_%7Bp%7D-%5C%7B0%5C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5Cmathbb+%7BZ%7D_%7Bp%7D-%5C%7B0%5C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5Cmathbb+%7BZ%7D_%7Bp%7D-%5C%7B0%5C%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;mathbb {Z}_{p}-&#92;{0&#92;})" class="latex" /> is a cyclic group, meaning that there exists a generator <img src="https://s0.wp.com/latex.php?latex=g%5Cin+%28%5Cmathbb+%7BZ%7D_%7Bp%7D-%5C%7B0%5C%7D%29%3A%5Cforall+x%5Cin+%28%5Cmathbb+%7BZ%7D_%7Bp%7D-%5C%7B0%5C%7D%29%2Cx%3Dg%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g%5Cin+%28%5Cmathbb+%7BZ%7D_%7Bp%7D-%5C%7B0%5C%7D%29%3A%5Cforall+x%5Cin+%28%5Cmathbb+%7BZ%7D_%7Bp%7D-%5C%7B0%5C%7D%29%2Cx%3Dg%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g%5Cin+%28%5Cmathbb+%7BZ%7D_%7Bp%7D-%5C%7B0%5C%7D%29%3A%5Cforall+x%5Cin+%28%5Cmathbb+%7BZ%7D_%7Bp%7D-%5C%7B0%5C%7D%29%2Cx%3Dg%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g&#92;in (&#92;mathbb {Z}_{p}-&#92;{0&#92;}):&#92;forall x&#92;in (&#92;mathbb {Z}_{p}-&#92;{0&#92;}),x=g^{i}" class="latex" />, for some <img src="https://s0.wp.com/latex.php?latex=i%5Cin+%5Cmathbb+%7BZ%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cin+%5Cmathbb+%7BZ%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cin+%5Cmathbb+%7BZ%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;in &#92;mathbb {Z}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-102017r1"></a> <b>Example</b> 9.1.  </span>For <img src="https://s0.wp.com/latex.php?latex=p%3D5&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%3D5&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%3D5&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p=5" class="latex" /> we can take <img src="https://s0.wp.com/latex.php?latex=g%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g=2" class="latex" />: <img src="https://s0.wp.com/latex.php?latex=2%5E%7B0%7D%3D1%2C2%5E%7B1%7D%3D2%2C2%5E%7B2%7D%3D4%2C2%5E%7B3%7D%3D8%3D3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B0%7D%3D1%2C2%5E%7B1%7D%3D2%2C2%5E%7B2%7D%3D4%2C2%5E%7B3%7D%3D8%3D3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B0%7D%3D1%2C2%5E%7B1%7D%3D2%2C2%5E%7B2%7D%3D4%2C2%5E%7B3%7D%3D8%3D3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{0}=1,2^{1}=2,2^{2}=4,2^{3}=8=3" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Item 4.&nbsp;in Theorem <a href="#x1-102001r3">9.3<!--tex4ht:ref: thm:arithmetic-NC1 --></a></b>.&nbsp;</span> We follow the proof for L in section&nbsp;<a href="#x1-830007.2.1">7.2.1<!--tex4ht:ref: subsec:Arithmetic-in-L --></a>. To compute iterated product of integers <img src="https://s0.wp.com/latex.php?latex=r_%7B1%7D%2Cr_%7B2%7D%2C%5Cldots+%2Cr_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7B1%7D%2Cr_%7B2%7D%2C%5Cldots+%2Cr_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7B1%7D%2Cr_%7B2%7D%2C%5Cldots+%2Cr_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{1},r_{2},&#92;ldots ,r_{t}" class="latex" /> modulo <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />, use Theorem <a href="#x1-102016r4">9.4<!--tex4ht:ref: thm:cyclic-group-Zp-multiplicative --></a> to compute exponents <img src="https://s0.wp.com/latex.php?latex=e_%7B1%7D%2Ce_%7B2%7D%2C%5Cldots+%2Ce_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=e_%7B1%7D%2Ce_%7B2%7D%2C%5Cldots+%2Ce_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=e_%7B1%7D%2Ce_%7B2%7D%2C%5Cldots+%2Ce_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="e_{1},e_{2},&#92;ldots ,e_{t}" class="latex" /> s.t.&nbsp;</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+r_%7Bi%7D%3Dg%5E%7Be_%7Bi%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+r_%7Bi%7D%3Dg%5E%7Be_%7Bi%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+r_%7Bi%7D%3Dg%5E%7Be_%7Bi%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} r_{i}=g^{e_{i}}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   Then <img src="https://s0.wp.com/latex.php?latex=%5Cprod+_%7Bi%7Dr_%7Bi%7D%5Cmod+p%3Dg%5E%7B%5Csum+_%7Bi%7De_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cprod+_%7Bi%7Dr_%7Bi%7D%5Cmod+p%3Dg%5E%7B%5Csum+_%7Bi%7De_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cprod+_%7Bi%7Dr_%7Bi%7D%5Cmod+p%3Dg%5E%7B%5Csum+_%7Bi%7De_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;prod _{i}r_{i}&#92;mod p=g^{&#92;sum _{i}e_{i}}" class="latex" />. We can use Item 2.&nbsp;to compute the iterated addition of the exponents. Note that computing the exponent of a number mod <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />, and vice versa, can be done in log-depth since the numbers have <img src="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log n" class="latex" /> bits (as follows for example by combining Theorem <a href="#x1-26003r3">2.3<!--tex4ht:ref: thm:every-function-ckt-Lupanov --></a> and Exercise <a href="#x1-101002r2">9.2<!--tex4ht:ref: xca:Or-log-depth --></a>). <b>QED</b></p>
</div>
<p style="text-align:justify">   One can also compute division, and make all these circuits uniform, but we wonât prove this now.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">9.2   </span> <a id="x1-1030009.2"></a>Computing with 3 bits of memory</h3>
<p style="text-align:justify">We now move to a surprising result that in particular strengthens Theorem <a href="#x1-101004r2">9.2<!--tex4ht:ref: thm:simu-depth-d-br-prog-pow-size --></a>. For a moment, letâs forget about circuits, branching programs, etc.&nbsp;and instead consider a new, minimalistic type of programs. We will have 3 one-bit registers: <img src="https://s0.wp.com/latex.php?latex=R_%7B0%7D%2CR_%7B1%7D%2CR_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7B0%7D%2CR_%7B1%7D%2CR_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7B0%7D%2CR_%7B1%7D%2CR_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{0},R_{1},R_{2}" class="latex" />, operating modulo <img src="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2" class="latex" />. We allow the following operations</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7D%2C%5C%5C+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Dx_%7Bk%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7D%2C%5C%5C+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Dx_%7Bk%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7D%2C%5C%5C+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Dx_%7Bk%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} R_{i} &amp; +=R_{j},&#92;&#92; R_{i} &amp; +=R_{j}x_{k} &#92;end{aligned}" class="latex" /></div>
<p>where <img src="https://s0.wp.com/latex.php?latex=x_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{k}" class="latex" /> is an input bit, for any <img src="https://s0.wp.com/latex.php?latex=i%2Cj%5Cin+%5C%7B0%2C1%2C2%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%2Cj%5Cin+%5C%7B0%2C1%2C2%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%2Cj%5Cin+%5C%7B0%2C1%2C2%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i,j&#92;in &#92;{0,1,2&#92;}" class="latex" />, with <img src="https://s0.wp.com/latex.php?latex=i%5Cne+j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cne+j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cne+j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;ne j" class="latex" />. (Talk about RISC!) Here <img src="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{i}+=R_{j}" class="latex" /> means to add the content of <img src="https://s0.wp.com/latex.php?latex=R_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{j}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=R_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{i}" class="latex" />, while <img src="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7Dx_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7Dx_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7Dx_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{i}+=R_{j}x_{k}" class="latex" /> means to add <img src="https://s0.wp.com/latex.php?latex=R_%7Bj%7Dx_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bj%7Dx_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bj%7Dx_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{j}x_{k}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=R_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{i}" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=R_%7Bj%7Dx_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bj%7Dx_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bj%7Dx_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{j}x_{k}" class="latex" /> is the product (a.k.a.&nbsp;And) of <img src="https://s0.wp.com/latex.php?latex=R_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{j}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=x_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{k}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-103001r2"></a> <b>Definition</b> 9.2.  </span>For <img src="https://s0.wp.com/latex.php?latex=i%2Cj&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%2Cj&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%2Cj&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i,j" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f: &#92;{0,1&#92;}^n &#92;to &#92;{0,1&#92;} " class="latex" /> we say that a program is <em>for</em> (or <em>equivalent to</em>)</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D%2B%3DR_%7Bj%7Df+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D%2B%3DR_%7Bj%7Df+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D%2B%3DR_%7Bj%7Df+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} R_{i}+=R_{j}f &#92;end{aligned}" class="latex" /></div>
<p>if for every input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and initial values of the registers, executing the program is equivalent to the instruction <img src="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7Df%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7Df%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7Df%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{i}+=R_{j}f(x)" class="latex" />, where note that <img src="https://s0.wp.com/latex.php?latex=R_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{j}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=R_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bk%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{k}" class="latex" /> are unchanged.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Also note that if we repeat twice a program for <img src="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7Df&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7Df&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7Df&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{i}+=R_{j}f" class="latex" /> then no register changes (recall the sum is modulo <img src="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2" class="latex" />, so <img src="https://s0.wp.com/latex.php?latex=1%2B1%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%2B1%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%2B1%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1+1=0" class="latex" />). This feature is critically exploited later to âclean upâ computation.</p>
<p style="text-align:justify">   We now state and prove the surprising result. It is convenient to state it for circuits with Xor instead of Or gates. This is without loss of generality since <img src="https://s0.wp.com/latex.php?latex=x%5Cvee+y%3Dx%2By%2Bx%5Cwedge+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cvee+y%3Dx%2By%2Bx%5Cwedge+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cvee+y%3Dx%2By%2Bx%5Cwedge+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;vee y=x+y+x&#92;wedge y" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-103002r5"></a> <b>Theorem</b> 9.5.  </span><span class="cite">[<a href="#XBarrington89">44</a>,&nbsp;<a href="#XBen-OrC92">15</a>]</span> Suppose <img src="https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f: &#92;{0,1&#92;}^n &#92;to &#92;{0,1&#92;} " class="latex" /> is computable by circuits of depth <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> with Xor and And gates. For every <img src="https://s0.wp.com/latex.php?latex=i%5Cne+j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cne+j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cne+j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;ne j" class="latex" /> there is a program of length <img src="https://s0.wp.com/latex.php?latex=%5Cle+c4%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c4%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c4%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c4^{d}" class="latex" /> for</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Df.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Df.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Df.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} R_{i} &amp; +=R_{j}f. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Once such a program is available, we can start with register values <img src="https://s0.wp.com/latex.php?latex=%280%2C1%2C0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%280%2C1%2C0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%280%2C1%2C0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(0,1,0)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=i%3D0%2Cj%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3D0%2Cj%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3D0%2Cj%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i=0,j=1" class="latex" /> to obtain <img src="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=R_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7B0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{0}" class="latex" />.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">                                                                                                                                                                                        <b>Proof</b>.&nbsp;</span>We proceed by induction on <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />. When <img src="https://s0.wp.com/latex.php?latex=d%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d=1" class="latex" /> the circuit is simply outputting a constant or one of the input bits, which we can compute with the corresponding instructions. (If the circuit is the constant zero then the empty program would do.)</p>
<p style="text-align:justify">   Proceeding with the induction step:</p>
<p style="text-align:justify">   A program for <img src="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7D%28f_%7B1%7D%2Bf_%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7D%28f_%7B1%7D%2Bf_%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7D%28f_%7B1%7D%2Bf_%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{i}+=R_{j}(f_{1}+f_{2})" class="latex" /> is simply given by the concatenation of (the programs for)</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Df_%7B1%7D%5C%5C+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Df_%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Df_%7B1%7D%5C%5C+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Df_%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Df_%7B1%7D%5C%5C+R_%7Bi%7D+%26+%2B%3DR_%7Bj%7Df_%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} R_{i} &amp; +=R_{j}f_{1}&#92;&#92; R_{i} &amp; +=R_{j}f_{2}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   Less obviously, a program for <img src="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7D%28f_%7B1%7D%5Cwedge+f_%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7D%28f_%7B1%7D%5Cwedge+f_%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R_%7Bi%7D%2B%3DR_%7Bj%7D%28f_%7B1%7D%5Cwedge+f_%7B2%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R_{i}+=R_{j}(f_{1}&#92;wedge f_{2})" class="latex" /> is given by</p>
<p style="text-align:justify">
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bk%7Df_%7B1%7D%5C%5C+R_%7Bk%7D+%26+%2B%3DR_%7Bj%7Df_%7B2%7D%5C%5C+R_%7Bi%7D+%26+%2B%3DR_%7Bk%7Df_%7B1%7D%5C%5C+R_%7Bk%7D+%26+%2B%3DR_%7Bj%7Df_%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bk%7Df_%7B1%7D%5C%5C+R_%7Bk%7D+%26+%2B%3DR_%7Bj%7Df_%7B2%7D%5C%5C+R_%7Bi%7D+%26+%2B%3DR_%7Bk%7Df_%7B1%7D%5C%5C+R_%7Bk%7D+%26+%2B%3DR_%7Bj%7Df_%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+R_%7Bi%7D+%26+%2B%3DR_%7Bk%7Df_%7B1%7D%5C%5C+R_%7Bk%7D+%26+%2B%3DR_%7Bj%7Df_%7B2%7D%5C%5C+R_%7Bi%7D+%26+%2B%3DR_%7Bk%7Df_%7B1%7D%5C%5C+R_%7Bk%7D+%26+%2B%3DR_%7Bj%7Df_%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} R_{i} &amp; +=R_{k}f_{1}&#92;&#92; R_{k} &amp; +=R_{j}f_{2}&#92;&#92; R_{i} &amp; +=R_{k}f_{1}&#92;&#92; R_{k} &amp; +=R_{j}f_{2}. &#92;end{aligned}" class="latex" /></div>
<p><b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-103003r8"></a> <b>Exercise</b> 9.8.  </span>Prove that the program for <img src="https://s0.wp.com/latex.php?latex=f_%7B1%7D%5Cwedge+f_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7B1%7D%5Cwedge+f_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7B1%7D%5Cwedge+f_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{1}&#92;wedge f_{2}" class="latex" /> in the proof works. Write down the contents of the registers after each instruction in the program.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   A similar proof works over other fields as well.</p>
<p style="text-align:justify">   We can now address the teaser Theorem <a href="#x1-18002r1">1.1<!--tex4ht:ref: thm:Majority-3-bits-teaser --></a> from Chapter <a href="#x1-180001">1<!--tex4ht:ref: chap:A-teaser --></a>.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-18002r1">1.1<!--tex4ht:ref: thm:Majority-3-bits-teaser --></a>.</b>.&nbsp;</span> Combine Corollary <a href="#x1-102013r1">9.1<!--tex4ht:ref: cor:Majority-is-in-NC1 --></a> with Theorem <a href="#x1-103002r5">9.5<!--tex4ht:ref: thm:-barrington-ben-or-cleve --></a>. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-103004r2"></a> <b>Corollary</b> 9.2.  </span>Iterated product of 3&#215;3 matrices over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{2}" class="latex" /> is complete for NC<img src="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^{1}" class="latex" /> under projections.</p>
<p style="text-align:justify">   That is, the problem is in NC<img src="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^{1}" class="latex" /> and for any <img src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%5Cin+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%5Cin+%5Ctext+%7BNC%7D%5E%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f&#92;in &#92;text {NC}^{1}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> one can write a sequence of <img src="https://s0.wp.com/latex.php?latex=t%3Dn%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%3Dn%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%3Dn%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t=n^{c}" class="latex" /> 3&#215;3 matrices <img src="https://s0.wp.com/latex.php?latex=M_%7B1%7D%2CM_%7B2%7D%2C%5Cldots+%2CM_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M_%7B1%7D%2CM_%7B2%7D%2C%5Cldots+%2CM_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M_%7B1%7D%2CM_%7B2%7D%2C%5Cldots+%2CM_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M_{1},M_{2},&#92;ldots ,M_{t}" class="latex" /> where each entry is either a constant or an input variable <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{i}" class="latex" /> s.t.&nbsp;for every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" />:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cprod+_%7Bi%3D1%7D%5E%7Bt%7DM_%7Bi%7D%5Ccdot+%5Cbegin+%7Bbmatrix%7D0%5C%5C+1%5C%5C+0+%5Cend+%7Bbmatrix%7D%3D%5Cbegin+%7Bbmatrix%7Df%28x%29%5C%5C+1%5C%5C+0+%5Cend+%7Bbmatrix%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cprod+_%7Bi%3D1%7D%5E%7Bt%7DM_%7Bi%7D%5Ccdot+%5Cbegin+%7Bbmatrix%7D0%5C%5C+1%5C%5C+0+%5Cend+%7Bbmatrix%7D%3D%5Cbegin+%7Bbmatrix%7Df%28x%29%5C%5C+1%5C%5C+0+%5Cend+%7Bbmatrix%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cprod+_%7Bi%3D1%7D%5E%7Bt%7DM_%7Bi%7D%5Ccdot+%5Cbegin+%7Bbmatrix%7D0%5C%5C+1%5C%5C+0+%5Cend+%7Bbmatrix%7D%3D%5Cbegin+%7Bbmatrix%7Df%28x%29%5C%5C+1%5C%5C+0+%5Cend+%7Bbmatrix%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;prod _{i=1}^{t}M_{i}&#92;cdot &#92;begin {bmatrix}0&#92;&#92; 1&#92;&#92; 0 &#92;end {bmatrix}=&#92;begin {bmatrix}f(x)&#92;&#92; 1&#92;&#92; 0 &#92;end {bmatrix}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-103005r9"></a> <b>Exercise</b> 9.9.  </span>Prove this.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">9.3   </span> <a id="x1-1040009.3"></a>Linear-size log-depth</h3>
<p style="text-align:justify">It is unknown whether NP has linear-size circuits of logarithmic depth! But there is a non-trivial simulation of such circuits by AltCkts of depth 3 of sub-exponential size.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-104001r6"></a> <b>Theorem</b> 9.6.  </span><span class="cite">[<a href="#XVal77">67</a>]</span> Any circuit <img src="https://s0.wp.com/latex.php?latex=C%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3A+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C: &#92;{0,1&#92;}^n &#92;to &#92;{0,1&#92;} " class="latex" /> of size <img src="https://s0.wp.com/latex.php?latex=an&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=an&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=an&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="an" class="latex" /> and depth <img src="https://s0.wp.com/latex.php?latex=a%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a&#92;log n" class="latex" /> has an equivalent alternating circuit of depth 3 and size <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bc_%7Ba%7Dn%2F%5Clog+%5Clog+n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bc_%7Ba%7Dn%2F%5Clog+%5Clog+n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bc_%7Ba%7Dn%2F%5Clog+%5Clog+n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{c_{a}n/&#92;log &#92;log n}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The idea is&#8230; yes! Once again, we are going to guess computation. It is possible to guess the values of about <img src="https://s0.wp.com/latex.php?latex=n%2F%5Clog+%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2F%5Clog+%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2F%5Clog+%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n/&#92;log &#92;log n" class="latex" /> wires to reduce the depth to say <img src="https://s0.wp.com/latex.php?latex=0.1%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0.1%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0.1%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0.1&#92;log n" class="latex" />, and the rest is brute-forced. For an exposition, see <span class="cite">[<a href="#Xviola-FTTCS09">73</a>]</span>.</p>
<p style="text-align:justify">
<h3 class="likesectionHead"><a id="x1-1050009.3"></a>Notes</h3>
<p style="text-align:justify">Our presentation of Theorem <a href="#x1-103002r5">9.5<!--tex4ht:ref: thm:-barrington-ben-or-cleve --></a> follows <span class="cite">[<a href="#XCleve91">18</a>]</span>.</p>
<div class="thebibliography">
<p class="bibitem"><span class="biblabel">   [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness      results for LCS and other sequence similarity measures.  In Venkatesan Guruswami,      editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS      2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59â78. IEEE Computer Society,      2015.</p>
<p class="bibitem"><span class="biblabel">   [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard  Adleman.   Two  theorems  on  random  polynomial  time.   In  19th IEEE      Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75â83. 1978.</p>
<p class="bibitem"><span class="biblabel">   [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjt83"></a>Miklï¿½s Ajtai.  <img src="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CSigma+%5Csp+%7B1%7D%5Csb+%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Sigma &#92;sp {1}&#92;sb {1}" class="latex" />-formulae on finite structures.  Annals of Pure and Applied Logic,      24(1):1â48, 1983.</p>
<p class="bibitem"><span class="biblabel">   [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAjtai05"></a>Miklï¿½s Ajtai. A non-linear time lower bound for boolean branching programs. Theory      of Computing, 1(1):149â176, 2005.</p>
<p class="bibitem"><span class="biblabel">   [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAll89"></a>Eric  Allender.   A  note  on  the  power  of  threshold  circuits.   In  30th Symposium      on Foundations of Computer Science, pages 580â584, Research Triangle Park, North      Carolina, 30 Octoberâ1 November 1989. IEEE.</p>
<p class="bibitem"><span class="biblabel">   [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllender01"></a>Eric Allender. The division breakthroughs. Bulletin of the EATCS, 74:61â77, 2001.</p>
<p class="bibitem"><span class="biblabel">   [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAllenderK10"></a>Eric  Allender  and  Michal  KouckÃ½.     Amplifying  lower  bounds  by  means  of      self-reducibility. J.&nbsp;of the ACM, 57(3), 2010.</p>
<p class="bibitem"><span class="biblabel">   [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAGHP92"></a>Noga Alon, Oded Goldreich, Johan Hï¿½stad, and Renï¿½ Peralta. Simple constructions      of  almost  <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-wise  independent  random  variables.   Random  Structures  &amp;  Algorithms,      3(3):289â304, 1992.</p>
<p class="bibitem"><span class="biblabel">   [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian      circuits and matchings. J. Comput. Syst. Sci., 18(2):155â193, 1979.</p>
<p class="bibitem"><span class="biblabel">  [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.      Proof  verification  and  the  hardness  of  approximation  problems.    J.&nbsp;of  the  ACM,      45(3):501â555, May 1998.</p>
<p class="bibitem"><span class="biblabel">  [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk.  Edit distance cannot be computed in strongly      subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087â1097, 2018.</p>
<p class="bibitem"><span class="biblabel">  [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBatcher68"></a>Kenneth&nbsp;E. Batcher.  Sorting networks and their applications.  In AFIPS Spring      Joint Computing Conference, volume&nbsp;32, pages 307â314, 1968.</p>
<p class="bibitem"><span class="biblabel">  [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBeameCH86"></a>Paul  Beame,  Stephen&nbsp;A.  Cook,  and  H.&nbsp;James  Hoover.   Log  depth  circuits  for      division and related problems. SIAM J. Comput., 15(4):994â1003, 1986.</p>
<p class="bibitem"><span class="biblabel">  [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBSSV03"></a>Paul Beame, Michael Saks, Xiaodong Sun, and Erik Vee.   Time-space trade-off      lower  bounds  for  randomized  computation  of  decision  problems.   J.&nbsp;of  the  ACM,      50(2):154â195, 2003.</p>
<p class="bibitem"><span class="biblabel">  [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBen-OrC92"></a>Michael Ben-Or and Richard Cleve. Computing algebraic formulas using a constant      number of registers. SIAM J.&nbsp;on Computing, 21(1):54â58, 1992.</p>
<p class="bibitem"><span class="biblabel">  [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/cc/BussW15"></a>Samuel&nbsp;R.  Buss  and  Ryan  Williams.   Limits  on  alternation  trading  proofs  for      time-space lower bounds. Comput. Complex., 24(3):533â600, 2015.</p>
<p class="bibitem"><span class="biblabel">  [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/stoc/ChenT19"></a>Lijie Chen and Roei Tell. Bootstrapping results for threshold circuits &#8220;just beyond&#8221;      known lower bounds.  In Moses Charikar and Edith Cohen, editors, Proceedings of the      51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix,      AZ, USA, June 23-26, 2019, pages 34â41. ACM, 2019.</p>
<p class="bibitem"><span class="biblabel">  [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCleve91"></a>Richard  Cleve.    Towards  optimal  simulations  of  formulas  by  bounded-width                                                                                                                                                                                          programs. Computational Complexity, 1:91â105, 1991.</p>
<p class="bibitem"><span class="biblabel">  [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCook73"></a>Stephen&nbsp;A. Cook. A hierarchy for nondeterministic time complexity. J.&nbsp;of Computer      and System Sciences, 7(4):343â353, 1973.</p>
<p class="bibitem"><span class="biblabel">  [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Csanky76"></a>L.&nbsp;Csanky.     Fast  parallel  matrix  inversion  algorithms.     SIAM  J.  Comput.,      5(4):618â623, 1976.</p>
<p class="bibitem"><span class="biblabel">  [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/Fortnow00"></a>Lance  Fortnow.   Time-space  tradeoffs  for  satisfiability.   J.  Comput.  Syst.  Sci.,      60(2):337â353, 2000.</p>
<p class="bibitem"><span class="biblabel">  [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jct/FraenkelL81"></a>Aviezri&nbsp;S. Fraenkel and David Lichtenstein. Computing a perfect strategy for n x n      chess requires time exponential in n. J. Comb. Theory, Ser. A, 31(2):199â214, 1981.</p>
<p class="bibitem"><span class="biblabel">  [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XFredmanS89"></a>Michael&nbsp;L. Fredman and Michael&nbsp;E. Saks.  The cell probe complexity of dynamic      data structures. In ACM Symp.&nbsp;on the Theory of Computing (STOC), pages 345â354,      1989.</p>
<p class="bibitem"><span class="biblabel">  [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational      geometry. Comput. Geom., 5:165â185, 1995.</p>
<p class="bibitem"><span class="biblabel">  [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the      Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel">  [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;Gï¿½del.   ï¿½ber  formal  unentscheidbare  sï¿½tze  der  Principia  Mathematica  und      verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel">  [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge      University Press, 2008.</p>
<p class="bibitem"><span class="biblabel">  [28]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGreenlawHR-Limits"></a>Raymond  Greenlaw,  H.&nbsp;James  Hoover,  and  Walter  Ruzzo.   Limits  to  Parallel      Computation: P-Completeness Theory. 02 2001.</p>
<p class="bibitem"><span class="biblabel">  [29]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of      Mathematics, 193(2):563 â 617, 2021.</p>
<p class="bibitem"><span class="biblabel">  [30]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie.  One-tape, off-line turing machine computations.  Information and      Control, 8(6):553â578, 1965.</p>
<p class="bibitem"><span class="biblabel">  [31]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred  Hennie  and  Richard  Stearns.    Two-tape  simulation  of  multitape  turing      machines. J.&nbsp;of the ACM, 13:533â546, October 1966.</p>
<p class="bibitem"><span class="biblabel">  [32]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jacm/HopcroftPV77"></a>John&nbsp;E. Hopcroft, Wolfgang&nbsp;J. Paul, and Leslie&nbsp;G. Valiant. On time versus space.      J. ACM, 24(2):332â337, 1977.</p>
<p class="bibitem"><span class="biblabel">  [33]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi.   The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 237â, 1999.</p>
<p class="bibitem"><span class="biblabel">  [34]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImpagliazzoPS97"></a>Russell Impagliazzo, Ramamohan Paturi, and Michael&nbsp;E. Saks. Size-depth tradeoffs      for threshold circuits. SIAM J. Comput., 26(3):693â707, 1997.</p>
<p class="bibitem"><span class="biblabel">  [35]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.  Which problems have      strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512â530, Dec      2001.</p>
<p class="bibitem"><span class="biblabel">  [36]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell  Impagliazzo  and  Avi  Wigderson.    <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" />  if  <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" />  requires  exponential  circuits:      Derandomizing the XOR lemma.  In 29th ACM Symp.&nbsp;on the Theory of Computing      (STOC), pages 220â229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel">  [37]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKarpLi82"></a>Richard&nbsp;M.  Karp  and  Richard&nbsp;J.  Lipton.    Turing  machines  that  take  advice.      LâEnseignement Mathï¿½matique. Revue Internationale. IIe Sï¿½rie, 28(3-4):191â209, 1982.</p>
<p class="bibitem"><span class="biblabel">  [38]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi.  On the structure of one-tape nondeterministic turing machine      time hierarchy. Theor. Comput. Sci., 40:175â193, 1985.</p>
<p class="bibitem"><span class="biblabel">  [39]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/LarsenWY20"></a>Kasper&nbsp;Green Larsen, Omri Weinstein, and Huacheng Yu. Crossing the logarithmic      barrier for dynamic boolean data structure lower bounds.  SIAM J. Comput., 49(5),      2020.</p>
<p class="bibitem"><span class="biblabel">  [40]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A.  Levin.    Universal  sequential  search  problems.    Problemy  Peredachi      Informatsii, 9(3):115â116, 1973.</p>
<p class="bibitem"><span class="biblabel">  [41]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLundFoKaNi92"></a>Carsten Lund, Lance Fortnow, Howard Karloff, and Noam Nisan. Algebraic methods      for interactive proof systems. J.&nbsp;of the ACM, 39(4):859â868, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [42]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120â140, 1958.</p>
<p class="bibitem"><span class="biblabel">  [43]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMaS87"></a>Wolfgang Maass and Amir Schorr. Speed-up of Turing machines with one work tape      and a two-way input tape. SIAM J.&nbsp;on Computing, 16(1):195â202, 1987.</p>
<p class="bibitem"><span class="biblabel">  [44]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBarrington89"></a>David&nbsp;A.  Mix  Barrington.   Bounded-width  polynomial-size  branching  programs      recognize  exactly  those  languages  in  NC<img src="https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5E1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="^1" class="latex" />.    J.&nbsp;of  Computer  and  System  Sciences,      38(1):150â164, 1989.</p>
<p class="bibitem"><span class="biblabel">  [45]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNaN93"></a>Joseph Naor and Moni Naor.  Small-bias probability spaces: efficient constructions      and applications. SIAM J.&nbsp;on Computing, 22(4):838â856, 1993.</p>
<p class="bibitem"><span class="biblabel">  [46]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNechiporuk66"></a>E.&nbsp;I. Nechiporuk. A boolean function. Soviet Mathematics-Doklady, 169(4):765â766,      1966.</p>
<p class="bibitem"><span class="biblabel">  [47]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XNep70"></a>Valery&nbsp;A. NepomnjaÅ¡ÄiÄ­. Rudimentary predicates and Turing calculations. Soviet      Mathematics-Doklady, 11(6):1462â1465, 1970.</p>
<p class="bibitem"><span class="biblabel">  [48]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaNEU-ram2sat-neu-author"></a>NEU. From RAM to SAT. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2012.</p>
<p class="bibitem"><span class="biblabel">                                                                                                                                                                                      [49]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation,      and complexity classes. J. Comput. Syst. Sci., 43(3):425â440, 1991.</p>
<p class="bibitem"><span class="biblabel">  [50]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPPST83"></a>Wolfgang&nbsp;J. Paul, Nicholas Pippenger, Endre Szemerï¿½di, and William&nbsp;T. Trotter.      On determinism versus non-determinism and related problems (preliminary version). In      IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 429â438, 1983.</p>
<p class="bibitem"><span class="biblabel">  [51]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures.      J.&nbsp;of the ACM, 26(2):361â381, 1979.</p>
<p class="bibitem"><span class="biblabel">  [52]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XRaz87"></a>Alexander Razborov. Lower bounds on the dimension of schemes of bounded depth      in a complete basis containing the logical addition function.  Akademiya Nauk SSSR.      Matematicheskie Zametki, 41(4):598â607, 1987.  English translation in Mathematical      Notes of the Academy of Sci. of the USSR, 41(4):333-338, 1987.</p>
<p class="bibitem"><span class="biblabel">  [53]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XReingold08"></a>Omer Reingold. Undirected connectivity in log-space. J.&nbsp;of the ACM, 55(4), 2008.</p>
<p class="bibitem"><span class="biblabel">  [54]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Robson84"></a>J.&nbsp;M.  Robson.    N  by  N  checkers  is  exptime  complete.    SIAM  J.  Comput.,      13(2):252â267, 1984.</p>
<p class="bibitem"><span class="biblabel">  [55]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/coco/Santhanam01"></a>Rahul Santhanam.   On separators, segregators and time versus space.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 286â294, 2001.</p>
<p class="bibitem"><span class="biblabel">  [56]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSAVITCH1970177"></a>Walter&nbsp;J. Savitch.  Relationships between nondeterministic and deterministic tape      complexities. Journal of Computer and System Sciences, 4(2):177â192, 1970.</p>
<p class="bibitem"><span class="biblabel">  [57]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold Schï¿½nhage. Storage modification machines. SIAM J. Comput., 9(3):490â508,      1980.</p>
<p class="bibitem"><span class="biblabel">  [58]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XShamir92"></a>Adi Shamir. IP = PSPACE. J.&nbsp;of the ACM, 39(4):869â877, October 1992.</p>
<p class="bibitem"><span class="biblabel">  [59]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System                                                                                                                                                                                          Tech. J., 28:59â98, 1949.</p>
<p class="bibitem"><span class="biblabel">  [60]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields.      Mathematics of Computation, 54(189):435â447, 1990.</p>
<p class="bibitem"><span class="biblabel">  [61]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSiegel04"></a>Alan Siegel. On universal classes of extremely random constant-time hash functions.      SIAM J.&nbsp;on Computing, 33(3):505â543, 2004.</p>
<p class="bibitem"><span class="biblabel">  [62]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSip83b"></a>Michael Sipser. A complexity theoretic approach to randomness. In ACM Symp.&nbsp;on      the Theory of Computing (STOC), pages 330â335, 1983.</p>
<p class="bibitem"><span class="biblabel">  [63]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSmo87"></a>Roman Smolensky.  Algebraic methods in the theory of lower bounds for Boolean      circuit complexity.  In 19th ACM Symp.&nbsp;on the Theory of Computing (STOC), pages      77â82. ACM, 1987.</p>
<p class="bibitem"><span class="biblabel">  [64]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer.  Cosmological lower bound on the circuit      complexity of a small problem in logic. J. ACM, 49(6):753â784, 2002.</p>
<p class="bibitem"><span class="biblabel">  [65]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XToda91"></a>Seinosuke Toda.   PP is as hard as the polynomial-time hierarchy.   SIAM J.&nbsp;on      Computing, 20(5):865â877, 1991.</p>
<p class="bibitem"><span class="biblabel">  [66]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M.   Turing.      On   computable   numbers,   with   an   application   to   the      entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230â265, 1937.</p>
<p class="bibitem"><span class="biblabel">  [67]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XVal77"></a>Leslie&nbsp;G.  Valiant.   Graph-theoretic  arguments  in  low-level  complexity.   In  6th      Symposium on Mathematical Foundations of Computer Science, volume&nbsp;53 of Lecture      Notes in Computer Science, pages 162â176. Springer, 1977.</p>
<p class="bibitem"><span class="biblabel">  [68]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/ValiantV86"></a>Leslie&nbsp;G. Valiant and Vijay&nbsp;V. Vazirani. NP is as easy as detecting unique solutions.      Theor. Comput. Sci., 47(3):85â93, 1986.</p>
<p class="bibitem"><span class="biblabel">  [69]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMelkebeek06"></a>Dieter  van  Melkebeek.   A  survey  of  lower  bounds  for  satisfiability  and  related                                                                                                                                                                                          problems. Foundations and Trends in Theoretical Computer Science, 2(3):197â303, 2006.</p>
<p class="bibitem"><span class="biblabel">  [70]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/MelkebeekR05"></a>Dieter van Melkebeek and Ran Raz.  A time lower bound for satisfiability.  Theor.      Comput. Sci., 348(2-3):311â320, 2005.</p>
<p class="bibitem"><span class="biblabel">  [71]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/Vinodchandran05"></a>N.&nbsp;V. Vinodchandran.  A note on the circuit complexity of PP.  Theor. Comput.      Sci., 347(1-2):415â418, 2005.</p>
<p class="bibitem"><span class="biblabel">  [72]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaBPvsE"></a>Emanuele Viola.  On approximate majority and probabilistic time.  Computational      Complexity, 18(3):337â375, 2009.</p>
<p class="bibitem"><span class="biblabel">  [73]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-FTTCS09"></a>Emanuele Viola. On the power of small-depth computation. Foundations and Trends      in Theoretical Computer Science, 5(1):1â72, 2009.</p>
<p class="bibitem"><span class="biblabel">  [74]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola.  Reducing 3XOR to listing triangles, an exposition.  Available at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel">  [75]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-datastructurelb-implies-cclb"></a>Emanuele Viola.  Lower bounds for data structures with space close to maximum      imply  circuit  lower  bounds.    Theory  of  Computing,  15:1â9,  2019.    Available  at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>.</p>
<p class="bibitem"><span class="biblabel">  [76]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele  Viola.   Pseudorandom  bits  and  lower  bounds  for  randomized  turing      machines. Theory of Computing, 18(10):1â12, 2022.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T15:55:05Z">Wednesday, April 19 2023, 15:55</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/050'>TR23-050 |  Communication complexity of half-plane membership | 

	Hamed Hatami, 

	TsunMing Cheung, 

	Manasseh Ahmed, 

	Kusha Sareen</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We study the randomized communication complexity of the following problem. Alice receives the integer coordinates of a point in the plane, and Bob receives the integer parameters of a half-plane, and their goal is to determine whether Alice&#39;s point belongs to Bob&#39;s half-plane. 


This communication task corresponds to  determining whether $x_1y_1+y_2\geq x_2$, where the first player knows $(x_1,x_2) \in [n]^2$ and the second player knows $(y_1,y_2) \in [n]^2$. We prove that its randomized communication complexity is $\Omega(\log n)$.   
  


 
Our lower bound extends a recent result of Hatami, Hosseini, and Lovett (CCC &#39;20 and ToC &#39;22) regarding the largest possible gap between sign-rank and randomized communication complexity.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We study the randomized communication complexity of the following problem. Alice receives the integer coordinates of a point in the plane, and Bob receives the integer parameters of a half-plane, and their goal is to determine whether Alice&#39;s point belongs to Bob&#39;s half-plane. 


This communication task corresponds to  determining whether $x_1y_1+y_2\geq x_2$, where the first player knows $(x_1,x_2) \in [n]^2$ and the second player knows $(y_1,y_2) \in [n]^2$. We prove that its randomized communication complexity is $\Omega(\log n)$.   
  


 
Our lower bound extends a recent result of Hatami, Hosseini, and Lovett (CCC &#39;20 and ToC &#39;22) regarding the largest possible gap between sign-rank and randomized communication complexity.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T12:14:07Z">Wednesday, April 19 2023, 12:14</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/049'>TR23-049 |  Top-Down Lower Bounds for Depth-Four Circuits | 

	Mika GÃ¶Ã¶s, 

	Artur Riazanov, 

	Anastasia Sofronova, 

	Dmitry Sokolov</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We present a top-down lower-bound method for depth-$4$  boolean circuits. In particular, we give a new proof of the well-known result that the parity function requires depth-$4$ circuits of size exponential in $n^{1/3}$. Our proof is an application of robust sunflowers and block unpredictability.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We present a top-down lower-bound method for depth-$4$  boolean circuits. In particular, we give a new proof of the well-known result that the parity function requires depth-$4$ circuits of size exponential in $n^{1/3}$. Our proof is an application of robust sunflowers and block unpredictability.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T12:02:39Z">Wednesday, April 19 2023, 12:02</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/04/18/an-award-for-ellen-zegura/'>An Award For Ellen Zegura</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Ellen Zegura was just honored with the Class of 1934 Distinguished Professor Award. The Class of 1934 Distinguished Professor Award recognizes outstanding achievement in teaching, research, and service. It is the highest honor given to a Georgia Tech professor. Created in 1984 by the Class of 1934 in observance of its 50th reunion, the award [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
Ellen Zegura was just honored with the Class of 1934 Distinguished Professor <a href="https://news.gatech.edu/news/2023/04/13/ellen-zegura-honored-class-1934-distinguished-professor-award">Award</a>. The Class of 1934 Distinguished Professor Award recognizes outstanding achievement in teaching, research, and service. It is the highest honor given to a Georgia Tech professor. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/18/an-award-for-ellen-zegura/ez/" rel="attachment wp-att-21482"><img data-attachment-id="21482" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/18/an-award-for-ellen-zegura/ez/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/ez.jpeg?fit=248%2C225&amp;ssl=1" data-orig-size="248,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ez" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/ez.jpeg?fit=248%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/ez.jpeg?fit=248%2C225&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/ez.jpeg?resize=200%2C180&#038;ssl=1" alt="" width="200" height="180" class="aligncenter wp-image-21482" data-recalc-dims="1" /></a></p>
<p><P><br />
Created in 1984 by the Class of 1934 in observance of its 50th reunion, the award is presented to an active professor who has made significant, long-term contributions&#8212;contributions that have brought widespread recognition to the professor, to their school, and to the Institute. The GaTech <a href="https://news.gatech.edu/news/2023/04/13/ellen-zegura-honored-class-1934-distinguished-professor-award">story</a> on Ellen has many delightful personal details touching all aspects of her vocation.</p>
<p>
Two other people in our line have been so honored recently: <a href="https://www.cc.gatech.edu/people/james-foley">Jim Foley</a> from computing and <a href="https://news.gatech.edu/news/2016/04/11/thomas-earns-top-faculty-honor">Robin Thomas</a> from mathematics. As a past Tech professor I knew both of them well. I&#8217;ve also known other past winners of this great award. Congrats to Ellen.<br />
<span id="more-21480"></span></p>
<p>
<p><H2> Voting Too </H2></p>
<p><p>
Zegura is getting this award for many reasons, but one prominent reason is her research with two other top Georgia Tech professors&#8212;Michael Best and Rich DeMillo on voting safety. Best is a professor of international affairs and interactive computing at Georgia Tech and has worked globally on election systems monitoring for more than 15 years. DeMillo is the chair of the School of Cybersecurity and Privacy at Georgia Tech and has also worked on voting for years. </p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/18/an-award-for-ellen-zegura/trio/" rel="attachment wp-att-21483"><img data-attachment-id="21483" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/18/an-award-for-ellen-zegura/trio/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/Trio.jpg?fit=605%2C219&amp;ssl=1" data-orig-size="605,219" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Trio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/Trio.jpg?fit=300%2C109&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/Trio.jpg?fit=600%2C217&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/Trio.jpg?resize=550%2C200&#038;ssl=1" alt="" width="550" height="200" class="aligncenter wp-image-21483" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/Trio.jpg?w=605&amp;ssl=1 605w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/Trio.jpg?resize=300%2C109&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/Trio.jpg?resize=600%2C219&amp;ssl=1 600w" sizes="(max-width: 550px) 100vw, 550px" data-recalc-dims="1" /></a></p>
<p><P><br />
The trio wrote an opinion piece on <a href="https://www.ajc.com/opinion/opinion-ga-voting-processes-should-be-both-secure-and-usable/H2N2RAET65GGTEPSJDS67ORXGQ/">elections</a> in the Atlanta Journal-Constitution newspaper. Also see <a href="https://scs.gatech.edu/news/640727/georgia-techs-secure-and-safe-elections-research-group-provide-live-wait-times-fulton">this</a> for comments by Tech&#8217;s Secure and Safe Elections Research Group. </p>
<p>
Here are some of the papers this was based on&#8212;Rich was a co-author of the first, Ellen and Michael on the others: </p>
<ul>
<li>
<a href="https://oar.princeton.edu/bitstream/88435/pr1qj9r/1/BallotMarkingDeviceVoters.pdf">Ballot-Marking Devices</a>&#8212;DeMillo </p>
<li>
<a href="https://dl.acm.org/doi/abs/10.1145/2909609.2909623">A First Look at &#8220;Eyes on the Vote&#8221;</a>&#8212;Best and Zegura </p>
<li>
<a href="https://dl.acm.org/doi/abs/10.1145/2909609.2909640">Lessons in Social Election Monitoring</a>&#8212;Best and Zegura
</ul>
<p><H2> Open Problems </H2></p>
<p><p>
Again congrats to Ellen on being honored. </p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T03:08:19Z">Wednesday, April 19 2023, 03:08</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.08615'>Revisiting Block-Diagonal SDP Relaxations for the Clique Number of the Paley Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vladimir A. Kobzar, Krishnan Mody</p><p>This work addresses the block-diagonal semidefinite program (SDP) relaxations
for the clique number of the Paley graphs. The size of the maximal clique
(clique number) of a graph is a classic NP-complete problem; a Paley graph is a
deterministic graph where two vertices are connected if their difference is a
quadratic residue modulo certain prime powers. Improving the upper bound for
the Paley graph clique number for odd prime powers is an open problem in
combinatorics. Moreover, since quadratic residues exhibit pseudorandom
properties, Paley graphs are related to the construction of deterministic
restricted isometries, an open problem in compressed sensing and sparse
recovery. Recent work provides evidence that the current upper bounds can be
improved by the sum-of-squares (SOS) relaxations. In particular the bounds
given by the SOS relaxations of degree 4 (SOS-4) are asymptotically growing at
an order smaller than square root of the prime. However computations of SOS-4
become intractable with respect to large graphs. Gvozdenovic et al. introduced
a more computationally efficient block-diagonal hierarchy of SDPs that refines
the SOS hierarchy. They computed the values of these SDPs of degrees 2 and 3
(L2 and L3 respectively) for the Paley graph clique numbers associated with
primes p less or equal to 809. These values bound from the above the values of
the corresponding SOS-4 and SOS-6 relaxations respectively. We revisit these
computations and determine the values of the L2 relaxation for larger p's. Our
results provide additional numerical evidence that the L2 relaxations, and
therefore also the SOS-4 relaxations, are asymptotically growing at an order
smaller than the square root of p.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kobzar_V/0/1/0/all/0/1">Vladimir A. Kobzar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mody_K/0/1/0/all/0/1">Krishnan Mody</a></p><p>This work addresses the block-diagonal semidefinite program (SDP) relaxations
for the clique number of the Paley graphs. The size of the maximal clique
(clique number) of a graph is a classic NP-complete problem; a Paley graph is a
deterministic graph where two vertices are connected if their difference is a
quadratic residue modulo certain prime powers. Improving the upper bound for
the Paley graph clique number for odd prime powers is an open problem in
combinatorics. Moreover, since quadratic residues exhibit pseudorandom
properties, Paley graphs are related to the construction of deterministic
restricted isometries, an open problem in compressed sensing and sparse
recovery. Recent work provides evidence that the current upper bounds can be
improved by the sum-of-squares (SOS) relaxations. In particular the bounds
given by the SOS relaxations of degree 4 (SOS-4) are asymptotically growing at
an order smaller than square root of the prime. However computations of SOS-4
become intractable with respect to large graphs. Gvozdenovic et al. introduced
a more computationally efficient block-diagonal hierarchy of SDPs that refines
the SOS hierarchy. They computed the values of these SDPs of degrees 2 and 3
(L2 and L3 respectively) for the Paley graph clique numbers associated with
primes p less or equal to 809. These values bound from the above the values of
the corresponding SOS-4 and SOS-6 relaxations respectively. We revisit these
computations and determine the values of the L2 relaxation for larger p's. Our
results provide additional numerical evidence that the L2 relaxations, and
therefore also the SOS-4 relaxations, are asymptotically growing at an order
smaller than the square root of p.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T00:30:00Z">Wednesday, April 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.08745'>Super-Logarithmic Lower Bounds for Dynamic Graph Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kasper Green Larsen, Huacheng Yu</p><p>In this work, we prove a $\tilde{\Omega}(\lg^{3/2} n )$ unconditional lower
bound on the maximum of the query time and update time for dynamic data
structures supporting reachability queries in $n$-node directed acyclic graphs
under edge insertions. This is the first super-logarithmic lower bound for any
natural graph problem. In proving the lower bound, we also make novel
contributions to the state-of-the-art data structure lower bound techniques
that we hope may lead to further progress in proving lower bounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1">Kasper Green Larsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Huacheng Yu</a></p><p>In this work, we prove a $\tilde{\Omega}(\lg^{3/2} n )$ unconditional lower
bound on the maximum of the query time and update time for dynamic data
structures supporting reachability queries in $n$-node directed acyclic graphs
under edge insertions. This is the first super-logarithmic lower bound for any
natural graph problem. In proving the lower bound, we also make novel
contributions to the state-of-the-art data structure lower bound techniques
that we hope may lead to further progress in proving lower bounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T00:30:00Z">Wednesday, April 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.08534'>Lossy Compressor preserving variant calling through Extended BWT</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Veronica Guerrini, Felipe A. Louza, Giovanna Rosone</p><p>A standard format used for storing the output of high-throughput sequencing
experiments is the FASTQ format. It comprises three main components: (i)
headers, (ii) bases (nucleotide sequences), and (iii) quality scores. FASTQ
files are widely used for variant calling, where sequencing data are mapped
into a reference genome to discover variants that may be used for further
analysis. There are many specialized compressors that exploit redundancy in
FASTQ data with the focus only on either the bases or the quality scores
components. In this paper we consider the novel problem of lossy compressing,
in a reference-free way, FASTQ data by modifying both components at the same
time, while preserving the important information of the original FASTQ. We
introduce a general strategy, based on the Extended Burrows-Wheeler Transform
(EBWT) and positional clustering, and we present implementations in both
internal memory and external memory. Experimental results show that the lossy
compression performed by our tool is able to achieve good compression while
preserving information relating to variant calling more than the competitors.
Availability: the software is freely available at
github.com/veronicaguerrini/BFQzip.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Guerrini_V/0/1/0/all/0/1">Veronica Guerrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Louza_F/0/1/0/all/0/1">Felipe A. Louza</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosone_G/0/1/0/all/0/1">Giovanna Rosone</a></p><p>A standard format used for storing the output of high-throughput sequencing
experiments is the FASTQ format. It comprises three main components: (i)
headers, (ii) bases (nucleotide sequences), and (iii) quality scores. FASTQ
files are widely used for variant calling, where sequencing data are mapped
into a reference genome to discover variants that may be used for further
analysis. There are many specialized compressors that exploit redundancy in
FASTQ data with the focus only on either the bases or the quality scores
components. In this paper we consider the novel problem of lossy compressing,
in a reference-free way, FASTQ data by modifying both components at the same
time, while preserving the important information of the original FASTQ. We
introduce a general strategy, based on the Extended Burrows-Wheeler Transform
(EBWT) and positional clustering, and we present implementations in both
internal memory and external memory. Experimental results show that the lossy
compression performed by our tool is able to achieve good compression while
preserving information relating to variant calling more than the competitors.
Availability: the software is freely available at
https://github.com/veronicaguerrini/BFQzip.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T00:30:00Z">Wednesday, April 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.08567'>Traversing combinatorial 0/1-polytopes via optimization</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Arturo Merino, Torsten M&#xfc;tze</p><p>In this paper, we present a new framework that exploits combinatorial
optimization for efficiently generating a large variety of combinatorial
objects based on graphs, matroids, posets and polytopes. Our method relies on a
simple and versatile algorithm for computing a Hamilton path on the skeleton of
any 0/1-polytope ${\rm conv}(X)$, where $X\subseteq \{0,1\}^n$. The algorithm
uses as a black box any algorithm that solves a variant of the classical linear
optimization problem $\min\{w\cdot x\mid x\in X\}$, and the resulting delay,
i.e., the running time per visited vertex on the Hamilton path, is only by a
factor of $\log n$ larger than the running time of the optimization algorithm.
When $X$ encodes a particular class of combinatorial objects, then traversing
the skeleton of the polytope ${\rm conv}(X)$ along a Hamilton path corresponds
to listing the combinatorial objects by local change operations, i.e., we
obtain Gray code listings. As concrete results of our general framework, we
obtain efficient algorithms for generating all ($c$-optimal) bases in a
matroid; ($c$-optimal) spanning trees, forests, ($c$-optimal) matchings in a
general graph; ($c$-optimal) vertex covers, ($c$-optimal) stable sets in a
bipartite graph; as well as ($c$-optimal) antichains and ideals of a poset. The
delay and space required by these algorithms are polynomial in the size of the
matroid, graph, or poset, respectively, and these listings correspond to
Hamilton paths on the corresponding combinatorial polytopes. We also obtain an
$O(t_{\rm LP} \log n)$ delay algorithm for the vertex enumeration problem on
0/1-polytopes $\{x\in\mathbb{R}^n\mid Ax\leq b\}$, where $A\in
\mathbb{R}^{m\times n}$ and $b\in\mathbb{R}^m$, and $t_{\rm LP}$ is the time
needed to solve the linear program $\min\{w\cdot x\mid Ax\leq b\}$. This
improves upon the 25-year old $O(t_{\rm LP}\,n)$ delay algorithm of Bussieck
and L\"ubbecke.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Merino_A/0/1/0/all/0/1">Arturo Merino</a>, <a href="http://arxiv.org/find/cs/1/au:+Mutze_T/0/1/0/all/0/1">Torsten M&#xfc;tze</a></p><p>In this paper, we present a new framework that exploits combinatorial
optimization for efficiently generating a large variety of combinatorial
objects based on graphs, matroids, posets and polytopes. Our method relies on a
simple and versatile algorithm for computing a Hamilton path on the skeleton of
any 0/1-polytope ${\rm conv}(X)$, where $X\subseteq \{0,1\}^n$. The algorithm
uses as a black box any algorithm that solves a variant of the classical linear
optimization problem $\min\{w\cdot x\mid x\in X\}$, and the resulting delay,
i.e., the running time per visited vertex on the Hamilton path, is only by a
factor of $\log n$ larger than the running time of the optimization algorithm.
When $X$ encodes a particular class of combinatorial objects, then traversing
the skeleton of the polytope ${\rm conv}(X)$ along a Hamilton path corresponds
to listing the combinatorial objects by local change operations, i.e., we
obtain Gray code listings. As concrete results of our general framework, we
obtain efficient algorithms for generating all ($c$-optimal) bases in a
matroid; ($c$-optimal) spanning trees, forests, ($c$-optimal) matchings in a
general graph; ($c$-optimal) vertex covers, ($c$-optimal) stable sets in a
bipartite graph; as well as ($c$-optimal) antichains and ideals of a poset. The
delay and space required by these algorithms are polynomial in the size of the
matroid, graph, or poset, respectively, and these listings correspond to
Hamilton paths on the corresponding combinatorial polytopes. We also obtain an
$O(t_{\rm LP} \log n)$ delay algorithm for the vertex enumeration problem on
0/1-polytopes $\{x\in\mathbb{R}^n\mid Ax\leq b\}$, where $A\in
\mathbb{R}^{m\times n}$ and $b\in\mathbb{R}^m$, and $t_{\rm LP}$ is the time
needed to solve the linear program $\min\{w\cdot x\mid Ax\leq b\}$. This
improves upon the 25-year old $O(t_{\rm LP}\,n)$ delay algorithm of Bussieck
and L\"ubbecke.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T00:30:00Z">Wednesday, April 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.08581'>Graph Sparsification by Approximate Matrix Multiplication</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Neophytos Charalambides, Alfred O. Hero III</p><p>Graphs arising in statistical problems, signal processing, large networks,
combinatorial optimization, and data analysis are often dense, which causes
both computational and storage bottlenecks. One way of \textit{sparsifying} a
\textit{weighted} graph, while sharing the same vertices as the original graph
but reducing the number of edges, is through \textit{spectral sparsification}.
We study this problem through the perspective of RandNLA. Specifically, we
utilize randomized matrix multiplication to give a clean and simple analysis of
how sampling according to edge weights gives a spectral approximation to graph
Laplacians. Through the $CR$-MM algorithm, we attain a simple and
computationally efficient sparsifier whose resulting Laplacian estimate is
unbiased and of minimum variance. Furthermore, we define a new notion of
\textit{additive spectral sparsifiers}, which has not been considered in the
literature.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Charalambides_N/0/1/0/all/0/1">Neophytos Charalambides</a>, <a href="http://arxiv.org/find/math/1/au:+Hero_A/0/1/0/all/0/1">Alfred O. Hero III</a></p><p>Graphs arising in statistical problems, signal processing, large networks,
combinatorial optimization, and data analysis are often dense, which causes
both computational and storage bottlenecks. One way of \textit{sparsifying} a
\textit{weighted} graph, while sharing the same vertices as the original graph
but reducing the number of edges, is through \textit{spectral sparsification}.
We study this problem through the perspective of RandNLA. Specifically, we
utilize randomized matrix multiplication to give a clean and simple analysis of
how sampling according to edge weights gives a spectral approximation to graph
Laplacians. Through the $CR$-MM algorithm, we attain a simple and
computationally efficient sparsifier whose resulting Laplacian estimate is
unbiased and of minimum variance. Furthermore, we define a new notion of
\textit{additive spectral sparsifiers}, which has not been considered in the
literature.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T00:30:00Z">Wednesday, April 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.08632'>Subcubic algorithm for (Unweighted) Unrooted Tree Edit Distance</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Krzysztof Pi&#xf3;ro</p><p>The tree edit distance problem is a natural generalization of the classic
string edit distance problem. Given two ordered, edge-labeled trees $T_1$ and
$T_2$, the edit distance between $T_1$ and $T_2$ is defined as the minimum
total cost of operations that transform $T_1$ into $T_2$. In one operation, we
can contract an edge, split a vertex into two or change the label of an edge.
For the weighted version of the problem, where the cost of each operation
depends on the type of the operation and the label on the edge involved,
$\mathcal{O}(n^3)$ time algorithms are known for both rooted and unrooted
trees. The existence of a truly subcubic $\mathcal{O}(n^{3-\epsilon})$ time
algorithm is unlikely, as it would imply a truly subcubic algorithm for the
APSP problem. However, recently Mao (FOCS'21) showed that if we assume that
each operation has a unit cost, then the tree edit distance between two rooted
trees can be computed in truly subcubic time. In this paper, we show how to
adapt Mao's algorithm to make it work for unrooted trees and we show an
$\widetilde{\mathcal{O}}(n^{(7\omega + 15)/(2\omega + 6)}) \leq
\mathcal{O}(n^{2.9417})$ time algorithm for the unweighted tree edit distance
between two unrooted trees, where $\omega \leq 2.373$ is the matrix
multiplication exponent. It is the first known subcubic algorithm for unrooted
trees. The main idea behind our algorithm is the fact that to compute the tree
edit distance between two unrooted trees, it is enough to compute the tree edit
distance between an arbitrary rooting of the first tree and every rooting of
the second tree.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pioro_K/0/1/0/all/0/1">Krzysztof Pi&#xf3;ro</a></p><p>The tree edit distance problem is a natural generalization of the classic
string edit distance problem. Given two ordered, edge-labeled trees $T_1$ and
$T_2$, the edit distance between $T_1$ and $T_2$ is defined as the minimum
total cost of operations that transform $T_1$ into $T_2$. In one operation, we
can contract an edge, split a vertex into two or change the label of an edge.
For the weighted version of the problem, where the cost of each operation
depends on the type of the operation and the label on the edge involved,
$\mathcal{O}(n^3)$ time algorithms are known for both rooted and unrooted
trees. The existence of a truly subcubic $\mathcal{O}(n^{3-\epsilon})$ time
algorithm is unlikely, as it would imply a truly subcubic algorithm for the
APSP problem. However, recently Mao (FOCS'21) showed that if we assume that
each operation has a unit cost, then the tree edit distance between two rooted
trees can be computed in truly subcubic time. In this paper, we show how to
adapt Mao's algorithm to make it work for unrooted trees and we show an
$\widetilde{\mathcal{O}}(n^{(7\omega + 15)/(2\omega + 6)}) \leq
\mathcal{O}(n^{2.9417})$ time algorithm for the unweighted tree edit distance
between two unrooted trees, where $\omega \leq 2.373$ is the matrix
multiplication exponent. It is the first known subcubic algorithm for unrooted
trees. The main idea behind our algorithm is the fact that to compute the tree
edit distance between two unrooted trees, it is enough to compute the tree edit
distance between an arbitrary rooting of the first tree and every rooting of
the second tree.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T00:30:00Z">Wednesday, April 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.08648'>Dynamic Vector Bin Packing for Online Resource Allocation in the Cloud</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aniket Murhekar, David Arbour, Tung Mai, Anup Rao</p><p>Several cloud-based applications, such as cloud gaming, rent servers to
execute jobs which arrive in an online fashion. Each job has a resource demand
and must be dispatched to a cloud server which has enough resources to execute
the job, which departs after its completion. Under the `pay-as-you-go' billing
model, the server rental cost is proportional to the total time that servers
are actively running jobs. The problem of efficiently allocating a sequence of
online jobs to servers without exceeding the resource capacity of any server
while minimizing total server usage time can be modelled as a variant of the
dynamic bin packing problem (DBP), called MinUsageTime DBP.
</p>
<p>In this work, we initiate the study of the problem with multi-dimensional
resource demands (e.g. CPU/GPU usage, memory requirement, bandwidth usage,
etc.), called MinUsageTime Dynamic Vector Bin Packing (DVBP). We study the
competitive ratio (CR) of Any Fit packing algorithms for this problem. We show
almost-tight bounds on the CR of three specific Any Fit packing algorithms,
namely First Fit, Next Fit, and Move To Front. We prove that the CR of Move To
Front is at most $(2\mu+1)d +1$, where $\mu$ is the ratio of the max/min item
durations. For $d=1$, this significantly improves the previously known upper
bound of $6\mu+7$ (Kamali &amp; Lopez-Ortiz, 2015). We then prove the CR of First
Fit and Next Fit are bounded by $(\mu+2)d+1$ and $2\mu d+1$, respectively.
Next, we prove a lower bound of $(\mu+1)d$ on the CR of any Any Fit packing
algorithm, an improved lower bound of $2\mu d$ for Next Fit, and a lower bound
of $2\mu$ for Move To Front in the 1-D case. All our bounds improve or match
the best-known bounds for the 1-D case. Finally, we experimentally study the
average-case performance of these algorithms on randomly generated synthetic
data, and observe that Move To Front outperforms other Any Fit packing
algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Murhekar_A/0/1/0/all/0/1">Aniket Murhekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbour_D/0/1/0/all/0/1">David Arbour</a>, <a href="http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1">Tung Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Anup Rao</a></p><p>Several cloud-based applications, such as cloud gaming, rent servers to
execute jobs which arrive in an online fashion. Each job has a resource demand
and must be dispatched to a cloud server which has enough resources to execute
the job, which departs after its completion. Under the `pay-as-you-go' billing
model, the server rental cost is proportional to the total time that servers
are actively running jobs. The problem of efficiently allocating a sequence of
online jobs to servers without exceeding the resource capacity of any server
while minimizing total server usage time can be modelled as a variant of the
dynamic bin packing problem (DBP), called MinUsageTime DBP.
</p>
<p>In this work, we initiate the study of the problem with multi-dimensional
resource demands (e.g. CPU/GPU usage, memory requirement, bandwidth usage,
etc.), called MinUsageTime Dynamic Vector Bin Packing (DVBP). We study the
competitive ratio (CR) of Any Fit packing algorithms for this problem. We show
almost-tight bounds on the CR of three specific Any Fit packing algorithms,
namely First Fit, Next Fit, and Move To Front. We prove that the CR of Move To
Front is at most $(2\mu+1)d +1$, where $\mu$ is the ratio of the max/min item
durations. For $d=1$, this significantly improves the previously known upper
bound of $6\mu+7$ (Kamali &amp; Lopez-Ortiz, 2015). We then prove the CR of First
Fit and Next Fit are bounded by $(\mu+2)d+1$ and $2\mu d+1$, respectively.
Next, we prove a lower bound of $(\mu+1)d$ on the CR of any Any Fit packing
algorithm, an improved lower bound of $2\mu d$ for Next Fit, and a lower bound
of $2\mu$ for Move To Front in the 1-D case. All our bounds improve or match
the best-known bounds for the 1-D case. Finally, we experimentally study the
average-case performance of these algorithms on randomly generated synthetic
data, and observe that Move To Front outperforms other Any Fit packing
algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-19T00:30:00Z">Wednesday, April 19 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
