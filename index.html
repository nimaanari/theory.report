<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>
  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel='stylesheet' type='text/css' href='css/font-awesome.css'>
  <link rel='stylesheet' type='text/css' href='css/blank.css'>
</head>
<body>
  <div id='navwrap'>
    <div id='nav'>
      <p>
        Last Update
      </p>
      <p class='small'>
        
          <time class='timeago' datetime="2022-10-17T22:45:05Z">Monday, October 17 2022, 22:45</time>
        
      </p>

      <p>Feeds</p>
      <ul class='subscriptions small' >
      
        <li>
          <a href='http://arxiv.org/rss/cs.CC'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.CG'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.DS'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
          
        </li>
      
        <li>
          <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
          
        </li>
      
        <li>
          <a href='https://adamsheffer.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
          
        </li>
      
        <li>
          <a href='https://adamdsmith.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
          
        </li>
      
        <li>
          <a href='https://polylogblog.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
          
        </li>
      
        <li>
          <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
          
        </li>
      
        <li>
          <a href='http://www.argmin.net/feed.xml'><img src='i/feed.png'></a>
          <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
          
        </li>
      
        <li>
          <a href='http://bit-player.org/feed/atom/'><img src='i/feed.png'></a>
          <a href='http://bit-player.org'>bit-player</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-jobs.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-jobs.org'>CCI: jobs</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-events.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-events.org'>CS Theory Events</a>
          
        </li>
      
        <li>
          <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='https://11011110.github.io/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='https://11011110.github.io/blog/'>David Eppstein</a>
          
        </li>
      
        <li>
          <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='i/feed.png'></a>
          <a href='https://daveagp.wordpress.com'>David Pritchard</a>
          
        </li>
      
        <li>
          <a href='https://decentdescent.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://decentdescent.org/'>Decent Descent</a>
          
        </li>
      
        <li>
          <a href='https://decentralizedthoughts.github.io/feed'><img src='i/feed.png'></a>
          <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
          
        </li>
      
        <li>
          <a href='https://differentialprivacy.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
          
        </li>
      
        <li>
          <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='i/feed.png'></a>
          <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
          
        </li>
      
        <li>
          <a href='https://emanueleviola.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
          
        </li>
      
        <li>
          <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='i/feed.png'></a>
          <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
          
        </li>
      
        <li>
          <a href='https://dstheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
          
        </li>
      
        <li>
          <a href='https://francisbach.com/feed/'><img src='i/feed.png'></a>
          <a href='https://francisbach.com'>Francis Bach</a>
          
        </li>
      
        <li>
          <a href='https://gilkalai.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
          
        </li>
      
        <li>
          <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
          
        </li>
      
        <li>
          <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='i/feed.png'></a>
          <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
          
        </li>
      
        <li>
          <a href='https://gradientscience.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://gradientscience.org/'>Gradient Science</a>
          
        </li>
      
        <li>
          <a href='http://grigory.us/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
          
        </li>
      
        <li>
          <a href='https://tcsmath.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
          
        </li>
      
        <li>
          <a href='https://kamathematics.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
          
        </li>
      
        <li>
          <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
          
        </li>
      
        <li>
          <a href='https://lucatrevisan.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
          
        </li>
      
        <li>
          <a href='https://mittheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
          
        </li>
      
        <li>
          <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
          
        </li>
      
        <li>
          <a href='http://blog.mrtz.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
          
        </li>
      
        <li>
          <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
          
        </li>
      
        <li>
          <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
          
        </li>
      
        <li>
          <a href='http://www.solipsistslog.com/feed/'><img src='i/feed.png'></a>
          <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
          
        </li>
      
        <li>
          <a href='http://www.offconvex.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://offconvex.github.io/'>Off the Convex Path</a>
          
        </li>
      
        <li>
          <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
          
        </li>
      
        <li>
          <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
          
        </li>
      
        <li>
          <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='i/feed.png'></a>
          <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
          
        </li>
      
        <li>
          <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
          
        </li>
      
        <li>
          <a href='https://scottaaronson.blog/?feed=atom'><img src='i/feed.png'></a>
          <a href='https://scottaaronson.blog'>Scott Aaronson</a>
          
        </li>
      
        <li>
          <a href='https://blog.simons.berkeley.edu/feed/'><img src='i/feed.png'></a>
          <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
          
        </li>
      
        <li>
          <a href='https://tcsplus.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
          
        </li>
      
        <li>
          <a href='https://toc4fairness.org/feed/'><img src='i/feed.png'></a>
          <a href='https://toc4fairness.org'>TOC for Fairness</a>
          
        </li>
      
        <li>
          <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='i/feed.png'></a>
          <a href='http://blog.geomblog.org/'>The Geomblog</a>
          
        </li>
      
        <li>
          <a href='https://www.let-all.com/blog/feed/'><img src='i/feed.png'></a>
          <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
          
        </li>
      
        <li>
          <a href='https://theorydish.blog/feed/'><img src='i/feed.png'></a>
          <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
          
        </li>
      
        <li>
          <a href='https://thmatters.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://thmatters.wordpress.com'>Theory Matters</a>
          
        </li>
      
        <li>
          <a href='https://mycqstate.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
          
        </li>
      
        <li>
          <a href='https://agtb.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
          
        </li>
      
        <li>
          <a href='https://windowsontheory.org/feed/'><img src='i/feed.png'></a>
          <a href='https://windowsontheory.org'>Windows on Theory</a>
          
        </li>
      
      </ul>

      <p class='small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
      <p class='small'>Subscribe to the <a href="atom.xml">Atom feed</a> or <a href="rss20.xml">RSS feed</a> to stay up to date.</p>
      <p class='small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
      <p class='small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
      <p class='small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
    </div>
  </div>

  <div id='opts'>
    <div style='width: 100%; text-align: right;'>
    <img src='i/view-headlines.png' id='show-headlines' title='Show Headlines Only' width='24' height='24'>
    <img src='i/view-snippets.png' id='show-snippets' title='Show Snippets' width='24' height='24'>
    <img src='i/view-standard.png' id='show-fulltext' title='Show Full Text' width='24' height='24'>
    </div>
  </div>

  <h1>
    Theory of Computing Report
  </h1>

  <div id="articles">
    
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Monday, October 17
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/10/17/assistant-professor-at-massachusetts-institute-of-technology-apply-by-december-15-2022/'>Assistant Professor  at Massachusetts Institute of Technology (apply by December 15, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The Mathematics Department at the Massachusetts Institute of Technology (MIT) together with the MIT Schwarzman College of Computing (SCC) is seeking to fill one position in Theoretical Aspects of Quantum Computing at the level of tenure-track Assistant Professor beginning July 1, 2023 (for the 2023-2024 academic year, or as soon thereafter as possible). Website: www.mathjobs.org/jobs/list/20993 [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The Mathematics Department at the Massachusetts Institute of Technology (MIT) together with the MIT Schwarzman College of Computing (SCC) is seeking to fill one position in Theoretical Aspects of Quantum Computing at the level of tenure-track Assistant Professor beginning July 1, 2023 (for the 2023-2024 academic year, or as soon thereafter as possible).</p>
<p>Website: <a href="https://www.mathjobs.org/jobs/list/20993">https://www.mathjobs.org/jobs/list/20993</a><br />
Email: akuhl@mit.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T18:01:45Z">Monday, October 17 2022, 18:01</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/10/17/faculty-at-university-of-memphis-apply-by-november-28-2022/'>Faculty at University of Memphis (apply by November 28, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The Department of Computer Science at the University of Memphis is seeking candidates for Assistant Professor position(s) beginning Fall 2023. Qualified candidates in all areas of computer science are invited, while candidates with core expertise in emerging areas of systems, software engineering, theory, and cybersecurity are particularly encouraged to apply. Website: workforum.memphis.edu/postings/33990 Email: cconnor2@memphis.edu
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The Department of Computer Science at the University of Memphis is seeking candidates for Assistant Professor position(s) beginning Fall 2023. Qualified candidates in all areas of computer science are invited, while candidates with core expertise in emerging areas of systems, software engineering, theory, and cybersecurity are particularly encouraged to apply.</p>
<p>Website: <a href="https://workforum.memphis.edu/postings/33990">https://workforum.memphis.edu/postings/33990</a><br />
Email: cconnor2@memphis.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T15:07:15Z">Monday, October 17 2022, 15:07</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07383'>Notes on CSPs and Polymorphisms</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Zarathustra Brady</p><p>These are notes from a multi-year learning seminar on the algebraic approach
to Constraint Satisfaction Problems (CSPs). The main topics covered are the
theory of algebraic structures with few subpowers, the theory of absorbing
subalgebras and its applications to studying CSP templates which can be solved
by local consistency methods, and the dichotomy theorem for conservative CSP
templates. Subsections and appendices cover supplementary material.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Brady_Z/0/1/0/all/0/1">Zarathustra Brady</a></p><p>These are notes from a multi-year learning seminar on the algebraic approach
to Constraint Satisfaction Problems (CSPs). The main topics covered are the
theory of algebraic structures with few subpowers, the theory of absorbing
subalgebras and its applications to studying CSP templates which can be solved
by local consistency methods, and the dichotomy theorem for conservative CSP
templates. Subsections and appendices cover supplementary material.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07754'>Zero-Rate Thresholds and New Capacity Bounds for List-Decoding and List-Recovery</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Nicolas Resch, Chen Yuan, Yihan Zhang</p><p>In this work we consider the list-decodability and list-recoverability of
arbitrary $q$-ary codes, for all integer values of $q\geq 2$. A code is called
$(p,L)_q$-list-decodable if every radius $pn$ Hamming ball contains less than
$L$ codewords; $(p,\ell,L)_q$-list-recoverability is a generalization where we
place radius $pn$ Hamming balls on every point of a combinatorial rectangle
with side length $\ell$ and again stipulate that there be less than $L$
codewords.
</p>
<p>Our main contribution is to precisely calculate the maximum value of $p$ for
which there exist infinite families of positive rate
$(p,\ell,L)_q$-list-recoverable codes, the quantity we call the zero-rate
threshold. Denoting this value by $p_*$, we in fact show that codes correcting
a $p_*+\varepsilon$ fraction of errors must have size $O_{\varepsilon}(1)$,
i.e., independent of $n$. Such a result is typically referred to as a ``Plotkin
bound.'' To complement this, a standard random code with expurgation
construction shows that there exist positive rate codes correcting a
$p_*-\varepsilon$ fraction of errors. We also follow a classical proof template
(typically attributed to Elias and Bassalygo) to derive from the zero-rate
threshold other tradeoffs between rate and decoding radius for list-decoding
and list-recovery.
</p>
<p>Technically, proving the Plotkin bound boils down to demonstrating the Schur
convexity of a certain function defined on the $q$-simplex as well as the
convexity of a univariate function derived from it. We remark that an earlier
argument claimed similar results for $q$-ary list-decoding; however, we point
out that this earlier proof is flawed.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Resch_N/0/1/0/all/0/1">Nicolas Resch</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_C/0/1/0/all/0/1">Chen Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yihan Zhang</a></p><p>In this work we consider the list-decodability and list-recoverability of
arbitrary $q$-ary codes, for all integer values of $q\geq 2$. A code is called
$(p,L)_q$-list-decodable if every radius $pn$ Hamming ball contains less than
$L$ codewords; $(p,\ell,L)_q$-list-recoverability is a generalization where we
place radius $pn$ Hamming balls on every point of a combinatorial rectangle
with side length $\ell$ and again stipulate that there be less than $L$
codewords.
</p>
<p>Our main contribution is to precisely calculate the maximum value of $p$ for
which there exist infinite families of positive rate
$(p,\ell,L)_q$-list-recoverable codes, the quantity we call the zero-rate
threshold. Denoting this value by $p_*$, we in fact show that codes correcting
a $p_*+\varepsilon$ fraction of errors must have size $O_{\varepsilon}(1)$,
i.e., independent of $n$. Such a result is typically referred to as a ``Plotkin
bound.'' To complement this, a standard random code with expurgation
construction shows that there exist positive rate codes correcting a
$p_*-\varepsilon$ fraction of errors. We also follow a classical proof template
(typically attributed to Elias and Bassalygo) to derive from the zero-rate
threshold other tradeoffs between rate and decoding radius for list-decoding
and list-recovery.
</p>
<p>Technically, proving the Plotkin bound boils down to demonstrating the Schur
convexity of a certain function defined on the $q$-simplex as well as the
convexity of a univariate function derived from it. We remark that an earlier
argument claimed similar results for $q$-ary list-decoding; however, we point
out that this earlier proof is flawed.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07545'>Hypergraphs for multiscale cycles in structured data</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Agnese Barbensi, Hee Rhang Yoon, Christian Degnbol Madsen, Deborah O. Ajayi, Michael P.H. Stumpf, Heather A. Harrington</p><p>Scientific data has been growing in both size and complexity across the
modern physical, engineering, life and social sciences. Spatial structure, for
example, is a hallmark of many of the most important real-world complex
systems, but its analysis is fraught with statistical challenges. Topological
data analysis can provide a powerful computational window on complex systems.
Here we present a framework to extend and interpret persistent homology
summaries to analyse spatial data across multiple scales. We introduce
hyperTDA, a topological pipeline that unifies local (e.g. geodesic) and global
(e.g. Euclidean) metrics without losing spatial information, even in the
presence of noise. Homology generators offer an elegant and flexible
description of spatial structures and can capture the information computed by
persistent homology in an interpretable way. Here the information computed by
persistent homology is transformed into a weighted hypergraph, where hyperedges
correspond to homology generators. We consider different choices of generators
(e.g. matroid or minimal) and find that centrality and community detection are
robust to either choice. We compare hyperTDA to existing geometric measures and
validate its robustness to noise. We demonstrate the power of computing
higher-order topological structures on spatial curves arising frequently in
ecology, biophysics, and biology, but also in high-dimensional financial
datasets. We find that hyperTDA can select between synthetic trajectories from
the landmark 2020 AnDi challenge and quantifies movements of different animal
species, even when data is limited.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Barbensi_A/0/1/0/all/0/1">Agnese Barbensi</a>, <a href="http://arxiv.org/find/math/1/au:+Yoon_H/0/1/0/all/0/1">Hee Rhang Yoon</a>, <a href="http://arxiv.org/find/math/1/au:+Madsen_C/0/1/0/all/0/1">Christian Degnbol Madsen</a>, <a href="http://arxiv.org/find/math/1/au:+Ajayi_D/0/1/0/all/0/1">Deborah O. Ajayi</a>, <a href="http://arxiv.org/find/math/1/au:+Stumpf_M/0/1/0/all/0/1">Michael P.H. Stumpf</a>, <a href="http://arxiv.org/find/math/1/au:+Harrington_H/0/1/0/all/0/1">Heather A. Harrington</a></p><p>Scientific data has been growing in both size and complexity across the
modern physical, engineering, life and social sciences. Spatial structure, for
example, is a hallmark of many of the most important real-world complex
systems, but its analysis is fraught with statistical challenges. Topological
data analysis can provide a powerful computational window on complex systems.
Here we present a framework to extend and interpret persistent homology
summaries to analyse spatial data across multiple scales. We introduce
hyperTDA, a topological pipeline that unifies local (e.g. geodesic) and global
(e.g. Euclidean) metrics without losing spatial information, even in the
presence of noise. Homology generators offer an elegant and flexible
description of spatial structures and can capture the information computed by
persistent homology in an interpretable way. Here the information computed by
persistent homology is transformed into a weighted hypergraph, where hyperedges
correspond to homology generators. We consider different choices of generators
(e.g. matroid or minimal) and find that centrality and community detection are
robust to either choice. We compare hyperTDA to existing geometric measures and
validate its robustness to noise. We demonstrate the power of computing
higher-order topological structures on spatial curves arising frequently in
ecology, biophysics, and biology, but also in high-dimensional financial
datasets. We find that hyperTDA can select between synthetic trajectories from
the landmark 2020 AnDi challenge and quantifies movements of different animal
species, even when data is limited.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07838'>Fields2Cover: An open-source coverage path planning library for unmanned agricultural vehicles</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Gonzalo Mier, Jo&#xe3;o Valente, Sytze de Bruin</p><p>This paper describes Fields2Cover, a novel open source library for coverage
path planning (CPP) for agricultural vehicles. While there are several CPP
solutions nowadays, there have been limited efforts to unify them into an open
source library and provide benchmarking tools to compare their performance.
Fields2Cover provides a framework for planning coverage paths, developing novel
techniques, and benchmarking state-of-the-art algorithms. The library features
a modular and extensible architecture that supports various vehicles and can be
used for a variety of applications, including farms. Its core modules are: a
headland generator, a swath generator, a route planner and a path planner. An
interface to the Robot Operating System (ROS) is also supplied as an add-on. In
this paper, the functionalities of the library for planning a coverage path in
agriculture are demonstrated using 8 state-of-the-art methods and 7 objective
functions in simulation and field experiments.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mier_G/0/1/0/all/0/1">Gonzalo Mier</a>, <a href="http://arxiv.org/find/cs/1/au:+Valente_J/0/1/0/all/0/1">Jo&#xe3;o Valente</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruin_S/0/1/0/all/0/1">Sytze de Bruin</a></p><p>This paper describes Fields2Cover, a novel open source library for coverage
path planning (CPP) for agricultural vehicles. While there are several CPP
solutions nowadays, there have been limited efforts to unify them into an open
source library and provide benchmarking tools to compare their performance.
Fields2Cover provides a framework for planning coverage paths, developing novel
techniques, and benchmarking state-of-the-art algorithms. The library features
a modular and extensible architecture that supports various vehicles and can be
used for a variety of applications, including farms. Its core modules are: a
headland generator, a swath generator, a route planner and a path planner. An
interface to the Robot Operating System (ROS) is also supplied as an add-on. In
this paper, the functionalities of the library for planning a coverage path in
agriculture are demonstrated using 8 state-of-the-art methods and 7 objective
functions in simulation and field experiments.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07534'>Time-Space Tradeoffs for Element Distinctness and Set Intersection via Pseudorandomness</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Xin Lyu, Weihao Zhu</p><p>In the Element Distinctness problem, one is given an array $a_1,\dots, a_n$
of integers from $[poly(n)]$ and is tasked to decide if $\{a_i\}$ are mutually
distinct. Beame, Clifford and Machmouchi (FOCS 2013) gave a low-space algorithm
for this problem running in space $S(n)$ and time $T(n)$ where $T(n) \le
\widetilde{O}(n^{3/2}/S(n)^{1/2})$, assuming a random oracle (i.e., random
access to polynomially many random bits). A recent breakthrough by Chen, Jin,
Williams and Wu (SODA 2022) showed how to remove the random oracle assumption
in the regime $S(n) = polylog(n)$ and $T(n) = \widetilde{O}(n^{3/2})$. They
designed the first truly $polylog(n)$-space, $\widetilde{O}(n^{3/2})$-time
algorithm by constructing a small family of hash functions $\mathcal{H}
\subseteq \{h | h:[poly(n)]\to [n]\}$ with a certain pseudorandom property.
</p>
<p>In this paper, we give a significantly simplified analysis of the
pseudorandom hash family by Chen et al. Our analysis clearly identifies the key
pseudorandom property required to fool the BCM algorithm, allowing us to
explore the full potential of this construction. As our main result, we show a
time-space tradeoff for Element Distinctness without random oracle. Namely, for
every $S(n),T(n)$ such that $T\approx \widetilde{O}(n^{3/2}/S(n)^{1/2})$, our
algorithm can solve the problem in space $S(n)$ and time $T(n)$. Our algorithm
also works for a related problem Set Intersection, for which this tradeoff is
tight due to a matching lower bound by Dinur (Eurocrypt 2020). As two
additional contributions, we show a more general pseudorandom property of the
hash family, and slightly improve the seed length to sample the pseudorandom
hash function.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1">Xin Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Weihao Zhu</a></p><p>In the Element Distinctness problem, one is given an array $a_1,\dots, a_n$
of integers from $[poly(n)]$ and is tasked to decide if $\{a_i\}$ are mutually
distinct. Beame, Clifford and Machmouchi (FOCS 2013) gave a low-space algorithm
for this problem running in space $S(n)$ and time $T(n)$ where $T(n) \le
\widetilde{O}(n^{3/2}/S(n)^{1/2})$, assuming a random oracle (i.e., random
access to polynomially many random bits). A recent breakthrough by Chen, Jin,
Williams and Wu (SODA 2022) showed how to remove the random oracle assumption
in the regime $S(n) = polylog(n)$ and $T(n) = \widetilde{O}(n^{3/2})$. They
designed the first truly $polylog(n)$-space, $\widetilde{O}(n^{3/2})$-time
algorithm by constructing a small family of hash functions $\mathcal{H}
\subseteq \{h | h:[poly(n)]\to [n]\}$ with a certain pseudorandom property.
</p>
<p>In this paper, we give a significantly simplified analysis of the
pseudorandom hash family by Chen et al. Our analysis clearly identifies the key
pseudorandom property required to fool the BCM algorithm, allowing us to
explore the full potential of this construction. As our main result, we show a
time-space tradeoff for Element Distinctness without random oracle. Namely, for
every $S(n),T(n)$ such that $T\approx \widetilde{O}(n^{3/2}/S(n)^{1/2})$, our
algorithm can solve the problem in space $S(n)$ and time $T(n)$. Our algorithm
also works for a related problem Set Intersection, for which this tradeoff is
tight due to a matching lower bound by Dinur (Eurocrypt 2020). As two
additional contributions, we show a more general pseudorandom property of the
hash family, and slightly improve the seed length to sample the pseudorandom
hash function.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07699'>s-Club Cluster Vertex Deletion on Interval and Well-Partitioned Chordal Graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Dibyayan Chakraborty, L. Sunil Chandran, Sajith Padinhatteeri, Raji. R. Pillai</p><p>In this paper, we study the computational complexity of \textsc{$s$-Club
Cluster Vertex Deletion}. Given a graph, \textsc{$s$-Club Cluster Vertex
Deletion ($s$-CVD)} aims to delete the minimum number of vertices from the
graph so that each connected component of the resulting graph has a diameter at
most $s$. When $s=1$, the corresponding problem is popularly known as \sloppy
\textsc{Cluster Vertex Deletion (CVD)}. We provide a faster algorithm for
\textsc{$s$-CVD} on \emph{interval graphs}. For each $s\geq 1$, we give an
$O(n(n+m))$-time algorithm for \textsc{$s$-CVD} on interval graphs with $n$
vertices and $m$ edges. In the case of $s=1$, our algorithm is a slight
improvement over the $O(n^3)$-time algorithm of Cao \etal (Theor. Comput. Sci.,
2018) and for $s \geq 2$, it significantly improves the state-of-the-art
running time $\left(O\left(n^4\right)\right)$.
</p>
<p>We also give a polynomial-time algorithm to solve \textsc{CVD} on
\emph{well-partitioned chordal graphs}, a graph class introduced by Ahn \etal
(\textsc{WG 2020}) as a tool for narrowing down complexity gaps for problems
that are hard on chordal graphs, and easy on split graphs. Our algorithm relies
on a characterisation of the optimal solution and on solving polynomially many
instances of the \textsc{Weighted Bipartite Vertex Cover}. This generalises a
result of Cao \etal (Theor. Comput. Sci., 2018) on split graphs.
</p>
<p>We also show that for any even integer $s\geq 2$, \textsc{$s$-CVD} is NP-hard
on well-partitioned chordal graphs.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1">Dibyayan Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandran_L/0/1/0/all/0/1">L. Sunil Chandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Padinhatteeri_S/0/1/0/all/0/1">Sajith Padinhatteeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Pillai_R/0/1/0/all/0/1">Raji. R. Pillai</a></p><p>In this paper, we study the computational complexity of \textsc{$s$-Club
Cluster Vertex Deletion}. Given a graph, \textsc{$s$-Club Cluster Vertex
Deletion ($s$-CVD)} aims to delete the minimum number of vertices from the
graph so that each connected component of the resulting graph has a diameter at
most $s$. When $s=1$, the corresponding problem is popularly known as \sloppy
\textsc{Cluster Vertex Deletion (CVD)}. We provide a faster algorithm for
\textsc{$s$-CVD} on \emph{interval graphs}. For each $s\geq 1$, we give an
$O(n(n+m))$-time algorithm for \textsc{$s$-CVD} on interval graphs with $n$
vertices and $m$ edges. In the case of $s=1$, our algorithm is a slight
improvement over the $O(n^3)$-time algorithm of Cao \etal (Theor. Comput. Sci.,
2018) and for $s \geq 2$, it significantly improves the state-of-the-art
running time $\left(O\left(n^4\right)\right)$.
</p>
<p>We also give a polynomial-time algorithm to solve \textsc{CVD} on
\emph{well-partitioned chordal graphs}, a graph class introduced by Ahn \etal
(\textsc{WG 2020}) as a tool for narrowing down complexity gaps for problems
that are hard on chordal graphs, and easy on split graphs. Our algorithm relies
on a characterisation of the optimal solution and on solving polynomially many
instances of the \textsc{Weighted Bipartite Vertex Cover}. This generalises a
result of Cao \etal (Theor. Comput. Sci., 2018) on split graphs.
</p>
<p>We also show that for any even integer $s\geq 2$, \textsc{$s$-CVD} is NP-hard
on well-partitioned chordal graphs.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07911'>Popularity on the Roommate Diversity Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Steven Ge, Toshiya Itoh</p><p>A recently introduced restricted variant of the multidimensional stable
roommate problem is the roommate diversity problem: each agent belongs to one
of two types (e.g., red and blue), and the agents' preferences over the
coalitions solely depend on the fraction of agents of their own type among
their roommates.
</p>
<p>There are various notions of stability that defines an optimal partitioning
of agents. The notion of popularity has received a lot of attention recently. A
partitioning of agents is popular if there does not exist another partitioning
in which more agents are better off than worse off. Computing a popular
partition in a stable roommate game can be done in polynomial time. When we
allow ties the stable roommate problem becomes NP-complete. Determining the
existence of a popular solution in the multidimensional stable roommate problem
also NP-hard.
</p>
<p>We show that in the roommate diversity problem with the room size fixed to
two, the problem becomes tractable. Particularly, a popular partitioning of
agents is guaranteed to exist and can be computed in polynomial time.
Additionally a mixed popular partitioning of agents is always guaranteed to
exist in any roommate diversity game. By contrast, when there are no
restrictions on the coalition size of a roommate diversity game, a popular
partitioning may fail to exist and the problem becomes intractable. Our results
intractability results are summarized as follows:
</p>
<p>* Determining the existence of a popular partitioning is co-NP-hard, even if
the agents' preferences are trichotomous.
</p>
<p>* Determining the existence of a strictly popular partitioning is co-NP-hard,
even if the agents' preferences are dichotomous.
</p>
<p>* Computing a mixed popular partitioning of agents in polynomial time is
impossible unless P=NP, even if the agents' preferences are dichotomous.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1">Steven Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Itoh_T/0/1/0/all/0/1">Toshiya Itoh</a></p><p>A recently introduced restricted variant of the multidimensional stable
roommate problem is the roommate diversity problem: each agent belongs to one
of two types (e.g., red and blue), and the agents' preferences over the
coalitions solely depend on the fraction of agents of their own type among
their roommates.
</p>
<p>There are various notions of stability that defines an optimal partitioning
of agents. The notion of popularity has received a lot of attention recently. A
partitioning of agents is popular if there does not exist another partitioning
in which more agents are better off than worse off. Computing a popular
partition in a stable roommate game can be done in polynomial time. When we
allow ties the stable roommate problem becomes NP-complete. Determining the
existence of a popular solution in the multidimensional stable roommate problem
also NP-hard.
</p>
<p>We show that in the roommate diversity problem with the room size fixed to
two, the problem becomes tractable. Particularly, a popular partitioning of
agents is guaranteed to exist and can be computed in polynomial time.
Additionally a mixed popular partitioning of agents is always guaranteed to
exist in any roommate diversity game. By contrast, when there are no
restrictions on the coalition size of a roommate diversity game, a popular
partitioning may fail to exist and the problem becomes intractable. Our results
intractability results are summarized as follows:
</p>
<p>* Determining the existence of a popular partitioning is co-NP-hard, even if
the agents' preferences are trichotomous.
</p>
<p>* Determining the existence of a strictly popular partitioning is co-NP-hard,
even if the agents' preferences are dichotomous.
</p>
<p>* Computing a mixed popular partitioning of agents in polynomial time is
impossible unless P=NP, even if the agents' preferences are dichotomous.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07333'>Online Algorithms for the Santa Claus Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: MohammadTaghi Hajiaghayi, MohammadReza Khani, Debmalya Panigrahi, Max Springer</p><p>The Santa Claus problem is a fundamental problem in fair division: the goal
is to partition a set of heterogeneous items among heterogeneous agents so as
to maximize the minimum value of items received by any agent. In this paper, we
study the online version of this problem where the items are not known in
advance and have to be assigned to agents as they arrive over time. If the
arrival order of items is arbitrary, then no good assignment rule exists in the
worst case. However, we show that, if the arrival order is random, then for $n$
agents and any $\varepsilon &gt; 0$, we can obtain a competitive ratio of
$1-\varepsilon$ when the optimal assignment gives value at least $\Omega(\log n
/ \varepsilon^2)$ to every agent (assuming each item has at most unit value).
We also show that this result is almost tight: namely, if the optimal solution
has value at most $C \ln n / \varepsilon$ for some constant $C$, then there is
no $(1-\varepsilon)$-competitive algorithm even for random arrival order.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1">MohammadTaghi Hajiaghayi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khani_M/0/1/0/all/0/1">MohammadReza Khani</a>, <a href="http://arxiv.org/find/cs/1/au:+Panigrahi_D/0/1/0/all/0/1">Debmalya Panigrahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Springer_M/0/1/0/all/0/1">Max Springer</a></p><p>The Santa Claus problem is a fundamental problem in fair division: the goal
is to partition a set of heterogeneous items among heterogeneous agents so as
to maximize the minimum value of items received by any agent. In this paper, we
study the online version of this problem where the items are not known in
advance and have to be assigned to agents as they arrive over time. If the
arrival order of items is arbitrary, then no good assignment rule exists in the
worst case. However, we show that, if the arrival order is random, then for $n$
agents and any $\varepsilon &gt; 0$, we can obtain a competitive ratio of
$1-\varepsilon$ when the optimal assignment gives value at least $\Omega(\log n
/ \varepsilon^2)$ to every agent (assuming each item has at most unit value).
We also show that this result is almost tight: namely, if the optimal solution
has value at most $C \ln n / \varepsilon$ for some constant $C$, then there is
no $(1-\varepsilon)$-competitive algorithm even for random arrival order.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07363'>The Power of Multi-Step Vizing Chains</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Aleksander B G Christiansen</p><p>Recent papers [Ber'2022], [GP'2020], [DHZ'2019] have addressed different
variants of the (\Delta + 1)-edge colouring problem by concatenating or gluing
together many Vizing chains to form what Bernshteyn [Ber'2022] coined
\emph{multi-step Vizing chains}.
</p>
<p>In this paper, we propose a slightly more general definition of this term. We
then apply multi-step Vizing chain constructions to prove combinatorial
properties of edge colourings that lead to (improved) algorithms for computing
edge colouring across different models of computation.
</p>
<p>This approach seems especially powerful for constructing augmenting subgraphs
which respect some notion of locality.
</p>
<p>First, we construct strictly local multi-step Vizing chains and use them to
show a local version of Vizings Theorem thus confirming a recent conjecture of
Bonamy, Delcourt, Lang and Postle [BDLP'2020].
</p>
<p>Our proof is constructive and also implies an algorithm for computing such a
colouring.
</p>
<p>Then, we show that for any uncoloured edge there exists an augmenting
subgraph of size O(\Delta^{6}\log n), answering an open problem of Bernshteyn
[Ber'2022]. Chang, He, Li, Pettie and Uitto [CHLPU'2018] show a lower bound of
\Omega(\Delta \log \frac{n}{\Delta}) for the size of such augmenting subgraphs,
so the upper bound is tight up to \Delta and constant factors.
</p>
<p>These ideas also extend to give a faster deterministic LOCAL algorithm for
(\Delta + 1)-edge colouring running in \tilde{O}(\poly(\Delta)\log^6 n) rounds.
These results improve the recent breakthrough result of Bernshteyn [Ber'2022],
who showed the existence of augmenting subgraphs of size O(\Delta^6\log^2 n),
and used these to give the first (\Delta + 1)-edge colouring algorithm in the
LOCAL model running in O(\poly(\Delta, \log n)) rounds. ... (see paper for the
remaining part of the abstract)
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Christiansen_A/0/1/0/all/0/1">Aleksander B G Christiansen</a></p><p>Recent papers [Ber'2022], [GP'2020], [DHZ'2019] have addressed different
variants of the (\Delta + 1)-edge colouring problem by concatenating or gluing
together many Vizing chains to form what Bernshteyn [Ber'2022] coined
\emph{multi-step Vizing chains}.
</p>
<p>In this paper, we propose a slightly more general definition of this term. We
then apply multi-step Vizing chain constructions to prove combinatorial
properties of edge colourings that lead to (improved) algorithms for computing
edge colouring across different models of computation.
</p>
<p>This approach seems especially powerful for constructing augmenting subgraphs
which respect some notion of locality.
</p>
<p>First, we construct strictly local multi-step Vizing chains and use them to
show a local version of Vizings Theorem thus confirming a recent conjecture of
Bonamy, Delcourt, Lang and Postle [BDLP'2020].
</p>
<p>Our proof is constructive and also implies an algorithm for computing such a
colouring.
</p>
<p>Then, we show that for any uncoloured edge there exists an augmenting
subgraph of size O(\Delta^{6}\log n), answering an open problem of Bernshteyn
[Ber'2022]. Chang, He, Li, Pettie and Uitto [CHLPU'2018] show a lower bound of
\Omega(\Delta \log \frac{n}{\Delta}) for the size of such augmenting subgraphs,
so the upper bound is tight up to \Delta and constant factors.
</p>
<p>These ideas also extend to give a faster deterministic LOCAL algorithm for
(\Delta + 1)-edge colouring running in \tilde{O}(\poly(\Delta)\log^6 n) rounds.
These results improve the recent breakthrough result of Bernshteyn [Ber'2022],
who showed the existence of augmenting subgraphs of size O(\Delta^6\log^2 n),
and used these to give the first (\Delta + 1)-edge colouring algorithm in the
LOCAL model running in O(\poly(\Delta, \log n)) rounds. ... (see paper for the
remaining part of the abstract)
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07556'>A Constructive Prophet Inequality Approach to The Adaptive ProbeMax Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Guillermo Gallego, Danny Segev</p><p>In the adaptive ProbeMax problem, given a collection of mutually-independent
random variables $X_1, \ldots, X_n$, our goal is to design an adaptive probing
policy for sequentially sampling at most $k$ of these variables, with the
objective of maximizing the expected maximum value sampled. In spite of its
stylized formulation, this setting captures numerous technical hurdles inherent
to stochastic optimization, related to both information structure and efficient
computation. For these reasons, adaptive ProbeMax has served as a test bed for
a multitude of algorithmic methods, and concurrently as a popular teaching tool
in courses and tutorials dedicated to recent trends in optimization under
uncertainty.
</p>
<p>The main contribution of this paper consists in proposing a novel method for
upper-bounding the expected maximum reward of optimal adaptive probing
policies, based on a simple min-max problem. Equipped with this method, we
devise purely-combinatorial algorithms for deterministically computing feasible
sets whose vicinity to the adaptive optimum is analyzed through prophet
inequality ideas. Consequently, this approach allows us to establish improved
constructive adaptivity gaps for the ProbeMax problem in its broadest form,
where $X_1, \ldots, X_n$ are general random variables, making further
advancements when $X_1, \ldots, X_n$ are continuous.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gallego_G/0/1/0/all/0/1">Guillermo Gallego</a>, <a href="http://arxiv.org/find/cs/1/au:+Segev_D/0/1/0/all/0/1">Danny Segev</a></p><p>In the adaptive ProbeMax problem, given a collection of mutually-independent
random variables $X_1, \ldots, X_n$, our goal is to design an adaptive probing
policy for sequentially sampling at most $k$ of these variables, with the
objective of maximizing the expected maximum value sampled. In spite of its
stylized formulation, this setting captures numerous technical hurdles inherent
to stochastic optimization, related to both information structure and efficient
computation. For these reasons, adaptive ProbeMax has served as a test bed for
a multitude of algorithmic methods, and concurrently as a popular teaching tool
in courses and tutorials dedicated to recent trends in optimization under
uncertainty.
</p>
<p>The main contribution of this paper consists in proposing a novel method for
upper-bounding the expected maximum reward of optimal adaptive probing
policies, based on a simple min-max problem. Equipped with this method, we
devise purely-combinatorial algorithms for deterministically computing feasible
sets whose vicinity to the adaptive optimum is analyzed through prophet
inequality ideas. Consequently, this approach allows us to establish improved
constructive adaptivity gaps for the ProbeMax problem in its broadest form,
where $X_1, \ldots, X_n$ are general random variables, making further
advancements when $X_1, \ldots, X_n$ are continuous.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07580'>GriT-DBSCAN: A Spatial Clustering Algorithm for Very Large Databases</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Xiaogang Huang, Tiefeng Ma, Conan Liu, Shuangzhe Liu</p><p>DBSCAN is a fundamental spatial clustering algorithm with numerous practical
applications. However, a bottleneck of the algorithm is in the worst case, the
run time complexity is $O(n^2)$. To address this limitation, we propose a new
grid-based algorithm for exact DBSCAN in Euclidean space called GriT-DBSCAN,
which is based on the following two techniques. First, we introduce a grid tree
to organize the non-empty grids for the purpose of efficient non-empty
neighboring grids queries. Second, by utilising the spatial relationships among
points, we propose a technique that iteratively prunes unnecessary distance
calculations when determining whether the minimum distance between two sets is
less than or equal to a certain threshold. We theoretically prove that the
complexity of GriT-DBSCAN is linear to the data set size. In addition, we
obtain two variants of GriT-DBSCAN by incorporating heuristics, or by combining
the second technique with an existing algorithm. Experiments are conducted on
both synthetic and real-world data sets to evaluate the efficiency of
GriT-DBSCAN and its variants. The results of our analyses show that our
algorithms outperform existing algorithms.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaogang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tiefeng Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Conan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuangzhe Liu</a></p><p>DBSCAN is a fundamental spatial clustering algorithm with numerous practical
applications. However, a bottleneck of the algorithm is in the worst case, the
run time complexity is $O(n^2)$. To address this limitation, we propose a new
grid-based algorithm for exact DBSCAN in Euclidean space called GriT-DBSCAN,
which is based on the following two techniques. First, we introduce a grid tree
to organize the non-empty grids for the purpose of efficient non-empty
neighboring grids queries. Second, by utilising the spatial relationships among
points, we propose a technique that iteratively prunes unnecessary distance
calculations when determining whether the minimum distance between two sets is
less than or equal to a certain threshold. We theoretically prove that the
complexity of GriT-DBSCAN is linear to the data set size. In addition, we
obtain two variants of GriT-DBSCAN by incorporating heuristics, or by combining
the second technique with an existing algorithm. Experiments are conducted on
both synthetic and real-world data sets to evaluate the efficiency of
GriT-DBSCAN and its variants. The results of our analyses show that our
algorithms outperform existing algorithms.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07639'>Parallel solutions for ordinal scheduling with a small number of machines</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Leah Epstein</p><p>We study ordinal makespan scheduling on small numbers of identical machines,
with respect to two parallel solutions. In ordinal scheduling, it is known that
jobs are sorted by non-increasing sizes, but the specific sizes are not known
in advance. For problems with two parallel solutions, it is required to design
two solutions, and the performance of algorithm is tested for each input using
the best solution of the two. We find tight results for makespan minimization
on two and three machines, and algorithms that have strictly better competitive
ratios than the best possible algorithm with a single solution also for four
and five machines. To prove upper bounds, we use a new approach of considering
pairs of machines from the two solutions.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_L/0/1/0/all/0/1">Leah Epstein</a></p><p>We study ordinal makespan scheduling on small numbers of identical machines,
with respect to two parallel solutions. In ordinal scheduling, it is known that
jobs are sorted by non-increasing sizes, but the specific sizes are not known
in advance. For problems with two parallel solutions, it is required to design
two solutions, and the performance of algorithm is tested for each input using
the best solution of the two. We find tight results for makespan minimization
on two and three machines, and algorithms that have strictly better competitive
ratios than the best possible algorithm with a single solution also for four
and five machines. To prove upper bounds, we use a new approach of considering
pairs of machines from the two solutions.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07722'>(1,1)-Cluster Editing is Polynomial-time Solvable</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Gregory Gutin, Anders Yeo</p><p>A graph $H$ is a clique graph if $H$ is a vertex-disjoin union of cliques.
Abu-Khzam (2017) introduced the $(a,d)$-{Cluster Editing} problem, where for
fixed natural numbers $a,d$, given a graph $G$ and vertex-weights $a^*:\
V(G)\rightarrow \{0,1,\dots, a\}$ and $d^*{}:\ V(G)\rightarrow \{0,1,\dots,
d\}$, we are to decide whether $G$ can be turned into a cluster graph by
deleting at most $d^*(v)$ edges incident to every $v\in V(G)$ and adding at
most $a^*(v)$ edges incident to every $v\in V(G)$. Results by Komusiewicz and
Uhlmann (2012) and Abu-Khzam (2017) provided a dichotomy of complexity (in P or
NP-complete) of $(a,d)$-{Cluster Editing} for all pairs $a,d$ apart from
$a=d=1.$ Abu-Khzam (2017) conjectured that $(1,1)$-{Cluster Editing} is in P.
We resolve Abu-Khzam's conjecture in affirmative by (i) providing a serious of
five polynomial-time reductions to $C_3$-free and $C_4$-free graphs of maximum
degree at most 3, and (ii) designing a polynomial-time algorithm for solving
$(1,1)$-{Cluster Editing} on $C_3$-free and $C_4$-free graphs of maximum degree
at most 3.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gutin_G/0/1/0/all/0/1">Gregory Gutin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_A/0/1/0/all/0/1">Anders Yeo</a></p><p>A graph $H$ is a clique graph if $H$ is a vertex-disjoin union of cliques.
Abu-Khzam (2017) introduced the $(a,d)$-{Cluster Editing} problem, where for
fixed natural numbers $a,d$, given a graph $G$ and vertex-weights $a^*:\
V(G)\rightarrow \{0,1,\dots, a\}$ and $d^*{}:\ V(G)\rightarrow \{0,1,\dots,
d\}$, we are to decide whether $G$ can be turned into a cluster graph by
deleting at most $d^*(v)$ edges incident to every $v\in V(G)$ and adding at
most $a^*(v)$ edges incident to every $v\in V(G)$. Results by Komusiewicz and
Uhlmann (2012) and Abu-Khzam (2017) provided a dichotomy of complexity (in P or
NP-complete) of $(a,d)$-{Cluster Editing} for all pairs $a,d$ apart from
$a=d=1.$ Abu-Khzam (2017) conjectured that $(1,1)$-{Cluster Editing} is in P.
We resolve Abu-Khzam's conjecture in affirmative by (i) providing a serious of
five polynomial-time reductions to $C_3$-free and $C_4$-free graphs of maximum
degree at most 3, and (ii) designing a polynomial-time algorithm for solving
$(1,1)$-{Cluster Editing} on $C_3$-free and $C_4$-free graphs of maximum degree
at most 3.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-17T00:30:00Z">Monday, October 17 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Sunday, October 16
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://emanueleviola.wordpress.com/2022/10/16/correlation-bounds-against-polynomials-a-survey/'>Correlation bounds against polynomials, a survey</a></h3>
          <p class='item-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          I have updated my survey on correlation bounds against polynomials (actually the new text does not completely subsume the old one). It is available here and comments are (always) welcome. A new result in the survey is that symmetric functions have correlation at least about with polynomials of degree .
        
        </div>

        <div class='item-content item-summary'>
        
          
          <h1 id="block-73ee638c-e9fa-4cf1-8d6b-4aea57a90379"></h1>



<p>I have updated my survey on correlation bounds against polynomials (actually the new text does not completely subsume the old one). <a href="https://www.ccs.neu.edu/home/viola/papers/corr-survey.pdf"> It is available here</a> and comments are (always) welcome.  A new result in the survey is that symmetric functions have correlation at least about <img src="https://s0.wp.com/latex.php?latex=2%5E%7B-n%2Fd%5E2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7B-n%2Fd%5E2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7B-n%2Fd%5E2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{-n/d^2}" class="latex" /> with polynomials of degree <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />.</p>
<p class="authors">By Manu</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-16T14:13:53Z">Sunday, October 16 2022, 14:13</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/10/16/faculty-at-umass-amherst-apply-by-december-1-2022/'>Faculty at Umass Amherst (apply by December 1, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The Manning College of Information and Computer Sciences (CICS) at the University of Massachusetts Amherst invites applications for tenure-track faculty whose research focuses on Theoretical Computer Science, broadly construed, at the Assistant and Associate Professor levels. Exceptional candidates at other ranks may be considered. We encourage applications from underrepresented groups. Website: www.cics.umass.edu/jobs Email: hungle@cs.umass.edu
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The Manning College of Information and Computer Sciences (CICS) at the University of Massachusetts Amherst invites applications for tenure-track faculty whose research focuses on Theoretical Computer Science, broadly construed, at the Assistant and Associate Professor levels. Exceptional candidates at other ranks may be considered. We encourage applications from underrepresented groups.</p>
<p>Website: <a href="https://www.cics.umass.edu/jobs">https://www.cics.umass.edu/jobs</a><br />
Email: hungle@cs.umass.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-16T13:39:30Z">Sunday, October 16 2022, 13:39</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/140'>TR22-140 |  Commitments to Quantum States | 

	Sam Gunn, 

	Nathan Ju, 

	Fermi Ma, 

	Mark Zhandry</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          What does it mean to commit to a quantum state? In this work, we propose a simple answer: a commitment to quantum messages is binding if, after the commit phase, the committed state is hidden from the sender&#39;s view. We accompany this new definition with several instantiations. We build the first non-interactive succinct quantum state commitments, which can be seen as an analogue of collision-resistant hashing for quantum messages. We also show that hiding quantum state commitments (QSCs) are implied by any commitment scheme for classical messages. All of our constructions can be based on quantum-cryptographic assumptions that are implied by but are potentially weaker than one-way functions.

Commitments to quantum states open the door to many new cryptographic possibilities. Our flagship application of a succinct QSC is a quantum-communication version of Kilian&#39;s succinct arguments for any language that has quantum PCPs with constant error and polylogarithmic locality. Plugging in the PCP theorem, this yields succinct arguments for NP under significantly weaker assumptions than required classically; moreover, if the quantum PCP conjecture holds, this extends to QMA. At the heart of our security proof is a new rewinding technique for extracting quantum information.
        
        </div>

        <div class='item-content item-summary'>
        
          
          What does it mean to commit to a quantum state? In this work, we propose a simple answer: a commitment to quantum messages is binding if, after the commit phase, the committed state is hidden from the sender&#39;s view. We accompany this new definition with several instantiations. We build the first non-interactive succinct quantum state commitments, which can be seen as an analogue of collision-resistant hashing for quantum messages. We also show that hiding quantum state commitments (QSCs) are implied by any commitment scheme for classical messages. All of our constructions can be based on quantum-cryptographic assumptions that are implied by but are potentially weaker than one-way functions.

Commitments to quantum states open the door to many new cryptographic possibilities. Our flagship application of a succinct QSC is a quantum-communication version of Kilian&#39;s succinct arguments for any language that has quantum PCPs with constant error and polylogarithmic locality. Plugging in the PCP theorem, this yields succinct arguments for NP under significantly weaker assumptions than required classically; moreover, if the quantum PCP conjecture holds, this extends to QMA. At the heart of our security proof is a new rewinding technique for extracting quantum information.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-16T06:07:10Z">Sunday, October 16 2022, 06:07</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://windowsontheory.org/2022/10/16/swiss-tcs-winter-school-ccc-2023-call-for-papers/'>Swiss TCS winter school,  CCC 2023 call for papers</a></h3>
          <p class='item-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          [Guest post by David Steurer, both the speakers and the location seem amazing! &#8211;Boaz] The Swiss Winter School on Theoretical Computer Science (Jan 29  &#8211; Feb 3 2023, theory.epfl.ch/WinterSchool2023/) will be the second installment in a series of annual winter schools jointly organized by EPFL and ETH Zurich (the first installment happened in 2020).The goal of &#8230; Continue reading Swiss TCS winter school,  CCC 2023 call for&#160;papers
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><em>[Guest post by David Steurer, both the speakers and the location seem amazing! &#8211;Boaz]</em></p>



<p><br>The <strong>Swiss Winter School on Theoretical Computer Science </strong>(Jan 29  &#8211; Feb 3 2023, <a rel="noreferrer noopener" href="https://theory.epfl.ch/WinterSchool2023/" target="_blank">https://theory.epfl.ch/WinterSchool2023/</a>)  will be the second installment in a series of annual winter schools jointly organized by EPFL and ETH Zurich (the first installment happened in 2020).<br>The goal of the school is to educate outstanding international PhD students about exciting recent developments in  theoretical computer science.</p>



<p><br>The winter school will be held in Zinal, a mountain village in the Swiss Alps that has a long tradition of hosting academic workshops and that allows for nice excursions and stimulating discussions in a relaxed atmosphere.</p>



<p>This year’s installment features an exciting trinity of speakers:<br>Rasmus Kyng (ETH Zurich), Yin Tat Lee (University of Washington), and Ryan Williams (MIT).</p>



<p>For full consideration, applications must be submitted by&nbsp;November 1st 2022.<br>Notifications will be sent by&nbsp;November 7th.<br>The application form is available at&nbsp;<a href="https://theory.epfl.ch/WinterSchool2023/" target="_blank" rel="noreferrer noopener">https://theory.epfl.ch/WinterSchool2023/</a>.</p>



<p>The winter school is organized by Mika Goos (EPFL), Michael Kapralov (EPFL), Rasmus Kyng (ETH Zurich), David Steurer (ETH Zurich), Ola Svennson (EPFL).</p>



<p></p>



<p>Also Amit Chakrabarti tells me that the Call for Papers for the <strong>Computational Complexity Conference (CCC) 2023</strong> is now out on <a href="https://www.computationalcomplexity.org/Archive/2023/cfp.php" rel="nofollow">https://www.computationalcomplexity.org/Archive/2023/cfp.php</a> . Deadline is <strong>Friday, February 10, 2023, 23:59 AoE</strong>.</p>



<p></p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-16T04:15:51Z">Sunday, October 16 2022, 04:15</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Saturday, October 15
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/139'>TR22-139 |  On the VNP-hardness of Some Monomial Symmetric Polynomials | 

	Nutan Limaye, 

	Srikanth Srinivasan, 

	Radu Curticapean</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          A polynomial $P\in F[x_1,\ldots,x_n]$ is said to be symmetric if it is invariant under any permutation of its input variables. The study of symmetric polynomials is a classical topic in mathematics, specifically in algebraic combinatorics and representation theory. More recently, they have been studied in several works in computer science, especially in algebraic complexity theory.
		
		In this paper, we prove the computational hardness of one of the most basic kinds of symmetric polynomials: the $monomial$ $symmetric$ $polynomials$, which are obtained by summing all distinct permutations of a single monomial. This family of symmetric functions is a natural basis for the space of symmetric polynomials (over any field), and generalizes many well-studied families such as the elementary symmetric polynomials and the power-sum symmetric polynomials.
		
		We show that certain families of monomial symmetric polynomials are $VNP$-$complete$ with respect to oracle reductions. This stands in stark contrast to the case of elementary and power symmetric polynomials, both of which have constant-depth circuits of polynomial size.
        
        </div>

        <div class='item-content item-summary'>
        
          
          A polynomial $P\in F[x_1,\ldots,x_n]$ is said to be symmetric if it is invariant under any permutation of its input variables. The study of symmetric polynomials is a classical topic in mathematics, specifically in algebraic combinatorics and representation theory. More recently, they have been studied in several works in computer science, especially in algebraic complexity theory.
		
		In this paper, we prove the computational hardness of one of the most basic kinds of symmetric polynomials: the $monomial$ $symmetric$ $polynomials$, which are obtained by summing all distinct permutations of a single monomial. This family of symmetric functions is a natural basis for the space of symmetric polynomials (over any field), and generalizes many well-studied families such as the elementary symmetric polynomials and the power-sum symmetric polynomials.
		
		We show that certain families of monomial symmetric polynomials are $VNP$-$complete$ with respect to oracle reductions. This stands in stark contrast to the case of elementary and power symmetric polynomials, both of which have constant-depth circuits of polynomial size.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-15T22:02:30Z">Saturday, October 15 2022, 22:02</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://11011110.github.io/blog/2022/10/15/linkage.html'>Linkage</a></h3>
          <p class='item-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Ultralightweight pavilion made from woven bamboo strips, aided by modern computer modeling (\(\mathbb{M}\)). Not very good for keeping sun or rain off in the form shown, but I imagine one could stretch a membrane over it if that were the goal.
        
        </div>

        <div class='item-content item-summary'>
        
          
          <ul>
  <li>
    <p><a href="https://actu.epfl.ch/news/age-old-technique-enhanced-by-computer-modeling/">Ultralightweight pavilion made from woven bamboo strips, aided by modern computer modeling</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109097228519637153">\(\mathbb{M}\)</a>).</span> Not very good for keeping sun or rain off in the form shown, but I imagine one could stretch a membrane over it if that were the goal.</p>
  </li>
  <li>
    <p><a href="https://support.google.com/photos/thread/180787712/corrupted-photos">Corruption in old images stored in Google Photos</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109104810612333424">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=32970623">via</a>). Let this be a reminder that if you care about the permanence and stability of your data, keep a safe copy on media you own and control, not on someone else’s machine on the cloud somewhere.</p>
  </li>
  <li>
    <p>“<a href="https://www.aaup.org/news/university-idaho-should-rescind-guidance-speech-about-abortion">The University of Idaho administration has abandoned its duty to uphold the mission of the institution and signaled to all the world that the university is no longer committed to academic freedom</a>” <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109108400913458700">\(\mathbb{M}\)</a>),</span> according to The American Association of University Professors. The context is a memo sent out by the university’s lawyers requesting faculty to “remain neutral on the topic of abortion”; for more on that, see <em>Inside Higher Ed</em>’s <a href="https://www.insidehighered.com/news/2022/09/27/university-tells-professors-stay-neutral-abortion">story</a> and <a href="https://www.insidehighered.com/quicktakes/2022/09/30/aaup-u-idaho-should-rescind-guidance-abortion-speech">editorial</a>.</p>
  </li>
  <li>
    <p><a href="http://blog.computationalcomplexity.org/2022/10/is-it-okay-for-paper-or-book-to-say-for.html">Gasarch asks for advice on whether it’s acceptable for an academic publication to cite Wikipedia</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109113654779787003">\(\mathbb{M}\)</a>).</span> Comments concern stability of Wikipedia articles, but that’s easy: every article has “cite this page” in the toolbar with sample citations that permalink stable versions. The bigger issue is the purpose of the citation. As background reading: fine. As credit for a figure: necessary. For a technical result: you should probably follow the references to a more-primary source.</p>
  </li>
  <li>
    <p><a href="https://www.deepmind.com/blog/discovering-novel-algorithms-with-alphatensor">Computer search for faster matrix multiplication algorithms</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@j2kun/109116859743991084">\(\mathbb{M}\)</a>,</span> <a href="https://cp4space.hatsya.com/2022/10/06/matrix-multiplication-update/">see also</a>).</p>
  </li>
  <li>
    <p>In place of the prime numbers, consider <a href="http://oeis.org/A050376">the numbers \(p^{2^k}\) for \(p\) prime and integer \(i\ge 0\)</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109119821643711856">\(\mathbb{M}\)</a>).</span> Each positive integer has a unique factorization into a product of these without repetition. For example,</p>

\[21600 = 2\cdot 3\cdot 9\cdot 16\cdot 25.\]

    <p>They are called the <a href="https://en.wikipedia.org/wiki/Fermi%E2%80%93Dirac_prime">Fermi–Dirac primes</a> because of an analogy to fermions and bosons from physics: like bosons, primes can appear repeatedly in an energy level (prime factorization), but these numbers appear only once.</p>
  </li>
  <li>
    <p>I linked to <a href="https://arxiv.org/abs/2205.09102">Milman and Neeman’s preprint on the triple bubble conjecture</a> <a href="/blog/2022/06/30/linkage.html">last June</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109131239935449901">\(\mathbb{M}\)</a>),</span> but now <a href="https://www.quantamagazine.org/monumental-math-proof-solves-triple-bubble-problem-and-more-20221006/"><em>Quanta</em> has a popularized explainer of it</a>.</p>
  </li>
  <li>
    <p><a href="https://amathr.org/an-aperiodic-set-of-eleven-wang-tiles/">An aperiodic set of 11 Wang tiles</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109136741064182404">\(\mathbb{M}\)</a>).</span> Wang tiles are edge-colored squares that tile the plane as a grid, without rotation and with matching edges. B. Durand and A. Shen explain a result of E. Jeandel and M. Rao from a <a href="https://arxiv.org/abs/1506.06492">2015 preprint</a> and <a href="https://amathr.org/an-aperiodic-set-of-eleven-wang-tiles/">2021 journal publication</a> using a computer search to prove that sets of 11 Wang tiles with 4 colors (but no fewer of either) can force the tiling to be aperiodic.</p>

    <p>The first link is on the site of an organization led by people who have publicly opposed mandatory statements of support for diversity or inclusiveness, and the organization itself conspicuously lacks any statement of support for those values. This led to some discussion on Mathstodon over whether we should link to even purely-mathematical content by these people. <a href="https://mathstodon.xyz/@11011110/109144568072282691">My position is that it would be a mistake to shun them</a>. I think their position that mathematics can and should be above such concerns is naive and overly idealistic, but we cannot find solutions to societal problems such as institutionalized discrimination if we shut down free and open discussions of alternatives by banning anyone at the slightest misstep from the political orthodoxy of the minute. Also, doing so would strengthen their position by playing into their storyline of good mathematics getting pushed aside for political reasons. As I wrote in the linked comment, “Let’s not be the monsters they think we are.”</p>
  </li>
  <li>
    <p><a href="https://planetofthepaul.com/wikipedia-download-usb-flash/">How to make yourself a copy of Wikipedia on a flash drive, usable offline</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109142543607772779">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=33114107">via</a>).</p>
  </li>
  <li>
    <p><a href="https://gafferongames.com/post/shape_of_the_go_stone/">The shape of a Go stone</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109147037847419575">\(\mathbb{M}\)</a>):</span> A project from 2013 to create “a physically accurate computer simulation of a Go board and stones” starts by trying to understand the shape of the stones, settling on an intersection between two balls, modified by using a torus to bevel the sharp edge where they meet. Which sort of looks right, but <a href="https://forums.online-go.com/t/the-shape-of-the-stones/27557">a 2020 discussion suggests that a more accurate model needs to take into account how real Go stones are made</a>.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=a-767WnbaCQ">Percolation: a Mathematical Phase Transition</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109153531832896359">\(\mathbb{M}\)</a>).</span> One of many recent mathematics exposition videos from the “Summer of Math Exposition 2”; this one is mostly about the bond percolation on an infinite square grid, the study of the connectivity of random subgraphs of the grid. There’s <a href="https://www.metafilter.com/196698/Summer-of-Math-Exposition-2">a more complete listing of the other videos on Metafilter</a>.</p>
  </li>
  <li>
    <p><a href="https://uxdesign.cc/how-apple-makes-you-think-green-bubbles-gross-e03b52b12fed">Intentionally-bad and anti-accessible user interface design by Apple, in order to undercut the competition</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109156160184481951">\(\mathbb{M}\)</a>,</span> <a href="https://boingboing.net/2022/10/12/apple-intentionally-made-the-green-chat-bubbles-of-android-text-messages-look-gross.html">via</a>, <a href="https://news.ycombinator.com/item?id=33176668">via2</a>).</p>
  </li>
  <li>
    <p><a href="https://github.com/mathjax/MathJax-src/releases/tag/4.0.0-alpha.1">MathJax 4.0.0-alpha.1 now available</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109165272680486533">\(\mathbb{M}\)</a>,</span> <a href="https://groups.google.com/g/mathjax-users/c/WhMiWK9Ld7k?pli=1">via</a>, <a href="https://www.ams.org/news?news_id=7098">via2</a>). Because it’s still an alpha-test version, it’s probably not the right time to switch unless you really need the new features (more fonts, better line breaking, html within math expressions).</p>
  </li>
  <li>
    <p><a href="https://www.boristhebrave.com/2021/05/23/triangle-grids/">An appreciation of triangular grids</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@jsiehler/109166889958867986">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Interesting_number_paradox">The interesting number paradox</a> <span style="white-space:nowrap">(<a href="https://mathstodon.xyz/@11011110/109173873212315062">\(\mathbb{M}\)</a>)</span> is the argument that there cannot be a smallest uninteresting natural number, because that property would make it interesting. I had thought that it dated from <a href="https://www.jstor.org/stable/24942039">a 1958 “Mathematical Games” column by Martin Gardner in <em>Scientific American</em></a>, but now another Wikipedia editor has found an earlier reference, <a href="https://doi.org/10.2307/2305682">a 1945 letter to the American Mathematical Monthly by Edwin F. Bechenbach</a> (see bottom of last page of link).</p>
  </li>
</ul><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-15T17:24:00Z">Saturday, October 15 2022, 17:24</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://gilkalai.wordpress.com/2022/10/15/boaz-klartag-and-joseph-lehec-the-slice-conjecture-up-to-polylogarithmic-factor/'>Bo’az Klartag and  Joseph Lehec: The Slice Conjecture Up to Polylogarithmic Factor!</a></h3>
          <p class='item-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Bo&#8217;az Klartag (right) and Joseph Lehec (left) In December 2020, we reported on Yuansi Chen breakthrough result on Bourgain&#8217;s alicing problem and the Kannan Lovasz Simonovits conjecture. It is a pleasure to report on a further fantastic progress on these &#8230; Continue reading &#8594;
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><img data-attachment-id="23425" data-permalink="https://gilkalai.wordpress.com/2022/10/15/boaz-klartag-and-joseph-lehec-the-slice-conjecture-up-to-polylogarithmic-factor/boazjoseph/" data-orig-file="https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png" data-orig-size="860,380" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BoazJoseph" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=640" class="alignnone size-full wp-image-23425" src="https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=640" alt="BoazJoseph" srcset="https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=640 640w, https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=150 150w, https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=300 300w, https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png?w=768 768w, https://gilkalai.files.wordpress.com/2022/10/boazjoseph.png 860w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p style="text-align:center;"><span style="color:#ff0000;"><strong>Bo&#8217;az Klartag (right) and Joseph Lehec (left)</strong></span></p>
<p>In December 2020, <a href="https://gilkalai.wordpress.com/2020/12/21/to-cheer-you-up-in-difficult-times-15-yuansi-chen-achieved-a-major-breakthrough-on-bourgains-slicing-problem-and-the-kannan-lovasz-and-simonovits-conjecture/">we reported on Yuansi Chen breakthrough result</a> on Bourgain&#8217;s alicing problem and the Kannan Lovasz Simonovits conjecture. It is a pleasure to report on a further fantastic progress on these problems.</p>
<p><strong>Bourgain&#8217;s slicing problem (1984):</strong>  Is there <em>c &gt; 0</em> such that for any dimension n and any centrally symmetric convex body <em>K ⊆</em> <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^n" class="latex" /> of volume one, there exists a hyperplane <em>H</em> such that the<em> (n − 1)-</em>dimensional volume of <em>K ∩ H</em> is at least <em>c</em>?</p>
<p>Some time ago we reported on Yuansi Chen&#8217;s startling result that c can be taken as <img src="https://s0.wp.com/latex.php?latex=n%5E%7B-o%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B-o%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B-o%281%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{-o(1)}" class="latex" />. More precisely, Chen proved:</p>
<p><strong>Theorem (Chen, 2021):</strong> For any dimension n and any centrally symmetric convex body <em>K ⊆</em> <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^n" class="latex" /> of volume one, there exists a hyperplane <em>H</em> such that the<em> (n − 1)-</em>dimensional volume of <em>K ∩ H</em> is at least <img src="https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;frac {1}{L_n}" class="latex" /> where</p>
<p><img src="https://s0.wp.com/latex.php?latex=L_n%3DC+%5Cexp+%28+%5Csqrt+%7B%5Clog+n%7D+%5Csqrt+%7B3%5Clog+%5Clog+n%7D+%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L_n%3DC+%5Cexp+%28+%5Csqrt+%7B%5Clog+n%7D+%5Csqrt+%7B3%5Clog+%5Clog+n%7D+%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L_n%3DC+%5Cexp+%28+%5Csqrt+%7B%5Clog+n%7D+%5Csqrt+%7B3%5Clog+%5Clog+n%7D+%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L_n=C &#92;exp ( &#92;sqrt {&#92;log n} &#92;sqrt {3&#92;log &#92;log n} )." class="latex" /></p>
<p><a href="https://arxiv.org/abs/2203.15551">A major improvement was recently achieved by  Bo&#8217;az Klartag and Joseph Lehec</a></p>
<p><strong>Theorem (Klartag and Lehec, 2022):</strong> For any dimension n and any centrally symmetric convex body <em>K ⊆</em> <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^n" class="latex" /> of volume one, there exists a hyperplane <em>H</em> such that the<em> (n − 1)-</em>dimensional volume of <em>K ∩ H</em> is at least <img src="https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac+%7B1%7D%7BL_n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;frac {1}{L_n}" class="latex" /> where</p>
<p><img src="https://s0.wp.com/latex.php?latex=L_n+%3D+C+%28%5Clog+n%29%5E4.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L_n+%3D+C+%28%5Clog+n%29%5E4.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L_n+%3D+C+%28%5Clog+n%29%5E4.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L_n = C (&#92;log n)^4." class="latex" /></p>
<p>Klartag and Lehec&#8217;s argument (as Chen&#8217;s earlier argument) relies on Ronen Eldan’s stochastic localization, with a new ingredients being the functional-analytic approach from a paper by Klartag and Eli Putterman</p>
<p>This is fantastic progress. Congratulations Bo&#8217;az and Joseph!</p>
<p><strong>Update:</strong> I was happy to learn that Arun Jambulapati, Yin Tat Lee, and Santosh S. Vempala further improved <a href="https://arxiv.org/abs/2208.11644">in this paper</a> the exponent from 4 to 2.2226.</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-15T15:50:56Z">Saturday, October 15 2022, 15:50</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Friday, October 14
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://gilkalai.wordpress.com/2022/10/14/alefs-corner-it-wont-work-sorry/'>Alef’s Corner: “It won’t work, sorry”</a></h3>
          <p class='item-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Alef thanks Nicolas Curien for the triangulation. Click here for other posts with Alef&#8217;s art.
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p><img data-attachment-id="23387" data-permalink="https://gilkalai.wordpress.com/2022/10/14/alefs-corner-it-wont-work-sorry/giliwnw/" data-orig-file="https://gilkalai.files.wordpress.com/2022/10/giliwnw.png" data-orig-size="2100,2100" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="gilIWNW" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=300" data-large-file="https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=640" class="alignnone size-full wp-image-23387" src="https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=640" alt="gilIWNW" srcset="https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=640 640w, https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=1280 1280w, https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=150 150w, https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=300 300w, https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=768 768w, https://gilkalai.files.wordpress.com/2022/10/giliwnw.png?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p>Alef thanks Nicolas Curien for the triangulation. <a href="https://gilkalai.wordpress.com/tag/alefs-corner/">Click here for other posts with Alef&#8217;s art.</a></p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T11:04:22Z">Friday, October 14 2022, 11:04</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06845'>The Fine-Grained Complexity of Graph Homomorphism Parameterized by Clique-Width</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Robert Ganian, Thekla Hamm, Viktoriia Korchemna, Karolina Okrasa, Kirill Simonov</p><p>The generic homomorphism problem, which asks whether an input graph $G$
admits a homomorphism into a fixed target graph $H$, has been widely studied in
the literature. In this article, we provide a fine-grained complexity
classification of the running time of the homomorphism problem with respect to
the clique-width of $G$ (denoted $\operatorname{cw}$) for virtually all choices
of $H$ under the Strong Exponential Time Hypothesis. In particular, we identify
a property of $H$ called the signature number $s(H)$ and show that for each
$H$, the homomorphism problem can be solved in time
$\mathcal{O}^*(s(H)^{\operatorname{cw}})$. Crucially, we then show that this
algorithm can be used to obtain essentially tight upper bounds. Specifically,
we provide a reduction that yields matching lower bounds for each $H$ that is
either a projective core or a graph admitting a factorization with additional
properties -- allowing us to cover all possible target graphs under
long-standing conjectures.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ganian_R/0/1/0/all/0/1">Robert Ganian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamm_T/0/1/0/all/0/1">Thekla Hamm</a>, <a href="http://arxiv.org/find/cs/1/au:+Korchemna_V/0/1/0/all/0/1">Viktoriia Korchemna</a>, <a href="http://arxiv.org/find/cs/1/au:+Okrasa_K/0/1/0/all/0/1">Karolina Okrasa</a>, <a href="http://arxiv.org/find/cs/1/au:+Simonov_K/0/1/0/all/0/1">Kirill Simonov</a></p><p>The generic homomorphism problem, which asks whether an input graph $G$
admits a homomorphism into a fixed target graph $H$, has been widely studied in
the literature. In this article, we provide a fine-grained complexity
classification of the running time of the homomorphism problem with respect to
the clique-width of $G$ (denoted $\operatorname{cw}$) for virtually all choices
of $H$ under the Strong Exponential Time Hypothesis. In particular, we identify
a property of $H$ called the signature number $s(H)$ and show that for each
$H$, the homomorphism problem can be solved in time
$\mathcal{O}^*(s(H)^{\operatorname{cw}})$. Crucially, we then show that this
algorithm can be used to obtain essentially tight upper bounds. Specifically,
we provide a reduction that yields matching lower bounds for each $H$ that is
either a projective core or a graph admitting a factorization with additional
properties -- allowing us to cover all possible target graphs under
long-standing conjectures.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07030'>Hard to Detect Factors of Univariate Integer Polynomials</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Alberto Dennunzio, Enrico Formenti, Luciano Margara</p><p>We investigate the computational complexity of deciding whether a given
univariate integer polynomial p(x) has a factor q(x) satisfying specific
additional constraints. When the only constraint imposed on q(x) is to have a
degree smaller than the degree of p(x) and greater than zero, the problem is
equivalent to testing the irreducibility of p(x) and then it is solvable in
polynomial time. We prove that deciding whether a given monic univariate
integer polynomial has factors satisfying additional properties may lead to
NP-complete problems in the strong sense. In particular, given any constant
value k in Z, we prove that it is NP-complete in the strong sense to detect the
existence of a factor that returns a prescribed value when evaluated at x=k or
to detect the existence of a pair of factors - whose product is equal to the
original polynomial - that return the same value when evaluated at x=k.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dennunzio_A/0/1/0/all/0/1">Alberto Dennunzio</a>, <a href="http://arxiv.org/find/cs/1/au:+Formenti_E/0/1/0/all/0/1">Enrico Formenti</a>, <a href="http://arxiv.org/find/cs/1/au:+Margara_L/0/1/0/all/0/1">Luciano Margara</a></p><p>We investigate the computational complexity of deciding whether a given
univariate integer polynomial p(x) has a factor q(x) satisfying specific
additional constraints. When the only constraint imposed on q(x) is to have a
degree smaller than the degree of p(x) and greater than zero, the problem is
equivalent to testing the irreducibility of p(x) and then it is solvable in
polynomial time. We prove that deciding whether a given monic univariate
integer polynomial has factors satisfying additional properties may lead to
NP-complete problems in the strong sense. In particular, given any constant
value k in Z, we prove that it is NP-complete in the strong sense to detect the
existence of a factor that returns a prescribed value when evaluated at x=k or
to detect the existence of a pair of factors - whose product is equal to the
original polynomial - that return the same value when evaluated at x=k.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07085'>Towards Uniform Certification in QBF</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Leroy Chew, Friedrich Slivovsky</p><p>We pioneer a new technique that allows us to prove a multitude of previously
open simulations in QBF proof complexity. In particular, we show that extended
QBF Frege p-simulates clausal proof systems such as IR-Calculus, IRM-Calculus,
Long-Distance Q-Resolution, and Merge Resolution. These results are obtained by
taking a technique of Beyersdorff et al. (JACM 2020) that turns strategy
extraction into simulation and combining it with new local strategy extraction
arguments.
</p>
<p>This approach leads to simulations that are carried out mainly in
propositional logic, with minimal use of the QBF rules. Our proofs therefore
provide a new, largely propositional interpretation of the simulated systems.
We argue that these results strengthen the case for uniform certification in
QBF solving, since many QBF proof systems now fall into place underneath
extended QBF Frege.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chew_L/0/1/0/all/0/1">Leroy Chew</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivovsky_F/0/1/0/all/0/1">Friedrich Slivovsky</a></p><p>We pioneer a new technique that allows us to prove a multitude of previously
open simulations in QBF proof complexity. In particular, we show that extended
QBF Frege p-simulates clausal proof systems such as IR-Calculus, IRM-Calculus,
Long-Distance Q-Resolution, and Merge Resolution. These results are obtained by
taking a technique of Beyersdorff et al. (JACM 2020) that turns strategy
extraction into simulation and combining it with new local strategy extraction
arguments.
</p>
<p>This approach leads to simulations that are carried out mainly in
propositional logic, with minimal use of the QBF rules. Our proofs therefore
provide a new, largely propositional interpretation of the simulated systems.
We argue that these results strengthen the case for uniform certification in
QBF solving, since many QBF proof systems now fall into place underneath
extended QBF Frege.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06739'>Computing the Best Case Energy Complexity of Satisfying Assignments in Monotone Circuits</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Janio Carlos Nascimento Silva, U&#xe9;verton S. Souza</p><p>Measures of circuit complexity are usually analyzed to ensure the computation
of Boolean functions with economy and efficiency. One of these measures is
energy complexity, which is related to the number of gates that output true in
a circuit for an assignment. The idea behind energy complexity comes from the
counting of `firing' neurons in a natural neural network. The initial model is
based on threshold circuits, but recent works also have analyzed the energy
complexity of traditional Boolean circuits. In this work, we discuss the time
complexity needed to compute the best-case energy complexity among satisfying
assignments of a monotone Boolean circuit, and we call such a problem as
MinEC$^+_M$. In the MinEC$^+_M$ problem, we are given a monotone Boolean
circuit $C$, a positive integer $k$ and asked to determine whether there is a
satisfying assignment $X$ for $C$ such that $EC(C,X) \leq k$, where $EC(C,X)$
is the number of gates that output true in $C$ according to the assignment $X$.
We prove that MinEC$^+_M$ is NP-complete even when the input monotone circuit
is planar. Besides, we show that the problem is W[1]-hard but in XP when
parameterized by the size of the solution. In contrast, we show that when the
size of the solution and the genus of the input circuit are aggregated
parameters, the MinEC$^+_M$ problem becomes fixed-parameter tractable.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1">Janio Carlos Nascimento Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Souza_U/0/1/0/all/0/1">U&#xe9;verton S. Souza</a></p><p>Measures of circuit complexity are usually analyzed to ensure the computation
of Boolean functions with economy and efficiency. One of these measures is
energy complexity, which is related to the number of gates that output true in
a circuit for an assignment. The idea behind energy complexity comes from the
counting of `firing' neurons in a natural neural network. The initial model is
based on threshold circuits, but recent works also have analyzed the energy
complexity of traditional Boolean circuits. In this work, we discuss the time
complexity needed to compute the best-case energy complexity among satisfying
assignments of a monotone Boolean circuit, and we call such a problem as
MinEC$^+_M$. In the MinEC$^+_M$ problem, we are given a monotone Boolean
circuit $C$, a positive integer $k$ and asked to determine whether there is a
satisfying assignment $X$ for $C$ such that $EC(C,X) \leq k$, where $EC(C,X)$
is the number of gates that output true in $C$ according to the assignment $X$.
We prove that MinEC$^+_M$ is NP-complete even when the input monotone circuit
is planar. Besides, we show that the problem is W[1]-hard but in XP when
parameterized by the size of the solution. In contrast, we show that when the
size of the solution and the genus of the input circuit are aggregated
parameters, the MinEC$^+_M$ problem becomes fixed-parameter tractable.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07146'>Efficient Algorithms for Obnoxious Facility Location on a Line Segment or Circle</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Bowei Zhang</p><p>We study different restricted variations of the obnoxious facility location
problem on a plane. The first is the constrained obnoxious facility location on
a line segment (COFL-Line) problem. We provide an efficient algorithm for this
problem that executes in $O(n ^ 2 \log k + n \log k \log (n^2 + k))$ time. Our
result improves on the best known result of $O((nk)^2 \log(nk) + (n + k) \log
(nk))$ time obtained by Singireddy and Basappa\cite{singireddy2022dispersing}.
We also study the same problem where the facilities must be placed on a given
circle (the constrained obnoxious facility location on a circle (COFL-Circ)
problem). We provide an efficient algorithm for this problem that executes in
$O(n ^ 2 \log k + n \log k \log (n^2 + k))$ time. Our result improves on the
best known result of $O((nk)^2 \log(nk) + (n + k) \log (nk))$ time obtained by
Singireddy and Basappa\cite{singireddy2022dispersing}. The third problem we
study is the min-sum obnoxious facility location (MOFL) problem.We provide an
efficient algorithm that executes in $O(nk\cdot \alpha(nk) \log^3 {nk})$ time,
where $\alpha(.)$ is the inverse Ackermann function. The best known previous
result is an $O(n^3k)$ time obtained by Singireddy and
Basappa\cite{singireddy2022dispersing}.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bowei Zhang</a></p><p>We study different restricted variations of the obnoxious facility location
problem on a plane. The first is the constrained obnoxious facility location on
a line segment (COFL-Line) problem. We provide an efficient algorithm for this
problem that executes in $O(n ^ 2 \log k + n \log k \log (n^2 + k))$ time. Our
result improves on the best known result of $O((nk)^2 \log(nk) + (n + k) \log
(nk))$ time obtained by Singireddy and Basappa\cite{singireddy2022dispersing}.
We also study the same problem where the facilities must be placed on a given
circle (the constrained obnoxious facility location on a circle (COFL-Circ)
problem). We provide an efficient algorithm for this problem that executes in
$O(n ^ 2 \log k + n \log k \log (n^2 + k))$ time. Our result improves on the
best known result of $O((nk)^2 \log(nk) + (n + k) \log (nk))$ time obtained by
Singireddy and Basappa\cite{singireddy2022dispersing}. The third problem we
study is the min-sum obnoxious facility location (MOFL) problem.We provide an
efficient algorithm that executes in $O(nk\cdot \alpha(nk) \log^3 {nk})$ time,
where $\alpha(.)$ is the inverse Ackermann function. The best known previous
result is an $O(n^3k)$ time obtained by Singireddy and
Basappa\cite{singireddy2022dispersing}.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06559'>Exact and approximation algorithms for sensor placement against DDoS attacks</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Konstanty Junosza-Szaniawski, Dariusz Nogalski, Pawe&#x142; Rz&#x105;&#x17c;ewski</p><p>In a DDoS attack (Distributed Denial of Service), an attacker gains control
of many network users through a virus. Then the controlled users send many
requests to a victim, leading to its resources being depleted. DDoS attacks are
hard to defend because of their distributed nature, large scale and various
attack techniques. One possible mode of defense is to place sensors in a
network that can detect and stop an unwanted request. However, such sensors are
expensive so there is a natural question as to the minimum number of sensors
and the optimal placement required to get the necessary level of safety.
Presented below are two mixed integer models for optimal sensor placement
against DDoS attacks. Both models lead to a trade-off between the number of
deployed sensors and the volume of uncontrolled flow. Since the above placement
problems are NP-hard, two efficient heuristics are designed, implemented and
compared experimentally with exact mixed integer linear programming solvers.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Junosza_Szaniawski_K/0/1/0/all/0/1">Konstanty Junosza-Szaniawski</a>, <a href="http://arxiv.org/find/cs/1/au:+Nogalski_D/0/1/0/all/0/1">Dariusz Nogalski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rzazewski_P/0/1/0/all/0/1">Pawe&#x142; Rz&#x105;&#x17c;ewski</a></p><p>In a DDoS attack (Distributed Denial of Service), an attacker gains control
of many network users through a virus. Then the controlled users send many
requests to a victim, leading to its resources being depleted. DDoS attacks are
hard to defend because of their distributed nature, large scale and various
attack techniques. One possible mode of defense is to place sensors in a
network that can detect and stop an unwanted request. However, such sensors are
expensive so there is a natural question as to the minimum number of sensors
and the optimal placement required to get the necessary level of safety.
Presented below are two mixed integer models for optimal sensor placement
against DDoS attacks. Both models lead to a trade-off between the number of
deployed sensors and the volume of uncontrolled flow. Since the above placement
problems are NP-hard, two efficient heuristics are designed, implemented and
compared experimentally with exact mixed integer linear programming solvers.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06594'>Sample Constrained Treatment Effect Estimation</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Raghavendra Addanki, David Arbour, Tung Mai, Cameron Musco, Anup Rao</p><p>Treatment effect estimation is a fundamental problem in causal inference. We
focus on designing efficient randomized controlled trials, to accurately
estimate the effect of some treatment on a population of $n$ individuals. In
particular, we study sample-constrained treatment effect estimation, where we
must select a subset of $s \ll n$ individuals from the population to experiment
on. This subset must be further partitioned into treatment and control groups.
Algorithms for partitioning the entire population into treatment and control
groups, or for choosing a single representative subset, have been well-studied.
The key challenge in our setting is jointly choosing a representative subset
and a partition for that set.
</p>
<p>We focus on both individual and average treatment effect estimation, under a
linear effects model. We give provably efficient experimental designs and
corresponding estimators, by identifying connections to discrepancy
minimization and leverage-score-based sampling used in randomized numerical
linear algebra. Our theoretical results obtain a smooth transition to known
guarantees when $s$ equals the population size. We also empirically demonstrate
the performance of our algorithms.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Addanki_R/0/1/0/all/0/1">Raghavendra Addanki</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbour_D/0/1/0/all/0/1">David Arbour</a>, <a href="http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1">Tung Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Anup Rao</a></p><p>Treatment effect estimation is a fundamental problem in causal inference. We
focus on designing efficient randomized controlled trials, to accurately
estimate the effect of some treatment on a population of $n$ individuals. In
particular, we study sample-constrained treatment effect estimation, where we
must select a subset of $s \ll n$ individuals from the population to experiment
on. This subset must be further partitioned into treatment and control groups.
Algorithms for partitioning the entire population into treatment and control
groups, or for choosing a single representative subset, have been well-studied.
The key challenge in our setting is jointly choosing a representative subset
and a partition for that set.
</p>
<p>We focus on both individual and average treatment effect estimation, under a
linear effects model. We give provably efficient experimental designs and
corresponding estimators, by identifying connections to discrepancy
minimization and leverage-score-based sampling used in randomized numerical
linear algebra. Our theoretical results obtain a smooth transition to known
guarantees when $s$ equals the population size. We also empirically demonstrate
the performance of our algorithms.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06703'>On the Minimum Cycle Cover problem on graphs with bounded co-degeneracy</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Gabriel L. Duarte, U&#xe9;verton S. Souza</p><p>In 2021, Duarte, Oliveira, and Souza [MFCS 2021] showed some problems that
are FPT when parameterized by the treewidth of the complement graph (called
co-treewidth). Since the degeneracy of a graph is at most its treewidth, they
also introduced the study of co-degeneracy (the degeneracy of the complement
graph) as a parameter. In 1976, Bondy and Chv\'{a}tal [DM 1976] introduced the
notion of closure of a graph: let $\ell$ be an integer; the $(n+\ell)$-closure,
$\operatorname{cl}_{n+\ell}(G)$, of a graph $G$ with $n$ vertices is obtained
from $G$ by recursively adding an edge between pairs of nonadjacent vertices
whose degree sum is at least $n+\ell$ until no such pair remains. A graph
property $\Upsilon$ defined on all graphs of order $n$ is said to be
$(n+\ell)$-stable if for any graph $G$ of order $n$ that does not satisfy
$\Upsilon$, the fact that $uv$ is not an edge of $G$ and that $G+uv$ satisfies
$\Upsilon$ implies $d(u)+d(v)&lt; n+\ell$. Duarte et al. [MFCS 2021] developed an
algorithmic framework for co-degeneracy parameterization based on the notion of
closures for solving problems that are $(n+\ell)$-stable for some $\ell$
bounded by a function of the co-degeneracy. In this paper, we first determine
the stability of the property of having a bounded cycle cover. After that,
combining the framework of Duarte et al. [MFCS 2021] with some results of
Jansen, Kozma, and Nederlof [WG 2019], we obtain a $2^{\mathcal{O}(k)}\cdot
n^{\mathcal{O}(1)}$-time algorithm for Minimum Cycle Cover on graphs with
co-degeneracy at most $k$, which generalizes Duarte et al. [MFCS 2021] and
Jansen et al. [WG 2019] results concerning the Hamiltonian Cycle problem.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Duarte_G/0/1/0/all/0/1">Gabriel L. Duarte</a>, <a href="http://arxiv.org/find/cs/1/au:+Souza_U/0/1/0/all/0/1">U&#xe9;verton S. Souza</a></p><p>In 2021, Duarte, Oliveira, and Souza [MFCS 2021] showed some problems that
are FPT when parameterized by the treewidth of the complement graph (called
co-treewidth). Since the degeneracy of a graph is at most its treewidth, they
also introduced the study of co-degeneracy (the degeneracy of the complement
graph) as a parameter. In 1976, Bondy and Chv\'{a}tal [DM 1976] introduced the
notion of closure of a graph: let $\ell$ be an integer; the $(n+\ell)$-closure,
$\operatorname{cl}_{n+\ell}(G)$, of a graph $G$ with $n$ vertices is obtained
from $G$ by recursively adding an edge between pairs of nonadjacent vertices
whose degree sum is at least $n+\ell$ until no such pair remains. A graph
property $\Upsilon$ defined on all graphs of order $n$ is said to be
$(n+\ell)$-stable if for any graph $G$ of order $n$ that does not satisfy
$\Upsilon$, the fact that $uv$ is not an edge of $G$ and that $G+uv$ satisfies
$\Upsilon$ implies $d(u)+d(v)&lt; n+\ell$. Duarte et al. [MFCS 2021] developed an
algorithmic framework for co-degeneracy parameterization based on the notion of
closures for solving problems that are $(n+\ell)$-stable for some $\ell$
bounded by a function of the co-degeneracy. In this paper, we first determine
the stability of the property of having a bounded cycle cover. After that,
combining the framework of Duarte et al. [MFCS 2021] with some results of
Jansen, Kozma, and Nederlof [WG 2019], we obtain a $2^{\mathcal{O}(k)}\cdot
n^{\mathcal{O}(1)}$-time algorithm for Minimum Cycle Cover on graphs with
co-degeneracy at most $k$, which generalizes Duarte et al. [MFCS 2021] and
Jansen et al. [WG 2019] results concerning the Hamiltonian Cycle problem.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06714'>Perfect matching cuts partitioning a graph into complementary subgraphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Diane Castonguay, Erika M. M. Coelho, Hebert Coelho, Julliano R. Nascimento, U&#xe9;verton S. Souza</p><p>In Partition Into Complementary Subgraphs (Comp-Sub) we are given a graph
$G=(V,E)$, and an edge set property $\Pi$, and asked whether $G$ can be
decomposed into two graphs, $H$ and its complement $\overline{H}$, for some
graph $H$, in such a way that the edge cut $[V(H),V(\overline{H})]$ satisfies
the property $\Pi$. Motivated by previous work, we consider Comp-Sub($\Pi$)
when the property $\Pi=\mathcal{PM}$ specifies that the edge cut of the
decomposition is a perfect matching. We prove that Comp-Sub($\mathcal{PM}$) is
GI-hard when the graph $G$ is $\{C_{k\geq 7}, \overline{C}_{k\geq 7} \}$-free.
On the other hand, we show that Comp-Sub($\mathcal{PM}$) is polynomial-time
solvable on $hole$-free graphs and on $P_5$-free graphs. Furthermore, we
present characterizations of Comp-Sub($\mathcal{PM}$) on chordal,
distance-hereditary, and extended $P_4$-laden graphs.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Castonguay_D/0/1/0/all/0/1">Diane Castonguay</a>, <a href="http://arxiv.org/find/cs/1/au:+Coelho_E/0/1/0/all/0/1">Erika M. M. Coelho</a>, <a href="http://arxiv.org/find/cs/1/au:+Coelho_H/0/1/0/all/0/1">Hebert Coelho</a>, <a href="http://arxiv.org/find/cs/1/au:+Nascimento_J/0/1/0/all/0/1">Julliano R. Nascimento</a>, <a href="http://arxiv.org/find/cs/1/au:+Souza_U/0/1/0/all/0/1">U&#xe9;verton S. Souza</a></p><p>In Partition Into Complementary Subgraphs (Comp-Sub) we are given a graph
$G=(V,E)$, and an edge set property $\Pi$, and asked whether $G$ can be
decomposed into two graphs, $H$ and its complement $\overline{H}$, for some
graph $H$, in such a way that the edge cut $[V(H),V(\overline{H})]$ satisfies
the property $\Pi$. Motivated by previous work, we consider Comp-Sub($\Pi$)
when the property $\Pi=\mathcal{PM}$ specifies that the edge cut of the
decomposition is a perfect matching. We prove that Comp-Sub($\mathcal{PM}$) is
GI-hard when the graph $G$ is $\{C_{k\geq 7}, \overline{C}_{k\geq 7} \}$-free.
On the other hand, we show that Comp-Sub($\mathcal{PM}$) is polynomial-time
solvable on $hole$-free graphs and on $P_5$-free graphs. Furthermore, we
present characterizations of Comp-Sub($\mathcal{PM}$) on chordal,
distance-hereditary, and extended $P_4$-laden graphs.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06728'>On the Efficient Implementation of High Accuracy Optimality of Profile Maximum Likelihood</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Moses Charikar, Zhihao Jiang, Kirankumar Shiragur, Aaron Sidford</p><p>We provide an efficient unified plug-in approach for estimating symmetric
properties of distributions given $n$ independent samples. Our estimator is
based on profile-maximum-likelihood (PML) and is sample optimal for estimating
various symmetric properties when the estimation error $\epsilon \gg n^{-1/3}$.
This result improves upon the previous best accuracy threshold of $\epsilon \gg
n^{-1/4}$ achievable by polynomial time computable PML-based universal
estimators [ACSS21, ACSS20]. Our estimator reaches a theoretical limit for
universal symmetric property estimation as [Han21] shows that a broad class of
universal estimators (containing many well known approaches including ours)
cannot be sample optimal for every $1$-Lipschitz property when $\epsilon \ll
n^{-1/3}$.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Charikar_M/0/1/0/all/0/1">Moses Charikar</a>, <a href="http://arxiv.org/find/stat/1/au:+Jiang_Z/0/1/0/all/0/1">Zhihao Jiang</a>, <a href="http://arxiv.org/find/stat/1/au:+Shiragur_K/0/1/0/all/0/1">Kirankumar Shiragur</a>, <a href="http://arxiv.org/find/stat/1/au:+Sidford_A/0/1/0/all/0/1">Aaron Sidford</a></p><p>We provide an efficient unified plug-in approach for estimating symmetric
properties of distributions given $n$ independent samples. Our estimator is
based on profile-maximum-likelihood (PML) and is sample optimal for estimating
various symmetric properties when the estimation error $\epsilon \gg n^{-1/3}$.
This result improves upon the previous best accuracy threshold of $\epsilon \gg
n^{-1/4}$ achievable by polynomial time computable PML-based universal
estimators [ACSS21, ACSS20]. Our estimator reaches a theoretical limit for
universal symmetric property estimation as [Han21] shows that a broad class of
universal estimators (containing many well known approaches including ours)
cannot be sample optimal for every $1$-Lipschitz property when $\epsilon \ll
n^{-1/3}$.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06846'>An $\alpha$-regret analysis of Adversarial Bilateral Trade</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Yossi Azar, Amos Fiat, Federico Fusco</p><p>We study sequential bilateral trade where sellers and buyers valuations are
completely arbitrary (i.e., determined by an adversary). Sellers and buyers are
strategic agents with private valuations for the good and the goal is to design
a mechanism that maximizes efficiency (or gain from trade) while being
incentive compatible, individually rational and budget balanced. In this paper
we consider gain from trade which is harder to approximate than social welfare.
</p>
<p>We consider a variety of feedback scenarios and distinguish the cases where
the mechanism posts one price and when it can post different prices for buyer
and seller. We show several surprising results about the separation between the
different scenarios. In particular we show that (a) it is impossible to achieve
sublinear $\alpha$-regret for any $\alpha&lt;2$, (b) but with full feedback
sublinear $2$-regret is achievable (c) with a single price and partial feedback
one cannot get sublinear $\alpha$ regret for any constant $\alpha$ (d)
nevertheless, posting two prices even with one-bit feedback achieves sublinear
$2$-regret, and (e) there is a provable separation in the $2$-regret bounds
between full and partial feedback.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Azar_Y/0/1/0/all/0/1">Yossi Azar</a>, <a href="http://arxiv.org/find/cs/1/au:+Fiat_A/0/1/0/all/0/1">Amos Fiat</a>, <a href="http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1">Federico Fusco</a></p><p>We study sequential bilateral trade where sellers and buyers valuations are
completely arbitrary (i.e., determined by an adversary). Sellers and buyers are
strategic agents with private valuations for the good and the goal is to design
a mechanism that maximizes efficiency (or gain from trade) while being
incentive compatible, individually rational and budget balanced. In this paper
we consider gain from trade which is harder to approximate than social welfare.
</p>
<p>We consider a variety of feedback scenarios and distinguish the cases where
the mechanism posts one price and when it can post different prices for buyer
and seller. We show several surprising results about the separation between the
different scenarios. In particular we show that (a) it is impossible to achieve
sublinear $\alpha$-regret for any $\alpha&lt;2$, (b) but with full feedback
sublinear $2$-regret is achievable (c) with a single price and partial feedback
one cannot get sublinear $\alpha$ regret for any constant $\alpha$ (d)
nevertheless, posting two prices even with one-bit feedback achieves sublinear
$2$-regret, and (e) there is a provable separation in the $2$-regret bounds
between full and partial feedback.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06882'>Beeping Shortest Paths via Hypergraph Bipartite Decomposition</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Fabien Dufoulon, Yuval Emek, Ran Gelles</p><p>Constructing a shortest path between two network nodes is a fundamental task
in distributed computing. This work develops schemes for the construction of
shortest paths in randomized beeping networks between a predetermined source
node and an arbitrary set of destination nodes. Our first scheme constructs a
(single) shortest path to an arbitrary destination in $O (D \log\log n + \log^3
n)$ rounds with high probability. Our second scheme constructs multiple
shortest paths, one per each destination, in $O (D \log^2 n + \log^3 n)$ rounds
with high probability.
</p>
<p>The key technique behind the aforementioned schemes is a novel decomposition
of hypergraphs into bipartite hypergraphs. Namely, we show how to partition the
hyperedge set of a hypergraph $H = (V_H, E_H)$ into $k = \Theta (\log^2 n)$
disjoint subsets $F_1 \cup \cdots \cup F_k = E_H$ such that the
(sub-)hypergraph $(V_H, F_i)$ is bipartite in the sense that there exists a
vertex subset $U \subseteq V$ such that $|U \cap e| = 1$ for every $e \in F_i$.
This decomposition turns out to be instrumental in speeding up shortest path
constructions under the beeping model.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dufoulon_F/0/1/0/all/0/1">Fabien Dufoulon</a>, <a href="http://arxiv.org/find/cs/1/au:+Emek_Y/0/1/0/all/0/1">Yuval Emek</a>, <a href="http://arxiv.org/find/cs/1/au:+Gelles_R/0/1/0/all/0/1">Ran Gelles</a></p><p>Constructing a shortest path between two network nodes is a fundamental task
in distributed computing. This work develops schemes for the construction of
shortest paths in randomized beeping networks between a predetermined source
node and an arbitrary set of destination nodes. Our first scheme constructs a
(single) shortest path to an arbitrary destination in $O (D \log\log n + \log^3
n)$ rounds with high probability. Our second scheme constructs multiple
shortest paths, one per each destination, in $O (D \log^2 n + \log^3 n)$ rounds
with high probability.
</p>
<p>The key technique behind the aforementioned schemes is a novel decomposition
of hypergraphs into bipartite hypergraphs. Namely, we show how to partition the
hyperedge set of a hypergraph $H = (V_H, E_H)$ into $k = \Theta (\log^2 n)$
disjoint subsets $F_1 \cup \cdots \cup F_k = E_H$ such that the
(sub-)hypergraph $(V_H, F_i)$ is bipartite in the sense that there exists a
vertex subset $U \subseteq V$ such that $|U \cap e| = 1$ for every $e \in F_i$.
This decomposition turns out to be instrumental in speeding up shortest path
constructions under the beeping model.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06926'>Delta-Closure Structure for Studying Data Distribution</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Aleksey Buzmakov, Tatiana Makhalova, Sergei O. Kuznetsov, Amedeo Napoli</p><p>In this paper, we revisit pattern mining and study the distribution
underlying a binary dataset thanks to the closure structure which is based on
passkeys, i.e., minimum generators in equivalence classes robust to noise. We
introduce $\Delta$-closedness, a generalization of the closure operator, where
$\Delta$ measures how a closed set differs from its upper neighbors in the
partial order induced by closure. A $\Delta$-class of equivalence includes
minimum and maximum elements and allows us to characterize the distribution
underlying the data. Moreover, the set of $\Delta$-classes of equivalence can
be partitioned into the so-called $\Delta$-closure structure. In particular, a
$\Delta$-class of equivalence with a high level demonstrates correlations among
many attributes, which are supported by more observations when $\Delta$ is
large. In the experiments, we study the $\Delta$-closure structure of several
real-world datasets and show that this structure is very stable for large
$\Delta$ and does not substantially depend on the data sampling used for the
analysis.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Buzmakov_A/0/1/0/all/0/1">Aleksey Buzmakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Makhalova_T/0/1/0/all/0/1">Tatiana Makhalova</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuznetsov_S/0/1/0/all/0/1">Sergei O. Kuznetsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Napoli_A/0/1/0/all/0/1">Amedeo Napoli</a></p><p>In this paper, we revisit pattern mining and study the distribution
underlying a binary dataset thanks to the closure structure which is based on
passkeys, i.e., minimum generators in equivalence classes robust to noise. We
introduce $\Delta$-closedness, a generalization of the closure operator, where
$\Delta$ measures how a closed set differs from its upper neighbors in the
partial order induced by closure. A $\Delta$-class of equivalence includes
minimum and maximum elements and allows us to characterize the distribution
underlying the data. Moreover, the set of $\Delta$-classes of equivalence can
be partitioned into the so-called $\Delta$-closure structure. In particular, a
$\Delta$-class of equivalence with a high level demonstrates correlations among
many attributes, which are supported by more observations when $\Delta$ is
large. In the experiments, we study the $\Delta$-closure structure of several
real-world datasets and show that this structure is very stable for large
$\Delta$ and does not substantially depend on the data sampling used for the
analysis.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07018'>Online matching with delays and stochastic arrival times</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mathieu Mari, Micha&#x142; Paw&#x142;owski, Runtian Ren, Piotr Sankowski</p><p>This paper presents a new research direction for the Min-cost Perfect
Matching with Delays (MPMD) - a problem introduced by Emek et al. (STOC'16). In
the original version of this problem, we are given an $n$-point metric space,
where requests arrive in an online fashion. The goal is to minimise the
matching cost for an even number of requests. However, contrary to traditional
online matching problems, a request does not have to be paired immediately at
the time of its arrival. Instead, the decision of whether to match a request
can be postponed for time $t$ at a delay cost of $t$. For this reason, the goal
of the MPMD is to minimise the overall sum of distance and delay costs.
Interestingly, for adversarially generated requests, no online algorithm can
achieve a competitive ratio better than $O(\log n/\log \log n)$ (Ashlagi et
al., APPROX/RANDOM'17).
</p>
<p>Here, we consider a stochastic version of the MPMD problem where the input
requests follow a Poisson arrival process. For such a problem, we show that the
above lower bound can be improved by presenting two deterministic online
algorithms, which, in expectation, are constant-competitive. The first one is a
simple greedy algorithm that matches any two requests once the sum of their
delay costs exceeds their connection cost, i.e., the distance between them. The
second algorithm builds on the tools used to analyse the first one in order to
obtain even better performance guarantees. This result is rather surprising as
the greedy approach for the adversarial model achieves a competitive ratio of
$\Omega(m^{\log \frac{3}{2}+\varepsilon})$, where $m$ denotes the number of
requests served (Azar et al., TOCS'20). Finally, we prove that it is possible
to obtain similar results for the general case when the delay cost follows an
arbitrary positive and non-decreasing function, as well as for the MPMD variant
with penalties to clear pending requests.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mari_M/0/1/0/all/0/1">Mathieu Mari</a>, <a href="http://arxiv.org/find/cs/1/au:+Pawlowski_M/0/1/0/all/0/1">Micha&#x142; Paw&#x142;owski</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1">Runtian Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankowski_P/0/1/0/all/0/1">Piotr Sankowski</a></p><p>This paper presents a new research direction for the Min-cost Perfect
Matching with Delays (MPMD) - a problem introduced by Emek et al. (STOC'16). In
the original version of this problem, we are given an $n$-point metric space,
where requests arrive in an online fashion. The goal is to minimise the
matching cost for an even number of requests. However, contrary to traditional
online matching problems, a request does not have to be paired immediately at
the time of its arrival. Instead, the decision of whether to match a request
can be postponed for time $t$ at a delay cost of $t$. For this reason, the goal
of the MPMD is to minimise the overall sum of distance and delay costs.
Interestingly, for adversarially generated requests, no online algorithm can
achieve a competitive ratio better than $O(\log n/\log \log n)$ (Ashlagi et
al., APPROX/RANDOM'17).
</p>
<p>Here, we consider a stochastic version of the MPMD problem where the input
requests follow a Poisson arrival process. For such a problem, we show that the
above lower bound can be improved by presenting two deterministic online
algorithms, which, in expectation, are constant-competitive. The first one is a
simple greedy algorithm that matches any two requests once the sum of their
delay costs exceeds their connection cost, i.e., the distance between them. The
second algorithm builds on the tools used to analyse the first one in order to
obtain even better performance guarantees. This result is rather surprising as
the greedy approach for the adversarial model achieves a competitive ratio of
$\Omega(m^{\log \frac{3}{2}+\varepsilon})$, where $m$ denotes the number of
requests served (Azar et al., TOCS'20). Finally, we prove that it is possible
to obtain similar results for the general case when the delay cost follows an
arbitrary positive and non-decreasing function, as well as for the MPMD variant
with penalties to clear pending requests.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.07040'>Threshold Treewidth and Hypertree Width</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Andre Schidler, Robert Ganian, Manuel Sorge, Stefan Szeider</p><p>Treewidth and hypertree width have proven to be highly successful structural
parameters in the context of the Constraint Satisfaction Problem (CSP). When
either of these parameters is bounded by a constant, then CSP becomes solvable
in polynomial time. However, here the order of the polynomial in the running
time depends on the width, and this is known to be unavoidable; therefore, the
problem is not fixed-parameter tractable parameterized by either of these width
measures. Here we introduce an enhancement of tree and hypertree width through
a novel notion of thresholds, allowing the associated decompositions to take
into account information about the computational costs associated with solving
the given CSP instance. Aside from introducing these notions, we obtain
efficient theoretical as well as empirical algorithms for computing threshold
treewidth and hypertree width and show that these parameters give rise to
fixed-parameter algorithms for CSP as well as other, more general problems. We
complement our theoretical results with experimental evaluations in terms of
heuristics as well as exact methods based on SAT/SMT encodings.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Schidler_A/0/1/0/all/0/1">Andre Schidler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganian_R/0/1/0/all/0/1">Robert Ganian</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorge_M/0/1/0/all/0/1">Manuel Sorge</a>, <a href="http://arxiv.org/find/cs/1/au:+Szeider_S/0/1/0/all/0/1">Stefan Szeider</a></p><p>Treewidth and hypertree width have proven to be highly successful structural
parameters in the context of the Constraint Satisfaction Problem (CSP). When
either of these parameters is bounded by a constant, then CSP becomes solvable
in polynomial time. However, here the order of the polynomial in the running
time depends on the width, and this is known to be unavoidable; therefore, the
problem is not fixed-parameter tractable parameterized by either of these width
measures. Here we introduce an enhancement of tree and hypertree width through
a novel notion of thresholds, allowing the associated decompositions to take
into account information about the computational costs associated with solving
the given CSP instance. Aside from introducing these notions, we obtain
efficient theoretical as well as empirical algorithms for computing threshold
treewidth and hypertree width and show that these parameters give rise to
fixed-parameter algorithms for CSP as well as other, more general problems. We
complement our theoretical results with experimental evaluations in terms of
heuristics as well as exact methods based on SAT/SMT encodings.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-14T00:30:00Z">Friday, October 14 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Thursday, October 13
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://blog.computationalcomplexity.org/2022/10/how-not-to-pass-polygraph-test.html'>How Not to Pass a Polygraph Test</a></h3>
          <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          ♦<br>Many years ago I was asked to serve on an advisory board for an organization that did confidential research. To be on the board I had to have US top secret clearance. The first step was filling out a lengthy form which asked deep details about every aspect of my life. Then there were the interviews with myself and many people I interacted with, especially internationally, and I have many international colleagues. Eventually I got past these steps.<br>The final step required taking a polygraph (lie-detector) test. So I flew to Baltimore to visit a non-descript office building near the airport. I failed the test. Twice more I went to Baltimore and failed those tests as well.&nbsp;<br>Just to be clear, I never tried to falsify or hide information on these tests. In one case I was asked "Do you live in Atlanta?" I said no. The person administering the test stopped and said I put my address down as Atlanta. I said my mailing address was Atlanta but (at the time) I lived just north of the border in Sandy Springs. She said I should use Atlanta for the test, in other words I should lie. The test didn't go well after that.<br>In another case, I was asked if I was ever arrested. For the record, I have never been arrested but the answer came up as inconclusive. The administrator, different than before, trusted the machine more than me and the rest of the day didn't go well.&nbsp;<br>Perhaps the test wasn't meant to just test whether I was telling the truth, but also my ability to keep a secret. At least that would make more sense why I failed three times. More likely I took questions too literally, a product of a mathematician's mind.<br>I never joined the advisory board but that wasn't the worst of it. In 2014 the Chinese hacked into the US Office of Personnel Management taking information from, among others, those who applied for security clearance. It's the main reason I keep security freezes with the credit bureaus.<p>By Lance Fortnow</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbVRkVbxq4nkOBNugqs01If78vjWowLhCCowXwEXkJCHuST_xZVWQApkTScjld0Z8sDgxwU_R6AwWsKPB4gbiKYW--3TkWtcpZGV4N2skRt7tW2XvxBi5VRjWQKZcqigp8Ewp18q6MrZQUUq_Y09300z8muVgiVskef70PibPTlUGGb08V_w/s300/meet-the-parents-original-300x189.jpg" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" data-original-height="189" data-original-width="300" height="189" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbVRkVbxq4nkOBNugqs01If78vjWowLhCCowXwEXkJCHuST_xZVWQApkTScjld0Z8sDgxwU_R6AwWsKPB4gbiKYW--3TkWtcpZGV4N2skRt7tW2XvxBi5VRjWQKZcqigp8Ewp18q6MrZQUUq_Y09300z8muVgiVskef70PibPTlUGGb08V_w/s1600/meet-the-parents-original-300x189.jpg" width="300" /></a></div><br />Many years ago I was asked to serve on an advisory board for an organization that did confidential research. To be on the board I had to have US top secret clearance. The first step was filling out a lengthy form which asked deep details about every aspect of my life. Then there were the interviews with myself and many people I interacted with, especially internationally, and I have many international colleagues. Eventually I got past these steps.<div><br /></div><div>The final step required taking a polygraph (lie-detector) test. So I flew to Baltimore to visit a non-descript office building near the airport. I failed the test. Twice more I went to Baltimore and failed those tests as well.&nbsp;</div><div><br /></div><div>Just to be clear, I never tried to falsify or hide information on these tests. In one case I was asked "Do you live in Atlanta?" I said no. The person administering the test stopped and said I put my address down as Atlanta. I said my mailing address was Atlanta but (at the time) I lived just north of the border in Sandy Springs. She said I should use Atlanta for the test, in other words I should lie. The test didn't go well after that.</div><div><br /></div><div>In another case, I was asked if I was ever arrested. For the record, I have never been arrested but the answer came up as inconclusive. The administrator, different than before, trusted the machine more than me and the rest of the day didn't go well.&nbsp;</div><div><br /></div><div>Perhaps the test wasn't meant to just test whether I was telling the truth, but also my ability to keep a secret. At least that would make more sense why I failed three times. More likely I took questions too literally, a product of a mathematician's mind.</div><div><br /></div><div>I never joined the advisory board but that wasn't the worst of it. In 2014 the Chinese hacked into the US Office of Personnel Management taking information from, among others, those who applied for security clearance. It's the main reason I keep security freezes with the credit bureaus.</div><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T13:34:00Z">Thursday, October 13 2022, 13:34</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05885'>Unitary property testing lower bounds by polynomials</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Adrian She, Henry Yuen</p><p>We study unitary property testing, where a quantum algorithm is given query
access to a black-box unitary and has to decide whether it satisfies some
property. In addition to containing the standard quantum query complexity model
(where the unitary encodes a binary string) as a special case, this model
contains "inherently quantum" problems that have no classical analogue.
Characterizing the query complexity of these problems requires new algorithmic
techniques and lower bound methods.
</p>
<p>Our main contribution is a generalized polynomial method for unitary property
testing problems. By leveraging connections with invariant theory, we apply
this method to obtain lower bounds on problems such as determining recurrence
times of unitaries, approximating the dimension of a marked subspace, and
approximating the entanglement entropy of a marked state. We also present a
unitary property testing-based approach towards an oracle separation between
$\mathsf{QMA}$ and $\mathsf{QMA(2)}$, a long standing question in quantum
complexity theory.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+She_A/0/1/0/all/0/1">Adrian She</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yuen_H/0/1/0/all/0/1">Henry Yuen</a></p><p>We study unitary property testing, where a quantum algorithm is given query
access to a black-box unitary and has to decide whether it satisfies some
property. In addition to containing the standard quantum query complexity model
(where the unitary encodes a binary string) as a special case, this model
contains "inherently quantum" problems that have no classical analogue.
Characterizing the query complexity of these problems requires new algorithmic
techniques and lower bound methods.
</p>
<p>Our main contribution is a generalized polynomial method for unitary property
testing problems. By leveraging connections with invariant theory, we apply
this method to obtain lower bounds on problems such as determining recurrence
times of unitaries, approximating the dimension of a marked subspace, and
approximating the entanglement entropy of a marked state. We also present a
unitary property testing-based approach towards an oracle separation between
$\mathsf{QMA}$ and $\mathsf{QMA(2)}$, a long standing question in quantum
complexity theory.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05788'>A Note on Reachability and Distance Oracles for Transmission Graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mark de Berg</p><p>Let $P$ be a set of $n$ points in the plane, where each point $p\in P$ has a
transmission radius $r(p)&gt;0$. The transmission graph defined by $P$ and the
given radii, denoted by $\mathcal{G}_{\mathrm{tr}}(P)$, is the directed graph
whose nodes are the points in $P$ and that contains the arcs $(p,q)$ such that
$|pq|\leq r(p)$.
</p>
<p>An and Oh [Algorithmica 2022] presented a reachability oracle for
transmission graphs. Their oracle uses $O(n^{5/3})$ storage and, given two
query points $s,t\in P$, can decide in $O(n^{2/3})$ time if there is a path
from $s$ to $t$ in $\mathcal{G}_{\mathrm{tr}}(P)$. We show that the
clique-based separators introduced by De Berg \emph{et al.} [SICOMP 2020] can
be used to improve the storage of the oracle to $O(n\sqrt{n})$ and the query
time to $O(\sqrt{n})$. Our oracle can be extended to approximate distance
queries: we can construct, for a given parameter $\varepsilon&gt;0$, an oracle
that uses $O((n/\varepsilon)\sqrt{n}\log n)$ storage and that can report in
$O((\sqrt{n}/\varepsilon)\log n)$ time a value $d_{\mathrm{hop}}^*(s,t)$
satisfying $d_{\mathrm{hop}}(s,t) \leq d_{\mathrm{hop}}^*(s,t) &lt;
(1+\varepsilon)\cdot d_{\mathrm{hop}}(s,t) + 1$, where $d_{\mathrm{hop}}(s,t)$
is the hop-distance from $s$ to $t$. We also show how to extend the oracle to
so-called continuous queries, where the target point $t$ can be any point in
the plane.
</p>
<p>To obtain an efficient preprocessing algorithm, we show that a clique-based
separator of a set~$F$ of convex fat objects in $\Bbb{R}^d$ can be constructed
in $O(n\log n)$ time.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berg_M/0/1/0/all/0/1">Mark de Berg</a></p><p>Let $P$ be a set of $n$ points in the plane, where each point $p\in P$ has a
transmission radius $r(p)&gt;0$. The transmission graph defined by $P$ and the
given radii, denoted by $\mathcal{G}_{\mathrm{tr}}(P)$, is the directed graph
whose nodes are the points in $P$ and that contains the arcs $(p,q)$ such that
$|pq|\leq r(p)$.
</p>
<p>An and Oh [Algorithmica 2022] presented a reachability oracle for
transmission graphs. Their oracle uses $O(n^{5/3})$ storage and, given two
query points $s,t\in P$, can decide in $O(n^{2/3})$ time if there is a path
from $s$ to $t$ in $\mathcal{G}_{\mathrm{tr}}(P)$. We show that the
clique-based separators introduced by De Berg \emph{et al.} [SICOMP 2020] can
be used to improve the storage of the oracle to $O(n\sqrt{n})$ and the query
time to $O(\sqrt{n})$. Our oracle can be extended to approximate distance
queries: we can construct, for a given parameter $\varepsilon&gt;0$, an oracle
that uses $O((n/\varepsilon)\sqrt{n}\log n)$ storage and that can report in
$O((\sqrt{n}/\varepsilon)\log n)$ time a value $d_{\mathrm{hop}}^*(s,t)$
satisfying $d_{\mathrm{hop}}(s,t) \leq d_{\mathrm{hop}}^*(s,t) &lt;
(1+\varepsilon)\cdot d_{\mathrm{hop}}(s,t) + 1$, where $d_{\mathrm{hop}}(s,t)$
is the hop-distance from $s$ to $t$. We also show how to extend the oracle to
so-called continuous queries, where the target point $t$ can be any point in
the plane.
</p>
<p>To obtain an efficient preprocessing algorithm, we show that a clique-based
separator of a set~$F$ of convex fat objects in $\Bbb{R}^d$ can be constructed
in $O(n\log n)$ time.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06333'>Pattern Characterization Using Topological Data Analysis: Application to Piezo Vibration Striking Treatment</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Max M. Chumley, Melih C. Yesilli, Jisheng Chen, Firas A. Khasawneh, Yang Guo</p><p>Quantifying patterns in visual or tactile textures provides important
information about the process or phenomena that generated these patterns. In
manufacturing, these patterns can be intentionally introduced as a design
feature, or they can be a byproduct of a specific process. Since surface
texture has significant impact on the mechanical properties and the longevity
of the workpiece, it is important to develop tools for quantifying surface
patterns and, when applicable, comparing them to their nominal counterparts.
While existing tools may be able to indicate the existence of a pattern, they
typically do not provide more information about the pattern structure, or how
much it deviates from a nominal pattern. Further, prior works do not provide
automatic or algorithmic approaches for quantifying other pattern
characteristics such as depths' consistency, and variations in the pattern
motifs at different level sets. This paper leverages persistent homology from
Topological Data Analysis (TDA) to derive noise-robust scores for quantifying
motifs' depth and roundness in a pattern. Specifically, sublevel persistence is
used to derive scores that quantify the consistency of indentation depths at
any level set in Piezo Vibration Striking Treatment (PVST) surfaces. Moreover,
we combine sublevel persistence with the distance transform to quantify the
consistency of the indentation radii, and to compare them with the nominal
ones. Although the tool in our PVST experiments had a semi-spherical profile,
we present a generalization of our approach to tools/motifs of arbitrary shapes
thus making our method applicable to other pattern-generating manufacturing
processes.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chumley_M/0/1/0/all/0/1">Max M. Chumley</a>, <a href="http://arxiv.org/find/cs/1/au:+Yesilli_M/0/1/0/all/0/1">Melih C. Yesilli</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jisheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Khasawneh_F/0/1/0/all/0/1">Firas A. Khasawneh</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yang Guo</a></p><p>Quantifying patterns in visual or tactile textures provides important
information about the process or phenomena that generated these patterns. In
manufacturing, these patterns can be intentionally introduced as a design
feature, or they can be a byproduct of a specific process. Since surface
texture has significant impact on the mechanical properties and the longevity
of the workpiece, it is important to develop tools for quantifying surface
patterns and, when applicable, comparing them to their nominal counterparts.
While existing tools may be able to indicate the existence of a pattern, they
typically do not provide more information about the pattern structure, or how
much it deviates from a nominal pattern. Further, prior works do not provide
automatic or algorithmic approaches for quantifying other pattern
characteristics such as depths' consistency, and variations in the pattern
motifs at different level sets. This paper leverages persistent homology from
Topological Data Analysis (TDA) to derive noise-robust scores for quantifying
motifs' depth and roundness in a pattern. Specifically, sublevel persistence is
used to derive scores that quantify the consistency of indentation depths at
any level set in Piezo Vibration Striking Treatment (PVST) surfaces. Moreover,
we combine sublevel persistence with the distance transform to quantify the
consistency of the indentation radii, and to compare them with the nominal
ones. Although the tool in our PVST experiments had a semi-spherical profile,
we present a generalization of our approach to tools/motifs of arbitrary shapes
thus making our method applicable to other pattern-generating manufacturing
processes.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05893'>The Power of Two Matrices in Spectral Algorithms</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Souvik Dhara, Julia Gaudio, Elchanan Mossel, Colin Sandon</p><p>Spectral algorithms are some of the main tools in optimization and inference
problems on graphs. Typically, the graph is encoded as a matrix and
eigenvectors and eigenvalues of the matrix are then used to solve the given
graph problem. Spectral algorithms have been successfully used for graph
partitioning, hidden clique recovery and graph coloring. In this paper, we
study the power of spectral algorithms using two matrices in a graph
partitioning problem. We use two different matrices resulting from two
different encodings of the same graph and then combine the spectral information
coming from these two matrices.
</p>
<p>We analyze a two matrix spectral algorithm for the problem of identifying
latent community structure in large random graphs. In particular, we consider
the problem of recovering community assignments exactly in the censored
stochastic block model, where each edge status is revealed independently with
some probability. We show that spectral algorithms based on two matrices are
optimal and succeed in recovering communities up to the information theory
threshold. On the other hand, we show that for most choices of the parameters,
any spectral algorithm based on one matrix is suboptimal. This is in contrast
to our prior works (2022a, 2022b) which showed that for the symmetric
Stochastic Block Model and the Planted Dense Subgraph problem, spectral
algorithm based on one matrix achieve the information theory threshold. Of
independent interest, we provide more general geometric conditions for the
(sub)-optimality of spectral algorithms, that are also applicable to cases when
there are more than two communities.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Dhara_S/0/1/0/all/0/1">Souvik Dhara</a>, <a href="http://arxiv.org/find/math/1/au:+Gaudio_J/0/1/0/all/0/1">Julia Gaudio</a>, <a href="http://arxiv.org/find/math/1/au:+Mossel_E/0/1/0/all/0/1">Elchanan Mossel</a>, <a href="http://arxiv.org/find/math/1/au:+Sandon_C/0/1/0/all/0/1">Colin Sandon</a></p><p>Spectral algorithms are some of the main tools in optimization and inference
problems on graphs. Typically, the graph is encoded as a matrix and
eigenvectors and eigenvalues of the matrix are then used to solve the given
graph problem. Spectral algorithms have been successfully used for graph
partitioning, hidden clique recovery and graph coloring. In this paper, we
study the power of spectral algorithms using two matrices in a graph
partitioning problem. We use two different matrices resulting from two
different encodings of the same graph and then combine the spectral information
coming from these two matrices.
</p>
<p>We analyze a two matrix spectral algorithm for the problem of identifying
latent community structure in large random graphs. In particular, we consider
the problem of recovering community assignments exactly in the censored
stochastic block model, where each edge status is revealed independently with
some probability. We show that spectral algorithms based on two matrices are
optimal and succeed in recovering communities up to the information theory
threshold. On the other hand, we show that for most choices of the parameters,
any spectral algorithm based on one matrix is suboptimal. This is in contrast
to our prior works (2022a, 2022b) which showed that for the symmetric
Stochastic Block Model and the Planted Dense Subgraph problem, spectral
algorithm based on one matrix achieve the information theory threshold. Of
independent interest, we provide more general geometric conditions for the
(sub)-optimality of spectral algorithms, that are also applicable to cases when
there are more than two communities.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05965'>Resolving the Approximability of Offline and Online Non-monotone DR-Submodular Maximization over General Convex Sets</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Loay Mualem, Moran Feldman</p><p>In recent years, maximization of DR-submodular continuous functions became an
important research field, with many real-worlds applications in the domains of
machine learning, communication systems, operation research and economics. Most
of the works in this field study maximization subject to down-closed convex set
constraints due to an inapproximability result by Vondr\'ak (2013). However,
Durr et al. (2021) showed that one can bypass this inapproximability by proving
approximation ratios that are functions of $m$, the minimum
$\ell_{\infty}$-norm of any feasible vector. Given this observation, it is
possible to get results for maximizing a DR-submodular function subject to
general convex set constraints, which has led to multiple works on this
problem. The most recent of which is a polynomial time $\tfrac{1}{4}(1 -
m)$-approximation offline algorithm due to Du (2022). However, only a
sub-exponential time $\tfrac{1}{3\sqrt{3}}(1 - m)$-approximation algorithm is
known for the corresponding online problem. In this work, we present a
polynomial time online algorithm matching the $\tfrac{1}{4}(1 -
m)$-approximation of the state-of-the-art offline algorithm. We also present an
inapproximability result showing that our online algorithm and Du's (2022)
offline algorithm are both optimal in a strong sense. Finally, we study the
empirical performance of our algorithm and the algorithm of Du (which was only
theoretically studied previously), and show that they consistently outperform
previously suggested algorithms on revenue maximization, location summarization
and quadratic programming applications.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mualem_L/0/1/0/all/0/1">Loay Mualem</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldman_M/0/1/0/all/0/1">Moran Feldman</a></p><p>In recent years, maximization of DR-submodular continuous functions became an
important research field, with many real-worlds applications in the domains of
machine learning, communication systems, operation research and economics. Most
of the works in this field study maximization subject to down-closed convex set
constraints due to an inapproximability result by Vondr\'ak (2013). However,
Durr et al. (2021) showed that one can bypass this inapproximability by proving
approximation ratios that are functions of $m$, the minimum
$\ell_{\infty}$-norm of any feasible vector. Given this observation, it is
possible to get results for maximizing a DR-submodular function subject to
general convex set constraints, which has led to multiple works on this
problem. The most recent of which is a polynomial time $\tfrac{1}{4}(1 -
m)$-approximation offline algorithm due to Du (2022). However, only a
sub-exponential time $\tfrac{1}{3\sqrt{3}}(1 - m)$-approximation algorithm is
known for the corresponding online problem. In this work, we present a
polynomial time online algorithm matching the $\tfrac{1}{4}(1 -
m)$-approximation of the state-of-the-art offline algorithm. We also present an
inapproximability result showing that our online algorithm and Du's (2022)
offline algorithm are both optimal in a strong sense. Finally, we study the
empirical performance of our algorithm and the algorithm of Du (which was only
theoretically studied previously), and show that they consistently outperform
previously suggested algorithms on revenue maximization, location summarization
and quadratic programming applications.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05974'>Clustering Embedding Tables, Without First Learning Them</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Henry Ling-Hei Tsang, Thomas Dybdahl Ahle</p><p>To work with categorical features, machine learning systems employ embedding
tables. These tables can become exceedingly large in modern recommendation
systems, necessitating the development of new methods for fitting them in
memory, even during training.
</p>
<p>Some of the most successful methods for table compression are Product- and
Residual Vector Quantization (Gray &amp; Neuhoff, 1998). These methods replace
table rows with references to k-means clustered "codewords." Unfortunately,
this means they must first know the table before compressing it, so they can
only save memory during inference, not training. Recent work has used
hashing-based approaches to minimize memory usage during training, but the
compression obtained is inferior to that obtained by "post-training"
quantization.
</p>
<p>We show that the best of both worlds may be obtained by combining techniques
based on hashing and clustering. By first training a hashing-based "sketch",
then clustering it, and then training the clustered quantization, our method
achieves compression ratios close to those of post-training quantization with
the training time memory reductions of hashing-based methods.
</p>
<p>We show experimentally that our method provides better compression and/or
accuracy that previous methods, and we prove that our method always converges
to the optimal embedding table for least-squares training.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tsang_H/0/1/0/all/0/1">Henry Ling-Hei Tsang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahle_T/0/1/0/all/0/1">Thomas Dybdahl Ahle</a></p><p>To work with categorical features, machine learning systems employ embedding
tables. These tables can become exceedingly large in modern recommendation
systems, necessitating the development of new methods for fitting them in
memory, even during training.
</p>
<p>Some of the most successful methods for table compression are Product- and
Residual Vector Quantization (Gray &amp; Neuhoff, 1998). These methods replace
table rows with references to k-means clustered "codewords." Unfortunately,
this means they must first know the table before compressing it, so they can
only save memory during inference, not training. Recent work has used
hashing-based approaches to minimize memory usage during training, but the
compression obtained is inferior to that obtained by "post-training"
quantization.
</p>
<p>We show that the best of both worlds may be obtained by combining techniques
based on hashing and clustering. By first training a hashing-based "sketch",
then clustering it, and then training the clustered quantization, our method
achieves compression ratios close to those of post-training quantization with
the training time memory reductions of hashing-based methods.
</p>
<p>We show experimentally that our method provides better compression and/or
accuracy that previous methods, and we prove that our method always converges
to the optimal embedding table for least-squares training.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05982'>A nearly optimal randomized algorithm for explorable heap selection</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Sander Borst, Daniel Dadush, Sophie Huiberts, Danish Kashaev</p><p>Explorable heap selection is the problem of selecting the $n$th smallest
value in a binary heap. The key values can only be accessed by traversing
through the underlying infinite binary tree, and the complexity of the
algorithm is measured by the total distance traveled in the tree (each edge has
unit cost). This problem was originally proposed as a model to study search
strategies for the branch-and-bound algorithm with storage restrictions by
Karp, Saks and Widgerson (FOCS '86), who gave deterministic and randomized
$n\cdot \exp(O(\sqrt{\log{n}}))$ time algorithms using $O(\log(n)^{2.5})$ and
$O(\sqrt{\log n})$ space respectively. We present a new randomized algorithm
with running time $O(n\log(n)^3)$ using $O(\log n)$ space, substantially
improving the previous best randomized running time at the expense of slightly
increased space usage. We also show an $\Omega(\log(n)n/\log(\log(n)))$ for any
algorithm that solves the problem in the same amount of space, indicating that
our algorithm is nearly optimal.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Borst_S/0/1/0/all/0/1">Sander Borst</a>, <a href="http://arxiv.org/find/cs/1/au:+Dadush_D/0/1/0/all/0/1">Daniel Dadush</a>, <a href="http://arxiv.org/find/cs/1/au:+Huiberts_S/0/1/0/all/0/1">Sophie Huiberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashaev_D/0/1/0/all/0/1">Danish Kashaev</a></p><p>Explorable heap selection is the problem of selecting the $n$th smallest
value in a binary heap. The key values can only be accessed by traversing
through the underlying infinite binary tree, and the complexity of the
algorithm is measured by the total distance traveled in the tree (each edge has
unit cost). This problem was originally proposed as a model to study search
strategies for the branch-and-bound algorithm with storage restrictions by
Karp, Saks and Widgerson (FOCS '86), who gave deterministic and randomized
$n\cdot \exp(O(\sqrt{\log{n}}))$ time algorithms using $O(\log(n)^{2.5})$ and
$O(\sqrt{\log n})$ space respectively. We present a new randomized algorithm
with running time $O(n\log(n)^3)$ using $O(\log n)$ space, substantially
improving the previous best randomized running time at the expense of slightly
increased space usage. We also show an $\Omega(\log(n)n/\log(\log(n)))$ for any
algorithm that solves the problem in the same amount of space, indicating that
our algorithm is nearly optimal.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05992'>Fast Convergence to Unanimity in Dense Erd\H{o}s-R\'enyi Graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Ran Tamir</p><p>Majority dynamics on the binomial Erd\H{o}s-R\'enyi graph $\mathsf{G}(n,p)$
with $p=\lambda/\sqrt{n}$ is studied. In this process, each vertex has a state
in $\{0,1\}$ and at each round, every vertex adopts the state of the majority
of its neighbors, retaining its state in the case of a tie. It was conjectured
by Benjamini et al. and proved by Fountoulakis et al. that this process reaches
unanimity with high probability in at most four rounds. By adding some extra
randomness and allowing the underlying graph to be drawn anew in each
communication round, we improve on their result and prove that this process
reaches consensus in only three communication rounds with probability
approaching $1$ as $n$ grows to infinity. We also provide a converse result,
showing that three rounds are not only sufficient, but also necessary.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tamir_R/0/1/0/all/0/1">Ran Tamir</a></p><p>Majority dynamics on the binomial Erd\H{o}s-R\'enyi graph $\mathsf{G}(n,p)$
with $p=\lambda/\sqrt{n}$ is studied. In this process, each vertex has a state
in $\{0,1\}$ and at each round, every vertex adopts the state of the majority
of its neighbors, retaining its state in the case of a tie. It was conjectured
by Benjamini et al. and proved by Fountoulakis et al. that this process reaches
unanimity with high probability in at most four rounds. By adding some extra
randomness and allowing the underlying graph to be drawn anew in each
communication round, we improve on their result and prove that this process
reaches consensus in only three communication rounds with probability
approaching $1$ as $n$ grows to infinity. We also provide a converse result,
showing that three rounds are not only sufficient, but also necessary.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06061'>Non-smooth and H\"older-smooth Submodular Maximization</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Duksang Lee, Nam Ho-Nguyen, Dabeen Lee</p><p>We study the problem of maximizing a continuous DR-submodular function that
is not necessarily smooth. We prove that the continuous greedy algorithm
achieves an $[(1-1/e)\text{OPT}-\epsilon]$ guarantee when the function is
monotone and H\"older-smooth, meaning that it admits a H\"older-continuous
gradient. For functions that are non-differentiable or non-smooth, we propose a
variant of the mirror-prox algorithm that attains an
$[(1/2)\text{OPT}-\epsilon]$ guarantee. We apply our algorithmic frameworks to
robust submodular maximization and distrbituionally robust submodular
maximization under Wasserstein ambiguity. In particular, the mirror-prox method
applies to robust submodular maximization to obtain a single feasible solution
whose value is at least $(1/2)\text{OPT}-\epsilon$. For distributionally robust
maximization under Wasserstein ambiguity, we deduce and work over a
submodular-convex maximin reformulation whose objective function is
H\"older-smooth, for which we may apply both the continuous greedy method and
the mirror-prox method.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Lee_D/0/1/0/all/0/1">Duksang Lee</a>, <a href="http://arxiv.org/find/math/1/au:+Ho_Nguyen_N/0/1/0/all/0/1">Nam Ho-Nguyen</a>, <a href="http://arxiv.org/find/math/1/au:+Lee_D/0/1/0/all/0/1">Dabeen Lee</a></p><p>We study the problem of maximizing a continuous DR-submodular function that
is not necessarily smooth. We prove that the continuous greedy algorithm
achieves an $[(1-1/e)\text{OPT}-\epsilon]$ guarantee when the function is
monotone and H\"older-smooth, meaning that it admits a H\"older-continuous
gradient. For functions that are non-differentiable or non-smooth, we propose a
variant of the mirror-prox algorithm that attains an
$[(1/2)\text{OPT}-\epsilon]$ guarantee. We apply our algorithmic frameworks to
robust submodular maximization and distrbituionally robust submodular
maximization under Wasserstein ambiguity. In particular, the mirror-prox method
applies to robust submodular maximization to obtain a single feasible solution
whose value is at least $(1/2)\text{OPT}-\epsilon$. For distributionally robust
maximization under Wasserstein ambiguity, we deduce and work over a
submodular-convex maximin reformulation whose objective function is
H\"older-smooth, for which we may apply both the continuous greedy method and
the mirror-prox method.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06140'>Differentially Private Bootstrap: New Privacy Analysis and Inference Strategies</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Zhanyu Wang, Guang Cheng, Jordan Awan</p><p>Differential private (DP) mechanisms protect individual-level information by
introducing randomness into the statistical analysis procedure. While there are
now many DP tools for various statistical problems, there is still a lack of
general techniques to understand the sampling distribution of a DP estimator,
which is crucial for uncertainty quantification in statistical inference. We
analyze a DP bootstrap procedure that releases multiple private bootstrap
estimates to infer the sampling distribution and construct confidence
intervals. Our privacy analysis includes new results on the privacy cost of a
single DP bootstrap estimate applicable to incorporate arbitrary DP mechanisms
and identifies some misuses of the bootstrap in the existing literature. We
show that the release of $B$ DP bootstrap estimates from mechanisms satisfying
$(\mu/\sqrt{(2-2/\mathrm{e})B})$-Gaussian DP asymptotically satisfies
$\mu$-Gaussian DP as $B$ goes to infinity. We also develop a statistical
procedure based on the DP bootstrap estimates to correctly infer the sampling
distribution using techniques related to the deconvolution of probability
measures, an approach which is novel in analyzing DP procedures. From our
density estimate, we construct confidence intervals and compare them to
existing methods through simulations and real-world experiments using the 2016
Canada Census Public Use Microdata. The coverage of our private confidence
intervals achieves the nominal confidence level, while other methods fail to
meet this guarantee.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1">Zhanyu Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1">Guang Cheng</a>, <a href="http://arxiv.org/find/stat/1/au:+Awan_J/0/1/0/all/0/1">Jordan Awan</a></p><p>Differential private (DP) mechanisms protect individual-level information by
introducing randomness into the statistical analysis procedure. While there are
now many DP tools for various statistical problems, there is still a lack of
general techniques to understand the sampling distribution of a DP estimator,
which is crucial for uncertainty quantification in statistical inference. We
analyze a DP bootstrap procedure that releases multiple private bootstrap
estimates to infer the sampling distribution and construct confidence
intervals. Our privacy analysis includes new results on the privacy cost of a
single DP bootstrap estimate applicable to incorporate arbitrary DP mechanisms
and identifies some misuses of the bootstrap in the existing literature. We
show that the release of $B$ DP bootstrap estimates from mechanisms satisfying
$(\mu/\sqrt{(2-2/\mathrm{e})B})$-Gaussian DP asymptotically satisfies
$\mu$-Gaussian DP as $B$ goes to infinity. We also develop a statistical
procedure based on the DP bootstrap estimates to correctly infer the sampling
distribution using techniques related to the deconvolution of probability
measures, an approach which is novel in analyzing DP procedures. From our
density estimate, we construct confidence intervals and compare them to
existing methods through simulations and real-world experiments using the 2016
Canada Census Public Use Microdata. The coverage of our private confidence
intervals achieves the nominal confidence level, while other methods fail to
meet this guarantee.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06227'>Quantum Optimisation for Continuous Multivariable Functions by a Structured Search</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Edric Matwiejew, Jason Pye, Jingbo B. Wang</p><p>Solving optimisation problems is a promising near-term application of quantum
computers. Quantum variational algorithms leverage quantum superposition and
entanglement to optimise over exponentially large solution spaces using an
alternating sequence of classically tunable unitaries. However, prior work has
primarily addressed discrete optimisation problems. In addition, these
algorithms have been designed generally under the assumption of an unstructured
solution space, which constrains their speedup to the theoretical limits for
the unstructured Grover's quantum search algorithm. In this paper, we show that
quantum variational algorithms can efficiently optimise continuous
multivariable functions by exploiting general structural properties of a
discretised continuous solution space with a convergence that exceeds the
limits of an unstructured quantum search. We introduce the Quantum
Multivariable Optimisation Algorithm (QMOA) and demonstrate its advantage over
pre-existing methods, particularly when optimising high-dimensional and
oscillatory functions.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Matwiejew_E/0/1/0/all/0/1">Edric Matwiejew</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pye_J/0/1/0/all/0/1">Jason Pye</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wang_J/0/1/0/all/0/1">Jingbo B. Wang</a></p><p>Solving optimisation problems is a promising near-term application of quantum
computers. Quantum variational algorithms leverage quantum superposition and
entanglement to optimise over exponentially large solution spaces using an
alternating sequence of classically tunable unitaries. However, prior work has
primarily addressed discrete optimisation problems. In addition, these
algorithms have been designed generally under the assumption of an unstructured
solution space, which constrains their speedup to the theoretical limits for
the unstructured Grover's quantum search algorithm. In this paper, we show that
quantum variational algorithms can efficiently optimise continuous
multivariable functions by exploiting general structural properties of a
discretised continuous solution space with a convergence that exceeds the
limits of an unstructured quantum search. We introduce the Quantum
Multivariable Optimisation Algorithm (QMOA) and demonstrate its advantage over
pre-existing methods, particularly when optimising high-dimensional and
oscillatory functions.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
  </div>

  <script src='js/jquery-2.0.3.min.js'></script>
  <script src="js/jquery.timeago.js" type="text/javascript"></script>
  <script>
    jQuery(document).ready(function() {
      jQuery("time.timeago").timeago();
    });
  </script>
  <script src='js/blank.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
