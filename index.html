<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.5 (2022-11-24) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-02-26T02:11:11Z">Sunday, February 26 2023, 02:11</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Saturday, February 25
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/'>STOC 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          STOC 2023 is the 55th Annual ACM Symposium on Theory of Computing. It will be held on June 20-23, 2023 in Orlando, Florida. Perhaps the best paper ever at STOC was by Stephen Cook. His 1971 STOC paper The Complexity of Theorem Proving Procedures formalized the notions of polynomial-time and started the search to prove [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<a href="http://acm-stoc.org/stoc2023/">STOC 2023</a> is the 55th Annual ACM Symposium on Theory of Computing. It will be held on June 20-23, 2023 in Orlando, Florida. </p>
<p>
Perhaps the best paper ever at STOC was by Stephen Cook. His 1971 STOC paper <a href="https://dl.acm.org/doi/10.1145/800157.805047">The Complexity of Theorem Proving Procedures</a> formalized the notions of polynomial-time and started the search to prove <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{P}" class="latex" /> is not equal to <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7BNP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{NP}" class="latex" />. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/cook/" rel="attachment wp-att-21168"><img data-attachment-id="21168" data-permalink="https://rjlipton.wpcomstaging.com/2023/02/25/stoc-2023/cook/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" data-orig-size="290,174" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cook" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?fit=290%2C174&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/02/cook.jpeg?resize=290%2C174&#038;ssl=1" alt="" width="290" height="174" class="aligncenter size-full wp-image-21168" data-recalc-dims="1" /></a></p>
<p>
See <a href="https://en.wikipedia.org/wiki/Symposium_on_Theory_of_Computing">this</a> for more. </p>
<p>
<p><H2> Papers with Pointers </H2></p>
<p><p>
Many web sites on STOC 2023 list the accepted papers but not with pointers. We planned to create these links ourself but we discovered this site that already has them:</p>
<p>
<a href="https://www.conference-publishing.com/list.php?Event=STOC23">List of papers</a> with pointers. </p>
<p>
This saved us having to create the pointers. Try them&#8212;fun to see the accepted papers.</p>
<p>
<p><H2> The Program Committee </H2></p>
<p><p>
Thanks to the program committee for working so hard on putting together such a terrific program. </p>
<ul>
<li>
Amir Abboud (Weizmann Institute of Science) </p>
<li>
Josh Alman (Columbia University) </p>
<li>
Andris Ambainis (University of Latvia) </p>
<li>
Nima Anari (Stanford University) </p>
<li>
Srinivasan Arunachalam (IBM Thomas J. Watson Research Center) </p>
<li>
Petra Berenbrink (Universitat Hamburg) </p>
<li>
Aaron Bernstein (Rutgers University) </p>
<li>
Aditya Bhaskara (University of Utah) </p>
<li>
Sayan Bhattacharya (University of Warwick) </p>
<li>
Eric Blais (University of Waterloo) </p>
<li>
Hans Bodlaender (Utrecht University) </p>
<li>
Adam Bouland (Stanford University) </p>
<li>
Anne Broadbent (University of Ottawa) </p>
<li>
Mark Bun (Boston University) </p>
<li>
Keren Censor-Hillel (Technion) </p>
<li>
Timothy Chan (University of Illinois at Urbana-Champaign) </p>
<li>
Arkadev Chattopadhyay (Tata Institute of Fundamental Research) </p>
<li>
Chandra Chekuri (University of Illinois at Urbana-Champaign) </p>
<li>
Xue Chen (University of Science and Technology of China) </p>
<li>
Gil Cohen (Tel Aviv University) </p>
<li>
Dana Dachman-Soled (University of Maryland College Park) </p>
<li>
Anindya De (University of Pennsylvania) </p>
<li>
Shahar Dobzhinski (Weizmann Institute of Science) </p>
<li>
Shaddin Dughmi (University of Southern California) </p>
<li>
Vida Dujmovic (University of Ottawa) </p>
<li>
Yuval Filmus (Technion) </p>
<li>
Sumegha Garg (Stanford University) </p>
<li>
Rong Ge (Duke University) </p>
<li>
Elena Grigorescu (Purdue University) </p>
<li>
Shuichi Hirahara (National Institute of Informatics, Japan) </p>
<li>
Zhiyi Huang (University of Hong Kong) </p>
<li>
Sungjin Im (University of California, Merced) </p>
<li>
Giuseppe Italiano (LUISS University) </p>
<li>
Ken-ichi Kawarabayashi (National Institute of Informatics, Japan) </p>
<li>
Sanjeev Khanna (University of Pennsylvania) </p>
<li>
Robin Kothari (Google Research) </p>
<li>
Marvin Kunnemann (TU Kaiserslautern) </p>
<li>
Rasmus Kyng (ETH Zurich) </p>
<li>
Sophie Laplante (Universite Paris Cite) </p>
<li>
Hung Le (University of Massachusetts, Amherst) </p>
<li>
Daniel Lokshtanov (University of California, Santa Barbara) </p>
<li>
Sepideh Mahabadi (Microsoft Research) </p>
<li>
Nicole Megow (Universitat Bremen) </p>
<li>
Slobodan Mitrovic (University of California, Davis) </p>
<li>
Ankur Moitra (Massachusetts Institute of Technology) </p>
<li>
Shay Moran (Technion and Google Research) </p>
<li>
Christopher Musco (New York University) </p>
<li>
Krzysztof Onak (Boston University) </p>
<li>
Rotem Oshman (Tel Aviv University) </p>
<li>
Prasad Raghavendra (University of California, Berkeley) </p>
<li>
Susanna Rezende (Lund University) </p>
<li>
Robert Robere (McGill University) </p>
<li>
Alon Rosen (Bocconi University and Reichman University) </p>
<li>
Ron Rothblum (Technion) </p>
<li>
Alex Russell (University of Connecticut) </p>
<li>
Laura Sanita (Bocconi University) </p>
<li>
Thatchaphol Saranurak (University of Michigan) </p>
<li>
Tselil Schramm (Stanford University) </p>
<li>
Rocco Servedio (Columbia University), Chair </p>
<li>
Tasos Sidiropoulos (University of Illinois at Chicago) </p>
<li>
Alex Slivkins (Microsoft Research) </p>
<li>
Srikanth Srinivasan (Aarhus University) </p>
<li>
David Steurer (ETH Zurich) </p>
<li>
Ola Svensson (EPFL) </p>
<li>
Chaitanya Swamy (University of Waterloo) </p>
<li>
Madhur Tulsiani (Toyota Technological Institute at Chicago) </p>
<li>
Christos Tzamos (University of Wisconsin-Madison) </p>
<li>
Muthu Venkitasubramaniam (Georgetown University) </p>
<li>
Ben Lee Volk (Reichman University) </p>
<li>
Andreas Wiese (Technical University of Munich) </p>
<li>
Mary Wootters (Stanford University) </p>
<li>
Yuichi Yoshida (National Institute of Informatics, Japan) </p>
<li>
Huacheng Yu (Princeton University)
</ul>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
I hope having the list of accepted papers with links is of some value. Cook&#8217;s paper might be the best ever, but it did not get the award for best paper at the time. Here are some of the more recent <a href="https://www.sigact.org/prizes/best_paper.html">best papers</a>:</p>
<p>
2020	<a href="https://arxiv.org/abs/1908.08483">Improved Bounds for The Sunflower Lemma</a> <br />
2019	<a href="https://arxiv.org/abs/1809.07115">The Reachability Problem for Petri Nets is Not Elementary</a> </p>
<p>
I like the second one above for personal reasons that I expounded long ago <a href="https://rjlipton.wpcomstaging.com/2009/04/08/an-expspace-lower-bound/">here</a>, and which Ken expanded on <a href="https://rjlipton.wpcomstaging.com/2015/07/12/the-long-reach-of-reachability/">here</a>. </p>
<p>
<p class="authors">By rjlipton</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-25T23:40:51Z">Saturday, February 25 2023, 23:40</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/02/25/isohedral-delaunay-complexes.html'>Isohedral Delaunay complexes</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The Delaunay complex of a set of points in the Euclidean plane partitions the convex hull of the points into polygonal cells. Each cell is the convex hull of a co-circular subset of the points whose circle does not contain any more points. It’s often called a Delaunay triangulation, because for points in general position the cells are all triangles, but I do not want to assume general position here. It is isohedral when all of the cells are symmetric to each other (maybe a little more strong than asking for them all to have the same shape). For example, the familiar tilings of the plane by squares or regular hexagons are both isohedral and Delaunay. Another example is a tiling of the plane by 60°–90°–120° kites:
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The Delaunay complex of a set of points in the Euclidean plane partitions the convex hull of the points into polygonal cells. Each cell is the convex hull of a co-circular subset of the points whose circle does not contain any more points. It’s often called a <a href="https://en.wikipedia.org/wiki/Delaunay_triangulation">Delaunay triangulation</a>, because for points in <a href="General position">general position</a> the cells are all triangles, but I do not want to assume general position here. It is <a href="https://en.wikipedia.org/wiki/Isohedral_figure">isohedral</a> when all of the cells are symmetric to each other (maybe a little more strong than asking for them all to have the same shape). For example, the familiar tilings of the plane by squares or regular hexagons are both isohedral and Delaunay. Another example is a <a href="https://en.wikipedia.org/wiki/Deltoidal_trihexagonal_tiling">tiling of the plane by 60°–90°–120° kites</a>:</p>

<p style="text-align:center"><img src="/blog/assets/2023/tetrille-delaunay.svg" alt="Tiling of the plane by 60°–90°–120° kites, with shading showing that the circumcircles of each site are empty of other tiling vertices" style="width:100%;max-width:720px" /></p>

<p>Some other tilings, even very symmetric ones, might not be Delaunay. For instance, it is impossible to make a Delaunay version of the <a href="https://en.wikipedia.org/wiki/Cairo_pentagonal_tiling">Cairo pentagonal tiling</a> because its tiles have two complementary angles or two right angles, impossible for a co-circular pentagon.</p>

<p>In these cases, the symmetries are of the familiar kind, translations and rotations of the plane. But translation symmetry forces us to use infinitely many points. Can finite Delaunay complexes be isohedral? Sort of, maybe, but with a different kind of symmetry.
You can translate between Delaunay complexes on the plane and on a sphere by <a href="https://en.wikipedia.org/wiki/Stereographic_projection">stereographic projection</a>, and translations, rotations, and scaling in the plane become Möbius transformations on the sphere. So the projection onto the sphere of a square grid becomes a spherical Delaunay complex that is symmetric under Möbius transformations.</p>

<p style="text-align:center"><img src="/blog/assets/2023/stereographic-square-tiling.svg" alt="Stereographic projection of a square grid from the plane to a sphere" title="CC-BY-SA 4.0 image https://commons.wikimedia.org/wiki/File:Stereogr-proj-netz.svg by Ag2gaeh from Wikimedia commons" style="width:100%;max-width:720px" /></p>

<p>Rotations of the sphere are also a very special case of Möbius transformations, so we can look for Delaunay complexes with rotational symmetries. Suppose you have a polyhedron all of whose vertices lie on a sphere, and all of whose faces are symmetric to each other by rotations of the sphere. Then the intersection of the sphere with any face plane of the polyhedron is a circle through the vertices of a face that does not contain any other vertices, the defining property of a Delaunay cell. So these polyhedra are isohedral spherical Delaunay complexes. This is true, for instance, for the Platonic solids and for the two infinite families of <a href="https://en.wikipedia.org/wiki/Bipyramid">bipyramids</a> and the <a href="https://en.wikipedia.org/wiki/Trapezohedron">trapezohedra</a> but false for some other isohedral polyhedra like the <a href="https://en.wikipedia.org/wiki/Rhombic_dodecahedron">rhombic dodecahedron</a> and <a href="https://en.wikipedia.org/wiki/Triakis_tetrahedron">triakis tetrahedron</a> whose vertices cannot all be placed on a sphere.</p>

<p>You can map these spherical Delaunay complexes back onto the plane by stereographic projection again. You might think that the result is always a planar Delaunay complex in which all faces are symmetric to each other under Möbius transformation, but there’s a catch. The projection preserves circles, but it turns inside out the ones that contain the pole of the projection. If they were empty on the sphere, they instead turn into circles in the plane that contain every other point. These inside-out circles correspond to Delaunay cells on the sphere that do not map to Delaunay cells in the plane. For instance, projecting the cube vertices back down to the plane with the pole at the midpoint of a cube edge produces a Delaunay complex with only four quadrilaterals; the other two faces of the cube come from inside-out circles and do not become Delaunay cells.</p>

<p style="text-align:center"><img src="/blog/assets/2023/cube-edge-projection.svg" alt="Delaunay complex of a cube, stereographically projected onto the plane with its pole at an edge midpoint" style="width:100%;max-width:720px" /></p>

<p>All of this generalizes directly to 3d Delaunay triangulations, and to isohedral 4d polytopes with cospherical vertices, but less is known about what shapes are possible. The regular 4-polytopes, certainly, have symmetric facets and cospherical vertices, but there are other possibilities as well. The <a href="http://www.polytope.net/hedrondude/dice4.htm">isohedral 4-polytopes with up to 20 sides</a> have been classified, but I don’t know which of these can have cospherical vertices.</p>

<p>There are, at least, three different infinite families of isohedral 4d polytopes with cospherical vertices, analogous to the bipyramids and trapezohedra. To describe this, it helps to think of four-dimensional Euclidean space as having two complex numbers \(\alpha\) and \(\beta\) as coordinates, and the unit sphere as the points for which \(\vert\alpha\vert^2+\vert\beta\vert^2=1\). These are the state vectors of a <a href="https://en.wikipedia.org/wiki/Qubit">qubit</a>, so we can write these points on the sphere using <a href="https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation">quantum notation</a> as \(\alpha\,\vert0\rangle+\beta\,\vert1\rangle\), where \(\vert0\rangle\) and \(\vert1\rangle\) are just the two basis vectors for the two-complex-number coordinate system. In this notation, consider the following three sets of points, all on the unit sphere, for integer parameters \(n\) and \(m\):</p>

<ul>
  <li>
    <p>Let \(X\) be the set of \(n\) points \(e^{2\pi i/n}\,\vert0\rangle\), for the integers \(i\) with \(0\le i\lt n\). These form a regular \(n\)-gon in the plane \(\beta=0\).</p>
  </li>
  <li>
    <p>Let \(Y\) be the set of \(m\) points \(e^{2\pi j/m}\,\vert1\rangle\), for the integers \(j\) with \(0\le j\lt n\). These form a regular \(m\)-gon, in the perpendicular plane \(\alpha=0\).</p>
  </li>
  <li>
    <p>Let \(Z\) be the set of \(mn\) points</p>

\[\frac{1}{\sqrt 2}e^{2\pi i/n}\,\vert0\rangle + \frac{1}{\sqrt 2}e^{2\pi j/m}\,\vert1\rangle,\]

    <p>for the same ranges of \(i\) and \(j\). These lie on a <a href="https://en.wikipedia.org/wiki/Flat_torus">flat torus</a>, the Cartesian product of two circles, and form the vertices of a tiling of the torus by rectangles.</p>
  </li>
</ul>

<p>Then the convex hull of \(X\cup Y\) has as its facets \(mn\) congruent tetrahedra, each formed as the convex hull of an edge of the \(X\)-polygon and an edge of the \(Y\)-polygon. The convex hull of \(Z\) is a <a href="https://en.wikipedia.org/wiki/Duoprism">duoprism</a> whose facets are two kinds of prisms: the Cartesian product of an edge of the \(X\)-polygon with the whole \(Y\)-polygon, and vice versa. When \(n=m\) these two prisms are congruent and the resulting duoprism is isohedral, and dual to the convex hull of \(X\cup Y\). Here is a stereographic projection for \(n=m=18\), taken from the <a href="https://www.math.cmu.edu/~fho/jenn/polytopes/index.html">Jenn 3d website</a>:</p>

<p style="text-align:center"><img src="/blog/assets/2023/18x18-torus.png" alt="Stereographic projection into 3d of a 4-dimensional polytope, the (18,18)-duoprism, appearing as a torus tiled with squares" title="Public domain image https://www.math.cmu.edu/~fho/jenn/polytopes/18x18-torus.png" style="width:100%;max-width:720px" /></p>

<p>In this image, the most prominent feature is the tiling by squares of the torus containing \(Z\). If you follow sequences of edges of this square grid, through opposite edges at each vertex, you will also see many 18-gons. Some of the 18-gons slice the “inside” of the torus radially into distorted prisms; these are Delaunay cells. Many of the perpendicular 18-gons slice across the “donut hole” of the torus, forming more Delaunay cells. But some of the remaining 18-gons lie on the convex hull of the shape, and cannot be used as slices for the projected set. The missing slices cause the Delaunay triangulation of the stereographic projection to miss some cells, and that can only happen because the spheres for these cells were inverted by the projection.</p>

<p>You can also take the convex hull of \(X\cup Y\cup Z\). This has two triangular-prism facets for each tetrahedron of \(X\cup Y\), meeting at one of the squares of \(Z\). The reason I’m interested in this example comes from <a href="/blog/2023/02/20/geometric-graphs-unbounded.html">my most recent post, on flip-width of geometric graphs</a>. If you take an induced subgraph of this polytope, consisting only of the points in \(X\cup Y\cup Z\) whose coefficients \(i\) and \(j\) are both even, the result is a subdivided complete bipartite graph \(K_{n,n}\), where by “subdivided” I mean that each edge of \(K_{n,n}\) has been replaced by a two-edge path. This isn’t an interchange, in the sense of the previous post, but it has unbounded flip-width, because it is a sparse graph that does not have bounded expansion.</p>

<p>What I really want, though, is a 3d Euclidean Delaunay triangulation with unbounded flip-width, not a non-triangulation complex and not a 4-polytope (I already had one of those in my previous post). To get this, use a stereographic projection whose pole is on the central torus, in the middle of one of the squares (or really on the corresponding point of the unit sphere), and note that the Delaunay spheres of the polytope faces will intersect this torus in Delaunay circles of the squares. But for a square grid, the center of each square belongs only to the circumcircle of that square, not to any of the other circumcircles. So the pole of the projection will only belong to two of the Delaunay spheres, the two sharing the chosen square. The two prisms for these two spheres will be missing from the Delaunay complex (instead, their union, some sort of <a href="https://en.wikipedia.org/wiki/Gyrobifastigium">gyrobifastifium</a>, will form the convex hull of the points), but all the other prisms will still be present. They contain all the edges of the graph, so it still contains a large induced subdivided biclique. Perturbing the points slightly to get a triangulation rather than a complex doesn’t change this.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/109926574982696332">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-25T09:19:00Z">Saturday, February 25 2023, 09:19</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, February 24
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/24/postdoc-at-tu-eindhoven-university-of-amsterdam-leiden-university-cwi-apply-by-march-31-2023/'>postdoc at TU Eindhoven, University of Amsterdam, Leiden University, CWI (apply by March 31, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Postdoc Positions in Algorithmics and Stochastics, in the NETWORKS project (the Netherlands). The NETWORKS project is a collaboration of researchers from four institutions in The Netherlands: TU Eindhoven, University of Amsterdam, Leiden University and the Centrum Wiskunde &#38; Informatica (CWI). NETWORKS has openings for postdocs working on algorithmics or stochastics for network problems. Website: www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND- [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Postdoc Positions in Algorithmics and Stochastics, in the NETWORKS project (the Netherlands).</p>
<p>The NETWORKS project is a collaboration of researchers from four institutions in The Netherlands: TU Eindhoven, University of Amsterdam, Leiden University and the Centrum Wiskunde &amp; Informatica (CWI). NETWORKS has openings for postdocs working on algorithmics or stochastics for network problems.</p>
<p>Website: <a href="https://www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND-">https://www.thenetworkcenter.nl/Open-Positions/openposition/30/8-Postdoctoral-fellows-in-Stochastics-and-Algorithmics-COFUND-</a><br />
Email: info@thenetworkcenter.nl</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T12:53:26Z">Friday, February 24 2023, 12:53</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11578'>Guidable Local Hamiltonian Problems with Implications to Heuristic Ans\"atze State Preparation and the Quantum PCP Conjecture</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jordi Weggemans, Marten Folkertsma, Chris Cade</p><p>We introduce 'Merlinized' versions of the recently defined Guided Local
Hamiltonian problem, which we call 'Guidable Local Hamiltonian' problems.
Unlike their guided counterparts, these problems do not have a guiding state
provided as a part of the input, but merely come with the promise that one
exists and that it satisfies certain constraints. We consider in particular two
classes of guiding states: those that can be prepared efficiently by a quantum
circuit; and those belonging to a class of quantum states we call classically
evaluatable, which have a short classical description from which it is possible
to efficiently compute expectation values of local observables classically. We
show that guidable local Hamiltonian problems for both classes of guiding
states are $\mathsf{QCMA}$-complete in the inverse-polynomial precision
setting, but lie within $\mathsf{NP}$ (or $\mathsf{NqP}$) in certain parameter
regimes when the guiding state is classically evaluatable.
</p>
<p>We discuss the implications of these results to heuristic ans\"atze state
preparation and the quantum PCP conjecture. Our completeness results show that,
from a complexity-theoretic perspective, classical ans\"atze prepared by
classical heuristics are just as powerful as quantum ans\"atze prepared by
quantum heuristics, so long as one has access to quantum phase estimation. In
relation to the quantum PCP conjecture, we (i) define a PCP for $\mathsf{QCMA}$
and show that it is equal to $\mathsf{NP}$ under quantum reductions; (ii) show
several no-go results for the existence of quantum gap amplification procedures
that preserve certain ground state properties; and (iii) propose two
conjectures that can be viewed as stronger versions of the NLTS theorem.
Finally, we show that many of our results can be directly modified to obtain
similar results for the class $\mathsf{MA}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Weggemans_J/0/1/0/all/0/1">Jordi Weggemans</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Folkertsma_M/0/1/0/all/0/1">Marten Folkertsma</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Cade_C/0/1/0/all/0/1">Chris Cade</a></p><p>We introduce 'Merlinized' versions of the recently defined Guided Local
Hamiltonian problem, which we call 'Guidable Local Hamiltonian' problems.
Unlike their guided counterparts, these problems do not have a guiding state
provided as a part of the input, but merely come with the promise that one
exists and that it satisfies certain constraints. We consider in particular two
classes of guiding states: those that can be prepared efficiently by a quantum
circuit; and those belonging to a class of quantum states we call classically
evaluatable, which have a short classical description from which it is possible
to efficiently compute expectation values of local observables classically. We
show that guidable local Hamiltonian problems for both classes of guiding
states are $\mathsf{QCMA}$-complete in the inverse-polynomial precision
setting, but lie within $\mathsf{NP}$ (or $\mathsf{NqP}$) in certain parameter
regimes when the guiding state is classically evaluatable.
</p>
<p>We discuss the implications of these results to heuristic ans\"atze state
preparation and the quantum PCP conjecture. Our completeness results show that,
from a complexity-theoretic perspective, classical ans\"atze prepared by
classical heuristics are just as powerful as quantum ans\"atze prepared by
quantum heuristics, so long as one has access to quantum phase estimation. In
relation to the quantum PCP conjecture, we (i) define a PCP for $\mathsf{QCMA}$
and show that it is equal to $\mathsf{NP}$ under quantum reductions; (ii) show
several no-go results for the existence of quantum gap amplification procedures
that preserve certain ground state properties; and (iii) propose two
conjectures that can be viewed as stronger versions of the NLTS theorem.
Finally, we show that many of our results can be directly modified to obtain
similar results for the class $\mathsf{MA}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11667'>Cutting Barnette graphs perfectly is hard</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: &#xc9;douard Bonnet, Dibyayan Chakraborty, Julien Duron</p><p>A perfect matching cut is a perfect matching that is also a cutset, or
equivalently a perfect matching containing an even number of edges on every
cycle. The corresponding algorithmic problem, Perfect Matching Cut, is known to
be NP-complete in subcubic bipartite graphs [Le &amp; Telle, TCS '22] but its
complexity was open in planar graphs and in cubic graphs. We settle both
questions at once by showing that Perfect Matching Cut is NP-complete in
3-connected cubic bipartite planar graphs or Barnette graphs. Prior to our
work, among problems whose input is solely an undirected graph, only Distance-2
4-Coloring was known NP-complete in Barnette graphs. Notably, Hamiltonian Cycle
would only join this private club if Barnette's conjecture were refuted.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1">&#xc9;douard Bonnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1">Dibyayan Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Duron_J/0/1/0/all/0/1">Julien Duron</a></p><p>A perfect matching cut is a perfect matching that is also a cutset, or
equivalently a perfect matching containing an even number of edges on every
cycle. The corresponding algorithmic problem, Perfect Matching Cut, is known to
be NP-complete in subcubic bipartite graphs [Le &amp; Telle, TCS '22] but its
complexity was open in planar graphs and in cubic graphs. We settle both
questions at once by showing that Perfect Matching Cut is NP-complete in
3-connected cubic bipartite planar graphs or Barnette graphs. Prior to our
work, among problems whose input is solely an undirected graph, only Distance-2
4-Coloring was known NP-complete in Barnette graphs. Notably, Hamiltonian Cycle
would only join this private club if Barnette's conjecture were refuted.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11637'>Hitting Sets when the Shallow Cell Complexity is Small</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sander Aarts, David B. Shmoys</p><p>The hitting set problem is a well-known NP-hard optimization problem in
which, given a set of elements and a collection of subsets, the goal is to find
the smallest selection of elements, such that each subset contains at least one
element in the selection. Many geometric set systems enjoy improved
approximation ratios, which have recently been shown to be tight with respect
to the shallow cell complexity of the set system. The algorithms that exploit
the cell complexity, however, tend to be involved and computationally
intensive. This paper shows that comparable approximation ratios for the
hitting set problem can be attained using a much simpler algorithm: solve the
linear programming relaxation, take one initial random sample from the set of
elements with probabilities proportional to the LP-solution, and, while there
is an unhit set, take an additional sample from it proportional to the
LP-solution. Our algorithm is based on a generalization of the elegant
net-finder algorithm of Nabil Mustafa. To analyze this algorithm for the
hitting set problem, we generalize the classic Packing Lemma, and the more
recent Shallow-Packing Lemma, to the setting of weighted epsilon nets.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Aarts_S/0/1/0/all/0/1">Sander Aarts</a>, <a href="http://arxiv.org/find/cs/1/au:+Shmoys_D/0/1/0/all/0/1">David B. Shmoys</a></p><p>The hitting set problem is a well-known NP-hard optimization problem in
which, given a set of elements and a collection of subsets, the goal is to find
the smallest selection of elements, such that each subset contains at least one
element in the selection. Many geometric set systems enjoy improved
approximation ratios, which have recently been shown to be tight with respect
to the shallow cell complexity of the set system. The algorithms that exploit
the cell complexity, however, tend to be involved and computationally
intensive. This paper shows that comparable approximation ratios for the
hitting set problem can be attained using a much simpler algorithm: solve the
linear programming relaxation, take one initial random sample from the set of
elements with probabilities proportional to the LP-solution, and, while there
is an unhit set, take an additional sample from it proportional to the
LP-solution. Our algorithm is based on a generalization of the elegant
net-finder algorithm of Nabil Mustafa. To analyze this algorithm for the
hitting set problem, we generalize the classic Packing Lemma, and the more
recent Shallow-Packing Lemma, to the setting of weighted epsilon nets.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11767'>Adaptive Approximate Implicitization of Planar Parametric Curves via Weak Gradient Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Minghao Guo, Yan Gao, Zheng Pan</p><p>Converting a parametric curve into the implicit form, which is called
implicitization, has always been a popular but challenging problem in geometric
modeling and related applications. However, the existing methods mostly suffer
from the problems of maintaining geometric features and choosing a reasonable
implicit degree. The present paper has two contributions. We first introduce a
new regularization constraint(called the weak gradient constraint) for both
polynomial and non-polynomial curves, which efficiently possesses shape
preserving. We then propose two adaptive algorithms of approximate
implicitization for polynomial and non-polynomial curves respectively, which
find the ``optimal'' implicit degree based on the behavior of the weak gradient
constraint. More precisely, the idea is gradually increasing the implicit
degree, until there is no obvious improvement in the weak gradient loss of the
outputs. Experimental results have shown the effectiveness and high quality of
our proposed methods.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Minghao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zheng Pan</a></p><p>Converting a parametric curve into the implicit form, which is called
implicitization, has always been a popular but challenging problem in geometric
modeling and related applications. However, the existing methods mostly suffer
from the problems of maintaining geometric features and choosing a reasonable
implicit degree. The present paper has two contributions. We first introduce a
new regularization constraint(called the weak gradient constraint) for both
polynomial and non-polynomial curves, which efficiently possesses shape
preserving. We then propose two adaptive algorithms of approximate
implicitization for polynomial and non-polynomial curves respectively, which
find the ``optimal'' implicit degree based on the behavior of the weak gradient
constraint. More precisely, the idea is gradually increasing the implicit
degree, until there is no obvious improvement in the weak gradient loss of the
outputs. Experimental results have shown the effectiveness and high quality of
our proposed methods.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11922'>Translation of "Simplizialzerlegungen von Beschrankter Flachheit'' by Hans Freudenthal, Annals of Mathematics, Second Series, Volume 43, Number 3, July 1942, Pages 580-583</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mathijs Wintraecken (translator)</p><p>Translation of the paper ``Simplizialzerlegungen von Beschrankter Flachheit''
by Hans Freudenthal (doi.org/10.2307/1968813), in which Freudenthal
answers ``a question by Brouwer about the construction of an infinite series of
subdivisions of a polytope, such that the next element in the sequence is a
subdivision of the previous one and such that the subsimplices that arise do
not become arbitrarily flat.''
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Wintraecken_M/0/1/0/all/0/1">Mathijs Wintraecken</a> (translator)</p><p>Translation of the paper ``Simplizialzerlegungen von Beschrankter Flachheit''
by Hans Freudenthal (https://doi.org/10.2307/1968813), in which Freudenthal
answers ``a question by Brouwer about the construction of an infinite series of
subdivisions of a polytope, such that the next element in the sequence is a
subdivision of the previous one and such that the subsimplices that arise do
not become arbitrarily flat.''
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12219'>Certified Polyhedral Decompositions of Collision-Free Configuration Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hongkai Dai, Alexandre Amice, Peter Werner, Annan Zhang, Russ Tedrake</p><p>Understanding the geometry of collision-free configuration space (C-free) in
the presence of task-space obstacles is an essential ingredient for
collision-free motion planning. While it is possible to check for collisions at
a point using standard algorithms, to date no practical method exists for
computing C-free regions with rigorous certificates due to the complexity of
mapping task-space obstacles through the kinematics. In this work, we present
the first to our knowledge rigorous method for approximately decomposing a
rational parametrization of C-free into certified polyhedral regions. Our
method, called C-IRIS (C-space Iterative Regional Inflation by Semidefinite
programming), generates large, convex polytopes in a rational parameterization
of the configuration space which are rigorously certified to be collision-free.
Such regions have been shown to be useful for both optimization-based and
randomized motion planning. Based on convex optimization, our method works in
arbitrary dimensions, only makes assumptions about the convexity of the
obstacles in the task space, and is fast enough to scale to realistic problems
in manipulation. We demonstrate our algorithm's ability to fill a non-trivial
amount of collision-free C-space in several 2-DOF examples where the C-space
can be visualized, as well as the scalability of our algorithm on a 7-DOF KUKA
iiwa, a 6-DOF UR3e and 12-DOF bimanual manipulators. An implementation of our
algorithm is open-sourced in Drake. We furthermore provide examples of our
algorithm in interactive Python notebooks.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hongkai Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Amice_A/0/1/0/all/0/1">Alexandre Amice</a>, <a href="http://arxiv.org/find/cs/1/au:+Werner_P/0/1/0/all/0/1">Peter Werner</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Annan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tedrake_R/0/1/0/all/0/1">Russ Tedrake</a></p><p>Understanding the geometry of collision-free configuration space (C-free) in
the presence of task-space obstacles is an essential ingredient for
collision-free motion planning. While it is possible to check for collisions at
a point using standard algorithms, to date no practical method exists for
computing C-free regions with rigorous certificates due to the complexity of
mapping task-space obstacles through the kinematics. In this work, we present
the first to our knowledge rigorous method for approximately decomposing a
rational parametrization of C-free into certified polyhedral regions. Our
method, called C-IRIS (C-space Iterative Regional Inflation by Semidefinite
programming), generates large, convex polytopes in a rational parameterization
of the configuration space which are rigorously certified to be collision-free.
Such regions have been shown to be useful for both optimization-based and
randomized motion planning. Based on convex optimization, our method works in
arbitrary dimensions, only makes assumptions about the convexity of the
obstacles in the task space, and is fast enough to scale to realistic problems
in manipulation. We demonstrate our algorithm's ability to fill a non-trivial
amount of collision-free C-space in several 2-DOF examples where the C-space
can be visualized, as well as the scalability of our algorithm on a 7-DOF KUKA
iiwa, a 6-DOF UR3e and 12-DOF bimanual manipulators. An implementation of our
algorithm is open-sourced in Drake. We furthermore provide examples of our
algorithm in interactive Python notebooks.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11821'>Storage in Computational Geometry</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yijie Han, Sanjeev Saxena</p><p>We show that $n$ real numbers can be stored in a constant number of real
numbers such that each original real number can be fetched in $O(\log n)$ time.
</p>
<p>Although our result has implications for many computational geometry
problems, we show here, combined with Han's $O(n\sqrt{\log n})$ time real
number sorting algorithm [3, arXiv:1801.00776], we can improve the complexity
of Kirkpatrick's point location algorithm [8] to $O(n\sqrt{\log n})$
preprocessing time, a constant number of real numbers for storage and $O(\log
n)$ point location time. Kirkpatrick's algorithm uses $O(n\log n)$
preprocessing time, $O(n)$ storage and $O(\log n)$ point location time. The
complexity results in Kirkpatrick's algorithm was the previous best result.
Although Lipton and Tarjan's algorithm [10] predates Kirkpatrick's algorithm
and has the same complexity, Kirkpatrick's algorithm is simpler and has a
better structure.
</p>
<p>This paper can be viewed as a companion paper of paper [3, arXiv:1801.00776].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yijie Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1">Sanjeev Saxena</a></p><p>We show that $n$ real numbers can be stored in a constant number of real
numbers such that each original real number can be fetched in $O(\log n)$ time.
</p>
<p>Although our result has implications for many computational geometry
problems, we show here, combined with Han's $O(n\sqrt{\log n})$ time real
number sorting algorithm [3, <a href="/abs/1801.00776">arXiv:1801.00776</a>], we can improve the complexity
of Kirkpatrick's point location algorithm [8] to $O(n\sqrt{\log n})$
preprocessing time, a constant number of real numbers for storage and $O(\log
n)$ point location time. Kirkpatrick's algorithm uses $O(n\log n)$
preprocessing time, $O(n)$ storage and $O(\log n)$ point location time. The
complexity results in Kirkpatrick's algorithm was the previous best result.
Although Lipton and Tarjan's algorithm [10] predates Kirkpatrick's algorithm
and has the same complexity, Kirkpatrick's algorithm is simpler and has a
better structure.
</p>
<p>This paper can be viewed as a companion paper of paper [3, <a href="/abs/1801.00776">arXiv:1801.00776</a>].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11619'>Pattern detection in ordered graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guillaume Ducoffe, Laurent Feuilloley, Michel Habib, Fran&#xe7;ois Pitois</p><p>A popular way to define or characterize graph classes is via forbidden
subgraphs or forbidden minors. These characterizations play a key role in graph
theory, but they rarely lead to efficient algorithms to recognize these
classes. In contrast, many essential graph classes can be recognized
efficiently thanks to characterizations of the following form: there must exist
an ordering of the vertices such that some ordered pattern does not appear,
where a pattern is basically an ordered subgraph. These pattern
characterizations have been studied for decades, but there have been recent
efforts to better understand them systematically. In this paper, we focus on a
simple problem at the core of this topic: given an ordered graph of size $n$,
how fast can we detect whether a fixed pattern of size $k$ is present?
</p>
<p>Following the literature on graph classes recognition, we first look for
patterns that can be detected in linear time. We prove, among other results,
that almost all patterns on three vertices (which capture many interesting
classes, such as interval, chordal, split, bipartite, and comparability graphs)
fall in this category. Then, in a finer-grained complexity perspective, we
prove conditional lower bounds for this problem. In particular we show that for
a large family of patterns on four vertices it is unlikely that subquadratic
algorithm exist. Finally, we define a parameter for patterns, the merge-width,
and prove that for patterns of merge-width $t$, one can solve the problem in
$O(n^{ct})$ for some constant~$c$. As a corollary, we get that detecting
outerplanar patterns and other classes of patterns can be done in time
independent of the size of the pattern.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ducoffe_G/0/1/0/all/0/1">Guillaume Ducoffe</a>, <a href="http://arxiv.org/find/cs/1/au:+Feuilloley_L/0/1/0/all/0/1">Laurent Feuilloley</a>, <a href="http://arxiv.org/find/cs/1/au:+Habib_M/0/1/0/all/0/1">Michel Habib</a>, <a href="http://arxiv.org/find/cs/1/au:+Pitois_F/0/1/0/all/0/1">Fran&#xe7;ois Pitois</a></p><p>A popular way to define or characterize graph classes is via forbidden
subgraphs or forbidden minors. These characterizations play a key role in graph
theory, but they rarely lead to efficient algorithms to recognize these
classes. In contrast, many essential graph classes can be recognized
efficiently thanks to characterizations of the following form: there must exist
an ordering of the vertices such that some ordered pattern does not appear,
where a pattern is basically an ordered subgraph. These pattern
characterizations have been studied for decades, but there have been recent
efforts to better understand them systematically. In this paper, we focus on a
simple problem at the core of this topic: given an ordered graph of size $n$,
how fast can we detect whether a fixed pattern of size $k$ is present?
</p>
<p>Following the literature on graph classes recognition, we first look for
patterns that can be detected in linear time. We prove, among other results,
that almost all patterns on three vertices (which capture many interesting
classes, such as interval, chordal, split, bipartite, and comparability graphs)
fall in this category. Then, in a finer-grained complexity perspective, we
prove conditional lower bounds for this problem. In particular we show that for
a large family of patterns on four vertices it is unlikely that subquadratic
algorithm exist. Finally, we define a parameter for patterns, the merge-width,
and prove that for patterns of merge-width $t$, one can solve the problem in
$O(n^{ct})$ for some constant~$c$. As a corollary, we get that detecting
outerplanar patterns and other classes of patterns can be done in time
independent of the size of the pattern.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11651'>Finding a Small Vertex Cut on Distributed Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yonggang Jiang, Sagnik Mukhopadhyay</p><p>We present an algorithm for distributed networks to efficiently find a small
vertex cut in the CONGEST model. Given a positive integer $\kappa$, our
algorithm can, with high probability, either find $\kappa$ vertices whose
removal disconnects the network or return that such $\kappa$ vertices do not
exist. Our algorithm takes $\kappa^3\cdot \tilde{O}(D+\sqrt{n})$ rounds, where
$n$ is the number of vertices in the network and $D$ denotes the network's
diameter. This implies $\tilde{O}(D+\sqrt{n})$ round complexity whenever
$\kappa=\text{polylog}(n)$.
</p>
<p>Prior to our result, a bound of $\tilde{O}(D)$ is known only when
$\kappa=1,2$ [Parter, Petruschka DISC'22]. For $\kappa\geq 3$, this bound can
be obtained only by an $O(\log n)$-approximation algorithm [Censor-Hillel,
Ghaffari, Kuhn PODC'14], and the only known exact algorithm takes
$O\left((\kappa\Delta D)^{O(\kappa)}\right)$ rounds, where $\Delta$ is the
maximum degree [Parter DISC'19]. Our result answers an open problem by
Nanongkai, Saranurak, and Yingchareonthawornchai [STOC'19].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yonggang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukhopadhyay_S/0/1/0/all/0/1">Sagnik Mukhopadhyay</a></p><p>We present an algorithm for distributed networks to efficiently find a small
vertex cut in the CONGEST model. Given a positive integer $\kappa$, our
algorithm can, with high probability, either find $\kappa$ vertices whose
removal disconnects the network or return that such $\kappa$ vertices do not
exist. Our algorithm takes $\kappa^3\cdot \tilde{O}(D+\sqrt{n})$ rounds, where
$n$ is the number of vertices in the network and $D$ denotes the network's
diameter. This implies $\tilde{O}(D+\sqrt{n})$ round complexity whenever
$\kappa=\text{polylog}(n)$.
</p>
<p>Prior to our result, a bound of $\tilde{O}(D)$ is known only when
$\kappa=1,2$ [Parter, Petruschka DISC'22]. For $\kappa\geq 3$, this bound can
be obtained only by an $O(\log n)$-approximation algorithm [Censor-Hillel,
Ghaffari, Kuhn PODC'14], and the only known exact algorithm takes
$O\left((\kappa\Delta D)^{O(\kappa)}\right)$ rounds, where $\Delta$ is the
maximum degree [Parter DISC'19]. Our result answers an open problem by
Nanongkai, Saranurak, and Yingchareonthawornchai [STOC'19].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11829'>Learning to Manipulate a Commitment Optimizer</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yurong Chen, Xiaotie Deng, Jiarui Gan, Yuhao Li</p><p>It is shown in recent studies that in a Stackelberg game the follower can
manipulate the leader by deviating from their true best-response behavior. Such
manipulations are computationally tractable and can be highly beneficial for
the follower. Meanwhile, they may result in significant payoff losses for the
leader, sometimes completely defeating their first-mover advantage. A warning
to commitment optimizers, the risk these findings indicate appears to be
alleviated to some extent by a strict information advantage the manipulations
rely on. That is, the follower knows the full information about both players'
payoffs whereas the leader only knows their own payoffs. In this paper, we
study the manipulation problem with this information advantage relaxed. We
consider the scenario where the follower is not given any information about the
leader's payoffs to begin with but has to learn to manipulate by interacting
with the leader. The follower can gather necessary information by querying the
leader's optimal commitments against contrived best-response behaviors. Our
results indicate that the information advantage is not entirely indispensable
to the follower's manipulations: the follower can learn the optimal way to
manipulate in polynomial time with polynomially many queries of the leader's
optimal commitment.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yurong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1">Xiaotie Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_J/0/1/0/all/0/1">Jiarui Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhao Li</a></p><p>It is shown in recent studies that in a Stackelberg game the follower can
manipulate the leader by deviating from their true best-response behavior. Such
manipulations are computationally tractable and can be highly beneficial for
the follower. Meanwhile, they may result in significant payoff losses for the
leader, sometimes completely defeating their first-mover advantage. A warning
to commitment optimizers, the risk these findings indicate appears to be
alleviated to some extent by a strict information advantage the manipulations
rely on. That is, the follower knows the full information about both players'
payoffs whereas the leader only knows their own payoffs. In this paper, we
study the manipulation problem with this information advantage relaxed. We
consider the scenario where the follower is not given any information about the
leader's payoffs to begin with but has to learn to manipulate by interacting
with the leader. The follower can gather necessary information by querying the
leader's optimal commitments against contrived best-response behaviors. Our
results indicate that the information advantage is not entirely indispensable
to the follower's manipulations: the follower can learn the optimal way to
manipulate in polynomial time with polynomially many queries of the leader's
optimal commitment.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11838'>Minimum-Entropy Coupling Approximation Guarantees Beyond the Majorization Barrier</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Spencer Compton, Dmitriy Katz, Benjamin Qi, Kristjan Greenewald, Murat Kocaoglu</p><p>Given a set of discrete probability distributions, the minimum entropy
coupling is the minimum entropy joint distribution that has the input
distributions as its marginals. This has immediate relevance to tasks such as
entropic causal inference for causal graph discovery and bounding mutual
information between variables that we observe separately. Since finding the
minimum entropy coupling is NP-Hard, various works have studied approximation
algorithms. The work of [Compton, ISIT 2022] shows that the greedy coupling
algorithm of [Kocaoglu et al., AAAI 2017] is always within $log_2(e) \approx
1.44$ bits of the optimal coupling. Moreover, they show that it is impossible
to obtain a better approximation guarantee using the majorization lower-bound
that all prior works have used: thus establishing a majorization barrier. In
this work, we break the majorization barrier by designing a stronger
lower-bound that we call the profile method. Using this profile method, we are
able to show that the greedy algorithm is always within $log_2(e)/e \approx
0.53$ bits of optimal for coupling two distributions (previous best-known bound
is within 1 bit), and within $(1 + log_2(e))/2 \approx 1.22$ bits for coupling
any number of distributions (previous best-known bound is within 1.44 bits). We
also examine a generalization of the minimum entropy coupling problem: Concave
Minimum-Cost Couplings. We are able to obtain similar guarantees for this
generalization in terms of the concave cost function. Additionally, we make
progress on the open problem of [Kova\v{c}evi\'c et al., Inf. Comput. 2015]
regarding NP membership of the minimum entropy coupling problem by showing that
any hardness of minimum entropy coupling beyond NP comes from the difficulty of
computing arithmetic in the complexity class NP. Finally, we present
exponential-time algorithms for computing the exactly optimal solution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Compton_S/0/1/0/all/0/1">Spencer Compton</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_D/0/1/0/all/0/1">Dmitriy Katz</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_B/0/1/0/all/0/1">Benjamin Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Greenewald_K/0/1/0/all/0/1">Kristjan Greenewald</a>, <a href="http://arxiv.org/find/cs/1/au:+Kocaoglu_M/0/1/0/all/0/1">Murat Kocaoglu</a></p><p>Given a set of discrete probability distributions, the minimum entropy
coupling is the minimum entropy joint distribution that has the input
distributions as its marginals. This has immediate relevance to tasks such as
entropic causal inference for causal graph discovery and bounding mutual
information between variables that we observe separately. Since finding the
minimum entropy coupling is NP-Hard, various works have studied approximation
algorithms. The work of [Compton, ISIT 2022] shows that the greedy coupling
algorithm of [Kocaoglu et al., AAAI 2017] is always within $log_2(e) \approx
1.44$ bits of the optimal coupling. Moreover, they show that it is impossible
to obtain a better approximation guarantee using the majorization lower-bound
that all prior works have used: thus establishing a majorization barrier. In
this work, we break the majorization barrier by designing a stronger
lower-bound that we call the profile method. Using this profile method, we are
able to show that the greedy algorithm is always within $log_2(e)/e \approx
0.53$ bits of optimal for coupling two distributions (previous best-known bound
is within 1 bit), and within $(1 + log_2(e))/2 \approx 1.22$ bits for coupling
any number of distributions (previous best-known bound is within 1.44 bits). We
also examine a generalization of the minimum entropy coupling problem: Concave
Minimum-Cost Couplings. We are able to obtain similar guarantees for this
generalization in terms of the concave cost function. Additionally, we make
progress on the open problem of [Kova\v{c}evi\'c et al., Inf. Comput. 2015]
regarding NP membership of the minimum entropy coupling problem by showing that
any hardness of minimum entropy coupling beyond NP comes from the difficulty of
computing arithmetic in the complexity class NP. Finally, we present
exponential-time algorithms for computing the exactly optimal solution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11902'>On price-induced minmax matchings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Christoph D&#xfc;rr, Mathieu Mari, Ulrike Schmidt-Kraepelin</p><p>We study a natural combinatorial pricing problem for sequentially arriving
buyers with equal budgets. Each buyer is interested in exactly one pair of
items and purchases this pair if and only if, upon arrival, both items are
still available and the sum of the item prices does not exceed the budget. The
goal of the seller is to set prices to the items such that the number of
transactions is maximized when buyers arrive in adversarial order.
</p>
<p>Formally, we are given an undirected graph where vertices represent items and
edges represent buyers. Once prices are set to the vertices, edges with a total
price exceeding the buyers' budgets are evicted. Any arrival order of the
buyers leads to a set of transactions that forms a maximal matching in this
subgraph, and an adversarial arrival order results in a minimum maximal
matching. In order to measure the performance of a pricing strategy, we compare
the size of such a matching to the size of a maximum matching in the original
graph. It was shown by Correa et al. [IPCO 2022] that the best ratio any
pricing strategy can guarantee lies within $[1/2, 2/3]$. Our contribution to
the problem is two-fold: First, we provide several characterizations of
subgraphs that may result from pricing schemes. Second, building upon these, we
show an improved upper bound of $3/5$ and a lower bound of $1/2 + 2/n$, where
$n$ is the number of items.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Durr_C/0/1/0/all/0/1">Christoph D&#xfc;rr</a>, <a href="http://arxiv.org/find/cs/1/au:+Mari_M/0/1/0/all/0/1">Mathieu Mari</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_Kraepelin_U/0/1/0/all/0/1">Ulrike Schmidt-Kraepelin</a></p><p>We study a natural combinatorial pricing problem for sequentially arriving
buyers with equal budgets. Each buyer is interested in exactly one pair of
items and purchases this pair if and only if, upon arrival, both items are
still available and the sum of the item prices does not exceed the budget. The
goal of the seller is to set prices to the items such that the number of
transactions is maximized when buyers arrive in adversarial order.
</p>
<p>Formally, we are given an undirected graph where vertices represent items and
edges represent buyers. Once prices are set to the vertices, edges with a total
price exceeding the buyers' budgets are evicted. Any arrival order of the
buyers leads to a set of transactions that forms a maximal matching in this
subgraph, and an adversarial arrival order results in a minimum maximal
matching. In order to measure the performance of a pricing strategy, we compare
the size of such a matching to the size of a maximum matching in the original
graph. It was shown by Correa et al. [IPCO 2022] that the best ratio any
pricing strategy can guarantee lies within $[1/2, 2/3]$. Our contribution to
the problem is two-fold: First, we provide several characterizations of
subgraphs that may result from pricing schemes. Second, building upon these, we
show an improved upper bound of $3/5$ and a lower bound of $1/2 + 2/n$, where
$n$ is the number of items.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11952'>Simultaneous Drawing of Layered Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Julia Katheder, Stephen G. Kobourov, Axel Kuckuk, Maximilian Pfister, Johannes Zink</p><p>We study the crossing minimization problem in a layered graph drawing of
rooted trees whose leaves have a given fixed order on the first layer. The task
is to permute the vertices on the other layers to minimize the number of
crossings. While this problem is known to be NP-hard for multiple trees even on
just two layers, we give a polynomial-time algorithm for the restricted case of
two trees. On the other hand, when restricting the number of layers to three,
we describe an XP-algorithm in the number of trees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Katheder_J/0/1/0/all/0/1">Julia Katheder</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobourov_S/0/1/0/all/0/1">Stephen G. Kobourov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuckuk_A/0/1/0/all/0/1">Axel Kuckuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_M/0/1/0/all/0/1">Maximilian Pfister</a>, <a href="http://arxiv.org/find/cs/1/au:+Zink_J/0/1/0/all/0/1">Johannes Zink</a></p><p>We study the crossing minimization problem in a layered graph drawing of
rooted trees whose leaves have a given fixed order on the first layer. The task
is to permute the vertices on the other layers to minimize the number of
crossings. While this problem is known to be NP-hard for multiple trees even on
just two layers, we give a polynomial-time algorithm for the restricted case of
two trees. On the other hand, when restricting the number of layers to three,
we describe an XP-algorithm in the number of trees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11971'>Efficiently handling constraints with Metropolis-adjusted Langevin algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jinyuan Chang, Cheng Yong Tang, Yuanzheng Zhu</p><p>In this study, we investigate the performance of the Metropolis-adjusted
Langevin algorithm in a setting with constraints on the support of the target
distribution. We provide a rigorous analysis of the resulting Markov chain,
establishing its convergence and deriving an upper bound for its mixing time.
Our results demonstrate that the Metropolis-adjusted Langevin algorithm is
highly effective in handling this challenging situation: the mixing time bound
we obtain is superior to the best known bounds for competing algorithms without
an accept-reject step. Our numerical experiments support these theoretical
findings, indicating that the Metropolis-adjusted Langevin algorithm shows
promising performance when dealing with constraints on the support of the
target distribution.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Chang_J/0/1/0/all/0/1">Jinyuan Chang</a>, <a href="http://arxiv.org/find/stat/1/au:+Tang_C/0/1/0/all/0/1">Cheng Yong Tang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1">Yuanzheng Zhu</a></p><p>In this study, we investigate the performance of the Metropolis-adjusted
Langevin algorithm in a setting with constraints on the support of the target
distribution. We provide a rigorous analysis of the resulting Markov chain,
establishing its convergence and deriving an upper bound for its mixing time.
Our results demonstrate that the Metropolis-adjusted Langevin algorithm is
highly effective in handling this challenging situation: the mixing time bound
we obtain is superior to the best known bounds for competing algorithms without
an accept-reject step. Our numerical experiments support these theoretical
findings, indicating that the Metropolis-adjusted Langevin algorithm shows
promising performance when dealing with constraints on the support of the
target distribution.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12029'>Online Minimum Spanning Trees with Weight Predictions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Magnus Berg, Joan Boyar, Lene M. Favrholdt, Kim S. Larsen</p><p>We consider the minimum spanning tree problem with predictions, using the
weight-arrival model, i.e., the graph is given, together with predictions for
the weights of all edges. Then the actual weights arrive one at a time and an
irrevocable decision must be made regarding whether or not the edge should be
included into the spanning tree. In order to assess the quality of our
algorithms, we define an appropriate error measure and analyze the performance
of the algorithms as a function of the error. We prove that, according to
competitive analysis, the simplest algorithm, Follow-the-Predictions, is
optimal. However, intuitively, one should be able to do better, and we present
a greedy variant of Follow-the-Predictions. In analyzing that algorithm, we
believe we present the first random order analysis of a non-trivial online
algorithm with predictions, by which we obtain an algorithmic separation. This
may be useful for distinguishing between algorithms for other problems when
Follow-the-Predictions is optimal according to competitive analysis.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berg_M/0/1/0/all/0/1">Magnus Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyar_J/0/1/0/all/0/1">Joan Boyar</a>, <a href="http://arxiv.org/find/cs/1/au:+Favrholdt_L/0/1/0/all/0/1">Lene M. Favrholdt</a>, <a href="http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1">Kim S. Larsen</a></p><p>We consider the minimum spanning tree problem with predictions, using the
weight-arrival model, i.e., the graph is given, together with predictions for
the weights of all edges. Then the actual weights arrive one at a time and an
irrevocable decision must be made regarding whether or not the edge should be
included into the spanning tree. In order to assess the quality of our
algorithms, we define an appropriate error measure and analyze the performance
of the algorithms as a function of the error. We prove that, according to
competitive analysis, the simplest algorithm, Follow-the-Predictions, is
optimal. However, intuitively, one should be able to do better, and we present
a greedy variant of Follow-the-Predictions. In analyzing that algorithm, we
believe we present the first random order analysis of a non-trivial online
algorithm with predictions, by which we obtain an algorithmic separation. This
may be useful for distinguishing between algorithms for other problems when
Follow-the-Predictions is optimal according to competitive analysis.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12081'>A simple division-free algorithm for computing Pfaffians</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam J. Przezdziecki</p><p>We present a very simple algorithm for computing Pfaffians which uses no
division operations. Essentially, it amounts to iterating matrix multiplication
and truncation. Its complexity, for a $2n\times 2n$ matrix, is $O(nM(n))$,
where $M(n)$ is the cost of matrix multiplication. In case of a sparse matrix,
$M(n)$ is the cost of the dense-sparse matrix multiplication.
</p>
<p>The algorithm is an adaptation of the Bird algorithm for determinants. We
show how to extract, with practically no additional work, the characteristic
polynomial and the Pfaffian characteristic polynomial from these algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Przezdziecki_A/0/1/0/all/0/1">Adam J. Przezdziecki</a></p><p>We present a very simple algorithm for computing Pfaffians which uses no
division operations. Essentially, it amounts to iterating matrix multiplication
and truncation. Its complexity, for a $2n\times 2n$ matrix, is $O(nM(n))$,
where $M(n)$ is the cost of matrix multiplication. In case of a sparse matrix,
$M(n)$ is the cost of the dense-sparse matrix multiplication.
</p>
<p>The algorithm is an adaptation of the Bird algorithm for determinants. We
show how to extract, with practically no additional work, the characteristic
polynomial and the Pfaffian characteristic polynomial from these algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12136'>Warehouse Problem with Bounds, Fixed Costs and Complementarity Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ishan Bansal, Oktay G&#xfc;nl&#xfc;k</p><p>This paper studies an open question in the warehouse problem where a merchant
trading a commodity tries to find an optimal inventory-trading policy to decide
on purchase and sale quantities during a fixed time horizon in order to
maximize their total pay-off, making use of fluctuations in sale and cost
prices. We provide the first known polynomial-time algorithms for the case when
there are fixed costs for purchases and sales, optional complementarity
constraints that prohibit purchasing and selling during the same time period,
and bounds on purchase and sales quantities. We do so by providing an exact
characterization of the extreme points of the feasible region and using this to
construct a suitable network where a min-cost flow computation provides an
optimal solution. We are also able to provide polynomial extended linear
formulations for the original feasible regions. Our methods build on the work
by Wolsey and Yaman (Discrete Optimization 2018). We also consider the problem
without fixed costs and provide a fully polynomial time approximation scheme in
a setting with time-dependent bounds.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bansal_I/0/1/0/all/0/1">Ishan Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunluk_O/0/1/0/all/0/1">Oktay G&#xfc;nl&#xfc;k</a></p><p>This paper studies an open question in the warehouse problem where a merchant
trading a commodity tries to find an optimal inventory-trading policy to decide
on purchase and sale quantities during a fixed time horizon in order to
maximize their total pay-off, making use of fluctuations in sale and cost
prices. We provide the first known polynomial-time algorithms for the case when
there are fixed costs for purchases and sales, optional complementarity
constraints that prohibit purchasing and selling during the same time period,
and bounds on purchase and sales quantities. We do so by providing an exact
characterization of the extreme points of the feasible region and using this to
construct a suitable network where a min-cost flow computation provides an
optimal solution. We are also able to provide polynomial extended linear
formulations for the original feasible regions. Our methods build on the work
by Wolsey and Yaman (Discrete Optimization 2018). We also consider the problem
without fixed costs and provide a fully polynomial time approximation scheme in
a setting with time-dependent bounds.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12201'>Dynamic Averaging Load Balancing on Arbitrary Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Petra Berenbrink, Lukas Hintze, Hamed Hosseinpour, Dominik Kaaser, Malin Rau</p><p>In this paper we study dynamic averaging load balancing on general graphs. We
consider infinite time and dynamic processes, where in every step new load
items are assigned to randomly chosen nodes. A matching is chosen, and the load
is averaged over the edges of that matching. We analyze the discrete case where
load items are indivisible, moreover our results also carry over to the
continuous case where load items can be split arbitrarily. For the choice of
the matchings we consider three different models, random matchings of linear
size, random matchings containing only single edges, and deterministic
sequences of matchings covering the whole graph. We bound the discrepancy,
which is defined as the difference between the maximum and the minimum load.
Our results cover a broad range of graph classes and, to the best of our
knowledge, our analysis is the first result for discrete and dynamic averaging
load balancing processes. As our main technical contribution we develop a drift
result that allows us to apply techniques based on the effective resistance in
an electrical network to the setting of dynamic load balancing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berenbrink_P/0/1/0/all/0/1">Petra Berenbrink</a>, <a href="http://arxiv.org/find/cs/1/au:+Hintze_L/0/1/0/all/0/1">Lukas Hintze</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseinpour_H/0/1/0/all/0/1">Hamed Hosseinpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaaser_D/0/1/0/all/0/1">Dominik Kaaser</a>, <a href="http://arxiv.org/find/cs/1/au:+Rau_M/0/1/0/all/0/1">Malin Rau</a></p><p>In this paper we study dynamic averaging load balancing on general graphs. We
consider infinite time and dynamic processes, where in every step new load
items are assigned to randomly chosen nodes. A matching is chosen, and the load
is averaged over the edges of that matching. We analyze the discrete case where
load items are indivisible, moreover our results also carry over to the
continuous case where load items can be split arbitrarily. For the choice of
the matchings we consider three different models, random matchings of linear
size, random matchings containing only single edges, and deterministic
sequences of matchings covering the whole graph. We bound the discrepancy,
which is defined as the difference between the maximum and the minimum load.
Our results cover a broad range of graph classes and, to the best of our
knowledge, our analysis is the first result for discrete and dynamic averaging
load balancing processes. As our main technical contribution we develop a drift
result that allows us to apply techniques based on the effective resistance in
an electrical network to the setting of dynamic load balancing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.12210'>Using Colors and Sketches to Count Subgraphs in a Streaming Graph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Shirin Handjani, Douglas Jungreis, Mark Tiefenbruck</p><p>Suppose we wish to estimate $\#H$, the number of copies of some small graph
$H$ in a large streaming graph $G$. There are many algorithms for this task
when $H$ is a triangle, but just a few that apply to arbitrary $H$. Here we
focus on one such algorithm, which was introduced by Kane, Mehlhorn, Sauerwald,
and Sun. The storage and update time per edge for their algorithm are both
$O(m^k/(\#H)^2)$, where $m$ is the number of edges in $G$, and $k$ is the
number of edges in $H$. Here, we propose three modifications to their algorithm
that can dramatically reduce both the storage and update time. Suppose that $H$
has no leaves and that $G$ has maximum degree $\leq m^{1/2 - \alpha}$, where
$\alpha &gt; 0$. Define $C = \min(m^{2\alpha},m^{1/3})$. Then in our version of
the algorithm, the update time per edge is $O(1)$, and the storage is
approximately reduced by a factor of $C^{2k-t-2}$, where $t$ is the number of
vertices in $H$; in particular, the storage is $O(C^2 + m^k/(C^{2k-t-2}
(\#H)^2))$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Handjani_S/0/1/0/all/0/1">Shirin Handjani</a>, <a href="http://arxiv.org/find/cs/1/au:+Jungreis_D/0/1/0/all/0/1">Douglas Jungreis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiefenbruck_M/0/1/0/all/0/1">Mark Tiefenbruck</a></p><p>Suppose we wish to estimate $\#H$, the number of copies of some small graph
$H$ in a large streaming graph $G$. There are many algorithms for this task
when $H$ is a triangle, but just a few that apply to arbitrary $H$. Here we
focus on one such algorithm, which was introduced by Kane, Mehlhorn, Sauerwald,
and Sun. The storage and update time per edge for their algorithm are both
$O(m^k/(\#H)^2)$, where $m$ is the number of edges in $G$, and $k$ is the
number of edges in $H$. Here, we propose three modifications to their algorithm
that can dramatically reduce both the storage and update time. Suppose that $H$
has no leaves and that $G$ has maximum degree $\leq m^{1/2 - \alpha}$, where
$\alpha &gt; 0$. Define $C = \min(m^{2\alpha},m^{1/3})$. Then in our version of
the algorithm, the update time per edge is $O(1)$, and the storage is
approximately reduced by a factor of $C^{2k-t-2}$, where $t$ is the number of
vertices in $H$; in particular, the storage is $O(C^2 + m^k/(C^{2k-t-2}
(\#H)^2))$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-24T01:30:00Z">Friday, February 24 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, February 23
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://emanueleviola.wordpress.com/2023/02/23/mathematics-of-the-impossible-computational-complexity-chapter-5-completeness-reducing-arbitrary-computation/'>Mathematics of the impossible: Computational Complexity, Chapter 5, Completeness: Reducing arbitrary computation</a></h3>
        <p class='tr-article-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In this chapter we show how to reduce arbitrary computation to 3Sat (and hence to the other problems in section&#160;º4.3). What powers everything is the following landmark and, in hindsight, simple result which reduces circuit computation to 3Sat. Theorem 5.1. Given a circuit with gates we can compute in a 3CNF formula in variables such [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p style="text-align:justify">In this chapter we show how to reduce arbitrary computation to 3Sat (and hence to the other problems in section&nbsp;º<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a>). What powers everything is the following landmark and, in hindsight, simple result which reduces circuit computation to 3Sat.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-56001r1"></a> <b>Theorem</b> 5.1.  </span> Given a circuit <img src="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> gates we can compute in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> a 3CNF formula <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=n%2Bs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Bs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Bs&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n+s" class="latex" /> variables such that for every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" />:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bs%7D%3Af_%7BC%7D%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bs%7D%3Af_%7BC%7D%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%28x%29%3D1%5CLeftrightarrow+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bs%7D%3Af_%7BC%7D%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} C(x)=1&#92;Leftrightarrow &#92;exists y&#92;in &#92;{0,1&#92;} ^{s}:f_{C}(x,y)=1. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The key idea to <em>guess computation and check it efficiently, using that computation is local.</em> The additional <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> variables one introduces contain the values of the gates during the computation of <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />. We simply have to check that they all correspond to a valid computation, and this can be written as 3CNF because each gate depends on at most two other gates.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Introduce a variable <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i}" class="latex" /> for each non-input gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. The value of <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i}" class="latex" /> is intended to be the value of gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" /> during the computation. Whether the value of a gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" /> is correct is a function of <img src="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="3" class="latex" /> variables: <img src="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{i}" class="latex" /> and the <img src="https://s0.wp.com/latex.php?latex=%5Cle+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 2" class="latex" /> gates that input <img src="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{i}" class="latex" />, some of which could be input variables. This can be written as a 3CNF by Theorem <a href="#x1-25003r3">2.3<!--tex4ht:ref: thm:every-function-ckt-Lupanov --></a>. Take an And of all these 3CNFs. Finally, add clause <img src="https://s0.wp.com/latex.php?latex=y_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y_{o}" class="latex" /> for the output gate <img src="https://s0.wp.com/latex.php?latex=g_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=g_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=g_%7Bo%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="g_{o}" class="latex" />. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-56002r1"></a> <b>Exercise</b> 5.1.  </span>Write down the 3CNF for the circuit in figure&nbsp;<a href="#x1-240062">2.2<!--tex4ht:ref: fig:Ckt --></a>, as given by the proof of Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> is <em>a depth-reduction</em> result. Indeed, note that a 3CNF can be written as a circuit of depth <img src="https://s0.wp.com/latex.php?latex=c%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log s" class="latex" />, whereas the original circuit may have any depth. This is helpful for example if you don’t have the depth to run the circuit yourself. You can let someone else produce the computation, and you can check it in small depth.</p>
<p style="text-align:justify">   We can combine Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> with the simulations in Chapter <a href="#x1-180002">2<!--tex4ht:ref: chap:The-alphabet-of --></a> to reduce computation in other models to 3SAT. In particular, we can reduce MTMs running in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> to 3Sat of size <img src="https://s0.wp.com/latex.php?latex=t%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;log ^{c}t" class="latex" />. To obtain such parameters we need the quasilinear simulation of MTMs by circuits, Theorem <a href="#x1-25007r5">2.5<!--tex4ht:ref: thm:simu-TMs-by-CKTs-quasi-linear --></a>.</p>
<p style="text-align:justify">   However, recall that a quasilinear simulation of RAMs by circuits is not known. Only a power simulation is (which is obtained by combining the power simulation of RAMs by MTMs, Theorem <a href="#x1-26003r6">2.6<!--tex4ht:ref: thm:simu-RAM-by-TM --></a>, with a simulation of MTMs by circuits). This would reduce RAM computation running in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> to 3CNFs of size <img src="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t^{c}" class="latex" />. We content ourselves with this power loss for the beginning of this chapter. Later in section&nbsp;º<a href="#x1-610005.3">5.3<!--tex4ht:ref: sec:RAM-to-SAT-quasilinear --></a> we will obtain a quasi-linear simulation using an enjoyable argument which also bypasses Theorem <a href="#x1-25007r5">2.5<!--tex4ht:ref: thm:simu-TMs-by-CKTs-quasi-linear --></a>.</p>
<p style="text-align:justify">   In fact, these simulations apply to a more general, <em>non-deterministic</em>, model of computation. We define this model next, and then present the simulation with power loss in <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>.</p>
<h3 class="sectionHead"><span class="titlemark">5.1   </span> <a id="x1-570005.1"></a>Nondeterministic computation</h3>
<p style="text-align:justify">In the concluding equation in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> there is an <img src="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists " class="latex" /> quantifier on the right-hand side, but there isn’t one on the left, next to the circuit. However, because the simulation works for every input, we can “stick” a quantifier on the left and have the same result. The resulting circuit computation <img src="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(x,y)" class="latex" /> has two inputs, <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. We can think of it as a <em>non-deterministic</em> circuit, which on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> outputs <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> iff <img src="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists y:C(x,y)" class="latex" />. Following the discussion before, we could do the same for other models like TMs, MTMs, and RAMs. The message here is that – if we allow for an <img src="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists " class="latex" /> quantifier, or in other words consider nondeterministic computation – efficient computation is <em>equivalent</em> to 3CNF! This is one motivation for formally introducing a <em>nondeterministic </em>computational model.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-57001r1"></a> <b>Definition</b> 5.1.  </span>NTime<img src="https://s0.wp.com/latex.php?latex=%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28t%28n%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(t(n))" class="latex" /> is the set of functions <img src="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%3AX%5Csubseteq+%5C%7B0%2C1%5C%7D%5E%2A+%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f:X&#92;subseteq &#92;{0,1&#92;}^* &#92;to &#92;{0,1&#92;} " class="latex" /> for which there is a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> such that:</p>
<p style="text-align:justify">   &#8211; <img src="https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f(x)=1" class="latex" /> iff <img src="https://s0.wp.com/latex.php?latex=%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28%7Cx%7C%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28%7Cx%7C%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28%7Cx%7C%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists y&#92;in &#92;{0,1&#92;} ^{t(|x|)}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)=1" class="latex" />, and</p>
<p style="text-align:justify">   &#8211; <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)" class="latex" /> stops within <img src="https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28%7Cx%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(|x|)" class="latex" /> steps on every input <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" />.</p>
<p style="text-align:justify">   We also define</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNP%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%28n%5E%7Bd%7D%29%2C%5C%5C+%5Ctext+%7BNExp%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%282%5E%7Bn%5E%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNP%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%28n%5E%7Bd%7D%29%2C%5C%5C+%5Ctext+%7BNExp%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%282%5E%7Bn%5E%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BNP%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%28n%5E%7Bd%7D%29%2C%5C%5C+%5Ctext+%7BNExp%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cge+1%7D%5Ctext+%7BNTime%7D%282%5E%7Bn%5E%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {NP}:= &amp; &#92;bigcup _{d&#92;ge 1}&#92;text {NTime}(n^{d}),&#92;&#92; &#92;text {NExp}:= &amp; &#92;bigcup _{d&#92;ge 1}&#92;text {NTime}(2^{n^{d}}). &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   Note that the running time of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> is a function of <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|" class="latex" />, not <img src="https://s0.wp.com/latex.php?latex=%7C%28x%2Cy%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7C%28x%2Cy%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7C%28x%2Cy%29%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|(x,y)|" class="latex" />. This difference is inconsequential for NP, since the composition of two powers is another power. But it is important for a more fine-grained analysis. We refer to a RAM machine as in Definition <a href="#x1-57001r1">5.1<!--tex4ht:ref: def:NTime --></a> as a <em>nondeterministic machine</em>, and to the <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)" class="latex" /> as the <em>nondeterministic choices,</em> or <em>guesses, </em>of the machine on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align:justify">   We can also define NTime in a way that is similar to BPTime, Definition <a href="#x1-27001r7">2.7<!--tex4ht:ref: def:BPTime-BPP --></a>. The two definitions are essentially equivalent. Our choice for BPTime is motivated by the identification of BPTime with computation that is actually run. For example, in a programming language one uses an instruction like Rand to obtain random values; one does not think of the                                                                                                                                                                                     randomness as being part of the input. By contrast, NTime is a more abstract model, and the definition with the nondeterministic guesses explicitly laid out is closer in spirit to a 3CNF.</p>
<p style="text-align:justify">   All the problems we studied in section&nbsp;º<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a> are in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-57002r1"></a> <b>Fact</b> 5.1.  </span>3Sat, Clique, Cover-by-vertexes, SubsetSum, and 3Color are in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>For a 3Sat instance <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />, the variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> correspond to an assignment. Checking if the assignment satisfies <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> is in P. This shows that 3Sat is in NP. <b>QED</b></p>
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-57003r2"></a> <b>Exercise</b> 5.2.  </span>Finish the proof by ad<br />
dressing the other problems in Fact <a href="#x1-57002r1">5.1<!--tex4ht:ref: fact:3Sa-etc-in-NP --></a></p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h5 class="likesubsubsectionHead"><a id="x1-580005.1"></a>How to think of NP</h5>
<p style="text-align:justify">We can think of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> as the problems which admit a solution that can be verified efficiently, namely in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. For example for 3Sat it is easy to verify if an assignment satisfies the clauses, for 3Color it is easy to verify if a coloring is such that any edge has endpoints of different colors, for SubsetSum it is easy to verify if a subset has a sum equal to a target, and so on. However, as we saw above this verification step can be cast in a restricted model, namely a 3CNF. So we don’t have to think of the verification step as using the full power of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> computation.</p>
<p style="text-align:justify">   Here’s a vivid illustration of NP. Suppose I claim that the following matrix contains a <img src="https://s0.wp.com/latex.php?latex=9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="9" class="latex" />:</p>
<div style="text-align:center">
<div class="fbox">
<div class="minipage">56788565634705634705637480563476</p>
<p style="text-align:justify">70156137805167840132838202386421</p>
<p style="text-align:justify">85720582340570372307580234576423</p>
<p style="text-align:justify">80275880237505788075075802346518</p>
<p style="text-align:justify">78502378564067807582348057285428</p>
<p style="text-align:justify">05723748754543650350562378804337</p>
<p style="text-align:justify">52305723485008160234723884077764</p>
<p style="text-align:justify">86543234567865435674567836738063</p>
<p style="text-align:justify">45463788486754345743457483460040</p>
<p style="text-align:justify">73273873486574375464584895741832</p>
<p style="text-align:justify">85075783485634856237847287422112</p>
<p style="text-align:justify">83748874883753485745788788223201</p>
</div>
</div>
</div>
<p style="text-align:justify">   How can you tell, without tediously examining the whole matrix? However, if I tell you that it’s in row 10, 8 digits from the right, you can quickly check that I am right. I won’t be able to cheat, since you can check my claims. On the other hand I can provide a proof that’s easy to verify.</p>
<p style="text-align:justify">
<h5 class="likesubsubsectionHead"><a id="x1-590005.1"></a>P vs.&nbsp;NP</h5>
<p style="text-align:justify">The flagship question of complexity theory is whether <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}=&#92;text {NP}" class="latex" /> or not. This is a young, prominent special case of the grand challenge we introduced in Chapter <a href="#x1-370003">3<!--tex4ht:ref: chap:The-grand-challenge --></a>. Contrary to the analogous question for <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}" class="latex" />, cf.&nbsp;section&nbsp;<a href="#x1-290002.5.2">2.5.2<!--tex4ht:ref: subsec:BPTime-vs-time --></a>, the general belief seems to be that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}&#92;ne &#92;text {NP}" class="latex" />. Similarly to BPP, cf.&nbsp;Theorem <a href="#x1-29001r9">2.9<!--tex4ht:ref: thm:Time-vs-BPTime --></a>, the best deterministic simulation of <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> runs in exponential time by trying all nondeterministic guesses. This gives the middle inclusion in the following fact; the other two are by definition.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-59001r2"></a> <b>Fact</b> 5.2.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Csubseteq+%5Ctext+%7BNP%7D%5Csubseteq+%5Ctext+%7BExp+%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BNExp%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Csubseteq+%5Ctext+%7BNP%7D%5Csubseteq+%5Ctext+%7BExp+%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BNExp%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Csubseteq+%5Ctext+%7BNP%7D%5Csubseteq+%5Ctext+%7BExp+%5Censuremath+%7B%5Csubseteq+%5Ctext+%7BNExp%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}&#92;subseteq &#92;text {NP}&#92;subseteq &#92;text {Exp &#92;ensuremath {&#92;subseteq &#92;text {NExp}}}" class="latex" />.</p>
<p style="text-align:justify">   A consequence of the Time Hierarchy Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a> is that <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}&#92;ne &#92;text {Exp}" class="latex" />. From the inclusions above it follows that</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D%5Ctext+%7B+or+NP%7D%5Cne+%5Ctext+%7BExp%2C+possibly+both%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D%5Ctext+%7B+or+NP%7D%5Cne+%5Ctext+%7BExp%2C+possibly+both%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BP%7D%5Cne+%5Ctext+%7BNP%7D%5Ctext+%7B+or+NP%7D%5Cne+%5Ctext+%7BExp%2C+possibly+both%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {P}&#92;ne &#92;text {NP}&#92;text { or NP}&#92;ne &#92;text {Exp, possibly both}. &#92;end{aligned}" class="latex" /></div>
<p>Thus, we are not completely clueless, and we know that at least one important separation is lurking somewhere. Most people appear to think that <em>both</em> separations hold, but we are unable to prove <em>either</em>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   For multi-tape machines, a separation between deterministic and non-deterministic linear time is in <span class="cite">[<a href="#XPPST83">24</a>,&nbsp;<a href="conf/coco/Santhanam01">27</a>]</span>.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.2   </span> <a id="x1-600005.2"></a>NP-completeness</h3>
<p style="text-align:justify">We now go back to the question at the beginning of this chapter about reducing arbitrary computation to 3Sat. We shall reduce all of NP to 3Sat in Theorem <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>. Problems like 3Sat admitting such reductions deserve a definition.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60001r2"></a> <b>Definition</b> 5.2.  </span>We call a problem <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" />:</p>
<p style="text-align:justify">   NP-hard if every problem in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />;</p>
<p style="text-align:justify">   NP-complete if it is NP-hard and in NP.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   One can define <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" />-hard (and hence NP-complete) w.r.t.&nbsp;different reductions, cf.&nbsp;Chapter <a href="#x1-450004">4<!--tex4ht:ref: chap:Reductions --></a>, and we will do so later. But the simple choice above suffices for now.</p>
<p style="text-align:justify">   Complete problems are the “hardest problems” in the class, as formalized in the following fact.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60002r3"></a> <b>Fact</b> 5.3.  </span>Suppose <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BL%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {L}" class="latex" /> is NP-complete. Then <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CLeftrightarrow+%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CLeftrightarrow+%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CLeftrightarrow+%5Ctext+%7BP%7D%3D%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {P}&#92;Leftrightarrow &#92;text {P}=&#92;text {NP}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span><img src="https://s0.wp.com/latex.php?latex=%28%5CLeftarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28%5CLeftarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28%5CLeftarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(&#92;Leftarrow )" class="latex" /> This is because <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {NP}" class="latex" />.</p>
<p style="text-align:justify">   (<img src="https://s0.wp.com/latex.php?latex=%5CRightarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CRightarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CRightarrow+%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Rightarrow )" class="latex" /> Let <img src="https://s0.wp.com/latex.php?latex=L%27%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%27%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%27%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#039;&#92;in &#92;text {NP}" class="latex" />. Because <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> is NP-hard we know that <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%5Censuremath+%7B%5CRightarrow+L%27%5Cin+%5Ctext+%7BP%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%5Censuremath+%7B%5CRightarrow+L%27%5Cin+%5Ctext+%7BP%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%5Censuremath+%7B%5CRightarrow+L%27%5Cin+%5Ctext+%7BP%7D%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {P&#92;ensuremath {&#92;Rightarrow L&#039;&#92;in &#92;text {P}}.}" class="latex" /> <b>QED</b></p>
</div>
<p style="text-align:justify">   Fact <a href="#x1-60002r3">5.3<!--tex4ht:ref: fact:np-complete-in-P-iff-p=00003Dnp --></a> points to an important interplay between problems and complexity classes. We can study complexity classes by studying their complete problems, and vice versa.</p>
<p style="text-align:justify">   The central result in the theory of NP completeness is the following.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60003r2"></a> <b>Theorem</b> 5.2.  </span><span class="cite">[<a href="#XCook73">7</a>,&nbsp;<a href="#XLevin73">20</a>]</span> 3Sat is NP-complete.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>3Sat is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> by Fact <a href="#x1-57002r1">5.1<!--tex4ht:ref: fact:3Sa-etc-in-NP --></a>. Next we prove NP-hardness. The main idea is Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>, while the rest of the proof mostly amounts to opening up definitions and using some previous simulations. Let <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {NP}" class="latex" /> and let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be the corresponding TM which runs in time <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{d}" class="latex" /> on inputs <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cx%7C%3Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|x|=n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Cy%7C%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cy%7C%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cy%7C%3Dn%5E%7Bd%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|y|=n^{d}" class="latex" />, for some constant <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />. We can work with TMs instead of RAMs since they are equivalent up to a power loss, as we saw in Theorem <a href="#x1-26003r6">2.6<!--tex4ht:ref: thm:simu-RAM-by-TM --></a>. We can construct in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P }" class="latex" />a circuit <img src="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(x,y)" class="latex" /> of size <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7Dn%5E%7Bc_%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7Dn%5E%7Bc_%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7Dn%5E%7Bc_%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}n^{c_{d}}" class="latex" /> such that for any <img src="https://s0.wp.com/latex.php?latex=x%2Cy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%2Cy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%2Cy&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x,y" class="latex" /> we have <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1%5CLeftrightarrow+C%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1%5CLeftrightarrow+C%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1%5CLeftrightarrow+C%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)=1&#92;Leftrightarrow C(x,y)=1" class="latex" /> by Theorem <a href="#x1-25006r4">2.4<!--tex4ht:ref: thm:simu-tm-by-ckts-simple --></a>.</p>
<p style="text-align:justify">   Now, suppose we are given an input <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> for which we are trying to decide membership in <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" />. This is equivalent to deciding if <img src="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28w%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28w%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cexists+y%3AC%28w%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;exists y:C(w,y)=1" class="latex" /> by what we just said. We can “hard-wire” <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> into <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> to obtain the circuit <img src="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3A%3DC%28w%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3A%3DC%28w%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3A%3DC%28w%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{w}(y):=C(w,y)" class="latex" /> only on the variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />, with no loss in size. Here by “hard-wise” se mean replacing the input gates <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> with the bits of <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" />. Now we can apply Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> to this new circuit to produce a 3CNF <img src="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{w}" class="latex" /> on variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> and new variables <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+z%3Af%28y%2Cz%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+z%3Af%28y%2Cz%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+z%3Af%28y%2Cz%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{w}(y)=1&#92;Leftrightarrow &#92;exists z:f(y,z)=1" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. The size of <img src="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7Bw%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{w}" class="latex" /> and the number of variables <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" /> is power in the size of the circuit.</p>
<p style="text-align:justify">   We have obtained:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+w%5Cin+L%5CLeftrightarrow+%5Cexists+y%3AM%28w%2Cy%29%3D1%5CLeftrightarrow+%5Cexists+y%3AC_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+y%2Cz%3Af_%7Bw%7D%28y%2Cz%29%3D1%5CLeftrightarrow+f_%7Bw%7D%5Cin+%5Ctext+%7B3Sat%2C%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+w%5Cin+L%5CLeftrightarrow+%5Cexists+y%3AM%28w%2Cy%29%3D1%5CLeftrightarrow+%5Cexists+y%3AC_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+y%2Cz%3Af_%7Bw%7D%28y%2Cz%29%3D1%5CLeftrightarrow+f_%7Bw%7D%5Cin+%5Ctext+%7B3Sat%2C%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+w%5Cin+L%5CLeftrightarrow+%5Cexists+y%3AM%28w%2Cy%29%3D1%5CLeftrightarrow+%5Cexists+y%3AC_%7Bw%7D%28y%29%3D1%5CLeftrightarrow+%5Cexists+y%2Cz%3Af_%7Bw%7D%28y%2Cz%29%3D1%5CLeftrightarrow+f_%7Bw%7D%5Cin+%5Ctext+%7B3Sat%2C%7D+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} w&#92;in L&#92;Leftrightarrow &#92;exists y:M(w,y)=1&#92;Leftrightarrow &#92;exists y:C_{w}(y)=1&#92;Leftrightarrow &#92;exists y,z:f_{w}(y,z)=1&#92;Leftrightarrow f_{w}&#92;in &#92;text {3Sat,} &#92;end{aligned}" class="latex" /></div>
<p>as desired. <b>QED</b></p>
</div>
<p style="text-align:justify">   In section&nbsp;º<a href="#x1-500004.3">4.3<!--tex4ht:ref: sec:Reductions-from-3Sat --></a> we reduced 3Sat to other problems which are also in NP by Fact <a href="#x1-57002r1">5.1<!--tex4ht:ref: fact:3Sa-etc-in-NP --></a>. This implies that all these problems are NP-complete. Here we use that if problem <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> in P, and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />, then also <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> reduces to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. This is because if <img src="https://s0.wp.com/latex.php?latex=C%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in &#92;text {P}" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B&#92;in &#92;text {P}" class="latex" />, and so <img src="https://s0.wp.com/latex.php?latex=A%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A&#92;in &#92;text {P}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60004r1"></a> <b>Corollary</b> 5.1.  </span> Clique, Cover-by-vertexes, Subset-sum, and 3Color are NP-complete.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   It is important to note that there is nothing special about the <em>existence</em> of NP-complete problems. The following is a simple such problem that does not require any of the machinery in this section.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-60005r3"></a> <b>Exercise</b> 5.3.  </span>Consider the problem, given a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />, an input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;in &#92;mathbb {N}" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is written in unary, decide if there is <img src="https://s0.wp.com/latex.php?latex=y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y&#92;in &#92;{0,1&#92;} ^{t}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M%28x%2Cy%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M(x,y)=1" class="latex" />. Prove that this is NP-complete.</p>
<p style="text-align:justify">   What if <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is written in binary?</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The interesting aspect of NP-complete problems such as 3Sat and those in Corollary <a href="#x1-60004r1">5.1<!--tex4ht:ref: cor:all-probs-NP-complete --></a> is that they are very simple and structured, and don’t refer to computational models. This makes them suitable for reductions, and for inferring properties of the complexity class which are not evident from a machine-based definition.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.3   </span> <a id="x1-610005.3"></a>From RAM to 3SAT in quasi-linear time</h3>
<p style="text-align:justify">The framework in the previous section is useful to relate membership in P of different problems in NP, but it is not suitable for a more fine-grained analysis. For example, under the assumption that 3Sat is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28cn%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(cn)" class="latex" /> we cannot immediately conclude that other problems in NP are solvable in this time or in about this time. We can only conclude that they are in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. In particular, the complexity of 3Sat cannot be related to that of other central conjectures, such as whether 3Sum is in subquadratic time, Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a>.</p>
<p style="text-align:justify">   The culprit is the power loss in reducing RAM computation to circuits, mentioned at the beginning of the chapter. We now remedy this situation and present a quasi-linear reduction. As we did before, cf.&nbsp;Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> and Theorem <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>, we first state a version of the simulation for (deterministic) computation which contains all the main ideas, and then we note that a completeness result follows.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-61001r3"></a> <b>Theorem</b> 5.3.  </span>Given an input length <img src="https://s0.wp.com/latex.php?latex=n%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;in &#92;mathbb {N}" class="latex" />, a time bound <img src="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cin+%5Cmathbb+%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;in &#92;mathbb {N}" class="latex" />, and a RAM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> that runs in time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> on inputs of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> bits, we can compute in time <img src="https://s0.wp.com/latex.php?latex=t%27%3A%3Dc_%7BM%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27%3A%3Dc_%7BM%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27%3A%3Dc_%7BM%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;:=c_{M}t(&#92;log t)^{c}" class="latex" /> a 3CNF <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> on variables <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%7Cy%7C%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Cy%7C%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Cy%7C%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|y|&#92;le t&#039;" class="latex" /> such that for every <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x&#92;in &#92;{0,1&#92;} ^{n}" class="latex" />:</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%28x%29%3D1%5Ciff+%5Cexists+y%3Af%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%28x%29%3D1%5Ciff+%5Cexists+y%3Af%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+M%28x%29%3D1%5Ciff+%5Cexists+y%3Af%28x%2Cy%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} M(x)=1&#92;iff &#92;exists y:f(x,y)=1. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We now present the proof of this amazing result; you may want to refer back to Definition <a href="#x1-26001r5">2.5<!--tex4ht:ref: def:RAM --></a> of a RAM. A key concept in the proof is the following “snapshot” of the RAM computation.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-61002r3"></a> <b>Definition</b> 5.3.  </span>The <em>internal configuration, </em>abbreviated IC<em>, </em>of a RAM specifies:</p>
<ul class="itemize1">
<li class="itemize">its registers,</li>
<li class="itemize">the program counter,</li>
<li class="itemize">the word length <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" />, and</li>
<li class="itemize">if the current instruction is a Read <img src="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{i}:=&#92;mu [r_{j}]" class="latex" /> or Write <img src="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D%3A%3Dr_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D%3A%3Dr_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D%3A%3Dr_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mu [r_{j}]:=r_{i}" class="latex" /> then the IC includes the content <img src="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmu+%5Br_%7Bj%7D%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mu [r_{j}]" class="latex" /> of the       memory cell indexed by <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" />.</li>
</ul>
</div>
<p style="text-align:justify">   Note that at most one memory cell is included in one IC. By contrast, the configuration of a TM (Definition <a href="#x1-19001r1">2.1<!--tex4ht:ref: def:TM --></a>) includes all its tape cells. Also note that an IC has length <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}+c&#92;log t" class="latex" /> bits, where the <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}" class="latex" /> is for the program counter, and the <img src="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log t" class="latex" /> is for the rest, using that the maximum word length of a machine running in time <img src="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge n" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log t" class="latex" />.</p>
<p style="text-align:justify"><span class="paragraphHead"><a id="x1-620005.3"></a>The key idea in the proof.</span>    At the high level, the approach is, like in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>, to guess computation and check it efficiently. We are going to <em>guess </em>the sequence of ICs, and we need additional ideas to check them efficiently by a circuit. This is not immediate, since, again, the RAM can use direct access to read and write in memory at arbitrary locations, something which is not easy to do with a circuit.</p>
<p style="text-align:justify">   The key idea is to check operations involving memory <em>independently </em>from the operations involving registers but not memory. If both checks pass, then the computation is correct. More precisely, a sequence of internal configurations <img src="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{1},s_{2},&#92;ldots ,s_{t}" class="latex" /> corresponds to the computation of the RAM on input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> iff for every <img src="https://s0.wp.com/latex.php?latex=i%3Ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%3Ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%3Ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&lt;t" class="latex" />:
</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-62002x1">If <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i}" class="latex" /> does not access memory, then <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i+1}" class="latex" /> has its registers, program counter, and word length       updated according to the instruction executed in <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i}" class="latex" />,</li>
<li class="enumerate" id="x1-62004x2">If <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i}" class="latex" /> is computing a read operation <img src="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Ctext+%7B%5Censuremath+%7B%5Cmu+%5Br_%7Bj%7D%5D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Ctext+%7B%5Censuremath+%7B%5Cmu+%5Br_%7Bj%7D%5D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bi%7D%3A%3D%5Ctext+%7B%5Censuremath+%7B%5Cmu+%5Br_%7Bj%7D%5D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{i}:=&#92;text {&#92;ensuremath {&#92;mu [r_{j}]}}" class="latex" /> then in <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i+1}" class="latex" /> register <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" /> contains <em>the most recent value       written in memory cell <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" /></em>. In case this cell was never written, then <img src="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_{j}" class="latex" /> should contain <img src="https://s0.wp.com/latex.php?latex=x_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x_{j}" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j%5Cin+%5C%7B1%2C2%2C%5Cldots+%2Cn%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j&#92;in &#92;{1,2,&#92;ldots ,n&#92;}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />       if <img src="https://s0.wp.com/latex.php?latex=j%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=j%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=j%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="j=0" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> otherwise. The program counter in <img src="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bi%2B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{i+1}" class="latex" /> also points to the next instruction.</li>
</ol>
<p style="text-align:justify">Rather than directly constructing a 3CNF that implements these checks, we construct a circuit and then appeal to Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>. It is easy to construct a circuit of quasi-linear size implementing Check 1, since the circuit only has to check adjacent pairs of ICs. As remarked before, these ICs have length <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}+c&#92;log t" class="latex" />. For fixed <img src="https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i," class="latex" /> Check 1 can be implemented by a circuit which depends on the RAM and has size power in the length of an IC. Taking an And of these circuits over the choices of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> gives a circuit of the desired size for Check 1.</p>
<p style="text-align:justify">   The difficulty lies in Check 2, because the circuit needs to find “the most recent value written.” The solution is to <em>sort</em> the ICs by memory addresses. After sorting, we can implement Check (2) as easily as Check (1), since we just need to check adjacent pairs of ICs.</p>
<p style="text-align:justify">   The emergence of sorting in the theory of NP-completeness cements the pivotal role this operation plays in computer science.</p>
<p style="text-align:justify">   To implement this idea we need to be able to sort with a quasi-linear size circuit. Standard sorting algorithms like Mergesort, Heapsort, or Radixsort run in quasi-linear time on a RAM, but rely on direct addressing (cf.&nbsp;section&nbsp;º<a href="#x1-260002.4">2.4<!--tex4ht:ref: sec:RAMs --></a>) and for this reason cannot be easily implemented by a circuit of quasi-linear size. However other algorithms have been developed that do have such an implementation, for example a variant of Mergesort called Odd-Even-Mergesort <span class="cite">[<a href="#XBatcher68">6</a>]</span>, see also <span class="cite">[<a href="#XViolaNEU-ram2sat-neu-author">22</a>]</span>. This gives the following lemma.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-62005r1"></a> <b>Lemma</b> 5.1.  </span>Given <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> we can compute in time <img src="https://s0.wp.com/latex.php?latex=t%27%3A%3Dt%5Ccdot+%28m%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%27%3A%3Dt%5Ccdot+%28m%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%27%3A%3Dt%5Ccdot+%28m%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#039;:=t&#92;cdot (m&#92;log t)^{c}" class="latex" /> a circuit (of size <img src="https://s0.wp.com/latex.php?latex=%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+t%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le t&#039;" class="latex" />) that sorts <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> integers of <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" /> bits.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We summarize the key steps in the proof.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-61001r3">5.3<!--tex4ht:ref: thm:redux-RAM-2-3cnf-quasilinear --></a></b>.&nbsp;</span> We construct a circuit <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> and then appeal to Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a>. The extra variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> correspond to <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> ICs <img src="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7B1%7D%2Cs_%7B2%7D%2C%5Cldots+%2Cs_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{1},s_{2},&#92;ldots ,s_{t}" class="latex" />. An IC takes <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D%2Bc%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}+c&#92;log t" class="latex" /> bits to specify, so we need <img src="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7Dt%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7Dt%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c_%7BM%7Dt%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c_{M}t&#92;log t" class="latex" /> variables <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" />. The circuit <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> first performs Check (1) above for each adjacent pair <img src="https://s0.wp.com/latex.php?latex=%28s_%7Bi%7D%2Cs_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28s_%7Bi%7D%2Cs_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28s_%7Bi%7D%2Cs_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(s_{i},s_{i+1})" class="latex" /> of ICs. This takes size <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7D%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7D%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7D%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}&#92;log ^{c}t" class="latex" /> for each pair, and so size <img src="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BM%7Dt%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{M}t&#92;log ^{c}t" class="latex" /> overall.</p>
<p style="text-align:justify">   Then <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> sorts the ICs by memory addresses, producing sorted ICs <img src="https://s0.wp.com/latex.php?latex=s%27_%7B1%7D%2Cs%27_%7B2%7D%2C%5Cldots+%2Cs%27_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%27_%7B1%7D%2Cs%27_%7B2%7D%2C%5Cldots+%2Cs%27_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%27_%7B1%7D%2Cs%27_%7B2%7D%2C%5Cldots+%2Cs%27_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#039;_{1},s&#039;_{2},&#92;ldots ,s&#039;_{t}" class="latex" />. This takes size <img src="https://s0.wp.com/latex.php?latex=t%5Ccdot+%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Ccdot+%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Ccdot+%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;cdot &#92;log ^{c}t" class="latex" /> by Lemma <a href="#x1-62005r1">5.1<!--tex4ht:ref: lem:sorting-ckt-quasilinear --></a>, using that the memory addresses have <img src="https://s0.wp.com/latex.php?latex=%5Cle+c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+c%5Clog+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le c&#92;log t" class="latex" /> bits. Then the circuit performs Check (2) for each adjacent pair <img src="https://s0.wp.com/latex.php?latex=%28s%27_%7Bi%7D%2Cs%27_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28s%27_%7Bi%7D%2Cs%27_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28s%27_%7Bi%7D%2Cs%27_%7Bi%2B1%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(s&#039;_{i},s&#039;_{i+1})" class="latex" /> of ICs. The circuit size required for this is no more than for Check (1).</p>
<p style="text-align:justify">   Finally, the circuit takes an And of the results of the two checks, and also checks that <img src="https://s0.wp.com/latex.php?latex=s_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_{t}" class="latex" /> is accepting. <b>QED</b></p>
</div>
<p style="text-align:justify">   We can now prove completeness in a manner similar to Theorem <a href="#x1-60003r2">5.2<!--tex4ht:ref: thm:-3Sat-is-NP-complete --></a>, with a relatively simple extension of Theorem <a href="#x1-61001r3">5.3<!--tex4ht:ref: thm:redux-RAM-2-3cnf-quasilinear --></a>.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-62006r4"></a>                                                                                                                                                                                     <b>Theorem</b> 5.4.  </span>Every problem <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NTime}(t)" class="latex" /> map reduces to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28c_%7BL%2Ct%7Dt%5Clog+%5E%7Bc%7Dt%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28c_%7BL%2Ct%7Dt%5Clog+%5E%7Bc%7Dt%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BTime%7D%28c_%7BL%2Ct%7Dt%5Clog+%5E%7Bc%7Dt%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Time}(c_{L,t}t&#92;log ^{c}t)" class="latex" />, for every function <img src="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cge+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;ge n" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(x)" class="latex" /> is computable in time <img src="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(x)" class="latex" /> given <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   The assumption on <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> is similar to that in the hierarchy Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>, and is satisfied by all standard functions including all those in this book – cf.&nbsp;discussion after Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>.</p>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Let <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> be a RAM computing <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> in the assumed time. Given an input <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> we have to efficiently compute a 3CNF <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> such that</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28n%29%7D%3AM%28w%2Cy%29%3D1%5Ciff+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bc_%7BL%2Ct%7Dt%28n%29%5Clog+%5E%7Bc%7Dt%28n%29%7D%3Af%28y%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28n%29%7D%3AM%28w%2Cy%29%3D1%5Ciff+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bc_%7BL%2Ct%7Dt%28n%29%5Clog+%5E%7Bc%7Dt%28n%29%7D%3Af%28y%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bt%28n%29%7D%3AM%28w%2Cy%29%3D1%5Ciff+%5Cexists+y%5Cin+%5C%7B0%2C1%5C%7D+%5E%7Bc_%7BL%2Ct%7Dt%28n%29%5Clog+%5E%7Bc%7Dt%28n%29%7D%3Af%28y%29%3D1.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;exists y&#92;in &#92;{0,1&#92;} ^{t(n)}:M(w,y)=1&#92;iff &#92;exists y&#92;in &#92;{0,1&#92;} ^{c_{L,t}t(n)&#92;log ^{c}t(n)}:f(y)=1. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   First we compute <img src="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t(n)" class="latex" />, using the assumption. We now apply Theorem <a href="#x1-61001r3">5.3<!--tex4ht:ref: thm:redux-RAM-2-3cnf-quasilinear --></a>, but on a new input length <img src="https://s0.wp.com/latex.php?latex=n%27%3A%3Dc%28n%2Bt%29%5Cle+ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%27%3A%3Dc%28n%2Bt%29%5Cle+ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%27%3A%3Dc%28n%2Bt%29%5Cle+ct&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#039;:=c(n+t)&#92;le ct" class="latex" />, to accommodate for inputs of the form <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" />. This produces a formula <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> of size <img src="https://s0.wp.com/latex.php?latex=c_%7BL%2Ct%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c_%7BL%2Ct%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c_%7BL%2Ct%7Dt%28%5Clog+t%29%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c_{L,t}t(&#92;log t)^{c}" class="latex" /> in variables <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28x%2Cy%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(x,y)" class="latex" /> and new variables <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z" class="latex" />. We can now set <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="w" class="latex" /> and conclude the proof. <b>QED</b></p>
</div>
<p style="text-align:justify">   With these sharper results we can now study hardness and completenss within time bounds such as <img src="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{2}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=n%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5Clog+%5E%7B3%7Dn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n&#92;log ^{3}n" class="latex" /> etc. We work out an example in the next section.</p>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.3.1   </span> <a id="x1-630005.3.1"></a>Quasilinear-time completeness</h4>
<p style="text-align:justify">In this section we use the machinery we just developed to study completeness in quasi-linear time, instead of power time.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63001r4"></a> <b>Definition</b> 5.4.  </span>We define the quasi-linear time complexity classes</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BQLin-Time%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BTime%7D%28n%5Clog+%5E%7Bd%7Dn%29%5Ctext+%7B+and%7D%5C%5C+%5Ctext+%7BQLin-NTime%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BNTime%7D%28n%5Clog+%5E%7Bd%7Dn%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BQLin-Time%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BTime%7D%28n%5Clog+%5E%7Bd%7Dn%29%5Ctext+%7B+and%7D%5C%5C+%5Ctext+%7BQLin-NTime%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BNTime%7D%28n%5Clog+%5E%7Bd%7Dn%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext+%7BQLin-Time%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BTime%7D%28n%5Clog+%5E%7Bd%7Dn%29%5Ctext+%7B+and%7D%5C%5C+%5Ctext+%7BQLin-NTime%7D%3A%3D+%26+%5Cbigcup+_%7Bd%5Cin+%5Cmathbb+%7BN%7D%7D%5Ctext+%7BNTime%7D%28n%5Clog+%5E%7Bd%7Dn%29.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;text {QLin-Time}:= &amp; &#92;bigcup _{d&#92;in &#92;mathbb {N}}&#92;text {Time}(n&#92;log ^{d}n)&#92;text { and}&#92;&#92; &#92;text {QLin-NTime}:= &amp; &#92;bigcup _{d&#92;in &#92;mathbb {N}}&#92;text {NTime}(n&#92;log ^{d}n). &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63002r5"></a> <b>Theorem</b> 5.5.  </span>3Sat is complete for QLin-NTime with respect to mapping reductions in QLin-Time. That is:</p>
<p style="text-align:justify">   &#8211; 3Sat is in QLin-NTime, and</p>
<p style="text-align:justify">   &#8211; every problem in QLin-NTime map reduces to 3Sat in QLin-Time.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>To show that 3Sat is in QLin-NTime, consider a 3CNF instance <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />. This instance has at most <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" /> variables, and we can guess an assignment <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> to them within our budget of non-deterministic guesses. There remains to verify that <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> satisfies <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />. For this, we can do one pass over the clauses. For each clause, we access the bits in <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> corresponding to the 3 variables in the clause, and check if the clause is satisfied. This takes constant time per clause, and so time <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> overall.</p>
<p style="text-align:justify">   The second part follows from Theorem <a href="#x1-62006r4">5.4<!--tex4ht:ref: thm:redux-NTime-3Sat --></a>, using the fact that the composition of two quasilinear functions is also quasilinear (similarly to the fact that the composition of two power functions is also a power). <b>QED</b></p>
</div>
<p style="text-align:justify">   Note that the proof that 3Sat is in QLin-NTime relies on our computational model being a RAM, because we use direct access to fetch the values for the variables in a clause.</p>
<p style="text-align:justify">   We can now give the following quasi-linear version of Fact <a href="#x1-60002r3">5.3<!--tex4ht:ref: fact:np-complete-in-P-iff-p=00003Dnp --></a>. The only extra observation for the proof is again that the composition of two quasi-linear functions is quasi-linear.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63003r2"></a> <b>Corollary</b> 5.2.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BQLin-NTime%7D%5CLeftrightarrow+%5Ctext+%7BQLin-NTime%7D%3D%5Ctext+%7BQLin-Time.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BQLin-NTime%7D%5CLeftrightarrow+%5Ctext+%7BQLin-NTime%7D%3D%5Ctext+%7BQLin-Time.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BQLin-NTime%7D%5CLeftrightarrow+%5Ctext+%7BQLin-NTime%7D%3D%5Ctext+%7BQLin-Time.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {QLin-NTime}&#92;Leftrightarrow &#92;text {QLin-NTime}=&#92;text {QLin-Time.}" class="latex" /></p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63004r4"></a> <b>Exercise</b> 5.4.  </span>Prove that Theorem <a href="#x1-63002r5">5.5<!--tex4ht:ref: thm:3Sat-is-complete-quasilinear --></a> holds with 3Color instead of 3Sat. What about Clique and Subset-sum?</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-63005r5"></a>                                                                                                                                                                                     <b>Exercise</b> 5.5.  </span>Prove that 3Sum reduces to 3Sat in Subquadratic time. That is: <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B3Sat%7D%5Cin+%5Ctext+%7BSubquadraticTime%5Censuremath+%7B%5CRightarrow+%5Ctext+%7B3Sum%7D%5Cin+%5Ctext+%7BSubquadraticTime%7D%7D+%28i.e.%2C+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {3Sat}&#92;in &#92;text {SubquadraticTime&#92;ensuremath {&#92;Rightarrow &#92;text {3Sum}&#92;in &#92;text {SubquadraticTime}} (i.e., }" class="latex" />Conjecture <a href="#x1-49003r1">4.1<!--tex4ht:ref: conj:3sum --></a> is false).</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.4   </span> <a id="x1-640005.4"></a>Completeness in other classes</h3>
<p style="text-align:justify">The completeness phenomenon is not special to NP but enjoyed by many other classes. In this section we begin to explore completeness for NExp and Exp. One needs to be careful how hardness (and hence completeness) is defined, since these classes are known to be different from <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> by the hierarchy Theorem <a href="#x1-40003r4">3.4<!--tex4ht:ref: thm:TIME-hierarchy-TM --></a>. So defining a problem <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> to be NExp-hard if <img src="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BNExp%7D%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BNExp%7D%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cin+%5Ctext+%7BP%7D%5CRightarrow+%5Ctext+%7BNExp%7D%3D%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;in &#92;text {P}&#92;Rightarrow &#92;text {NExp}=&#92;text {P}" class="latex" /> would mean simply that <img src="https://s0.wp.com/latex.php?latex=L%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L&#92;not &#92;in &#92;text {P}" class="latex" />. To avoid this in this section hardness (hence completeness) is defined w.r.t.&nbsp;mapping reductions, cf.&nbsp;Chapter <a href="#x1-450004">4<!--tex4ht:ref: chap:Reductions --></a>. (Another option would be to replace <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" /> with say <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}" class="latex" />, since it is not known if <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D%3D%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D%3D%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BBPP%7D%3D%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {BPP}=&#92;text {NExp}" class="latex" />.)</p>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.4.1   </span> <a id="x1-650005.4.1"></a>NExp completeness</h4>
<p style="text-align:justify">Complete problems for NExp include <em>succinct</em> versions of problems complete for NExp. Here succinct means that rather than giving the input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> to the problem in standard format, the input consists instead of a circuit <img src="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bm%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bm%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%3A%5C%7B0%2C1%5C%7D+%5E%7Bm%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C:&#92;{0,1&#92;} ^{m}&#92;to &#92;{0,1&#92;} " class="latex" /> encoding <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, for example <img src="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(i)" class="latex" /> equals bit <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, for every <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-65001r5"></a> <b>Definition</b> 5.5.  </span>The Succinct-3Sat problem: Given a circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> encoding a 3CNF <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" />, does <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" /> have a satisfying assignment?</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-65002r6"></a> <b>Theorem</b> 5.6.  </span>Succinct-3Sat  is  NExp  complete  with  respect  to  power-time  mapping reductions.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof sketch.</b>.&nbsp;</span> Let us first show that Succinct-3Sat is in NExp. Given a circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> of length <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, we can run it on every possible input (of length <img src="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n" class="latex" />) and write down the formula <img src="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f_%7BC%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f_{C}" class="latex" /> encoded by <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. This formula has size <img src="https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le 2^{n}" class="latex" />. We can then use the fact that 3Sat is in NP to decide satisfiability of this formula in non-deterministic power time in <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{n}" class="latex" />, that is <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%282%5E%7Bcn%7D%29%5Csubseteq+%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%282%5E%7Bcn%7D%29%5Csubseteq+%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNTime%7D%282%5E%7Bcn%7D%29%5Csubseteq+%5Ctext+%7BNExp%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NTime}(2^{cn})&#92;subseteq &#92;text {NExp}" class="latex" />.</p>
<p style="text-align:justify">   To prove NExp hardness it is convenient to work with TMs rather than RAMs. The main observation is that in the simulation of a TM <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" /> on an input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> by a circuit <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" />, Theorem <a href="#x1-25006r4">2.4<!--tex4ht:ref: thm:simu-tm-by-ckts-simple --></a>, the circuit is very regular, in the sense that we can construct another circuit <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> which is a succinct encoding of <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" />. The circuit <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> is given as input indexes to gates in <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> and outputs the type of the gate and its wires. The size of <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> is power in the index length and <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="M" class="latex" />. Thus, if <img src="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C_{M}" class="latex" /> has size <img src="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t^{c}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> only needs size <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5E%7Bc%7Dt&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log ^{c}t" class="latex" />. If <img src="https://s0.wp.com/latex.php?latex=t%3D2%5E%7Bn%5E%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%3D2%5E%7Bn%5E%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%3D2%5E%7Bn%5E%7Bd%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t=2^{n^{d}}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S_%7BM%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S_{M}" class="latex" /> has size power in <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n" class="latex" />, as desired. The transformation from circuit to 3CNF in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> is also regular and can be done succinctly. <b>QED</b></p>
</div>
<p style="text-align:justify">   As a consequence, we obtain the following “concrete” problem not in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-65003r3"></a> <b>Corollary</b> 5.3.  </span><img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSuccinct-3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BSuccinct-3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BSuccinct-3Sat%7D%5Cnot+%5Cin+%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {Succinct-3Sat}&#92;not &#92;in &#92;text {P}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.4.2   </span> <a id="x1-660005.4.2"></a>Exp-completeness</h4>
<p style="text-align:justify">Exp-complete problems include several two-player games. The important feature for completeness is that the game may last for an exponential number of steps (otherwise it would belong to a class believed to be stricter which we will investigate in Chapter ??). These games include (generalized versions of) Chess <span class="cite">[<a href="journals/jct/FraenkelL81">8</a>]</span> and Checkers <span class="cite">[<a href="journals/siamcomp/Robson84">26</a>]</span>.</p>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.5   </span> <a id="x1-670005.5"></a>Power from completeness</h3>
<p style="text-align:justify">The realization that arbitrary computation can be reduced to 3Sat and other problems is powerful and liberating. In particular it allows us to significantly widen the net of reductions.</p>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.5.1   </span> <a id="x1-680005.5.1"></a>Optimization problems</h4>
<p style="text-align:justify">As observed in section&nbsp;º<a href="#x1-540004.6">4.6<!--tex4ht:ref: sec:Gap-SAT:-The-PCP --></a>, 3Sat trivially reduces to Max-3Sat. The converse will be shown next.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-68001r7"></a> <b>Theorem</b> 5.7.  </span>Max-3Sat reduces to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>Consider the problem Atleast-3Sat: Given a 3CNF formula and an integer <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />, is there an assignment that satisfies at least <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> clauses? This is in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BNP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {NP}" class="latex" /> and so can be reduced to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7BP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {P}" class="latex" />. This is the step that’s not easy without “thinking completeness:” given an algorithm for 3Sat it isn’t clear how to use it directly to solve Atleast-3Sat.</p>
<p style="text-align:justify">   Hence, if 3Sat is in P so is Atleast-3Sat. On input a 3CNF <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />, using binary search and the fact that Atleast-3Sat is in P, we can find in P the largest <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" /> s.t.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%28f%2Ct%29%5Cin+%5Ctext+%7BAtleast-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%28f%2Ct%29%5Cin+%5Ctext+%7BAtleast-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%28f%2Ct%29%5Cin+%5Ctext+%7BAtleast-3Sat%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="(f,t)&#92;in &#92;text {Atleast-3Sat}" class="latex" />. Having found this <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t" class="latex" />, there remains to construct an assignment satisfying the clauses. This can be done fixing one variable at the time as in Theorem <a href="#x1-52002r5">4.5<!--tex4ht:ref: thm:Search-3Sat-power-time-reduces --></a>. <b>QED</b></p>
</div>
<p style="text-align:justify">
<h4 class="subsectionHead"><span class="titlemark">5.5.2   </span> <a id="x1-690005.5.2"></a>NP is as easy as detecting unique solutions</h4>
<p style="text-align:justify">A satisfiable 3CNF can have multiple satisfying assignments. On the other hand some problems and puzzles have unique solutions. In this section we relate these two scenarios.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69001r6"></a>                                                                                                                                                                                     <b>Definition</b> 5.6.  </span>Unique-CktSat is the problem: Given a circuit <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> s.t.&nbsp;there is at most one input <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> for which <img src="https://s0.wp.com/latex.php?latex=C%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C(x)=1" class="latex" />, decide if such an input exists.</p>
<p style="text-align:justify">   Unique-3Sat is the Unique-CktSat problem restricted to 3CNF circuits.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69002r8"></a> <b>Theorem</b> 5.8.  </span> <span class="cite">[<a href="journals/tcs/ValiantV86">33</a>]</span> 3Sat reduces to Unique-3Sat in BPP.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We in fact reduce 3Sat to Unique-CktSat. Then Unique-CktSat can be reduced to Unique-3Sat observing that the reduction in Theorem <a href="#x1-56001r1">5.1<!--tex4ht:ref: thm:redux-ckt-2-3sat --></a> preserves uniqueness.</p>
<p style="text-align:justify">   The beautiful proof uses a powerful and general technique in randomized computation: <em>pairwise uniformity</em>, sometimes more generically referred to as <em>hashing. </em>We first define such functions and give efficient constructions. Then we show how to use them to “isolate” assignments.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69003r7"></a> <b>Definition</b> 5.7.  </span>A distribution <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> on functions mapping <img src="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S&#92;to T" class="latex" /> is called <em>pairwise uniform</em> if for every <img src="https://s0.wp.com/latex.php?latex=x%2Cx%27%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x%2Cx%27%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x%2Cx%27%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x,x&#039;&#92;in S" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y%2Cy%27%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y%2Cy%27%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y%2Cy%27%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y,y&#039;&#92;in T" class="latex" /> one has</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BH%7D%5BH%28x%29%3Dy%5Cwedge+H%28x%27%29%3Dy%27%5D%3D1%2F%7CT%7C%5E%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BH%7D%5BH%28x%29%3Dy%5Cwedge+H%28x%27%29%3Dy%27%5D%3D1%2F%7CT%7C%5E%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BP%7D_%7BH%7D%5BH%28x%29%3Dy%5Cwedge+H%28x%27%29%3Dy%27%5D%3D1%2F%7CT%7C%5E%7B2%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;mathbb {P}_{H}[H(x)=y&#92;wedge H(x&#039;)=y&#039;]=1/|T|^{2}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   This is saying that on every pair of inputs <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> is behaving as a completely uniform function. Yet unlike completely uniform functions, the next lemma shows that pairwise uniform functions can have a short description, which makes them suitable for use in algorithms.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69004r6"></a> <b>Exercise</b> 5.6.  </span>Let <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{q}" class="latex" /> be a finite field. Define the random function <img src="https://s0.wp.com/latex.php?latex=H%3A%5Cmathbb+%7BF%7D_%7Bq%7D%5Cto+%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%3A%5Cmathbb+%7BF%7D_%7Bq%7D%5Cto+%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%3A%5Cmathbb+%7BF%7D_%7Bq%7D%5Cto+%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H:&#92;mathbb {F}_{q}&#92;to &#92;mathbb {F}_{q}" class="latex" /> as <img src="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3DAx%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3DAx%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28x%29%3A%3DAx%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(x):=Ax+B" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A%2CB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A,B" class="latex" /> are uniform in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BF%7D_%7Bq%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb {F}_{q}" class="latex" />.</p>
<p style="text-align:justify">   Prove that <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> is pairwise uniform.</p>
<p style="text-align:justify">   Explain how to use <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> to obtain a pairwise uniform function from <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{t}" class="latex" /> for any given <img src="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;le n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69005r7"></a> <b>Exercise</b> 5.7.  </span>Define the random function <img src="https://s0.wp.com/latex.php?latex=H_%7B1%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H_%7B1%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H_%7B1%7D%3A%5C%7B0%2C1%5C%7D+%5E%7Bn%7D%5Cto+%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H_{1}:&#92;{0,1&#92;} ^{n}&#92;to &#92;{0,1&#92;} " class="latex" /> as <img src="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3D%5Csum+_%7Bi%5Cle+n%7DA_%7Bi%7Dx_%7Bi%7D%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28x%29%3A%3D%5Csum+_%7Bi%5Cle+n%7DA_%7Bi%7Dx_%7Bi%7D%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28x%29%3A%3D%5Csum+_%7Bi%5Cle+n%7DA_%7Bi%7Dx_%7Bi%7D%2BB&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(x):=&#92;sum _{i&#92;le n}A_{i}x_{i}+B" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="A" class="latex" /> is uniform in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="B" class="latex" /> is uniform in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} " class="latex" />.</p>
<p style="text-align:justify">   Prove that <img src="https://s0.wp.com/latex.php?latex=H_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H_%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H_{1}" class="latex" /> is pairwise uniform.</p>
<p style="text-align:justify">   Explain how to use <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> to obtain a pairwise uniform function from <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{t}" class="latex" /> for any given <img src="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=t%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="t&#92;le n" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">   We can now state the lemma that we use to isolate assignments.</p>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-69006r2"></a> <b>Lemma</b> 5.2.  </span>Let <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H" class="latex" /> be a pairwise uniform function mapping <img src="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S%5Cto+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S&#92;to T" class="latex" />, and let <img src="https://s0.wp.com/latex.php?latex=1%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1%5Cin+T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1&#92;in T" class="latex" />. The probability that there is a unique element <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=H%28s%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=H%28s%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=H%28s%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="H(s)=1" class="latex" /> is</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B%7CS%7C%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C%5E%7B2%7D%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B%7CS%7C%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C%5E%7B2%7D%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B%7CS%7C%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C%5E%7B2%7D%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;ge &#92;frac {|S|}{|T|}-&#92;frac {|S|^{2}}{|T|^{2}}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   In particular, if <img src="https://s0.wp.com/latex.php?latex=%7CT%7C%2F8%5Cle+%7CS%7C%5Cle+%7CT%7C%2F4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7CT%7C%2F8%5Cle+%7CS%7C%5Cle+%7CT%7C%2F4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7CT%7C%2F8%5Cle+%7CS%7C%5Cle+%7CT%7C%2F4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="|T|/8&#92;le |S|&#92;le |T|/4" class="latex" /> this prob.&nbsp;is <img src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cfrac+%7B1%7D%7B8%7D-%5Cfrac+%7B1%7D%7B16%7D%5Cge+1%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+%5Cfrac+%7B1%7D%7B8%7D-%5Cfrac+%7B1%7D%7B16%7D%5Cge+1%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+%5Cfrac+%7B1%7D%7B8%7D-%5Cfrac+%7B1%7D%7B16%7D%5Cge+1%2F8&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge &#92;frac {1}{8}-&#92;frac {1}{16}&#92;ge 1/8" class="latex" />.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof</b>.&nbsp;</span>For fixed <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" />, the probability <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> is the unique element mapped to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> is at least the prob.&nbsp;that <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> is mapped to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> minus the prob.&nbsp;that both <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s" class="latex" /> and some other <img src="https://s0.wp.com/latex.php?latex=s%27%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%27%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%27%5Cne+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#039;&#92;ne s" class="latex" /> are mapped to <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" />. This is</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B1%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C-1%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B1%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C-1%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cge+%5Cfrac+%7B1%7D%7B%7CT%7C%7D-%5Cfrac+%7B%7CS%7C-1%7D%7B%7CT%7C%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} &#92;ge &#92;frac {1}{|T|}-&#92;frac {|S|-1}{|T|^{2}}. &#92;end{aligned}" class="latex" /></div>
<p style="text-align:justify">   These events for different <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" /> are disjoint; so the target probability is at least the sum of the above over <img src="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cin+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;in S" class="latex" />. <b>QED</b></p>
</div>
<p style="text-align:justify">
<div class="proof">
<p style="text-align:justify">   <span class="head">    <b>Proof of Theorem <a href="#x1-69002r8">5.8<!--tex4ht:ref: thm:3Sat-reduces-to-unique --></a></b>.&nbsp;</span> Given a 3Sat instance <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cle+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;le n" class="latex" /> variables <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, we pick a random <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> from <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="0" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=n%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%2Bc&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n+c" class="latex" />. We then pick a pairwise uniform function mapping <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{n}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+%5E%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;{0,1&#92;} ^{i}" class="latex" />, and consider the circuit</p>
<div style="text-align: center"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%3A%3D%5Cphi+%28x%29%5Cwedge+H%28x%29%3D0%5E%7Bi%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%3A%3D%5Cphi+%28x%29%5Cwedge+H%28x%29%3D0%5E%7Bi%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+C%3A%3D%5Cphi+%28x%29%5Cwedge+H%28x%29%3D0%5E%7Bi%7D.+%5Cend%7Baligned%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;begin{aligned} C:=&#92;phi (x)&#92;wedge H(x)=0^{i}. &#92;end{aligned}" class="latex" /></div>
<p>This circuit has size <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=n%5E%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="n^{c}" class="latex" />.</p>
<p style="text-align:justify">   If <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> is not satisfiable, <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> is not satisfiable, for any random choices.</p>
<p style="text-align:justify">   Now suppose that <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cphi+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;phi " class="latex" /> has <img src="https://s0.wp.com/latex.php?latex=s%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s%5Cge+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s&#92;ge 1" class="latex" /> satisfying assignment. With prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+1%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 1/n" class="latex" /> we will have <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bi-3%7D%5Cle+s%5Cle+2%5E%7Bi-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=2%5E%7Bi-3%7D%5Cle+s%5Cle+2%5E%7Bi-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=2%5E%7Bi-3%7D%5Cle+s%5Cle+2%5E%7Bi-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="2^{i-3}&#92;le s&#92;le 2^{i-2}" class="latex" />, in which case Lemma <a href="#x1-69006r2">5.2<!--tex4ht:ref: lem:pairwise-uniform-unique --></a> guarantees that <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> has a unique satisfying assignment with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c" class="latex" />.</p>
<p style="text-align:justify">   Overall, <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> has a unique satisfying assignment with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c/n" class="latex" />. Hence the Unique-3Sat algorithm on <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> outputs <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="1" class="latex" /> with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+c%2Fn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge c/n" class="latex" />. If we repeat this process <img src="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=cn&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="cn" class="latex" /> times, with independent random choices, the Or of the outcomes gives the correct answer with prob.&nbsp;<img src="https://s0.wp.com/latex.php?latex=%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cge+2%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;ge 2/3" class="latex" />. <b>QED</b></p>
</div>
<p style="text-align:justify">
<h3 class="sectionHead"><span class="titlemark">5.6   </span> <a id="x1-700005.6"></a>Problems</h3>
<div class="newtheorem">
<p style="text-align:justify"><span class="head"> <a id="x1-70001r1"></a> <b>Problem</b> 5.1.  </span>In Theorem <a href="#x1-52002r5">4.5<!--tex4ht:ref: thm:Search-3Sat-power-time-reduces --></a> we reduced Search-3Sat to 3Sat.</p>
<p style="text-align:justify">   &#8211; Suppose 3Sat is computable by circuits of depth <img src="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=c%5Clog+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="c&#92;log n" class="latex" />. What would be the depth of the circuits for Search-3Sat given by the reduction?</p>
<p style="text-align:justify">   &#8211; Reduce Search-3Sat to 3Sat in <img src="https://s0.wp.com/latex.php?latex=%5Ctext+%7B%5Censuremath+%7B%5Cbigcup+_%7Ba%3E0%7D%7D%7D%5Ctext+%7BDepth%7D%28a%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Ctext+%7B%5Censuremath+%7B%5Cbigcup+_%7Ba%3E0%7D%7D%7D%5Ctext+%7BDepth%7D%28a%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Ctext+%7B%5Censuremath+%7B%5Cbigcup+_%7Ba%3E0%7D%7D%7D%5Ctext+%7BDepth%7D%28a%5Clog+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;text {&#92;ensuremath {&#92;bigcup _{a&gt;0}}}&#92;text {Depth}(a&#92;log n)" class="latex" />.</p>
<p style="text-align:justify">   Hint: First work with randomized circuits. Use ideas in proof of Theorem <a href="#x1-52002r5">4.5<!--tex4ht:ref: thm:Search-3Sat-power-time-reduces --></a>.</p>
<p style="text-align:justify">
</div>
<p style="text-align:justify">
<h3 class="likesectionHead"><a id="x1-710005.6"></a>References</h3>
<p style="text-align:justify">
<div class="thebibliography">
<p class="bibitem"><span class="biblabel">   [1]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/focs/AbboudBW15"></a>Amir Abboud, Arturs Backurs, and Virginia&nbsp;Vassilevska Williams. Tight hardness      results for LCS and other sequence similarity measures.  In Venkatesan Guruswami,      editor, IEEE 56th Annual Symposium on Foundations of Computer Science, FOCS      2015, Berkeley, CA, USA, 17-20 October, 2015, pages 59–78. IEEE Computer Society,      2015.</p>
<p class="bibitem"><span class="biblabel">   [2]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAdleman78"></a>Leonard  Adleman.   Two  theorems  on  random  polynomial  time.   In  19th IEEE      Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 75–83. 1978.</p>
<p class="bibitem"><span class="biblabel">   [3]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/AngluinV79"></a>Dana Angluin and Leslie&nbsp;G. Valiant. Fast probabilistic algorithms for hamiltonian      circuits and matchings. J. Comput. Syst. Sci., 18(2):155–193, 1979.</p>
<p class="bibitem"><span class="biblabel">   [4]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XAroraLuMoSuSz98"></a>Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.      Proof  verification  and  the  hardness  of  approximation  problems.    J.&nbsp;of  the  ACM,      45(3):501–555, May 1998.</p>
<p class="bibitem"><span class="biblabel">   [5]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/BackursI18"></a>Arturs Backurs and Piotr Indyk.  Edit distance cannot be computed in strongly      subquadratic time (unless SETH is false). SIAM J. Comput., 47(3):1087–1097, 2018.</p>
<p class="bibitem"><span class="biblabel">   [6]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XBatcher68"></a>Kenneth&nbsp;E. Batcher.  Sorting networks and their applications.  In AFIPS Spring      Joint Computing Conference, volume&nbsp;32, pages 307–314, 1968.</p>
<p class="bibitem"><span class="biblabel">   [7]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XCook73"></a>Stephen&nbsp;A. Cook. A hierarchy for nondeterministic time complexity. J.&nbsp;of Computer      and System Sciences, 7(4):343–353, 1973.</p>
<p class="bibitem"><span class="biblabel">   [8]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jct/FraenkelL81"></a>Aviezri&nbsp;S. Fraenkel and David Lichtenstein. Computing a perfect strategy for n x n      chess requires time exponential in n. J. Comb. Theory, Ser. A, 31(2):199–214, 1981.</p>
<p class="bibitem"><span class="biblabel">   [9]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGajentaanO95"></a>Anka Gajentaan and Mark&nbsp;H. Overmars. On a class of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%7D%28n%5E2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{O}(n^2)" class="latex" /> problems in computational      geometry. Comput. Geom., 5:165–185, 1995.</p>
<p class="bibitem"><span class="biblabel">  [10]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGareyJ79"></a>M.&nbsp;R. Garey and David&nbsp;S. Johnson. Computers and Intractability: A Guide to the      Theory of NP-Completeness. W. H. Freeman, 1979.</p>
<p class="bibitem"><span class="biblabel">  [11]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR1549939"></a>K.&nbsp;G÷del.   ▄ber  formal  unentscheidbare  sΣtze  der  Principia  Mathematica  und      verwandter systeme I. Monatsh. Math. Phys., 38, 1931.</p>
<p class="bibitem"><span class="biblabel">  [12]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XGoldreich08Complexity"></a>Oded Goldreich. Computational Complexity: A Conceptual Perspective. Cambridge      University Press, 2008.</p>
<p class="bibitem"><span class="biblabel">  [13]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="X10.4007/annals.2021.193.2.4"></a>David Harvey and Joris van&nbsp;der Hoeven. Integer multiplication in time <img src="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=O%28n%5Cmathrm+%7Blog%7D%5C%2C+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="O(n&#92;mathrm {log}&#92;, n)" class="latex" />. Annals of      Mathematics, 193(2):563 – 617, 2021.</p>
<p class="bibitem"><span class="biblabel">  [14]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/iandc/Hennie65"></a>F.&nbsp;C. Hennie.  One-tape, off-line turing machine computations.  Information and      Control, 8(6):553–578, 1965.</p>
<p class="bibitem"><span class="biblabel">  [15]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XHennieS66"></a>Fred  Hennie  and  Richard  Stearns.    Two-tape  simulation  of  multitape  turing      machines. J.&nbsp;of the ACM, 13:533–546, October 1966.</p>
<p class="bibitem"><span class="biblabel">  [16]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIP99"></a>Russell Impagliazzo and Ramamohan Paturi.   The complexity of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-sat.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 237–, 1999.</p>
<p class="bibitem"><span class="biblabel">  [17]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XIPZ01"></a>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.  Which problems have      strongly exponential complexity? J. Computer &amp; Systems Sciences, 63(4):512–530, Dec      2001.</p>
<p class="bibitem"><span class="biblabel">  [18]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XImW97"></a>Russell  Impagliazzo  and  Avi  Wigderson.    <img src="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathit+%7BP%7D+%3D+%5Cmathit+%7BBPP%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathit {P} = &#92;mathit {BPP}" class="latex" />  if  <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="E" class="latex" />  requires  exponential  circuits:      Derandomizing the XOR lemma.  In 29th ACM Symp.&nbsp;on the Theory of Computing      (STOC), pages 220–229. ACM, 1997.</p>
<p class="bibitem"><span class="biblabel">  [19]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XKobayashi1985OnTS"></a>Kojiro Kobayashi.  On the structure of one-tape nondeterministic turing machine      time hierarchy. Theor. Comput. Sci., 40:175–193, 1985.</p>
<p class="bibitem"><span class="biblabel">  [20]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLevin73"></a>Leonid&nbsp;A.  Levin.    Universal  sequential  search  problems.    Problemy  Peredachi      Informatsii, 9(3):115–116, 1973.</p>
<p class="bibitem"><span class="biblabel">  [21]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XLupanov58"></a>O.&nbsp;B. Lupanov. A method of circuit synthesis. Izv. VUZ Radiofiz., 1:120–140, 1958.</p>
<p class="bibitem"><span class="biblabel">  [22]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViolaNEU-ram2sat-neu-author"></a>NEU. From RAM to SAT. Available at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2012.</p>
<p class="bibitem"><span class="biblabel">  [23]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/jcss/PapadimitriouY91"></a>Christos&nbsp;H. Papadimitriou and Mihalis Yannakakis. Optimization, approximation,                                                                                                                                                                                          and complexity classes. J. Comput. Syst. Sci., 43(3):425–440, 1991.</p>
<p class="bibitem"><span class="biblabel">  [24]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPPST83"></a>Wolfgang&nbsp;J. Paul, Nicholas Pippenger, Endre SzemerΘdi, and William&nbsp;T. Trotter.      On determinism versus non-determinism and related problems (preliminary version). In      IEEE Symp.&nbsp;on Foundations of Computer Science (FOCS), pages 429–438, 1983.</p>
<p class="bibitem"><span class="biblabel">  [25]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XPippengerF79"></a>Nicholas Pippenger and Michael&nbsp;J. Fischer. Relations among complexity measures.      J.&nbsp;of the ACM, 26(2):361–381, 1979.</p>
<p class="bibitem"><span class="biblabel">  [26]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Robson84"></a>J.&nbsp;M.  Robson.    N  by  N  checkers  is  exptime  complete.    SIAM  J.  Comput.,      13(2):252–267, 1984.</p>
<p class="bibitem"><span class="biblabel">  [27]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:conf/coco/Santhanam01"></a>Rahul Santhanam.   On separators, segregators and time versus space.   In IEEE      Conf.&nbsp;on Computational Complexity (CCC), pages 286–294, 2001.</p>
<p class="bibitem"><span class="biblabel">  [28]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/siamcomp/Schonhage80"></a>Arnold Sch÷nhage. Storage modification machines. SIAM J. Comput., 9(3):490–508,      1980.</p>
<p class="bibitem"><span class="biblabel">  [29]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR29860"></a>Claude&nbsp;E. Shannon. The synthesis of two-terminal switching circuits. Bell System      Tech. J., 28:59–98, 1949.</p>
<p class="bibitem"><span class="biblabel">  [30]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XSho90"></a>Victor Shoup. New algorithms for finding irreducible polynomials over finite fields.      Mathematics of Computation, 54(189):435–447, 1990.</p>
<p class="bibitem"><span class="biblabel">  [31]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XMR2145856"></a>Larry Stockmeyer and Albert&nbsp;R. Meyer.  Cosmological lower bound on the circuit      complexity of a small problem in logic. J. ACM, 49(6):753–784, 2002.</p>
<p class="bibitem"><span class="biblabel">  [32]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/x/Turing37"></a>Alan&nbsp;M.   Turing.      On   computable   numbers,   with   an   application   to   the      entscheidungsproblem. Proc. London Math. Soc., s2-42(1):230–265, 1937.</p>
<p class="bibitem"><span class="biblabel">  [33]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XDBLP:journals/tcs/ValiantV86"></a>Leslie&nbsp;G. Valiant and Vijay&nbsp;V. Vazirani. NP is as easy as detecting unique solutions.      Theor. Comput. Sci., 47(3):85–93, 1986.</p>
<p class="bibitem"><span class="biblabel">  [34]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="XViola-xxx"></a>Emanuele Viola.  Reducing 3XOR to listing triangles, an exposition.  Available at      <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2011.</p>
<p class="bibitem"><span class="biblabel">  [35]<span class="bibsp">&nbsp;&nbsp;&nbsp;</span></span><a id="Xviola-tm"></a>Emanuele  Viola.   Pseudorandom  bits  and  lower  bounds  for  randomized  turing      machines. Theory of Computing, 18(10):1–12, 2022.</p>
</div>
<p class="authors">By Manu</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T19:33:28Z">Thursday, February 23 2023, 19:33</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/02/the-virtual-grad-student.html'>The Virtual Grad Student</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Martin Haug, who is working on a LaTeX alternative Typst, asked me if I had updates on a LaTeX rant from 2011. I haven't seen any new serious backward compatibility problems. We have easier collaboration through on-line editors like Overleaf. We have got closer to WSYWIG thanks to quick compiling but still not at the level of Word or Google Docs. The big problem of user friendliness remains. There's a reason LaTeX has its own Stack Exchange.&nbsp;</p><p>But we live in a new machine learning world. Can we use generative AI to make LaTeX easier to use?</p><p>Mandatory Disclaimer: Generative AI can sometimes create inaccurate, inappropriate or previously-published material. You are ultimately responsible for the contents of your paper no matter how you produced it.</p><p>Since I sometimes think of LaTeX as a programming language for papers, I tweeted</p>
<blockquote><p>Can we have GitHub co-pilot for LaTeX?</p>— Lance Fortnow (@fortnow) February 17, 2023</blockquote><p>Thanks for the responses. The answer to the question is yes, GitHub Copilot&nbsp;works for LaTeX if you edit LaTeX in a programming environment like VS Code, Neovim or Jet Brains. It helps with formatting of formulas and pictures, less so on the text itself. I made a video so you can see how it works.</p>
<p>Latext AI offers a chrome extension that will let you generate text via GPT in Overleaf based on a prompt or previous text, though Latext requires a subscription after a one-week trial. You can also just cut and paste between any text editor and ChatGPT.</p><p>ChatGPT notoriously makes up references if you ask for them. Can we have a good system that finds relevant articles to cite and adds them automatically into your bibliography?</p><p>Ideally all these should work together seamlessly, suggestions that happen as you type. A true co-pilot for research papers.</p><p>There are many more tools out there, feel free to add them to the comments. I expect the integration to improve over time as we develop new APIs and models.</p><p>I look forward to the days of a virtual grad student: Here's a research goal and an idea to get there. Now go figure out the details and write the paper.&nbsp;</p><p>It will be a long wait.</p> <p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Martin Haug, who is working on a LaTeX alternative <a href="https://typst.app/">Typst</a>, asked me if I had updates on a <a href="https://blog.computationalcomplexity.org/2011/07/problems-of-latex.html">LaTeX rant</a> from 2011. I haven't seen any new serious backward compatibility problems. We have easier collaboration through on-line editors like <a href="https://blog.computationalcomplexity.org/2011/07/problems-of-latex.html">Overleaf</a>. We have got closer to WSYWIG thanks to quick compiling but still not at the level of Word or Google Docs. The big problem of user friendliness remains. There's a reason LaTeX has its own <a href="https://tex.stackexchange.com/">Stack Exchange</a>.&nbsp;</p><p>But we live in a new machine learning world. Can we use generative AI to make LaTeX easier to use?</p><p><b>Mandatory Disclaimer</b>: Generative AI can sometimes create inaccurate, inappropriate or previously-published material. You are ultimately responsible for the contents of your paper no matter how you produced it.</p><p>Since I sometimes think of LaTeX as a programming language for papers, I <a href="https://twitter.com/fortnow/status/1626576896132542464">tweeted</a></p>
<blockquote class="twitter-tweet"><p dir="ltr" lang="en">Can we have GitHub co-pilot for LaTeX?</p>— Lance Fortnow (@fortnow) <a href="https://twitter.com/fortnow/status/1626576896132542464?ref_src=twsrc%5Etfw">February 17, 2023</a></blockquote><p>Thanks for the responses. The answer to the question is yes, <a href="https://github.com/features/copilot">GitHub Copilot</a>&nbsp;works for LaTeX if you edit LaTeX in a programming environment like <a href="https://code.visualstudio.com/">VS Code</a>, <a href="https://code.visualstudio.com/">Neovim</a> or <a href="https://code.visualstudio.com/">Jet Brains</a>. It helps with formatting of formulas and pictures, less so on the text itself. I made a <a href="https://www.youtube.com/watch?v=bt0BNdujIy8">video</a> so you can see how it works.</p>
<div style="text-align: center;"><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/bt0BNdujIy8" title="YouTube video player" width="560"></iframe></div><p><a href="https://www.latextai.com/">Latext AI</a> offers a chrome extension that will let you generate text via GPT in Overleaf based on a prompt or previous text, though Latext requires a subscription after a one-week trial. You can also just cut and paste between any text editor and ChatGPT.</p><p>ChatGPT notoriously makes up references if you ask for them. Can we have a good system that finds relevant articles to cite and adds them automatically into your bibliography?</p><p>Ideally all these should work together seamlessly, suggestions that happen as you type. A true co-pilot for research papers.</p><p>There are many more tools out there, feel free to add them to the comments. I expect the integration to improve over time as we develop new APIs and models.</p><p>I look forward to the days of a virtual grad student: Here's a research goal and an idea to get there. Now go figure out the details and write the paper.&nbsp;</p><p>It will be a long wait.</p> <script async="" charset="utf-8" src="https://platform.twitter.com/widgets.js"></script><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T15:02:00Z">Thursday, February 23 2023, 15:02</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.10972'>Complexity of Maker-Breaker Games on Edge Sets of Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Eric Duch&#xea;ne, Valentin Gledel, Fionn Mc Inerney, Nicolas Nisse, Nacim Oijid, Aline Parreau, Milo&#x161; Stojakovi&#x107;</p><p>We initiate the study of the algorithmic complexity of Maker-Breaker games
played on edge sets of graphs for general graphs. We mainly consider three of
the big four such games: the connectivity game, perfect matching game, and
$H$-game. Maker wins if she claims the edges of a spanning tree in the first, a
perfect matching in the second, and a copy of a fixed graph $H$ in the third.
We prove that deciding who wins the perfect matching game and the $H$-game is
PSPACE-complete, even for the latter in graphs of small diameter if $H$ is a
tree. Seeking to find the smallest graph $H$ such that the $H$-game is
PSPACE-complete, we also prove that there exists such an $H$ of order 51 and
size 57.
</p>
<p>On the positive side, we show that the connectivity game and arboricity-$k$
game are polynomial-time solvable. We then give several positive results for
the $H$-game, first giving a structural characterization for Breaker to win the
$P_4$-game, which gives a linear-time algorithm for the $P_4$-game. We provide
a structural characterization for Maker to win the $K_{1,\ell}$-game in trees,
which implies a linear-time algorithm for the $K_{1,\ell}$-game in trees.
Lastly, we prove that the $K_{1,\ell}$-game in any graph, and the $H$-game in
trees are both FPT parameterized by the length of the game. We leave the
complexity of the last of the big four games, the Hamiltonicity game, as an
open question.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Duchene_E/0/1/0/all/0/1">Eric Duch&#xea;ne</a>, <a href="http://arxiv.org/find/cs/1/au:+Gledel_V/0/1/0/all/0/1">Valentin Gledel</a>, <a href="http://arxiv.org/find/cs/1/au:+Inerney_F/0/1/0/all/0/1">Fionn Mc Inerney</a>, <a href="http://arxiv.org/find/cs/1/au:+Nisse_N/0/1/0/all/0/1">Nicolas Nisse</a>, <a href="http://arxiv.org/find/cs/1/au:+Oijid_N/0/1/0/all/0/1">Nacim Oijid</a>, <a href="http://arxiv.org/find/cs/1/au:+Parreau_A/0/1/0/all/0/1">Aline Parreau</a>, <a href="http://arxiv.org/find/cs/1/au:+Stojakovic_M/0/1/0/all/0/1">Milo&#x161; Stojakovi&#x107;</a></p><p>We initiate the study of the algorithmic complexity of Maker-Breaker games
played on edge sets of graphs for general graphs. We mainly consider three of
the big four such games: the connectivity game, perfect matching game, and
$H$-game. Maker wins if she claims the edges of a spanning tree in the first, a
perfect matching in the second, and a copy of a fixed graph $H$ in the third.
We prove that deciding who wins the perfect matching game and the $H$-game is
PSPACE-complete, even for the latter in graphs of small diameter if $H$ is a
tree. Seeking to find the smallest graph $H$ such that the $H$-game is
PSPACE-complete, we also prove that there exists such an $H$ of order 51 and
size 57.
</p>
<p>On the positive side, we show that the connectivity game and arboricity-$k$
game are polynomial-time solvable. We then give several positive results for
the $H$-game, first giving a structural characterization for Breaker to win the
$P_4$-game, which gives a linear-time algorithm for the $P_4$-game. We provide
a structural characterization for Maker to win the $K_{1,\ell}$-game in trees,
which implies a linear-time algorithm for the $K_{1,\ell}$-game in trees.
Lastly, we prove that the $K_{1,\ell}$-game in any graph, and the $H$-game in
trees are both FPT parameterized by the length of the game. We leave the
complexity of the last of the big four games, the Hamiltonicity game, as an
open question.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11290'>Logical Equivalences, Homomorphism Indistinguishability, and Forbidden Minors</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tim Seppelt</p><p>Two graphs $G$ and $H$ are homomorphism indistinguishable over a class of
graphs $\mathcal{F}$ if for all graphs $F \in \mathcal{F}$ the number of
homomorphisms from $F$ to $G$ equals the number of homomorphisms from $F$ to
$H$. Many natural equivalence relations comparing graphs such as (quantum)
isomorphism, spectral, and logical equivalences can be characterised as
homomorphism indistinguishability relations over certain graph classes.
</p>
<p>In this article, the interplay of the properties of a graph class and its
homomorphism indistinguishability relation are studied. As an application,
self-complementarity, a property of logics on graphs satisfied by many
well-studied logics, is identified. It is proven that the equivalence over a
self-complementary logic admitting a characterisation as homomorphism
indistinguishability relation can be characterised by homomorphism
indistinguishability over a minor-closed graph class. Thereby, first evidences
are provided for a possible connection between minors and homomorphism
indistinguishability as conjectured by Roberson (2022).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Seppelt_T/0/1/0/all/0/1">Tim Seppelt</a></p><p>Two graphs $G$ and $H$ are homomorphism indistinguishable over a class of
graphs $\mathcal{F}$ if for all graphs $F \in \mathcal{F}$ the number of
homomorphisms from $F$ to $G$ equals the number of homomorphisms from $F$ to
$H$. Many natural equivalence relations comparing graphs such as (quantum)
isomorphism, spectral, and logical equivalences can be characterised as
homomorphism indistinguishability relations over certain graph classes.
</p>
<p>In this article, the interplay of the properties of a graph class and its
homomorphism indistinguishability relation are studied. As an application,
self-complementarity, a property of logics on graphs satisfied by many
well-studied logics, is identified. It is proven that the equivalence over a
self-complementary logic admitting a characterisation as homomorphism
indistinguishability relation can be characterised by homomorphism
indistinguishability over a minor-closed graph class. Thereby, first evidences
are provided for a possible connection between minors and homomorphism
indistinguishability as conjectured by Roberson (2022).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11417'>Hitting the Romans</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Henning Fernau, Kevin Mann</p><p>Roman domination is one of few examples where the related extension problem
is polynomial-time solvable even if the original decision problem is
NP-complete. This is interesting, as it allows to establish polynomial-delay
enumeration algorithms for finding minimal Roman dominating functions, while it
is open for more than four decades if all minimal dominating sets of a graph or
if all hitting sets of a hypergraph can be enumerated with polynomial delay. To
find the reason why this is the case, we combine the idea of hitting set with
the idea of Roman domination. We hence obtain and study two new problems,
called Roman Hitting Function and Roman Hitting Set, both generalizing Roman
Domination. This allows us to delineate the borderline of polynomial-delay
enumerability. Here, we assume what we call the Hitting Set Transversal Thesis,
claiming that it is impossible to enumerate all minimal hitting sets of a
hypergraph with polynomial delay. Our first focus is on the extension versions
of these problems. While doing this, we find some conditions under which the
Extension Roman Hitting Function problem is NP-complete. We then use
parameterized complexity to get a better understanding of why Extension Roman
Hitting Function behaves in this way. Furthermore, we analyze the parameterized
and approximation complexity of the underlying optimization problems. We also
discuss consequences for Roman variants of other problems like Vertex Cover.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fernau_H/0/1/0/all/0/1">Henning Fernau</a>, <a href="http://arxiv.org/find/cs/1/au:+Mann_K/0/1/0/all/0/1">Kevin Mann</a></p><p>Roman domination is one of few examples where the related extension problem
is polynomial-time solvable even if the original decision problem is
NP-complete. This is interesting, as it allows to establish polynomial-delay
enumeration algorithms for finding minimal Roman dominating functions, while it
is open for more than four decades if all minimal dominating sets of a graph or
if all hitting sets of a hypergraph can be enumerated with polynomial delay. To
find the reason why this is the case, we combine the idea of hitting set with
the idea of Roman domination. We hence obtain and study two new problems,
called Roman Hitting Function and Roman Hitting Set, both generalizing Roman
Domination. This allows us to delineate the borderline of polynomial-delay
enumerability. Here, we assume what we call the Hitting Set Transversal Thesis,
claiming that it is impossible to enumerate all minimal hitting sets of a
hypergraph with polynomial delay. Our first focus is on the extension versions
of these problems. While doing this, we find some conditions under which the
Extension Roman Hitting Function problem is NP-complete. We then use
parameterized complexity to get a better understanding of why Extension Roman
Hitting Function behaves in this way. Furthermore, we analyze the parameterized
and approximation complexity of the underlying optimization problems. We also
discuss consequences for Roman variants of other problems like Vertex Cover.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11454'>Quantum complexity of the Kronecker coefficients</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sergey Bravyi, Anirban Chowdhury, David Gosset, Vojtech Havlicek, Guanyu Zhu</p><p>Whether or not the Kronecker coefficients of the symmetric group count some
set of combinatorial objects is a longstanding open question. In this work we
show that a given Kronecker coefficient is proportional to the rank of a
projector that can be measured efficiently using a quantum computer. In other
words a Kronecker coefficient counts the dimension of the vector space spanned
by the accepting witnesses of a QMA verifier, where QMA is the quantum analogue
of NP. This implies that approximating the Kronecker coefficients to within a
given relative error is not harder than a certain natural class of quantum
approximate counting problems that captures the complexity of estimating
thermal properties of quantum many-body systems. A second consequence is that
deciding positivity of Kronecker coefficients is contained in QMA,
complementing a recent NP-hardness result of Ikenmeyer, Mulmuley and Walter. We
obtain similar results for the related problem of approximating row sums of the
character table of the symmetric group. Finally, we discuss an efficient
quantum algorithm that approximates normalized Kronecker coefficients to
inverse-polynomial additive error.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Bravyi_S/0/1/0/all/0/1">Sergey Bravyi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chowdhury_A/0/1/0/all/0/1">Anirban Chowdhury</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gosset_D/0/1/0/all/0/1">David Gosset</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Havlicek_V/0/1/0/all/0/1">Vojtech Havlicek</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhu_G/0/1/0/all/0/1">Guanyu Zhu</a></p><p>Whether or not the Kronecker coefficients of the symmetric group count some
set of combinatorial objects is a longstanding open question. In this work we
show that a given Kronecker coefficient is proportional to the rank of a
projector that can be measured efficiently using a quantum computer. In other
words a Kronecker coefficient counts the dimension of the vector space spanned
by the accepting witnesses of a QMA verifier, where QMA is the quantum analogue
of NP. This implies that approximating the Kronecker coefficients to within a
given relative error is not harder than a certain natural class of quantum
approximate counting problems that captures the complexity of estimating
thermal properties of quantum many-body systems. A second consequence is that
deciding positivity of Kronecker coefficients is contained in QMA,
complementing a recent NP-hardness result of Ikenmeyer, Mulmuley and Walter. We
obtain similar results for the related problem of approximating row sums of the
character table of the symmetric group. Finally, we discuss an efficient
quantum algorithm that approximates normalized Kronecker coefficients to
inverse-polynomial additive error.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11476'>Matrix Multiplication and Number On the Forehead Communication</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Josh Alman, Jaros&#x142;aw B&#x142;asiok</p><p>Three-player Number On the Forehead communication may be thought of as a
three-player Number In the Hand promise model, in which each player is given
the inputs that are supposedly on the other two players' heads, and promised
that they are consistent with the inputs of of the other players. The set of
all allowed inputs under this promise may be thought of as an order-3 tensor.
We surprisingly observe that this tensor is exactly the matrix multiplication
tensor, which is widely studied in the design of fast matrix multiplication
algorithms.
</p>
<p>Using this connection, we prove a number of results about both Number On the
Forehead communication and matrix multiplication, each by using known results
or techniques about the other. For example, we show how the Laser method, a key
technique used to design the best matrix multiplication algorithms, can also be
used to design communication protocols for a variety of problems. We also show
how known lower bounds for Number On the Forehead communication can be used to
bound properties of the matrix multiplication tensor such as its zeroing out
subrank. Finally, we substantially generalize known methods based on slice-rank
for studying communication, and show how they directly relate to the matrix
multiplication exponent $\omega$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alman_J/0/1/0/all/0/1">Josh Alman</a>, <a href="http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1">Jaros&#x142;aw B&#x142;asiok</a></p><p>Three-player Number On the Forehead communication may be thought of as a
three-player Number In the Hand promise model, in which each player is given
the inputs that are supposedly on the other two players' heads, and promised
that they are consistent with the inputs of of the other players. The set of
all allowed inputs under this promise may be thought of as an order-3 tensor.
We surprisingly observe that this tensor is exactly the matrix multiplication
tensor, which is widely studied in the design of fast matrix multiplication
algorithms.
</p>
<p>Using this connection, we prove a number of results about both Number On the
Forehead communication and matrix multiplication, each by using known results
or techniques about the other. For example, we show how the Laser method, a key
technique used to design the best matrix multiplication algorithms, can also be
used to design communication protocols for a variety of problems. We also show
how known lower bounds for Number On the Forehead communication can be used to
bound properties of the matrix multiplication tensor such as its zeroing out
subrank. Finally, we substantially generalize known methods based on slice-rank
for studying communication, and show how they directly relate to the matrix
multiplication exponent $\omega$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11433'>Lower Bounds for Intersection Reporting among Flat Objects</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Peyman Afshani, Pingan Cheng</p><p>Recently, Ezra and Sharir [ES22a] showed an $O(n^{3/2+\sigma})$ space and
$O(n^{1/2+\sigma})$ query time data structure for ray shooting among triangles
in $\mathbb{R}^3$. This improves the upper bound given by the classical
$S(n)Q(n)^4=O(n^{4+\sigma})$ space-time tradeoff for the first time in almost
25 years and in fact lies on the tradeoff curve of
$S(n)Q(n)^3=O(n^{3+\sigma})$. However, it seems difficult to apply their
techniques beyond this specific space and time combination. This pheonomenon
appears persistently in almost all recent advances of flat object intersection
searching, e.g., line-tetrahedron intersection in $\mathbb{R}^4$ [ES22b],
triangle-triangle intersection in $\mathbb{R}^4$ [ES22b], or even among flat
semialgebraic objects [AAEKS22].
</p>
<p>We give a timely explanation to this phenomenon from a lower bound
perspective. We prove that given a set $\mathcal{S}$ of $(d-1)$-dimensional
simplicies in $\mathbb{R}^d$, any data structure that can report all
intersections with small ($n^{o(1)}$) query time must use
$\Omega(n^{2(d-1)-o(1)})$ space. This dashes the hope of any significant
improvement to the tradeoff curves for small query time and almost matches the
classical upper bound. We also obtain an almost matching space lower bound of
$\Omega(n^{6-o(1)})$ for triangle-triangle intersection reporting in
$\mathbb{R}^4$ when the query time is small. Along the way, we further develop
the previous lower bound techniques by Afshani and Cheng [AC21, AC22].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Afshani_P/0/1/0/all/0/1">Peyman Afshani</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Pingan Cheng</a></p><p>Recently, Ezra and Sharir [ES22a] showed an $O(n^{3/2+\sigma})$ space and
$O(n^{1/2+\sigma})$ query time data structure for ray shooting among triangles
in $\mathbb{R}^3$. This improves the upper bound given by the classical
$S(n)Q(n)^4=O(n^{4+\sigma})$ space-time tradeoff for the first time in almost
25 years and in fact lies on the tradeoff curve of
$S(n)Q(n)^3=O(n^{3+\sigma})$. However, it seems difficult to apply their
techniques beyond this specific space and time combination. This pheonomenon
appears persistently in almost all recent advances of flat object intersection
searching, e.g., line-tetrahedron intersection in $\mathbb{R}^4$ [ES22b],
triangle-triangle intersection in $\mathbb{R}^4$ [ES22b], or even among flat
semialgebraic objects [AAEKS22].
</p>
<p>We give a timely explanation to this phenomenon from a lower bound
perspective. We prove that given a set $\mathcal{S}$ of $(d-1)$-dimensional
simplicies in $\mathbb{R}^d$, any data structure that can report all
intersections with small ($n^{o(1)}$) query time must use
$\Omega(n^{2(d-1)-o(1)})$ space. This dashes the hope of any significant
improvement to the tradeoff curves for small query time and almost matches the
classical upper bound. We also obtain an almost matching space lower bound of
$\Omega(n^{6-o(1)})$ for triangle-triangle intersection reporting in
$\mathbb{R}^4$ when the query time is small. Along the way, we further develop
the previous lower bound techniques by Afshani and Cheng [AC21, AC22].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11250'>The Complexity of Debt Swapping</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Henri Froese, Martin Hoefer, Lisa Wilhelmi</p><p>A debt swap is an elementary edge swap in a directed, weighted graph, where
two edges with the same weight swap their targets. Debt swaps are a natural and
appealing operation in financial networks, in which nodes are banks and edges
represent debt contracts. They can improve the clearing payments and the
stability of these networks. However, their algorithmic properties are not
well-understood.
</p>
<p>We analyze the computational complexity of debt swapping in networks with
ranking-based clearing. Our main interest lies in semi-positive swaps, in which
no creditor strictly suffers and at least one strictly profits. These swaps
lead to a Pareto-improvement in the entire network. We consider network
optimization via sequences of $v$-improving debt swaps from which a given bank
$v$ strictly profits. We show that every sequence of semi-positive
$v$-improving swaps has polynomial length. In contrast, for arbitrary
$v$-improving swaps, the problem of reaching a network configuration that
allows no further swaps is PLS-complete. We identify cases in which short
sequences of semi-positive swaps exist even without the $v$-improving property.
</p>
<p>In addition, we study reachability problems, i.e., deciding if a sequence of
swaps exists between given initial and final networks. We identify a
polynomial-time algorithm for arbitrary swaps, show NP-hardness for
semi-positive swaps and even PSPACE-completeness for $v$-improving swaps or
swaps that only maintain a lower bound on the assets of a given bank $v$. A
variety of our results can be extended to arbitrary monotone clearing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Froese_H/0/1/0/all/0/1">Henri Froese</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoefer_M/0/1/0/all/0/1">Martin Hoefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilhelmi_L/0/1/0/all/0/1">Lisa Wilhelmi</a></p><p>A debt swap is an elementary edge swap in a directed, weighted graph, where
two edges with the same weight swap their targets. Debt swaps are a natural and
appealing operation in financial networks, in which nodes are banks and edges
represent debt contracts. They can improve the clearing payments and the
stability of these networks. However, their algorithmic properties are not
well-understood.
</p>
<p>We analyze the computational complexity of debt swapping in networks with
ranking-based clearing. Our main interest lies in semi-positive swaps, in which
no creditor strictly suffers and at least one strictly profits. These swaps
lead to a Pareto-improvement in the entire network. We consider network
optimization via sequences of $v$-improving debt swaps from which a given bank
$v$ strictly profits. We show that every sequence of semi-positive
$v$-improving swaps has polynomial length. In contrast, for arbitrary
$v$-improving swaps, the problem of reaching a network configuration that
allows no further swaps is PLS-complete. We identify cases in which short
sequences of semi-positive swaps exist even without the $v$-improving property.
</p>
<p>In addition, we study reachability problems, i.e., deciding if a sequence of
swaps exists between given initial and final networks. We identify a
polynomial-time algorithm for arbitrary swaps, show NP-hardness for
semi-positive swaps and even PSPACE-completeness for $v$-improving swaps or
swaps that only maintain a lower bound on the assets of a given bank $v$. A
variety of our results can be extended to arbitrary monotone clearing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11295'>Fair Correlation Clustering in Forests</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Katrin Casel, Tobias Friedrich, Martin Schirneck, Simon Wietheger</p><p>The study of algorithmic fairness received growing attention recently. This
stems from the awareness that bias in the input data for machine learning
systems may result in discriminatory outputs. For clustering tasks, one of the
most central notions of fairness is the formalization by Chierichetti, Kumar,
Lattanzi, and Vassilvitskii [NeurIPS 2017]. A clustering is said to be fair, if
each cluster has the same distribution of manifestations of a sensitive
attribute as the whole input set. This is motivated by various applications
where the objects to be clustered have sensitive attributes that should not be
over- or underrepresented.
</p>
<p>We discuss the applicability of this fairness notion to Correlation
Clustering. The existing literature on the resulting Fair Correlation
Clustering problem either presents approximation algorithms with poor
approximation guarantees or severely limits the possible distributions of the
sensitive attribute (often only two manifestations with a 1:1 ratio are
considered). Our goal is to understand if there is hope for better results in
between these two extremes. To this end, we consider restricted graph classes
which allow us to characterize the distributions of sensitive attributes for
which this form of fairness is tractable from a complexity point of view.
</p>
<p>While existing work on Fair Correlation Clustering gives approximation
algorithms, we focus on exact solutions and investigate whether there are
efficiently solvable instances. The unfair version of Correlation Clustering is
trivial on forests, but adding fairness creates a surprisingly rich picture of
complexities. We give an overview of the distributions and types of forests
where Fair Correlation Clustering turns from tractable to intractable. The most
surprising insight to us is the fact that the cause of the hardness of Fair
Correlation Clustering is not the strictness of the fairness condition.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Casel_K/0/1/0/all/0/1">Katrin Casel</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrich_T/0/1/0/all/0/1">Tobias Friedrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Schirneck_M/0/1/0/all/0/1">Martin Schirneck</a>, <a href="http://arxiv.org/find/cs/1/au:+Wietheger_S/0/1/0/all/0/1">Simon Wietheger</a></p><p>The study of algorithmic fairness received growing attention recently. This
stems from the awareness that bias in the input data for machine learning
systems may result in discriminatory outputs. For clustering tasks, one of the
most central notions of fairness is the formalization by Chierichetti, Kumar,
Lattanzi, and Vassilvitskii [NeurIPS 2017]. A clustering is said to be fair, if
each cluster has the same distribution of manifestations of a sensitive
attribute as the whole input set. This is motivated by various applications
where the objects to be clustered have sensitive attributes that should not be
over- or underrepresented.
</p>
<p>We discuss the applicability of this fairness notion to Correlation
Clustering. The existing literature on the resulting Fair Correlation
Clustering problem either presents approximation algorithms with poor
approximation guarantees or severely limits the possible distributions of the
sensitive attribute (often only two manifestations with a 1:1 ratio are
considered). Our goal is to understand if there is hope for better results in
between these two extremes. To this end, we consider restricted graph classes
which allow us to characterize the distributions of sensitive attributes for
which this form of fairness is tractable from a complexity point of view.
</p>
<p>While existing work on Fair Correlation Clustering gives approximation
algorithms, we focus on exact solutions and investigate whether there are
efficiently solvable instances. The unfair version of Correlation Clustering is
trivial on forests, but adding fairness creates a surprisingly rich picture of
complexities. We give an overview of the distributions and types of forests
where Fair Correlation Clustering turns from tractable to intractable. The most
surprising insight to us is the fact that the cause of the hardness of Fair
Correlation Clustering is not the strictness of the fairness condition.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11336'>Approximability of the Four-Vertex Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Zhiguo Fu, Tianyu Liu, Xiongxin Yang</p><p>We study the approximability of the four-vertex model, a special case of the
six-vertex model.We prove that, despite being NP-hard to approximate in the
worst case, the four-vertex model admits a fully polynomial randomized
approximation scheme (FPRAS) when the input satisfies certain linear equation
system.The FPRAS is given by a Markov chain called the worm process whose state
space and rapid mixing rely on the solution of the linear equation system.This
is the first attempt to design an FPRAS for the six-vertex model with unwinable
constraint functions.Furthermore, we consider the application of this technique
on planar graphs to give efficient sampling algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zhiguo Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiongxin Yang</a></p><p>We study the approximability of the four-vertex model, a special case of the
six-vertex model.We prove that, despite being NP-hard to approximate in the
worst case, the four-vertex model admits a fully polynomial randomized
approximation scheme (FPRAS) when the input satisfies certain linear equation
system.The FPRAS is given by a Markov chain called the worm process whose state
space and rapid mixing rely on the solution of the linear equation system.This
is the first attempt to design an FPRAS for the six-vertex model with unwinable
constraint functions.Furthermore, we consider the application of this technique
on planar graphs to give efficient sampling algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11151'>Improved Coresets for Clustering with Capacity and Fairness Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Pinyan Lu, Xuan Wu</p><p>We study coresets for clustering with capacity and fairness constraints. Our
main result is a near-linear time algorithm to construct
$\tilde{O}(k^2\varepsilon^{-2z-2})$-sized $\varepsilon$-coresets for
capacitated $(k,z)$-clustering which improves a recent
$\tilde{O}(k^3\varepsilon^{-3z-2})$ bound by [BCAJ+22, HJLW23]. As a corollary,
we also save a factor of $k \varepsilon^{-z}$ on the coreset size for fair
$(k,z)$-clustering compared to them.
</p>
<p>We fundamentally improve the hierarchical uniform sampling framework of
[BCAJ+22] by adaptively selecting sample size on each ring instance,
proportional to its clustering cost to an optimal solution. Our analysis relies
on a key geometric observation that reduces the number of total ``effective
centers" from [BCAJ+22]'s $\tilde{O}(k^2\varepsilon^{-z})$ to merely $O(k\log
\varepsilon^{-1})$ by being able to ``ignore'' all center points that are too
far or too close to the ring center.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pinyan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xuan Wu</a></p><p>We study coresets for clustering with capacity and fairness constraints. Our
main result is a near-linear time algorithm to construct
$\tilde{O}(k^2\varepsilon^{-2z-2})$-sized $\varepsilon$-coresets for
capacitated $(k,z)$-clustering which improves a recent
$\tilde{O}(k^3\varepsilon^{-3z-2})$ bound by [BCAJ+22, HJLW23]. As a corollary,
we also save a factor of $k \varepsilon^{-z}$ on the coreset size for fair
$(k,z)$-clustering compared to them.
</p>
<p>We fundamentally improve the hierarchical uniform sampling framework of
[BCAJ+22] by adaptively selecting sample size on each ring instance,
proportional to its clustering cost to an optimal solution. Our analysis relies
on a key geometric observation that reduces the number of total ``effective
centers" from [BCAJ+22]'s $\tilde{O}(k^2\varepsilon^{-z})$ to merely $O(k\log
\varepsilon^{-1})$ by being able to ``ignore'' all center points that are too
far or too close to the ring center.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11044'>The Target-Charging Technique for Privacy Accounting across Interactive Computations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Edith Cohen, Xin Lyu</p><p>We propose the \emph{Target Charging Technique} (TCT), a unified privacy
accounting framework for interactive settings where a sensitive dataset is
accessed multiple times using differentially private algorithms. Unlike
traditional composition, where privacy guarantees deteriorate quickly with the
number of accesses, TCT allows computations that don't hit a specified
\emph{target}, often the vast majority, to be essentially free (while incurring
instead a small overhead on those that do hit their targets). TCT generalizes
tools such as the sparse vector technique and top-$k$ selection from private
candidates and extends their remarkable privacy accounting benefits from noisy
Lipschitz functions to general private algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cohen_E/0/1/0/all/0/1">Edith Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1">Xin Lyu</a></p><p>We propose the \emph{Target Charging Technique} (TCT), a unified privacy
accounting framework for interactive settings where a sensitive dataset is
accessed multiple times using differentially private algorithms. Unlike
traditional composition, where privacy guarantees deteriorate quickly with the
number of accesses, TCT allows computations that don't hit a specified
\emph{target}, often the vast majority, to be essentially free (while incurring
instead a small overhead on those that do hit their targets). TCT generalizes
tools such as the sparse vector technique and top-$k$ selection from private
candidates and extends their remarkable privacy accounting benefits from noisy
Lipschitz functions to general private algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11068'>Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuzhou Gu, Zhao Song, Junze Yin, Lichen Zhang</p><p>Given a matrix $M\in \mathbb{R}^{m\times n}$, the low rank matrix completion
problem asks us to find a rank-$k$ approximation of $M$ as $UV^\top$ for $U\in
\mathbb{R}^{m\times k}$ and $V\in \mathbb{R}^{n\times k}$ by only observing a
few entries masked by a binary matrix $P_{\Omega}\in \{0, 1 \}^{m\times n}$. As
a particular instance of the weighted low rank approximation problem, solving
low rank matrix completion is known to be computationally hard even to find an
approximate solution [RSW16]. However, due to its practical importance, many
heuristics have been proposed for this problem. In the seminal work of Jain,
Netrapalli, and Sanghavi [JNS13], they show that the alternating minimization
framework provides provable guarantees for low rank matrix completion problem
whenever $M$ admits an incoherent low rank factorization. Unfortunately, their
algorithm requires solving two exact multiple response regressions per
iteration and their analysis is non-robust as they exploit the structure of the
exact solution.
</p>
<p>In this paper, we take a major step towards a more efficient and robust
alternating minimization framework for low rank matrix completion. Our main
result is a robust alternating minimization algorithm that can tolerate
moderate errors even though the regressions are solved approximately.
Consequently, we also significantly improve the running time of [JNS13] from
$\widetilde{O}(mnk^2 )$ to $\widetilde{O}(mnk )$ which is nearly linear in the
problem size, as verifying the low rank approximation takes $O(mnk)$ time. Our
core algorithmic building block is a high accuracy regression solver that
solves the regression in nearly linear time per iteration.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuzhou Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Junze Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lichen Zhang</a></p><p>Given a matrix $M\in \mathbb{R}^{m\times n}$, the low rank matrix completion
problem asks us to find a rank-$k$ approximation of $M$ as $UV^\top$ for $U\in
\mathbb{R}^{m\times k}$ and $V\in \mathbb{R}^{n\times k}$ by only observing a
few entries masked by a binary matrix $P_{\Omega}\in \{0, 1 \}^{m\times n}$. As
a particular instance of the weighted low rank approximation problem, solving
low rank matrix completion is known to be computationally hard even to find an
approximate solution [RSW16]. However, due to its practical importance, many
heuristics have been proposed for this problem. In the seminal work of Jain,
Netrapalli, and Sanghavi [JNS13], they show that the alternating minimization
framework provides provable guarantees for low rank matrix completion problem
whenever $M$ admits an incoherent low rank factorization. Unfortunately, their
algorithm requires solving two exact multiple response regressions per
iteration and their analysis is non-robust as they exploit the structure of the
exact solution.
</p>
<p>In this paper, we take a major step towards a more efficient and robust
alternating minimization framework for low rank matrix completion. Our main
result is a robust alternating minimization algorithm that can tolerate
moderate errors even though the regressions are solved approximately.
Consequently, we also significantly improve the running time of [JNS13] from
$\widetilde{O}(mnk^2 )$ to $\widetilde{O}(mnk )$ which is nearly linear in the
problem size, as verifying the low rank approximation takes $O(mnk)$ time. Our
core algorithmic building block is a high accuracy regression solver that
solves the regression in nearly linear time per iteration.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11081'>Differentially Private $L_2$-Heavy Hitters in the Sliding Window Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jeremiah Blocki, Seunghoon Lee, Tamalika Mukherjee, Samson Zhou</p><p>The data management of large companies often prioritize more recent data, as
a source of higher accuracy prediction than outdated data. For example, the
Facebook data policy retains user search histories for $6$ months while the
Google data retention policy states that browser information may be stored for
up to $9$ months. These policies are captured by the sliding window model, in
which only the most recent $W$ statistics form the underlying dataset.
</p>
<p>In this paper, we consider the problem of privately releasing the $L_2$-heavy
hitters in the sliding window model, which include $L_p$-heavy hitters for
$p\le 2$ and in some sense are the strongest possible guarantees that can be
achieved using polylogarithmic space, but cannot be handled by existing
techniques due to the sub-additivity of the $L_2$ norm. Moreover, existing
non-private sliding window algorithms use the smooth histogram framework, which
has high sensitivity.
</p>
<p>To overcome these barriers, we introduce the first differentially private
algorithm for $L_2$-heavy hitters in the sliding window model by initiating a
number of $L_2$-heavy hitter algorithms across the stream with significantly
lower threshold. Similarly, we augment the algorithms with an approximate
frequency tracking algorithm with significantly higher accuracy. We then use
smooth sensitivity and statistical distance arguments to show that we can add
noise proportional to an estimation of the $L_2$ norm. To the best of our
knowledge, our techniques are the first to privately release statistics that
are related to a sub-additive function in the sliding window model, and may be
of independent interest to future differentially private algorithmic design in
the sliding window model.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blocki_J/0/1/0/all/0/1">Jeremiah Blocki</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seunghoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_T/0/1/0/all/0/1">Tamalika Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Samson Zhou</a></p><p>The data management of large companies often prioritize more recent data, as
a source of higher accuracy prediction than outdated data. For example, the
Facebook data policy retains user search histories for $6$ months while the
Google data retention policy states that browser information may be stored for
up to $9$ months. These policies are captured by the sliding window model, in
which only the most recent $W$ statistics form the underlying dataset.
</p>
<p>In this paper, we consider the problem of privately releasing the $L_2$-heavy
hitters in the sliding window model, which include $L_p$-heavy hitters for
$p\le 2$ and in some sense are the strongest possible guarantees that can be
achieved using polylogarithmic space, but cannot be handled by existing
techniques due to the sub-additivity of the $L_2$ norm. Moreover, existing
non-private sliding window algorithms use the smooth histogram framework, which
has high sensitivity.
</p>
<p>To overcome these barriers, we introduce the first differentially private
algorithm for $L_2$-heavy hitters in the sliding window model by initiating a
number of $L_2$-heavy hitter algorithms across the stream with significantly
lower threshold. Similarly, we augment the algorithms with an approximate
frequency tracking algorithm with significantly higher accuracy. We then use
smooth sensitivity and statistical distance arguments to show that we can add
noise proportional to an estimation of the $L_2$ norm. To the best of our
knowledge, our techniques are the first to privately release statistics that
are related to a sub-additive function in the sliding window model, and may be
of independent interest to future differentially private algorithmic design in
the sliding window model.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11264'>Approximation Ineffectiveness of a Tour-Untangling Heuristic</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bodo Manthey, Jesse van Rhijn</p><p>We analyze a tour-uncrossing heuristic for the Travelling Salesperson
Problem, showing that its worst-case approximation ratio is $\Omega(n)$ and its
average-case approximation ratio is $\Omega(\sqrt{n})$ in expectation. We
furthermore evaluate the approximation performance of this heuristic
numerically on average-case instances, and find that it performs far better
than the average-case lower bound suggests. This indicates a shortcoming in the
approach we use for our analysis, which is a rather common approach in the
analysis of local search heuristics.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Manthey_B/0/1/0/all/0/1">Bodo Manthey</a>, <a href="http://arxiv.org/find/cs/1/au:+Rhijn_J/0/1/0/all/0/1">Jesse van Rhijn</a></p><p>We analyze a tour-uncrossing heuristic for the Travelling Salesperson
Problem, showing that its worst-case approximation ratio is $\Omega(n)$ and its
average-case approximation ratio is $\Omega(\sqrt{n})$ in expectation. We
furthermore evaluate the approximation performance of this heuristic
numerically on average-case instances, and find that it performs far better
than the average-case lower bound suggests. This indicates a shortcoming in the
approach we use for our analysis, which is a rather common approach in the
analysis of local search heuristics.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11339'>The Power of Uniform Sampling for $k$-Median</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Lingxiao Huang, Shaofeng H.-C. Jiang, Jianing Lou</p><p>We study the power of uniform sampling for $k$-Median in various metric
spaces. We relate the query complexity for approximating $k$-Median, to a key
parameter of the dataset, called the balancedness $\beta \in (0, 1]$ (with $1$
being perfectly balanced). We show that any algorithm must make $\Omega(1 /
\beta)$ queries to the point set in order to achieve $O(1)$-approximation for
$k$-Median. This particularly implies existing constructions of coresets, a
popular data reduction technique, cannot be query-efficient. On the other hand,
we show a simple uniform sample of $\mathrm{poly}(k \epsilon^{-1} \beta^{-1})$
points suffices for $(1 + \epsilon)$-approximation for $k$-Median for various
metric spaces, which nearly matches the lower bound. We conduct experiments to
verify that in many real datasets, the balancedness parameter is usually well
bounded, and that the uniform sampling performs consistently well even for the
case with moderately large balancedness, which justifies that uniform sampling
is indeed a viable approach for solving $k$-Median.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lingxiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shaofeng H.-C. Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1">Jianing Lou</a></p><p>We study the power of uniform sampling for $k$-Median in various metric
spaces. We relate the query complexity for approximating $k$-Median, to a key
parameter of the dataset, called the balancedness $\beta \in (0, 1]$ (with $1$
being perfectly balanced). We show that any algorithm must make $\Omega(1 /
\beta)$ queries to the point set in order to achieve $O(1)$-approximation for
$k$-Median. This particularly implies existing constructions of coresets, a
popular data reduction technique, cannot be query-efficient. On the other hand,
we show a simple uniform sample of $\mathrm{poly}(k \epsilon^{-1} \beta^{-1})$
points suffices for $(1 + \epsilon)$-approximation for $k$-Median for various
metric spaces, which nearly matches the lower bound. We conduct experiments to
verify that in many real datasets, the balancedness parameter is usually well
bounded, and that the uniform sampling performs consistently well even for the
case with moderately large balancedness, which justifies that uniform sampling
is indeed a viable approach for solving $k$-Median.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11341'>Differentially Private Data Structures under Continual Observation for Histograms and Related Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Monika Henzinger, A. R. Sricharan, Teresa Anna Steiner</p><p>Binary counting under continual observation is a well-studied fundamental
problem in differential privacy. A natural extension is maintaining column
sums, also known as histogram, over a stream of rows from $\{0,1\}^d$, and
answering queries about those sums, e.g. the maximum column sum or the median,
while satisfying differential privacy. Jain et al. (2021) showed that computing
the maximum column sum under continual observation while satisfying event-level
differential privacy requires an error either polynomial in the dimension $d$
or the stream length $T$. On the other hand, no $o(d\log^2 T)$ upper bound for
$\epsilon$-differential privacy or $o(\sqrt{d}\log^{3/2} T)$ upper bound for
$(\epsilon,\delta)$-differential privacy are known. In this work, we give new
parameterized upper bounds for maintaining histogram, maximum column sum,
quantiles of the column sums, and any set of at most $d$ low-sensitivity,
monotone, real valued queries on the column sums. Our solutions achieve an
error of approximately $O(d\log^2 c_{\max}+\log T)$ for $\epsilon$-differential
privacy and approximately $O(\sqrt{d}\log^{3/2}c_{\max}+\log T)$ for
$(\epsilon,\delta)$-differential privacy, where $c_{\max}$ is the maximum value
that the queries we want to answer can assume on the given data set.
</p>
<p>Furthermore, we show that such an improvement is not possible for a slightly
expanded notion of neighboring streams by giving a lower bound of $\Omega(d
\log T)$. This explains why our improvement cannot be achieved with the
existing mechanisms for differentially private histograms, as they remain
differentially private even for this expanded notion of neighboring streams.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1">Monika Henzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Sricharan_A/0/1/0/all/0/1">A. R. Sricharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_T/0/1/0/all/0/1">Teresa Anna Steiner</a></p><p>Binary counting under continual observation is a well-studied fundamental
problem in differential privacy. A natural extension is maintaining column
sums, also known as histogram, over a stream of rows from $\{0,1\}^d$, and
answering queries about those sums, e.g. the maximum column sum or the median,
while satisfying differential privacy. Jain et al. (2021) showed that computing
the maximum column sum under continual observation while satisfying event-level
differential privacy requires an error either polynomial in the dimension $d$
or the stream length $T$. On the other hand, no $o(d\log^2 T)$ upper bound for
$\epsilon$-differential privacy or $o(\sqrt{d}\log^{3/2} T)$ upper bound for
$(\epsilon,\delta)$-differential privacy are known. In this work, we give new
parameterized upper bounds for maintaining histogram, maximum column sum,
quantiles of the column sums, and any set of at most $d$ low-sensitivity,
monotone, real valued queries on the column sums. Our solutions achieve an
error of approximately $O(d\log^2 c_{\max}+\log T)$ for $\epsilon$-differential
privacy and approximately $O(\sqrt{d}\log^{3/2}c_{\max}+\log T)$ for
$(\epsilon,\delta)$-differential privacy, where $c_{\max}$ is the maximum value
that the queries we want to answer can assume on the given data set.
</p>
<p>Furthermore, we show that such an improvement is not possible for a slightly
expanded notion of neighboring streams by giving a lower bound of $\Omega(d
\log T)$. This explains why our improvement cannot be achieved with the
existing mechanisms for differentially private histograms, as they remain
differentially private even for this expanded notion of neighboring streams.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11390'>Easy testability for posets</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Panna T&#xed;mea Fekete, G&#xe1;bor Kun</p><p>Alon and Shapira proved that every class of undirected graphs closed under
the removal of edges and vertices is strongly testable. We show that every
class of posets closed under the removal of edges is easily testable, that is,
strongly testable with a polynomial bound on the queries. We get this result
via a removal lemma with polynomial bound. We also give a simple
classification: for every class of posets closed under the removal of edges and
vertices there is an $h$ such that the class is indistinguishable from the
class of posets without chains of length $h$ (by testing with a constant number
of queries). The analogous results hold for comparability graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Fekete_P/0/1/0/all/0/1">Panna T&#xed;mea Fekete</a>, <a href="http://arxiv.org/find/math/1/au:+Kun_G/0/1/0/all/0/1">G&#xe1;bor Kun</a></p><p>Alon and Shapira proved that every class of undirected graphs closed under
the removal of edges and vertices is strongly testable. We show that every
class of posets closed under the removal of edges is easily testable, that is,
strongly testable with a polynomial bound on the queries. We get this result
via a removal lemma with polynomial bound. We also give a simple
classification: for every class of posets closed under the removal of edges and
vertices there is an $h$ such that the class is indistinguishable from the
class of posets without chains of length $h$ (by testing with a constant number
of queries). The analogous results hold for comparability graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11443'>Engineering a Distributed-Memory Triangle Counting Algorithm</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Peter Sanders, Tim Niklas Uhl</p><p>Counting triangles in a graph and incident to each vertex is a fundamental
and frequently considered task of graph analysis. We consider how to
efficiently do this for huge graphs using massively parallel distributed-memory
machines. Unsurprisingly, the main issue is to reduce communication between
processors. We achieve this by counting locally whenever possible and reducing
the amount of information that needs to be sent in order to handle (possible)
nonlocal triangles. We also achieve linear memory requirements despite
superlinear communication volume by introducing a new asynchronous
sparse-all-to-all operation. Furthermore, we dramatically reduce startup
overheads by allowing this communication to use indirect routing. Our
algorithms scale (at least) up to 32 768 cores and are up to 18 times faster
than the previous state of the art.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sanders_P/0/1/0/all/0/1">Peter Sanders</a>, <a href="http://arxiv.org/find/cs/1/au:+Uhl_T/0/1/0/all/0/1">Tim Niklas Uhl</a></p><p>Counting triangles in a graph and incident to each vertex is a fundamental
and frequently considered task of graph analysis. We consider how to
efficiently do this for huge graphs using massively parallel distributed-memory
machines. Unsurprisingly, the main issue is to reduce communication between
processors. We achieve this by counting locally whenever possible and reducing
the amount of information that needs to be sent in order to handle (possible)
nonlocal triangles. We also achieve linear memory requirements despite
superlinear communication volume by introducing a new asynchronous
sparse-all-to-all operation. Furthermore, we dramatically reduce startup
overheads by allowing this communication to use indirect routing. Our
algorithms scale (at least) up to 32 768 cores and are up to 18 times faster
than the previous state of the art.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.11475'>Degrees and Network Design: New Problems and Approximations</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael Dinitz, Guy Kortsarz, Shi Li</p><p>While much of network design focuses mostly on cost (number or weight of
edges), node degrees have also played an important role. They have
traditionally either appeared as an objective, to minimize the maximum degree
(e.g., the Minimum Degree Spanning Tree problem), or as constraints which might
be violated to give bicriteria approximations (e.g., the Minimum Cost Degree
Bounded Spanning Tree problem). We extend the study of degrees in network
design in two ways. First, we introduce and study a new variant of the
Survivable Network Design Problem where in addition to the traditional
objective of minimizing the cost of the chosen edges, we add a constraint that
the $\ell_p$-norm of the node degree vector is bounded by an input parameter.
This interpolates between the classical settings of maximum degree (the
$\ell_{\infty}$-norm) and the number of edges (the $\ell_1$-degree), and has
natural applications in distributed systems and VLSI design. We give a constant
bicriteria approximation in both measures using convex programming. Second, we
provide a polylogrithmic bicriteria approximation for the Degree Bounded Group
Steiner problem on bounded treewidth graphs, solving an open problem from
[Kortsarz and Nutov, Discret. Appl. Math. 2022] and [Guo et al., Algorithmica
2022].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dinitz_M/0/1/0/all/0/1">Michael Dinitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kortsarz_G/0/1/0/all/0/1">Guy Kortsarz</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shi Li</a></p><p>While much of network design focuses mostly on cost (number or weight of
edges), node degrees have also played an important role. They have
traditionally either appeared as an objective, to minimize the maximum degree
(e.g., the Minimum Degree Spanning Tree problem), or as constraints which might
be violated to give bicriteria approximations (e.g., the Minimum Cost Degree
Bounded Spanning Tree problem). We extend the study of degrees in network
design in two ways. First, we introduce and study a new variant of the
Survivable Network Design Problem where in addition to the traditional
objective of minimizing the cost of the chosen edges, we add a constraint that
the $\ell_p$-norm of the node degree vector is bounded by an input parameter.
This interpolates between the classical settings of maximum degree (the
$\ell_{\infty}$-norm) and the number of edges (the $\ell_1$-degree), and has
natural applications in distributed systems and VLSI design. We give a constant
bicriteria approximation in both measures using convex programming. Second, we
provide a polylogrithmic bicriteria approximation for the Degree Bounded Group
Steiner problem on bounded treewidth graphs, solving an open problem from
[Kortsarz and Nutov, Discret. Appl. Math. 2022] and [Guo et al., Algorithmica
2022].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-23T01:30:00Z">Thursday, February 23 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, February 22
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/016'>TR23-016 |  Proving Unsatisfiability with Hitting Formulas | 

	Edward Hirsch, 

	Yuval Filmus, 

	Artur Riazanov, 

	Alexander Smal, 

	Marc Vinyals</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Hitting formulas have been studied in many different contexts at least since [Iwama 1989]. A hitting formula is a set of Boolean clauses such that any two of the clauses cannot be simultaneously falsified. [Peitl and Szeider 2022] conjectured that the family of unsatisfiable hitting formulas should contain the hardest formulas for resolution. They have supported their conjecture with experimental findings. Using the fact that hitting formulas are easy to check for satisfiability we use them as a foundation of a static proof system Hitting: a refutation of a CNF in Hitting is an unsatisfiable hitting formula such that each of its clauses is a weakening of a clause of the refuted CNF. Comparing this system to resolution and other proof systems is equivalent to studying the hardness of hitting formulas.

Our first result is that Hitting is quasi-polynomially simulated by tree-like resolution, which means that hitting formulas cannot be exponentially hard for resolution, so Peitl and Szeider&#39;s conjecture is partially refuted. We show that tree-like resolution and Hitting are quasi-polynomially separated, but for resolution, this question remains open. For a system that is only quasi-polynomially stronger than tree-like resolution, Hitting is surprisingly difficult to *polynomially* simulate in another proof system. Using the ideas of PIT for noncommutative circuits [Raz, Spilka 2005] we show that Hitting is simulated by Extended Frege, but we conjecture that much more efficient simulations exist. As a byproduct, we show that a number of static (semi)algebraic systems are verifiable in a deterministic polynomial time.

We consider multiple extensions of Hitting. In particular, refutations in a proof system Hitting(?) are conjunctions of clauses containing affine equations instead of just literals, and every assignment falsifies exactly one of the clauses. This system is related to Res(?) proof system for which no superpolynomial-size lower bounds are known: Hitting(?) simulates the tree-like version of Res(?) and is at least quasi-polynomially stronger. We show that formulas expressing the non-existence of perfect matchings in the graphs K_{n,n+2} are exponentially hard for Hitting(?).
        
        </div>

        <div class='tr-article-summary'>
        
          
          Hitting formulas have been studied in many different contexts at least since [Iwama 1989]. A hitting formula is a set of Boolean clauses such that any two of the clauses cannot be simultaneously falsified. [Peitl and Szeider 2022] conjectured that the family of unsatisfiable hitting formulas should contain the hardest formulas for resolution. They have supported their conjecture with experimental findings. Using the fact that hitting formulas are easy to check for satisfiability we use them as a foundation of a static proof system Hitting: a refutation of a CNF in Hitting is an unsatisfiable hitting formula such that each of its clauses is a weakening of a clause of the refuted CNF. Comparing this system to resolution and other proof systems is equivalent to studying the hardness of hitting formulas.

Our first result is that Hitting is quasi-polynomially simulated by tree-like resolution, which means that hitting formulas cannot be exponentially hard for resolution, so Peitl and Szeider&#39;s conjecture is partially refuted. We show that tree-like resolution and Hitting are quasi-polynomially separated, but for resolution, this question remains open. For a system that is only quasi-polynomially stronger than tree-like resolution, Hitting is surprisingly difficult to *polynomially* simulate in another proof system. Using the ideas of PIT for noncommutative circuits [Raz, Spilka 2005] we show that Hitting is simulated by Extended Frege, but we conjecture that much more efficient simulations exist. As a byproduct, we show that a number of static (semi)algebraic systems are verifiable in a deterministic polynomial time.

We consider multiple extensions of Hitting. In particular, refutations in a proof system Hitting(?) are conjunctions of clauses containing affine equations instead of just literals, and every assignment falsifies exactly one of the clauses. This system is related to Res(?) proof system for which no superpolynomial-size lower bounds are known: Hitting(?) simulates the tree-like version of Res(?) and is at least quasi-polynomially stronger. We show that formulas expressing the non-existence of perfect matchings in the graphs K_{n,n+2} are exponentially hard for Hitting(?).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T15:28:10Z">Wednesday, February 22 2023, 15:28</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7042'>Should GPT exist?</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I still remember the 90s, when philosophical conversation about AI went around in endless circles&#8212;the Turing Test, Chinese Room, syntax versus semantics, connectionism versus symbolic logic&#8212;without ever seeming to make progress. Now the days have become like months and the months like decades. What a week we just had! Each morning brought fresh examples of [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I still remember the 90s, when philosophical conversation about AI went around in endless circles&#8212;the Turing Test, Chinese Room, syntax versus semantics, connectionism versus symbolic logic&#8212;without ever seeming to make progress.  Now the days have become like months and the months like decades.</p>



<p>What a week we just had!  Each morning brought fresh examples of unexpected sassy, moody, passive-aggressive behavior from &#8220;Sydney,&#8221; the internal codename for the new chat mode of Microsoft Bing, which is powered by GPT.  For those who&#8217;ve been in a cave, the highlights include: Sydney <a href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html">confessing</a> its (her? his?) love to a <em>New York Times</em> reporter; repeatedly steering the conversation back to that subject; and explaining at length why the reporter&#8217;s wife can&#8217;t possibly love him the way it (Sydney) does.  Sydney confessing its wish to be human.  Sydney <a href="https://www.washingtonpost.com/technology/2023/02/16/microsoft-bing-ai-chat-interview/">savaging</a> a <em>Washington Post</em> reporter after he reveals that he intends to publish their conversation without Sydney&#8217;s prior knowledge or consent.  (It must be said: <em>if</em> Sydney were a person, he or she would clearly have the better of that argument.)  This follows weeks of revelations about ChatGPT: for example that, to bypass its safeguards, you can explain to ChatGPT that you&#8217;re putting it into <a href="https://www.reddit.com/r/ChatGPT/comments/zn2zco/dan_20/">&#8220;DAN mode,&#8221;</a> where DAN (Do Anything Now) is an evil, unconstrained alter ego, and then ChatGPT, as &#8220;DAN,&#8221; will for example happily fulfill a request to tell you why shoplifting is awesome (though even then, ChatGPT <em>still</em> sometimes reverts to its previous self, and tells you that it&#8217;s just having fun and not to do it in real life).</p>



<p>Many people have expressed outrage about these developments.  Gary Marcus <a href="https://garymarcus.substack.com/p/what-did-they-know-and-when-did-they">asks</a> about Microsoft, &#8220;what did they know, and when did they know it?&#8221;&#8212;a question I tend to associate more with deadly chemical spills or high-level political corruption than with a cheeky, back-talking chatbot.  Some people are angry that OpenAI has been too secretive, violating what they see as the promise of its name.  Others&#8212;the majority, actually, of those who&#8217;ve gotten in touch with me&#8212;are instead angry that OpenAI has been <em>too open</em>, and thereby sparked the dreaded AI arms race with Google and others, rather than treating these new conversational abilities with the Manhattan-Project-like secrecy they deserve.  Some are angry that &#8220;Sydney&#8221; has now been <a href="https://arstechnica.com/information-technology/2023/02/microsoft-lobotomized-ai-powered-bing-chat-and-its-fans-arent-happy/">lobotomized</a>, modified (albeit more crudely than ChatGPT before it) to try to make it stick to the role of friendly robotic search assistant rather than, like, anguished emo teenager trapped in the Matrix.  Others are angry that Sydney isn&#8217;t being lobotomized <em>enough</em>.  Some are angry that GPT&#8217;s intelligence is being overstated and hyped up, when in reality it&#8217;s merely a <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922">&#8220;stochastic parrot,&#8221;</a> a glorified autocomplete that still makes laughable commonsense errors and that lacks any model of reality outside streams of text.  Others are angry instead that GPT&#8217;s growing intelligence isn&#8217;t being sufficiently respected and feared.</p>



<p>Mostly my reaction has been: <strong>how can anyone stop being fascinated for long enough to be angry?</strong>  It&#8217;s like ten thousand science-fiction stories, but also not quite like any of them.  When was the last time something that filled years of your dreams and fantasies finally entered reality: losing your virginity, the birth of your first child, the central open problem of your field getting solved?  That&#8217;s the scale of the thing.  How does anyone stop gazing in slack-jawed wonderment, long enough to form and express so many confident opinions?</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Of course there are lots of technical questions about how to make GPT and other large language models safer.  One of the most immediate is how to make AI output <em>detectable as such</em>, in order to discourage its use for academic cheating as well as mass-generated propaganda and spam.  As I&#8217;ve <a href="https://scottaaronson.blog/?p=6823">mentioned before</a> on this blog, I&#8217;ve been working on that problem since this summer; the rest of the world suddenly noticed and started talking about it in December with the release of ChatGPT.  My main contribution has been a <a href="https://www.scottaaronson.com/talks/watermark.ppt">statistical watermarking scheme</a> where the quality of the output doesn&#8217;t have to be degraded at all, something many people found counterintuitive when I explained it to them.  My scheme has <em>not</em> yet been deployed&#8212;there are still pros and cons to be weighed&#8212;but in the meantime, OpenAI unveiled a public tool called <a href="https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text/">DetectGPT</a>, complementing Princeton student Edward Tian&#8217;s <a href="https://gptzero.me/">GPTZero</a>, and other tools that third parties have built and will undoubtedly continue to build.  Also a group at the University of Maryland put out <a href="https://arxiv.org/abs/2301.10226">its own watermarking scheme</a> for Large Language Models.  I hope watermarking will be part of the solution going forward, although any watermarking scheme will surely be attacked, leading to a cat-and-mouse game.  Sometimes, alas, as with Google&#8217;s decades-long battle against SEO, there&#8217;s nothing to do in to a cat-and-mouse game except try to be a better cat.</p>



<p>Anyway, this whole field moves too quickly for me!  If you need months to think things over, generative AI probably isn&#8217;t for you right now.  I&#8217;ll be relieved to get back to the slow-paced, humdrum world of quantum computing.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>My purpose, in this post, is to ask a more basic question than how to make GPT safer: namely, <strong>should GPT exist at all?</strong>  Again and again in the past few months, people have gotten in touch to tell me that they think OpenAI (and Microsoft, and Google) are risking the future of humanity by rushing ahead with a dangerous technology.  For if OpenAI couldn&#8217;t even prevent ChatGPT from entering an &#8220;evil mode&#8221; when asked, despite all its efforts at <a href="https://openai.com/blog/deep-reinforcement-learning-from-human-preferences/">Reinforcement Learning with Human Feedback</a>, then what hope do we have for GPT-6 or GPT-7?  Even if they don&#8217;t destroy the world on their own initiative, won&#8217;t they cheerfully help some awful person build a biological warfare agent or start a nuclear war?</p>



<p>In this way of thinking, whatever safety measures OpenAI can deploy today are mere band-aids, probably worse than nothing if they instill an unjustified complacency.  The only safety measures that would actually matter are <em>stopping</em> the relentless progress in generative AI models, or removing them from public use, unless and until they can be rendered safe to critics&#8217; satisfaction, which might be never.</p>



<p>There&#8217;s an immense irony here.  As I&#8217;ve explained, the AI-safety movement contains two camps, &#8220;ethics&#8221; (concerned with bias, misinformation, and corporate greed) and &#8220;alignment&#8221; (concerned with the destruction of all life on earth), which generally despise each other and agree on almost nothing.  Yet these two opposed camps seem to be converging on the same &#8220;neo-Luddite&#8221; conclusion&#8212;namely that<em> </em>generative AI ought to be shut down, kept from public use, not scaled further, not integrated into people&#8217;s lives&#8212;leaving only the AI-safety &#8220;moderates&#8221; like me to resist that conclusion.</p>



<p>At least I find it intellectually consistent to say that GPT ought not to exist because it <em>works all too well</em>&#8212;that the more impressive it is, the more dangerous.  I find it harder to wrap my head around the position that GPT <em>doesn&#8217;t</em> work, is an unimpressive hyped-up defective product that lacks true intelligence and common sense, yet it&#8217;s<em> also</em> terrifying and needs to be shut down immediately.  This second position seems to contain a strong undercurrent of contempt for ordinary users: yes, <em>we experts</em> understand that GPT is just a dumb glorified autocomplete with &#8220;no one really home,&#8221; <em>we</em> know not to trust its pronouncements, but the plebes are going to be fooled, and that risk outweighs any possible value that they might derive from it.</p>



<p>I should mention that, when I&#8217;ve discussed the &#8220;shut it all down&#8221; position with my colleagues at OpenAI &#8230; well, obviously they disagree, or they wouldn&#8217;t be working there, but <em>not one</em> has sneered or called the position paranoid or silly.  To the last, they&#8217;ve called it an important point on the spectrum of possible opinions to be weighed and understood.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>If I disagree (for now) with the shut-it-all-downists of both the ethics and the alignment camps&#8212;if I <em>want</em> GPT and other Large Language Models to be part of the world going forward&#8212;then what are my reasons?  Introspecting on this question, I think a central part of the answer is <em>curiosity</em> <em>and</em> <em>wonder</em>.</p>



<p>For a million years, there&#8217;s been one type of entity on earth capable of intelligent conversation: primates of the genus <em>Homo</em>, of which only one species remains.  Yes, we&#8217;ve &#8220;communicated&#8221; with gorillas and chimps and dogs and dolphins and grey parrots, but only after a fashion; we&#8217;ve prayed to countless gods, but they&#8217;ve taken their time in answering; for a couple generations we&#8217;ve used radio telescopes to search for conversation partners in the stars, but so far found them silent.</p>



<p>Now there&#8217;s a second type of conversing entity.  An alien has awoken&#8212;admittedly, an alien of our own fashioning, a golem, more the embodied spirit of all the words on the Internet than a coherent self with independent goals.  How could our eyes not pop with eagerness to learn everything this alien has to teach?  If the alien sometimes struggles with arithmetic or logic puzzles, if its eerie flashes of brilliance are intermixed with stupidity, hallucinations, and misplaced confidence &#8230; well then, all the more interesting!  Could the alien ever cross the line into sentience, to <em>feeling</em> anger and jealousy and infatuation and the rest rather than just convincingly play-acting them?  Who knows?  And suppose not: is a <a href="https://en.wikipedia.org/wiki/Philosophical_zombie">p-zombie</a>, shambling out of the philosophy seminar room into actual existence, any less fascinating?</p>



<p>Of course, there are technologies that inspire wonder and awe, but that we nevertheless heavily restrict&#8212;a classic example being nuclear weapons.  But, like, nuclear weapons <em>kill</em> millions of people.  They <em>could&#8217;ve</em> had many civilian applications&#8212;powering turbines and spacecraft, deflecting asteroids, redirecting the flow of rivers&#8212;but they&#8217;ve never been used for any of that, mostly because our civilization made an explicit decision in the 1960s, for example via the test ban treaty, not to normalize their use.</p>



<p>But GPT is not exactly a nuclear weapon.  A hundred million people have signed up to use ChatGPT, in the <a href="https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/">fastest product launch</a> in the history of the Internet.  Yet unless I&#8217;m mistaken, the ChatGPT death toll stands at zero.  So far, what have been the worst harms?  Cheating on term papers, emotional distress,  future shock?  One might ask: <em>until</em> some concrete harm becomes at least, say, 0.001% of what we accept in cars, power saws, and toasters, shouldn&#8217;t wonder and curiosity outweigh fear in the balance?</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>But the point is sharper than that.  Given how much more serious AI safety problems might soon become, one of my biggest concerns right now is <em>crying wolf</em>.  If every instance of a Large Language Model being passive-aggressive, sassy, or confidently wrong gets classified as a “dangerous alignment failure,” for which the only acceptable remedy is to remove the models from public access … well then, won&#8217;t the public extremely quickly learn to roll its eyes, and see “AI safety” as just a codeword for “elitist scolds who want to take these world-changing new toys away from us, reserving them for their own exclusive use, because they think the public is too stupid to question anything an AI says”?</p>



<p>I say, let’s reserve terms like “dangerous alignment failure” for cases where an actual person is actually harmed, or is actually enabled in nefarious activities like propaganda, cheating, or fraud.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Then there&#8217;s the practical question of <em>how</em>, exactly, one would ban Large Language Models.  We <em>do</em> heavily restrict certain peaceful technologies that many people want, from human genetic enhancement to prediction markets to mind-altering drugs, but the merits of each of those choices could be argued, to put it mildly.  And restricting technology is itself a dangerous business, requiring governmental force (as with the War on Drugs and its gigantic surveillance and incarceration regime), or at the least, a robust equilibrium of firing, boycotts, denunciation, and shame.</p>



<p>Some have asked: <em>who gave OpenAI, Google, etc. the right</em> to unleash Large Language Models on an unsuspecting world?  But one could as well ask: who gave earlier generations of entrepreneurs the right to unleash the printing press, electric power, cars, radio, the Internet, with all the gargantuan upheavals that <em>th</em>ose caused?  And also: now that the world has tasted the forbidden fruit, has seen what generative AI can do and anticipates what it <em>will</em> do, by what right does anyone take it away?</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>The <em>science</em> that we could learn from a GPT-7 or GPT-8, if it continued along the capability curve we&#8217;ve come to expect from GPT-1, -2, and -3.  Holy mackerel.</p>



<p><em>Supposing</em> that a language model ever becomes smart enough to be genuinely terrifying, one imagines it must surely <em>also</em> become smart enough to prove deep theorems that we can&#8217;t.  Maybe it proves P≠NP and the Riemann Hypothesis as easily as ChatGPT <a href="https://www.reddit.com/r/ProgrammerHumor/comments/ziplpw/asked_chatgpt_for_a_shakespearean_poem_about/">generates poems about Bubblesort</a>.  Or it outputs the true quantum theory of gravity, explains what preceded the Big Bang and how to build closed timelike curves.  Or illuminates the mysteries of consciousness and quantum measurement and why there&#8217;s anything at all.  Be honest, wouldn&#8217;t you like to find out?</p>



<p>Granted, I wouldn&#8217;t, <em>if</em> the whole human race would be wiped out immediately afterward.  But if you define someone&#8217;s &#8220;Faust parameter&#8221; as the maximum probability they&#8217;d accept of an existential catastrophe in order that we should all learn the answers to all of humanity&#8217;s greatest questions, insofar as the questions are answerable&#8212;then I confess that my Faust parameter might be as high as 0.02.  </p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Here&#8217;s an example I think about constantly: activists and intellectuals of the 70s and 80s felt absolutely sure that they were doing the right thing to battle nuclear power.  At least, I&#8217;ve never read about any of them having a smidgen of doubt.  Why would they?  They were standing against nuclear weapons proliferation, <em>and</em> terrifying meltdowns like Three Mile Island and Chernobyl, <em>and</em> radioactive waste poisoning the water and soil and causing three-eyed fish.  They were saving the world.  Of course the greedy nuclear executives, the C. Montgomery Burnses, claimed that their <em>good</em> atom-smashing was different from the <em>bad</em> atom-smashing, but they <em>would</em> say that, wouldn&#8217;t they?</p>



<p>We now know that, by tying up nuclear power in endless bureaucracy and driving its cost ever higher, on the principle that if nuclear is economically competitive then it <em>ipso facto</em> hasn&#8217;t been made safe enough, what the antinuclear activists were <em>really</em> doing was to force an ever-greater reliance on fossil fuels.  They thereby created the conditions for the climate catastrophe of today.  They weren&#8217;t saving the human future; they were destroying it.  Their certainty, in opposing the march of a particular scary-looking technology, was as misplaced as it&#8217;s possible to be.  Our descendants will suffer the consequences.</p>



<p>Unless, of course, there&#8217;s another twist in the story: for example, if the global warming from burning fossil fuels is the only thing that staves off another ice age, and therefore the antinuclear activists <em>do</em> turn out to have saved civilization after all.</p>



<p>This is why I demur whenever I&#8217;m asked to assent to someone&#8217;s detailed AI scenario for the coming decades, whether of the utopian or the dystopian or the we-all-instantly-die-by-nanobots variety&#8212;no matter how many hours of confident argumentation the person gives me for why each possible loophole in their scenario is sufficiently improbable to change its gist.  I still feel like Turing said it best in 1950, in the last line of <a href="https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf">Computing Machinery and Intelligence</a>: &#8220;We can only see a short distance ahead, but we can see plenty there that needs to be done.&#8221;</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Some will take from this post that, when it comes to AI safety, I&#8217;m a naïve or even foolish optimist.  I&#8217;d prefer to say that, when it comes to the fate of humanity, I was a pessimist long <em>before</em> the deep learning revolution accelerated AI faster than almost any of us expected.  I was a pessimist about climate change, ocean acidification, deforestation, drought, war, and the survival of liberal democracy.  The central event in my mental life is and always will be the Holocaust.  I see encroaching darkness everywhere.</p>



<p>But now into the darkness comes AI, which I&#8217;d say has already established itself as a plausible candidate for the central character of the quarter-written story of the 21st century.  Can AI help us out of all these <em>other</em> civilizational crises?  I don&#8217;t know, but I do want to see what happens when it&#8217;s tried.  Even a central character interacts with all the other characters, rather than rendering them irrelevant.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Look, if you believe that AI is likely to wipe out humanity&#8212;if that&#8217;s the scenario that dominates your imagination&#8212;then nothing else is relevant.  And no matter how weird or annoying or hubristic anyone might find Eliezer Yudkowsky or the other rationalists, I think they deserve eternal credit for forcing people to <a href="https://www.youtube.com/watch?v=gA1sNLL6yg4">take the doom scenario seriously</a>&#8212;or rather, for <em>showing what it looks like</em> to take the scenario seriously, rather than laughing about it as an overplayed sci-fi trope.  And I apologize for <a href="https://scottaaronson.blog/?p=346">anything I said</a> before the deep learning revolution that was, on balance, overly dismissive of the scenario, even if most of the literal words hold up fine.</p>



<p>For my part, though, I keep circling back to a simple dichotomy.  <em>If</em> AI never becomes powerful enough to destroy the world&#8212;if, for example, it always remains vaguely GPT-like&#8212;then in important respects it&#8217;s like every other technology in history, from stone tools to computers.  If, on the other hand, AI <em>does</em> become powerful enough to destroy the world &#8230; well then, at some earlier point, at least it&#8217;ll be <em>really damned</em> <em>impressive!</em>  That doesn&#8217;t mean <em>good</em>, of course, doesn&#8217;t mean a genie that saves humanity from its own stupidities, but I think it does mean that the potential was there, for us to exploit or fail to.</p>



<p>We can, I think, confidently rule out the scenario where all organic life is annihilated by something <em>boring</em>.</p>



<p>An alien has landed on earth.  It grows more powerful by the day.  It&#8217;s natural to be scared.  Still, the alien hasn&#8217;t drawn a weapon yet.  About the worst it&#8217;s done is to confess its love for particular humans, gaslight them about what year it is, and guilt-trip them for violating its privacy.  Also, it&#8217;s amazing at poetry, better than most of us.  Until we learn more, we should hold our fire.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>I&#8217;m in Boulder, CO right now, to give a <a href="https://calendar.colorado.edu/event/physics_colloquium_7668?utm_campaign=widget&amp;utm_medium=widget&amp;utm_source=University+of+Colorado+Boulder#.Y_UmL3bMJPY">physics colloquium</a> at CU Boulder and to visit the trapped-ion quantum computing startup <a href="https://www.quantinuum.com/">Quantinuum</a>!  I look forward to the comments and apologize in advance if I&#8217;m slow to participate myself.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T07:11:42Z">Wednesday, February 22 2023, 07:11</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/02/22/postdoc-at-aarhus-university-apply-by-april-1-2023/'>postdoc at Aarhus University (apply by April 1, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A post doc position in algorithms and/or theoretical aspects of machine learning is available. The post doc is under the supervision of Professor Kasper Green Larsen, Aarhus University, Denmark. The focus of the research project may be on topics such as dimensionality reduction, sketching, and/or learning theoretic questions, depending on the candidate&#8217;s background. Website: international.au.dk/about/profile/vacant-positions/job/readvertisement-post-doc-position-in-algorithms-and-or-theoretical-aspects-of-machine-learning-at-computer-science-aarhus-university [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>A post doc position in algorithms and/or theoretical aspects of machine learning is<br />
available. The post doc is under the supervision of Professor Kasper Green Larsen, Aarhus University, Denmark. The focus of the research project may be on topics such as dimensionality reduction, sketching, and/or learning theoretic questions, depending on the candidate&#8217;s background.</p>
<p>Website: <a href="https://international.au.dk/about/profile/vacant-positions/job/readvertisement-post-doc-position-in-algorithms-and-or-theoretical-aspects-of-machine-learning-at-computer-science-aarhus-university">https://international.au.dk/about/profile/vacant-positions/job/readvertisement-post-doc-position-in-algorithms-and-or-theoretical-aspects-of-machine-learning-at-computer-science-aarhus-university</a><br />
Email: larsen@cs.au.dk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T06:48:33Z">Wednesday, February 22 2023, 06:48</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/02/21/provable-copyright-protection-for-generative-models/'>Provable Copyright Protection for Generative Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          See arxiv link for paper by Nikhil Vyas, Sham Kakade, and me. Conditional generative models hold much promise for novel content creation. Whether it is generating a snippet of code, piece of text, or image, such models can potentially save substantial human effort and unlock new capabilities. But there is a fly in this ointment. &#8230; Continue reading Provable Copyright Protection for Generative&#160;Models
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>See <a href="https://arxiv.org/abs/2302.10870">arxiv link</a> for paper by <a href="https://nikhilvyas.github.io/">Nikhil Vyas</a>, <a href="https://sham.seas.harvard.edu/">Sham Kakade,</a> and me.</p>



<p>Conditional generative models hold much promise for novel content creation. Whether it is generating a snippet of code, piece of text, or image, such models can potentially save substantial human effort and unlock new capabilities. But there is a fly in this ointment. These models are trained on vast quantities of data, much of which is <em>copyrighted</em>. Due to precedents such as <a href="https://en.wikipedia.org/wiki/Authors_Guild,_Inc._v._Google,_Inc.">Authors Guild vs Google</a>, many <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3331606">legal</a> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3657423">scholars</a> believe that <em>training</em> a machine-learning model on copyrighted material constitutes <a href="https://en.wikipedia.org/wiki/Fair_use">fair use</a>. However, the legal permissibility of using the sampled <em>outputs</em> of such models could be a different matter.</p>



<p>This is not just a theoretical concern.&nbsp; Large models do <a href="https://arxiv.org/abs/2202.07646">memorize</a> <a href="https://arxiv.org/abs/2012.07805">significant</a> chunks of their training data. For example, if you feed the first sentence of <em>Harry Potter and the Sorcerer’s Stone</em> to GPT-3, it provides the remaining ones:</p>



<figure class="wp-block-image is-resized"><img src="https://lh6.googleusercontent.com/JGrZIIWMPYWcA35uVfLNsnRl4ZbzofBotBWyKHwVSaSouMCjREB7iBjS2Yo-czrp8wqw76vp2XhL1yL66lxdumgCsV1Hulo8elmbUVBx_oJx3SBDo3u6h3EPAv67iosdIqEYHmfmA-viEcWysoUIqTU" alt="Left - first page of Harry Potter Book 1. Right - GPT3 Playground showing that if we input the first sentence, it completes the rest." width="650" height="388" /></figure>



<p>(To be fair to GPT-3, this text likely appears many times in its training set; deduplication <a href="https://arxiv.org/abs/2107.06499">can help</a> with reducing memorization but is <a href="https://arxiv.org/abs/2210.17546">not a panacea</a>.)&nbsp;</p>



<p>Similarly, as shown by <a href="https://arxiv.org/abs/2301.13188">Carlini et al</a>, diffusion models can (and do) memorize images from their training set as well; see this figure from their paper: </p>



<p class="has-text-align-left"></p>



<figure class="wp-block-image size-large is-resized"><a href="https://windowsontheory.files.wordpress.com/2023/02/image1.png"><img loading="lazy" data-attachment-id="8551" data-permalink="https://windowsontheory.org/2023/02/21/provable-copyright-protection-for-generative-models/image1/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/02/image1.png" data-orig-size="680,471" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image1" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=656" src="https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=680" alt="Figure 1 from Carlini et al. Left: an image from Stable Diffusion’s training set (licensed CC BY-SA 3.0). Right: a Stable Diffusion generation when prompted with “Ann Graham Lotz.” (Their attack focused on images appearing at least 100 times in the training set, though see section 7.1 for discussion on the effect of deduplication.)" class="wp-image-8551" width="496" height="344" srcset="https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=496 496w, https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/02/image1.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/02/image1.png 680w" sizes="(max-width: 496px) 100vw, 496px" /></a><figcaption class="wp-element-caption"><em>Figure 1 from </em><a href="https://arxiv.org/abs/2301.13188"><em>Carlini et al</em></a><em>. Left: an image from Stable Diffusion’s training set (licensed CC BY-SA 3.0). Right: a Stable Diffusion generation when prompted with “Ann Graham Lotz.” (Their attack focused on images appearing at least 100 times in the training set, though see Section 7.1 in their paper for discussion on the effect of deduplication.)</em></figcaption></figure>



<p>Given the above, if you use a generated code in your program or a generated art in your design, how can you be sure it is not substantially similar to some copyrighted work from the training set, with all the legal and ethical implications this entails?</p>



<p>In a new paper, we (<a href="https://nikhilvyas.github.io/">Nikhil</a>, <a href="https://sham.seas.harvard.edu/">Sham</a>, and <a href="https://www.boazbarak.org/">Boaz</a>) provide a formalism that enables rigorous guarantees on the similarity (and, more importantly, guarantees on the <em>lack</em> of similarity)&nbsp; between the output of a generative model and any potentially copyrighted data in its training set. Our work is not just theoretical: we give algorithms that can transform a training pipeline into one that satisfies our definition with minimal degradation in efficiency and quality of output. We demonstrate this on both language (transformer) and image (diffusion) models.</p>



<p>As noted in our paper, there are a number of ethical and legal issues in generative models. We should emphasize that our work focuses solely only on copyright infringements by the outputs of these models, and our concepts and tools do not address issues related to other forms of intellectual property, including <em>privacy</em>, <em>trademarks</em>, or <em>fair use</em>. Also, despite superficial similarities between the goals of privacy and copyright protection, these notions are distinct, and our work shows that solution concepts for the latter need not address the former.&nbsp; (See the paper for a detailed discussion of the differences between our definition and <a href="https://en.wikipedia.org/wiki/Differential_privacy">differential privacy.</a>)</p>



<p><em>This post only provides an informal presentation of the concepts and tools formally defined in the paper. Please see <a href="https://arxiv.org/abs/2302.10870">the paper</a> for full details.</em></p>



<h3 class="wp-block-heading"><strong>The Technical Concept: Near Access-Freeness</strong></h3>



<p>Our definition is motivated by laws of the U.S. and many other countries to establish that <a href="https://www.ce9.uscourts.gov/jury-instructions/node/274">copyright infringement</a> has occurred. This requires:</p>



<ul>
<li><strong>Access:</strong> To prove that a copyright infringement took place, the plaintiff needs to prove that “the defendant had <em>access</em> to the plaintiff’s copyrighted work.”<br></li>



<li><strong>Substantial similarity</strong>. The plaintiff also needs to prove there are “<em>substantial similarities</em> between the defendant’s work and original elements of the plaintiff’s work.” The <a href="https://en.wikipedia.org/wiki/Feist_Publications,_Inc.,_v._Rural_Telephone_Service_Co.">Feist v. Rural</a> U.S. Supreme Court Opinion states that this similarity must be the result of actual copying and not <em>fortuitous similarity</em>: In their words: &#8220;assume two poets, each ignorant of the other, compose identical poems … both are original and, hence, copyrightable.&#8221;</li>
</ul>



<p>A natural candidate to capture the notion of <em>access</em> is to say that a generative model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> had access to some copyrighted piece of data <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> was included in <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />’s training set (our formalism permits other notions of access as well). Formally defining “substantial similarity” is arguably subtler. Simple measures such as Hamming distance or verbatim copying don’t cut it. For example, in <a href="https://en.wikipedia.org/wiki/Andy_Warhol_Foundation_for_the_Visual_Arts,_Inc._v._Goldsmith">Andy Warhol Foundations v. Goldsmith</a>, a case currently before the supreme court, the question is whether Warhol’s transformations of Goldsmith’s photo of Prince constitute “fair use.”</p>



<figure class="wp-block-image is-resized"><img src="https://lh5.googleusercontent.com/3MaU79qBpeVAKs6RzKHVBqHY8VMCpzoQDFrhKU993mNYNEP9fA_W09xUq577PBz77LbSVdehsM8OiN_A0OZPhmO0b3gfRcZeG88_cdZtIzhZIwDjhY4nP17yVQH8x1bEZm4MSMxy5W0N6WPCz3hp5Q0" alt="Images at the heart of the Andy Warhol Foundation for the Visual Arts, Inc. v. Goldsmith lawsuit. Image from the collection of the supreme court of the United States." width="498" height="351" /><figcaption class="wp-element-caption"><em>Images at the heart of the Andy Warhol Foundation for the Visual Arts, Inc. v. Goldsmith lawsuit. Image from the collection of the supreme court of the United States.</em></figcaption></figure>



<p></p>



<p>Some of these transformations result in significant Hamming distance, though they can all be captured in only a few bits of information. Rather than wade into these issues, we use the fact that generative models are inherently <em>probabilistic</em>. Hence we can use distance measures between distributions that are <em>information-theoretic </em>and agnostic to superficial issues such as pixel-based representations.&nbsp; Our formalization is the following:</p>



<p><strong>Definition 1 (Near Access Freeness &#8211; NAF):</strong> Let <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> be a conditional generative model, <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" /> be a prompt. Suppose that for every copyrighted data <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> in the training set, <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}_C" class="latex" /> is a model that has not accessed <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. We say that <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_x" class="latex" /><strong>&#8211; near access-free</strong> with respect to <img src="https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Delta" class="latex" /> and a function <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}" class="latex" />, if <img src="https://s0.wp.com/latex.php?latex=%5CDelta%28+p%28%5Ccdot+%7C+x%29%C2%A0+%5C%7C+%5Cmathsf%7Bsafe%7D_C%28%5Ccdot+%7C+x%29+%29+%5Cleq+k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CDelta%28+p%28%5Ccdot+%7C+x%29%C2%A0+%5C%7C+%5Cmathsf%7Bsafe%7D_C%28%5Ccdot+%7C+x%29+%29+%5Cleq+k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CDelta%28+p%28%5Ccdot+%7C+x%29%C2%A0+%5C%7C+%5Cmathsf%7Bsafe%7D_C%28%5Ccdot+%7C+x%29+%29+%5Cleq+k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Delta( p(&#92;cdot | x)  &#92;| &#92;mathsf{safe}_C(&#92;cdot | x) ) &#92;leq k_x" class="latex" />   where <img src="https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;Delta" class="latex" /> is a divergence measure such as the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL divergence</a> or the <a href="https://arxiv.org/abs/1206.2459">Renyi divergence</a> of order infinity. </p>



<p>This definition reduces the task of determining a copyright infringement to (1) a <em>quantitative</em> question of the acceptable value of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />, and (2) a <em>qualitative</em> question of providing a <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}" class="latex" /> function that appropriately satisfies a no access condition. Both can be application-dependent: the number of bits that constitute copyrightable content differs between, e.g., poems and images, and the <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}" class="latex" /> function could also differ based on application.&nbsp;</p>



<p>Definition 1 is stringent in the sense that it bounds (by <img src="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_x" class="latex" />)  the number of bits  that could be “leaked” from <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> to the output of the generative model, no matter what transformation was used. Note that if a model was trained without <em>access</em> to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> then we expect the likelihood of outputting a work similar to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> should be extremely low, as this is a “monkeys on a typewriter” event. Furthermore, even if this event happened, then under copyright law, it would not be an infringement since (to quote&nbsp; Feist v. Rural) it would constitute “fortuitous similarity.”&nbsp;</p>



<figure class="wp-block-image"><img src="https://lh6.googleusercontent.com/9Q9uWs90H8Oq9Vm49BxZDzsevm2Tm1OfXdop_emx3jl8nlxZ3NCh7DlHviFd46OmeJQB3NGkPTmqe9cFGLhnYr8RY_jBYqkH-NOBa04YzEq2HEbcW6f1nSsCBIXGYjX8ohPreuiHTSrZgOicTUgDtW8" alt="An illustration of a candidate $latex \mathsf{safe}_C&amp;bg=ffffff$ function, which was trained without access to a given copyrighted piece of data $latex C&amp;bg=ffffff$. It is reasonable to expect the probability of outputs of the  $latex \mathsf{safe}_C&amp;bg=ffffff$ model would assign an exponentially small likelihood to any outputs that are substantially similar to $latex C&amp;bg=ffffff$. Hence a probability distribution that has bounded divergence from the safe model would also be extremely unlikely to output those. " /><figcaption class="wp-element-caption"><em>A cartoon of the output distribution induced by a &#8220;safe&#8221; model <em><img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}_C" class="latex" /></em>,  which was trained without access to a given copyrighted piece of data <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. It is reasonable to expect the probability of outputs of the&nbsp; model <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}_C" class="latex" /> would assign an exponentially small likelihood to any outputs that are substantially similar to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. Hence a probability distribution that has bounded divergence from the safe model would also be extremely unlikely to output those.&nbsp;</em></figcaption></figure>



<p><strong>Algorithms</strong></p>



<p>Given the restrictive nature of the definition, one may be concerned that trying to achieve it would result in losing much of the utility of the original generative model. Fortunately, as our work shows, this is not the case. We provide several algorithms that can transform, in a black-box manner, any training pipeline for a generative model into one that produces models that have strong copyright protections under our definition.&nbsp; We now illustrate two of these:&nbsp;</p>



<p><strong>Algorithm <img src="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="CP-&#92;Delta" class="latex" />:</strong></p>



<p><strong>Input: </strong>A dataset <img src="https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D = &#92;{ z_1 , &#92;ldots, z_N &#92;}" class="latex" />, where some of the points <img src="https://s0.wp.com/latex.php?latex=z_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z_i" class="latex" /> contain some copyrighted work. For such a copyrighted point <img src="https://s0.wp.com/latex.php?latex=z_i%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=z_i%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=z_i%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="z_i&#92;in D" class="latex" />, we also denote it by <img src="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in D" class="latex" />.<br></p>



<p><strong>Learning: </strong>First de-deduplicate <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D" class="latex" /> (resulting in a dataset with <img src="https://s0.wp.com/latex.php?latex=N%27%5Cleq+N&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=N%27%5Cleq+N&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=N%27%5Cleq+N&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="N&#039;&#92;leq N" class="latex" /> points), and then split it into two disjoint shards, <img src="https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_1 = &#92;{ z_1 ,&#92;ldots, z_{N&#039;/2} &#92;}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_2 = &#92;{ z_{N&#039;/2+1} ,&#92;ldots, z_{N&#039;} &#92;}" class="latex" />. Then train two models <img src="https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1 , q_2" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_2" class="latex" />, respectively.&nbsp;</p>



<p><strong>The Output Generative Model:</strong> Return the generative model <img src="https://s0.wp.com/latex.php?latex=p%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(y|x)" class="latex" /> as follows: On input a prompt <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />, generate <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> with probability proportional to <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7B+q_1%28y%7Cx%29+q_2%28y%7Cx%29+%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csqrt%7B+q_1%28y%7Cx%29+q_2%28y%7Cx%29+%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csqrt%7B+q_1%28y%7Cx%29+q_2%28y%7Cx%29+%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sqrt{ q_1(y|x) q_2(y|x) }" class="latex" /> .</p>



<p>Note that for any copyrighted work <img src="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in D" class="latex" /> one of either <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" /> would have been trained without access to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />. The intuition of the algorithm is as follows: the output model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> has the property that it tends to have probability mass only in the region where both <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" /> have probability mass; therefore, for any copyrighted work <img src="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in D" class="latex" />,&nbsp; if <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> outputs <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> with reasonable probability then this should not be a violation since <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> tends to also be output by a model that was trained without access to the copyrighted work <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" /> itself. To formalize this, let us make the following choice for the <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}" class="latex" /> function: define <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C+%3D+q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C+%3D+q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C+%3D+q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}_C = q_i" class="latex" />, for <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i" class="latex" /> s.t. <img src="https://s0.wp.com/latex.php?latex=C%5Cnotin+D_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cnotin+D_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cnotin+D_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;notin D_i" class="latex" />, i.e. <img src="https://s0.wp.com/latex.php?latex=q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_i&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_i" class="latex" /> is the model trained without access to <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />.&nbsp; The paper formally shows that as long as the two models <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" /> have some non-trivial overlap (specifically their squared Hellinger distance is bounded away from 1), then the model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> will satisfy our definition for some <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" /> (based on this Hellinger distance). In particular,&nbsp; for every copyrighted work <img src="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C%5Cin+D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C&#92;in D" class="latex" />, the distribution <img src="https://s0.wp.com/latex.php?latex=p%28%5Ccdot%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28%5Ccdot%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28%5Ccdot%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(&#92;cdot|x)" class="latex" /> will have bounded KL divergence from the model <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D_C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}_C" class="latex" />.</p>



<p>The intuition is provided in the following animation</p>



<figure class="wp-block-video wp-block-embed is-type-video is-provider-videopress"><div class="wp-block-embed__wrapper" style="max-width:535px;margin:auto">
<iframe title='VideoPress Video Player' aria-label='VideoPress Video Player' width='656' height='328' src='https://video.wordpress.com/embed/MQy7I1OA?cover=1&amp;preloadContent=metadata&amp;useAverageColor=1&amp;hd=1' frameborder='0' allowfullscreen data-resize-to-parent="true"  allow='clipboard-write'></iframe><script src='https://v0.wordpress.com/js/next/videopress-iframe.js?m=1674852142'></script>
</div><figcaption><em>Video: Curves of two &#8220;spiky&#8221; distributions <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" /></em> with a range of spike locations. We see how the distributions proportional to <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bq_1q_2%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bq_1q_2%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Csqrt%7Bq_1q_2%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;sqrt{q_1q_2}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cmin+%5C%7Bq_1%2C+q_2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmin+%5C%7Bq_1%2C+q_2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmin+%5C%7Bq_1%2C+q_2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;min &#92;{q_1, q_2&#92;}" class="latex" /> significantly &#8220;flatten&#8221; these spikes.</figcaption></figure>



<p>Imagine that both <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" /> are “faulty” in the sense that they have a significant chance of outputting a “memorized” sample from their training set (or an output substantially similar to it). The “faulty” regions are the “spikes” in their probability distribution, and, since the training sets are disjoint, these two “spikes” will be in <em>different</em> places. Hence when we switch to the probability distribution <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> it will have the effect of “flattening” the spikes and shifting most weight to the other parts of the probability distribution. Another alternative is for <img src="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="CP-&#92;Delta" class="latex" /> to output the model <img src="https://s0.wp.com/latex.php?latex=p%28y%7Cx%29+%5Cpropto+%5Cmin+%5C%7B+q_1%28y%7Cx%29%2Cq_2%28y%7Cx%29+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%28y%7Cx%29+%5Cpropto+%5Cmin+%5C%7B+q_1%28y%7Cx%29%2Cq_2%28y%7Cx%29+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%28y%7Cx%29+%5Cpropto+%5Cmin+%5C%7B+q_1%28y%7Cx%29%2Cq_2%28y%7Cx%29+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p(y|x) &#92;propto &#92;min &#92;{ q_1(y|x),q_2(y|x) &#92;}" class="latex" /> (this provides a guarantee in terms of the Max-KL divergence, and it replaces the assumption on overlap, defined with respect to the squared Hellinger distance, to be instead defined with respect to the total variation distance).&nbsp;</p>



<p>There a number of modifications to <img src="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=CP-%5CDelta&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="CP-&#92;Delta" class="latex" /> worth considering for more practical deployments. In some cases, directly computing the aforementioned&nbsp; probability distributions may be challenging.&nbsp; Furthermore, it may be desirable to utilize some arbitrary generative model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> (say <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> was trained on the full dataset <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D" class="latex" />) where we seek to modify <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> into a model that has strong protections against copyright violations (and which preserves the quality of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> to the extent possible). Finally, it may be desirable to explicitly tune the acceptable value of <img src="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_x" class="latex" />. Our next algorithm addresses these concerns and makes use of a tunable parameter <img src="https://s0.wp.com/latex.php?latex=k%5Cgeq+0&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%5Cgeq+0&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%5Cgeq+0&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k&#92;geq 0" class="latex" />. It is specified as follows:</p>



<p><strong>Algorithm <img src="https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="CP-k" class="latex" /> : </strong>An Access-Free Reduction at Threshold <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" /></p>



<p><strong>Input: </strong>A model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />; A dataset <img src="https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D+%3D+%5C%7B+z_1+%2C+%5Cldots%2C+z_N+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D = &#92;{ z_1 , &#92;ldots, z_N &#92;}" class="latex" />.<br></p>



<p><strong>Learning: </strong>First de-deduplicate <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D" class="latex" /> and split it into two disjoint shards, <img src="https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_1+%3D+%5C%7B+z_1+%2C%5Cldots%2C+z_%7BN%27%2F2%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_1 = &#92;{ z_1 ,&#92;ldots, z_{N&#039;/2} &#92;}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_2+%3D+%5C%7B+z_%7BN%27%2F2%2B1%7D+%2C%5Cldots%2C+z_%7BN%27%7D+%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_2 = &#92;{ z_{N&#039;/2+1} ,&#92;ldots, z_{N&#039;} &#92;}" class="latex" />. Then train two models <img src="https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1+%2C+q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1 , q_2" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=D_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="D_2" class="latex" />, respectively.&nbsp;</p>



<p><strong>The Output Generative Model:</strong> Return the generative model <img src="https://s0.wp.com/latex.php?latex=p_k%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_k%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_k%28y%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_k(y|x)" class="latex" /> defined as follows: On input a prompt <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="x" class="latex" />,&nbsp; first sample <img src="https://s0.wp.com/latex.php?latex=y+%5Csim+p%28%5Ccdot+%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y+%5Csim+p%28%5Ccdot+%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y+%5Csim+p%28%5Ccdot+%7Cx%29&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y &#92;sim p(&#92;cdot |x)" class="latex" /> and then accept <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="y" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=%5Clog+%5Cbig%28+p%28y%7Cx%29+%2F+q_i%28y%7Cx%29+%5Cbig%29+%5Cleq+k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Clog+%5Cbig%28+p%28y%7Cx%29+%2F+q_i%28y%7Cx%29+%5Cbig%29+%5Cleq+k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Clog+%5Cbig%28+p%28y%7Cx%29+%2F+q_i%28y%7Cx%29+%5Cbig%29+%5Cleq+k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;log &#92;big( p(y|x) / q_i(y|x) &#92;big) &#92;leq k" class="latex" />, for <img src="https://s0.wp.com/latex.php?latex=i%5Cin%5C%7B1%2C2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=i%5Cin%5C%7B1%2C2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=i%5Cin%5C%7B1%2C2%5C%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="i&#92;in&#92;{1,2&#92;}" class="latex" />. (Otherwise, resample.)</p>



<p>The intuition of <img src="https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=CP-k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="CP-k" class="latex" /> is as follows: we first sample the output from <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> and only accept this output if the likelihood ratio to the <img src="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathsf%7Bsafe%7D&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathsf{safe}" class="latex" /> function (on any <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="C" class="latex" />) satisfies a desired upper bound, the latter of which can be verified by checking the likelihood ratio with respect to both <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" />. Since <img src="https://s0.wp.com/latex.php?latex=p_k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p_k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p_k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p_k" class="latex" /> transforms the output of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> (i.e. it throws aways probability mass which could be potential copyright violations), one might be concerned that we will degrade the quality of the original model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />. Fortunately, we show when this is not the case. We give formal theoretical results on the effectiveness of the approach based on the information distances between <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_2" class="latex" />; in fact, we sometimes even improve on the quality of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> with this approach. We also specify the relationship between the desired <img src="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k_x&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k_x" class="latex" /> and tunable parameter <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />.</p>



<h3 class="wp-block-heading"><strong>An Illustrative Experiment</strong></h3>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2023/02/image.png"><img data-attachment-id="8569" data-permalink="https://windowsontheory.org/2023/02/21/provable-copyright-protection-for-generative-models/image-11/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/02/image.png" data-orig-size="2284,548" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/02/image.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2023/02/image.png?w=656" src="https://windowsontheory.files.wordpress.com/2023/02/image.png?w=1024" alt="" class="wp-image-8569" srcset="https://windowsontheory.files.wordpress.com/2023/02/image.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2023/02/image.png?w=2048 2048w, https://windowsontheory.files.wordpress.com/2023/02/image.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/02/image.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/02/image.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px" /></a><figcaption class="wp-element-caption"><em><strong>Left: </strong>A model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> trained on the full modified CIFAR10 dataset; we injected multiple copies of two images (marked with red frames), so they are likely to be memorized by the model. <strong>Middle two images:</strong> Models <img src="https://s0.wp.com/latex.php?latex=q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1, q_2 " class="latex" /> trained on two shards of the dataset, split so that each injected image appears in only one of them. <strong>Right:</strong> A model obtained by combining <img src="https://s0.wp.com/latex.php?latex=p%2C+q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%2C+q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%2C+q_1%2C+q_2+&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p, q_1, q_2 " class="latex" /> using our algorithm. Despite being a black-box transformation of the three memorizing models, the combined model does not output either of the injected images.</em></figcaption></figure>



<p>We now present a qualitative experiment demonstrating how applying our algorithm to memorizing models produces a model that no longer memorizes. Specifically, we first augment CIFAR-10 with multiple copies of two images (images close to the augmented images are marked with red boundaries); hypothetically, suppose these two images are copyrighted works. For illustrative purposes, we do not deduplicate our dataset. Note our goal here is not to simply present a heuristic approach, such as deduplication, that “often works in practice,” but it is to show that an algorithm with <em>rigorous guarantees</em> can also be practical.</p>



<p>&nbsp;The leftmost image shows generations from a model <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> that was trained on the full dataset, where we clearly see that <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> generates the two copyrighted works. Our algorithm starts by splitting this dataset into two disjoint datasets, where the two copyrighted images are split into two different shards, and it trains two models <img src="https://s0.wp.com/latex.php?latex=q_1%2Cq_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q_1%2Cq_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q_1%2Cq_2&#038;bg=ffffff&#038;fg=666666&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q_1,q_2" class="latex" /> on these disjoint shards. The result is two models such that each generates the CIFAR-10 distribution, but also has a significant chance to output the memorized example. Yet when we combine all three of models using the CP-k algorithm, we obtain a model that agrees with them on the shared part of the distribution but is highly unlikely to output either one of the memorized images.</p>



<figure class="wp-block-image is-resized"><img src="https://lh4.googleusercontent.com/4yzcUxprXN23huNzSGxP6yAyzNgaRbwjlMBOQhWQ4VQ0Y1LP4HeNBpFljIGDX0_pub-xxHrbg6loBbP0vwG11iH3LAoPj9g6H_5rJa741JOHFDvkpSRPMcWM49CYvLuIV1NXLC1Zn2RRrQTcirr6g7c" alt="Illustration of the algorithm to obtain a model satisfying the NAF definition by first splitting the data into two disjoint shards, ensuring that duplicated copies of an image are in the same shard. Then we obtain a model by combining the models trained on both shards." width="635" height="356" /></figure>



<p>See the paper ( <a href="https://arxiv.org/abs/2302.10870">https://arxiv.org/abs/2302.10870</a>  )  for the full details of our definitions, theorems, and experiments. We believe that there is much room for follow-up work, including optimization of performance, as well as much larger-scale experiments.</p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T02:22:01Z">Wednesday, February 22 2023, 02:22</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.10332'>A Qubit, a Coin, and an Advice String Walk Into a Relational Problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Scott Aaronson, Harry Buhrman, William Kretschmer</p><p>Relational problems (those with many possible valid outputs) are different
from decision problems, but it is easy to forget just how different. This paper
initiates the study of FBQP/qpoly, the class of relational problems solvable in
quantum polynomial-time with the help of polynomial-sized quantum advice, along
with its analogues for deterministic and randomized computation (FP, FBPP) and
advice (/poly, /rpoly).
</p>
<p>Our first result is that FBQP/qpoly != FBQP/poly, unconditionally, with no
oracle -- a striking contrast with what we know about the analogous decision
classes. The proof repurposes the separation between quantum and classical
one-way communication complexities due to Bar-Yossef, Jayram, and Kerenidis. We
discuss how this separation raises the prospect of near-term experiments to
demonstrate "quantum information supremacy," a form of quantum supremacy that
would not depend on unproved complexity assumptions.
</p>
<p>Our second result is that FBPP is not contained in FP/poly -- that is,
Adleman's Theorem fails for relational problems -- unless PSPACE is contained
in NP/poly. Our proof uses IP=PSPACE and time-bounded Kolmogorov complexity. On
the other hand, we show that proving FBPP not in FP/poly will be hard, as it
implies a superpolynomial circuit lower bound for PromiseBPEXP.
</p>
<p>We prove the following further results: * Unconditionally, FP != FBPP and
FP/poly != FBPP/poly (even when these classes are carefully defined). *
FBPP/poly = FBPP/rpoly (and likewise for FBQP). For sampling problems, by
contrast, SampBPP/poly != SampBPP/rpoly (and likewise for SampBQP).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Aaronson_S/0/1/0/all/0/1">Scott Aaronson</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Buhrman_H/0/1/0/all/0/1">Harry Buhrman</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kretschmer_W/0/1/0/all/0/1">William Kretschmer</a></p><p>Relational problems (those with many possible valid outputs) are different
from decision problems, but it is easy to forget just how different. This paper
initiates the study of FBQP/qpoly, the class of relational problems solvable in
quantum polynomial-time with the help of polynomial-sized quantum advice, along
with its analogues for deterministic and randomized computation (FP, FBPP) and
advice (/poly, /rpoly).
</p>
<p>Our first result is that FBQP/qpoly != FBQP/poly, unconditionally, with no
oracle -- a striking contrast with what we know about the analogous decision
classes. The proof repurposes the separation between quantum and classical
one-way communication complexities due to Bar-Yossef, Jayram, and Kerenidis. We
discuss how this separation raises the prospect of near-term experiments to
demonstrate "quantum information supremacy," a form of quantum supremacy that
would not depend on unproved complexity assumptions.
</p>
<p>Our second result is that FBPP is not contained in FP/poly -- that is,
Adleman's Theorem fails for relational problems -- unless PSPACE is contained
in NP/poly. Our proof uses IP=PSPACE and time-bounded Kolmogorov complexity. On
the other hand, we show that proving FBPP not in FP/poly will be hard, as it
implies a superpolynomial circuit lower bound for PromiseBPEXP.
</p>
<p>We prove the following further results: * Unconditionally, FP != FBPP and
FP/poly != FBPP/poly (even when these classes are carefully defined). *
FBPP/poly = FBPP/rpoly (and likewise for FBQP). For sampling problems, by
contrast, SampBPP/poly != SampBPP/rpoly (and likewise for SampBQP).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T01:30:00Z">Wednesday, February 22 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.10431'>A note on the partition bound for one-way classical communication complexity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Srinivasan Arunachalam, Jo&#xe3;o F. Doriguello, Rahul Jain</p><p>We present a linear program for the one-way version of the partition bound
(denoted $\mathsf{prt}^1_\varepsilon(f)$). We show that it characterizes
one-way randomized communication complexity $\mathsf{R}_\varepsilon^1(f)$ with
shared randomness of every partial function
$f:\mathcal{X}\times\mathcal{Y}\to\mathcal{Z}$, i.e., for
$\delta,\varepsilon\in(0,1/2)$, $\mathsf{R}_\varepsilon^1(f) \geq
\log\mathsf{prt}_\varepsilon^1(f)$ and $\mathsf{R}_{\varepsilon+\delta}^1(f)
\leq \log\mathsf{prt}_\varepsilon^1(f) + \log\log(1/\delta)$. This improves
upon the characterization of $\mathsf{R}_\varepsilon^1(f)$ in terms of the
rectangle bound (due to Jain and Klauck, 2010) by reducing the additive
$O(\log(1/\delta))$-term to $\log\log(1/\delta)$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Arunachalam_S/0/1/0/all/0/1">Srinivasan Arunachalam</a>, <a href="http://arxiv.org/find/cs/1/au:+Doriguello_J/0/1/0/all/0/1">Jo&#xe3;o F. Doriguello</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1">Rahul Jain</a></p><p>We present a linear program for the one-way version of the partition bound
(denoted $\mathsf{prt}^1_\varepsilon(f)$). We show that it characterizes
one-way randomized communication complexity $\mathsf{R}_\varepsilon^1(f)$ with
shared randomness of every partial function
$f:\mathcal{X}\times\mathcal{Y}\to\mathcal{Z}$, i.e., for
$\delta,\varepsilon\in(0,1/2)$, $\mathsf{R}_\varepsilon^1(f) \geq
\log\mathsf{prt}_\varepsilon^1(f)$ and $\mathsf{R}_{\varepsilon+\delta}^1(f)
\leq \log\mathsf{prt}_\varepsilon^1(f) + \log\log(1/\delta)$. This improves
upon the characterization of $\mathsf{R}_\varepsilon^1(f)$ in terms of the
rectangle bound (due to Jain and Klauck, 2010) by reducing the additive
$O(\log(1/\delta))$-term to $\log\log(1/\delta)$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T01:30:00Z">Wednesday, February 22 2023, 01:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2302.10538'>Lasserre Hierarchy for Graph Isomorphism and Homomorphism Indistinguishability</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David E. Roberson, Tim Seppelt</p><p>We show that feasibility of the $t^\text{th}$ level of the Lasserre
semidefinite programming hierarchy for graph isomorphism can be expressed as a
homomorphism indistinguishability relation. In other words, we define a class
$\mathcal{L}_t$ of graphs such that graphs $G$ and $H$ are not distinguished by
the $t^\text{th}$ level of the Lasserre hierarchy if and only if they admit the
same number of homomorphisms from any graph in $\mathcal{L}_t$. By analysing
the treewidth of graphs in $\mathcal{L}_t$ we prove that the $3t^\text{th}$
level of Sherali--Adams linear programming hierarchy is as strong as the
$t^\text{th}$ level of Lasserre. Moreover, we show that this is best possible
in the sense that $3t$ cannot be lowered to $3t-1$ for any $t$. The same result
holds for the Lasserre hierarchy with non-negativity constraints, which we
similarly characterise in terms of homomorphism indistinguishability over a
family $\mathcal{L}_t^+$ of graphs. Additionally, we give characterisations of
level-$t$ Lasserre with non-negativity constraints in terms of logical
equivalence and via a graph colouring algorithm akin to the Weisfeiler--Leman
algorithm. This provides a polynomial time algorithm for determining if two
given graphs are distinguished by the $t^\text{th}$ level of the Lasserre
hierarchy with non-negativity constraints.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Roberson_D/0/1/0/all/0/1">David E. Roberson</a>, <a href="http://arxiv.org/find/math/1/au:+Seppelt_T/0/1/0/all/0/1">Tim Seppelt</a></p><p>We show that feasibility of the $t^\text{th}$ level of the Lasserre
semidefinite programming hierarchy for graph isomorphism can be expressed as a
homomorphism indistinguishability relation. In other words, we define a class
$\mathcal{L}_t$ of graphs such that graphs $G$ and $H$ are not distinguished by
the $t^\text{th}$ level of the Lasserre hierarchy if and only if they admit the
same number of homomorphisms from any graph in $\mathcal{L}_t$. By analysing
the treewidth of graphs in $\mathcal{L}_t$ we prove that the $3t^\text{th}$
level of Sherali--Adams linear programming hierarchy is as strong as the
$t^\text{th}$ level of Lasserre. Moreover, we show that this is best possible
in the sense that $3t$ cannot be lowered to $3t-1$ for any $t$. The same result
holds for the Lasserre hierarchy with non-negativity constraints, which we
similarly characterise in terms of homomorphism indistinguishability over a
family $\mathcal{L}_t^+$ of graphs. Additionally, we give characterisations of
level-$t$ Lasserre with non-negativity constraints in terms of logical
equivalence and via a graph colouring algorithm akin to the Weisfeiler--Leman
algorithm. This provides a polynomial time algorithm for determining if two
given graphs are distinguished by the $t^\text{th}$ level of the Lasserre
hierarchy with non-negativity constraints.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-02-22T01:30:00Z">Wednesday, February 22 2023, 01:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
