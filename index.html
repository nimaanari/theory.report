<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-03-31T16:36:24Z">Friday, March 31 2023, 16:36</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, March 31
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.simons.berkeley.edu/2023/03/using-theory-to-design-better-interactions-with-visualized-data/'>Using Theory to Design Better Interactions with Visualized Data</a></h3>
        <p class='tr-article-feed'>from <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          by Jessica Hullman (Senior Law and Society Fellow, Simons Institute) &#160; Theories of sequential decision-making have been around for decades but continue to flourish. The Simons Institute’s Fall 2022 program on Data-Driven Decision Processes provided an excellent overview of recent &#8230; Continue reading &#8594;<p>By Simons Institute Editor</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          by Jessica Hullman (Senior Law and Society Fellow, Simons Institute) &#160; Theories of sequential decision-making have been around for decades but continue to flourish. The Simons Institute’s Fall 2022 program on Data-Driven Decision Processes provided an excellent overview of recent &#8230; <a href="https://blog.simons.berkeley.edu/2023/03/using-theory-to-design-better-interactions-with-visualized-data/">Continue reading <span class="meta-nav">&#8594;</span></a><p class="authors">By Simons Institute Editor</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T07:01:00Z">Friday, March 31 2023, 07:01</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/'>A New Tiling</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          With a flip and some twists Roger Penrose has been floored. And perhaps re-floored. Here he is standing on the floor of the Mitchell Institute of Texas A&#038;M, which features one of the famous aperiodic tilings he discovered in the 1970s. Wikipedia src Aperiodic means that the set of two rhombus tiles can cover the [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>With a flip and some twists</em><br />
<font color="#000000"></p>
<p>
Roger Penrose has been floored. And perhaps re-floored. Here he is standing on the floor of the Mitchell Institute of Texas A&#038;M, which features one of the famous aperiodic <a href="https://en.wikipedia.org/wiki/Penrose_tiling">tilings</a> he discovered in the 1970s. </p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/rp-2/" rel="attachment wp-att-21357"><img data-attachment-id="21357" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/rp-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/rp.jpg?fit=440%2C518&amp;ssl=1" data-orig-size="440,518" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rp" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/rp.jpg?fit=255%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/rp.jpg?fit=440%2C518&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/rp.jpg?resize=330%2C390&#038;ssl=1" alt="" width="330" height="390" class="aligncenter wp-image-21357" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/rp.jpg?w=440&amp;ssl=1 440w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/rp.jpg?resize=255%2C300&amp;ssl=1 255w" sizes="(max-width: 330px) 100vw, 330px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Wikipedia <a href="https://en.wikipedia.org/wiki/Penrose_tiling">src</a></FONT>
</td>
</tr>
</table>
<p>
Aperiodic means that the set of two <a href="https://tilings.math.uni-bielefeld.de/substitution/penrose-rhomb/">rhombus</a> tiles can cover the entire plane but only without any globally repeating pattern. Simple tilings, of the kind we covered <a href="https://rjlipton.wpcomstaging.com/2017/07/16/kitchen-tile-catalog-complete/">here</a>, make a finite pattern that can be translated to cover the infinite plane.</p>
<p>
Penrose discovered another aperiodic tiling with only two pieces: the <a href="https://mathworld.wolfram.com/PenroseTiles.html">kite</a> and <a href="https://www.r-bloggers.com/2019/06/kites-and-darts-the-penrose-tiling/">dart</a>. But for over 50 years it was open whether there is a single connected tile that can cover the whole plane but only aperiodically.</p>
<p>
Oxford&#8217;s new Mathematical Institute&#8212;Roger&#8217;s home base&#8212;has a courtyard paved with another of his tilings.  Now there is a new pattern to use for flooring:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/pattern/" rel="attachment wp-att-21358"><img data-attachment-id="21358" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/pattern/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/pattern.jpg?fit=1440%2C810&amp;ssl=1" data-orig-size="1440,810" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pattern" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/pattern.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/pattern.jpg?fit=600%2C338&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/pattern.jpg?resize=550%2C310&#038;ssl=1" alt="" width="550" height="310" class="aligncenter wp-image-21358" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/pattern.jpg?w=1440&amp;ssl=1 1440w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/pattern.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/pattern.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/pattern.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/pattern.jpg?resize=1200%2C675&amp;ssl=1 1200w" sizes="(max-width: 550px) 100vw, 550px" data-recalc-dims="1" /></a></p>
<p><P></p>
<p><H2> The New Pattern and Its Twists </H2></p>
<p><p>
The single tile and its surprising properties were discovered by David Smith, Joseph Samuel Myers, Craig Kaplan, and Chaim Goodman-Strauss.</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/tilers4/" rel="attachment wp-att-21359"><img data-attachment-id="21359" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/tilers4/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Tilers4.png?fit=369%2C403&amp;ssl=1" data-orig-size="369,403" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Tilers4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Tilers4.png?fit=275%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Tilers4.png?fit=369%2C403&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Tilers4.png?resize=246%2C268&#038;ssl=1" alt="" width="246" height="268" class="aligncenter wp-image-21359" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Tilers4.png?w=369&amp;ssl=1 369w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/Tilers4.png?resize=275%2C300&amp;ssl=1 275w" sizes="(max-width: 246px) 100vw, 246px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Composite crop from <a href="https://twitter.com/AlexKontorovich/status/1640047202763522049">this</a>, <a href="https://www.egmo.org/people/person144/">this</a>, <a href="https://www.gathering4gardner.org/chaim-goodman-strauss/">this</a>, and <a href="https://cs.uwaterloo.ca/~csk/">this</a>.</FONT>
</td>
</tr>
</table>
<p>
The introduction to their recently-posted <a href="https://arxiv.org/abs/2303.10798">paper</a> has a nifty sentence that foreshadows why neither the discovery nor the proof of its correctness were easy:</p>
<blockquote><p><b> </b> <em> Can one tile embody enough complexity to forcibly disrupt periodic order at all scales? </em>
</p></blockquote>
<p><p>
They have answered this question <em>yes</em>, though with one asterisk: their asymmetric tile needs to call on its mirror twin&#8212;obtained by flipping it over&#8212;to complete the tilings. Whereas, the tiles in Penrose&#8217;s pairs each have mirror symmetry and so work solely by translations. Penrose&#8217;s rhombus tiles are also convex, whereas the 13-sided &#8220;hat&#8221; or &#8220;shirt&#8221; shape&#8212;as with Penrose&#8217;s &#8220;dart&#8221; shape&#8212;is not.</p>
<p>
After <a href="https://www.sciencenews.org/article/mathematicians-discovered-einstein-tile">several</a> popular-science <a href="https://phys.org/news/2023-03-geometric-tiled.html">articles</a> and <a href="https://cp4space.hatsya.com/2023/03/21/aperiodic-monotile/">blog</a> <a href="https://aperiodical.com/2023/03/an-aperiodic-monotile-exists/">posts</a>, in turn <a href="https://gilkalai.wordpress.com/2023/03/25/an-aperiodic-monotile/">linked</a> by Gil Kalai, the New York Times <a href="https://www.nytimes.com/2023/03/28/science/mathematics-tiling-einstein.html">covered</a> this in Tuesday&#8217;s science section. The story by <a href="https://siobhanroberts.com/">Siobhan Roberts</a> quoted <a href="http://www.science.smith.edu/~senechal/">Marjorie Senechal</a>&#8212;who was recently editor of the <a href="https://www.springer.com/journal/283">Mathematical Intelligencer</a>:</p>
<blockquote><p><b> </b> <em> &#8220;Mathematicians had been searching for such a shape for half a century. It wasn&#8217;t even clear that such a thing could exist.&#8221; </em>
</p></blockquote>
<p><p>
This applies whether or not one insists on convexity or translation without flips. In fact, the tile is composed of eight hexagonal slices, also referred to as &#8220;kites&#8221; but thinner than Penrose&#8217;s, in a way that forms an asymmetric sub-region of a simple repeating tiling of those regions:</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/monotile3/" rel="attachment wp-att-21360"><img data-attachment-id="21360" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/monotile3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/monotile3.png?fit=768%2C768&amp;ssl=1" data-orig-size="768,768" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="monotile3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/monotile3.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/monotile3.png?fit=600%2C600&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/monotile3.png?resize=256%2C256&#038;ssl=1" alt="" width="256" height="256" class="aligncenter wp-image-21360" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/monotile3.png?w=768&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/monotile3.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/monotile3.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/monotile3.png?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/monotile3.png?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 256px) 100vw, 256px" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2"><a href="https://cp4space.hatsya.com/2023/03/21/aperiodic-monotile/">source</a> crediting Tilman Piesk</FONT>
</td>
</tr>
</table>
<p>
This does not constitute a proof that the tile can cover the whole plane, let alone that it must do so aperiodically. Penrose is quoted in the NYT article as saying he finds the proofs in the new paper &#8220;very complicated.&#8221; </p>
<p>
One further fact that both augments and aids the task of proving is that all tilings composed of hats can be continuously deformed keeping identical shapes that still tautly cover the plane. One direction of twisting terminates in a chevron pattern and the other in a &#8220;comet&#8221; composed of a hexagon plus diamond. The chevron and comet <em>can</em> tile repeatedly but here they do not&#8212;meanwhile the authors prove that <em>every</em> shape in-between can only tile aperiodically. The <a href="https://twitter.com/cs_kaplan/status/1639269752194342912">animation</a> created by Kaplan is also in the NYT article.</p>
<p>
<p><H2> The Proofs </H2></p>
<p><p>
The proofs in the paper need to accomplish two goals:</p>
<ol>
<li>
Show that the tile (and its flip) can cover the entire plane&#8212;no holes or gaps or dead-ends. </p>
<li>
Show that no such covering can be periodic.
</ol>
<p>
Both tasks are hard, but among several proofs of the latter there is a nifty trick. The former works by an argument that rings of the hat tiles have a logical &#8220;metastructure&#8221; that enables them to scale up while preserving the ability to mesh with the next-inner and next-outer ring. Because the scale expands, this does not constitute a finite period. Also providing slack is the further-proved fact that the hat tile can cover the plane in <em>uncountably</em> many ways, no two isomorphic.</p>
<p>
Some visuals for the proofs of both points are summarized in a seven-part <a href="https://twitter.com/AlexKontorovich/status/1640047202763522049">telling</a> on twitter by Alex Kontorovich of Rutgers, which is based on a <a href="https://www.youtube.com/watch?v=FkZPMf73qYc">presentation</a> given by the authors at the <a href="https://www.youtube.com/@MuseumOfMathematics">National Museum of Mathematics</a>, with which Goodman-Strauss is affiliated.</p>
<p>
The latter point is given multiple proofs in the paper. One of them, also summarized by Kontorovich from the presentation, has a nifty trick: Suppose the hat gave a periodic tiling. That tiling would admit the continuous twisting action, under which periodicity would be preserved. In particular, the chevron and comet tilings at the endpoints would be periodic after all.</p>
<p><P></p>
<table style="margin:auto;">
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/gridargument/" rel="attachment wp-att-21362"><img data-attachment-id="21362" data-permalink="https://rjlipton.wpcomstaging.com/2023/03/31/a-new-tiling/gridargument/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/GridArgument.png?fit=1099%2C260&amp;ssl=1" data-orig-size="1099,260" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GridArgument" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/GridArgument.png?fit=300%2C71&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/GridArgument.png?fit=600%2C142&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/03/GridArgument.png?resize=600%2C145&#038;ssl=1" alt="" width="600" height="145" class="aligncenter wp-image-21362" data-recalc-dims="1" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><FONT size="-2">Kontorovich <a href="https://twitter.com/AlexKontorovich/status/1640047218802450432">source</a></FONT>
</td>
</tr>
</table>
<p>
What the authors call &#8220;a new kind of geometric incommensurability argument&#8221; then comes into play. It ultimately reaches the conclusion that the simple triangular lattice would have equal-area regions under scalings that differ by a factor of <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B2%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;sqrt{2}}" class="latex" />, a contradiction.</p>
<p>
The paper also gives a long separate proof of forced aperiodicity by means that are more analogous to proofs with other tile sets, but here it needs computer-assisted enumeration and verification of many cases. </p>
<p>
<p><H2> Logic and Complexity Impact? </H2></p>
<p><p>
The subject of tilings has a long history growing out of art and esthetics, but vital connections to biology, crystallography, and logic were discovered more recently. The logical connection ties in the other two and was elevated by Hao Wang&#8217;s famous <a href="https://en.wikipedia.org/wiki/Wang_tile">proofs</a> that certain tiling problems&#8212;and questions of periodicity&#8212;are undecidable. </p>
<p>
Just a few months ago, the online magazine <em>Quanta</em> <a href="https://www.quantamagazine.org/nasty-geometry-breaks-decades-old-tiling-conjecture-20221215/">covered</a> recent work by Rachel Greenfield and Terance Tao showing that in certain high dimensions <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{d}" class="latex" />, there are single tiles that cover the space&#8212;using only orientation-preserving translations&#8212;but only aperiodically. Moreover, those tiles conform to the integer grid <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%5Ed%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathbb{Z}^d}" class="latex" />&#8212;that is, they are gluings of unit hypercubes. Siddhartha Bhattacharya <a href="https://arxiv.org/abs/1602.05738">proved</a> in 2020 that such a result was impossible in <img decoding="async" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%5E2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0&#038;c=20201002" alt="{&#92;mathbb{Z}^2}" class="latex" />.</p>
<p>
The first <a href="https://arxiv.org/abs/2108.07902">paper</a> by Greenfield and Tao is titled, &#8220;Undecidable translational tilings with only two tiles, or one nonabelian tile,&#8221; while the second <a href="https://arxiv.org/pdf/2209.08451.pdf">paper</a> is, &#8220;A counterexample to the periodic tiling conjecture&#8221; with the above result. This supplements and offsets the geenral result that when all translational tilings must be periodic, whether such a tiling is possible for a given set of tiles becomes decidable.</p>
<p>
We wonder what the impact of the new result will be on these connections, and how far the nexus of logic and combinatorics will reach down into computational complexity theory. </p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
In-between the new discovery using a tile and its flip and the impossibility results for translation-only tilings are questions when rotations in the plane but not flips are allowed. Are those questions still wide open? Look at <a href="https://blog.mathed.page/2020/12/29/tiling-and-transformations/">here</a> for lots on this issue in general. </p>
<p>
And partly in jest we ask: will Oxford&#8217;s Mathematical Institute&#8212;or maybe better, <a href="https://momath.org/">MoMath</a>&#8212;put in a new floor with the new tiling?</p>
<p><P><br />
[fixed usage of &#8220;kites&#8221;]</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T05:16:36Z">Friday, March 31 2023, 05:16</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/03/30/tcs-talk-wednesday-april-5-yael-kalai-msr-new-england/'>TCS+ talk: Wednesday, April 5 — Yael Kalai, MSR New England</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The next TCS+ talk will take place this coming Wednesday, April 5th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Yael Kalai from MSR New England will speak about &#8220;Efficient Verification of Computation on Untrusted Platforms&#8221; (abstract below). You can reserve a spot as an individual or a [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The next TCS+ talk will take place this coming Wednesday, April 5th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Yael Kalai</strong> from MSR New England will speak about &#8220;<em>Efficient Verification of Computation on Untrusted Platforms</em>&#8221; (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Efficient verification of computation is fundamental to computer science and is at the heart of the P vs. NP question. Recently it has had growing practical significance, especially with the increasing popularity of blockchain technologies and cloud computing. In this talk, I will present schemes for verifying the correctness of a computation. I will discuss their impact on quantum complexity, hardness of approximation, and the complexity of Nash equilibrium.</p></blockquote>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T02:47:42Z">Friday, March 31 2023, 02:47</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.17578'>Online Learning and Disambiguations of Partial Concept Classes</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tsun-Ming Cheung, Hamed Hatami, Pooya Hatami, Kaave Hosseini</p><p>In a recent article, Alon, Hanneke, Holzman, and Moran (FOCS '21) introduced
a unifying framework to study the learnability of classes of partial concepts.
One of the central questions studied in their work is whether the learnability
of a partial concept class is always inherited from the learnability of some
``extension'' of it to a total concept class.
</p>
<p>They showed this is not the case for PAC learning but left the problem open
for the stronger notion of online learnability.
</p>
<p>We resolve this problem by constructing a class of partial concepts that is
online learnable, but no extension of it to a class of total concepts is online
learnable (or even PAC learnable).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cheung_T/0/1/0/all/0/1">Tsun-Ming Cheung</a>, <a href="http://arxiv.org/find/cs/1/au:+Hatami_H/0/1/0/all/0/1">Hamed Hatami</a>, <a href="http://arxiv.org/find/cs/1/au:+Hatami_P/0/1/0/all/0/1">Pooya Hatami</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseini_K/0/1/0/all/0/1">Kaave Hosseini</a></p><p>In a recent article, Alon, Hanneke, Holzman, and Moran (FOCS '21) introduced
a unifying framework to study the learnability of classes of partial concepts.
One of the central questions studied in their work is whether the learnability
of a partial concept class is always inherited from the learnability of some
``extension'' of it to a total concept class.
</p>
<p>They showed this is not the case for PAC learning but left the problem open
for the stronger notion of online learnability.
</p>
<p>We resolve this problem by constructing a class of partial concepts that is
online learnable, but no extension of it to a class of total concepts is online
learnable (or even PAC learnable).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T00:30:00Z">Friday, March 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.17028'>On the complexity of embedding in graph products</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Therese Biedl, David Eppstein, Torsten Ueckerdt</p><p>Graph embedding, especially as a subgraph of a grid, is an old topic in VLSI
design and graph drawing. In this paper, we investigate related questions
concerning the complexity of embedding a graph $G$ in a host graph that is the
strong product of a path $P$ with a graph $H$ that satisfies some properties,
such as having small treewidth, pathwidth or tree depth. We show that this is
NP-hard, even under numerous restrictions on both $G$ and $H$. In particular,
computing the row pathwidth and the row treedepth is NP-hard even for a tree of
small pathwidth, while computing the row treewidth is NP-hard even for
series-parallel graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Biedl_T/0/1/0/all/0/1">Therese Biedl</a>, <a href="http://arxiv.org/find/cs/1/au:+Eppstein_D/0/1/0/all/0/1">David Eppstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Ueckerdt_T/0/1/0/all/0/1">Torsten Ueckerdt</a></p><p>Graph embedding, especially as a subgraph of a grid, is an old topic in VLSI
design and graph drawing. In this paper, we investigate related questions
concerning the complexity of embedding a graph $G$ in a host graph that is the
strong product of a path $P$ with a graph $H$ that satisfies some properties,
such as having small treewidth, pathwidth or tree depth. We show that this is
NP-hard, even under numerous restrictions on both $G$ and $H$. In particular,
computing the row pathwidth and the row treedepth is NP-hard even for a tree of
small pathwidth, while computing the row treewidth is NP-hard even for
series-parallel graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T00:30:00Z">Friday, March 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.17045'>Training Neural Networks is NP-Hard in Fixed Dimension</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vincent Froese, Christoph Hertrich</p><p>We study the parameterized complexity of training two-layer neural networks
with respect to the dimension of the input data and the number of hidden
neurons, considering ReLU and linear threshold activation functions. Albeit the
computational complexity of these problems has been studied numerous times in
recent years, several questions are still open. We answer questions by Arora et
al. [ICLR '18] and Khalife and Basu [IPCO '22] showing that both problems are
NP-hard for two dimensions, which excludes any polynomial-time algorithm for
constant dimension. We also answer a question by Froese et al. [JAIR '22]
proving W[1]-hardness for four ReLUs (or two linear threshold neurons) with
zero training error. Finally, in the ReLU case, we show fixed-parameter
tractability for the combined parameter number of dimensions and number of
ReLUs if the network is assumed to compute a convex map. Our results settle the
complexity status regarding these parameters almost completely.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Froese_V/0/1/0/all/0/1">Vincent Froese</a>, <a href="http://arxiv.org/find/cs/1/au:+Hertrich_C/0/1/0/all/0/1">Christoph Hertrich</a></p><p>We study the parameterized complexity of training two-layer neural networks
with respect to the dimension of the input data and the number of hidden
neurons, considering ReLU and linear threshold activation functions. Albeit the
computational complexity of these problems has been studied numerous times in
recent years, several questions are still open. We answer questions by Arora et
al. [ICLR '18] and Khalife and Basu [IPCO '22] showing that both problems are
NP-hard for two dimensions, which excludes any polynomial-time algorithm for
constant dimension. We also answer a question by Froese et al. [JAIR '22]
proving W[1]-hardness for four ReLUs (or two linear threshold neurons) with
zero training error. Finally, in the ReLU case, we show fixed-parameter
tractability for the combined parameter number of dimensions and number of
ReLUs if the network is assumed to compute a convex map. Our results settle the
complexity status regarding these parameters almost completely.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T00:30:00Z">Friday, March 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.17506'>Sum-of-Squares Lower Bounds for Densest $k$-Subgraph</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chris Jones, Aaron Potechin, Goutham Rajendran, Jeff Xu</p><p>Given a graph and an integer $k$, Densest $k$-Subgraph is the algorithmic
task of finding the subgraph on $k$ vertices with the maximum number of edges.
This is a fundamental problem that has been subject to intense study for
decades, with applications spanning a wide variety of fields. The
state-of-the-art algorithm is an $O(n^{1/4 + \epsilon})$-factor approximation
(for any $\epsilon &gt; 0$) due to Bhaskara et al. [STOC '10]. Moreover, the
so-called log-density framework predicts that this is optimal, i.e. it is
impossible for an efficient algorithm to achieve an $O(n^{1/4 -
\epsilon})$-factor approximation. In the average case, Densest $k$-Subgraph is
a prototypical noisy inference task which is conjectured to exhibit a
statistical-computational gap.
</p>
<p>In this work, we provide the strongest evidence yet of hardness for Densest
$k$-Subgraph by showing matching lower bounds against the powerful
Sum-of-Squares (SoS) algorithm, a meta-algorithm based on convex programming
that achieves state-of-art algorithmic guarantees for many optimization and
inference problems. For $k \leq n^{\frac{1}{2}}$, we obtain a degree
$n^{\delta}$ SoS lower bound for the hard regime as predicted by the
log-density framework.
</p>
<p>To show this, we utilize the modern framework for proving SoS lower bounds on
average-case problems pioneered by Barak et al. [FOCS '16]. A key issue is that
small denser-than-average subgraphs in the input will greatly affect the value
of the candidate pseudoexpectation operator around the subgraph. To handle this
challenge, we devise a novel matrix factorization scheme based on the positive
minimum vertex separator. We then prove an intersection tradeoff lemma to show
that the error terms when using this separator are indeed small.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jones_C/0/1/0/all/0/1">Chris Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Potechin_A/0/1/0/all/0/1">Aaron Potechin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajendran_G/0/1/0/all/0/1">Goutham Rajendran</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jeff Xu</a></p><p>Given a graph and an integer $k$, Densest $k$-Subgraph is the algorithmic
task of finding the subgraph on $k$ vertices with the maximum number of edges.
This is a fundamental problem that has been subject to intense study for
decades, with applications spanning a wide variety of fields. The
state-of-the-art algorithm is an $O(n^{1/4 + \epsilon})$-factor approximation
(for any $\epsilon &gt; 0$) due to Bhaskara et al. [STOC '10]. Moreover, the
so-called log-density framework predicts that this is optimal, i.e. it is
impossible for an efficient algorithm to achieve an $O(n^{1/4 -
\epsilon})$-factor approximation. In the average case, Densest $k$-Subgraph is
a prototypical noisy inference task which is conjectured to exhibit a
statistical-computational gap.
</p>
<p>In this work, we provide the strongest evidence yet of hardness for Densest
$k$-Subgraph by showing matching lower bounds against the powerful
Sum-of-Squares (SoS) algorithm, a meta-algorithm based on convex programming
that achieves state-of-art algorithmic guarantees for many optimization and
inference problems. For $k \leq n^{\frac{1}{2}}$, we obtain a degree
$n^{\delta}$ SoS lower bound for the hard regime as predicted by the
log-density framework.
</p>
<p>To show this, we utilize the modern framework for proving SoS lower bounds on
average-case problems pioneered by Barak et al. [FOCS '16]. A key issue is that
small denser-than-average subgraphs in the input will greatly affect the value
of the candidate pseudoexpectation operator around the subgraph. To handle this
challenge, we devise a novel matrix factorization scheme based on the positive
minimum vertex separator. We then prove an intersection tradeoff lemma to show
that the error terms when using this separator are indeed small.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T00:30:00Z">Friday, March 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.17204'>A Subquadratic Time Algorithm for the Weighted $k$-Center Problem on Cactus Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Binay Bhattacharya, Sandip Das, Subhadeep Ranjan Dev</p><p>The weighted $k$-center problem in graphs is a classical facility location
problem where we place $k$ centers on the graph, which minimize the maximum
weighted distance of a vertex to its nearest center. We study this problem when
the underlying graph is a cactus with $n$ vertices and present an $O(n \log^2
n)$ time algorithm for the same. This time complexity improves upon the
$O(n^2)$ time algorithm by Ben-Moshe et al. [TCS 2007], which is the current
state-of-the-art.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_B/0/1/0/all/0/1">Binay Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Sandip Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Dev_S/0/1/0/all/0/1">Subhadeep Ranjan Dev</a></p><p>The weighted $k$-center problem in graphs is a classical facility location
problem where we place $k$ centers on the graph, which minimize the maximum
weighted distance of a vertex to its nearest center. We study this problem when
the underlying graph is a cactus with $n$ vertices and present an $O(n \log^2
n)$ time algorithm for the same. This time complexity improves upon the
$O(n^2)$ time algorithm by Ben-Moshe et al. [TCS 2007], which is the current
state-of-the-art.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T00:30:00Z">Friday, March 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.17274'>Capacity-Preserving Subgraphs of Directed Flow Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Markus Chimani, Max Ilsen</p><p>We introduce and discuss the Minimum Capacity-Preserving Subgraph (MCPS)
problem: given a directed graph and a retention ratio $\alpha \in (0,1)$, find
the smallest subgraph that, for each pair of vertices $(u,v)$, preserves at
least a fraction $\alpha$ of a maximum $u$-$v$-flow's value. This problem
originates from the practical setting of reducing the power consumption in a
computer network: it models turning off as many links as possible while
retaining the ability to transmit at least $\alpha$ times the traffic compared
to the original network.
</p>
<p>First we prove that MCPS is NP-hard already on directed acyclic graphs
(DAGs). Our reduction also shows that a closely related problem (which only
considers the arguably most complicated core of the problem in the objective
function) is NP-hard to approximate within a sublogarithmic factor already on
DAGs. In terms of positive results, we present a simple linear time algorithm
that solves MCPS optimally on directed series-parallel graphs (DSPs). Further,
we introduce the family of laminar series-parallel graphs (LSPs), a
generalization of DSPs that also includes cyclic and very dense graphs. Not
only are we able to solve MCPS on LSPs in quadratic time, but our approach also
yields straightforward quadratic time algorithms for several related problems
such as Minimum Equivalent Digraph and Directed Hamiltonian Cycle on LSPs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chimani_M/0/1/0/all/0/1">Markus Chimani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilsen_M/0/1/0/all/0/1">Max Ilsen</a></p><p>We introduce and discuss the Minimum Capacity-Preserving Subgraph (MCPS)
problem: given a directed graph and a retention ratio $\alpha \in (0,1)$, find
the smallest subgraph that, for each pair of vertices $(u,v)$, preserves at
least a fraction $\alpha$ of a maximum $u$-$v$-flow's value. This problem
originates from the practical setting of reducing the power consumption in a
computer network: it models turning off as many links as possible while
retaining the ability to transmit at least $\alpha$ times the traffic compared
to the original network.
</p>
<p>First we prove that MCPS is NP-hard already on directed acyclic graphs
(DAGs). Our reduction also shows that a closely related problem (which only
considers the arguably most complicated core of the problem in the objective
function) is NP-hard to approximate within a sublogarithmic factor already on
DAGs. In terms of positive results, we present a simple linear time algorithm
that solves MCPS optimally on directed series-parallel graphs (DSPs). Further,
we introduce the family of laminar series-parallel graphs (LSPs), a
generalization of DSPs that also includes cyclic and very dense graphs. Not
only are we able to solve MCPS on LSPs in quadratic time, but our approach also
yields straightforward quadratic time algorithms for several related problems
such as Minimum Equivalent Digraph and Directed Hamiltonian Cycle on LSPs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T00:30:00Z">Friday, March 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.17346'>Advice Complexity bounds for Online Delayed F-Node-, H-Node- and H-Edge-Deletion Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Niklas Berndt, Henri Lotze</p><p>Let F be a fixed finite obstruction set of graphs and G be a graph revealed
in an online fashion, node by node. The online Delayed F-Node-Deletion Problem
(F-Edge-Deletion Problem}) is to keep G free of every H in F by deleting nodes
(edges) until no induced subgraph isomorphic to any graph in F can be found in
G. The task is to keep the number of deletions minimal.
</p>
<p>Advice complexity is a model in which an online algorithm has access to a
binary tape of infinite length, on which an oracle can encode information to
increase the performance of the algorithm. We are interested in the minimum
number of advice bits that are necessary and sufficient to solve a deletion
problem optimally.
</p>
<p>In this work, we first give essentially tight bounds on the advice complexity
of the Delayed F-Node-Deletion Problem and F-Edge-Deletion Problem where F
consists of a single, arbitrary graph H. We then show that the gadget used to
prove these results can be utilized to give tight bounds in the case of node
deletions if F consists of either only disconnected graphs or only connected
graphs. Finally, we show that the number of advice bits that is necessary and
sufficient to solve the general Delayed F-Node-Deletion Problem is heavily
dependent on the obstruction set F. To this end, we provide sets for which this
number is either constant, logarithmic or linear in the optimal number of
deletions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berndt_N/0/1/0/all/0/1">Niklas Berndt</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotze_H/0/1/0/all/0/1">Henri Lotze</a></p><p>Let F be a fixed finite obstruction set of graphs and G be a graph revealed
in an online fashion, node by node. The online Delayed F-Node-Deletion Problem
(F-Edge-Deletion Problem}) is to keep G free of every H in F by deleting nodes
(edges) until no induced subgraph isomorphic to any graph in F can be found in
G. The task is to keep the number of deletions minimal.
</p>
<p>Advice complexity is a model in which an online algorithm has access to a
binary tape of infinite length, on which an oracle can encode information to
increase the performance of the algorithm. We are interested in the minimum
number of advice bits that are necessary and sufficient to solve a deletion
problem optimally.
</p>
<p>In this work, we first give essentially tight bounds on the advice complexity
of the Delayed F-Node-Deletion Problem and F-Edge-Deletion Problem where F
consists of a single, arbitrary graph H. We then show that the gadget used to
prove these results can be utilized to give tight bounds in the case of node
deletions if F consists of either only disconnected graphs or only connected
graphs. Finally, we show that the number of advice bits that is necessary and
sufficient to solve the general Delayed F-Node-Deletion Problem is heavily
dependent on the obstruction set F. To this end, we provide sets for which this
number is either constant, logarithmic or linear in the optimal number of
deletions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T00:30:00Z">Friday, March 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.17551'>The Online Pause and Resume Problem: Optimal Algorithms and An Application to Carbon-Aware Load Shifting</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adam Lechowicz, Nicolas Christianson, Jinhang Zuo, Noman Bashir, Mohammad Hajiesmaili, Adam Wierman, Prashant Shenoy</p><p>We introduce and study the online pause and resume problem. In this problem,
a player attempts to find the $k$ lowest (alternatively, highest) prices in a
sequence of fixed length $T$, which is revealed sequentially. At each time
step, the player is presented with a price and decides whether to accept or
reject it. The player incurs a switching cost whenever their decision changes
in consecutive time steps, i.e., whenever they pause or resume purchasing. This
online problem is motivated by the goal of carbon-aware load shifting, where a
workload may be paused during periods of high carbon intensity and resumed
during periods of low carbon intensity and incurs a cost when saving or
restoring its state. It has strong connections to existing problems studied in
the literature on online optimization, though it introduces unique technical
challenges that prevent the direct application of existing algorithms.
Extending prior work on threshold-based algorithms, we introduce
double-threshold algorithms for both the minimization and maximization variants
of this problem. We further show that the competitive ratios achieved by these
algorithms are the best achievable by any deterministic online algorithm.
Finally, we empirically validate our proposed algorithm through case studies on
the application of carbon-aware load shifting using real carbon trace data and
existing baseline algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lechowicz_A/0/1/0/all/0/1">Adam Lechowicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Christianson_N/0/1/0/all/0/1">Nicolas Christianson</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_J/0/1/0/all/0/1">Jinhang Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bashir_N/0/1/0/all/0/1">Noman Bashir</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1">Mohammad Hajiesmaili</a>, <a href="http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1">Adam Wierman</a>, <a href="http://arxiv.org/find/cs/1/au:+Shenoy_P/0/1/0/all/0/1">Prashant Shenoy</a></p><p>We introduce and study the online pause and resume problem. In this problem,
a player attempts to find the $k$ lowest (alternatively, highest) prices in a
sequence of fixed length $T$, which is revealed sequentially. At each time
step, the player is presented with a price and decides whether to accept or
reject it. The player incurs a switching cost whenever their decision changes
in consecutive time steps, i.e., whenever they pause or resume purchasing. This
online problem is motivated by the goal of carbon-aware load shifting, where a
workload may be paused during periods of high carbon intensity and resumed
during periods of low carbon intensity and incurs a cost when saving or
restoring its state. It has strong connections to existing problems studied in
the literature on online optimization, though it introduces unique technical
challenges that prevent the direct application of existing algorithms.
Extending prior work on threshold-based algorithms, we introduce
double-threshold algorithms for both the minimization and maximization variants
of this problem. We further show that the competitive ratios achieved by these
algorithms are the best achievable by any deterministic online algorithm.
Finally, we empirically validate our proposed algorithm through case studies on
the application of carbon-aware load shifting using real carbon trace data and
existing baseline algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T00:30:00Z">Friday, March 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.17554'>Pseudorandom Linear Codes are List Decodable to Capacity</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Aaron (Louie) Putterman, Edward Pyne</p><p>We introduce a novel family of expander-based error correcting codes. These
codes can be sampled with randomness linear in the block-length, and achieve
list-decoding capacity (among other local properties). Our expander-based codes
can be made starting from any family of sufficiently low-bias codes, and as a
consequence, we give the first construction of a family of algebraic codes that
can be sampled with linear randomness and achieve list-decoding capacity. We
achieve this by introducing the notion of a pseudorandom puncturing of a code,
where we select $n$ indices of a base code $C\subset \mathbb{F}_q^m$ via an
expander random walk on a graph on $[m]$. Concretely, whereas a random linear
code (i.e. a truly random puncturing of the Hadamard code) requires $O(n^2)$
random bits to sample, we sample a pseudorandom linear code with $O(n)$ random
bits. We show that pseudorandom puncturings satisfy several desirable
properties exhibited by truly random puncturings. In particular, we extend a
result of (Guruswami Mosheiff FOCS 2022) and show that a pseudorandom
puncturing of a small-bias code satisfies the same local properties as a random
linear code with high probability. As a further application of our techniques,
we also show that pseudorandom puncturings of Reed Solomon codes are
list-recoverable beyond the Johnson bound, extending a result of (Lund
Potukuchi RANDOM 2020). We do this by instead analyzing properties of codes
with large distance, and show that pseudorandom puncturings still work well in
this regime.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Aaron/0/1/0/all/0/1">Aaron</a> (Louie) <a href="http://arxiv.org/find/math/1/au:+Putterman/0/1/0/all/0/1">Putterman</a>, <a href="http://arxiv.org/find/math/1/au:+Pyne_E/0/1/0/all/0/1">Edward Pyne</a></p><p>We introduce a novel family of expander-based error correcting codes. These
codes can be sampled with randomness linear in the block-length, and achieve
list-decoding capacity (among other local properties). Our expander-based codes
can be made starting from any family of sufficiently low-bias codes, and as a
consequence, we give the first construction of a family of algebraic codes that
can be sampled with linear randomness and achieve list-decoding capacity. We
achieve this by introducing the notion of a pseudorandom puncturing of a code,
where we select $n$ indices of a base code $C\subset \mathbb{F}_q^m$ via an
expander random walk on a graph on $[m]$. Concretely, whereas a random linear
code (i.e. a truly random puncturing of the Hadamard code) requires $O(n^2)$
random bits to sample, we sample a pseudorandom linear code with $O(n)$ random
bits. We show that pseudorandom puncturings satisfy several desirable
properties exhibited by truly random puncturings. In particular, we extend a
result of (Guruswami Mosheiff FOCS 2022) and show that a pseudorandom
puncturing of a small-bias code satisfies the same local properties as a random
linear code with high probability. As a further application of our techniques,
we also show that pseudorandom puncturings of Reed Solomon codes are
list-recoverable beyond the Johnson bound, extending a result of (Lund
Potukuchi RANDOM 2020). We do this by instead analyzing properties of codes
with large distance, and show that pseudorandom puncturings still work well in
this regime.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-31T00:30:00Z">Friday, March 31 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, March 30
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/03/30/tenure-track-faculty-at-iowa-state-university-apply-by-april-4-2023/'>Tenure Track Faculty at Iowa State University (apply by April 4, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Iowa State University is seeking tenure track faculty in Theoretical Computer Science (broadly defined). Website: cra.org/job/iowa-state-university-tenure-track-faculty-positions-in-computer-science/ Email: pavan@iastate.edu
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Iowa State University is seeking tenure track faculty in Theoretical Computer Science (broadly defined).</p>
<p>Website: <a href="https://cra.org/job/iowa-state-university-tenure-track-faculty-positions-in-computer-science/">https://cra.org/job/iowa-state-university-tenure-track-faculty-positions-in-computer-science/</a><br />
Email: pavan@iastate.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T18:09:58Z">Thursday, March 30 2023, 18:09</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://11011110.github.io/blog/2023/03/30/logic-engines-product.html'>Logic engines and product graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://11011110.github.io/blog/'>David Eppstein</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The graph product structure theorem of Dujmović et al.1 states that every planar graph can be represented as a subgraph of a special kind of graph product: the strong product of a path graph and a graph of bounded treewidth. Like other graph products, the strong product \(G\boxtimes H\) of two graphs \(G\) and \(H\) has a vertex for each pair of a vertex in \(G\) and a vertex in \(H\). You can move in the strong product by moving along an edge in one of the factors and staying put in the other (like the Cartesian product) but also by moving along an edge in each factor (like the tensor product). So, for instance, the graph of king moves on a chessboard is a strong product of two paths, one representing the sequence of rows along which the king can move and the other representing the sequence of columns. Vida Dujmović, Gwenaël Joret, Piotr Micek, Pat Morin, Torsten Ueckerdt, and David R. Wood (2020), “Planar graphs have bounded queue-number”, JACM 67 (4): Art. 22, doi:10.1145/3385731, arXiv:1904.04791. &#8617;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>The graph product structure theorem of Dujmović et al.<sup id="fnref:duj" role="doc-noteref"><a href="#fn:duj" class="footnote" rel="footnote">1</a></sup> states that every planar graph can be represented as a subgraph of a special kind of graph product: the <a href="https://en.wikipedia.org/wiki/Strong_product_of_graphs">strong product</a> of a <a href="Path graph">path graph</a> and a graph of <a href="https://en.wikipedia.org/wiki/Treewidth">bounded treewidth</a>. Like other graph products, the strong product \(G\boxtimes H\) of two graphs \(G\) and \(H\) has a vertex for each pair of a vertex in \(G\) and a vertex in \(H\). You can move in the strong product by moving along an edge in one of the factors and staying put in the other (like the Cartesian product) but also by moving along an edge in each factor (like the tensor product). So, for instance, the graph of king moves on a chessboard is a strong product of two paths, one representing the sequence of rows along which the king can move and the other representing the sequence of columns.</p>

<p style="text-align:center"><img src="/blog/assets/2019/kings-graph.svg" alt="The king's graph" /></p>

<p>In terminology later introduced by Bose et al.,<sup id="fnref:bos" role="doc-noteref"><a href="#fn:bos" class="footnote" rel="footnote">2</a></sup> the graph product structure theorem states that planar graphs have “bounded row treewidth”. Here, having row treewidth \(w\) is the same as being a subgraph of a strong product of a path with a graph of treewidth \(w\). You can define the same sort of concept “row X-width” for any other graph width parameter, meaning the same thing: having row X-width \(w\) means being a subgraph of a strong product of a graph of X-width \(w\). Since the announcement of the graph product structure theorem, this area has quickly expanded in interest, with many papers studying the relations between these row parameters, the decompositions of beyond-planar graphs, and other kinds of product decompositions.</p>

<p>However, there has not been as much work so far on the computational complexity of row treewidth and related parameters. Treewidth is NP-hard in general, but for any fixed \(k\), testing whether a graph has treewidth \(k\) takes only linear time.<sup id="fnref:bod" role="doc-noteref"><a href="#fn:bod" class="footnote" rel="footnote">3</a></sup> Can this sort of fixed-parameter tractable algorithm be found for row treewidth and other analogous parameters? The answer turns out to be no. My new preprint, “On the complexity of embedding in graph products”, with Therese Biedl and Torsten Ueckerdt (<a href="https://arxiv.org/abs/2303.17028">arXiv:2303.17028</a>) provides NP-completeness proofs showing that even the smallest nontrivial parameter values are difficult to test, even on very simple graphs.</p>

<p>The starting point for several of our proofs is a result that has been known for much longer: it is hard to tell whether a given graph is a subgraph of the integer grid. It remains hard even when the given graph is a tree.<sup id="fnref:bc" role="doc-noteref"><a href="#fn:bc" class="footnote" rel="footnote">4</a></sup> The proof uses a technique later called the “logic engine”,<sup id="fnref:ew" role="doc-noteref"><a href="#fn:ew" class="footnote" rel="footnote">5</a></sup> in which one makes a graph with pieces that, in any grid embedding, must remain rigid, with flexible connections to the other pieces. The illustration below shows an example that could be used in a proof of the known result that embedding planar graphs as subgraphs of a grid is NP-complete. It is constructed from a not-all-equal satisfiability problem, whose variables are translated into the blue arms of the figure. Each arm can flip vertically, across the central horizontal spine, giving its variable two states, true or false. The green flags, each suspended from a vertical path attached to an arm, can flip to the left or to the right. Each row of flags is confined by the surrounding yellow frame, in such a way that the flags can only fit into their row if at least one arm is missing a flag on that row. When a variable belongs to a clause, its flag is removed from the clause’s row of the construction, providing a gap that will allow all the flags to fit on that row.</p>

<p style="text-align:center"><img src="/blog/assets/2023/logic-engine.svg" alt="Logic engine graph constructed by a reduction from not-all-equal satisfiability to planar grid embedding. In order for the blue variable arms and green term flags to all fit within the yellow frame, each row of the grid must have at least one missing flag." /></p>

<p>Grids are Cartesian products of a path with a path, but the products involved in row treewidth and row pathwidth are a bit more complicated, both because they use the strong product in place of the Cartesian product, and because one of the factors is not a path. The simplest case for row treewidth is width one, embedding into a strong product of a path and a tree. Testing whether such an embedding exists is trivial for trees (just use the product of the tree itself with a one-vertex path). But as we prove, it is hard for the next simplest case, when the graph to be embedded has treewidth two. Our proof again uses the logic engine. However, compared to the figure above, more care is needed in the construction to ensure that parts of the logic engine cannot avoid bumping into each other by twisting in ways that would be impossible for Cartesian products but possible in strong products, or by escaping into another branch of the factor graph.</p>

<p>Testing whether the row pathwidth one turns out to be hard even for trees. Because the graphs of pathwidth one are just the caterpillars, this means testing whether the given tree can be embedded into a strong product of a path with a caterpillar. It would be possible to prove this again using the logic engine, but we don’t. Instead, we use the known result that it’s hard to embed trees into grids. We find a way to transform trees into larger trees so that grid embedding of the smaller tree becomes equivalent to path-caterpillar-product embedding of the expanded tree.</p>

<p>We also prove that row treedepth, defined in the same way, is hard, even to test whether a tree has row treedepth one. This is the same as asking whether the given tree can be represented as a subgraph of a product of a path with a star. For this problem, the logic engine doesn’t work. Path-star products are too narrow for its components to fit into them. Instead, we use a different hardness reduction based on bin packing.</p>

<p>Even accurately approximating the row treewidth is hard, at least if you believe that approximating treewidth itself is hard. The hardness of approximation of treewidth has not been proven rigorously, but instead rests on an unproven assumption, the <a href="https://en.wikipedia.org/wiki/Small_set_expansion_hypothesis">small set expansion hypothesis</a>, a variant of the <a href="https://en.wikipedia.org/wiki/Unique_games_conjecture">unique games conjecture</a>. But if this assumption is true, then it is impossible to approximate treewidth to within any constant factor. If you add a universal vertex to a graph, you don’t change its treewidth much, but you force its row treewidth to be within a constant factor of its treewidth, because it prevents you from using path factors that are longer than two edges. So, under this assumption, it is also impossible to approximate row treewidth to within any constant factor.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:duj" role="doc-endnote">
      <p>Vida Dujmović, Gwenaël Joret, Piotr Micek, Pat Morin, Torsten Ueckerdt, and David R. Wood (2020), “Planar graphs have bounded queue-number”, <em>JACM</em> 67 (4): Art. 22, <a href="https://doi.org/10.1145/3385731">doi:10.1145/3385731</a>, <a href="https://arxiv.org/abs/1904.04791">arXiv:1904.04791</a>. <a href="#fnref:duj" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:bos" role="doc-endnote">
      <p>Prosenjit Bose, Vida Dujmović, Mehrnoosh Javarsineh, Pat Morin, David R. Wood (2022), “Separating layered treewidth and row treewidth”, <em>DMTCS</em> 24 (1): Art. 18, <a href="https://arxiv.org/abs/2105.01230">arXiv:2105.01230</a>. <a href="#fnref:bos" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:bod" role="doc-endnote">
      <p>Hans L. Bodlaender (1996), “A linear time algorithm for finding tree-decompositions of small treewidth”, <em>SICOMP</em> 25 (6): 1305–1317, <a href="https://doi.org/10.1137/S0097539793251219">doi:10.1137/S0097539793251219</a>. <a href="#fnref:bod" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:bc" role="doc-endnote">
      <p>Sandeep Bhatt and Stavros Cosmadakis (1987), “The complexity of minimizing wire lengths in VLSI layouts”, <em>IPL</em> 25 (4): 263–267, <a href="https://doi.org/10.1016/0020-0190(87)90173-6">doi:10.1016/0020-0190(87)90173-6</a> <a href="#fnref:bc" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:ew" role="doc-endnote">
      <p>Peter Eades and Sue Whitesides (1996), “The logic engine and the realization problem for nearest neighbor graphs”, <em>TCS</em> 169 (1): 23–27, <a href="https://doi.org/10.1016/S0304-3975(97)84223-5">doi:10.1016/S0304-3975(97)84223-5</a>. <a href="#fnref:ew" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/110115277230448668">Discuss on Mastodon</a>)</p><p class="authors">By David Eppstein</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T16:46:00Z">Thursday, March 30 2023, 16:46</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/03/30/tcs-for-all-travel-grants-and-speaker-nominations-guest-post-by-elena-grigorescu/'>TCS for all travel grants and speaker nominations (guest post by Elena Grigorescu)</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          TCS for All (previously TCS Women) Spotlight Workshop at STOC 2023/Theory Fest: Travel grants and call for speaker nominations You are cordially invited to our TCS for All Spotlight Workshop! The workshop will be held&#160;on Thursday, June 22nd, 2023 (2-4pm), in Orlando, Florida, USA, as part of the&#160;54th&#160;Symposium&#160;on Theory of Computing (STOC)&#160;and TheoryFest! The workshop &#8230; Continue reading TCS for all travel grants and speaker nominations (guest post by Elena&#160;Grigorescu)
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><strong>TCS for All (previously TCS Women) Spotlight Workshop at STOC 2023/Theory Fest: Travel grants and call for speaker nominations</strong></p>



<p>You are cordially invited to our TCS for All Spotlight Workshop! The workshop will be held&nbsp;on Thursday, June 22nd, 2023 (2-4pm), in Orlando, Florida, USA, as part of the&nbsp;<a href="http://acm-stoc.org/stoc2022/" target="_blank" rel="noreferrer noopener">54th&nbsp;</a><a href="http://acm-stoc.org/stoc2023/" target="_blank" rel="noreferrer noopener">Symposium&nbsp;</a><a href="http://acm-stoc.org/stoc2022/" target="_blank" rel="noreferrer noopener">on Theory of Computing (STOC)</a>&nbsp;and TheoryFest! The workshop is open to all.</p>



<p>We are happy to announce that our annual inspirational talk will be given by Professor Dana Randall!</p>



<p>More information about the workshop is available here:&nbsp;<a href="https://sigact.org/tcsforall/" target="_blank" rel="noreferrer noopener">https://sigact.org/tcsforall/</a>. In particular, we would like to highlight the TCS for All Travel Scholarships (deadline&nbsp;May 7th) and a call for nominations for Rising Stars talks at the workshop (deadline&nbsp;May 7th).&nbsp; More information on those are below.</p>



<p>Hope to see you in Orlando!</p>



<p><strong><em>TCS for All Travel Scholarship:</em></strong></p>



<p>TCS for All Travel Scholarships are intended for researchers at the beginning of their career. This scholarship is being made available for minorities in TCS, and anyone who identifies as such is welcome to apply; this scholarship is open to both US and international students. Preference will be given to students at the beginning of their studies. If we have sufficient funding, we will give awards to more senior students and possibly even postdocs.</p>



<p>To apply, you will need to fill out the following form by&nbsp;<strong>May 7th, 2023</strong>&nbsp;(11:59 pm PDT) in which you provide basic information about yourself, an estimate of your expenses, and a brief statement:</p>



<p><a href="https://forms.gle/btayQhoATxEkGoV18" target="_blank" rel="noreferrer noopener">Apply for a travel grant here.</a></p>



<p>In addition, you will need to have your advisor (or department head or other faculty mentor if you do not yet have an advisor) send a letter of support to&nbsp;<a href="mailto:tcswomen@gmail.com" target="_blank" rel="noreferrer noopener">tcswomen@gmail.com</a>&nbsp;by&nbsp;May 7th. Your advisor’s letter should also describe the availability of other travel funds.&nbsp; Note for advisors: Specifics about alternative funding are very helpful.&nbsp; Statements like “funding is tight” are not very helpful. This letter should be sent with subject line “support letter for [your name]”. This is very important. Your application is not complete without this letter.</p>



<p>Late applications (after&nbsp;May 7th) will not be accepted. You will be notified about your status by&nbsp;May 15th, which is prior to the STOC early registration deadline and hotel cut-off deadline.</p>



<p>Notes: Receipts will be required for all travel awards, and reimbursements will be made after the conference. Food or visa expenses will not be reimbursed.</p>



<p><strong><em>Nominations for Rising Star talks:</em></strong></p>



<p>We invite nomination for speakers in our Rising Star talks at the TCS for All Spotlight Workshop at STOC 2023. To be eligible, your nominee has to be a senior PhD student with expected graduation no later than August 2024,&nbsp;or&nbsp;a postdoc in theoretical computer science (all topics represented at STOC are welcome), an underrepresented minority, and not a speaker at a previous TCS Women Spotlight Workshop.&nbsp; Preference will be given to speakers who are currently on the job market for postdoctoral/faculty positions, or who expect to be on the job market in Fall 2023.</p>



<p>You can make your nomination by filling this form by&nbsp;<strong>May 7th</strong>:&nbsp;<a href="https://forms.gle/jCMXsTmZ4DZ8r5xJA" target="_blank" rel="noreferrer noopener">https://forms.gle/jCMXsTmZ4DZ8r5xJA</a></p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T13:10:38Z">Thursday, March 30 2023, 13:10</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7174'>If AI scaling is to be shut down, let it be for a coherent reason</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          There&#8217;s now an open letter arguing that the world should impose a six-month moratorium on the further scaling of AI models such as GPT, by government fiat if necessary, to give AI safety and interpretability research a bit more time to catch up. The letter is signed by many of my friends and colleagues, many [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>There&#8217;s now an <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter</a> arguing that the world should impose a six-month moratorium on the further scaling of AI models such as GPT, by government fiat if necessary, to give AI safety and interpretability research a bit more time to catch up.  The letter is signed by many of my friends and colleagues, many who probably agree with each other about little else, over a thousand people including Elon Musk, Steve Wozniak, Andrew Yang, Jaan Tallinn, Stuart Russell, Max Tegmark, Yuval Noah Harari, Ernie Davis, Gary Marcus, and Yoshua Bengio. </p>



<p>Meanwhile, Eliezer Yudkowsky <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">published a piece in <em>TIME</em></a> arguing that the open letter doesn&#8217;t go nearly far enough, and that AI scaling needs to be shut down entirely until the AI alignment problem is solved&#8212;with the shutdown enforced by military strikes on GPU farms if needed, and treated as more important than preventing nuclear war.</p>



<p>Readers, as they do, asked me to respond.  Alright, alright.  While the open letter is presumably targeted at OpenAI more than any other entity, and while I’ve been <a href="https://scottaaronson.blog/?p=6484">spending the year at OpenAI</a> to work on theoretical foundations of AI safety, I’m going to answer strictly for myself.</p>



<p>Given the jaw-droppingly spectacular abilities of GPT-4&#8212;e.g., <a href="https://www.semafor.com/article/03/15/2023/how-gpt-4-performed-in-academic-exams">acing</a> the Advanced Placement biology and macroeconomics exams, correctly <a href="https://arxiv.org/abs/2303.12712">manipulating images</a> (via their source code) without having been programmed for anything of the kind, etc. etc.&#8212;the idea that AI now needs to be treated with extreme caution strikes me as far from absurd.  I don&#8217;t even dismiss the possibility that advanced AI could eventually require the same sorts of safeguards as nuclear weapons.</p>



<p>Furthermore, people might be surprised about the diversity of opinion about these issues <em>within</em> OpenAI, by how many there have discussed or even forcefully advocated slowing down.  And there&#8217;s a world not so far from this one where I, too, get behind a pause.  For example, one <em>actual</em> major human tragedy caused by a generative AI model might suffice to push me over the edge.  (What would push <em>you</em> over the edge, if you&#8217;re not already over?)</p>



<p>Before I join the slowdown brigade, though, I have (this being the week before Passover) four questions for the signatories:</p>



<ol>
<li>Would your rationale for this pause have applied to basically <em>any</em> nascent technology — the printing press, radio, airplanes, the Internet?  “We don’t yet know the implications, but there’s an excellent chance terrible people will misuse this, ergo the only responsible choice is to pause until we&#8217;re confident that they won&#8217;t”?</li>



<li>Why six months?  Why not six weeks or six years?</li>



<li>When, by your lights, would we ever know that it was safe to <em>resume</em> scaling AI&#8212;or at least that the risks of pausing exceeded the risks of scaling?  Why won&#8217;t the <a href="https://en.wikipedia.org/wiki/Precautionary_principle">precautionary principle</a> continue for apply forever?</li>



<li>Were you, until approximately last week, ridiculing GPT as unimpressive, a stochastic parrot, lacking common sense, piffle, a scam, etc. — before turning around and declaring that it could be existentially dangerous? How can you have it both ways?  If the problem, in your view, is that GPT-4 is too stupid, then shouldn&#8217;t GPT-5 be smarter <em>and therefore</em> <em>safer</em>?  Thus, shouldn&#8217;t we keep scaling AI as quickly as we can &#8230; <em>for safety reasons</em>?  If, on the other hand, the problem is that GPT-4 is too smart, then why can’t you bring yourself to say so?</li>
</ol>



<p>With the “why six months?” question, I confess that I was deeply confused, until I heard a dear friend and colleague in academic AI, one who&#8217;s long been skeptical of AI-doom scenarios, explain why <em>he</em> signed the open letter.  He said: look, we all started writing research papers about the safety issues with ChatGPT; then our work became obsolete when OpenAI released GPT-4 just a few months later.  So now we&#8217;re writing papers about GPT-4.  Will we <em>again</em> have to throw our work away when OpenAI releases GPT-5?  I realized that, while six months might not suffice to save human civilization, it&#8217;s just enough for the more immediate concern of getting papers into academic AI conferences.</p>



<p>Look: while I&#8217;ve spent <a href="https://scottaaronson.blog/?p=6821">multiple</a> <a href="https://scottaaronson.blog/?p=6823">posts</a> explaining how I part ways from the Orthodox Yudkowskyan position, I do find that position intellectually consistent, with conclusions that follow neatly from premises.  The Orthodox, in particular, can straightforwardly answer all four of my questions above:</p>



<ol>
<li>AI is manifestly different from any other technology humans have ever created, because it could become to us as we are to orangutans;</li>



<li>a six-month pause is very far from sufficient but is better than no pause;</li>



<li>we&#8217;ll know that it&#8217;s safe to scale when (and only when) we understand our AIs so deeply that we can <em>mathematically explain</em> why they won&#8217;t do anything bad; and</li>



<li>GPT-4 is <em>extremely</em> impressive&#8212;that&#8217;s why it&#8217;s so terrifying!</li>
</ol>



<p>On the other hand, I&#8217;m deeply confused by the people who signed the open letter, <em>even though they continue to downplay or even ridicule GPT&#8217;s abilities, as well as the &#8220;sensationalist&#8221; predictions of an AI apocalypse.</em>  I&#8217;d feel less confused if such people came out and argued explicitly: &#8220;yes, we should also have paused the rapid improvement of printing presses to avert Europe&#8217;s religious wars.  Yes, we should&#8217;ve paused the scaling of radio transmitters to prevent the rise of Hitler.  Yes, we should&#8217;ve paused the race for ever-faster home Internet to prevent the election of Donald Trump.  And yes, we should&#8217;ve trusted our governments to manage these pauses, to foresee brand-new technologies&#8217; likely harms and take appropriate actions to mitigate them.&#8221;</p>



<p>Absent such an argument, I come back to the question of whether generative AI <em>actually</em> poses a near-term risk that&#8217;s totally unparalleled in human history, or perhaps approximated only by the risk of nuclear weapons.  After sharing an email from his partner, Eliezer rather movingly writes:</p>



<blockquote class="wp-block-quote">
<p>When the insider conversation is about the grief of seeing your daughter lose her first tooth, and thinking she’s not going to get a chance to grow up, I believe we are past the point of playing political chess about a six-month moratorium.</p>
</blockquote>



<p>Look, I too have a 10-year-old daughter and a 6-year-old son, and I wish to see them grow up.  But the causal story that starts with a GPT-5 or GPT-4.5 training run, and ends with the sudden death of my children and of all carbon-based life, still has a few too many gaps for my aging, inadequate brain to fill in.  I can complete the story in my imagination, of course, but I could equally complete a story that starts with GPT-5 and ends with the world saved from various natural stupidities.  For better or worse, I lack the &#8220;Bayescraft&#8221; to see why the first story is <em>obviously</em> 1000x or 1,000,000x likelier than the second one.</p>



<p>But, I dunno, maybe I&#8217;m making the greatest mistake of my life?  Feel free to try convincing me that I should sign the letter.  But let&#8217;s see how polite and charitable everyone can be: hopefully a six-month moratorium won&#8217;t be needed to solve the alignment problem of the <em>Shtetl-Optimized</em> comment section.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T06:23:41Z">Thursday, March 30 2023, 06:23</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.16705'>Planar 3-way Edge Perfect Matching Leads to A Holant Dichotomy</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jin-Yi Cai, Austen Z. Fan</p><p>We prove a complexity dichotomy theorem for a class of Holant problems on
planar 3-regular bipartite graphs. The complexity dichotomy states that for
every weighted constraint function $f$ defining the problem (the weights can
even be negative), the problem is either computable in polynomial time if $f$
satisfies a tractability criterion, or \#P-hard otherwise. One particular
problem in this problem space is a long-standing open problem of Moore and
Robson on counting Cubic Planar X3C. The dichotomy resolves this problem by
showing that it is \numP-hard. Our proof relies on the machinery of signature
theory developed in the study of Holant problems. An essential ingredient in
our proof of the main dichotomy theorem is a pure graph-theoretic result:
Excepting some trivial cases, every 3-regular plane graph has a planar 3-way
edge perfect matching. The proof technique of this graph-theoretic result is a
combination of algebraic and combinatorial methods.
</p>
<p>The P-time tractability criterion of the dichotomy is explicit. Other than
the known classes of tractable constraint functions (degenerate, affine,
product type, matchgates-transformable) we also identify a new infinite set of
P-time computable planar Holant problems; however, its tractability is not by a
direct holographic transformation to matchgates, but by a combination of this
method and a global argument. The complexity dichotomy states that everything
else in this Holant class is \#P-hard.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jin-Yi Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1">Austen Z. Fan</a></p><p>We prove a complexity dichotomy theorem for a class of Holant problems on
planar 3-regular bipartite graphs. The complexity dichotomy states that for
every weighted constraint function $f$ defining the problem (the weights can
even be negative), the problem is either computable in polynomial time if $f$
satisfies a tractability criterion, or \#P-hard otherwise. One particular
problem in this problem space is a long-standing open problem of Moore and
Robson on counting Cubic Planar X3C. The dichotomy resolves this problem by
showing that it is \numP-hard. Our proof relies on the machinery of signature
theory developed in the study of Holant problems. An essential ingredient in
our proof of the main dichotomy theorem is a pure graph-theoretic result:
Excepting some trivial cases, every 3-regular plane graph has a planar 3-way
edge perfect matching. The proof technique of this graph-theoretic result is a
combination of algebraic and combinatorial methods.
</p>
<p>The P-time tractability criterion of the dichotomy is explicit. Other than
the known classes of tractable constraint functions (degenerate, affine,
product type, matchgates-transformable) we also identify a new infinite set of
P-time computable planar Holant problems; however, its tractability is not by a
direct holographic transformation to matchgates, but by a combination of this
method and a global argument. The complexity dichotomy states that everything
else in this Holant class is \#P-hard.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T00:30:00Z">Thursday, March 30 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.16303'>Constant-Hop Spanners for More Geometric Intersection Graphs, with Even Smaller Size</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Timothy M. Chan, Zhengcheng Huang</p><p>In SoCG 2022, Conroy and T\'oth presented several constructions of sparse,
low-hop spanners in geometric intersection graphs, including an $O(n\log
n)$-size 3-hop spanner for $n$ disks (or fat convex objects) in the plane, and
an $O(n\log^2 n)$-size 3-hop spanner for $n$ axis-aligned rectangles in the
plane. Their work left open two major questions: (i) can the size be made
closer to linear by allowing larger constant stretch? and (ii) can near-linear
size be achieved for more general classes of intersection graphs?
</p>
<p>We address both questions simultaneously, by presenting new constructions of
constant-hop spanners that have almost linear size and that hold for a much
larger class of intersection graphs. More precisely, we prove the existence of
an $O(1)$-hop spanner for arbitrary string graphs with $O(n\alpha_k(n))$ size
for any constant $k$, where $\alpha_k(n)$ denotes the $k$-th function in the
inverse Ackermann hierarchy. We similarly prove the existence of an $O(1)$-hop
spanner for intersection graphs of $d$-dimensional fat objects with
$O(n\alpha_k(n))$ size for any constant $k$ and $d$.
</p>
<p>We also improve on some of Conroy and T\'oth's specific previous results, in
either the number of hops or the size: we describe an $O(n\log n)$-size 2-hop
spanner for disks (or more generally objects with linear union complexity) in
the plane, and an $O(n\log n)$-size 3-hop spanner for axis-aligned rectangles
in the plane.
</p>
<p>Our proofs are all simple, using separator theorems, recursion, shifted
quadtrees, and shallow cuttings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1">Timothy M. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhengcheng Huang</a></p><p>In SoCG 2022, Conroy and T\'oth presented several constructions of sparse,
low-hop spanners in geometric intersection graphs, including an $O(n\log
n)$-size 3-hop spanner for $n$ disks (or fat convex objects) in the plane, and
an $O(n\log^2 n)$-size 3-hop spanner for $n$ axis-aligned rectangles in the
plane. Their work left open two major questions: (i) can the size be made
closer to linear by allowing larger constant stretch? and (ii) can near-linear
size be achieved for more general classes of intersection graphs?
</p>
<p>We address both questions simultaneously, by presenting new constructions of
constant-hop spanners that have almost linear size and that hold for a much
larger class of intersection graphs. More precisely, we prove the existence of
an $O(1)$-hop spanner for arbitrary string graphs with $O(n\alpha_k(n))$ size
for any constant $k$, where $\alpha_k(n)$ denotes the $k$-th function in the
inverse Ackermann hierarchy. We similarly prove the existence of an $O(1)$-hop
spanner for intersection graphs of $d$-dimensional fat objects with
$O(n\alpha_k(n))$ size for any constant $k$ and $d$.
</p>
<p>We also improve on some of Conroy and T\'oth's specific previous results, in
either the number of hops or the size: we describe an $O(n\log n)$-size 2-hop
spanner for disks (or more generally objects with linear union complexity) in
the plane, and an $O(n\log n)$-size 3-hop spanner for axis-aligned rectangles
in the plane.
</p>
<p>Our proofs are all simple, using separator theorems, recursion, shifted
quadtrees, and shallow cuttings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T00:30:00Z">Thursday, March 30 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.16716'>Topological Point Cloud Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vincent P. Grande, Michael T. Schaub</p><p>We present Topological Point Cloud Clustering (TPCC), a new method to cluster
points in an arbitrary point cloud based on their contribution to global
topological features. TPCC synthesizes desirable features from spectral
clustering and topological data analysis and is based on considering the
spectral properties of a simplicial complex associated to the considered point
cloud. As it is based on considering sparse eigenvector computations, TPCC is
similarly easy to interpret and implement as spectral clustering. However, by
focusing not just on a single matrix associated to a graph created from the
point cloud data, but on a whole set of Hodge-Laplacians associated to an
appropriately constructed simplicial complex, we can leverage a far richer set
of topological features to characterize the data points within the point cloud
and benefit from the relative robustness of topological techniques against
noise. We test the performance of TPCC on both synthetic and real-world data
and compare it with classical spectral clustering.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Grande_V/0/1/0/all/0/1">Vincent P. Grande</a>, <a href="http://arxiv.org/find/math/1/au:+Schaub_M/0/1/0/all/0/1">Michael T. Schaub</a></p><p>We present Topological Point Cloud Clustering (TPCC), a new method to cluster
points in an arbitrary point cloud based on their contribution to global
topological features. TPCC synthesizes desirable features from spectral
clustering and topological data analysis and is based on considering the
spectral properties of a simplicial complex associated to the considered point
cloud. As it is based on considering sparse eigenvector computations, TPCC is
similarly easy to interpret and implement as spectral clustering. However, by
focusing not just on a single matrix associated to a graph created from the
point cloud data, but on a whole set of Hodge-Laplacians associated to an
appropriately constructed simplicial complex, we can leverage a far richer set
of topological features to characterize the data points within the point cloud
and benefit from the relative robustness of topological techniques against
noise. We test the performance of TPCC on both synthetic and real-world data
and compare it with classical spectral clustering.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T00:30:00Z">Thursday, March 30 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.16208'>Lifting uniform learners via distributional decomposition</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Guy Blanc, Jane Lange, Ali Malik, Li-Yang Tan</p><p>We show how any PAC learning algorithm that works under the uniform
distribution can be transformed, in a blackbox fashion, into one that works
under an arbitrary and unknown distribution $\mathcal{D}$. The efficiency of
our transformation scales with the inherent complexity of $\mathcal{D}$,
running in $\mathrm{poly}(n, (md)^d)$ time for distributions over $\{\pm 1\}^n$
whose pmfs are computed by depth-$d$ decision trees, where $m$ is the sample
complexity of the original algorithm. For monotone distributions our
transformation uses only samples from $\mathcal{D}$, and for general ones it
uses subcube conditioning samples.
</p>
<p>A key technical ingredient is an algorithm which, given the aforementioned
access to $\mathcal{D}$, produces an optimal decision tree decomposition of
$\mathcal{D}$: an approximation of $\mathcal{D}$ as a mixture of uniform
distributions over disjoint subcubes. With this decomposition in hand, we run
the uniform-distribution learner on each subcube and combine the hypotheses
using the decision tree. This algorithmic decomposition lemma also yields new
algorithms for learning decision tree distributions with runtimes that
exponentially improve on the prior state of the art -- results of independent
interest in distribution learning.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Blanc_G/0/1/0/all/0/1">Guy Blanc</a>, <a href="http://arxiv.org/find/stat/1/au:+Lange_J/0/1/0/all/0/1">Jane Lange</a>, <a href="http://arxiv.org/find/stat/1/au:+Malik_A/0/1/0/all/0/1">Ali Malik</a>, <a href="http://arxiv.org/find/stat/1/au:+Tan_L/0/1/0/all/0/1">Li-Yang Tan</a></p><p>We show how any PAC learning algorithm that works under the uniform
distribution can be transformed, in a blackbox fashion, into one that works
under an arbitrary and unknown distribution $\mathcal{D}$. The efficiency of
our transformation scales with the inherent complexity of $\mathcal{D}$,
running in $\mathrm{poly}(n, (md)^d)$ time for distributions over $\{\pm 1\}^n$
whose pmfs are computed by depth-$d$ decision trees, where $m$ is the sample
complexity of the original algorithm. For monotone distributions our
transformation uses only samples from $\mathcal{D}$, and for general ones it
uses subcube conditioning samples.
</p>
<p>A key technical ingredient is an algorithm which, given the aforementioned
access to $\mathcal{D}$, produces an optimal decision tree decomposition of
$\mathcal{D}$: an approximation of $\mathcal{D}$ as a mixture of uniform
distributions over disjoint subcubes. With this decomposition in hand, we run
the uniform-distribution learner on each subcube and combine the hypotheses
using the decision tree. This algorithmic decomposition lemma also yields new
algorithms for learning decision tree distributions with runtimes that
exponentially improve on the prior state of the art -- results of independent
interest in distribution learning.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T00:30:00Z">Thursday, March 30 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.16413'>Certified Hardness vs. Randomness for Log-Space</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Edward Pyne, Ran Raz, Wei Zhan</p><p>Let $\mathcal{L}$ be a language that can be decided in linear space and let
$\epsilon &gt;0$ be any constant. Let $\mathcal{A}$ be the exponential hardness
assumption that for every $n$, membership in $\mathcal{L}$ for inputs of
length~$n$ cannot be decided by circuits of size smaller than $2^{\epsilon n}$.
We prove that for every function $f :\{0,1\}^* \rightarrow \{0,1\}$, computable
by a randomized logspace algorithm $R$, there exists a deterministic logspace
algorithm $D$ (attempting to compute $f$), such that on every input $x$ of
length $n$, the algorithm $D$ outputs one of the following:
</p>
<p>1: The correct value $f(x)$.
</p>
<p>2: The string: ``I am unable to compute $f(x)$ because the hardness
assumption $\mathcal{A}$ is false'', followed by a (provenly correct) circuit
of size smaller than $2^{\epsilon n'}$ for membership in $\mathcal{L}$ for
inputs of length~$n'$, for some $n' = \Theta (\log n)$; that is, a circuit that
refutes $\mathcal{A}$.
</p>
<p>Our next result is a universal derandomizer for $BPL$: We give a
deterministic algorithm $U$ that takes as an input a randomized logspace
algorithm $R$ and an input $x$ and simulates the computation of $R$ on $x$,
deteriministically. Under the widely believed assumption $BPL=L$, the space
used by $U$ is at most $C_R \cdot \log n$ (where $C_R$ is a constant depending
on~$R$). Moreover, for every constant $c \geq 1$, if $BPL\subseteq
SPACE[(\log(n))^{c}]$ then the space used by $U$ is at most $C_R \cdot
(\log(n))^{c}$.
</p>
<p>Finally, we prove that if optimal hitting sets for ordered branching programs
exist then there is a deterministic logspace algorithm that, given a black-box
access to an ordered branching program $B$ of size $n$, estimates the
probability that $B$ accepts on a uniformly random input. This extends the
result of (Cheng and Hoza CCC 2020), who proved that an optimal hitting set
implies a white-box two-sided derandomization.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pyne_E/0/1/0/all/0/1">Edward Pyne</a>, <a href="http://arxiv.org/find/cs/1/au:+Raz_R/0/1/0/all/0/1">Ran Raz</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1">Wei Zhan</a></p><p>Let $\mathcal{L}$ be a language that can be decided in linear space and let
$\epsilon &gt;0$ be any constant. Let $\mathcal{A}$ be the exponential hardness
assumption that for every $n$, membership in $\mathcal{L}$ for inputs of
length~$n$ cannot be decided by circuits of size smaller than $2^{\epsilon n}$.
We prove that for every function $f :\{0,1\}^* \rightarrow \{0,1\}$, computable
by a randomized logspace algorithm $R$, there exists a deterministic logspace
algorithm $D$ (attempting to compute $f$), such that on every input $x$ of
length $n$, the algorithm $D$ outputs one of the following:
</p>
<p>1: The correct value $f(x)$.
</p>
<p>2: The string: ``I am unable to compute $f(x)$ because the hardness
assumption $\mathcal{A}$ is false'', followed by a (provenly correct) circuit
of size smaller than $2^{\epsilon n'}$ for membership in $\mathcal{L}$ for
inputs of length~$n'$, for some $n' = \Theta (\log n)$; that is, a circuit that
refutes $\mathcal{A}$.
</p>
<p>Our next result is a universal derandomizer for $BPL$: We give a
deterministic algorithm $U$ that takes as an input a randomized logspace
algorithm $R$ and an input $x$ and simulates the computation of $R$ on $x$,
deteriministically. Under the widely believed assumption $BPL=L$, the space
used by $U$ is at most $C_R \cdot \log n$ (where $C_R$ is a constant depending
on~$R$). Moreover, for every constant $c \geq 1$, if $BPL\subseteq
SPACE[(\log(n))^{c}]$ then the space used by $U$ is at most $C_R \cdot
(\log(n))^{c}$.
</p>
<p>Finally, we prove that if optimal hitting sets for ordered branching programs
exist then there is a deterministic logspace algorithm that, given a black-box
access to an ordered branching program $B$ of size $n$, estimates the
probability that $B$ accepts on a uniformly random input. This extends the
result of (Cheng and Hoza CCC 2020), who proved that an optimal hitting set
implies a white-box two-sided derandomization.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T00:30:00Z">Thursday, March 30 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.16287'>Lower Bounds for Pseudo-Deterministic Counting in a Stream</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vladimir Braverman, Robert Krauthgamer, Aditya Krishnan, Shay Sapir</p><p>Many streaming algorithms provide only a high-probability relative
approximation. These two relaxations, of allowing approximation and
randomization, seem necessary -- for many streaming problems, both relaxations
must be employed simultaneously, to avoid an exponentially larger (and often
trivial) space complexity. A common drawback of these randomized approximate
algorithms is that independent executions on the same input have different
outputs, that depend on their random coins. Pseudo-deterministic algorithms
combat this issue, and for every input, they output with high probability the
same ``canonical'' solution.
</p>
<p>We consider perhaps the most basic problem in data streams, of counting the
number of items in a stream of length at most $n$. Morris's counter [CACM,
1978] is a randomized approximation algorithm for this problem that uses
$O(\log\log n)$ bits of space, for every fixed approximation factor (greater
than $1$). Goldwasser, Grossman, Mohanty and Woodruff [ITCS 2020] asked whether
pseudo-deterministic approximation algorithms can match this space complexity.
Our main result answers their question negatively, and shows that such
algorithms must use $\Omega(\sqrt{\log n / \log\log n})$ bits of space.
</p>
<p>Our approach is based on a problem that we call Shift Finding, and may be of
independent interest. In this problem, one has query access to a shifted
version of a known string $F\in\{0,1\}^{3n}$, which is guaranteed to start with
$n$ zeros and end with $n$ ones, and the goal is to find the unknown shift
using a small number of queries. We provide for this problem an algorithm that
uses $O(\sqrt{n})$ queries. It remains open whether $poly(\log n)$ queries
suffice; if true, then our techniques immediately imply a nearly-tight
$\Omega(\log n/\log\log n)$ space bound for pseudo-deterministic approximate
counting.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Krauthgamer_R/0/1/0/all/0/1">Robert Krauthgamer</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_A/0/1/0/all/0/1">Aditya Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sapir_S/0/1/0/all/0/1">Shay Sapir</a></p><p>Many streaming algorithms provide only a high-probability relative
approximation. These two relaxations, of allowing approximation and
randomization, seem necessary -- for many streaming problems, both relaxations
must be employed simultaneously, to avoid an exponentially larger (and often
trivial) space complexity. A common drawback of these randomized approximate
algorithms is that independent executions on the same input have different
outputs, that depend on their random coins. Pseudo-deterministic algorithms
combat this issue, and for every input, they output with high probability the
same ``canonical'' solution.
</p>
<p>We consider perhaps the most basic problem in data streams, of counting the
number of items in a stream of length at most $n$. Morris's counter [CACM,
1978] is a randomized approximation algorithm for this problem that uses
$O(\log\log n)$ bits of space, for every fixed approximation factor (greater
than $1$). Goldwasser, Grossman, Mohanty and Woodruff [ITCS 2020] asked whether
pseudo-deterministic approximation algorithms can match this space complexity.
Our main result answers their question negatively, and shows that such
algorithms must use $\Omega(\sqrt{\log n / \log\log n})$ bits of space.
</p>
<p>Our approach is based on a problem that we call Shift Finding, and may be of
independent interest. In this problem, one has query access to a shifted
version of a known string $F\in\{0,1\}^{3n}$, which is guaranteed to start with
$n$ zeros and end with $n$ ones, and the goal is to find the unknown shift
using a small number of queries. We provide for this problem an algorithm that
uses $O(\sqrt{n})$ queries. It remains open whether $poly(\log n)$ queries
suffice; if true, then our techniques immediately imply a nearly-tight
$\Omega(\log n/\log\log n)$ space bound for pseudo-deterministic approximate
counting.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T00:30:00Z">Thursday, March 30 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.16388'>Complexity of Equilibria in First-Price Auctions under General Tie-Breaking Rules</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xi Chen, Binghui Peng</p><p>We study the complexity of finding an approximate (pure) Bayesian Nash
equilibrium in a first-price auction with common priors when the tie-breaking
rule is part of the input. We show that the problem is PPAD-complete even when
the tie-breaking rule is trilateral (i.e., it specifies item allocations when
no more than three bidders are in tie, and adopts the uniform tie-breaking rule
otherwise). This is the first hardness result for equilibrium computation in
first-price auctions with common priors. On the positive side, we give a PTAS
for the problem under the uniform tie-breaking rule.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Binghui Peng</a></p><p>We study the complexity of finding an approximate (pure) Bayesian Nash
equilibrium in a first-price auction with common priors when the tie-breaking
rule is part of the input. We show that the problem is PPAD-complete even when
the tie-breaking rule is trilateral (i.e., it specifies item allocations when
no more than three bidders are in tie, and adopts the uniform tie-breaking rule
otherwise). This is the first hardness result for equilibrium computation in
first-price auctions with common priors. On the positive side, we give a PTAS
for the problem under the uniform tie-breaking rule.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-30T00:30:00Z">Thursday, March 30 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, March 29
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/03/alan-turing-opera.html'>Alan Turing, The Opera</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>♦&nbsp;</p>Last Thursday I attended the world premier of The Life and Death(s) of Alan Turing, a new production from Chicago Opera Theater composed by Justine Chen with the libretto (text) from David Simpatico.<p></p><p>The opera takes a mostly chronological trip through his life in seven scenes, focusing less on the computer science and more on Turing's struggle with homosexuality and his prosecution. Turing does fiddle with an old computer throughout the opera. The opera ends with a different take on his death (spoiler alert), where he attempts to upload his consciousness to escape his chemically castrated body.&nbsp;</p><p>Between the scenes, a chorus chants random numbers and words as they floated on a scrim, in what the composer calls "chat clouds".&nbsp;</p><blockquote><p>These “chat clouds” transport the listeners with a sonic approximation of internet chatter, filled with information that brings them to the next moment. The aural depiction of these "chat clouds" was inspired by the animated movies and television series of Masamune Shirow's cyberpunk manga Ghost in the Shell. Another sonic influence was Walt Disney’s fantastical Snow White, one of Alan’s greatest obsessions.</p></blockquote><p>I found them reminiscent of the Philip Glass'&nbsp;knee play&nbsp;from Einstein on the Beach. I really enjoyed these sequences, though another academic I ran into during intermission felt otherwise.</p><p>Over all I enjoyed the music and the opera, particularly the courtroom scene where Turing gave an impassioned defense though it turns out all in his head. The cast did well across the board, especially Jonathan Michie who sang Turing.&nbsp;</p>♦Librettist David Simpatico (wearing jacking), Composer Justine Chen (in gown)<br>conductor&nbsp;Lidiya Yankovskaya behind her and Jonathan Michie (in red robe)<p>One can't help compare this opera to The (R)evolution of Steve Jobs, that I&nbsp;saw in Atlanta last year. Both operas chart a metaphysical journey of a computing giant through various important moments of their lives. During a Q&amp;A I asked Simpatico about the two and he said he purposely avoided the Jobs opera so as to not affect how he wrote this one. Probably for the best.</p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEih91e9xcRo-Hr1RCp_82Gpy7YFV2sUTXy8IYTFSJ-LMZrr__CZtlFk2EHGczD2-XZdOtbkYNOC2pX_nSJqFqz6PFQTj0vNEDQMgSi02QC5vQ0gF5KnEsIXCDh4wB_NTBP2TzFdwYXCeYIoNRUDjKwYpNZpCGvTHyH8a2tW-q2Bw3F2vpMwxw/s1312/Turing.png" style="clear: right; display: inline; float: right; margin-bottom: 1em; margin-left: 1em; text-align: center;"><img border="0" data-original-height="1312" data-original-width="855" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEih91e9xcRo-Hr1RCp_82Gpy7YFV2sUTXy8IYTFSJ-LMZrr__CZtlFk2EHGczD2-XZdOtbkYNOC2pX_nSJqFqz6PFQTj0vNEDQMgSi02QC5vQ0gF5KnEsIXCDh4wB_NTBP2TzFdwYXCeYIoNRUDjKwYpNZpCGvTHyH8a2tW-q2Bw3F2vpMwxw/w210-h320/Turing.png" width="210" /></a>&nbsp;</p>Last Thursday I attended the world premier of <a href="https://chicagooperatheater.org/season/turing">The Life and Death(s) of Alan Turing</a>, a new production from Chicago Opera Theater composed by Justine Chen with the libretto (text) from David Simpatico.<p></p><p>The opera takes a mostly chronological trip through his life in seven scenes, focusing less on the computer science and more on Turing's struggle with homosexuality and his prosecution. Turing does fiddle with an old computer throughout the opera. The opera ends with a different take on his death (spoiler alert), where he attempts to upload his consciousness to escape his chemically castrated body.&nbsp;</p><p>Between the scenes, a chorus chants random numbers and words as they floated on a scrim, in what the composer calls "chat clouds".&nbsp;</p><blockquote><p>These “chat clouds” transport the listeners with a sonic approximation of internet chatter, filled with information that brings them to the next moment. The aural depiction of these "chat clouds" was inspired by the animated movies and television series of Masamune Shirow's cyberpunk manga Ghost in the Shell. Another sonic influence was Walt Disney’s fantastical Snow White, one of Alan’s greatest obsessions.</p></blockquote><p>I found them reminiscent of the Philip Glass'&nbsp;<a href="https://www.youtube.com/watch?v=9YRzS9y-8S8">knee play</a>&nbsp;from Einstein on the Beach. I really enjoyed these sequences, though another academic I ran into during intermission felt otherwise.</p><p>Over all I enjoyed the music and the opera, particularly the courtroom scene where Turing gave an impassioned defense though it turns out all in his head. The cast did well across the board, especially Jonathan Michie who sang Turing.&nbsp;</p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgTEyFR4Sjvw7Ew4ip5OXdi6Q0Q3iJLmzZg7P0jknvTJjHgVdUj7f_XtvW16CiHsbDu8pJxL8QVKurCOc3crdwE03zcWzfh0FF1SLPBGUBqqunj_GAUmmcGnoQKHr2b-QPI5X2fafywY1UrVIEXQBHJGxChdL699rjzysU0OgQbQvY1tuJnDg/s1954/PXL_20230324_024100463.jpg" style="margin-left: auto; margin-right: auto;"><img border="0" data-original-height="769" data-original-width="1954" height="158" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgTEyFR4Sjvw7Ew4ip5OXdi6Q0Q3iJLmzZg7P0jknvTJjHgVdUj7f_XtvW16CiHsbDu8pJxL8QVKurCOc3crdwE03zcWzfh0FF1SLPBGUBqqunj_GAUmmcGnoQKHr2b-QPI5X2fafywY1UrVIEXQBHJGxChdL699rjzysU0OgQbQvY1tuJnDg/w400-h158/PXL_20230324_024100463.jpg" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Librettist David Simpatico (wearing jacking), Composer Justine Chen (in gown)<br />conductor&nbsp;Lidiya Yankovskaya behind her and Jonathan Michie (in red robe)</td></tr></tbody></table><p>One can't help compare this opera to <a href="https://en.wikipedia.org/wiki/The_(R)evolution_of_Steve_Jobs">The (R)evolution of Steve Jobs</a>, that I&nbsp;<a href="https://blog.computationalcomplexity.org/2022/05/the-revolution-of-steve-jobs.html">saw in Atlanta</a> last year. Both operas chart a metaphysical journey of a computing giant through various important moments of their lives. During a Q&amp;A I asked Simpatico about the two and he said he purposely avoided the Jobs opera so as to not affect how he wrote this one. Probably for the best.</p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T15:29:00Z">Wednesday, March 29 2023, 15:29</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.15556'>Complexity of Reconfiguration in Surface Chemical Reaction Networks</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Robert M. Alaniz, Josh Brunner, Michael Coulombe, Erik D. Demaine, Yevhenii Diomidov, Ryan Knobel, Timothy Gomez, Elise Grizzell, Jayson Lynch, Andrew Rodriguez, Robert Schweller, Tim Wylie</p><p>We analyze the computational complexity of basic reconfiguration problems for
the recently introduced surface Chemical Reaction Networks (sCRNs), where
ordered pairs of adjacent species nondeterministically transform into a
different ordered pair of species according to a predefined set of allowed
transition rules (chemical reactions). In particular, two questions that are
fundamental to the simulation of sCRNs are whether a given configuration of
molecules can ever transform into another given configuration, and whether a
given cell can ever contain a given species, given a set of transition rules.
We show that these problems can be solved in polynomial time, are NP-complete,
or are PSPACE-complete in a variety of different settings, including when
adjacent species just swap instead of arbitrary transformation (swap sCRNs),
and when cells can change species a limited number of times (k-burnout). Most
problems turn out to be at least NP-hard except with very few distinct species
(2 or 3).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Alaniz_R/0/1/0/all/0/1">Robert M. Alaniz</a>, <a href="http://arxiv.org/find/cs/1/au:+Brunner_J/0/1/0/all/0/1">Josh Brunner</a>, <a href="http://arxiv.org/find/cs/1/au:+Coulombe_M/0/1/0/all/0/1">Michael Coulombe</a>, <a href="http://arxiv.org/find/cs/1/au:+Demaine_E/0/1/0/all/0/1">Erik D. Demaine</a>, <a href="http://arxiv.org/find/cs/1/au:+Diomidov_Y/0/1/0/all/0/1">Yevhenii Diomidov</a>, <a href="http://arxiv.org/find/cs/1/au:+Knobel_R/0/1/0/all/0/1">Ryan Knobel</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_T/0/1/0/all/0/1">Timothy Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Grizzell_E/0/1/0/all/0/1">Elise Grizzell</a>, <a href="http://arxiv.org/find/cs/1/au:+Lynch_J/0/1/0/all/0/1">Jayson Lynch</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1">Andrew Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Schweller_R/0/1/0/all/0/1">Robert Schweller</a>, <a href="http://arxiv.org/find/cs/1/au:+Wylie_T/0/1/0/all/0/1">Tim Wylie</a></p><p>We analyze the computational complexity of basic reconfiguration problems for
the recently introduced surface Chemical Reaction Networks (sCRNs), where
ordered pairs of adjacent species nondeterministically transform into a
different ordered pair of species according to a predefined set of allowed
transition rules (chemical reactions). In particular, two questions that are
fundamental to the simulation of sCRNs are whether a given configuration of
molecules can ever transform into another given configuration, and whether a
given cell can ever contain a given species, given a set of transition rules.
We show that these problems can be solved in polynomial time, are NP-complete,
or are PSPACE-complete in a variety of different settings, including when
adjacent species just swap instead of arbitrary transformation (swap sCRNs),
and when cells can change species a limited number of times (k-burnout). Most
problems turn out to be at least NP-hard except with very few distinct species
(2 or 3).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T00:30:00Z">Wednesday, March 29 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.15610'>Towards Crossing-Free Hamiltonian Cycles in Simple Drawings of Complete Graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Oswin Aichholzer, Joachim Orthaber, Birgit Vogtenhuber</p><p>It is a longstanding conjecture that every simple drawing of a complete graph
on $n\geq 3$ vertices contains a crossing-free Hamiltonian cycle. We confirm
this conjecture for cylindrical drawings, strongly $c$-monotone drawings, as
well as $x$-bounded drawings. Moreover, we introduce the stronger question of
whether a crossing-free Hamiltonian path between each pair of vertices always
exists.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Aichholzer_O/0/1/0/all/0/1">Oswin Aichholzer</a>, <a href="http://arxiv.org/find/math/1/au:+Orthaber_J/0/1/0/all/0/1">Joachim Orthaber</a>, <a href="http://arxiv.org/find/math/1/au:+Vogtenhuber_B/0/1/0/all/0/1">Birgit Vogtenhuber</a></p><p>It is a longstanding conjecture that every simple drawing of a complete graph
on $n\geq 3$ vertices contains a crossing-free Hamiltonian cycle. We confirm
this conjecture for cylindrical drawings, strongly $c$-monotone drawings, as
well as $x$-bounded drawings. Moreover, we introduce the stronger question of
whether a crossing-free Hamiltonian path between each pair of vertices always
exists.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T00:30:00Z">Wednesday, March 29 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.15945'>Online embedding of metrics</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ilan Newman, Yuri Rabinovich</p><p>We study deterministic online embeddings of metrics spaces into normed spaces
and into trees against an adaptive adversary. Main results include a polynomial
lower bound on the (multiplicative) distortion of embedding into Euclidean
spaces, a tight exponential upper bound on embedding into the line, and a
$(1+\epsilon)$-distortion embedding in $\ell_\infty$ of a suitably high
dimension.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Newman_I/0/1/0/all/0/1">Ilan Newman</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabinovich_Y/0/1/0/all/0/1">Yuri Rabinovich</a></p><p>We study deterministic online embeddings of metrics spaces into normed spaces
and into trees against an adaptive adversary. Main results include a polynomial
lower bound on the (multiplicative) distortion of embedding into Euclidean
spaces, a tight exponential upper bound on embedding into the line, and a
$(1+\epsilon)$-distortion embedding in $\ell_\infty$ of a suitably high
dimension.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T00:30:00Z">Wednesday, March 29 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.15550'>Randomized rounding algorithms for large scale unsplittable flow problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fran&#xe7;ois Lamothe, Emmanuel Rachelson, Alain Ha&#xef;t, Cedric Baudoin, Jean-Baptiste Dupe</p><p>Unsplittable flow problems cover a wide range of telecommunication and
transportation problems and their efficient resolution is key to a number of
applications. In this work, we study algorithms that can scale up to large
graphs and important numbers of commodities. We present and analyze in detail a
heuristic based on the linear relaxation of the problem and randomized
rounding. We provide empirical evidence that this approach is competitive with
state-of-the-art resolution methods either by its scaling performance or by the
quality of its solutions. We provide a variation of the heuristic which has the
same approximation factor as the state-of-the-art approximation algorithm. We
also derive a tighter analysis for the approximation factor of both the
variation and the state-of-the-art algorithm. We introduce a new objective
function for the unsplittable flow problem and discuss its differences with the
classical congestion objective function. Finally, we discuss the gap in
practical performance and theoretical guarantees between all the aforementioned
algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lamothe_F/0/1/0/all/0/1">Fran&#xe7;ois Lamothe</a>, <a href="http://arxiv.org/find/cs/1/au:+Rachelson_E/0/1/0/all/0/1">Emmanuel Rachelson</a>, <a href="http://arxiv.org/find/cs/1/au:+Hait_A/0/1/0/all/0/1">Alain Ha&#xef;t</a>, <a href="http://arxiv.org/find/cs/1/au:+Baudoin_C/0/1/0/all/0/1">Cedric Baudoin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dupe_J/0/1/0/all/0/1">Jean-Baptiste Dupe</a></p><p>Unsplittable flow problems cover a wide range of telecommunication and
transportation problems and their efficient resolution is key to a number of
applications. In this work, we study algorithms that can scale up to large
graphs and important numbers of commodities. We present and analyze in detail a
heuristic based on the linear relaxation of the problem and randomized
rounding. We provide empirical evidence that this approach is competitive with
state-of-the-art resolution methods either by its scaling performance or by the
quality of its solutions. We provide a variation of the heuristic which has the
same approximation factor as the state-of-the-art approximation algorithm. We
also derive a tighter analysis for the approximation factor of both the
variation and the state-of-the-art algorithm. We introduce a new objective
function for the unsplittable flow problem and discuss its differences with the
classical congestion objective function. Finally, we discuss the gap in
practical performance and theoretical guarantees between all the aforementioned
algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T00:30:00Z">Wednesday, March 29 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.15594'>On de novo Bridging Paired-end RNA-seq Data</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Xiang Li, Mingfu Shao</p><p>The high-throughput short-reads RNA-seq protocols often produce paired-end
reads, with the middle portion of the fragments being unsequenced. We explore
if the full-length fragments can be computationally reconstructed from the
sequenced two ends in the absence of the reference genome - a problem here we
refer to as de novo bridging. Solving this problem provides longer, more
informative RNA-seq reads, and benefits downstream RNA-seq analysis such as
transcript assembly, expression quantification, and splicing differential
analysis. However, de novo bridging is a challenging and complicated task owing
to alternative splicing, transcript noises, and sequencing errors. It remains
unclear if the data provides sufficient information for accurate bridging, let
alone efficient algorithms that determine the true bridges. Methods have been
proposed to bridge paired-end reads in the presence of reference genome (called
reference-based bridging), but the algorithms are far away from scaling for de
novo bridging as the underlying compacted de Bruijn graph(cdBG) used in the
latter task often contains millions of vertices and edges. We designed a new
truncated Dijkstra's algorithm for this problem, and proposed a novel algorithm
that reuses the shortest path tree to avoid running the truncated Dijkstra's
algorithm from scratch for all vertices for further speeding up. These
innovative techniques result in scalable algorithms that can bridge all
paired-end reads in a cdBG with millions of vertices. Our experiments showed
that paired-end RNA-seq reads can be accurately bridged to a large extent. The
resulting tool is freely available at
github.com/Shao-Group/rnabridge-denovo.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/q-bio/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Shao_M/0/1/0/all/0/1">Mingfu Shao</a></p><p>The high-throughput short-reads RNA-seq protocols often produce paired-end
reads, with the middle portion of the fragments being unsequenced. We explore
if the full-length fragments can be computationally reconstructed from the
sequenced two ends in the absence of the reference genome - a problem here we
refer to as de novo bridging. Solving this problem provides longer, more
informative RNA-seq reads, and benefits downstream RNA-seq analysis such as
transcript assembly, expression quantification, and splicing differential
analysis. However, de novo bridging is a challenging and complicated task owing
to alternative splicing, transcript noises, and sequencing errors. It remains
unclear if the data provides sufficient information for accurate bridging, let
alone efficient algorithms that determine the true bridges. Methods have been
proposed to bridge paired-end reads in the presence of reference genome (called
reference-based bridging), but the algorithms are far away from scaling for de
novo bridging as the underlying compacted de Bruijn graph(cdBG) used in the
latter task often contains millions of vertices and edges. We designed a new
truncated Dijkstra's algorithm for this problem, and proposed a novel algorithm
that reuses the shortest path tree to avoid running the truncated Dijkstra's
algorithm from scratch for all vertices for further speeding up. These
innovative techniques result in scalable algorithms that can bridge all
paired-end reads in a cdBG with millions of vertices. Our experiments showed
that paired-end RNA-seq reads can be accurately bridged to a large extent. The
resulting tool is freely available at
https://github.com/Shao-Group/rnabridge-denovo.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T00:30:00Z">Wednesday, March 29 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.15608'>Overcoming Probabilistic Faults in Disoriented Linear Search</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Konstantinos Georgiou, Nikos Giachoudis, Evangelos Kranakis</p><p>We consider search by mobile agents for a hidden, idle target, placed on the
infinite line. Feasible solutions are agent trajectories in which all agents
reach the target sooner or later. A special feature of our problem is that the
agents are $p$-faulty, meaning that every attempt to change direction is an
independent Bernoulli trial with known probability $p$, where $p$ is the
probability that a turn fails. We are looking for agent trajectories that
minimize the worst-case expected termination time, relative to competitive
analysis.
</p>
<p>First, we study linear search with one deterministic $p$-faulty agent, i.e.,
with no access to random oracles, $p\in (0,1/2)$. For this problem, we provide
trajectories that leverage the probabilistic faults into an algorithmic
advantage. Our strongest result pertains to a search algorithm (deterministic,
aside from the adversarial probabilistic faults) which, as $p\to 0$, has
optimal performance $4.59112+\epsilon$, up to the additive term $\epsilon$ that
can be arbitrarily small. Additionally, it has performance less than $9$ for
$p\leq 0.390388$. When $p\to 1/2$, our algorithm has performance
$\Theta(1/(1-2p))$, which we also show is optimal up to a constant factor.
</p>
<p>Second, we consider linear search with two $p$-faulty agents, $p\in (0,1/2)$,
for which we provide three algorithms of different advantages, all with a
bounded competitive ratio even as $p\rightarrow 1/2$. Indeed, for this problem,
we show how the agents can simulate the trajectory of any $0$-faulty agent
(deterministic or randomized), independently of the underlying communication
model. As a result, searching with two agents allows for a solution with a
competitive ratio of $9+\epsilon$, or a competitive ratio of
$4.59112+\epsilon$. Our final contribution is a novel algorithm for searching
with two $p$-faulty agents that achieves a competitive ratio
$3+4\sqrt{p(1-p)}$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Georgiou_K/0/1/0/all/0/1">Konstantinos Georgiou</a>, <a href="http://arxiv.org/find/cs/1/au:+Giachoudis_N/0/1/0/all/0/1">Nikos Giachoudis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kranakis_E/0/1/0/all/0/1">Evangelos Kranakis</a></p><p>We consider search by mobile agents for a hidden, idle target, placed on the
infinite line. Feasible solutions are agent trajectories in which all agents
reach the target sooner or later. A special feature of our problem is that the
agents are $p$-faulty, meaning that every attempt to change direction is an
independent Bernoulli trial with known probability $p$, where $p$ is the
probability that a turn fails. We are looking for agent trajectories that
minimize the worst-case expected termination time, relative to competitive
analysis.
</p>
<p>First, we study linear search with one deterministic $p$-faulty agent, i.e.,
with no access to random oracles, $p\in (0,1/2)$. For this problem, we provide
trajectories that leverage the probabilistic faults into an algorithmic
advantage. Our strongest result pertains to a search algorithm (deterministic,
aside from the adversarial probabilistic faults) which, as $p\to 0$, has
optimal performance $4.59112+\epsilon$, up to the additive term $\epsilon$ that
can be arbitrarily small. Additionally, it has performance less than $9$ for
$p\leq 0.390388$. When $p\to 1/2$, our algorithm has performance
$\Theta(1/(1-2p))$, which we also show is optimal up to a constant factor.
</p>
<p>Second, we consider linear search with two $p$-faulty agents, $p\in (0,1/2)$,
for which we provide three algorithms of different advantages, all with a
bounded competitive ratio even as $p\rightarrow 1/2$. Indeed, for this problem,
we show how the agents can simulate the trajectory of any $0$-faulty agent
(deterministic or randomized), independently of the underlying communication
model. As a result, searching with two agents allows for a solution with a
competitive ratio of $9+\epsilon$, or a competitive ratio of
$4.59112+\epsilon$. Our final contribution is a novel algorithm for searching
with two $p$-faulty agents that achieves a competitive ratio
$3+4\sqrt{p(1-p)}$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T00:30:00Z">Wednesday, March 29 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.15652'>Structured Dynamic Pricing: Optimal Regret in a Global Shrinkage Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rashmi Ranjan Bhuyan, Adel Javanmard, Sungchul Kim, Gourab Mukherjee, Ryan A. Rossi, Tong Yu, Handong Zhao</p><p>We consider dynamic pricing strategies in a streamed longitudinal data set-up
where the objective is to maximize, over time, the cumulative profit across a
large number of customer segments. We consider a dynamic probit model with the
consumers' preferences as well as price sensitivity varying over time. Building
on the well-known finding that consumers sharing similar characteristics act in
similar ways, we consider a global shrinkage structure, which assumes that the
consumers' preferences across the different segments can be well approximated
by a spatial autoregressive (SAR) model. In such a streamed longitudinal
set-up, we measure the performance of a dynamic pricing policy via regret,
which is the expected revenue loss compared to a clairvoyant that knows the
sequence of model parameters in advance. We propose a pricing policy based on
penalized stochastic gradient descent (PSGD) and explicitly characterize its
regret as functions of time, the temporal variability in the model parameters
as well as the strength of the auto-correlation network structure spanning the
varied customer segments. Our regret analysis results not only demonstrate
asymptotic optimality of the proposed policy but also show that for policy
planning it is essential to incorporate available structural information as
policies based on unshrunken models are highly sub-optimal in the
aforementioned set-up.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bhuyan_R/0/1/0/all/0/1">Rashmi Ranjan Bhuyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Javanmard_A/0/1/0/all/0/1">Adel Javanmard</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sungchul Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_G/0/1/0/all/0/1">Gourab Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1">Ryan A. Rossi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1">Tong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Handong Zhao</a></p><p>We consider dynamic pricing strategies in a streamed longitudinal data set-up
where the objective is to maximize, over time, the cumulative profit across a
large number of customer segments. We consider a dynamic probit model with the
consumers' preferences as well as price sensitivity varying over time. Building
on the well-known finding that consumers sharing similar characteristics act in
similar ways, we consider a global shrinkage structure, which assumes that the
consumers' preferences across the different segments can be well approximated
by a spatial autoregressive (SAR) model. In such a streamed longitudinal
set-up, we measure the performance of a dynamic pricing policy via regret,
which is the expected revenue loss compared to a clairvoyant that knows the
sequence of model parameters in advance. We propose a pricing policy based on
penalized stochastic gradient descent (PSGD) and explicitly characterize its
regret as functions of time, the temporal variability in the model parameters
as well as the strength of the auto-correlation network structure spanning the
varied customer segments. Our regret analysis results not only demonstrate
asymptotic optimality of the proposed policy but also show that for policy
planning it is essential to incorporate available structural information as
policies based on unshrunken models are highly sub-optimal in the
aforementioned set-up.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T00:30:00Z">Wednesday, March 29 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.15873'>Algorithms for subgraph complementation to some classes of graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dhanyamol Antony, Sagartanu Pal, R.B. Sandeep</p><p>For a class $\mathcal{G}$ of graphs, the objective of \textsc{Subgraph
Complementation to} $\mathcal{G}$ is to find whether there exists a subset $S$
of vertices of the input graph $G$ such that modifying $G$ by complementing the
subgraph induced by $S$ results in a graph in $\mathcal{G}$. We obtain a
polynomial-time algorithm for the problem when $\mathcal{G}$ is the class of
graphs with minimum degree at least $k$, for a constant $k$, answering an open
problem by Fomin et al. (Algorithmica, 2020). When $\mathcal{G}$ is the class
of graphs without any induced copies of the star graph on $t+1$ vertices (for
any constant $t\geq 3$) and diamond, we obtain a polynomial-time algorithm for
the problem. This is in contrast with a result by Antony et al. (Algorithmica,
2022) that the problem is NP-complete and cannot be solved in
subexponential-time (assuming the Exponential Time Hypothesis) when
$\mathcal{G}$ is the class of graphs without any induced copies of the star
graph on $t+1$ vertices, for every constant $t\geq 5$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Antony_D/0/1/0/all/0/1">Dhanyamol Antony</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1">Sagartanu Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandeep_R/0/1/0/all/0/1">R.B. Sandeep</a></p><p>For a class $\mathcal{G}$ of graphs, the objective of \textsc{Subgraph
Complementation to} $\mathcal{G}$ is to find whether there exists a subset $S$
of vertices of the input graph $G$ such that modifying $G$ by complementing the
subgraph induced by $S$ results in a graph in $\mathcal{G}$. We obtain a
polynomial-time algorithm for the problem when $\mathcal{G}$ is the class of
graphs with minimum degree at least $k$, for a constant $k$, answering an open
problem by Fomin et al. (Algorithmica, 2020). When $\mathcal{G}$ is the class
of graphs without any induced copies of the star graph on $t+1$ vertices (for
any constant $t\geq 3$) and diamond, we obtain a polynomial-time algorithm for
the problem. This is in contrast with a result by Antony et al. (Algorithmica,
2022) that the problem is NP-complete and cannot be solved in
subexponential-time (assuming the Exponential Time Hypothesis) when
$\mathcal{G}$ is the class of graphs without any induced copies of the star
graph on $t+1$ vertices, for every constant $t\geq 5$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T00:30:00Z">Wednesday, March 29 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.16043'>Faster Deterministic Distributed MIS and Approximate Matching</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohsen Ghaffari, Christoph Grunau</p><p>$ \renewcommand{\tilde}{\widetilde} $We present an $\tilde{O}(\log^2 n)$
round deterministic distributed algorithm for the maximal independent set
problem. By known reductions, this round complexity extends also to maximal
matching, $\Delta+1$ vertex coloring, and $2\Delta-1$ edge coloring. These four
problems are among the most central problems in distributed graph algorithms
and have been studied extensively for the past four decades. This improved
round complexity comes closer to the $\tilde{\Omega}(\log n)$ lower bound of
maximal independent set and maximal matching [Balliu et al. FOCS '19]. The
previous best known deterministic complexity for all of these problems was
$\Theta(\log^3 n)$. Via the shattering technique, the improvement permeates
also to the corresponding randomized complexities, e.g., the new randomized
complexity of $\Delta+1$ vertex coloring is now $\tilde{O}(\log^2\log n)$
rounds.
</p>
<p>Our approach is a novel combination of the previously known two methods for
developing deterministic algorithms for these problems, namely global
derandomization via network decomposition (see e.g., [Rozhon, Ghaffari STOC'20;
Ghaffari, Grunau, Rozhon SODA'21; Ghaffari et al. SODA'23]) and local rounding
of fractional solutions (see e.g., [Fischer DISC'17; Harris FOCS'19; Fischer,
Ghaffari, Kuhn FOCS'17; Ghaffari, Kuhn FOCS'21; Faour et al. SODA'23]). We
consider a relaxation of the classic network decomposition concept, where
instead of requiring the clusters in the same block to be non-adjacent, we
allow each node to have a small number of neighboring clusters. We also show a
deterministic algorithm that computes this relaxed decomposition faster than
standard decompositions. We then use this relaxed decomposition to
significantly improve the integrality of certain fractional solutions, before
handing them to the local rounding procedure that now has to do fewer rounding
steps.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1">Christoph Grunau</a></p><p>$ \renewcommand{\tilde}{\widetilde} $We present an $\tilde{O}(\log^2 n)$
round deterministic distributed algorithm for the maximal independent set
problem. By known reductions, this round complexity extends also to maximal
matching, $\Delta+1$ vertex coloring, and $2\Delta-1$ edge coloring. These four
problems are among the most central problems in distributed graph algorithms
and have been studied extensively for the past four decades. This improved
round complexity comes closer to the $\tilde{\Omega}(\log n)$ lower bound of
maximal independent set and maximal matching [Balliu et al. FOCS '19]. The
previous best known deterministic complexity for all of these problems was
$\Theta(\log^3 n)$. Via the shattering technique, the improvement permeates
also to the corresponding randomized complexities, e.g., the new randomized
complexity of $\Delta+1$ vertex coloring is now $\tilde{O}(\log^2\log n)$
rounds.
</p>
<p>Our approach is a novel combination of the previously known two methods for
developing deterministic algorithms for these problems, namely global
derandomization via network decomposition (see e.g., [Rozhon, Ghaffari STOC'20;
Ghaffari, Grunau, Rozhon SODA'21; Ghaffari et al. SODA'23]) and local rounding
of fractional solutions (see e.g., [Fischer DISC'17; Harris FOCS'19; Fischer,
Ghaffari, Kuhn FOCS'17; Ghaffari, Kuhn FOCS'21; Faour et al. SODA'23]). We
consider a relaxation of the classic network decomposition concept, where
instead of requiring the clusters in the same block to be non-adjacent, we
allow each node to have a small number of neighboring clusters. We also show a
deterministic algorithm that computes this relaxed decomposition faster than
standard decompositions. We then use this relaxed decomposition to
significantly improve the integrality of certain fractional solutions, before
handing them to the local rounding procedure that now has to do fewer rounding
steps.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T00:30:00Z">Wednesday, March 29 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.16180'>Universal Coating in the 3D Hybrid Model</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Irina Kostitsyna, David Liedtke, Christian Scheideler</p><p>Motivated by the prospect of nano-robots that assist human physiological
functions at the nanoscale, we investigate the coating problem in the
three-dimensional model for hybrid programmable matter. In this model, a single
agent with strictly limited viewing range and the computational capability of a
deterministic finite automaton can act on passive tiles by picking up a tile,
moving, and placing it at some spot. The goal of the coating problem is to fill
each node of some surface graph of size $n$ with a tile. We first solve the
problem on a restricted class of graphs with a single tile type, and then use
constantly many tile types to encode this graph in certain surface graphs
capturing the surface of 3D objects. Our algorithm requires $\mathcal{O}(n^2)$
steps, which is worst-case optimal compared to an agent with global knowledge
and no memory restrictions.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kostitsyna_I/0/1/0/all/0/1">Irina Kostitsyna</a>, <a href="http://arxiv.org/find/cs/1/au:+Liedtke_D/0/1/0/all/0/1">David Liedtke</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheideler_C/0/1/0/all/0/1">Christian Scheideler</a></p><p>Motivated by the prospect of nano-robots that assist human physiological
functions at the nanoscale, we investigate the coating problem in the
three-dimensional model for hybrid programmable matter. In this model, a single
agent with strictly limited viewing range and the computational capability of a
deterministic finite automaton can act on passive tiles by picking up a tile,
moving, and placing it at some spot. The goal of the coating problem is to fill
each node of some surface graph of size $n$ with a tile. We first solve the
problem on a restricted class of graphs with a single tile type, and then use
constantly many tile types to encode this graph in certain surface graphs
capturing the surface of 3D objects. Our algorithm requires $\mathcal{O}(n^2)$
steps, which is worst-case optimal compared to an agent with global knowledge
and no memory restrictions.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-29T00:30:00Z">Wednesday, March 29 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, March 28
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7170'>An unexpected democracy slogan</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          At least six readers have by now sent me the following photo, which was taken in Israel a couple nights ago during the historic street protests against Netanyahu&#8217;s attempted putsch: (Update: The photo was also featured on Gil Kalai&#8217;s blog, and was credited there to Alon Rosen.) This is surely the first time that &#8220;P=NP&#8221; [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>At least six readers have by now sent me the following photo, which was taken in Israel a couple nights ago during the historic street protests against Netanyahu&#8217;s attempted <em>putsch</em>:</p>



<figure class="wp-block-image size-large"><img decoding="async" src="https://www.scottaaronson.com/pnp.jpg" alt=""/></figure>



<p>(<strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Update:</mark></strong> The photo was also featured on <a href="https://gilkalai.wordpress.com/2023/03/27/critical-times-in-israel-last-nights-demonstrations/">Gil Kalai&#8217;s blog</a>, and was credited there to Alon Rosen.)</p>



<p>This is surely the first time that &#8220;P=NP&#8221; has emerged as a viral rallying cry for the preservation of liberal democracy, even to whatever limited extent it has.</p>



<p>But what was the graffiti artist&#8217;s intended meaning?  A few possibilities:</p>



<ol>
<li>The government has flouted so many rules of Israel&#8217;s social compact that our side needs to flout the rules too: shut down the universities, shut down the airport, block the roads, <em>even assert that P=NP (!)</em>.</li>



<li>As a protest movement up against overwhelming odds, we need to shoot for the possibly-impossible, like solving 3SAT in polynomial time.</li>



<li>A shibboleth for scientific literate people following the news: &#8220;Israel is full of sane people who know what &#8216;P=NP&#8217; means as you know what it means, are amused by its use as political graffiti as you&#8217;d be amused by it, and oppose Netanyahu&#8217;s <em>putsch</em> for the same reasons you&#8217;d oppose it.&#8221;</li>



<li>No meaning, the artist was just amusing himself or herself.</li>



<li>The artist reads <em>Shtetl-Optimized</em> and wanted effectively to force me to feature his or her work here.</li>
</ol>



<p>Anyway, if the artist becomes aware of this post, he or she is warmly welcomed to clear things up for us.</p>



<p>And when this fight resumes after Passover, may those standing up for the checks and balances of a liberal-democratic society achieve &#8230; err &#8230; satisfaction, however exponentially unlikely it seems.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T20:27:28Z">Tuesday, March 28 2023, 20:27</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/040'>TR23-040 |  Certified Hardness vs. Randomness for Log-Space | 

	Edward Pyne, 

	Wei Zhan, 

	Ran Raz</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Let $\mathcal{L}$ be a language that can be decided in linear space and let $\epsilon &gt;0$ be any constant. Let $\mathcal{A}$ be the exponential hardness assumption that for every $n$, membership in $\mathcal{L}$ for inputs of length~$n$ cannot be decided by circuits of size smaller than $2^{\epsilon n}$. 
We prove that for every function $f :\{0,1\}^* \rightarrow \{0,1\}$, computable by a randomized logspace algorithm $R$, there exists a deterministic logspace algorithm $D$ (attempting to compute $f$), such that on every input $x$ of length $n$, the algorithm $D$ outputs one of the following:

1: The correct value $f(x)$.

2: The string: ``I am unable to compute $f(x)$ because the hardness assumption $\mathcal{A}$ is false&#39;&#39;, followed by a (provenly correct) circuit of size smaller than $2^{\epsilon n&#39;}$ for membership in $\mathcal{L}$ for inputs of length~$n&#39;$, for some $n&#39; = \Theta (\log n)$; that is, a circuit that refutes $\mathcal{A}$.

Moreover, $D$ is explicitly constructed, given $R$.

We note that previous works on the hardness-versus-randomness paradigm give derandomized algorithms that rely blindly on the hardness assumption. If the hardness assumption is false, the algorithms may output incorrect values, and thus a user cannot trust that an output given by the algorithm is correct. Instead, our algorithm $D$ verifies the computation so that it never outputs an incorrect value. Thus, if $D$ outputs a value for $f(x)$, that value is certified to be correct. Moreover, if $D$ does not output a value for $f(x)$, it alerts that the hardness assumption was found to be false, and refutes the assumption.

Our next result is a universal derandomizer for $BPL$ (the class of problems solvable by bounded-error randomized logspace algorithms): We give a deterministic algorithm $U$ that takes as an input a randomized logspace algorithm $R$ and an input $x$ and simulates the computation of $R$ on $x$, deteriministically. Under the widely believed assumption $BPL=L$, the space used by $U$ is at most $C_R \cdot \log n$ (where $C_R$ is a constant depending on~$R$). Moreover, for every constant $c \geq 1$, if $BPL\subseteq SPACE[(\log(n))^{c}]$ then the space used by $U$ is at most $C_R  \cdot (\log(n))^{c}$.

Finally, we prove that if optimal hitting sets for ordered branching programs exist then there is a deterministic logspace algorithm that, given a black-box access to an ordered branching program $B$ of size $n$, estimates the probability that $B$ accepts on a uniformly random input. This extends the result of (Cheng and Hoza CCC 2020), who proved that an optimal hitting set implies a white-box two-sided derandomization.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Let $\mathcal{L}$ be a language that can be decided in linear space and let $\epsilon &gt;0$ be any constant. Let $\mathcal{A}$ be the exponential hardness assumption that for every $n$, membership in $\mathcal{L}$ for inputs of length~$n$ cannot be decided by circuits of size smaller than $2^{\epsilon n}$. 
We prove that for every function $f :\{0,1\}^* \rightarrow \{0,1\}$, computable by a randomized logspace algorithm $R$, there exists a deterministic logspace algorithm $D$ (attempting to compute $f$), such that on every input $x$ of length $n$, the algorithm $D$ outputs one of the following:

1: The correct value $f(x)$.

2: The string: ``I am unable to compute $f(x)$ because the hardness assumption $\mathcal{A}$ is false&#39;&#39;, followed by a (provenly correct) circuit of size smaller than $2^{\epsilon n&#39;}$ for membership in $\mathcal{L}$ for inputs of length~$n&#39;$, for some $n&#39; = \Theta (\log n)$; that is, a circuit that refutes $\mathcal{A}$.

Moreover, $D$ is explicitly constructed, given $R$.

We note that previous works on the hardness-versus-randomness paradigm give derandomized algorithms that rely blindly on the hardness assumption. If the hardness assumption is false, the algorithms may output incorrect values, and thus a user cannot trust that an output given by the algorithm is correct. Instead, our algorithm $D$ verifies the computation so that it never outputs an incorrect value. Thus, if $D$ outputs a value for $f(x)$, that value is certified to be correct. Moreover, if $D$ does not output a value for $f(x)$, it alerts that the hardness assumption was found to be false, and refutes the assumption.

Our next result is a universal derandomizer for $BPL$ (the class of problems solvable by bounded-error randomized logspace algorithms): We give a deterministic algorithm $U$ that takes as an input a randomized logspace algorithm $R$ and an input $x$ and simulates the computation of $R$ on $x$, deteriministically. Under the widely believed assumption $BPL=L$, the space used by $U$ is at most $C_R \cdot \log n$ (where $C_R$ is a constant depending on~$R$). Moreover, for every constant $c \geq 1$, if $BPL\subseteq SPACE[(\log(n))^{c}]$ then the space used by $U$ is at most $C_R  \cdot (\log(n))^{c}$.

Finally, we prove that if optimal hitting sets for ordered branching programs exist then there is a deterministic logspace algorithm that, given a black-box access to an ordered branching program $B$ of size $n$, estimates the probability that $B$ accepts on a uniformly random input. This extends the result of (Cheng and Hoza CCC 2020), who proved that an optimal hitting set implies a white-box two-sided derandomization.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T19:09:05Z">Tuesday, March 28 2023, 19:09</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/039'>TR23-039 |  Query Complexity of Search Problems | 

	Yogesh Dahiya, 

	Arkadev Chattopadhyay, 

	Meena Mahajan</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We relate various complexity measures like sensitivity, block sensitivity, certificate complexity for multi-output functions to the query complexities of such functions. Using these relations, we improve upon the known relationship between pseudo-deterministic query complexity and deterministic query complexity for total search problems: We show that pseudo-deterministic query complexity is at most the third power of its deterministic query complexity. (Previously a fourth-power relation was shown by Goldreich,Goldwasser,Ron (ITCS13).) We then obtain a significantly simpler and self-contained proof of a separation between pseudodeterminism and randomized query complexity recently proved by Goldwasser, Impagliazzo, Pitassi, Santhanam (CCC 2021). We also separate pseudodeterminism from randomness in AND decision trees, and determinism from pseudodeterminism in PARITY decision trees. For a hypercube colouring problem closely related to the pseudodeterministic complexity of a complete problem in $TFNP^{dt}$, we prove that either the monotone block-sensitivity or the anti-monotone block sensitivity is $\Omega(n^{1/3})$; previously an $\Omega(n^{1/2})$ bound was known but for general block-sensitivity.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We relate various complexity measures like sensitivity, block sensitivity, certificate complexity for multi-output functions to the query complexities of such functions. Using these relations, we improve upon the known relationship between pseudo-deterministic query complexity and deterministic query complexity for total search problems: We show that pseudo-deterministic query complexity is at most the third power of its deterministic query complexity. (Previously a fourth-power relation was shown by Goldreich,Goldwasser,Ron (ITCS13).) We then obtain a significantly simpler and self-contained proof of a separation between pseudodeterminism and randomized query complexity recently proved by Goldwasser, Impagliazzo, Pitassi, Santhanam (CCC 2021). We also separate pseudodeterminism from randomness in AND decision trees, and determinism from pseudodeterminism in PARITY decision trees. For a hypercube colouring problem closely related to the pseudodeterministic complexity of a complete problem in $TFNP^{dt}$, we prove that either the monotone block-sensitivity or the anti-monotone block sensitivity is $\Omega(n^{1/3})$; previously an $\Omega(n^{1/2})$ bound was known but for general block-sensitivity.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T18:07:01Z">Tuesday, March 28 2023, 18:07</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/038'>TR23-038 |  Indistinguishability Obfuscation, Range Avoidance, and Bounded Arithmetic | 

	Rahul Ilango, 

	Jiatu Li, 

	Ryan Williams</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The range avoidance problem (denoted by Avoid) asks to find a string outside of the range of a given circuit $C:\{0,1\}^n\to\{0,1\}^m$, where $m&gt;n$. Although at least half of the strings of length $m$ are correct answers, it is not clear how to deterministically find one. Recent results of Korten (FOCS&#39;21) and Ren, Wang, and Santhanam (FOCS&#39; 22) show that efficient deterministic algorithms for Avoid would have far-reaching consequences, including strong circuit lower bounds and explicit constructions of combinatorial objects (e.g., Ramsey graphs, extractors, rigid matrices). This strongly motivates the question: does an efficient deterministic algorithm for Avoid actually exist?

In this work, we prove under the existence of subexponentially secure indistinguishability obfuscation (iO) that deterministic polynomial-time algorithms for Avoid imply NP=coNP. Combining this with Jain, Lin, and Sahai&#39;s recent breakthrough construction of iO from well-founded assumptions (STOC&#39;21, EUROCRYPT&#39;22), we provide the first plausible evidence that Avoid has no efficient deterministic algorithm. Moreover, we also prove the hardness of Avoid based on polynomially-secure iO and a weaker variant of the Nondeterministic Exponential Time Hypothesis (NETH).

Extending our techniques, we prove a surprising separation in bounded arithmetic, conditioned on similar assumptions. Assuming subexponentially secure iO and coNP is not infinitely often in AM, we show that Avoid has no deterministic polynomial-time algorithm even when we are allowed $O(1)$ queries to an oracle that can invert the given input circuit on an arbitrarily chosen $m$-bit string. It follows that the dual Weak Pigeonhole Principle, the combinatorial principle underlying Avoid, is not provable in Cook&#39;s theory $PV_1$. This gives (under plausible assumptions) the first separation of Cook&#39;s theory $PV_1$ for polynomial-time reasoning and Jerabek&#39;s theory $APC_1$ for probabilistic polynomial-time reasoning.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The range avoidance problem (denoted by Avoid) asks to find a string outside of the range of a given circuit $C:\{0,1\}^n\to\{0,1\}^m$, where $m&gt;n$. Although at least half of the strings of length $m$ are correct answers, it is not clear how to deterministically find one. Recent results of Korten (FOCS&#39;21) and Ren, Wang, and Santhanam (FOCS&#39; 22) show that efficient deterministic algorithms for Avoid would have far-reaching consequences, including strong circuit lower bounds and explicit constructions of combinatorial objects (e.g., Ramsey graphs, extractors, rigid matrices). This strongly motivates the question: does an efficient deterministic algorithm for Avoid actually exist?

In this work, we prove under the existence of subexponentially secure indistinguishability obfuscation (iO) that deterministic polynomial-time algorithms for Avoid imply NP=coNP. Combining this with Jain, Lin, and Sahai&#39;s recent breakthrough construction of iO from well-founded assumptions (STOC&#39;21, EUROCRYPT&#39;22), we provide the first plausible evidence that Avoid has no efficient deterministic algorithm. Moreover, we also prove the hardness of Avoid based on polynomially-secure iO and a weaker variant of the Nondeterministic Exponential Time Hypothesis (NETH).

Extending our techniques, we prove a surprising separation in bounded arithmetic, conditioned on similar assumptions. Assuming subexponentially secure iO and coNP is not infinitely often in AM, we show that Avoid has no deterministic polynomial-time algorithm even when we are allowed $O(1)$ queries to an oracle that can invert the given input circuit on an arbitrarily chosen $m$-bit string. It follows that the dual Weak Pigeonhole Principle, the combinatorial principle underlying Avoid, is not provable in Cook&#39;s theory $PV_1$. This gives (under plausible assumptions) the first separation of Cook&#39;s theory $PV_1$ for polynomial-time reasoning and Jerabek&#39;s theory $APC_1$ for probabilistic polynomial-time reasoning.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T12:58:10Z">Tuesday, March 28 2023, 12:58</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/03/28/some-problems/'>Some Problems</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          In the previous post, Two Three Four posts ago I wrote about three recent breakthroughs in combinatorics and here I want to mention some problems that I posed over the years that are loosely related to these advances. Rank of &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><del>In the previous post, Two Three</del> Four posts ago I wrote about <a href="https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/">three recent breakthroughs in combinatorics</a> and here I want to mention some problems that I posed over the years that are loosely related to these advances.</p>
<h2>Rank of incidence matrices and <em>q</em>-analogs</h2>
<p>The goal of finding <em>q</em>-analogs of combinatorial results where, roughly speaking, sets are replaced by subspaces of vector spaces over a field with <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" /> elements, is common both in enumerative combinatorics and in extremal combinatorics. A recent breakthrough we discussed by Keevash, Sah, and Sawhney was about the existence of <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" />-analogs of designs (subspace designs).</p>
<p>I will mention a problem (Question 4) in this direction about incidence matrices, following three questions that were largely solved.</p>
<h3>Incidence matrices and weighted incidence matrices for sets</h3>
<p>The incidence matrix of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-subsets vs. <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />-subsets of <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="[n]" class="latex" />, is a matrix <img src="https://s0.wp.com/latex.php?latex=I_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=I_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=I_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="I_{k,m}(n)" class="latex" /> whose rows correspond to <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-subsets <img src="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="[n]" class="latex" />, whose columns correspond to <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />-subsets <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="[n]" class="latex" />, and the entry <img src="https://s0.wp.com/latex.php?latex=I%28S%2CT%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=I%28S%2CT%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=I%28S%2CT%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="I(S,T)" class="latex" /> equals 1 if <img src="https://s0.wp.com/latex.php?latex=R+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R &#92;subset S" class="latex" />, and equals 0 if <img src="https://s0.wp.com/latex.php?latex=R+%5Cnot+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R+%5Cnot+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R+%5Cnot+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R &#92;not &#92;subset S" class="latex" />.</p>
<p>A weighted incidence matrix of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-subsets vs. <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />-subsets of <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="[n]" class="latex" />, is a matrix <img src="https://s0.wp.com/latex.php?latex=J_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=J_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=J_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="J_{k,m}(n)" class="latex" /> whose rows correspond to <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-subsets <img src="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="[n]" class="latex" />, whose columns correspond to <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />-subsets <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="[n]" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=J%28R%2CS%29+%5Cne+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=J%28R%2CS%29+%5Cne+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=J%28R%2CS%29+%5Cne+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="J(R,S) &#92;ne 0" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=R+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R &#92;subset S" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=J%28R%2CS%29%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=J%28R%2CS%29%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=J%28R%2CS%29%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="J(R,S)=0" class="latex" />  if <img src="https://s0.wp.com/latex.php?latex=R+%5Cnot+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R+%5Cnot+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R+%5Cnot+%5Csubset+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R &#92;not &#92;subset S" class="latex" />.</p>
<p><strong>Question 1:</strong> What is the rank <img src="https://s0.wp.com/latex.php?latex=r_p%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_p%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_p%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_p(n,k,m)" class="latex" /> of the incidence matrix of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-subsets vs. <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />-subsets of <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Bn%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="[n]" class="latex" />, over a field of characteristic <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />.</p>
<p>This question was <a href="http://A diagonal form for the incidence matrices of t-subsets vs. k-subsets‏">beautifully answered</a> by Richard Wilson in 1990 . The problem was posed by Nati Linial and Bruce Rothschild in 1981 and they settled the case <img src="https://s0.wp.com/latex.php?latex=p%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p=2" class="latex" />.  (The answer for <img src="https://s0.wp.com/latex.php?latex=p%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%3D2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p=2" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=m%3Dk-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m%3Dk-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m%3Dk-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m=k-1" class="latex" />, that motivated the question, was observed earlier by Perles and by Frankl.) It is unforgivable that I did not present the statement of Wilson&#8217;s theorem here on the blog.</p>
<p><strong>Question 2:</strong> What is the minimum rank, denoted by <img src="https://s0.wp.com/latex.php?latex=s_p%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_p%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_p%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_p(n,k,m)" class="latex" />, of a weighted incidence matrix of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-subsets vs. <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />-subsets of $[n]$ over a field of characteristic <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />.</p>
<p>This question was answered by me in the early 80s (it is related also to various results by others around the same time). The answer is <img src="https://s0.wp.com/latex.php?latex=%7Bn-k%2Bm%7D+%5Cchoose+%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn-k%2Bm%7D+%5Cchoose+%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn-k%2Bm%7D+%5Cchoose+%7Bm%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="{n-k+m} &#92;choose {m}" class="latex" />, and remarkably it is independent from the characteristic <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />.</p>
<h3>Incidence matrices and weighted incidence matrices for subspaces</h3>
<p>The incidence matrix <img src="https://s0.wp.com/latex.php?latex=I%5Eq%3DI%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=I%5Eq%3DI%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=I%5Eq%3DI%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="I^q=I^q_{k,m}(n)" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-dimensional subspaces vs. <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />-dimensional subspaces of <img src="https://s0.wp.com/latex.php?latex=F_q%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=F_q%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=F_q%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="F_q^n" class="latex" /> (<img src="https://s0.wp.com/latex.php?latex=k%3Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%3Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%3Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k&lt;m)" class="latex" /> has entries <img src="https://s0.wp.com/latex.php?latex=I_%7BV%2CU%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=I_%7BV%2CU%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=I_%7BV%2CU%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="I_{V,U}=1" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=V+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V &#92;subset U" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=I_%7BV%2CU%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=I_%7BV%2CU%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=I_%7BV%2CU%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="I_{V,U}=0" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=V+%5Cnot+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V+%5Cnot+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V+%5Cnot+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V &#92;not &#92;subset U" class="latex" />.</p>
<p>A weighted incidence matrix <img src="https://s0.wp.com/latex.php?latex=J%5Eq%3DJ%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=J%5Eq%3DJ%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=J%5Eq%3DJ%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="J^q=J^q_{k,m}(n)" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k" class="latex" />-dimensional subspaces vs. <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />-dimensional subspaces of <img src="https://s0.wp.com/latex.php?latex=F_q%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=F_q%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=F_q%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="F_q^n" class="latex" /> (<img src="https://s0.wp.com/latex.php?latex=k%3Cm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=k%3Cm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=k%3Cm&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="k&lt;m" class="latex" />) has entries <img src="https://s0.wp.com/latex.php?latex=J_%7BV%2CU%7D%5Cne+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=J_%7BV%2CU%7D%5Cne+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=J_%7BV%2CU%7D%5Cne+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="J_{V,U}&#92;ne 0" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=V+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V &#92;subset U" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=J_%7BV%2CU%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=J_%7BV%2CU%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=J_%7BV%2CU%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="J_{V,U}=0" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=V+%5Cnot+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V+%5Cnot+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V+%5Cnot+%5Csubset+U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V &#92;not &#92;subset U" class="latex" />.</p>
<p>We pose two additional questions which are the &#8220;<em>q</em>-analogs&#8221; of Questions 1 and 2.</p>
<p><strong>Question 3:</strong>  What is the rank <img src="https://s0.wp.com/latex.php?latex=r_q%5Ep%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=r_q%5Ep%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=r_q%5Ep%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="r_q^p(n,k,m)" class="latex" /> of the incidence matrix <img src="https://s0.wp.com/latex.php?latex=I%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=I%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=I%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="I^q_{k,m}(n)" class="latex" /> over a field of characteristic $p$ (you can simply take the field <img src="https://s0.wp.com/latex.php?latex=F_p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=F_p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=F_p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="F_p" class="latex" />).</p>
<p><a href="https://gilkalai.files.wordpress.com/2023/03/bf027737492.pdf">Frumkin and Yakir settled problem 3</a> when <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" /> is not a power of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />.</p>
<p>The problem I want to pose (again) here is:</p>
<p><strong><span style="color: #ff0000">Question 4:</span> </strong> What is the minimum rank denoted by <img src="https://s0.wp.com/latex.php?latex=s_q%5Ep%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=s_q%5Ep%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=s_q%5Ep%28n%2Ck%2Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="s_q^p(n,k,m)" class="latex" /> of a weighted incidence matrix <img src="https://s0.wp.com/latex.php?latex=J%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=J%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=J%5Eq_%7Bk%2Cm%7D%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="J^q_{k,m}(n)" class="latex" /> over a field of characteristic <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" />.</p>
<p>In particular, I would like to know if the answer does not depend on <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p" class="latex" /> and if it agrees with some easy lower bounds (obtained from certain identity submatrices) like in the case of a field with one element <img src="https://s0.wp.com/latex.php?latex=p%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=p%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=p%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="p=1" class="latex" /> (namely, subsets).</p>
<h2>q-trees</h2>
<p><strong><span style="color: #ff0000">Qoestion 5:</span></strong> What are the <em>q</em>-analogs of trees? (and hypertrees).</p>
<p>The basic idea is first to find weights so that the incidence matrix of 1-subspace vs 2-subspaces has rank <img src="https://s0.wp.com/latex.php?latex=q%2Bq%5E2%2B%5Ccdots+%2Bq%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q%2Bq%5E2%2B%5Ccdots+%2Bq%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%2Bq%5E2%2B%5Ccdots+%2Bq%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q+q^2+&#92;cdots +q^n" class="latex" />, and then the <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" />-trees will correspond to collection of <img src="https://s0.wp.com/latex.php?latex=q%2Bq%5E2%2B%5Ccdots+%2Bq%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q%2Bq%5E2%2B%5Ccdots+%2Bq%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q%2Bq%5E2%2B%5Ccdots+%2Bq%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q+q^2+&#92;cdots +q^n" class="latex" /> 2-spaces with linearly independent columns. (I don&#8217;t expect uniqueness.) This is a little related to a <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="q" class="latex" />-analog of the notion of symmetric matroids that I studied in the late 80s.</p>
<p>A year ago Ferdinand Ihringer, Motaz Mokatren and I made some very preliminary steps in this direction before moving on (separately) to other projects. It will be nice to come back to it.</p>
<p><strong>Remark:</strong> There is even greater generalities where problems can be extended from set systems (graphs and hypergraphs) to more general algebraic objects. Those could be related to general primitive permutation groups, to association schemes, and to other objects in algebraic combinatorics.</p>
<h2>Unit distances and related problems in discrete geometry.</h2>
<p>Let <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> be a normed space. For a set <img src="https://s0.wp.com/latex.php?latex=S+%5Csubset+V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S+%5Csubset+V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S+%5Csubset+V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S &#92;subset V" class="latex" /> the unit distance graph <img src="https://s0.wp.com/latex.php?latex=G%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G(V)" class="latex" /> is the graph whose vertices are points in <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> and two vertices are adjacent if their distance is one.</p>
<p>We can consider the following quantities</p>
<p>1) <img src="https://s0.wp.com/latex.php?latex=a%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=a%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=a%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="a(V)" class="latex" />: The maximum size of a unit distance set in <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" />. (In other words, the maximum clique in <img src="https://s0.wp.com/latex.php?latex=G%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G(V)" class="latex" />.)</p>
<p>2) <img src="https://s0.wp.com/latex.php?latex=%5Cchi%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cchi%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cchi%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;chi(V)" class="latex" />:  The number of colors needed for <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> if two points of unit distance are colored with different colors.</p>
<p>3) <img src="https://s0.wp.com/latex.php?latex=b%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b(V)" class="latex" />: The maximum number of colors needed to color points in a set <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> of diameter 1 if  every color set has diameter smaller than 1. (This is the Borsuk number of <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" />.)</p>
<p>4) <img src="https://s0.wp.com/latex.php?latex=b_f%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b_f%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b_f%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b_f(V)" class="latex" /> The maximum number of colors needed to color points in a finite set <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> of diameter 1 if  two points of unit distance are colored with different colors.</p>
<p>5) <img src="https://s0.wp.com/latex.php?latex=kiss%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=kiss%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=kiss%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="kiss(V)" class="latex" /> The maximum number of points of norm 1 with pairwise distances at least 1.</p>
<p>6) The maximum over all sets <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> with points of pairwise distance at least one, of the minimum degree in the unit distance graph <img src="https://s0.wp.com/latex.php?latex=G%28S%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=G%28S%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=G%28S%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="G(S)" class="latex" />.</p>
<p>7) The maximum over all sets <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" /> with points of pairwise distance at least one of the chromatic number of the unit distance graph of <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" />.</p>
<p>Estimating these seven quantities for Euclidean spaces and for other normed spaces are well-known problems. (See my <a href="https://arxiv.org/abs/1505.04952">survey article</a> on problems around Borsuk&#8217;s problem.) Alon, Bucić, and Sauermann made a remarkable breakthrough on the first problem of the largest clique in a unit distance graphs for arbitrary normed spaces.</p>
<p>Jordan Ellenberg asked: &#8220;Does the Alon-Bucic-Sauermann result give you upper bounds for the chromatic number of (the unit distance graph of) <img src="https://s0.wp.com/latex.php?latex=R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="R^d" class="latex" /> with a typical norm? (Or is that already easy for some reason?) &#8220;.  But I know little about Jordan&#8217;s question.</p>
<p>There is much to say about them but I will not discuss these problems here. I will mention a single annoying problem.</p>
<p><span style="color: #ff0000"><strong>Question 6:</strong></span> Is there an example of a normed space <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="V" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=b%28V%29+%5Cne+b_f%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=b%28V%29+%5Cne+b_f%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=b%28V%29+%5Cne+b_f%28V%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="b(V) &#92;ne b_f(V)" class="latex" />?</p>
<p>(I am not even sure if for the seventh item it makes a difference to consider finite <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="S" class="latex" />.)</p>
<h2>Intersection patterns of standard boxes</h2>
<p>In <a href="https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/">the post that I mentioned</a> we also discussed Tomon&#8217;s remarkable result on intersection patterns of standard boxes. Here is some loosely related problem. In short, we want to find topological analogs for results on intersection patterns of standard boxes.</p>
<p>Topological Helly-type theorems is an important direction in geometric and topological combinatorics. The idea is to prove Helly type theorems about convex sets in a much wider topological contexts.</p>
<p>A primary goal of Topological Helly-type theorems is to extend results for nerves of families of convex sets in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="&#92;mathbb R^d" class="latex" /> to the class of <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />-Leray simplcial complexes. Among the results achieved so far are: The upper bound theorem; Eckhoff&#8217;s conjecture; Alon and Kleitman&#8217;s (p,q)-theorem; colorful and matroidal Helly&#8217;s theorem; topological Amenta&#8217;s theorem, and more.</p>
<p>Another goal of Topological Helly-type theorems is to study if results on nerves of standard boxes can be extended to flag <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />-Leray simplicial complexes?</p>
<p>In this direction the immediate goal is to extend <a href="https://gilkalai.files.wordpress.com/2023/03/bf02783298.pdf">Eckhoff&#8217;s upper bound theorem</a>. (Item 3 in <a href="https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/">this post</a>.)</p>
<p><span style="color: #ff0000"><strong>Question 7.</strong></span> Conjecture: Let <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> be a <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> Leray flag complex of dimension <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" /> with $n$ vertices. Then the <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />-vector of <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> obeys Eckhoff&#8217;s upper bound theorem for standard boxes.</p>
<p>A closely related question is</p>
<p><span style="color: #ff0000"><strong>Question 8.</strong></span> Conjecture: Let <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> be a <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />-Leray flag complex of dimension <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />, then the <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />-vector of <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> is the <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="f" class="latex" />-vector of a completely balanced <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="m" class="latex" />-dimensional <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="d" class="latex" />-Leray complex.</p>
<p>Studying the equality cases of the conjecture is also of interest and the extremal complexes can also be regarded as some sort of ultra-trees.</p>
<p><img loading="lazy" data-attachment-id="24056" data-permalink="https://gilkalai.wordpress.com/2023/03/28/some-problems/roy_meshulam/" data-orig-file="https://gilkalai.files.wordpress.com/2023/03/roy_meshulam.jpg" data-orig-size="220,220" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="roy_meshulam" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/03/roy_meshulam.jpg?w=220" data-large-file="https://gilkalai.files.wordpress.com/2023/03/roy_meshulam.jpg?w=220" class="alignnone  wp-image-24056" src="https://gilkalai.files.wordpress.com/2023/03/roy_meshulam.jpg?w=307&#038;h=307" alt="roy_meshulam" width="307" height="307" srcset="https://gilkalai.files.wordpress.com/2023/03/roy_meshulam.jpg 220w, https://gilkalai.files.wordpress.com/2023/03/roy_meshulam.jpg?w=150&amp;h=150 150w" sizes="(max-width: 307px) 100vw, 307px" /></p>
<p>Roy Meshulam and I worked together on topological Helly type theorems for more than two decades.</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T08:24:43Z">Tuesday, March 28 2023, 08:24</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/037'>TR23-037 |  Capturing One-Way Functions via NP-Hardness of Meta-Complexity | 

	Shuichi Hirahara</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          A one-way function is a function that is easy to compute but hard to invert *on average*.  We establish the first characterization of a one-way function by *worst-case* hardness assumptions, by introducing a natural meta-computational problem whose NP-hardness (and the worst-case hardness of NP) characterizes the existence of a one-way function.  Specifically, we generalize the notion of time-bounded conditional Kolmogorov complexity to *distributional Kolmogorov complexity*, and prove that a one-way function exists if and only if it is NP-hard to approximate the distributional Kolmogorov complexity under randomized polynomial-time reductions and NP is hard in the worst case.  We also propose the *Meta-Complexity Padding Conjecture*, which postulates that distributional Kolmogorov complexity is paddable by an approximation-preserving reduction.  Under this conjecture, we prove that the worst-case hardness of an approximate version of the Minimum Circuit Size Problem characterizes the existence of a one-way function.

Our results extend the emerging paradigm of meta-complexity, which suggests that proving NP-hardness of meta-computational problems (i.e., problems that ask to compute complexity) is sufficient to exclude errorless Heuristica and error-prone Pessiland from Impagliazzo&#39;s five worlds.  The key technical contribution is to conditionally close the gap between errorless and error-prone average-case complexities by combining Nanashima&#39;s proof techniques of showing &quot;limits&quot; of black-box reductions (ITCS&#39;21) with non-black-box worst-case-to-average-case reductions of Hirahara (FOCS&#39;18).
        
        </div>

        <div class='tr-article-summary'>
        
          
          A one-way function is a function that is easy to compute but hard to invert *on average*.  We establish the first characterization of a one-way function by *worst-case* hardness assumptions, by introducing a natural meta-computational problem whose NP-hardness (and the worst-case hardness of NP) characterizes the existence of a one-way function.  Specifically, we generalize the notion of time-bounded conditional Kolmogorov complexity to *distributional Kolmogorov complexity*, and prove that a one-way function exists if and only if it is NP-hard to approximate the distributional Kolmogorov complexity under randomized polynomial-time reductions and NP is hard in the worst case.  We also propose the *Meta-Complexity Padding Conjecture*, which postulates that distributional Kolmogorov complexity is paddable by an approximation-preserving reduction.  Under this conjecture, we prove that the worst-case hardness of an approximate version of the Minimum Circuit Size Problem characterizes the existence of a one-way function.

Our results extend the emerging paradigm of meta-complexity, which suggests that proving NP-hardness of meta-computational problems (i.e., problems that ask to compute complexity) is sufficient to exclude errorless Heuristica and error-prone Pessiland from Impagliazzo&#39;s five worlds.  The key technical contribution is to conditionally close the gap between errorless and error-prone average-case complexities by combining Nanashima&#39;s proof techniques of showing &quot;limits&quot; of black-box reductions (ITCS&#39;21) with non-black-box worst-case-to-average-case reductions of Hirahara (FOCS&#39;18).
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T07:18:08Z">Tuesday, March 28 2023, 07:18</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.14293'>Efficient Lipschitzian Global Optimization of H\"older Continuous Multivariate Functions</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Kaan Gokcesu, Hakan Gokcesu</p><p>This study presents an effective global optimization technique designed for
multivariate functions that are H\"older continuous. Unlike traditional methods
that construct lower bounding proxy functions, this algorithm employs a
predetermined query creation rule that makes it computationally superior. The
algorithm's performance is assessed using the average or cumulative regret,
which also implies a bound for the simple regret and reflects the overall
effectiveness of the approach. The results show that with appropriate
parameters the algorithm attains an average regret bound of
$O(T^{-\frac{\alpha}{n}})$ for optimizing a H\"older continuous target function
with H\"older exponent $\alpha$ in an $n$-dimensional space within a given time
horizon $T$. We demonstrate that this bound is minimax optimal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gokcesu_K/0/1/0/all/0/1">Kaan Gokcesu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gokcesu_H/0/1/0/all/0/1">Hakan Gokcesu</a></p><p>This study presents an effective global optimization technique designed for
multivariate functions that are H\"older continuous. Unlike traditional methods
that construct lower bounding proxy functions, this algorithm employs a
predetermined query creation rule that makes it computationally superior. The
algorithm's performance is assessed using the average or cumulative regret,
which also implies a bound for the simple regret and reflects the overall
effectiveness of the approach. The results show that with appropriate
parameters the algorithm attains an average regret bound of
$O(T^{-\frac{\alpha}{n}})$ for optimizing a H\"older continuous target function
with H\"older exponent $\alpha$ in an $n$-dimensional space within a given time
horizon $T$. We demonstrate that this bound is minimax optimal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T00:30:00Z">Tuesday, March 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.14405'>On the Efficiency of An Election Game of Two or More Parties: How Bad Can It Be?</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Chuang-Chieh Lin, Chi-Jen Lu, Po-An Chen</p><p>We extend our previous work on two-party election competition [Lin, Lu &amp; Chen
2021] to the setting of three or more parties. An election campaign among two
or more parties is viewed as a game of two or more players. Each of them has
its own candidates as the pure strategies to play. People, as voters, comprise
supporters for each party, and a candidate brings utility for the the
supporters of each party. Each player nominates exactly one of its candidates
to compete against the other party's. \emph{A candidate is assumed to win the
election with higher odds if it brings more utility for all the people.} The
payoff of each player is the expected utility its supporters get. The game is
egoistic if every candidate benefits her party's supporters more than any
candidate from the competing party does. In this work, we first argue that the
election game always has a pure Nash equilibrium when the winner is chosen by
the hardmax function, while there exist game instances in the three-party
election game such that no pure Nash equilibrium exists even the game is
egoistic. Next, we propose two sufficient conditions for the egoistic election
game to have a pure Nash equilibrium. Based on these conditions, we propose a
fixed-parameter tractable algorithm to compute a pure Nash equilibrium of the
egoistic election game. Finally, perhaps surprisingly, we show that the price
of anarchy of the egoistic election game is upper bounded by the number of
parties. Our findings suggest that the election becomes unpredictable when more
than two parties are involved and, moreover, the social welfare deteriorates
with the number of participating parties in terms of possibly increasing price
of anarchy. This work alternatively explains why the two-party system is
prevalent in democratic countries.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chuang-Chieh Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chi-Jen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Po-An Chen</a></p><p>We extend our previous work on two-party election competition [Lin, Lu &amp; Chen
2021] to the setting of three or more parties. An election campaign among two
or more parties is viewed as a game of two or more players. Each of them has
its own candidates as the pure strategies to play. People, as voters, comprise
supporters for each party, and a candidate brings utility for the the
supporters of each party. Each player nominates exactly one of its candidates
to compete against the other party's. \emph{A candidate is assumed to win the
election with higher odds if it brings more utility for all the people.} The
payoff of each player is the expected utility its supporters get. The game is
egoistic if every candidate benefits her party's supporters more than any
candidate from the competing party does. In this work, we first argue that the
election game always has a pure Nash equilibrium when the winner is chosen by
the hardmax function, while there exist game instances in the three-party
election game such that no pure Nash equilibrium exists even the game is
egoistic. Next, we propose two sufficient conditions for the egoistic election
game to have a pure Nash equilibrium. Based on these conditions, we propose a
fixed-parameter tractable algorithm to compute a pure Nash equilibrium of the
egoistic election game. Finally, perhaps surprisingly, we show that the price
of anarchy of the egoistic election game is upper bounded by the number of
parties. Our findings suggest that the election becomes unpredictable when more
than two parties are involved and, moreover, the social welfare deteriorates
with the number of participating parties in terms of possibly increasing price
of anarchy. This work alternatively explains why the two-party system is
prevalent in democratic countries.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T00:30:00Z">Tuesday, March 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.14195'>The limited-memory recursive variational Gaussian approximation (L-RVGA)</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Marc Lambert (DGA, SIERRA), Silv&#xe8;re Bonnabel (CAOR, ISEA), Francis Bach (LIENS, SIERRA)</p><p>We consider the problem of computing a Gaussian approximation to the
posterior distribution of a parameter given a large number N of observations
and a Gaussian prior, when the dimension of the parameter d is also large. To
address this problem we build on a recently introduced recursive algorithm for
variational Gaussian approximation of the posterior, called recursive
variational Gaussian approximation (RVGA), which is a single pass algorithm,
free of parameter tuning. In this paper, we consider the case where the
parameter dimension d is high, and we propose a novel version of RVGA that
scales linearly in the dimension d (as well as in the number of observations
N), and which only requires linear storage capacity in d. This is afforded by
the use of a novel recursive expectation maximization (EM) algorithm applied
for factor analysis introduced herein, to approximate at each step the
covariance matrix of the Gaussian distribution conveying the uncertainty in the
parameter. The approach is successfully illustrated on the problems of high
dimensional least-squares and logistic regression, and generalized to a large
class of nonlinear models.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lambert_M/0/1/0/all/0/1">Marc Lambert</a> (DGA, SIERRA), <a href="http://arxiv.org/find/cs/1/au:+Bonnabel_S/0/1/0/all/0/1">Silv&#xe8;re Bonnabel</a> (CAOR, ISEA), <a href="http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1">Francis Bach</a> (LIENS, SIERRA)</p><p>We consider the problem of computing a Gaussian approximation to the
posterior distribution of a parameter given a large number N of observations
and a Gaussian prior, when the dimension of the parameter d is also large. To
address this problem we build on a recently introduced recursive algorithm for
variational Gaussian approximation of the posterior, called recursive
variational Gaussian approximation (RVGA), which is a single pass algorithm,
free of parameter tuning. In this paper, we consider the case where the
parameter dimension d is high, and we propose a novel version of RVGA that
scales linearly in the dimension d (as well as in the number of observations
N), and which only requires linear storage capacity in d. This is afforded by
the use of a novel recursive expectation maximization (EM) algorithm applied
for factor analysis introduced herein, to approximate at each step the
covariance matrix of the Gaussian distribution conveying the uncertainty in the
parameter. The approach is successfully illustrated on the problems of high
dimensional least-squares and logistic regression, and generalized to a large
class of nonlinear models.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T00:30:00Z">Tuesday, March 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.14321'>Exact Short Products From Truncated Multipliers</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Lemire</p><p>We sometimes need to compute the most significant digits of the product of
small integers with a multiplier requiring much storage: e.g., a large integer
(e.g., $5^{100}$) or an irrational number ($\pi$). We only need to access the
most significant digits of the multiplier-as long as the integers are
sufficiently small. We provide an efficient algorithm to compute the range of
integers given a truncated multiplier and a desired number of digits.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lemire_D/0/1/0/all/0/1">Daniel Lemire</a></p><p>We sometimes need to compute the most significant digits of the product of
small integers with a multiplier requiring much storage: e.g., a large integer
(e.g., $5^{100}$) or an irrational number ($\pi$). We only need to access the
most significant digits of the multiplier-as long as the integers are
sufficiently small. We provide an efficient algorithm to compute the range of
integers given a truncated multiplier and a desired number of digits.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T00:30:00Z">Tuesday, March 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.14424'>Orbits, schemes and dynamic programming procedures for the TSP 4-OPT neighborhood</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Giuseppe Lancia, Marcello Dalpasso</p><p>We discuss the way to group all 25 possible 4-OPT moves into 7 orbits of
equivalent moves. We then describe two implementations, one for a $\Theta(n^3)$
algorithm by de Berg's et al. and one of a $\Theta(n^2)$ algorithm by Glover,
for finding the best 4-OPT move via dynamic programming.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lancia_G/0/1/0/all/0/1">Giuseppe Lancia</a>, <a href="http://arxiv.org/find/cs/1/au:+Dalpasso_M/0/1/0/all/0/1">Marcello Dalpasso</a></p><p>We discuss the way to group all 25 possible 4-OPT moves into 7 orbits of
equivalent moves. We then describe two implementations, one for a $\Theta(n^3)$
algorithm by de Berg's et al. and one of a $\Theta(n^2)$ algorithm by Glover,
for finding the best 4-OPT move via dynamic programming.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T00:30:00Z">Tuesday, March 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2303.14467'>A Survey on the Densest Subgraph Problem and its Variants</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tommaso Lanciano, Atsushi Miyauchi, Adriano Fazzone, Francesco Bonchi</p><p>The Densest Subgraph Problem requires to find, in a given graph, a subset of
vertices whose induced subgraph maximizes a measure of density. The problem has
received a great deal of attention in the algorithmic literature over the last
five decades, with many variants proposed and many applications built on top of
this basic definition. Recent years have witnessed a revival of research
interest on this problem with several interesting contributions, including some
groundbreaking results, published in 2022 and 2023. This survey provides a deep
overview of the fundamental results and an exhaustive coverage of the many
variants proposed in the literature, with a special attention on the most
recent results. The survey also presents a comprehensive overview of
applications and discusses some interesting open problems for this evergreen
research topic.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lanciano_T/0/1/0/all/0/1">Tommaso Lanciano</a>, <a href="http://arxiv.org/find/cs/1/au:+Miyauchi_A/0/1/0/all/0/1">Atsushi Miyauchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazzone_A/0/1/0/all/0/1">Adriano Fazzone</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonchi_F/0/1/0/all/0/1">Francesco Bonchi</a></p><p>The Densest Subgraph Problem requires to find, in a given graph, a subset of
vertices whose induced subgraph maximizes a measure of density. The problem has
received a great deal of attention in the algorithmic literature over the last
five decades, with many variants proposed and many applications built on top of
this basic definition. Recent years have witnessed a revival of research
interest on this problem with several interesting contributions, including some
groundbreaking results, published in 2022 and 2023. This survey provides a deep
overview of the fundamental results and an exhaustive coverage of the many
variants proposed in the literature, with a special attention on the most
recent results. The survey also presents a comprehensive overview of
applications and discusses some interesting open problems for this evergreen
research topic.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-28T00:30:00Z">Tuesday, March 28 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, March 27
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://lucatrevisan.wordpress.com/2023/03/27/introducing-bocconis-new-m-sc-in-artificial-intelligence/'>Introducing Bocconi’s new M.Sc. in Artificial Intelligence</a></h3>
        <p class='tr-article-feed'>from <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          This September, Bocconi will start a new M.Sc. in Artificial Intelligence. It will be a two-year computer science degree meant for students with Bachelor degrees in computer science, engineering, math, statistics, physics and related quantitative fields. In the first year, &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>This September, Bocconi will start a new M.Sc. in Artificial Intelligence. It will be a two-year computer science degree meant for students with Bachelor degrees in computer science, engineering, math, statistics, physics and related quantitative fields. </p>



<p>In the first year, courses on algorithms, mathematical methods, optimization, information theory, and software engineering will build a foundation in math and CS, then courses on deep learning, reinforcement learning, natural language processing and computer vision and image processing will go in depth on machine learning and some of its applications.  In the second year there are various options and elective courses, with the possibility to study, for example, cryptography and blockchains, or bio-medical applications. As common for the second year of Bocconi&#8217;s M.Sc. degrees, there will be options for exchange programs to spend a semester abroad. Students also take a seminar on ethics in AI, a project-oriented AI lab, and a foreign language (not English and not the student&#8217;s native language) course. The language of instruction is English.</p>



<p>Tomorrow at 5pm CET there will be an online information session: those interested can <a href="https://info.unibocconi.it/info/session.php?tipo=B&amp;lingua=eng&amp;key=AI">sign up here</a>.</p>



<p>More information about the degree are at <strong><a href="https://www.unibocconi.eu/ai-msc">www.unibocconi.eu/ai-msc</a></strong>.</p>



<p>Applications open today and are due by May 25th.</p>
<p class="authors">By luca</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-27T18:30:52Z">Monday, March 27 2023, 18:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/036'>TR23-036 |  Derandomization with Minimal Memory Footprint | 

	Dean Doron, 

	Roei Tell</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Existing proofs that deduce BPL=L from circuit lower bounds convert randomized algorithms into deterministic algorithms with large constant overhead in space. We study space-bounded derandomization with minimal footprint, and ask what is the minimal possible space overhead for derandomization.
We show that $BPSPACE[S] \subseteq DSPACE[c \cdot S]$ for $c \approx 2$, assuming space-efficient cryptographic PRGs, and, either: (1) lower bounds against bounded-space algorithms with advice, or: (2) lower bounds against certain uniform compression algorithms.
Under additional assumptions regarding the power of catalytic computation, in a new setting of parameters that was not studied before, we are even able to get $c \approx 1$.

Our results are constructive: Given a candidate hard function (and a candidate cryptographic PRG) we show how to transform the randomized algorithm into an efficient deterministic one.
This follows from new PRGs and targeted PRGs for space-bounded algorithms, which we combine with novel space-efficient evaluation methods. A central ingredient in all our constructions is hardness amplification reductions in logspace-uniform $TC^0$, that were not known before.
        
        </div>

        <div class='tr-article-summary'>
        
          
          Existing proofs that deduce BPL=L from circuit lower bounds convert randomized algorithms into deterministic algorithms with large constant overhead in space. We study space-bounded derandomization with minimal footprint, and ask what is the minimal possible space overhead for derandomization.
We show that $BPSPACE[S] \subseteq DSPACE[c \cdot S]$ for $c \approx 2$, assuming space-efficient cryptographic PRGs, and, either: (1) lower bounds against bounded-space algorithms with advice, or: (2) lower bounds against certain uniform compression algorithms.
Under additional assumptions regarding the power of catalytic computation, in a new setting of parameters that was not studied before, we are even able to get $c \approx 1$.

Our results are constructive: Given a candidate hard function (and a candidate cryptographic PRG) we show how to transform the randomized algorithm into an efficient deterministic one.
This follows from new PRGs and targeted PRGs for space-bounded algorithms, which we combine with novel space-efficient evaluation methods. A central ingredient in all our constructions is hardness amplification reductions in logspace-uniform $TC^0$, that were not known before.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-27T16:29:15Z">Monday, March 27 2023, 16:29</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://cstheory-jobs.org/2023/03/27/phd-student-at-jonkoping-university-apply-by-april-17-2023/'>PhD student at Jönköping university (apply by April 17, 2023)</a></h3>
        <p class='tr-article-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Jönköping University (JU) advertises one position as PhD student in Computer Science, in collaboration with the theoretical computer science laboratory, Linköping university (LiU). The PhD student will join a research project in the intersection of artificial intelligence, complexity theory, and universal algebra, directed by Johannes Schmidt (JU) and Victor Lagerkvist (LiU). Website: ju.varbi.com/se/what:job/jobID:601050/where:4/ Email: victor.lagerkvist@liu.se
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Jönköping University (JU) advertises one position as PhD student in Computer Science, in collaboration with the theoretical computer science laboratory, Linköping university (LiU). The PhD student will join a research project in the intersection of artificial intelligence, complexity theory, and universal algebra, directed by Johannes Schmidt (JU) and Victor Lagerkvist (LiU).</p>
<p>Website: <a href="https://ju.varbi.com/se/what:job/jobID:601050/where:4/">https://ju.varbi.com/se/what:job/jobID:601050/where:4/</a><br />
Email: victor.lagerkvist@liu.se</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-27T13:13:13Z">Monday, March 27 2023, 13:13</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://gilkalai.wordpress.com/2023/03/27/critical-times-in-israel-last-nights-demonstrations/'>Critical Times in Israel: Last Night’s Demonstrations</a></h3>
        <p class='tr-article-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Last night, the demonstrations in Israel regarding the &#8220;judicial reforms&#8221; escalated after the prime minister Netanyahu fired the defense minister Galant who called to stop the legislation. My wife and I enjoyed a concert and after it we heard loud &#8230; Continue reading &#8594;
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><img data-attachment-id="24066" data-permalink="https://gilkalai.wordpress.com/pnp/" data-orig-file="https://gilkalai.files.wordpress.com/2023/03/pnp.jpeg" data-orig-size="2040,1536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pnp" data-image-description="" data-image-caption="" data-medium-file="https://gilkalai.files.wordpress.com/2023/03/pnp.jpeg?w=300" data-large-file="https://gilkalai.files.wordpress.com/2023/03/pnp.jpeg?w=640" class="alignnone size-full wp-image-24066" src="https://gilkalai.files.wordpress.com/2023/03/pnp.jpeg?w=640" alt="pnp" srcset="https://gilkalai.files.wordpress.com/2023/03/pnp.jpeg?w=640 640w, https://gilkalai.files.wordpress.com/2023/03/pnp.jpeg?w=1280 1280w, https://gilkalai.files.wordpress.com/2023/03/pnp.jpeg?w=150 150w, https://gilkalai.files.wordpress.com/2023/03/pnp.jpeg?w=300 300w, https://gilkalai.files.wordpress.com/2023/03/pnp.jpeg?w=768 768w, https://gilkalai.files.wordpress.com/2023/03/pnp.jpeg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"   /></p>
<p>Last night, the demonstrations in Israel regarding the &#8220;judicial reforms&#8221; escalated after the prime minister Netanyahu fired the defense minister Galant who called to stop the legislation. My wife and I enjoyed a concert and after it we heard loud calls &#8220;Bibi fired Galant&#8221; and even &#8220;The dictator fired Galant,&#8221; and were surprised by the news and the huge groups of young people, very angry for a very good reason. And, of course, we joined them. The picture above provided by <a href="https://www.facebook.com/alon.rosen.9/posts/757365502688213:757365502688213">Alon Rosen</a> is from a major highway in Tel Aviv that was blocked for 9 hours. Whether the picture is genuine or not, it shows the anarchist nature of at least some of the protestors.  (We know for sure that some computer scientists were there.) I am not sure if a proof of this bold claim was also provided.</p>
<p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-03-27T06:54:21Z">Monday, March 27 2023, 06:54</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
