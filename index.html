<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>
  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel='stylesheet' type='text/css' href='css/font-awesome.css'>
  <link rel='stylesheet' type='text/css' href='css/blank.css'>
</head>
<body>
  <div id='navwrap'>
    <div id='nav'>
      <p>
        Last Update
      </p>
      <p class='small'>
        
          <time class='timeago' datetime="2022-09-29T11:39:17Z">Thursday, September 29 2022, 11:39</time>
        
      </p>

      <p>Feeds</p>
      <ul class='subscriptions small' >
      
        <li>
          <a href='http://arxiv.org/rss/cs.CC'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.CG'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.DS'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
          
        </li>
      
        <li>
          <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
          
        </li>
      
        <li>
          <a href='https://adamsheffer.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
          
        </li>
      
        <li>
          <a href='https://adamdsmith.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
          
        </li>
      
        <li>
          <a href='https://polylogblog.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
          
        </li>
      
        <li>
          <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
          
        </li>
      
        <li>
          <a href='http://www.argmin.net/feed.xml'><img src='i/feed.png'></a>
          <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
          
        </li>
      
        <li>
          <a href='http://bit-player.org/feed/atom/'><img src='i/feed.png'></a>
          <a href='http://bit-player.org'>bit-player</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-jobs.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-jobs.org'>CCI: jobs</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-events.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-events.org'>CS Theory Events</a>
          
        </li>
      
        <li>
          <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='https://11011110.github.io/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='https://11011110.github.io/blog/'>David Eppstein</a>
          
        </li>
      
        <li>
          <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='i/feed.png'></a>
          <a href='https://daveagp.wordpress.com'>David Pritchard</a>
          
        </li>
      
        <li>
          <a href='https://decentdescent.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://decentdescent.org/'>Decent Descent</a>
          
        </li>
      
        <li>
          <a href='https://decentralizedthoughts.github.io/feed'><img src='i/feed.png'></a>
          <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
          
        </li>
      
        <li>
          <a href='https://differentialprivacy.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
          
        </li>
      
        <li>
          <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='i/feed.png'></a>
          <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
          
        </li>
      
        <li>
          <a href='https://emanueleviola.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
          
        </li>
      
        <li>
          <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='i/feed.png'></a>
          <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
          
        </li>
      
        <li>
          <a href='https://dstheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
          
        </li>
      
        <li>
          <a href='https://francisbach.com/feed/'><img src='i/feed.png'></a>
          <a href='https://francisbach.com'>Francis Bach</a>
          
        </li>
      
        <li>
          <a href='https://gilkalai.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
          
        </li>
      
        <li>
          <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
          
        </li>
      
        <li>
          <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='i/feed.png'></a>
          <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
          
        </li>
      
        <li>
          <a href='https://gradientscience.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://gradientscience.org/'>Gradient Science</a>
          
        </li>
      
        <li>
          <a href='http://grigory.us/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
          
        </li>
      
        <li>
          <a href='https://tcsmath.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
          
        </li>
      
        <li>
          <a href='https://kamathematics.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
          
        </li>
      
        <li>
          <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
          
        </li>
      
        <li>
          <a href='https://lucatrevisan.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
          
        </li>
      
        <li>
          <a href='https://mittheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
          
        </li>
      
        <li>
          <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
          
        </li>
      
        <li>
          <a href='http://blog.mrtz.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
          
        </li>
      
        <li>
          <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
          
        </li>
      
        <li>
          <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
          
        </li>
      
        <li>
          <a href='http://www.solipsistslog.com/feed/'><img src='i/feed.png'></a>
          <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
          
        </li>
      
        <li>
          <a href='http://www.offconvex.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://offconvex.github.io/'>Off the Convex Path</a>
          
        </li>
      
        <li>
          <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
          
        </li>
      
        <li>
          <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
          
        </li>
      
        <li>
          <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='i/feed.png'></a>
          <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
          
        </li>
      
        <li>
          <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
          
        </li>
      
        <li>
          <a href='https://scottaaronson.blog/?feed=atom'><img src='i/feed.png'></a>
          <a href='https://scottaaronson.blog'>Scott Aaronson</a>
          
        </li>
      
        <li>
          <a href='https://blog.simons.berkeley.edu/feed/'><img src='i/feed.png'></a>
          <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
          
        </li>
      
        <li>
          <a href='https://tcsplus.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
          
        </li>
      
        <li>
          <a href='https://toc4fairness.org/feed/'><img src='i/feed.png'></a>
          <a href='https://toc4fairness.org'>TOC for Fairness</a>
          
        </li>
      
        <li>
          <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='i/feed.png'></a>
          <a href='http://blog.geomblog.org/'>The Geomblog</a>
          
        </li>
      
        <li>
          <a href='https://www.let-all.com/blog/feed/'><img src='i/feed.png'></a>
          <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
          
        </li>
      
        <li>
          <a href='https://theorydish.blog/feed/'><img src='i/feed.png'></a>
          <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
          
        </li>
      
        <li>
          <a href='https://thmatters.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://thmatters.wordpress.com'>Theory Matters</a>
          
        </li>
      
        <li>
          <a href='https://mycqstate.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
          
        </li>
      
        <li>
          <a href='https://agtb.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
          
        </li>
      
        <li>
          <a href='https://windowsontheory.org/feed/'><img src='i/feed.png'></a>
          <a href='https://windowsontheory.org'>Windows on Theory</a>
          
        </li>
      
      </ul>

      <p class='small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
      <p class='small'>Subscribe to the <a href="atom.xml">Atom feed</a> or <a href="rss20.xml">RSS feed</a> to stay up to date.</p>
      <p class='small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
      <p class='small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
      <p class='small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
    </div>
  </div>

  <div id='opts'>
    <div style='width: 100%; text-align: right;'>
    <img src='i/view-headlines.png' id='show-headlines' title='Show Headlines Only' width='24' height='24'>
    <img src='i/view-snippets.png' id='show-snippets' title='Show Snippets' width='24' height='24'>
    <img src='i/view-standard.png' id='show-fulltext' title='Show Full Text' width='24' height='24'>
    </div>
  </div>

  <h1>
    Theory of Computing Report
  </h1>

  <div id="articles">
    
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Thursday, September 29
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13599'>A characterization of polynomial time computable functions from the integers to the reals using discrete ordinary differential equations</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Manon Blanc, Olivier Bournez</p><p>In a recent article, the class of functions from the integers to the integers
computable in polynomial time has been characterized using discrete ordinary
differential equations (ODE), also known as finite differences. Doing so, we
pointed out the fundamental role of linear (discrete) ODEs and classical ODE
tools such as changes of variables to capture computability and complexity
measures, or as a tool for programming. In this article, we extend the approach
to a characterization of functions from the integers to the reals computable in
polynomial time in the sense of computable analysis. In particular, we provide
a characterization of such functions in terms of the smallest class of
functions that contains some basic functions, and that is closed by
composition, linear length ODEs, and a natural effective limit schema.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blanc_M/0/1/0/all/0/1">Manon Blanc</a>, <a href="http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1">Olivier Bournez</a></p><p>In a recent article, the class of functions from the integers to the integers
computable in polynomial time has been characterized using discrete ordinary
differential equations (ODE), also known as finite differences. Doing so, we
pointed out the fundamental role of linear (discrete) ODEs and classical ODE
tools such as changes of variables to capture computability and complexity
measures, or as a tool for programming. In this article, we extend the approach
to a characterization of functions from the integers to the reals computable in
polynomial time in the sense of computable analysis. In particular, we provide
a characterization of such functions in terms of the smallest class of
functions that contains some basic functions, and that is closed by
composition, linear length ODEs, and a natural effective limit schema.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13725'>On the Descriptive Complexity of Groups without Abelian Normal Subgroups</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Joshua A. Grochow, Michael Levet</p><p>In this paper, we explore the descriptive complexity theory of finite groups
by examining the power of the second Ehrenfeucht-Fra\"iss\'e bijective pebble
game in Hella's (Ann. Pure Appl. Log., 1989) heirarchy. This is a
Spoiler-Duplicator game in which Spoiler can place up to two pebbles each
round. While it trivially solves graph isomorphism, it may be nontrivial for
finite groups, and other ternary relational structures. We first provide a
novel generalization of Weisfeiler-Leman (WL) coloring, which we call 2-ary WL.
We then show that the 2-ary WL is equivalent to the second
Ehrenfeucht-Fra\"iss\'e bijective pebble game in Hella's heirarchy.
</p>
<p>Our main result is that, in the pebble game characterization, only $O(1)$
pebbles and $O(1)$ rounds are sufficient to identify all groups without Abelian
normal subgroups (a class of groups for which isomorphism testing is known to
be in $\mathsf{P}$; Babai, Codenotti, &amp; Qiao, ICALP 2012). In particular, we
show that within the first few rounds, Spoiler can force Duplicator to select
an isomorphism between two such groups at each subsequent round. By Hella's
results (\emph{ibid.}), this is equivalent to saying that these groups are
identified by formulas in first-order logic with generalized 2-ary quantifiers,
using only $O(1)$ variables and $O(1)$ quantifier depth.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Grochow_J/0/1/0/all/0/1">Joshua A. Grochow</a>, <a href="http://arxiv.org/find/cs/1/au:+Levet_M/0/1/0/all/0/1">Michael Levet</a></p><p>In this paper, we explore the descriptive complexity theory of finite groups
by examining the power of the second Ehrenfeucht-Fra\"iss\'e bijective pebble
game in Hella's (Ann. Pure Appl. Log., 1989) heirarchy. This is a
Spoiler-Duplicator game in which Spoiler can place up to two pebbles each
round. While it trivially solves graph isomorphism, it may be nontrivial for
finite groups, and other ternary relational structures. We first provide a
novel generalization of Weisfeiler-Leman (WL) coloring, which we call 2-ary WL.
We then show that the 2-ary WL is equivalent to the second
Ehrenfeucht-Fra\"iss\'e bijective pebble game in Hella's heirarchy.
</p>
<p>Our main result is that, in the pebble game characterization, only $O(1)$
pebbles and $O(1)$ rounds are sufficient to identify all groups without Abelian
normal subgroups (a class of groups for which isomorphism testing is known to
be in $\mathsf{P}$; Babai, Codenotti, &amp; Qiao, ICALP 2012). In particular, we
show that within the first few rounds, Spoiler can force Duplicator to select
an isomorphism between two such groups at each subsequent round. By Hella's
results (\emph{ibid.}), this is equivalent to saying that these groups are
identified by formulas in first-order logic with generalized 2-ary quantifiers,
using only $O(1)$ variables and $O(1)$ quantifier depth.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14094'>Dynamic Embeddings of Dynamic Single-Source Upward Planar Graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Ivor van der Hoog, Irene Parada, Eva Rotenberg</p><p>A directed graph $G$ is upward planar if it admits a planar embedding such
that each edge is $y$-monotone. Unlike planarity testing, upward planarity
testing is NP-hard except in restricted cases, such as when the graph has the
single-source property (i.e. each connected component only has one source).
</p>
<p>In this paper, we present a dynamic algorithm for maintaining a combinatorial
embedding $\mathcal{E}(G)$ of a single-source upward planar graph subject to
edge deletions, edge contractions, edge insertions upwards across a face, and
single-source-preserving vertex splits through specified corners. We
furthermore support changes to the embedding $\mathcal{E}(G)$ on the form of
subgraph flips that mirror or slide the placement of a subgraph that is
connected to the rest of the graph via at most two vertices.
</p>
<p>All update operations are supported as long as the graph remains upward
planar, and all queries are supported as long as the graph remains
single-source. Updates that violate upward planarity are identified as such and
rejected by our update algorithm. We dynamically maintain a linear-size data
structure on $G$ which supports incidence queries between a vertex and a face,
and upward-linkability of vertex pairs. If a pair of vertices are not
upwards-linkable, we facilitate one-flip-linkable queries that point to a
subgraph flip that makes them linkable, if any such flip exists.
</p>
<p>We support all updates and queries in $O(\log^2 n)$ time.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hoog_I/0/1/0/all/0/1">Ivor van der Hoog</a>, <a href="http://arxiv.org/find/cs/1/au:+Parada_I/0/1/0/all/0/1">Irene Parada</a>, <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1">Eva Rotenberg</a></p><p>A directed graph $G$ is upward planar if it admits a planar embedding such
that each edge is $y$-monotone. Unlike planarity testing, upward planarity
testing is NP-hard except in restricted cases, such as when the graph has the
single-source property (i.e. each connected component only has one source).
</p>
<p>In this paper, we present a dynamic algorithm for maintaining a combinatorial
embedding $\mathcal{E}(G)$ of a single-source upward planar graph subject to
edge deletions, edge contractions, edge insertions upwards across a face, and
single-source-preserving vertex splits through specified corners. We
furthermore support changes to the embedding $\mathcal{E}(G)$ on the form of
subgraph flips that mirror or slide the placement of a subgraph that is
connected to the rest of the graph via at most two vertices.
</p>
<p>All update operations are supported as long as the graph remains upward
planar, and all queries are supported as long as the graph remains
single-source. Updates that violate upward planarity are identified as such and
rejected by our update algorithm. We dynamically maintain a linear-size data
structure on $G$ which supports incidence queries between a vertex and a face,
and upward-linkability of vertex pairs. If a pair of vertices are not
upwards-linkable, we facilitate one-flip-linkable queries that point to a
subgraph flip that makes them linkable, if any such flip exists.
</p>
<p>We support all updates and queries in $O(\log^2 n)$ time.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13712'>A Quantum Optimization Algorithm for Single Machine Total Weighted Tardiness Minimization</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Youhao Steve Wang, Julian Cheng</p><p>A single machine total weighted tardiness minimization (TWTM) problem in
operational planning is considered. The problem is formulated as an NP-hard
constrained combinatorial problem, which has no known deterministic polynomial
complexity solution using classical computing. Based on efficient Grover's
quantum search and Trugenberger's quantum optimization algorithms, a novel
efficient quantum optimization algorithm is proposed to solve the NP-hard
single machine TWTM problem, which makes the desired solution satisfying the
searching constraints and showing the minimal TWT value be measured with the
highest probability.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Youhao Steve Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Julian Cheng</a></p><p>A single machine total weighted tardiness minimization (TWTM) problem in
operational planning is considered. The problem is formulated as an NP-hard
constrained combinatorial problem, which has no known deterministic polynomial
complexity solution using classical computing. Based on efficient Grover's
quantum search and Trugenberger's quantum optimization algorithms, a novel
efficient quantum optimization algorithm is proposed to solve the NP-hard
single machine TWTM problem, which makes the desired solution satisfying the
searching constraints and showing the minimal TWT value be measured with the
highest probability.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13878'>Near-Optimal Adaptive Policies for Serving Stochastically Departing Customers</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Danny Segev</p><p>We consider a multi-stage stochastic optimization problem originally
introduced by Cygan et al. (2013), studying how a single server should
prioritize stochastically departing customers. In this setting, our objective
is to determine an adaptive service policy that maximizes the expected total
reward collected along a discrete planning horizon, in the presence of
customers who are independently departing between one stage and the next with
known stationary probabilities. In spite of its deceiving structural
simplicity, we are unaware of non-trivial results regarding the rigorous design
of optimal or truly near-optimal policies at present time.
</p>
<p>Our main contribution resides in proposing a quasi-polynomial-time
approximation scheme for adaptively serving impatient customers. Specifically,
letting $n$ be the number of underlying customers, our algorithm identifies in
$O( n^{ O_{ \epsilon }( \log^2 n ) } )$ time an adaptive service policy whose
expected reward is within factor $1 - \epsilon$ of the optimal adaptive reward.
Our method for deriving this approximation scheme synthesizes various
stochastic analyses in order to investigate how the adaptive optimum is
affected by alteration to several instance parameters, including the reward
values, the departure probabilities, and the collection of customers itself.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Segev_D/0/1/0/all/0/1">Danny Segev</a></p><p>We consider a multi-stage stochastic optimization problem originally
introduced by Cygan et al. (2013), studying how a single server should
prioritize stochastically departing customers. In this setting, our objective
is to determine an adaptive service policy that maximizes the expected total
reward collected along a discrete planning horizon, in the presence of
customers who are independently departing between one stage and the next with
known stationary probabilities. In spite of its deceiving structural
simplicity, we are unaware of non-trivial results regarding the rigorous design
of optimal or truly near-optimal policies at present time.
</p>
<p>Our main contribution resides in proposing a quasi-polynomial-time
approximation scheme for adaptively serving impatient customers. Specifically,
letting $n$ be the number of underlying customers, our algorithm identifies in
$O( n^{ O_{ \epsilon }( \log^2 n ) } )$ time an adaptive service policy whose
expected reward is within factor $1 - \epsilon$ of the optimal adaptive reward.
Our method for deriving this approximation scheme synthesizes various
stochastic analyses in order to investigate how the adaptive optimum is
affected by alteration to several instance parameters, including the reward
values, the departure probabilities, and the collection of customers itself.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14079'>Worst-case Deterministic Fully-Dynamic Planar 2-vertex Connectivity</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jacob Holm, Ivor van der Hoog, Eva Rotenberg</p><p>We study dynamic planar graphs with $n$ vertices, subject to edge deletion,
edge contraction, edge insertion across a face, and the splitting of a vertex
in specified corners. We dynamically maintain a combinatorial embedding of such
a planar graph, subject to connectivity and $2$-vertex-connectivity
(biconnectivity) queries between pairs of vertices. Whenever a query pair is
connected and not biconnected, we find the first and last cutvertex separating
them.
</p>
<p>Additionally, we allow local changes to the embedding by flipping the
embedding of a subgraph that is connected by at most two vertices to the rest
of the graph.
</p>
<p>We support all queries and updates in deterministic, worst-case, $O(\log^2
n)$ time, using an $O(n)$-sized data structure.
</p>
<p>Previously, the best bound for fully-dynamic planar biconnectivity (subject
to our set of operations) was an amortised $\tilde{O}(\log^3 n)$ for general
graphs, and algorithms with worst-case polylogarithmic update times were known
only in the partially dynamic (insertion-only or deletion-only) setting.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Holm_J/0/1/0/all/0/1">Jacob Holm</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoog_I/0/1/0/all/0/1">Ivor van der Hoog</a>, <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1">Eva Rotenberg</a></p><p>We study dynamic planar graphs with $n$ vertices, subject to edge deletion,
edge contraction, edge insertion across a face, and the splitting of a vertex
in specified corners. We dynamically maintain a combinatorial embedding of such
a planar graph, subject to connectivity and $2$-vertex-connectivity
(biconnectivity) queries between pairs of vertices. Whenever a query pair is
connected and not biconnected, we find the first and last cutvertex separating
them.
</p>
<p>Additionally, we allow local changes to the embedding by flipping the
embedding of a subgraph that is connected by at most two vertices to the rest
of the graph.
</p>
<p>We support all queries and updates in deterministic, worst-case, $O(\log^2
n)$ time, using an $O(n)$-sized data structure.
</p>
<p>Previously, the best bound for fully-dynamic planar biconnectivity (subject
to our set of operations) was an amortised $\tilde{O}(\log^3 n)$ for general
graphs, and algorithms with worst-case polylogarithmic update times were known
only in the partially dynamic (insertion-only or deletion-only) setting.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14087'>Adaptive Out-Orientations with Applications</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Aleksander B. G. Christiansen, Jacob Holm, Ivor van der Hoog, Eva Rotenberg, Chris Schwiegelshohn</p><p>We give simple algorithms for maintaining edge-orientations of a
fully-dynamic graph, such that the out-degree of each vertex is bounded. On one
hand, we show how to orient the edges such that the out-degree of each vertex
is proportional to the arboricity $\alpha$ of the graph, in a worst-case update
time of $O(\log^2 n \log \alpha)$. On the other hand, motivated by applications
in dynamic maximal matching, we obtain a different trade-off, namely the
improved worst case update time of $O(\log n \log \alpha)$ for the problem of
maintaining an edge-orientation with at most $O(\alpha + \log n)$ out-edges per
vertex. Since our algorithms have update times with worst-case guarantees, the
number of changes to the solution (i.e. the recourse) is naturally limited.
</p>
<p>Our algorithms make choices based entirely on local information, which makes
them automatically adaptive to the current arboricity of the graph. In other
words, they are arboricity-oblivious, while they are arboricity-sensitive. This
both simplifies and improves upon previous work, by having fewer assumptions or
better asymptotic guarantees.
</p>
<p>As a consequence, one obtains an algorithm with improved efficiency for
maintaining a $(1+\varepsilon)$ approximation of the maximum subgraph density,
and an algorithm for dynamic maximal matching whose worst-case update time is
guaranteed to be upper bounded by $O(\alpha + \log n\log \alpha)$, where
$\alpha$ is the arboricity at the time of the update.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Christiansen_A/0/1/0/all/0/1">Aleksander B. G. Christiansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Holm_J/0/1/0/all/0/1">Jacob Holm</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoog_I/0/1/0/all/0/1">Ivor van der Hoog</a>, <a href="http://arxiv.org/find/cs/1/au:+Rotenberg_E/0/1/0/all/0/1">Eva Rotenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwiegelshohn_C/0/1/0/all/0/1">Chris Schwiegelshohn</a></p><p>We give simple algorithms for maintaining edge-orientations of a
fully-dynamic graph, such that the out-degree of each vertex is bounded. On one
hand, we show how to orient the edges such that the out-degree of each vertex
is proportional to the arboricity $\alpha$ of the graph, in a worst-case update
time of $O(\log^2 n \log \alpha)$. On the other hand, motivated by applications
in dynamic maximal matching, we obtain a different trade-off, namely the
improved worst case update time of $O(\log n \log \alpha)$ for the problem of
maintaining an edge-orientation with at most $O(\alpha + \log n)$ out-edges per
vertex. Since our algorithms have update times with worst-case guarantees, the
number of changes to the solution (i.e. the recourse) is naturally limited.
</p>
<p>Our algorithms make choices based entirely on local information, which makes
them automatically adaptive to the current arboricity of the graph. In other
words, they are arboricity-oblivious, while they are arboricity-sensitive. This
both simplifies and improves upon previous work, by having fewer assumptions or
better asymptotic guarantees.
</p>
<p>As a consequence, one obtains an algorithm with improved efficiency for
maintaining a $(1+\varepsilon)$ approximation of the maximum subgraph density,
and an algorithm for dynamic maximal matching whose worst-case update time is
guaranteed to be upper bounded by $O(\alpha + \log n\log \alpha)$, where
$\alpha$ is the arboricity at the time of the update.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14140'>Time and Energy Efficient Contention Resolution in Asynchronous Shared Channels</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Gianluca De Marco, Dariusz R. Kowalski, Grzegorz Stachowiak</p><p>A number of stations, independently activated over time, is able to
communicate by transmitting and listening to a shared channel in discrete time
slots, and a message is successfully delivered to all stations if and only if
its source station is the only transmitter at a time. Despite a vast amount of
work in the last decades, many fundamental questions remain open in the
realistic situation where stations do not start synchronously but are awaken in
arbitrary times. In this work we present a broad picture of results for the
fundamental problem of Contention resolution, in which each of the contending
stations needs to broadcast successfully its message.
</p>
<p>We show that adaptive algorithms or algorithms with the knowledge of the
contention size $k$ achieve a linear $O(k)$ message latency even if the channel
feedback is restricted to simple acknowledgements in case of successful
transmissions and in the absence of synchronization. This asymptotically
optimal performance cannot be extended to other settings: we prove that there
is no non-adaptive algorithm without the knowledge of contention size $k$
admitting latency $o(k\log k/(\log\log k)^2)$. This means, in particular, that
coding (even random) with acknowledgements is not very efficient on a shared
channel without synchronization or an estimate of the contention size. We also
present a non-adaptive algorithm with no knowledge of contention size that
almost matches the lower bound on latency.
</p>
<p>Finally, despite the absence of a collision detection mechanism, we show that
our algorithms are also efficient in terms of energy, understood as the total
number of transmissions performed by the stations during the execution.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Marco_G/0/1/0/all/0/1">Gianluca De Marco</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowalski_D/0/1/0/all/0/1">Dariusz R. Kowalski</a>, <a href="http://arxiv.org/find/cs/1/au:+Stachowiak_G/0/1/0/all/0/1">Grzegorz Stachowiak</a></p><p>A number of stations, independently activated over time, is able to
communicate by transmitting and listening to a shared channel in discrete time
slots, and a message is successfully delivered to all stations if and only if
its source station is the only transmitter at a time. Despite a vast amount of
work in the last decades, many fundamental questions remain open in the
realistic situation where stations do not start synchronously but are awaken in
arbitrary times. In this work we present a broad picture of results for the
fundamental problem of Contention resolution, in which each of the contending
stations needs to broadcast successfully its message.
</p>
<p>We show that adaptive algorithms or algorithms with the knowledge of the
contention size $k$ achieve a linear $O(k)$ message latency even if the channel
feedback is restricted to simple acknowledgements in case of successful
transmissions and in the absence of synchronization. This asymptotically
optimal performance cannot be extended to other settings: we prove that there
is no non-adaptive algorithm without the knowledge of contention size $k$
admitting latency $o(k\log k/(\log\log k)^2)$. This means, in particular, that
coding (even random) with acknowledgements is not very efficient on a shared
channel without synchronization or an estimate of the contention size. We also
present a non-adaptive algorithm with no knowledge of contention size that
almost matches the lower bound on latency.
</p>
<p>Finally, despite the absence of a collision detection mechanism, we show that
our algorithms are also efficient in terms of energy, understood as the total
number of transmissions performed by the stations during the execution.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14146'>Quantum Subroutine Composition</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Stacey Jeffery</p><p>An important tool in algorithm design is the ability to build algorithms from
other algorithms that run as subroutines. In the case of quantum algorithms, a
subroutine may be called on a superposition of different inputs, which
complicates things. For example, a classical algorithm that calls a subroutine
$Q$ times, where the average probability of querying the subroutine on input
$i$ is $p_i$, and the cost of the subroutine on input $i$ is $T_i$, incurs
expected cost $Q\sum_i p_i E[T_i]$ from all subroutine queries. While this
statement is obvious for classical algorithms, for quantum algorithms, it is
much less so, since naively, if we run a quantum subroutine on a superposition
of inputs, we need to wait for all branches of the superposition to terminate
before we can apply the next operation. We nonetheless show an analogous
quantum statement (*): If $q_i$ is the average query weight on $i$ over all
queries, the cost from all quantum subroutine queries is $Q\sum_i q_i E[T_i]$.
Here the query weight on $i$ for a particular query is the probability of
measuring $i$ in the input register if we were to measure right before the
query.
</p>
<p>We prove this result using the technique of multidimensional quantum walks,
recently introduced in arXiv:2208.13492. We present a more general version of
their quantum walk edge composition result, which yields variable-time quantum
walks, generalizing variable-time quantum search, by, for example, replacing
the update cost with $\sqrt{\sum_{u,v}\pi_u P_{u,v} E[T_{u,v}^2]}$, where
$T_{u,v}$ is the cost to move from vertex $u$ to vertex $v$. The same technique
that allows us to compose quantum subroutines in quantum walks can also be used
to compose in any quantum algorithm, which is how we prove (*).
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Jeffery_S/0/1/0/all/0/1">Stacey Jeffery</a></p><p>An important tool in algorithm design is the ability to build algorithms from
other algorithms that run as subroutines. In the case of quantum algorithms, a
subroutine may be called on a superposition of different inputs, which
complicates things. For example, a classical algorithm that calls a subroutine
$Q$ times, where the average probability of querying the subroutine on input
$i$ is $p_i$, and the cost of the subroutine on input $i$ is $T_i$, incurs
expected cost $Q\sum_i p_i E[T_i]$ from all subroutine queries. While this
statement is obvious for classical algorithms, for quantum algorithms, it is
much less so, since naively, if we run a quantum subroutine on a superposition
of inputs, we need to wait for all branches of the superposition to terminate
before we can apply the next operation. We nonetheless show an analogous
quantum statement (*): If $q_i$ is the average query weight on $i$ over all
queries, the cost from all quantum subroutine queries is $Q\sum_i q_i E[T_i]$.
Here the query weight on $i$ for a particular query is the probability of
measuring $i$ in the input register if we were to measure right before the
query.
</p>
<p>We prove this result using the technique of multidimensional quantum walks,
recently introduced in <a href="/abs/2208.13492">arXiv:2208.13492</a>. We present a more general version of
their quantum walk edge composition result, which yields variable-time quantum
walks, generalizing variable-time quantum search, by, for example, replacing
the update cost with $\sqrt{\sum_{u,v}\pi_u P_{u,v} E[T_{u,v}^2]}$, where
$T_{u,v}$ is the cost to move from vertex $u$ to vertex $v$. The same technique
that allows us to compose quantum subroutines in quantum walks can also be used
to compose in any quantum algorithm, which is how we prove (*).
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.14197'>On Computing Exact Means of Time Series Using the Move-Split-Merge Metric</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jana Holznigenkemper, Christian Komusiewicz, Bernhard Seeger</p><p>Computing an accurate mean of a set of time series is a critical task in
applications like nearest-neighbor classification and clustering of time
series. While there are many distance functions for time series, the most
popular distance function used for the computation of time series means is the
non-metric dynamic time warping (DTW) distance. A recent algorithm for the
exact computation of a DTW-Mean has a running time of
$\mathcal{O}(n^{2k+1}2^kk)$, where $k$ denotes the number of time series and
$n$ their maximum length. In this paper, we study the mean problem for the
move-split-merge (MSM) metric that not only offers high practical accuracy for
time series classification but also carries of the advantages of the metric
properties that enable further diverse applications. The main contribution of
this paper is an exact and efficient algorithm for the MSM-Mean problem of time
series. The running time of our algorithm is $\mathcal{O}(n^{k+3}2^k k^3 )$,
and thus better than the previous DTW-based algorithm. The results of an
experimental comparison confirm the running time superiority of our algorithm
in comparison to the DTW-Mean competitor. Moreover, we introduce a heuristic to
improve the running time significantly without sacrificing much accuracy.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Holznigenkemper_J/0/1/0/all/0/1">Jana Holznigenkemper</a>, <a href="http://arxiv.org/find/cs/1/au:+Komusiewicz_C/0/1/0/all/0/1">Christian Komusiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Seeger_B/0/1/0/all/0/1">Bernhard Seeger</a></p><p>Computing an accurate mean of a set of time series is a critical task in
applications like nearest-neighbor classification and clustering of time
series. While there are many distance functions for time series, the most
popular distance function used for the computation of time series means is the
non-metric dynamic time warping (DTW) distance. A recent algorithm for the
exact computation of a DTW-Mean has a running time of
$\mathcal{O}(n^{2k+1}2^kk)$, where $k$ denotes the number of time series and
$n$ their maximum length. In this paper, we study the mean problem for the
move-split-merge (MSM) metric that not only offers high practical accuracy for
time series classification but also carries of the advantages of the metric
properties that enable further diverse applications. The main contribution of
this paper is an exact and efficient algorithm for the MSM-Mean problem of time
series. The running time of our algorithm is $\mathcal{O}(n^{k+3}2^k k^3 )$,
and thus better than the previous DTW-based algorithm. The results of an
experimental comparison confirm the running time superiority of our algorithm
in comparison to the DTW-Mean competitor. Moreover, we introduce a heuristic to
improve the running time significantly without sacrificing much accuracy.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-29T00:30:00Z">Thursday, September 29 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Wednesday, September 28
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/28/phd-and-postdoc-at-irif-apply-by-november-1-2022/'>PhD and postdoc at IRIF (apply by November 1, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The Algorithms &#38; Complexity group at IRIF (CNRS, Université Paris-Cité) in Paris offers multiple PhD and postdoc positions on the theory of quantum computing. The group has expertise in quantum algorithms and quantum complexity theory, with permanent members S. Apers, I. Kerenidis, S. Laplante and F. Magniez. Soft deadline: November 1st, 2022. Website: irif.fr/en/equipes/algocomp/ Email: [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The Algorithms &amp; Complexity group at IRIF (CNRS, Université Paris-Cité) in Paris offers multiple PhD and postdoc positions on the theory of quantum computing. The group has expertise in quantum algorithms and quantum complexity theory, with permanent members S. Apers, I. Kerenidis, S. Laplante and F. Magniez.</p>
<p>Soft deadline: November 1st, 2022.</p>
<p>Website: irif.fr/en/equipes/algocomp/<br />
Email: apers@irif.fr</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T10:12:03Z">Wednesday, September 28 2022, 10:12</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13148'>Strategyproofness-Exposing Mechanism Descriptions</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Yannai A. Gonczarowski, Ori Heffetz, Clayton Thomas</p><p>A menu description defines a mechanism to player $i$ in two steps. Step (1)
uses the reports of other players to describe $i$'s menu: the set of $i$'s
potential outcomes. Step (2) uses $i$'s report to select $i$'s favorite outcome
from her menu. Can menu descriptions better expose strategyproofness, without
sacrificing simplicity? We propose a new, simple menu description of Deferred
Acceptance. We prove that -- in contrast with other common matching mechanisms
-- this menu description must differ substantially from the corresponding
traditional description. We demonstrate, with a lab experiment on two simple
mechanisms, the promise and challenges of menu descriptions.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/econ/1/au:+Gonczarowski_Y/0/1/0/all/0/1">Yannai A. Gonczarowski</a>, <a href="http://arxiv.org/find/econ/1/au:+Heffetz_O/0/1/0/all/0/1">Ori Heffetz</a>, <a href="http://arxiv.org/find/econ/1/au:+Thomas_C/0/1/0/all/0/1">Clayton Thomas</a></p><p>A menu description defines a mechanism to player $i$ in two steps. Step (1)
uses the reports of other players to describe $i$'s menu: the set of $i$'s
potential outcomes. Step (2) uses $i$'s report to select $i$'s favorite outcome
from her menu. Can menu descriptions better expose strategyproofness, without
sacrificing simplicity? We propose a new, simple menu description of Deferred
Acceptance. We prove that -- in contrast with other common matching mechanisms
-- this menu description must differ substantially from the corresponding
traditional description. We demonstrate, with a lab experiment on two simple
mechanisms, the promise and challenges of menu descriptions.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13404'>Polynomial time computable functions over the reals characterized using discrete ordinary differential equations</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Manon Blanc, Olivier Bournez</p><p>The class of functions from the integers to the integers computable in
polynomial time has been characterized recently using discrete ordinary
differential equations (ODE), also known as finite differences. In the
framework of ordinary differential equations, this is very natural to try to
extend the approach to classes of functions over the reals, and not only over
the integers. Recently, an extension of previous characterization was obtained
for functions from the integers to the reals, but the method used in the proof,
based on the existence of a continuous function from the integers to a suitable
discrete set of reals, cannot extend to functions from the reals to the reals,
as such a function cannot exist for clear topological reasons. In this article,
we prove that this is indeed possible to provide an elegant and simple
algebraic characterization of functions from the reals to the reals: we provide
a characterization of such functions as the smallest class of functions that
contains some basic functions, and that is closed by composition, linear length
ODEs, and a natural effective limit schema. This is obtained using an
alternative proof technique based on the construction of specific suitable
functions defined recursively, and a barycentric method. Furthermore, we also
extend previous characterizations in several directions: First, we prove that
there is no need of multiplication. We prove a normal form theorem, with a nice
side effect related to formal neural networks. Indeed, given some fixed error
and some polynomial time t(n), our settings produce effectively some neural
network that computes the function over its domain with the given precision,
for any t(n)-polynomial time computable function f .
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blanc_M/0/1/0/all/0/1">Manon Blanc</a>, <a href="http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1">Olivier Bournez</a></p><p>The class of functions from the integers to the integers computable in
polynomial time has been characterized recently using discrete ordinary
differential equations (ODE), also known as finite differences. In the
framework of ordinary differential equations, this is very natural to try to
extend the approach to classes of functions over the reals, and not only over
the integers. Recently, an extension of previous characterization was obtained
for functions from the integers to the reals, but the method used in the proof,
based on the existence of a continuous function from the integers to a suitable
discrete set of reals, cannot extend to functions from the reals to the reals,
as such a function cannot exist for clear topological reasons. In this article,
we prove that this is indeed possible to provide an elegant and simple
algebraic characterization of functions from the reals to the reals: we provide
a characterization of such functions as the smallest class of functions that
contains some basic functions, and that is closed by composition, linear length
ODEs, and a natural effective limit schema. This is obtained using an
alternative proof technique based on the construction of specific suitable
functions defined recursively, and a barycentric method. Furthermore, we also
extend previous characterizations in several directions: First, we prove that
there is no need of multiplication. We prove a normal form theorem, with a nice
side effect related to formal neural networks. Indeed, given some fixed error
and some polynomial time t(n), our settings produce effectively some neural
network that computes the function over its domain with the given precision,
for any t(n)-polynomial time computable function f .
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13024'>Improved and Generalized Algorithms for Burning a Planar Point Set</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Prashant Gokhale, J. Mark Keil, Debajyoti Mondal</p><p>Given a set $P$ of points in the plane, a point burning process is a discrete
time process to burn all the points of $P$ where fires must be initiated at the
given points. Specifically, the point burning process starts with a single
burnt point from $P$, and at each subsequent step, burns all the points in the
plane that are within one unit distance from the currently burnt points, as
well as one other unburnt point of $P$ (if exists). The point burning number of
$P$ is the smallest number of steps required to burn all the points of $P$. If
we allow the fire to be initiated anywhere, then the burning process is called
an anywhere burning process, and the corresponding burning number is called
anywhere burning number. Computing the point and anywhere burning number is
known to be NP-hard. In this paper we show that both these problems admit PTAS
in one dimension. We then show that in two dimensions, point burning and
anywhere burning are $(1.96296+\varepsilon)$ and $(1.92188+\varepsilon)$
approximable, respectively, for every $\varepsilon&gt;0$, which improves the
previously known $(2+\varepsilon)$ factor for these problems. We also observe
that a known result on set cover problem can be leveraged to obtain a
2-approximation for burning the maximum number of points in a given number of
steps. We show how the results generalize if we allow the points to have
different fire spreading rates. Finally, we prove that even if the burning
sources are given as input, finding a point burning sequence itself is NP-hard.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Gokhale_P/0/1/0/all/0/1">Prashant Gokhale</a>, <a href="http://arxiv.org/find/cs/1/au:+Keil_J/0/1/0/all/0/1">J. Mark Keil</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1">Debajyoti Mondal</a></p><p>Given a set $P$ of points in the plane, a point burning process is a discrete
time process to burn all the points of $P$ where fires must be initiated at the
given points. Specifically, the point burning process starts with a single
burnt point from $P$, and at each subsequent step, burns all the points in the
plane that are within one unit distance from the currently burnt points, as
well as one other unburnt point of $P$ (if exists). The point burning number of
$P$ is the smallest number of steps required to burn all the points of $P$. If
we allow the fire to be initiated anywhere, then the burning process is called
an anywhere burning process, and the corresponding burning number is called
anywhere burning number. Computing the point and anywhere burning number is
known to be NP-hard. In this paper we show that both these problems admit PTAS
in one dimension. We then show that in two dimensions, point burning and
anywhere burning are $(1.96296+\varepsilon)$ and $(1.92188+\varepsilon)$
approximable, respectively, for every $\varepsilon&gt;0$, which improves the
previously known $(2+\varepsilon)$ factor for these problems. We also observe
that a known result on set cover problem can be leveraged to obtain a
2-approximation for burning the maximum number of points in a given number of
steps. We show how the results generalize if we allow the points to have
different fire spreading rates. Finally, we prove that even if the burning
sources are given as input, finding a point burning sequence itself is NP-hard.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13311'>Optimal Placement of Base Stations in Border Surveillance using Limited Capacity Drones</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: S. Bereg, J.M. D&#xed;az-B&#xe1;&#xf1;ez, M. Haghpanah, P. Horn, M.A. Lopez, N. Mar&#xed;n, A. Ram&#xed;rez-Vigueras, F. Rodr&#xed;guez, O. Sol&#xe9;-Pi, A. Stevens, J. Urrutia</p><p>Imagine an island modeled as a simple polygon $\P$ with $n$ vertices whose
coastline we wish to monitor. We consider the problem of building the minimum
number of refueling stations along the boundary of $\P$ in such a way that a
drone can follow a polygonal route enclosing the island without running out of
fuel. A drone can fly a maximum distance $d$ between consecutive stations and
is restricted to move either along the boundary of $\P$ or its exterior (i.e.,
over water). We present an algorithm that, given $\mathcal P$, finds the
locations for a set of refueling stations whose cardinality is at most the
optimal plus one. The time complexity of this algorithm is $O(n^2 + \frac{L}{d}
n)$, where $L$ is the length of $\mathcal P$. We also present an algorithm that
returns an additive $\epsilon$-approximation for the problem of minimizing the
fuel capacity required for the drones when we are allowed to place $k$ base
stations around the boundary of the island; this algorithm also finds the
locations of these refueling stations. Finally, we propose a practical
discretization heuristic which, under certain conditions, can be used to
certify optimality of the results.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bereg_S/0/1/0/all/0/1">S. Bereg</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1">J.M. D&#xed;az-B&#xe1;&#xf1;ez</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghpanah_M/0/1/0/all/0/1">M. Haghpanah</a>, <a href="http://arxiv.org/find/cs/1/au:+Horn_P/0/1/0/all/0/1">P. Horn</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_M/0/1/0/all/0/1">M.A. Lopez</a>, <a href="http://arxiv.org/find/cs/1/au:+Marin_N/0/1/0/all/0/1">N. Mar&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramirez_Vigueras_A/0/1/0/all/0/1">A. Ram&#xed;rez-Vigueras</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_F/0/1/0/all/0/1">F. Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Sole_Pi_O/0/1/0/all/0/1">O. Sol&#xe9;-Pi</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevens_A/0/1/0/all/0/1">A. Stevens</a>, <a href="http://arxiv.org/find/cs/1/au:+Urrutia_J/0/1/0/all/0/1">J. Urrutia</a></p><p>Imagine an island modeled as a simple polygon $\P$ with $n$ vertices whose
coastline we wish to monitor. We consider the problem of building the minimum
number of refueling stations along the boundary of $\P$ in such a way that a
drone can follow a polygonal route enclosing the island without running out of
fuel. A drone can fly a maximum distance $d$ between consecutive stations and
is restricted to move either along the boundary of $\P$ or its exterior (i.e.,
over water). We present an algorithm that, given $\mathcal P$, finds the
locations for a set of refueling stations whose cardinality is at most the
optimal plus one. The time complexity of this algorithm is $O(n^2 + \frac{L}{d}
n)$, where $L$ is the length of $\mathcal P$. We also present an algorithm that
returns an additive $\epsilon$-approximation for the problem of minimizing the
fuel capacity required for the drones when we are allowed to place $k$ base
stations around the boundary of the island; this algorithm also finds the
locations of these refueling stations. Finally, we propose a practical
discretization heuristic which, under certain conditions, can be used to
certify optimality of the results.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13538'>Mathematics and Flamenco: An Unexpected Partnership</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jos&#xe9;-Miguel D&#xed;az-B&#xe1;&#xf1;ez</p><p>In this paper, we present a series of mathematical problems which throw
interesting lights on flamenco music. More specifically, these are problems in
discrete and computational mathematics suggested by an analytical (not
compositional) examination of flamenco ``cante'' (singing). As a consequence,
since the problems are taken from a culturally specific context, the examples
can make more effective mathematics education.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Diaz_Banez_J/0/1/0/all/0/1">Jos&#xe9;-Miguel D&#xed;az-B&#xe1;&#xf1;ez</a></p><p>In this paper, we present a series of mathematical problems which throw
interesting lights on flamenco music. More specifically, these are problems in
discrete and computational mathematics suggested by an analytical (not
compositional) examination of flamenco ``cante'' (singing). As a consequence,
since the problems are taken from a culturally specific context, the examples
can make more effective mathematics education.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13028'>How to Sample From The Limiting Distribution of a Continuous-Time Quantum Walk</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Javad Doliskani</p><p>We introduce $\varepsilon$-projectors, using which we can sample from
limiting distributions of continuous-time quantum walks. The standard algorithm
for sampling from a distribution that is close to the limiting distribution of
a given quantum walk is to run the quantum walk for a time chosen uniformly at
random from a large interval, and measure the resulting quantum state. This
approach usually results in an exponential running time.
</p>
<p>We show that, using $\varepsilon$-projectors, we can sample exactly from the
limiting distribution. In the black-box setting, where we only have query
access to the adjacency matrix of the graph, our sampling algorithm runs in
time proportional to $\Delta^{-1}$, where $\Delta$ is the minimum spacing
between the distinct eigenvalues of the graph. In the non-black-box setting, we
give examples of graphs for which our algorithm runs exponentially faster than
the standard sampling algorithm.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Doliskani_J/0/1/0/all/0/1">Javad Doliskani</a></p><p>We introduce $\varepsilon$-projectors, using which we can sample from
limiting distributions of continuous-time quantum walks. The standard algorithm
for sampling from a distribution that is close to the limiting distribution of
a given quantum walk is to run the quantum walk for a time chosen uniformly at
random from a large interval, and measure the resulting quantum state. This
approach usually results in an exponential running time.
</p>
<p>We show that, using $\varepsilon$-projectors, we can sample exactly from the
limiting distribution. In the black-box setting, where we only have query
access to the adjacency matrix of the graph, our sampling algorithm runs in
time proportional to $\Delta^{-1}$, where $\Delta$ is the minimum spacing
between the distinct eigenvalues of the graph. In the non-black-box setting, we
give examples of graphs for which our algorithm runs exponentially faster than
the standard sampling algorithm.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13063'>Quantum-Inspired Perfect Matching under Vertex-Color Constraints</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Moshe Y. Vardi, Zhiwei Zhang</p><p>We propose and study the graph-theoretical problem PM-VC: perfect matching
under vertex-color constraints on graphs with bi-colored edges. PM-VC is of
special interest because of its motivation from quantum-state identification
and quantum-experiment design, as well as its rich expressiveness, i.e., PM-VC
subsumes many constrained matching problems naturally, such as exact perfect
matching. We give complexity and algorithmic results for PM-VC under two types
of vertex color constraints: 1) symmetric constraints (PM-VC-Sym) and 2)
decision-diagram constraints (PM-VC-DD).
</p>
<p>We prove that PM-VC-Sym is in RNC via a symbolic determinant algorithm, which
can be derandomized on planar graphs. Moreover, PM-VC-Sym can be expressed in
extended MSO, which encourages our design of an efficient dynamic programming
algorithm for PM-VC-Sym on bounded-treewidth graphs. For PM-VC-DD, we reveal
its NP-hardness by a graph-gadget technique. Our novel results for PM-VC
provide insights to both constrained matching and scalable quantum experiment
design.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1">Moshe Y. Vardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a></p><p>We propose and study the graph-theoretical problem PM-VC: perfect matching
under vertex-color constraints on graphs with bi-colored edges. PM-VC is of
special interest because of its motivation from quantum-state identification
and quantum-experiment design, as well as its rich expressiveness, i.e., PM-VC
subsumes many constrained matching problems naturally, such as exact perfect
matching. We give complexity and algorithmic results for PM-VC under two types
of vertex color constraints: 1) symmetric constraints (PM-VC-Sym) and 2)
decision-diagram constraints (PM-VC-DD).
</p>
<p>We prove that PM-VC-Sym is in RNC via a symbolic determinant algorithm, which
can be derandomized on planar graphs. Moreover, PM-VC-Sym can be expressed in
extended MSO, which encourages our design of an efficient dynamic programming
algorithm for PM-VC-Sym on bounded-treewidth graphs. For PM-VC-DD, we reveal
its NP-hardness by a graph-gadget technique. Our novel results for PM-VC
provide insights to both constrained matching and scalable quantum experiment
design.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13134'>An $O(3.82^k)$ Time FPT Algorithm for Convex Flip Distance</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Haohong Li, Ge Xia</p><p>Let ${\cal P}$ be a convex polygon in the plane, and let ${\cal T}$ be a
triangulation of ${\cal P}$. An edge $e$ in ${\cal T}$ is called a diagonal if
it is shared by two triangles in ${\cal T}$. A {\em flip} of a diagonal $e$ is
the operation of removing $e$ and adding the opposite diagonal of the resulting
quadrilateral to obtain a new triangulation of ${\cal P}$ from ${\cal T}$. The
{\em flip distance} between two triangulations of ${\cal P}$ is the minimum
number of flips needed to transform one triangulation into the other. The {\sc
Convex Flip Distance} problem asks if the flip distance between two given
triangulations of ${\cal P}$ is at most $k$, for some given parameter $k$.
</p>
<p>We present an FPT algorithm for the {\sc Convex Flip Distance} problem that
runs in time $O(3.82^{k})$ and uses polynomial space, where $k$ is the number
of flips. This algorithm significantly improves the previous best FPT
algorithms for the problem.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haohong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1">Ge Xia</a></p><p>Let ${\cal P}$ be a convex polygon in the plane, and let ${\cal T}$ be a
triangulation of ${\cal P}$. An edge $e$ in ${\cal T}$ is called a diagonal if
it is shared by two triangles in ${\cal T}$. A {\em flip} of a diagonal $e$ is
the operation of removing $e$ and adding the opposite diagonal of the resulting
quadrilateral to obtain a new triangulation of ${\cal P}$ from ${\cal T}$. The
{\em flip distance} between two triangulations of ${\cal P}$ is the minimum
number of flips needed to transform one triangulation into the other. The {\sc
Convex Flip Distance} problem asks if the flip distance between two given
triangulations of ${\cal P}$ is at most $k$, for some given parameter $k$.
</p>
<p>We present an FPT algorithm for the {\sc Convex Flip Distance} problem that
runs in time $O(3.82^{k})$ and uses polynomial space, where $k$ is the number
of flips. This algorithm significantly improves the previous best FPT
algorithms for the problem.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13175'>Partial and Simultaneous Transitive Orientations via Modular Decomposition</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Miriam M&#xfc;nch, Ignaz Rutter, Peter Stumpf</p><p>A natural generalization of the recognition problem for a geometric graph
class is the problem of extending a representation of a subgraph to a
representation of the whole graph. A related problem is to find representations
for multiple input graphs that coincide on subgraphs shared by the input
graphs. A common restriction is the sunflower case where the shared graph is
the same for each pair of input graphs. These problems translate to the setting
of comparability graphs where the representations correspond to transitive
orientations of their edges. We use modular decompositions to improve the
runtime for the orientation extension problem and the sunflower orientation
problem to linear time. We apply these results to improve the runtime for the
partial representation problem and the sunflower case of the simultaneous
representation problem for permutation graphs to linear time. We also give the
first efficient algorithms for these problems on circular permutation graphs.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Munch_M/0/1/0/all/0/1">Miriam M&#xfc;nch</a>, <a href="http://arxiv.org/find/cs/1/au:+Rutter_I/0/1/0/all/0/1">Ignaz Rutter</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpf_P/0/1/0/all/0/1">Peter Stumpf</a></p><p>A natural generalization of the recognition problem for a geometric graph
class is the problem of extending a representation of a subgraph to a
representation of the whole graph. A related problem is to find representations
for multiple input graphs that coincide on subgraphs shared by the input
graphs. A common restriction is the sunflower case where the shared graph is
the same for each pair of input graphs. These problems translate to the setting
of comparability graphs where the representations correspond to transitive
orientations of their edges. We use modular decompositions to improve the
runtime for the orientation extension problem and the sunflower orientation
problem to linear time. We apply these results to improve the runtime for the
partial representation problem and the sunflower case of the simultaneous
representation problem for permutation graphs to linear time. We also give the
first efficient algorithms for these problems on circular permutation graphs.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.13355'>Algorithms for Large-scale Network Analysis and the NetworKit Toolkit</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Eugenio Angriman, Alexander van der Grinten, Michael Hamann, Henning Meyerhenke, Manuel Penschuck</p><p>The abundance of massive network data in a plethora of applications makes
scalable analysis algorithms and software tools necessary to generate knowledge
from such data in reasonable time. Addressing scalability as well as other
requirements such as good usability and a rich feature set, the open-source
software NetworKit has established itself as a popular tool for large-scale
network analysis. This chapter provides a brief overview of the contributions
to NetworKit made by the DFG Priority Programme SPP 1736 Algorithms for Big
Data. Algorithmic contributions in the areas of centrality computations,
community detection, and sparsification are in the focus, but we also mention
several other aspects -- such as current software engineering principles of the
project and ways to visualize network data within a NetworKit-based workflow.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Angriman_E/0/1/0/all/0/1">Eugenio Angriman</a>, <a href="http://arxiv.org/find/cs/1/au:+Grinten_A/0/1/0/all/0/1">Alexander van der Grinten</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamann_M/0/1/0/all/0/1">Michael Hamann</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyerhenke_H/0/1/0/all/0/1">Henning Meyerhenke</a>, <a href="http://arxiv.org/find/cs/1/au:+Penschuck_M/0/1/0/all/0/1">Manuel Penschuck</a></p><p>The abundance of massive network data in a plethora of applications makes
scalable analysis algorithms and software tools necessary to generate knowledge
from such data in reasonable time. Addressing scalability as well as other
requirements such as good usability and a rich feature set, the open-source
software NetworKit has established itself as a popular tool for large-scale
network analysis. This chapter provides a brief overview of the contributions
to NetworKit made by the DFG Priority Programme SPP 1736 Algorithms for Big
Data. Algorithmic contributions in the areas of centrality computations,
community detection, and sparsification are in the focus, but we also mention
several other aspects -- such as current software engineering principles of the
project and ways to visualize network data within a NetworKit-based workflow.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-28T00:30:00Z">Wednesday, September 28 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Tuesday, September 27
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://blog.simons.berkeley.edu/2022/09/the-blooming-of-the-c3-ltc-flowers/'>The Blooming of the \(c^3\) LTC Flowers</a></h3>
          <p class='item-feed'>from <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          by Prahladh Harsha The last year (2021–22) has seen some amazing new constructions of locally testable codes with constant rate and constant fractional distance and testable with a constant number of queries, sometimes referred to as \(c^3\) LTCs [DELLM22, PK22]. &#8230; Continue reading &#8594;<p>By Simons Institute Editor</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          by Prahladh Harsha The last year (2021–22) has seen some amazing new constructions of locally testable codes with constant rate and constant fractional distance and testable with a constant number of queries, sometimes referred to as \(c^3\) LTCs [DELLM22, PK22]. &#8230; <a href="https://blog.simons.berkeley.edu/2022/09/the-blooming-of-the-c3-ltc-flowers/">Continue reading <span class="meta-nav">&#8594;</span></a><p class="authors">By Simons Institute Editor</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T17:51:01Z">Tuesday, September 27 2022, 17:51</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/09/27/postdoc-in-quantum-algorithms-complexity-at-university-of-warwick-apply-by-october-18-2022/'>Postdoc in Quantum Algorithms & Complexity at University of Warwick (apply by October 18, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We seek to appoint a postdoc for 24 months starting in March 2023 or as soon as possible thereafter. The aim is to study property testing algorithms for quantum channels as part of a collaboration between CS &#38; Physics at Warwick, led by Animesh Datta and Tom Gur. For informal enquires, email your CV, explaining [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>We seek to appoint a postdoc for 24 months starting in March 2023 or as soon as possible thereafter. The aim is to study property testing algorithms for quantum channels as part of a collaboration between CS &amp; Physics at Warwick, led by Animesh Datta and Tom Gur.</p>
<p>For informal enquires, email your CV, explaining your suitability for the position.</p>
<p>Website: <a href="https://atsv7.wcn.co.uk/search_engine/jobs.cgi?owner=5062452&amp;ownertype=fair&amp;jcode=1888004&amp;vt_template=1457&amp;adminview=1">https://atsv7.wcn.co.uk/search_engine/jobs.cgi?owner=5062452&amp;ownertype=fair&amp;jcode=1888004&amp;vt_template=1457&amp;adminview=1</a><br />
Email: animesh.datta@warwick.ac.uk; tom.gur@warwick.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T15:22:22Z">Tuesday, September 27 2022, 15:22</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/137'>TR22-137 |  On blocky ranks of matrices | 

	Daniel Avraham , 

	Amir Yehudayoff</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          A matrix is blocky if it is a blowup of a permutation matrix. The blocky rank of a matrix M is the minimum number of blocky matrices that linearly span M. Hambardzumyan, Hatami and Hatami defined blocky rank and showed that it is connected to communication complexity and operator theory. We describe additional connections to circuit complexity and combinatorics, and we prove upper and lower bounds on blocky rank in various contexts.
        
        </div>

        <div class='item-content item-summary'>
        
          
          A matrix is blocky if it is a blowup of a permutation matrix. The blocky rank of a matrix M is the minimum number of blocky matrices that linearly span M. Hambardzumyan, Hatami and Hatami defined blocky rank and showed that it is connected to communication complexity and operator theory. We describe additional connections to circuit complexity and combinatorics, and we prove upper and lower bounds on blocky rank in various contexts.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T12:24:21Z">Tuesday, September 27 2022, 12:24</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://blog.computationalcomplexity.org/2022/09/is-complexity-of-vertex-cover-of-degree.html'>Is the complexity of approximating Vertex Cover of degree 3 open? (ADDED LATER-NO)</a></h3>
          <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>&nbsp;RECALL:</p><p>A max-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \ge (1-\epsilon)f(x).</p><p><br></p><p>A min-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \le (1+\epsilon)f(x).</p><p><br></p><p>(Note that the poly can depend on epsilon so it may be something like n^{1/epsilon}.)</p><p><br></p><p>MAX3SAT is, given a formula with \le 3 literals per clause, find an assignment</p><p>that maximized the number of clauses satisfied.</p><p><br></p><p>VCB-a is Vertex cover where graphs have degree \le a</p><p><br></p><p>The following are known:</p><p>0) MAX3SAT is in APX.</p><p>1) The PCP paper,&nbsp;here, showed that if MAX3SAT has a PTAS then P=NP.</p><p>2) Papadimitriou and Yannakakis (here)&nbsp; had showed much earlier that MAX3SAT \le VCB-4 with an approx preserving reduction.</p><p>3) From (1) and (2) we have that VCB-4 has a PTAS then P=NP. (VC is in APX by an easy 2-approx).</p><p>4) Clearly VCB-2 is in P.</p><p>The following seems to be open, though if you know otherwise pleae leave a comment:</p><p><br></p><p>Is VCB-3 a) in P? b) NPC? (ADDED LATER- NPC- See comments.)&nbsp;</p><p>Is the following true: if VCB-3 has a PTAS then P=NP. (ADDED LATER- NO PTAS-See Comments)</p><p><br></p><p>NOTE- all of the above is true for Ind Set-4 and Dom Set-4. So that leads to more open problems.</p><br><p>By gasarch</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>&nbsp;RECALL:</p><p>A max-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \ge (1-\epsilon)f(x).</p><p><br /></p><p>A min-problem f has a A P Time App Scheme (PTAS) if there is an algorithm ALG such that</p><p>&nbsp;ALG(\epsilon) \le (1+\epsilon)f(x).</p><p><br /></p><p>(Note that the poly can depend on epsilon so it may be something like n^{1/epsilon}.)</p><p><br /></p><p>MAX3SAT is, given a formula with \le 3 literals per clause, find an assignment</p><p>that maximized the number of clauses satisfied.</p><p><br /></p><p>VCB-a is Vertex cover where graphs have degree \le a</p><p><br /></p><p>The following are known:</p><p>0) MAX3SAT is in APX.</p><p>1) The PCP paper,&nbsp;<a href="https://doi.org/10.1145/278298.278306">here</a>, showed that if MAX3SAT has a PTAS then P=NP.</p><p>2) Papadimitriou and Yannakakis (<a href="https://doi.org/10.1016/0022-0000(91)90023-X">here</a>)&nbsp; had showed much earlier that MAX3SAT \le VCB-4 with an approx preserving reduction.</p><p>3) From (1) and (2) we have that VCB-4 has a PTAS then P=NP. (VC is in APX by an easy 2-approx).</p><p>4) Clearly VCB-2 is in P.</p><p>The following seems to be open, though if you know otherwise pleae leave a comment:</p><p><br /></p><p>Is VCB-3 a) in P? b) NPC? (ADDED LATER- NPC- See comments.)&nbsp;</p><p>Is the following true: if VCB-3 has a PTAS then P=NP. (ADDED LATER- NO PTAS-See Comments)</p><p><br /></p><p>NOTE- all of the above is true for Ind Set-4 and Dom Set-4. So that leads to more open problems.</p><div><br /></div><p class="authors">By gasarch</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T02:02:00Z">Tuesday, September 27 2022, 02:02</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12168'>A characterization of functions over the integers computable in polynomial time using discrete differential equations</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Olivier Bournez, Arnaud Durand</p><p>This paper studies the expressive and computational power of discrete
Ordinary Differential Equations (ODEs), a.k.a. (Ordinary) Difference Equations.
It presents a new framework using these equations as a central tool for
computation and algorithm design. We present the general theory of discrete
ODEs for computation theory, we illustrate this with various examples of
algorithms, and we provide several implicit characterizations of complexity and
computability classes.
</p>
<p>The proposed framework presents an original point of view on complexity and
computation classes. It unifies several constructions that have been proposed
for characterizing these classes including classical approaches in implicit
complexity using restricted recursion schemes, as well as recent
characterizations of computability and complexity by classes of continuous
ordinary differential equations. It also helps understanding the relationships
between analog computations and classical discrete models of computation
theory.
</p>
<p>At a more technical point of view, this paper points out the fundamental role
of linear (discrete) ODEs and classical ODE tools such as changes of variables
to capture computability and complexity measures, or as a tool for programming
many algorithms.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bournez_O/0/1/0/all/0/1">Olivier Bournez</a>, <a href="http://arxiv.org/find/cs/1/au:+Durand_A/0/1/0/all/0/1">Arnaud Durand</a></p><p>This paper studies the expressive and computational power of discrete
Ordinary Differential Equations (ODEs), a.k.a. (Ordinary) Difference Equations.
It presents a new framework using these equations as a central tool for
computation and algorithm design. We present the general theory of discrete
ODEs for computation theory, we illustrate this with various examples of
algorithms, and we provide several implicit characterizations of complexity and
computability classes.
</p>
<p>The proposed framework presents an original point of view on complexity and
computation classes. It unifies several constructions that have been proposed
for characterizing these classes including classical approaches in implicit
complexity using restricted recursion schemes, as well as recent
characterizations of computability and complexity by classes of continuous
ordinary differential equations. It also helps understanding the relationships
between analog computations and classical discrete models of computation
theory.
</p>
<p>At a more technical point of view, this paper points out the fundamental role
of linear (discrete) ODEs and classical ODE tools such as changes of variables
to capture computability and complexity measures, or as a tool for programming
many algorithms.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11817'>An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Matthew Jones, Huy L&#xea; Nguyen, Thy Nguyen</p><p>Recently a multi-agent variant of the classical multi-armed bandit was
proposed to tackle fairness issues in online learning. Inspired by a long line
of work in social choice and economics, the goal is to optimize the Nash social
welfare instead of the total utility. Unfortunately previous algorithms either
are not efficient or achieve sub-optimal regret in terms of the number of
rounds $T$. We propose a new efficient algorithm with lower regret than even
previous inefficient ones. For $N$ agents, $K$ arms, and $T$ rounds, our
approach has a regret bound of $\tilde{O}(\sqrt{NKT} + NK)$. This is an
improvement to the previous approach, which has regret bound of $\tilde{O}(
\min(NK, \sqrt{N} K^{3/2})\sqrt{T})$. We also complement our efficient
algorithm with an inefficient approach with $\tilde{O}(\sqrt{KT} + N^2K)$
regret. The experimental findings confirm the effectiveness of our efficient
algorithm compared to the previous approaches.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1">Matthew Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huy L&#xea; Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thy Nguyen</a></p><p>Recently a multi-agent variant of the classical multi-armed bandit was
proposed to tackle fairness issues in online learning. Inspired by a long line
of work in social choice and economics, the goal is to optimize the Nash social
welfare instead of the total utility. Unfortunately previous algorithms either
are not efficient or achieve sub-optimal regret in terms of the number of
rounds $T$. We propose a new efficient algorithm with lower regret than even
previous inefficient ones. For $N$ agents, $K$ arms, and $T$ rounds, our
approach has a regret bound of $\tilde{O}(\sqrt{NKT} + NK)$. This is an
improvement to the previous approach, which has regret bound of $\tilde{O}(
\min(NK, \sqrt{N} K^{3/2})\sqrt{T})$. We also complement our efficient
algorithm with an inefficient approach with $\tilde{O}(\sqrt{KT} + N^2K)$
regret. The experimental findings confirm the effectiveness of our efficient
algorithm compared to the previous approaches.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11934'>The Online Knapsack Problem with Departures</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Bo Sun, Lin Yang, Mohammad Hajiesmaili, Adam Wierman, John C.S. Lui, Don Towsley, Danny H.K. Tsang</p><p>The online knapsack problem is a classic online resource allocation problem
in networking and operations research. Its basic version studies how to pack
online arriving items of different sizes and values into a capacity-limited
knapsack. In this paper, we study a general version that includes item
departures, while also considering multiple knapsacks and multi-dimensional
item sizes. We design a threshold-based online algorithm and prove that the
algorithm can achieve order-optimal competitive ratios. Beyond worst-case
performance guarantees, we also aim to achieve near-optimal average performance
under typical instances. Towards this goal, we propose a data-driven online
algorithm that learns within a policy-class that guarantees a worst-case
performance bound. In trace-driven experiments, we show that our data-driven
algorithm outperforms other benchmark algorithms in an application of online
knapsack to job scheduling for cloud computing.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Bo Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1">Mohammad Hajiesmaili</a>, <a href="http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1">Adam Wierman</a>, <a href="http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1">John C.S. Lui</a>, <a href="http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1">Don Towsley</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsang_D/0/1/0/all/0/1">Danny H.K. Tsang</a></p><p>The online knapsack problem is a classic online resource allocation problem
in networking and operations research. Its basic version studies how to pack
online arriving items of different sizes and values into a capacity-limited
knapsack. In this paper, we study a general version that includes item
departures, while also considering multiple knapsacks and multi-dimensional
item sizes. We design a threshold-based online algorithm and prove that the
algorithm can achieve order-optimal competitive ratios. Beyond worst-case
performance guarantees, we also aim to achieve near-optimal average performance
under typical instances. Towards this goal, we propose a data-driven online
algorithm that learns within a policy-class that guarantees a worst-case
performance bound. In trace-driven experiments, we show that our data-driven
algorithm outperforms other benchmark algorithms in an application of online
knapsack to job scheduling for cloud computing.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11936'>Online Admission Control and Rebalancing in Payment Channel Networks</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mahsa Bastankhah, Krishnendu Chatterjee, Mohammad Ali Maddah-Ali, Stefan Schmid, Jakub Svoboda, Michelle Yeo</p><p>Payment channel networks (PCNs) are a promising technology to improve the
scalability of cryptocurrencies. PCNs, however, face the challenge that the
frequent usage of certain routes may deplete channels in one direction, and
hence prevent further transactions. In order to reap the full potential of
PCNs, recharging and rebalancing mechanisms are required to provision channels,
as well as an admission control logic to decide which transactions to reject in
case capacity is insufficient. This paper presents a formal model of this
optimisation problem. In particular, we consider an online algorithms
perspective, where transactions arrive over time in an unpredictable manner.
Our main contributions are competitive online algorithms which come with
provable guarantees over time. We empirically evaluate our algorithms on
randomly generated transactions to compare the average performance of our
algorithms to our theoretical bounds. We also show how this model and approach
differs from related problems in classic communication networks.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bastankhah_M/0/1/0/all/0/1">Mahsa Bastankhah</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_K/0/1/0/all/0/1">Krishnendu Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddah_Ali_M/0/1/0/all/0/1">Mohammad Ali Maddah-Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1">Stefan Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Svoboda_J/0/1/0/all/0/1">Jakub Svoboda</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_M/0/1/0/all/0/1">Michelle Yeo</a></p><p>Payment channel networks (PCNs) are a promising technology to improve the
scalability of cryptocurrencies. PCNs, however, face the challenge that the
frequent usage of certain routes may deplete channels in one direction, and
hence prevent further transactions. In order to reap the full potential of
PCNs, recharging and rebalancing mechanisms are required to provision channels,
as well as an admission control logic to decide which transactions to reject in
case capacity is insufficient. This paper presents a formal model of this
optimisation problem. In particular, we consider an online algorithms
perspective, where transactions arrive over time in an unpredictable manner.
Our main contributions are competitive online algorithms which come with
provable guarantees over time. We empirically evaluate our algorithms on
randomly generated transactions to compare the average performance of our
algorithms to our theoretical bounds. We also show how this model and approach
differs from related problems in classic communication networks.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12013'>Non-monotonic Resource Utilization in the Bandits with Knapsacks Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Raunak Kumar, Robert Kleinberg</p><p>Bandits with knapsacks (BwK) is an influential model of sequential
decision-making under uncertainty that incorporates resource consumption
constraints. In each round, the decision-maker observes an outcome consisting
of a reward and a vector of nonnegative resource consumptions, and the budget
of each resource is decremented by its consumption. In this paper we introduce
a natural generalization of the stochastic BwK problem that allows
non-monotonic resource utilization. In each round, the decision-maker observes
an outcome consisting of a reward and a vector of resource drifts that can be
positive, negative or zero, and the budget of each resource is incremented by
its drift. Our main result is a Markov decision process (MDP) policy that has
constant regret against a linear programming (LP) relaxation when the
decision-maker knows the true outcome distributions. We build upon this to
develop a learning algorithm that has logarithmic regret against the same LP
relaxation when the decision-maker does not know the true outcome
distributions. We also present a reduction from BwK to our model that shows our
regret bound matches existing results.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Raunak Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_R/0/1/0/all/0/1">Robert Kleinberg</a></p><p>Bandits with knapsacks (BwK) is an influential model of sequential
decision-making under uncertainty that incorporates resource consumption
constraints. In each round, the decision-maker observes an outcome consisting
of a reward and a vector of nonnegative resource consumptions, and the budget
of each resource is decremented by its consumption. In this paper we introduce
a natural generalization of the stochastic BwK problem that allows
non-monotonic resource utilization. In each round, the decision-maker observes
an outcome consisting of a reward and a vector of resource drifts that can be
positive, negative or zero, and the budget of each resource is incremented by
its drift. Our main result is a Markov decision process (MDP) policy that has
constant regret against a linear programming (LP) relaxation when the
decision-maker knows the true outcome distributions. We build upon this to
develop a learning algorithm that has logarithmic regret against the same LP
relaxation when the decision-maker does not know the true outcome
distributions. We also present a reduction from BwK to our model that shows our
regret bound matches existing results.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12021'>Improving the Bounds of the Online Dynamic Power Management Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Ya-Chun Liang, Kazuo Iwama, Chung-Shou Liao</p><p>We investigate the {\em power-down mechanism} which decides when a machine
transitions between states such that the total energy consumption,
characterized by execution cost, idle cost and switching cost, is minimized. In
contrast to most of the previous studies on the offline model, we focus on the
online model in which a sequence of jobs with their release time, execution
time and deadline, arrive in an online fashion. More precisely, we exploit a
different switching on and off strategy and present an upper bound of 3, and
further show a lower bound of 2.1, in a dual-machine model, introduced by Chen
et al. in 2014 [STACS 2014: 226-238], both of which beat the currently best
result.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Ya-Chun Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwama_K/0/1/0/all/0/1">Kazuo Iwama</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1">Chung-Shou Liao</a></p><p>We investigate the {\em power-down mechanism} which decides when a machine
transitions between states such that the total energy consumption,
characterized by execution cost, idle cost and switching cost, is minimized. In
contrast to most of the previous studies on the offline model, we focus on the
online model in which a sequence of jobs with their release time, execution
time and deadline, arrive in an online fashion. More precisely, we exploit a
different switching on and off strategy and present an upper bound of 3, and
further show a lower bound of 2.1, in a dual-machine model, introduced by Chen
et al. in 2014 [STACS 2014: 226-238], both of which beat the currently best
result.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12023'>Twin-width V: linear minors, modular counting, and matrix multiplication</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: &#xc9;douard Bonnet, Ugo Giocanti, Patrice Ossona de Mendez, St&#xe9;phan Thomass&#xe9;</p><p>We continue developing the theory around the twin-width of totally ordered
binary structures, initiated in the previous paper of the series. We first
introduce the notion of parity and linear minors of a matrix, which consists of
iteratively replacing consecutive rows or consecutive columns with a linear
combination of them. We show that a matrix class has bounded twin-width if and
only if its linear-minor closure does not contain all matrices. We observe that
the fixed-parameter tractable algorithm for first-order model checking on
structures given with an $O(1)$-sequence (certificate of bounded twin-width)
and the fact that first-order transductions of bounded twin-width classes have
bounded twin-width, both established in Twin-width I, extend to first-order
logic with modular counting quantifiers. We make explicit a win-win argument
obtained as a by-product of Twin-width IV, and somewhat similar to
bidimensionality, that we call rank-bidimensionality. Armed with the
above-mentioned extension to modular counting, we show that the twin-width of
the product of two conformal matrices $A, B$ over a finite field is bounded by
a function of the twin-width of $A$, of $B$, and of the size of the field.
Furthermore, if $A$ and $B$ are $n \times n$ matrices of twin-width $d$ over
$\mathbb F_q$, we show that $AB$ can be computed in time $O_{d,q}(n^2 \log n)$.
We finally present an ad hoc algorithm to efficiently multiply two matrices of
bounded twin-width, with a single-exponential dependence in the twin-width
bound: If the inputs are given in a compact tree-like form, called
twin-decomposition (of width $d$), then two $n \times n$ matrices $A, B$ over
$\mathbb F_2$, a twin-decomposition of $AB$ with width $2^{d+o(d)}$ can be
computed in time $4^{d+o(d)}n$ (resp. $4^{d+o(d)}n^{1+\varepsilon}$), and
entries queried in doubly-logarithmic (resp. constant) time.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bonnet_E/0/1/0/all/0/1">&#xc9;douard Bonnet</a>, <a href="http://arxiv.org/find/cs/1/au:+Giocanti_U/0/1/0/all/0/1">Ugo Giocanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendez_P/0/1/0/all/0/1">Patrice Ossona de Mendez</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomasse_S/0/1/0/all/0/1">St&#xe9;phan Thomass&#xe9;</a></p><p>We continue developing the theory around the twin-width of totally ordered
binary structures, initiated in the previous paper of the series. We first
introduce the notion of parity and linear minors of a matrix, which consists of
iteratively replacing consecutive rows or consecutive columns with a linear
combination of them. We show that a matrix class has bounded twin-width if and
only if its linear-minor closure does not contain all matrices. We observe that
the fixed-parameter tractable algorithm for first-order model checking on
structures given with an $O(1)$-sequence (certificate of bounded twin-width)
and the fact that first-order transductions of bounded twin-width classes have
bounded twin-width, both established in Twin-width I, extend to first-order
logic with modular counting quantifiers. We make explicit a win-win argument
obtained as a by-product of Twin-width IV, and somewhat similar to
bidimensionality, that we call rank-bidimensionality. Armed with the
above-mentioned extension to modular counting, we show that the twin-width of
the product of two conformal matrices $A, B$ over a finite field is bounded by
a function of the twin-width of $A$, of $B$, and of the size of the field.
Furthermore, if $A$ and $B$ are $n \times n$ matrices of twin-width $d$ over
$\mathbb F_q$, we show that $AB$ can be computed in time $O_{d,q}(n^2 \log n)$.
We finally present an ad hoc algorithm to efficiently multiply two matrices of
bounded twin-width, with a single-exponential dependence in the twin-width
bound: If the inputs are given in a compact tree-like form, called
twin-decomposition (of width $d$), then two $n \times n$ matrices $A, B$ over
$\mathbb F_2$, a twin-decomposition of $AB$ with width $2^{d+o(d)}$ can be
computed in time $4^{d+o(d)}n$ (resp. $4^{d+o(d)}n^{1+\varepsilon}$), and
entries queried in doubly-logarithmic (resp. constant) time.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12062'>Compressing bipartite graphs with a dual reordering scheme</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Maximilien Danisch, Ioannis Panagiotas, Lionel Tabourier</p><p>In order to manage massive graphs in practice, it is often necessary to
resort to graph compression, which aims at reducing the memory used when
storing and processing the graph. Efficient compression methods have been
proposed in the literature, especially for web graphs. In most cases, they are
combined with a vertex reordering pre-processing step which significantly
improves the compression rate. However, these techniques are not as efficient
when considering other kinds of graphs. In this paper, we focus on the class of
bipartite graphs and adapt the vertex reordering phase to their specific
structure by proposing a dual reordering scheme. By reordering each group of
vertices in the purpose of minimizing a specific score, we show that we can
reach better compression rates. We also suggest that this approach can be
further refined to make the node orderings more adapted to the compression
phase that follows the ordering phase.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Danisch_M/0/1/0/all/0/1">Maximilien Danisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Panagiotas_I/0/1/0/all/0/1">Ioannis Panagiotas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabourier_L/0/1/0/all/0/1">Lionel Tabourier</a></p><p>In order to manage massive graphs in practice, it is often necessary to
resort to graph compression, which aims at reducing the memory used when
storing and processing the graph. Efficient compression methods have been
proposed in the literature, especially for web graphs. In most cases, they are
combined with a vertex reordering pre-processing step which significantly
improves the compression rate. However, these techniques are not as efficient
when considering other kinds of graphs. In this paper, we focus on the class of
bipartite graphs and adapt the vertex reordering phase to their specific
structure by proposing a dual reordering scheme. By reordering each group of
vertices in the purpose of minimizing a specific score, we show that we can
reach better compression rates. We also suggest that this approach can be
further refined to make the node orderings more adapted to the compression
phase that follows the ordering phase.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12273'>Augmentation based Approximation Algorithms for Flexible Network Design</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Chandra Chekuri, Rhea Jain</p><p>Adjiashvili introduced network design in a non-uniform fault model: the edge
set of a given graph is partitioned into safe and unsafe edges. A vertex pair
$(s,t)$ is $(p,q)$-flex-connected if $s$ and $t$ have $p$ edge-connectivity
even after the removal of any $q$ unsafe edges. Given a graph $G$, the goal is
to choose a min-cost subgraph $H$ of $G$ that has desired flex-connectivity for
a given set of vertex pairs. This model generalizes the well-studied
edge-connectivity based network design, however, even special cases are
provably much harder to approximate.
</p>
<p>The approximability of network design in this model has been mainly studied
for two settings of interest: (i) single pair setting under the names FTP and
FTF (fault tolerant path and fault tolerant flow), (ii) spanning setting under
the name FGC (flexible graph connectivity). There have been several positive
results in these papers. However, despite similarity to the well-known network
design problems, this new model has been challenging to design approximation
algorithms for, especially when $p,q \ge 2$. We obtain two results that advance
our understanding of algorithm design in this model.
</p>
<p>1. We obtain a $5$-approximation for the $(2,2)$-flex-connectivity for a
single pair $(s,t)$. Previously no non-trivial approximation was known for this
setting.
</p>
<p>2. We obtain $O(p)$ approximation for $(p,2)$ and $(p,3)$-FGC for any $p \ge
1$, and for $(p,4)$-FGC for any even $p$. We obtain an $O(q)$-approximation for
$(2,q)$-FGC for any $q \ge 1$. Previously only a $O(q \log n)$-approximation
was known for these settings.
</p>
<p>Our results are obtained via the augmentation framework where we identify a
structured way to use the well-known $2$-approximation for covering uncrossable
families of cuts. Our analysis also proves corresponding integrality gap bounds
on an LP relaxation that we formulate.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chekuri_C/0/1/0/all/0/1">Chandra Chekuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1">Rhea Jain</a></p><p>Adjiashvili introduced network design in a non-uniform fault model: the edge
set of a given graph is partitioned into safe and unsafe edges. A vertex pair
$(s,t)$ is $(p,q)$-flex-connected if $s$ and $t$ have $p$ edge-connectivity
even after the removal of any $q$ unsafe edges. Given a graph $G$, the goal is
to choose a min-cost subgraph $H$ of $G$ that has desired flex-connectivity for
a given set of vertex pairs. This model generalizes the well-studied
edge-connectivity based network design, however, even special cases are
provably much harder to approximate.
</p>
<p>The approximability of network design in this model has been mainly studied
for two settings of interest: (i) single pair setting under the names FTP and
FTF (fault tolerant path and fault tolerant flow), (ii) spanning setting under
the name FGC (flexible graph connectivity). There have been several positive
results in these papers. However, despite similarity to the well-known network
design problems, this new model has been challenging to design approximation
algorithms for, especially when $p,q \ge 2$. We obtain two results that advance
our understanding of algorithm design in this model.
</p>
<p>1. We obtain a $5$-approximation for the $(2,2)$-flex-connectivity for a
single pair $(s,t)$. Previously no non-trivial approximation was known for this
setting.
</p>
<p>2. We obtain $O(p)$ approximation for $(p,2)$ and $(p,3)$-FGC for any $p \ge
1$, and for $(p,4)$-FGC for any even $p$. We obtain an $O(q)$-approximation for
$(2,q)$-FGC for any $q \ge 1$. Previously only a $O(q \log n)$-approximation
was known for these settings.
</p>
<p>Our results are obtained via the augmentation framework where we identify a
structured way to use the well-known $2$-approximation for covering uncrossable
families of cuts. Our analysis also proves corresponding integrality gap bounds
on an LP relaxation that we formulate.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12301'>Constant-delay enumeration for SLP-compressed documents</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mart&#xed;n Mu&#xf1;oz, Cristian Riveros</p><p>We study the problem of enumerating results from a query over a compressed
document. The model we use for compression are straight-line programs (SLPs),
which are defined by a context-free grammar that produces a single string. For
our queries we use a model called Annotated Automata, an extension of regular
automata that allows annotations on letters. This model extends the notion of
Regular Spanners as it allows arbitrarily long outputs. Our main result is an
algorithm which evaluates such a query by enumerating all results with
output-linear delay after a preprocessing phase which takes linear time on the
size of the SLP, and cubic time over the size of the automaton. This is an
improvement over Schmid and Schweikardt's result, which, with the same
preprocessing time, enumerates with a delay which is logarithmic on the size of
the uncompressed document. We achieve this through a persistent data structure
named Enumerable Compact Sets with Shifts which guarantees output-linear delay
under certain restrictions. These results imply constant-delay enumeration
algorithms in the context of regular spanners. Further, we use an extension of
annotated automata which utilizes succinctly encoded annotations to save an
exponential factor from previous results that dealt with constant-delay
enumeration over vset automata. Lastly, we extend our results in the same
fashion Schmid and Schweikardt did to allow complex document editing while
maintaining the constant-delay guarantee.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Munoz_M/0/1/0/all/0/1">Mart&#xed;n Mu&#xf1;oz</a>, <a href="http://arxiv.org/find/cs/1/au:+Riveros_C/0/1/0/all/0/1">Cristian Riveros</a></p><p>We study the problem of enumerating results from a query over a compressed
document. The model we use for compression are straight-line programs (SLPs),
which are defined by a context-free grammar that produces a single string. For
our queries we use a model called Annotated Automata, an extension of regular
automata that allows annotations on letters. This model extends the notion of
Regular Spanners as it allows arbitrarily long outputs. Our main result is an
algorithm which evaluates such a query by enumerating all results with
output-linear delay after a preprocessing phase which takes linear time on the
size of the SLP, and cubic time over the size of the automaton. This is an
improvement over Schmid and Schweikardt's result, which, with the same
preprocessing time, enumerates with a delay which is logarithmic on the size of
the uncompressed document. We achieve this through a persistent data structure
named Enumerable Compact Sets with Shifts which guarantees output-linear delay
under certain restrictions. These results imply constant-delay enumeration
algorithms in the context of regular spanners. Further, we use an extension of
annotated automata which utilizes succinctly encoded annotations to save an
exponential factor from previous results that dealt with constant-delay
enumeration over vset automata. Lastly, we extend our results in the same
fashion Schmid and Schweikardt did to allow complex document editing while
maintaining the constant-delay guarantee.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12313'>Random graph matching at Otter's threshold via counting chandeliers</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Cheng Mao, Yihong Wu, Jiaming Xu, Sophie H. Yu</p><p>We propose an efficient algorithm for graph matching based on similarity
scores constructed from counting a certain family of weighted trees rooted at
each vertex. For two Erd\H{o}s-R\'enyi graphs $\mathcal{G}(n,q)$ whose edges
are correlated through a latent vertex correspondence, we show that this
algorithm correctly matches all but a vanishing fraction of the vertices with
high probability, provided that $nq\to\infty$ and the edge correlation
coefficient $\rho$ satisfies $\rho^2&gt;\alpha \approx 0.338$, where $\alpha$ is
Otter's tree-counting constant. Moreover, this almost exact matching can be
made exact under an extra condition that is information-theoretically
necessary. This is the first polynomial-time graph matching algorithm that
succeeds at an explicit constant correlation and applies to both sparse and
dense graphs. In comparison, previous methods either require $\rho=1-o(1)$ or
are restricted to sparse graphs.
</p>
<p>The crux of the algorithm is a carefully curated family of rooted trees
called chandeliers, which allows effective extraction of the graph correlation
from the counts of the same tree while suppressing the undesirable correlation
between those of different trees.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1">Cheng Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yihong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiaming Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Sophie H. Yu</a></p><p>We propose an efficient algorithm for graph matching based on similarity
scores constructed from counting a certain family of weighted trees rooted at
each vertex. For two Erd\H{o}s-R\'enyi graphs $\mathcal{G}(n,q)$ whose edges
are correlated through a latent vertex correspondence, we show that this
algorithm correctly matches all but a vanishing fraction of the vertices with
high probability, provided that $nq\to\infty$ and the edge correlation
coefficient $\rho$ satisfies $\rho^2&gt;\alpha \approx 0.338$, where $\alpha$ is
Otter's tree-counting constant. Moreover, this almost exact matching can be
made exact under an extra condition that is information-theoretically
necessary. This is the first polynomial-time graph matching algorithm that
succeeds at an explicit constant correlation and applies to both sparse and
dense graphs. In comparison, previous methods either require $\rho=1-o(1)$ or
are restricted to sparse graphs.
</p>
<p>The crux of the algorithm is a carefully curated family of rooted trees
called chandeliers, which allows effective extraction of the graph correlation
from the counts of the same tree while suppressing the undesirable correlation
between those of different trees.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12314'>Package Delivery Using Drones with Restricted Movement Areas</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Thomas Erlebach, Kelin Luo, Frits C.R. Spieksma</p><p>For the problem of delivering a package from a source node to a destination
node in a graph using a set of drones, we study the setting where the movements
of each drone are restricted to a certain subgraph of the given graph. We
consider the objectives of minimizing the delivery time (problem DDT) and of
minimizing the total energy consumption (problem DDC). For general graphs, we
show a strong inapproximability result and a matching approximation algorithm
for DDT as well as NP-hardness and a 2-approximation algorithm for DDC. For the
special case of a path, we show that DDT is NP-hard if the drones have
different speeds. For trees, we give optimal algorithms under the assumption
that all drones have the same speed or the same energy consumption rate. The
results for trees extend to arbitrary graphs if the subgraph of each drone is
isometric.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Erlebach_T/0/1/0/all/0/1">Thomas Erlebach</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1">Kelin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Spieksma_F/0/1/0/all/0/1">Frits C.R. Spieksma</a></p><p>For the problem of delivering a package from a source node to a destination
node in a graph using a set of drones, we study the setting where the movements
of each drone are restricted to a certain subgraph of the given graph. We
consider the objectives of minimizing the delivery time (problem DDT) and of
minimizing the total energy consumption (problem DDC). For general graphs, we
show a strong inapproximability result and a matching approximation algorithm
for DDT as well as NP-hardness and a 2-approximation algorithm for DDC. For the
special case of a path, we show that DDT is NP-hard if the drones have
different speeds. For trees, we give optimal algorithms under the assumption
that all drones have the same speed or the same energy consumption rate. The
results for trees extend to arbitrary graphs if the subgraph of each drone is
isometric.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12315'>Tree decompositions with bounded independence number: beyond independent sets</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Martin Milani&#x10d;, Pawe&#x142; Rz&#x105;&#x17c;ewski</p><p>We continue the study of graph classes in which the treewidth can only be
large due to the presence of a large clique, and, more specifically, of graph
classes with bounded tree-independence number. In [Dallard, Milani\v{c}, and
\v{S}torgel, Treewidth versus clique number. {II}. Tree-independence number,
2022], it was shown that the Maximum Weight Independent Packing problem, which
is a common generalization of the Independent Set and Induced Matching
problems, can be solved in polynomial time provided that the input graph is
given along with a tree decomposition with bounded independence number. We
provide further examples of algorithmic problems that can be solved in
polynomial time under this assumption. This includes, for all even positive
integers $d$, the problem of packing subgraphs at distance at least $d$
(generalizing the Maximum Weight Independent Packing problem) and the problem
of finding a large induced sparse subgraph satisfying an arbitrary but fixed
property expressible in counting monadic second-order logic. As part of our
approach, we generalize some classical results on powers of chordal graphs to
the context of general graphs and their tree-independence numbers.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Milanic_M/0/1/0/all/0/1">Martin Milani&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Rzazewski_P/0/1/0/all/0/1">Pawe&#x142; Rz&#x105;&#x17c;ewski</a></p><p>We continue the study of graph classes in which the treewidth can only be
large due to the presence of a large clique, and, more specifically, of graph
classes with bounded tree-independence number. In [Dallard, Milani\v{c}, and
\v{S}torgel, Treewidth versus clique number. {II}. Tree-independence number,
2022], it was shown that the Maximum Weight Independent Packing problem, which
is a common generalization of the Independent Set and Induced Matching
problems, can be solved in polynomial time provided that the input graph is
given along with a tree decomposition with bounded independence number. We
provide further examples of algorithmic problems that can be solved in
polynomial time under this assumption. This includes, for all even positive
integers $d$, the problem of packing subgraphs at distance at least $d$
(generalizing the Maximum Weight Independent Packing problem) and the problem
of finding a large induced sparse subgraph satisfying an arbitrary but fixed
property expressible in counting monadic second-order logic. As part of our
approach, we generalize some classical results on powers of chordal graphs to
the context of general graphs and their tree-independence numbers.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.12332'>On the Optimal Linear Contraction Order for Tree Tensor Networks</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mihail Stoian</p><p>Tensor networks are nowadays the backbone of classical simulations of quantum
many-body systems and quantum circuits. Most tensor methods rely on the fact
that we can eventually contract the tensor network to obtain the final result.
While the contraction operation itself is trivial, its execution time is highly
dependent on the order in which the contractions are performed. To this end,
one tries to find beforehand an optimal order in which the contractions should
be performed. However, there is a drawback: the general problem of finding the
optimal contraction order is NP-complete. Therefore, one must settle for a
mixture of exponential algorithms for small problems, e.g., $n \leq 20$, and
otherwise hope for good contraction orders. For this reason, previous research
has focused on the latter part, trying to find better heuristics.
</p>
<p>In this work, we take a more conservative approach and show that tree tensor
networks accept optimal linear contraction orders. Beyond the optimality
results, we adapt two join ordering techniques that can build on our work to
guarantee near-optimal orders for arbitrary tensor networks.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Stoian_M/0/1/0/all/0/1">Mihail Stoian</a></p><p>Tensor networks are nowadays the backbone of classical simulations of quantum
many-body systems and quantum circuits. Most tensor methods rely on the fact
that we can eventually contract the tensor network to obtain the final result.
While the contraction operation itself is trivial, its execution time is highly
dependent on the order in which the contractions are performed. To this end,
one tries to find beforehand an optimal order in which the contractions should
be performed. However, there is a drawback: the general problem of finding the
optimal contraction order is NP-complete. Therefore, one must settle for a
mixture of exponential algorithms for small problems, e.g., $n \leq 20$, and
otherwise hope for good contraction orders. For this reason, previous research
has focused on the latter part, trying to find better heuristics.
</p>
<p>In this work, we take a more conservative approach and show that tree tensor
networks accept optimal linear contraction orders. Beyond the optimality
results, we adapt two join ordering techniques that can build on our work to
guarantee near-optimal orders for arbitrary tensor networks.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-27T00:30:00Z">Tuesday, September 27 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Monday, September 26
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11505'>The complexity of unsupervised learning of lexicographic preferences</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: H&#xe9;l&#xe8;ne Fargier (IRIT-ADRIA, ANITI), Pierre-Fran&#xe7;ois Gimenez (CIDRE), J&#xe9;r&#xf4;me Mengin (IRIT-ADRIA, ANITI), Bao Ngoc Le Nguyen (INSA Toulouse)</p><p>This paper considers the task of learning users' preferences on a
combinatorial set of alternatives, as generally used by online configurators,
for example. In many settings, only a set of selected alternatives during past
interactions is available to the learner. Fargier et al. [2018] propose an
approach to learn, in such a setting, a model of the users' preferences that
ranks previously chosen alternatives as high as possible; and an algorithm to
learn, in this setting, a particular model of preferences: lexicographic
preferences trees (LP-trees). In this paper, we study complexity-theoretical
problems related to this approach. We give an upper bound on the sample
complexity of learning an LP-tree, which is logarithmic in the number of
attributes. We also prove that computing the LP tree that minimises the
empirical risk can be done in polynomial time when restricted to the class of
linear LP-trees.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Fargier_H/0/1/0/all/0/1">H&#xe9;l&#xe8;ne Fargier</a> (IRIT-ADRIA, ANITI), <a href="http://arxiv.org/find/cs/1/au:+Gimenez_P/0/1/0/all/0/1">Pierre-Fran&#xe7;ois Gimenez</a> (CIDRE), <a href="http://arxiv.org/find/cs/1/au:+Mengin_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Mengin</a> (IRIT-ADRIA, ANITI), <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Bao Ngoc Le Nguyen</a> (INSA Toulouse)</p><p>This paper considers the task of learning users' preferences on a
combinatorial set of alternatives, as generally used by online configurators,
for example. In many settings, only a set of selected alternatives during past
interactions is available to the learner. Fargier et al. [2018] propose an
approach to learn, in such a setting, a model of the users' preferences that
ranks previously chosen alternatives as high as possible; and an algorithm to
learn, in this setting, a particular model of preferences: lexicographic
preferences trees (LP-trees). In this paper, we study complexity-theoretical
problems related to this approach. We give an upper bound on the sample
complexity of learning an LP-tree, which is logarithmic in the number of
attributes. We also prove that computing the LP tree that minimises the
empirical risk can be done in polynomial time when restricted to the class of
linear LP-trees.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11650'>An Algebraic-Geometry Approach to Prime Factorization</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Alberto Montina, Stefan Wolf</p><p>New algorithms for prime factorization that outperform the existing ones or
take advantage of particular properties of the prime factors can have a
practical impact on present implementations of cryptographic algorithms that
rely on the complexity of factorization. Currently used keys are chosen on the
basis of the present algorithmic knowledge and, thus, can potentially be
subject to future breaches. For this reason, it is worth to investigate new
approaches which have the potentiality of giving a computational advantage. The
problem has also relevance in quantum computation, as an efficient quantum
algorithm for prime factorization already exists. Thus, better classical
asymptotic complexity can provide a better understanding of the advantages
offered by quantum computers. In this paper, we reduce the factorization
problem to the search of points of parametrizable varieties, in particular
curves, over finite fields. The varieties are required to have an arbitrarily
large number of intersection points with some hypersurface over the base field.
For a subexponential or poly- nomial factoring complexity, the number of
parameters have to scale sublinearly in the space dimension n and the
complexity of computing a point given the parameters has to be subexponential
or polynomial, respectively. We outline a procedure for building these
varieties, which is illustrated with two constructions. In one case, we show
that there are varieties whose points can be evaluated efficiently given a
number of parameters not greater than n/2. In the other case, the bound is
dropped to n/3. Incidentally, the first construction resembles a kind of
retro-causal model. Retro-causality is considered one possible explanation of
quantum weirdness.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Montina_A/0/1/0/all/0/1">Alberto Montina</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_S/0/1/0/all/0/1">Stefan Wolf</a></p><p>New algorithms for prime factorization that outperform the existing ones or
take advantage of particular properties of the prime factors can have a
practical impact on present implementations of cryptographic algorithms that
rely on the complexity of factorization. Currently used keys are chosen on the
basis of the present algorithmic knowledge and, thus, can potentially be
subject to future breaches. For this reason, it is worth to investigate new
approaches which have the potentiality of giving a computational advantage. The
problem has also relevance in quantum computation, as an efficient quantum
algorithm for prime factorization already exists. Thus, better classical
asymptotic complexity can provide a better understanding of the advantages
offered by quantum computers. In this paper, we reduce the factorization
problem to the search of points of parametrizable varieties, in particular
curves, over finite fields. The varieties are required to have an arbitrarily
large number of intersection points with some hypersurface over the base field.
For a subexponential or poly- nomial factoring complexity, the number of
parameters have to scale sublinearly in the space dimension n and the
complexity of computing a point given the parameters has to be subexponential
or polynomial, respectively. We outline a procedure for building these
varieties, which is illustrated with two constructions. In one case, we show
that there are varieties whose points can be evaluated efficiently given a
number of parameters not greater than n/2. In the other case, the bound is
dropped to n/3. Incidentally, the first construction resembles a kind of
retro-causal model. Retro-causality is considered one possible explanation of
quantum weirdness.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11260'>Piercing Diametral Disks Induced by Edges of Maximum Spanning Tree</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: A. Karim Abu-Affash, Paz Carmi, Meytal Maman</p><p>Let $P$ be a set of points in the plane and let $T$ be a maximum-weight
spanning tree of $P$. For an edge $(p,q)$, let $D_{pq}$ be the diametral disk
induced by $(p,q)$, i.e., the disk having the segment $\overline{pq}$ as its
diameter. Let $\cal{D_T}$ be the set of the diametral disks induced by the
edges of $T$. In this paper, we show that one point is sufficient to pierce all
the disks in $\cal{D_T}$, thus, the set $\cal{D_T}$ is Helly. Actually, we show
that the center of the smallest enclosing circle of $P$ is contained in all the
disks of $\cal{D_T}$, and thus the piercing point can be computed in linear
time.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Abu_Affash_A/0/1/0/all/0/1">A. Karim Abu-Affash</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmi_P/0/1/0/all/0/1">Paz Carmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maman_M/0/1/0/all/0/1">Meytal Maman</a></p><p>Let $P$ be a set of points in the plane and let $T$ be a maximum-weight
spanning tree of $P$. For an edge $(p,q)$, let $D_{pq}$ be the diametral disk
induced by $(p,q)$, i.e., the disk having the segment $\overline{pq}$ as its
diameter. Let $\cal{D_T}$ be the set of the diametral disks induced by the
edges of $T$. In this paper, we show that one point is sufficient to pierce all
the disks in $\cal{D_T}$, thus, the set $\cal{D_T}$ is Helly. Actually, we show
that the center of the smallest enclosing circle of $P$ is contained in all the
disks of $\cal{D_T}$, and thus the piercing point can be computed in linear
time.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11606'>An extension to VORO++ for multithreaded computation of Voronoi cells</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jiayin Lu, Emanuel A. Lazar, Chris H. Rycroft</p><p>VORO++ is a software library written in C++ for computing the Voronoi
tessellation, a technique in computational geometry that is widely used for
analyzing systems of particles. VORO++ was released in 2009 and is based on
computing the Voronoi cell for each particle individually. Here, we take
advantage of modern computer hardware, and extend the original serial version
to allow for multithreaded computation of Voronoi cells via the OpenMP
application programming interface. We test the performance of the code, and
demonstrate that we can achieve parallel efficiencies greater than 95% in many
cases. The multithreaded extension follows standard OpenMP programming
paradigms, allowing it to be incorporated into other programs. We provide an
example of this using the VoroTop software library, performing a multithreaded
Voronoi cell topology analysis of up to 102.4 million particles.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/physics/1/au:+Lu_J/0/1/0/all/0/1">Jiayin Lu</a>, <a href="http://arxiv.org/find/physics/1/au:+Lazar_E/0/1/0/all/0/1">Emanuel A. Lazar</a>, <a href="http://arxiv.org/find/physics/1/au:+Rycroft_C/0/1/0/all/0/1">Chris H. Rycroft</a></p><p>VORO++ is a software library written in C++ for computing the Voronoi
tessellation, a technique in computational geometry that is widely used for
analyzing systems of particles. VORO++ was released in 2009 and is based on
computing the Voronoi cell for each particle individually. Here, we take
advantage of modern computer hardware, and extend the original serial version
to allow for multithreaded computation of Voronoi cells via the OpenMP
application programming interface. We test the performance of the code, and
demonstrate that we can achieve parallel efficiencies greater than 95% in many
cases. The multithreaded extension follows standard OpenMP programming
paradigms, allowing it to be incorporated into other programs. We provide an
example of this using the VoroTop software library, performing a multithreaded
Voronoi cell topology analysis of up to 102.4 million particles.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11452'>From String Detection to Orthogonal Vector Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Yunhao Wang, Tianyuan Zheng, Lior Horesh</p><p>Considering Grover's Search Algorithm (GSA) with the standard diffuser stage
applied, we revisit the $3$-qubit unique String Detection Problem (SDP) and
extend the algorithm to $4$-qubit SDP with multiple winners. We then
investigate unstructured search problems with non-uniform distributions and
define the Orthogonal Vector Problem (OVP) under quantum settings. Although no
numerically stable results is reached under the original GSA framework, we
provide intuition behind our implementation and further observations on OVP. We
further perform a special case analysis under the modified GSA framework which
aims to stabilize the final measurement under arbitrary initial distribution.
Based on the result of the analysis, we generalize the initial condition under
which neither the original framework nor the modification works. Instead of
utilizing GSA, we also propose a short-depth circuit that can calculate the
orthogonal pair for a given vector represented as a binary string with constant
runtime.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Wang_Y/0/1/0/all/0/1">Yunhao Wang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zheng_T/0/1/0/all/0/1">Tianyuan Zheng</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Horesh_L/0/1/0/all/0/1">Lior Horesh</a></p><p>Considering Grover's Search Algorithm (GSA) with the standard diffuser stage
applied, we revisit the $3$-qubit unique String Detection Problem (SDP) and
extend the algorithm to $4$-qubit SDP with multiple winners. We then
investigate unstructured search problems with non-uniform distributions and
define the Orthogonal Vector Problem (OVP) under quantum settings. Although no
numerically stable results is reached under the original GSA framework, we
provide intuition behind our implementation and further observations on OVP. We
further perform a special case analysis under the modified GSA framework which
aims to stabilize the final measurement under arbitrary initial distribution.
Based on the result of the analysis, we generalize the initial condition under
which neither the original framework nor the modification works. Instead of
utilizing GSA, we also propose a short-depth circuit that can calculate the
orthogonal pair for a given vector represented as a binary string with constant
runtime.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11651'>Local Distributed Rounding: Generalized to MIS, Matching, Set Cover, and Beyond</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Salwa Faour, Mohsen Ghaffari, Christoph Grunau, Fabian Kuhn, V&#xe1;clav Rozho&#x148;</p><p>We develop a general deterministic distributed method for locally rounding
fractional solutions of graph problems for which the analysis can be broken
down into analyzing pairs of vertices. Roughly speaking, the method can
transform fractional/probabilistic label assignments of the vertices into
integral/deterministic label assignments for the vertices, while approximately
preserving a potential function that is a linear combination of functions, each
of which depends on at most two vertices (subject to some conditions usually
satisfied in pairwise analyses). The method unifies and significantly
generalizes prior work on deterministic local rounding techniques [Ghaffari,
Kuhn FOCS'21; Harris FOCS'19; Fischer, Ghaffari, Kuhn FOCS'17; Fischer DISC'17]
to obtain polylogarithmic-time deterministic distributed solutions for
combinatorial graph problems. Our general rounding result enables us to locally
and efficiently derandomize a range of distributed algorithms for local graph
problems, including maximal independent set (MIS), maximum-weight independent
set approximation, and minimum-cost set cover approximation. As a highlight, we
in particular obtain a deterministic $O(\log^2\Delta\cdot\log n)$-round
algorithm for computing an MIS in the LOCAL model and an almost as efficient
$O(\log^2\Delta\cdot\log\log\Delta\cdot\log n)$-round deterministic MIS
algorithm in the CONGEST model. As a result, the best known deterministic
distributed time complexity of the four most widely studied distributed
symmetry breaking problems (MIS, maximal matching, $(\Delta+1)$-vertex
coloring, and $(2\Delta-1)$-edge coloring) is now $O(\log^2\Delta\cdot\log n)$.
Our new MIS algorithm is also the first direct polylogarithmic-time
deterministic distributed MIS algorithm, which is not based on network
decomposition.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Faour_S/0/1/0/all/0/1">Salwa Faour</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1">Christoph Grunau</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhn_F/0/1/0/all/0/1">Fabian Kuhn</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozhon_V/0/1/0/all/0/1">V&#xe1;clav Rozho&#x148;</a></p><p>We develop a general deterministic distributed method for locally rounding
fractional solutions of graph problems for which the analysis can be broken
down into analyzing pairs of vertices. Roughly speaking, the method can
transform fractional/probabilistic label assignments of the vertices into
integral/deterministic label assignments for the vertices, while approximately
preserving a potential function that is a linear combination of functions, each
of which depends on at most two vertices (subject to some conditions usually
satisfied in pairwise analyses). The method unifies and significantly
generalizes prior work on deterministic local rounding techniques [Ghaffari,
Kuhn FOCS'21; Harris FOCS'19; Fischer, Ghaffari, Kuhn FOCS'17; Fischer DISC'17]
to obtain polylogarithmic-time deterministic distributed solutions for
combinatorial graph problems. Our general rounding result enables us to locally
and efficiently derandomize a range of distributed algorithms for local graph
problems, including maximal independent set (MIS), maximum-weight independent
set approximation, and minimum-cost set cover approximation. As a highlight, we
in particular obtain a deterministic $O(\log^2\Delta\cdot\log n)$-round
algorithm for computing an MIS in the LOCAL model and an almost as efficient
$O(\log^2\Delta\cdot\log\log\Delta\cdot\log n)$-round deterministic MIS
algorithm in the CONGEST model. As a result, the best known deterministic
distributed time complexity of the four most widely studied distributed
symmetry breaking problems (MIS, maximal matching, $(\Delta+1)$-vertex
coloring, and $(2\Delta-1)$-edge coloring) is now $O(\log^2\Delta\cdot\log n)$.
Our new MIS algorithm is also the first direct polylogarithmic-time
deterministic distributed MIS algorithm, which is not based on network
decomposition.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2209.11669'>Improved Distributed Network Decomposition, Hitting Sets, and Spanners, via Derandomization</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mohsen Ghaffari, Christoph Grunau, Bernhard Haeupler, Saeed Ilchi, V&#xe1;clav Rozho&#x148;</p><p>This paper presents significantly improved deterministic algorithms for some
of the key problems in the area of distributed graph algorithms, including
network decomposition, hitting sets, and spanners. As the main ingredient in
these results, we develop novel randomized distributed algorithms that we can
analyze using only pairwise independence, and we can thus derandomize
efficiently. As our most prominent end-result, we obtain a deterministic
construction for $O(\log n)$-color $O(\log n \cdot \log\log\log n)$-strong
diameter network decomposition in $\tilde{O}(\log^3 n)$ rounds. This is the
first construction that achieves almost $\log n$ in both parameters, and it
improves on a recent line of exciting progress on deterministic distributed
network decompositions [Rozho\v{n}, Ghaffari STOC'20; Ghaffari, Grunau,
Rozho\v{n} SODA'21; Chang, Ghaffari PODC'21; Elkin, Haeupler, Rozho\v{n},
Grunau FOCS'22].
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Mohsen Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Grunau_C/0/1/0/all/0/1">Christoph Grunau</a>, <a href="http://arxiv.org/find/cs/1/au:+Haeupler_B/0/1/0/all/0/1">Bernhard Haeupler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilchi_S/0/1/0/all/0/1">Saeed Ilchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozhon_V/0/1/0/all/0/1">V&#xe1;clav Rozho&#x148;</a></p><p>This paper presents significantly improved deterministic algorithms for some
of the key problems in the area of distributed graph algorithms, including
network decomposition, hitting sets, and spanners. As the main ingredient in
these results, we develop novel randomized distributed algorithms that we can
analyze using only pairwise independence, and we can thus derandomize
efficiently. As our most prominent end-result, we obtain a deterministic
construction for $O(\log n)$-color $O(\log n \cdot \log\log\log n)$-strong
diameter network decomposition in $\tilde{O}(\log^3 n)$ rounds. This is the
first construction that achieves almost $\log n$ in both parameters, and it
improves on a recent line of exciting progress on deterministic distributed
network decompositions [Rozho\v{n}, Ghaffari STOC'20; Ghaffari, Grunau,
Rozho\v{n} SODA'21; Chang, Ghaffari PODC'21; Elkin, Haeupler, Rozho\v{n},
Grunau FOCS'22].
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-26T00:30:00Z">Monday, September 26 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Sunday, September 25
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://emanueleviola.wordpress.com/2022/09/25/getting-started-with-opengl-and-c/'>Getting started with OpenGL and C++</a></h3>
          <p class='item-feed'>from <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Below is a template that shows a fractal plant that you can modify with the keys z,w,s. Getting this to work was not straightforward, but the idea is that now you can just have fun and start your videogame. The code is not meant to be optimized at all, but simple. It&#8217;s pretty much self-explanatory, [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Below is a template that shows a fractal plant that you can modify with the keys z,w,s.  Getting this to work was not straightforward, but the idea is that now you can just have fun and start your videogame.  The code is not meant to be optimized at all, but simple.  It&#8217;s pretty much self-explanatory, basically you can just replace the call to drawFrac in display to show whatever you want, and you handle key strokes in the idle function.  I only tested it on Linux.</p>



<figure class="wp-block-image size-large"><a href="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png"><img data-attachment-id="1080" data-permalink="https://emanueleviola.wordpress.com/2022/09/25/getting-started-with-opengl-and-c/screenshot-from-2022-09-25-19-37-42/" data-orig-file="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png" data-orig-size="1369,873" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-from-2022-09-25-19-37-42" data-image-description="" data-image-caption="" data-medium-file="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=300" data-large-file="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=640" src="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=1024" alt="" class="wp-image-1080" srcset="https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=1024 1024w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=150 150w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=300 300w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png?w=768 768w, https://emanueleviola.files.wordpress.com/2022/09/screenshot-from-2022-09-25-19-37-42.png 1369w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure>



<pre class="wp-block-code"><code>/*
This is a template to get started with OpenGL (which needs to be installed)
To compile: g++ GLtemplate.c++ -o GLtemplate -lglut -lGLU -lGL
To run: ./GLtemplate

It shows a fractal plant that you can modify with the keys z,w,s

*/

#include &lt;GL/glut.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;

GLfloat userAngle = M_PI/2, userLength = 0.5;

//Keyboard code.  keyStates&#091;x] is true if x is pressed.

bool keyStates&#091;256];     //Key state values

void keyPressed (unsigned char key, int x, int y) { keyStates&#091;key] = true;  }
void keyUp      (unsigned char key, int x, int y) { keyStates&#091;key] = false; }

void idle() {
  if (keyStates&#091;'z']) {userAngle += 0.01;}
  if (keyStates&#091;'w']) {userLength += 0.01;}
  if (keyStates&#091;'s']) {userLength -= 0.01; if (userLength &lt; 0) userLength = 0;}
}

/* Draws a plant from x,y with first piece length l, and angle a
The window has coordinates from (-1,-1) to (1,1).  The center is 0,0.
*/

void drawFrac(GLfloat x,GLfloat y,GLfloat l, GLfloat a) {
  if ( l &lt; 0.001 )
    return;

  glColor3f(0, l*30, 0);
  glLineWidth(l*10);  //Must be before glBegin(GL_LINES)

  glBegin(GL_LINES);

  glVertex2d(x,y);
  glVertex2d(x+cos(a)*l,y+sin(a)*l);

  glEnd();

  drawFrac(x+cos(a)*l*0.3,y+sin(a)*l*0.3,l*0.3,a+M_PI/4);
  drawFrac(x+cos(a)*l*0.6,y+sin(a)*l*0.6,l*0.4,a-M_PI/4);

  drawFrac(x+cos(a)*l,y+sin(a)*l,l*0.5,a+M_PI/4);
  drawFrac(x+cos(a)*l,y+sin(a)*l,l*0.5,a-M_PI/4);
}

//This is the function that draws everything on the screen
void display() {
  glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); //Clear screen

  /* Draw whatever you need here */
  drawFrac(0,0,userLength,userAngle);

  glutSwapBuffers();
  glutPostRedisplay();
}

int main(int argc, char** argv)
{
    glutInit(&amp;argc, argv);
    glutInitDisplayMode(GLUT_SINGLE);
    glutInitWindowSize(1000, 1000);
    glutInitWindowPosition(0,0);
    glutCreateWindow("GLtemplate");
    glutDisplayFunc(display);
    glutIdleFunc(idle);
    glutKeyboardUpFunc(keyUp);
    glutKeyboardFunc(keyPressed);

    glutMainLoop();
    return 0;
}
</code></pre>
<p class="authors">By Manu</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-25T23:45:43Z">Sunday, September 25 2022, 23:45</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/136'>TR22-136 |  Rounds vs Communication Tradeoffs for Maximal Independent Sets | 

	Sepehr Assadi, 

	Gillat Kol, 

	Zhijun Zhang</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We consider the problem of finding a maximal independent set (MIS) in the shared blackboard communication model with vertex-partitioned inputs. There are $n$ players corresponding to vertices of an undirected graph, and each player sees the edges incident on its vertex -- this way, each edge is known by both its endpoints and is thus shared by two players. The players communicate in simultaneous rounds by posting their messages on a shared blackboard visible to all players, with the goal of computing an MIS of the graph. While the MIS problem is well studied in other distributed models, and while shared blackboard is, perhaps, the simplest broadcast model, lower bounds for our problem were only known against one-round protocols.

We present a lower bound on the round-communication tradeoff for computing an MIS in this model. Specifically, we show that when $r$ rounds of interaction are allowed, at least one player needs to communicate $\Omega(n^{1/20^{r+1}})$ bits. In particular, with logarithmic bandwidth, finding an MIS requires $\Omega(\log\log{n})$ rounds. This lower bound can be compared with the algorithm of Ghaffari, Gouleakis, Konrad, Mitrovi ?c, and Rubinfeld [PODC 2018] that solves MIS in $O(\log\log{n})$ rounds but with a logarithmic bandwidth for an average player. Additionally, our lower bound further extends to the closely related problem of maximal bipartite matching.

The presence of edge-sharing gives the algorithms in our model a surprising power and numerous algorithmic results exploiting this power are known. For a similar reason, proving lower bounds in this model is much more challenging, as this sharing in the players&#39; inputs prohibits the use of standard number-in-hand communication complexity arguments. Thus, to prove our results, we devise a new round elimination framework, which we call partial-input embedding, that may also be useful in future work for proving round-sensitive lower bounds in the presence of shared inputs.

Finally, we discuss several implications of our results to multi-round (adaptive) distributed sketching algorithms, broadcast congested clique, and to the welfare maximization problem in two-sided matching markets.
        
        </div>

        <div class='item-content item-summary'>
        
          
          We consider the problem of finding a maximal independent set (MIS) in the shared blackboard communication model with vertex-partitioned inputs. There are $n$ players corresponding to vertices of an undirected graph, and each player sees the edges incident on its vertex -- this way, each edge is known by both its endpoints and is thus shared by two players. The players communicate in simultaneous rounds by posting their messages on a shared blackboard visible to all players, with the goal of computing an MIS of the graph. While the MIS problem is well studied in other distributed models, and while shared blackboard is, perhaps, the simplest broadcast model, lower bounds for our problem were only known against one-round protocols.

We present a lower bound on the round-communication tradeoff for computing an MIS in this model. Specifically, we show that when $r$ rounds of interaction are allowed, at least one player needs to communicate $\Omega(n^{1/20^{r+1}})$ bits. In particular, with logarithmic bandwidth, finding an MIS requires $\Omega(\log\log{n})$ rounds. This lower bound can be compared with the algorithm of Ghaffari, Gouleakis, Konrad, Mitrovi ?c, and Rubinfeld [PODC 2018] that solves MIS in $O(\log\log{n})$ rounds but with a logarithmic bandwidth for an average player. Additionally, our lower bound further extends to the closely related problem of maximal bipartite matching.

The presence of edge-sharing gives the algorithms in our model a surprising power and numerous algorithmic results exploiting this power are known. For a similar reason, proving lower bounds in this model is much more challenging, as this sharing in the players&#39; inputs prohibits the use of standard number-in-hand communication complexity arguments. Thus, to prove our results, we devise a new round elimination framework, which we call partial-input embedding, that may also be useful in future work for proving round-sensitive lower bounds in the presence of shared inputs.

Finally, we discuss several implications of our results to multi-round (adaptive) distributed sketching algorithms, broadcast congested clique, and to the welfare maximization problem in two-sided matching markets.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-25T06:24:48Z">Sunday, September 25 2022, 06:24</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/135'>TR22-135 |  Decision Tree Complexity versus Block Sensitivity and Degree | 

	Swagato Sanyal, 

	Supartha Poddar, 

	Rahul Chugh</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Relations between the decision tree complexity and various other complexity measures of Boolean functions is a thriving topic of research in computational complexity. While decision tree complexity is long known to be polynomially related with many other measures, the optimal exponents of many of these relations are not known. It is known that decision tree complexity is bounded above by the cube of block sensitivity, and the cube of polynomial degree. However, the widest separation between decision tree complexity and each of block sensitivity and degree that is witnessed by known Boolean functions is quadratic.

Proving quadratic relations between these measures would resolve several open questions in decision tree complexity. For example, we get a tight relation between decision tree complexity and square of randomized decision tree complexity and a tight relation between zero-error randomized decision tree complexity and square of fractional block sensitivity, resolving an open question raised by Aaronson. In this work, we investigate the tightness of the existing cubic upper bounds. 

We improve the cubic upper bounds for many interesting classes of Boolean functions. We show that for graph properties and for functions with a constant number of alternations, both of the cubic upper bounds can be improved to quadratic. We define a class of Boolean functions, which we call the zebra functions, that comprises Boolean functions where each monotone path from $0^n$ to $1^n$ has an equal number of alternations. This class contains the symmetric and monotone functions as its subclasses. We show that for any zebra function, decision tree complexity is at most the square of block sensitivity, and certificate complexity is at most the square of degree. 

Finally, we show using a lifting theorem of communication complexity by G{\&quot;{o}}{\&quot;{o}}s, Pitassi and Watson that the task of proving an improved upper bound on the decision tree complexity for all functions is in a sense equivalent to the potentially easier task of proving a similar upper bound on communication complexity for each bi-partition of the input variables, for all functions. In particular, this implies that to bound the decision tree complexity it suffices to bound smaller measures like parity decision tree complexity, subcube decision tree complexity and decision tree rank, that are defined in terms of models that can be efficiently simulated by communication protocols.
        
        </div>

        <div class='item-content item-summary'>
        
          
          Relations between the decision tree complexity and various other complexity measures of Boolean functions is a thriving topic of research in computational complexity. While decision tree complexity is long known to be polynomially related with many other measures, the optimal exponents of many of these relations are not known. It is known that decision tree complexity is bounded above by the cube of block sensitivity, and the cube of polynomial degree. However, the widest separation between decision tree complexity and each of block sensitivity and degree that is witnessed by known Boolean functions is quadratic.

Proving quadratic relations between these measures would resolve several open questions in decision tree complexity. For example, we get a tight relation between decision tree complexity and square of randomized decision tree complexity and a tight relation between zero-error randomized decision tree complexity and square of fractional block sensitivity, resolving an open question raised by Aaronson. In this work, we investigate the tightness of the existing cubic upper bounds. 

We improve the cubic upper bounds for many interesting classes of Boolean functions. We show that for graph properties and for functions with a constant number of alternations, both of the cubic upper bounds can be improved to quadratic. We define a class of Boolean functions, which we call the zebra functions, that comprises Boolean functions where each monotone path from $0^n$ to $1^n$ has an equal number of alternations. This class contains the symmetric and monotone functions as its subclasses. We show that for any zebra function, decision tree complexity is at most the square of block sensitivity, and certificate complexity is at most the square of degree. 

Finally, we show using a lifting theorem of communication complexity by G{\&quot;{o}}{\&quot;{o}}s, Pitassi and Watson that the task of proving an improved upper bound on the decision tree complexity for all functions is in a sense equivalent to the potentially easier task of proving a similar upper bound on communication complexity for each bi-partition of the input variables, for all functions. In particular, this implies that to bound the decision tree complexity it suffices to bound smaller measures like parity decision tree complexity, subcube decision tree complexity and decision tree rank, that are defined in terms of models that can be efficiently simulated by communication protocols.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-25T06:22:55Z">Sunday, September 25 2022, 06:22</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://eccc.weizmann.ac.il/report/2022/134'>TR22-134 |  Some Games on Turing Machines and Power from Random Strings | 

	Alexey Milovanov, 

	Greg McLellan</a></h3>
          <p class='item-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Denote by $R$ the set of strings with high Kolmogorov complexity. In [E. Allender, H. Buhrman, M. Kouck\&#39;y, D. van Melkebeek, and D. Ronneburger.
Power from random strings.
\emph{SIAM Journal on Computing}, 35:1467--1493, 2006.] the idea of using $R$ as an oracle for resource-bounded computation models was presented. This idea was later developed in several others papers.
We prove new lower bounds for $Q^R_{tt}$ and $Q^R_{sa}$:
- Oblivious-NP is subset of $Q^R_{tt}$;
- Oblivious-MA is subset of $Q^R_{sa}$.

Here $Q$ means quazi-polynomial-time; ``sa&#39;&#39; means sub-adaptive
reduction - a new type of reduction that we introduce. This type of reduction is not weaker than truth-table reduction and is not stronger than Turing reduction.

Also we prove upper bounds for BBP^R_{tt} and P^R_{sa} following [E. Allender, L. Friedman, and W. Gasarch. Limits on the computational power of random
strings.]:

P^R_{sa} is subset of EXP
BBP^R_{tt} is subset of AEXP(poly).

Here AEXP(poly) is the class of languages decidable in exponential time by an alternating Turing machine that switches from an existential to a universal state or vice versa at most polynomial times.


Finally we analyze some games that originate in [E. Allender, L. Friedman, and W. Gasarch. Limits on the computational power of random
strings.]. We prove completeness of these games. These results show that methods in this can not prove better upper bounds for P^R, NP^R and P^R_{tt} than known.
        
        </div>

        <div class='item-content item-summary'>
        
          
          Denote by $R$ the set of strings with high Kolmogorov complexity. In [E. Allender, H. Buhrman, M. Kouck\&#39;y, D. van Melkebeek, and D. Ronneburger.
Power from random strings.
\emph{SIAM Journal on Computing}, 35:1467--1493, 2006.] the idea of using $R$ as an oracle for resource-bounded computation models was presented. This idea was later developed in several others papers.
We prove new lower bounds for $Q^R_{tt}$ and $Q^R_{sa}$:
- Oblivious-NP is subset of $Q^R_{tt}$;
- Oblivious-MA is subset of $Q^R_{sa}$.

Here $Q$ means quazi-polynomial-time; ``sa&#39;&#39; means sub-adaptive
reduction - a new type of reduction that we introduce. This type of reduction is not weaker than truth-table reduction and is not stronger than Turing reduction.

Also we prove upper bounds for BBP^R_{tt} and P^R_{sa} following [E. Allender, L. Friedman, and W. Gasarch. Limits on the computational power of random
strings.]:

P^R_{sa} is subset of EXP
BBP^R_{tt} is subset of AEXP(poly).

Here AEXP(poly) is the class of languages decidable in exponential time by an alternating Turing machine that switches from an existential to a universal state or vice versa at most polynomial times.


Finally we analyze some games that originate in [E. Allender, L. Friedman, and W. Gasarch. Limits on the computational power of random
strings.]. We prove completeness of these games. These results show that methods in this can not prove better upper bounds for P^R, NP^R and P^R_{tt} than known.
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-09-25T06:21:39Z">Sunday, September 25 2022, 06:21</time>
        </div>
      </div>
    </article>
  
  </div>

  <script src='js/jquery-2.0.3.min.js'></script>
  <script src="js/jquery.timeago.js" type="text/javascript"></script>
  <script>
    jQuery(document).ready(function() {
      jQuery("time.timeago").timeago();
    });
  </script>
  <script src='js/blank.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
