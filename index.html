<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>

  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.6 (2023-03-30) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/solid.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/regular.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/fontawesome.min.css">
  <link rel='stylesheet' type='text/css' href='css/theory.css'>
</head>
<body>
  <details class="tr-panel" open>
    <summary>
      <span>Last Update</span>
      <div class="tr-small">
        
          <time class='timeago' datetime="2023-04-13T06:32:21Z">Thursday, April 13 2023, 06:32</time>
        
      </div>
      <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
    </summary>
    <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

    <ul class='tr-subscriptions tr-small' >
    
      <li>
        <a href='http://arxiv.org/rss/cs.CC'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.CG'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
      </li>
    
      <li>
        <a href='http://arxiv.org/rss/cs.DS'><img src='icon/feed.png'></a>
        <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
      </li>
    
      <li>
        <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
      </li>
    
      <li>
        <a href='https://adamsheffer.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
      </li>
    
      <li>
        <a href='https://adamdsmith.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
      </li>
    
      <li>
        <a href='https://polylogblog.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
      </li>
    
      <li>
        <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
      </li>
    
      <li>
        <a href='http://www.argmin.net/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
      </li>
    
      <li>
        <a href='http://bit-player.org/feed/atom/'><img src='icon/feed.png'></a>
        <a href='http://bit-player.org'>bit-player</a>
      </li>
    
      <li>
        <a href='https://cstheory-jobs.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-jobs.org'>CCI: jobs</a>
      </li>
    
      <li>
        <a href='https://cstheory-events.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://cstheory-events.org'>CS Theory Events</a>
      </li>
    
      <li>
        <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
      </li>
    
      <li>
        <a href='https://11011110.github.io/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://11011110.github.io/blog/'>David Eppstein</a>
      </li>
    
      <li>
        <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='icon/feed.png'></a>
        <a href='https://daveagp.wordpress.com'>David Pritchard</a>
      </li>
    
      <li>
        <a href='https://decentdescent.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://decentdescent.org/'>Decent Descent</a>
      </li>
    
      <li>
        <a href='https://decentralizedthoughts.github.io/feed'><img src='icon/feed.png'></a>
        <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
      </li>
    
      <li>
        <a href='https://differentialprivacy.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
      </li>
    
      <li>
        <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='icon/feed.png'></a>
        <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
      </li>
    
      <li>
        <a href='https://emanueleviola.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
      </li>
    
      <li>
        <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='icon/feed.png'></a>
        <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
      </li>
    
      <li>
        <a href='https://dstheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
      </li>
    
      <li>
        <a href='https://francisbach.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://francisbach.com'>Francis Bach</a>
      </li>
    
      <li>
        <a href='https://gilkalai.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
      </li>
    
      <li>
        <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
      </li>
    
      <li>
        <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='icon/feed.png'></a>
        <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
      </li>
    
      <li>
        <a href='https://gradientscience.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://gradientscience.org/'>Gradient Science</a>
      </li>
    
      <li>
        <a href='http://grigory.us/blog/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
      </li>
    
      <li>
        <a href='https://minorfree.github.io/feed.xml'><img src='icon/feed.png'></a>
        <a href='https://minorfree.github.io'>Hung Le</a>
      </li>
    
      <li>
        <a href='https://tcsmath.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
      </li>
    
      <li>
        <a href='https://kamathematics.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
      </li>
    
      <li>
        <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
      </li>
    
      <li>
        <a href='https://lucatrevisan.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
      </li>
    
      <li>
        <a href='https://mittheory.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
      </li>
    
      <li>
        <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='icon/feed.png'></a>
        <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
      </li>
    
      <li>
        <a href='http://blog.mrtz.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
      </li>
    
      <li>
        <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
      </li>
    
      <li>
        <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
      </li>
    
      <li>
        <a href='http://www.solipsistslog.com/feed/'><img src='icon/feed.png'></a>
        <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
      </li>
    
      <li>
        <a href='http://www.offconvex.org/feed.xml'><img src='icon/feed.png'></a>
        <a href='http://offconvex.github.io/'>Off the Convex Path</a>
      </li>
    
      <li>
        <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='icon/feed.png'></a>
        <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
      </li>
    
      <li>
        <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='icon/feed.png'></a>
        <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
      </li>
    
      <li>
        <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
      </li>
    
      <li>
        <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='icon/feed.png'></a>
        <a href='https://blogs.princeton.edu/imabandit'>Sébastien Bubeck</a>
      </li>
    
      <li>
        <a href='https://scottaaronson.blog/?feed=atom'><img src='icon/feed.png'></a>
        <a href='https://scottaaronson.blog'>Scott Aaronson</a>
      </li>
    
      <li>
        <a href='https://blog.simons.berkeley.edu/feed/'><img src='icon/feed.png'></a>
        <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
      </li>
    
      <li>
        <a href='https://tcsplus.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
      </li>
    
      <li>
        <a href='https://toc4fairness.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://toc4fairness.org'>TOC for Fairness</a>
      </li>
    
      <li>
        <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='icon/feed.png'></a>
        <a href='http://blog.geomblog.org/'>The Geomblog</a>
      </li>
    
      <li>
        <a href='https://www.let-all.com/blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
      </li>
    
      <li>
        <a href='https://theorydish.blog/feed/'><img src='icon/feed.png'></a>
        <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
      </li>
    
      <li>
        <a href='https://thmatters.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://thmatters.wordpress.com'>Theory Matters</a>
      </li>
    
      <li>
        <a href='https://mycqstate.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
      </li>
    
      <li>
        <a href='https://agtb.wordpress.com/feed/'><img src='icon/feed.png'></a>
        <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
      </li>
    
      <li>
        <a href='https://windowsontheory.org/feed/'><img src='icon/feed.png'></a>
        <a href='https://windowsontheory.org'>Windows on Theory</a>
      </li>
    
    </ul>

    <p class='tr-small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
    <p class='tr-small'>Subscribe to the <a href="atom.xml">Atom feed</a>, <a href="rss20.xml">RSS feed</a>, or follow on <a href="https://twitter.com/cstheory">Twitter</a>, to stay up to date.</p>
    <p class='tr-small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
    <p class='tr-small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
    <p class='tr-small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
  </details>

  <div class="tr-opts">
    <i id='tr-show-headlines' class="fa-solid fa-fw fa-window-minimize tr-button" title='Show Headlines Only'></i>
    <i id='tr-show-snippets' class="fa-solid fa-fw fa-compress tr-button" title='Show Snippets'></i>
    <i id='tr-show-fulltext' class="fa-solid fa-fw fa-expand tr-button" title='Show Full Text'></i>
  </div>

  <h1>Theory of Computing Report</h1>

  <div class="tr-articles tr-shrink">
    
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Thursday, April 13
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/'>ACM Prize to Yael Kalai</a></h3>
        <p class='tr-article-feed'>from <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Plus evocations of the roles of complexity and verification in crypto and human relations Yael Kalai has just been named the winner of the 2022 ACM Prize. She works at Microsoft Research. Today we congratulate her, say a little about her work, and riff on some related and &#8220;unrelated&#8221; matters. The prize cites Kalai for [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>
<font color="#0044cc"><br />
<em>Plus evocations of the roles of complexity and verification in crypto and human relations</em><br />
<font color="#000000"></p>
<p><a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/kalai_6965246/" rel="attachment wp-att-21430"><img data-attachment-id="21430" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/kalai_6965246/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?fit=485%2C550&amp;ssl=1" data-orig-size="485,550" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kalai_6965246" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?fit=265%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?fit=485%2C550&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/kalai_6965246.jpeg?resize=124%2C138&#038;ssl=1" alt="" width="124" height="138" class="alignright wp-image-21430" data-recalc-dims="1" /></a></p>
<p>
Yael Kalai has just been named the winner of the <a href="https://awards.acm.org/about/2022-acm-prize">2022 ACM Prize</a>. She works at Microsoft Research. </p>
<p>
Today we congratulate her, say a little about her work, and riff on some related and &#8220;unrelated&#8221; matters.</p>
<p>
The prize cites Kalai for her work on cryptography. Her work is immediately practical. It provides both ways to speed up interactive protocols and to verify the results. Two ways of speeding up the kind of protocols we engage in daily are:</p>
<ol>
<li>
Reduce the number of rounds of interaction needed. </p>
<li>
Shift the computational burden from the weaker party (exemplified by your credit card chip) to the stronger party&#8212;without allowing the latter more ways to be malicious.
</ol>
<p>
One also needs to devise and provide an efficient certificate that the security needs have been met.</p>
<p>
<p><H2> Her Work </H2></p>
<p><p>
Kalai&#8217;s work on objective 1 starts with a <a href="https://en.wikipedia.org/wiki/Fiat-Shamir_heuristic">paradigm</a> originally expounded by Amos Fiat and Adi Shamir in the 1980s:</p>
<blockquote><p><b> </b> <em> An interactive round in which Arthur challenges Merlin with a string he chose <b>randomly</b> from public coins can be replaced by nonteractive requests to a random oracle. The oracle in turn can be simulated via a cryptographically strong hash function. </em>
</p></blockquote>
<p><p>
The second clause is the delicate one. How can we know, in a particular application, that a particular hash function does not have correlations that could be exploited by malicious choices of plaintext or seed strings? She and Shafi Goldwasser, her PhD advisor, <a href="https://eprint.iacr.org/2003/034.pdf">showed</a> cases where a 3-round protocol secure in the random oracle model becomes insecure under cases of this transformation. </p>
<p>
However, in a series of papers culminating in a <a href="https://dl.acm.org/doi/10.1145/3313276.3316380">Part I</a> and a <a href="https://eprint.iacr.org/2018/1248.pdf">Part II</a>, she and coauthors designed cases that work under progressively more reasonable hardness assumptions. (Note: the date on the &#8220;Part II&#8221; paper is three days earlier than that on the &#8220;Part I&#8221;&#8211;a good solution to a problem we noted at the end of <a href="https://rjlipton.wpcomstaging.com/2013/03/13/no-go-theorems/">this post</a>.)</p>
<p>
Objective 2 not only runs the risk of leakage in shifting the party who executes the computation, it involves issues of trust. How does the one who delegated the task know the result is correct, without having done the computation? This leads to issues of proving computations correct that we have mentioned, but with a twist: both the computation and the proof needs to be real-time efficient to generate. Her many papers on this (ACM features <a href="https://dl.acm.org/doi/10.1145/2699436">these</a> <a href="https://dl.acm.org/doi/pdf/10.1145/3456867">two</a>) are well represented in a <a href="https://gilkalai.files.wordpress.com/2018/01/cacm-delegation.pdf">survey</a> she presented at the 2018 International Congress of Mathematicians. Its abstract proclaims:</p>
<blockquote><p><b> </b> <em> Efficient verification of computation, also known as delegation of computation, is one of the most fundamental notions in computer science, and in particular it lies at the heart of the P vs. NP question. </em>
</p></blockquote>
<p>
<p><H2> P = NP: An Omen? </H2></p>
<p><p>
Her survey was unveiled &#8220;exclusively for our readers&#8221; in a January 6, 2018 <a href="https://gilkalai.wordpress.com/2018/01/06/yael-tauman-kalais-icm2018-paper-my-paper-and-cryptography/">post</a> by Gil Kalai, along with two photos of adoring father(-in-law)/grandparent type. We hasten to add that all this is not just about how &#8220;P=NP?&#8221; captures the question of whether it is as easy to <em>generate</em> a proof as to <em>verify</em> it. Much of Yael Kalai&#8217;s work depends on hardness assumptions that vanish if in fact P equals NP (with relevant efficiency).</p>
<p>
Thinking of Gil Kalai makes us leap to two other topics that are variously related and &#8220;unrelated.&#8221; Gil recently <a href="https://gilkalai.wordpress.com/2023/03/27/critical-times-in-israel-last-nights-demonstrations/">featured</a> the following photo from street protests in Israel on his blog:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/pnp-3/" rel="attachment wp-att-21433"><img data-attachment-id="21433" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/pnp-3/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?fit=1080%2C816&amp;ssl=1" data-orig-size="1080,816" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pnp" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?fit=300%2C227&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?fit=600%2C454&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=550%2C415&#038;ssl=1" alt="" width="550" height="415" class="aligncenter wp-image-21433" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=1024%2C774&amp;ssl=1 1024w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=300%2C227&amp;ssl=1 300w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=768%2C580&amp;ssl=1 768w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/pnp.jpg?w=1080&amp;ssl=1 1080w" sizes="(max-width: 550px) 100vw, 550px" data-recalc-dims="1" /></a></p>
<p><P><br />
The photo was also <a href="https://scottaaronson.blog/?p=7170">picked up</a> and commented on by Scott Aaronson on his blog. Gil added:</p>
<blockquote><p><b> </b> <em> Whether the picture is genuine or not, it shows the anarchist nature of at least some of the protestors. (We know for sure that some computer scientists were there.) I am not sure if a proof of this bold claim was also provided. </em>
</p></blockquote>
<p><p>
Lightheartedness aside, we wonder if this is an omen of growing public awareness of the connection of our field&#8217;s signature question not only to the security workings of governments, but to the walks of life represented by Yael Kalai&#8217;s applications. </p>
<p>
<p><H2> Educating GPT </H2></p>
<p><p>
Your humble bloggers face a kind of verification problem with nearly every post: how to pin down and attest basic facts. Here we remembered <a href="https://rjlipton.wpcomstaging.com/2014/12/13/chats/">writing</a> in 2014&#8212;correctly&#8212;that &#8220;Yael Kalai [is] not related to our friend Gil Kalai.&#8221; But learning that Yael Tauman married Adam Kalai (<a href="https://en.wikipedia.org/wiki/Yael_Tauman_Kalai">which</a> is <a href="https://www.facebook.com/adam.t.kalai/">attested</a> in <a href="https://kids.kiddle.co/Yael_Tauman_Kalai">many</a> <a href="https://www.microsoft.com/en-us/research/blog/new-england-researcher-finds-bliss/">places</a>) added another thing to check. The passage of time&#8212;and Gil&#8217;s photos&#8212;revived doubt. </p>
<p>
Heretofore we&#8217;ve refined the art of crafting Google queries to filter out professional information and bring what we want to the top page of hits. But in theory, such quests are better posed directly to the likes of ChatGPT. So I (Ken) did so, first to the free GPT-3.5:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt3-5kalais-2/" rel="attachment wp-att-21441"><img data-attachment-id="21441" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt3-5kalais-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?fit=590%2C458&amp;ssl=1" data-orig-size="590,458" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1681333545&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GPT3.5Kalais" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?fit=300%2C233&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?fit=590%2C458&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?resize=590%2C458&#038;ssl=1" alt="" width="590" height="458" class="aligncenter size-full wp-image-21441" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?w=590&amp;ssl=1 590w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT3.5Kalais-1.jpg?resize=300%2C233&amp;ssl=1 300w" sizes="(max-width: 590px) 100vw, 590px" data-recalc-dims="1" /></a></p>
<p><P><br />
Wait a second&#8212;has ChatGPT not been briefed on the injunction against incestuous marriage? Or have too many Roman and Greek emperors dominated its data? When Moses flung down and broke the stone tablets in exasperation, was it over chatbots? I tried the pay-grade version and got a different&#8212;but not better&#8212;answer:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisa-2/" rel="attachment wp-att-21442"><img data-attachment-id="21442" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisa-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?fit=540%2C350&amp;ssl=1" data-orig-size="540,350" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1681334250&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GPT4KalaisA" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?fit=300%2C194&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?fit=540%2C350&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?resize=540%2C350&#038;ssl=1" alt="" width="540" height="350" class="aligncenter size-full wp-image-21442" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?w=540&amp;ssl=1 540w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisA-1.jpg?resize=300%2C194&amp;ssl=1 300w" sizes="(max-width: 540px) 100vw, 540px" data-recalc-dims="1" /></a></p>
<p><P><br />
Nor did GPT-4 correct my typo of an extra &#8216;n.&#8217; Happily, Gil&#8217;s mention of the <a href="https://en.wikipedia.org/wiki/Ehud_Kalai">fourth Kalai</a>&#8212;and confirmation <a href="https://blog.computationalcomplexity.org/2008/07/games-and-computer-science.html">gratia</a> Lance Fortnow that I found via Google&#8212;enabled me to confront GPT-4 with a pertinent question. This produced an all-too-human reaction:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisb-2/" rel="attachment wp-att-21443"><img data-attachment-id="21443" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisb-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?fit=536%2C313&amp;ssl=1" data-orig-size="536,313" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1681334908&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GPT4KalaisB" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?fit=300%2C175&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?fit=536%2C313&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?resize=536%2C313&#038;ssl=1" alt="" width="536" height="313" class="aligncenter size-full wp-image-21443" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?w=536&amp;ssl=1 536w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisB-1.jpg?resize=300%2C175&amp;ssl=1 300w" sizes="(max-width: 536px) 100vw, 536px" data-recalc-dims="1" /></a></p>
<p><P><br />
&#8220;Confusion,&#8221; indeed? At the right are little hands to upvote or downvote responses. I upvoted the true one and gave the reason as, &#8220;it is true.&#8221; <em>Then</em> I down-voted the false one and clicked a reason button saying, &#8220;This isn&#8217;t true.&#8221; To my consternation a new box appeared:</p>
<p><P><br />
<a href="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisc-2/" rel="attachment wp-att-21444"><img data-attachment-id="21444" data-permalink="https://rjlipton.wpcomstaging.com/2023/04/12/acm-prize-to-yael-kalai/gpt4kalaisc-2/" data-orig-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?fit=642%2C384&amp;ssl=1" data-orig-size="642,384" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;KWRegan&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1681335110&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GPT4KalaisC" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?fit=300%2C179&amp;ssl=1" data-large-file="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?fit=600%2C359&amp;ssl=1" decoding="async" loading="lazy" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?resize=540%2C323&#038;ssl=1" alt="" width="540" height="323" class="aligncenter wp-image-21444" srcset="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?w=642&amp;ssl=1 642w, https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2023/04/GPT4KalaisC-1.jpg?resize=300%2C179&amp;ssl=1 300w" sizes="(max-width: 540px) 100vw, 540px" data-recalc-dims="1" /></a></p>
<p><P><br />
In words that won the 2016 Literature Nobel, <a href="https://en.wikipedia.org/wiki/No_Direction_Home">no direction home</a>. It seems our task of educating GPT will pale that in the wonderful play and movie <a href="https://en.wikipedia.org/wiki/Educating_Rita_(film)">Educating Rita</a>.</p>
<p>
<p><H2> Open Problems </H2></p>
<p><p>
Should we have been more worried if P=PSPACE was sprayed in the street? Or if a proof was referenced somehow?  As for GPT, it calls to our minds some other <a href="https://www.azlyrics.com/lyrics/simongarfunkel/thesoundofsilence.html">words</a> that have not yet won a Literature Nobel.  </p>
<p><P><br />
[some word tweaks]</p>
<p class="authors">By RJLipton+KWRegan</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T02:26:38Z">Thursday, April 13 2023, 02:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05598'>Optimal Testing of Generalized Reed-Muller Codes in Fewer Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Dor Minzer, Kai Zheng</p><p>A local tester for an error correcting code $C\subseteq \Sigma^{n}$ is a
tester that makes $Q$ oracle queries to a given word $w\in \Sigma^n$ and
decides to accept or reject the word $w$. An optimal local tester is a local
tester that has the additional properties of completeness and optimal
soundness. By completeness, we mean that the tester must accept with
probability $1$ if $w\in C$. By optimal soundness, we mean that if the tester
accepts with probability at least $1-\epsilon$ (where $\epsilon$ is small),
then it must be the case that $w$ is $O(\epsilon/Q)$-close to some codeword
$c\in C$ in Hamming distance.
</p>
<p>We show that Generalized Reed-Muller codes admit optimal testers with $Q =
(3q)^{\lceil{ \frac{d+1}{q-1}\rceil}+O(1)}$ queries. Here, for a prime power $q
= p^{k}$, the Generalized Reed-Muller code, RM[n,q,d], consists of the
evaluations of all $n$-variate degree $d$ polynomials over $\mathbb{F}_q$.
Previously, no tester achieving this query complexity was known, and the best
known testers due to Haramaty, Shpilka and Sudan(which is optimal) and due to
Ron-Zewi and Sudan(which was not known to be optimal) both required
$q^{\lceil{\frac{d+1}{q-q/p} \rceil}}$ queries. Our tester achieves query
complexity which is polynomially better than by a power of $p/(p-1)$, which is
nearly the best query complexity possible for generalized Reed-Muller codes.
</p>
<p>The tester we analyze is due to Ron-Zewi and Sudan, and we show that their
basic tester is in fact optimal. Our methods are more general and also allow us
to prove that a wide class of testers, which follow the form of the Ron-Zewi
and Sudan tester, are optimal. This result applies to testers for all
affine-invariant codes (which are not necessarily generalized Reed-Muller
codes).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Minzer_D/0/1/0/all/0/1">Dor Minzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Kai Zheng</a></p><p>A local tester for an error correcting code $C\subseteq \Sigma^{n}$ is a
tester that makes $Q$ oracle queries to a given word $w\in \Sigma^n$ and
decides to accept or reject the word $w$. An optimal local tester is a local
tester that has the additional properties of completeness and optimal
soundness. By completeness, we mean that the tester must accept with
probability $1$ if $w\in C$. By optimal soundness, we mean that if the tester
accepts with probability at least $1-\epsilon$ (where $\epsilon$ is small),
then it must be the case that $w$ is $O(\epsilon/Q)$-close to some codeword
$c\in C$ in Hamming distance.
</p>
<p>We show that Generalized Reed-Muller codes admit optimal testers with $Q =
(3q)^{\lceil{ \frac{d+1}{q-1}\rceil}+O(1)}$ queries. Here, for a prime power $q
= p^{k}$, the Generalized Reed-Muller code, RM[n,q,d], consists of the
evaluations of all $n$-variate degree $d$ polynomials over $\mathbb{F}_q$.
Previously, no tester achieving this query complexity was known, and the best
known testers due to Haramaty, Shpilka and Sudan(which is optimal) and due to
Ron-Zewi and Sudan(which was not known to be optimal) both required
$q^{\lceil{\frac{d+1}{q-q/p} \rceil}}$ queries. Our tester achieves query
complexity which is polynomially better than by a power of $p/(p-1)$, which is
nearly the best query complexity possible for generalized Reed-Muller codes.
</p>
<p>The tester we analyze is due to Ron-Zewi and Sudan, and we show that their
basic tester is in fact optimal. Our methods are more general and also allow us
to prove that a wide class of testers, which follow the form of the Ron-Zewi
and Sudan tester, are optimal. This result applies to testers for all
affine-invariant codes (which are not necessarily generalized Reed-Muller
codes).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05697'>Foundations for an Abstract Proof Theory in the Context of Horn Rules</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Tim S. Lyon, Piotr Ostropolski-Nalewaja</p><p>We introduce a novel, logic-independent framework for the study of
sequent-style proof systems, which covers a number of proof-theoretic
formalisms and concrete proof systems that appear in the literature. In
particular, we introduce a generalized form of sequents, dubbed 'g-sequents,'
which are taken to be binary graphs of typical, Gentzen-style sequents. We then
define a variety of 'inference rule types' as sets of operations that act over
such objects, and define 'abstract (sequent) calculi' as pairs consisting of a
set of g-sequents together with a finite set of operations. Our approach
permits an analysis of how certain inference rule types interact in a general
setting, demonstrating under what conditions rules of a specific type can be
permuted with or simulated by others, and being applicable to any sequent-style
proof system that fits within our framework. We then leverage our permutation
and simulation results to establish generic calculus and proof transformation
algorithms, which show that every abstract calculus can be effectively
transformed into a lattice of polynomially equivalent abstract calculi. We
determine the complexity of computing this lattice and compute the relative
sizes of proofs and sequents within distinct calculi of a lattice. We recognize
that top elements in lattices correspond to nested sequent systems, while
bottom elements correspond to labeled sequent systems, and observe that top and
bottom elements coincide with many known (cut-free) nested and labeled sequent
systems for logics characterized by Horn properties.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lyon_T/0/1/0/all/0/1">Tim S. Lyon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ostropolski_Nalewaja_P/0/1/0/all/0/1">Piotr Ostropolski-Nalewaja</a></p><p>We introduce a novel, logic-independent framework for the study of
sequent-style proof systems, which covers a number of proof-theoretic
formalisms and concrete proof systems that appear in the literature. In
particular, we introduce a generalized form of sequents, dubbed 'g-sequents,'
which are taken to be binary graphs of typical, Gentzen-style sequents. We then
define a variety of 'inference rule types' as sets of operations that act over
such objects, and define 'abstract (sequent) calculi' as pairs consisting of a
set of g-sequents together with a finite set of operations. Our approach
permits an analysis of how certain inference rule types interact in a general
setting, demonstrating under what conditions rules of a specific type can be
permuted with or simulated by others, and being applicable to any sequent-style
proof system that fits within our framework. We then leverage our permutation
and simulation results to establish generic calculus and proof transformation
algorithms, which show that every abstract calculus can be effectively
transformed into a lattice of polynomially equivalent abstract calculi. We
determine the complexity of computing this lattice and compute the relative
sizes of proofs and sequents within distinct calculi of a lattice. We recognize
that top elements in lattices correspond to nested sequent systems, while
bottom elements correspond to labeled sequent systems, and observe that top and
bottom elements coincide with many known (cut-free) nested and labeled sequent
systems for logics characterized by Horn properties.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05831'>When Should You Wait Before Updating? Toward a Robustness Refinement</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Swan Dubois, Laurent Feuilloley, Franck Petit, Mika&#xeb;l Rabie</p><p>Consider a dynamic network and a given distributed problem. At any point in
time, there might exist several solutions that are equally good with respect to
the problem specification, but that are different from an algorithmic
perspective, because some could be easier to update than others when the
network changes. In other words, one would prefer to have a solution that is
more robust to topological changes in the network; and in this direction the
best scenario would be that the solution remains correct despite the dynamic of
the network.
</p>
<p>In~\cite{CasteigtsDPR20}, the authors introduced a very strong robustness
criterion: they required that for any removal of edges that maintain the
network connected, the solution remains valid. They focus on the maximal
independent set problem, and their approach consists in characterizing the
graphs in which there exists a robust solution (the existential problem), or
even stronger, where any solution is robust (the universal problem). As the
robustness criteria is very demanding, few graphs have a robust solution, and
even fewer are such that all of their solutions are robust. In this paper, we
ask the following question: \textit{Can we have robustness for a larger class
of networks, if we bound the number $k$ of edge removals allowed}? (See the
full paper for the full abstract.)
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dubois_S/0/1/0/all/0/1">Swan Dubois</a>, <a href="http://arxiv.org/find/cs/1/au:+Feuilloley_L/0/1/0/all/0/1">Laurent Feuilloley</a>, <a href="http://arxiv.org/find/cs/1/au:+Petit_F/0/1/0/all/0/1">Franck Petit</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabie_M/0/1/0/all/0/1">Mika&#xeb;l Rabie</a></p><p>Consider a dynamic network and a given distributed problem. At any point in
time, there might exist several solutions that are equally good with respect to
the problem specification, but that are different from an algorithmic
perspective, because some could be easier to update than others when the
network changes. In other words, one would prefer to have a solution that is
more robust to topological changes in the network; and in this direction the
best scenario would be that the solution remains correct despite the dynamic of
the network.
</p>
<p>In~\cite{CasteigtsDPR20}, the authors introduced a very strong robustness
criterion: they required that for any removal of edges that maintain the
network connected, the solution remains valid. They focus on the maximal
independent set problem, and their approach consists in characterizing the
graphs in which there exists a robust solution (the existential problem), or
even stronger, where any solution is robust (the universal problem). As the
robustness criteria is very demanding, few graphs have a robust solution, and
even fewer are such that all of their solutions are robust. In this paper, we
ask the following question: \textit{Can we have robustness for a larger class
of networks, if we bound the number $k$ of edge removals allowed}? (See the
full paper for the full abstract.)
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05859'>A Hall-type theorem with algorithmic consequences in planar graphs</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Hossein Jowhari</p><p>Given a graph $G=(V,E)$, for a vertex set $S\subseteq V$, let $N(S)$ denote
the set of vertices in $V$ that have a neighbor in $S$. In this paper, we prove
the following Hall-type statement. Let $k \ge 2$ be an integer. Let $X$ be a
vertex set in the undirected graph $G$ such that for each subset $S$ of $X$ it
holds $|N(S)|\ge \frac1k {|S|}$. Then $G$ has a matching of size at least
$\frac{|X|}{k+1}$. Using this statement, we derive tight bounds for the
estimators of the matching size in planar graphs. These estimators are used in
designing sublinear space algorithms for approximating the maching size in the
data stream model of computation. In particular, we show the number of locally
superior vertices, introduced in \cite{Jowhari23}, is a $3$ factor
approximation of the matching size in planar graphs. The previous analysis
proved a $3.5$ approximation factor. In another consequence, we show a simple
setting of an estimator by Esfandiari \etal \cite{EHLMO15} achieves $3$ factor
approximation of the matching size in planar graphs. Namely, let $s$ be the
number of edges with both endpoints having degree at most $2$ and let $h$ be
the number of vertices with degree at least $3$. We show when the graph is
planar, the size of matching is at least $\frac{s+h}3$. This result generalizes
a known fact that every planar graph on $n$ vertices with minimum degree $3$
has a matching of size at least $\frac{n}3$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jowhari_H/0/1/0/all/0/1">Hossein Jowhari</a></p><p>Given a graph $G=(V,E)$, for a vertex set $S\subseteq V$, let $N(S)$ denote
the set of vertices in $V$ that have a neighbor in $S$. In this paper, we prove
the following Hall-type statement. Let $k \ge 2$ be an integer. Let $X$ be a
vertex set in the undirected graph $G$ such that for each subset $S$ of $X$ it
holds $|N(S)|\ge \frac1k {|S|}$. Then $G$ has a matching of size at least
$\frac{|X|}{k+1}$. Using this statement, we derive tight bounds for the
estimators of the matching size in planar graphs. These estimators are used in
designing sublinear space algorithms for approximating the maching size in the
data stream model of computation. In particular, we show the number of locally
superior vertices, introduced in \cite{Jowhari23}, is a $3$ factor
approximation of the matching size in planar graphs. The previous analysis
proved a $3.5$ approximation factor. In another consequence, we show a simple
setting of an estimator by Esfandiari \etal \cite{EHLMO15} achieves $3$ factor
approximation of the matching size in planar graphs. Namely, let $s$ be the
number of edges with both endpoints having degree at most $2$ and let $h$ be
the number of vertices with degree at least $3$. We show when the graph is
planar, the size of matching is at least $\frac{s+h}3$. This result generalizes
a known fact that every planar graph on $n$ vertices with minimum degree $3$
has a matching of size at least $\frac{n}3$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05883'>On Parallel k-Center Clustering</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Sam Coy, Artur Czumaj, Gopinath Mishra</p><p>We consider the classic $k$-center problem in a parallel setting, on the
low-local-space Massively Parallel Computation (MPC) model, with local space
per machine of $\mathcal{O}(n^{\delta})$, where $\delta \in (0,1)$ is an
arbitrary constant. As a central clustering problem, the $k$-center problem has
been studied extensively. Still, until very recently, all parallel MPC
algorithms have been requiring $\Omega(k)$ or even $\Omega(k n^{\delta})$ local
space per machine. While this setting covers the case of small values of $k$,
for a large number of clusters these algorithms require large local memory,
making them poorly scalable. The case of large $k$, $k \ge \Omega(n^{\delta})$,
has been considered recently for the low-local-space MPC model by Bateni et al.
(2021), who gave an $\mathcal{O}(\log \log n)$-round MPC algorithm that
produces $k(1+o(1))$ centers whose cost has multiplicative approximation of
$\mathcal{O}(\log\log\log n)$. In this paper we extend the algorithm of Bateni
et al. and design a low-local-space MPC algorithm that in $\mathcal{O}(\log\log
n)$ rounds returns a clustering with $k(1+o(1))$ clusters that is an
$\mathcal{O}(\log^*n)$-approximation for $k$-center.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Coy_S/0/1/0/all/0/1">Sam Coy</a>, <a href="http://arxiv.org/find/cs/1/au:+Czumaj_A/0/1/0/all/0/1">Artur Czumaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_G/0/1/0/all/0/1">Gopinath Mishra</a></p><p>We consider the classic $k$-center problem in a parallel setting, on the
low-local-space Massively Parallel Computation (MPC) model, with local space
per machine of $\mathcal{O}(n^{\delta})$, where $\delta \in (0,1)$ is an
arbitrary constant. As a central clustering problem, the $k$-center problem has
been studied extensively. Still, until very recently, all parallel MPC
algorithms have been requiring $\Omega(k)$ or even $\Omega(k n^{\delta})$ local
space per machine. While this setting covers the case of small values of $k$,
for a large number of clusters these algorithms require large local memory,
making them poorly scalable. The case of large $k$, $k \ge \Omega(n^{\delta})$,
has been considered recently for the low-local-space MPC model by Bateni et al.
(2021), who gave an $\mathcal{O}(\log \log n)$-round MPC algorithm that
produces $k(1+o(1))$ centers whose cost has multiplicative approximation of
$\mathcal{O}(\log\log\log n)$. In this paper we extend the algorithm of Bateni
et al. and design a low-local-space MPC algorithm that in $\mathcal{O}(\log\log
n)$ rounds returns a clustering with $k(1+o(1))$ clusters that is an
$\mathcal{O}(\log^*n)$-approximation for $k$-center.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05890'>Node-Differentially Private Estimation of the Number of Connected Components</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Iden Kalemaj, Sofya Raskhodnikova, Adam Smith, Charalampos E. Tsourakakis</p><p>We design the first node-differentially private algorithm for approximating
the number of connected components in a graph. Given a database representing an
$n$-vertex graph $G$ and a privacy parameter $\varepsilon$, our algorithm runs
in polynomial time and, with probability $1-o(1)$, has additive error
$\widetilde{O}(\frac{\Delta^*\ln\ln n}{\varepsilon}),$ where $\Delta^*$ is the
smallest possible maximum degree of a spanning forest of $G.$
Node-differentially private algorithms are known only for a small number of
database analysis tasks. A major obstacle for designing such an algorithm for
the number of connected components is that this graph statistic is not robust
to adding one node with arbitrary connections (a change that node-differential
privacy is designed to hide): {\em every} graph is a neighbor of a connected
graph.
</p>
<p>We overcome this by designing a family of efficiently computable Lipschitz
extensions of the number of connected components or, equivalently, the size of
a spanning forest. The construction of the extensions, which is at the core of
our algorithm, is based on the forest polytope of $G.$ We prove several
combinatorial facts about spanning forests, in particular, that a graph with no
induced $\Delta$-stars has a spanning forest of degree at most $\Delta$. With
this fact, we show that our Lipschitz extensions for the number of connected
components equal the true value of the function for the largest possible
monotone families of graphs. More generally, on all monotone sets of graphs,
the $\ell_\infty$ error of our Lipschitz extensions is nearly optimal.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kalemaj_I/0/1/0/all/0/1">Iden Kalemaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Raskhodnikova_S/0/1/0/all/0/1">Sofya Raskhodnikova</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1">Adam Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsourakakis_C/0/1/0/all/0/1">Charalampos E. Tsourakakis</a></p><p>We design the first node-differentially private algorithm for approximating
the number of connected components in a graph. Given a database representing an
$n$-vertex graph $G$ and a privacy parameter $\varepsilon$, our algorithm runs
in polynomial time and, with probability $1-o(1)$, has additive error
$\widetilde{O}(\frac{\Delta^*\ln\ln n}{\varepsilon}),$ where $\Delta^*$ is the
smallest possible maximum degree of a spanning forest of $G.$
Node-differentially private algorithms are known only for a small number of
database analysis tasks. A major obstacle for designing such an algorithm for
the number of connected components is that this graph statistic is not robust
to adding one node with arbitrary connections (a change that node-differential
privacy is designed to hide): {\em every} graph is a neighbor of a connected
graph.
</p>
<p>We overcome this by designing a family of efficiently computable Lipschitz
extensions of the number of connected components or, equivalently, the size of
a spanning forest. The construction of the extensions, which is at the core of
our algorithm, is based on the forest polytope of $G.$ We prove several
combinatorial facts about spanning forests, in particular, that a graph with no
induced $\Delta$-stars has a spanning forest of degree at most $\Delta$. With
this fact, we show that our Lipschitz extensions for the number of connected
components equal the true value of the function for the largest possible
monotone families of graphs. More generally, on all monotone sets of graphs,
the $\ell_\infty$ error of our Lipschitz extensions is nearly optimal.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-13T00:30:00Z">Thursday, April 13 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Wednesday, April 12
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://tcsplus.wordpress.com/2023/04/12/tcs-for-all-originally-tcs-women-spotlight-workshop-at-stoc-2023-rising-star-nominations/'>Guest Post: TCS for All (originally TCS Women) spotlight workshop at STOC 2023: Rising Star nominations</a></h3>
        <p class='tr-article-feed'>from <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          TCS for All (originally TCS Women) invites nominations for speakers in Rising Star talks at the TCS for All Spotlight Workshop at STOC 2023. To be eligible, your nominee has to be a senior PhD student with expected graduation no later than August 2024, or a postdoc in theoretical computer science (all topics represented at [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>TCS for All (originally TCS Women) invites nominations for speakers in Rising Star talks at the <a href="https://sigact.org/tcsforall/">TCS for All Spotlight Workshop</a> at <a href="http://acm-stoc.org/stoc2023/">STOC 2023</a>. To be eligible, your nominee has to be a senior PhD student with expected graduation no later than August 2024, or a postdoc in theoretical computer science (all topics represented at STOC are welcome), an underrepresented minority, and not a speaker at a previous TCS Women Spotlight Workshop. Preference will be given to speakers who are currently on the job market for postdoctoral/faculty positions, or who expect to be on the job market in Fall 2023.</p>



<p>You can make your nomination by <a href="https://forms.gle/jCMXsTmZ4DZ8r5xJA">filling this form</a> by <strong>May 7th</strong>. TCS for All Spotlight Workshop will be held on Thursday, June 22nd, 2023 (2-4pm), in Orlando, Florida, USA, as part of the 54th Symposium on Theory of Computing (STOC) and TheoryFest! We are happy to announce that our annual inspirational talk will be given by Professor Dana Randall!</p>



<p>For more information, check out the website: <a href="https://sigact.org/tcsforall/">https://sigact.org/tcsforall/</a></p>
<p class="authors">By plustcs</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T22:08:35Z">Wednesday, April 12 2023, 22:08</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/'>Thoughts on AI safety</a></h3>
        <p class='tr-article-feed'>from <a href='https://windowsontheory.org'>Windows on Theory</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Last week, I gave a lecture on AI safety as part of my deep learning foundations course. In this post, I’ll try to write down a few of my thoughts on this topic. (The lecture was three hours, and this blog post will not cover all of what we discussed or all the points that &#8230; Continue reading Thoughts on AI&#160;safety
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>Last week, I gave a lecture on AI safety as part of my <a href="https://boazbk.github.io/mltheoryseminar/">deep learning foundations course</a>. In this post, I’ll try to write down a few of my thoughts on this topic. (The lecture was three hours, and this blog post will not cover all of what we discussed or all the points that appeared in the pre-readings and the papers linked below.)  </p>



<p>The general goal of safety in artificial intelligence is to protect individual humans or society at large from harm. The field of AI safety is broad and considers risks including:</p>



<ol>
<li>Harm to users of an AI system or harm to third parties due to the system not functioning as intended. One example includes drivers or pedestrians harmed by the failures of self-driving cars. For instance, there were several fatal accidents involving Tesla&#8217;s autopilot. Interestingly, just last week, Elon Musk tweeted the following: <img width="355" height="320" src="https://lh6.googleusercontent.com/i9Z8g5ZkhsRZgxZgRMNf09mSgrrRY2zTK0ZukDVs3kooksLLCwroUgdZr6OSGBNb0DbtAFK3FBYW_DIVpOPuCSu4ImmboKNTZH6fq9hWlZiDkLWkxIVEJeMFEcx9UBOHgVlRPce772sv9AZo-E6MPVo"></li>



<li>Another example is harm from automated decisions that may be unfair. The paper of<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4238015"> Wang </a>et al. discusses the risks of “predictive optimization.” One well-known example is the COMPAS risk-assessment system for bail decisions (see <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Pro-Publica’s investigation</a>, as well as the broader discussion by <a href="https://arxiv.org/abs/1610.02413">Hardt, Price, and Srebro</a>)</li>



<li>Algorithmic decisions could cause “feedback loops”, where several algorithms interact with each other in unexpected and ever-escalating ways. Algorithmic trading was blamed for the <a href="https://en.wikipedia.org/wiki/2010_flash_crash">2010 “Flash Crash”</a>; another example is how a single not-very-rare book came to be priced <a href="https://www.wired.com/2011/04/amazon-flies-24-million/">at $24M on Amazon</a>.</li>



<li>There are many societal risks in AI. These include <a href="https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=7306d7e4782b">job loss</a>, <a href="https://www.nytimes.com/2019/11/19/technology/artificial-intelligence-bias.html">amplifying biases</a>, <a href="https://en.wikipedia.org/wiki/The_Age_of_Surveillance_Capitalism">concentrating power</a>, <a href="https://www.newyorker.com/culture/infinite-scroll/is-ai-art-stealing-from-artists">appropriating content</a>, and <a href="https://www.noemamag.com/the-exploited-labor-behind-artificial-intelligence/">exploiting data workers</a>.</li>



<li>Yet another issue was pointed out to me by Yejin Choi &#8211; “AI literacy.” As AI’s capabilities are rapidly advancing, it will take some time for people to get used to them, and during this time, we may misinterpret them. This is manifested in people seeing such systems as <a href="https://www.scientificamerican.com/article/google-engineer-claims-ai-chatbot-is-sentient-why-that-matters/">sentient</a> (something that already happened with the 1966 chatbot <a href="https://en.wikipedia.org/wiki/ELIZA_effect">ELIZA</a>). Another example is “deepfakes”: inauthentic images or videos that could mislead people that are not yet aware of AI’s capabilities (again, an issue with a <a href="https://en.wikipedia.org/wiki/Cottingley_Fairies">long history</a>).<br><br><img width="504" height="325" src="https://lh4.googleusercontent.com/DTisxiomU8oCYSmmjTUULGCvq8Cwy6Xxlq872pWXHU-gaC6SDgESdwRVdu_cyIGmHBgpleY2ozToXU-8MYADtUG8sPpfaKlbb_1HAlfvEnBG_nC1d3_oLZoNqC5hBw8VfK8aPNrDIZpM_812ia-hpco">    </li>



<li>AI could be misused by bad actors for hacking, spreading dis-information, help in designing weapons, and more.</li>



<li>Finally, several people are concerned about artificial intelligence systems acting themselves as “malicious agents”, which could behave in adversarial ways, harming humanity and in extreme cases leading to an existential risk of “loss of control” of humanity over its future or extinction.</li>
</ol>



<p>Different subfields of “AI safety” deal with different aspects of these risks. AI “<strong>assurance</strong>,<em>” </em>or quality control, is about ensuring that systems have clear specifications and satisfy these specifications. An example of work along these lines is <a href="https://arxiv.org/abs/1708.06374">Shalev-Shwartz et al</a>, who gave a framework for formally specifying safety assurances for self-driving cars.. AI <em><strong>ethics</strong></em> deals with the individual and social implications of deploying AI systems, asking the question of how AI systems could be deployed responsibly and even<em> </em>whether such a system should be deployed at all. <em><strong>Security</strong></em> deals with malicious actors, that could both be the users of AI, suppliers of data (e.g., data poisoning and prompt injection attacks), or control other aspects of the environment. Finally, researchers in <em>“<strong>alignment</strong>”</em> or <em>“<strong>existential risk</strong>”</em> are concerned with the case in which the AI itself is the adversary. These subfields are not disjoint and share overlapping concerns.</p>



<p>Another way to classify risks is to consider the extent to which they are reduced or magnified by the normal processes of the free market and improved technology. </p>



<figure class="wp-block-image size-large is-resized"><a href="https://windowsontheory.files.wordpress.com/2023/04/image-2.png"><img loading="lazy" data-attachment-id="8602" data-permalink="https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/image-2-4/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/04/image-2.png" data-orig-size="1224,692" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=656" src="https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=1024" alt="" class="wp-image-8602" width="680" height="385" srcset="https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=680 680w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png?w=768 768w, https://windowsontheory.files.wordpress.com/2023/04/image-2.png 1224w" sizes="(max-width: 680px) 100vw, 680px" /></a></figure>



<p>In some cases, the interests of safety go hand in hand with the economic incentives for the entity controlling the model, while in others they could be unrelated or even directly opposed to these incentives. Similarly, in some cases, improving capabilities (e.g., by increasing the size of models and data) would reduce risks, while in others, this might not help or even harm.</p>



<h2 class="wp-block-heading">Impact of AI on humanity &#8211; the baseline expectation</h2>



<p>Artificial intelligence is a very general technology, and as such, we might expect its impact on humanity to be qualitatively similar to that of past technological revolutions. If we look at the past, we can draw two lessons:</p>



<ol>
<li>Technological revolutions have both positive and negative impacts, but in the long run and summing over populations, the positives outweigh the negatives. For example, measures such as life expectancy and GDP per capita have gone up over history.</li>
</ol>



<figure class="wp-block-image"><img src="https://lh4.googleusercontent.com/Z8ccZBQmNvYP8ylKcAFuAox35d7rmpx16r1zpqAAyA6yG9X0xAVcNJFICaG5gbIKqH_2Af2EacONKXOnfQQRzMBGUA9FS0KTOD2Jw7ovvp2DXeRpofulsOKB1-2lYU0KjTAPIUNhrlcPGFEfK6WR8hw" alt="" /></figure>



<ol start="2">
<li>There is no reason to assume that the benefits of technology will be distributed equally. <a href="https://www.cbpp.org/research/poverty-and-inequality/a-guide-to-statistics-on-historical-trends-in-income-inequality">Inequality</a> can go either <a href="https://www.imf.org/external/pubs/ft/fandd/2011/09/picture.htm">up or down</a>, dependent on government policies rather than technological improvements. </li>
</ol>



<p>In my lecture, I discussed the issue of fairness. I discussed both the COMPAS system as well as the paper of <a href="https://arxiv.org/abs/1610.02413">Hardt et al</a>, visualized in the <a href="https://research.google.com/bigpicture/attacking-discrimination-in-ml/">following page</a>, demonstrating how different notions of fairness can be at odds with maximizing profits and even at odds with one another.  In this blog post, I focus on the settings where <strong>capabilities</strong> and <strong>safety </strong>may be at odds.</p>



<h2 class="wp-block-heading">Capabilities</h2>



<p>As is well known, the capabilities of artificial intelligence systems have been growing in recent years, see, for example this paper of <a href="https://arxiv.org/abs/2206.07682">Wei et al</a>. </p>



<figure class="wp-block-image is-resized"><img src="https://lh4.googleusercontent.com/M18nhEY3ApIXjrril-PxYPFrgx4mxgIxzIXYvXWaAXfgwguAO9r0igfIoYplJ59b1oV5_dTwe-QmETaHCN4_fZPmA4TTTOaxdiUD_YdEITKID8nVoctBU3Hg707JRKZ2ntqFUxOH6qmSPgCNbkH2HGs" alt="" width="543" height="367" /></figure>



<p>Graphs like these show capabilities emerging suddenly with model scale. However, we should note that these graphs are plotted with the X axis on the <strong>log scale.</strong> If we plot it on linear scale, it would be much less abrupt.&nbsp;</p>



<figure class="wp-block-image is-resized"><img src="https://lh5.googleusercontent.com/UbtJ1n09TuRPznworgdaznIIkGdceuK_ZUrVwpYqsGmjUUktxCfdHBAdtKTf-KG9-TZTf709ZS9gNDtnUr2BoCQeYq_KzsnQS3-NCOZEtkbYrqJCqzEXHfTfWlC2FnofBHIgfP5VsSkSu05jaYGkjug" alt="" width="635" height="376" /></figure>



<p>Another way to plot increasing capabilities is to look at improvements in ELO scores of Chess engines.&nbsp;</p>



<figure class="wp-block-image is-resized"><img src="https://lh3.googleusercontent.com/9MNusf0mSr5PExwfDqGULmPYEwuL7QU79m0fTBmzEI1iCXcVsYabauEiAjLSEq_owZUK1UqlImqwWIwuLTBP74fOXAldhbW988uARoG8N08mmsfawt4Q-PV2T3a8Hq4TgaKk5GCo_s6okNB2U7NyP0Y" alt="" width="691" height="369" /></figure>



<p>Once again, we see improvement with time. (Due to Moore’s law, we can also treat the X axis as a log scale here. BTW credit for this figure is due to GPT4; I didn’t verify the numbers though I probably should have.)</p>



<p>Given the above, we might expect future capabilities to increase roughly as follows: (this is a cartoon, so the slope or the labels on either axis should not be taken too seriously)<img src="https://lh3.googleusercontent.com/7t_z2fR0rHtTnjq7XVBa2kyQsPiIM3zFvXPo_GrXciBjNay046-9-WcVaSA9itWAbxD2o50K9VP6Q6UJHmw8_NA3jeSc2ngCOBsrBrJXjmBheqxe9kNESt-8UVgToR770JPTSSJKfoekfW7Z1IG9Ks4" width="474" height="349"></p>



<p>However, Moore’s law (assuming <a href="https://www.semianalysis.com/p/a-century-of-moores-law">it keeps holding</a>) can reduce costs as a function of time. Also, the graph may well behave differently for different skills. Finally, if we manage to use AI to reduce the costs of building future AI (i.e. “self improvement” or “singularity”), then the costs could be radically reduced.</p>



<h2 class="wp-block-heading">Capabilities vs. Safety Round 1: Risk of misuse</h2>



<p>One aspect in which increased capabilities seem to be at odds with safety is the potential for <em>misuse</em> of AI. The more powerful an AI system is, the more harm one can do with it. However, this logic assumes that only the attacker can access the system. In many cases, increased capabilities of AI benefits both the “attacker” and “defender”, and it is unclear which one would be helped more. </p>



<p>For example, AI systems could find software vulnerabilities and help hackers, but software companies could also use them to secure their systems. AI could be used to spread disinformation on social media and by social media companies to detect such disinformation. A related setting is the use of AI for persuasion. However, it is still an open question whether the current “limiting factor” in persuasion, whether it’s advertising or scams, is a lack of know-how or workforce on the part of the persuaders. Rather, it may be that different people have varying susceptibility to persuasion; thus, even very skilled persuaders will be limited in the number of people they can persuade and the things they can persuade them to do. Also, AI could be used to combat illicit persuasion by detecting scams, just as it is currently used in spam detection.</p>



<p>An example closest to my expertise is student cheating. AI may help professors detect cheating more than it helps potential cheaters. In past semesters, if I wanted to detect whether two students copied from one another, I needed to &#8220;run&#8221; an N² time algorithm (manually comparing all pairs of submissions).  Now I could ask ChatGPT to compare all pairs and summarize any suspicious similarities. If I am worried about students using ChatGPT itself to cheat, I can ask it to throw its own solution into the pool of comparands (and maybe some solutions from past semesters or Course Hero as well). </p>



<p>There are other misuse scenarios in which the balance does favor the attacker. For example, an attacker might be able to use a system to learn how to make a bomb or get detailed information about a physical target for an attack. However, society has been through inflection points such as this in the past, when the amount of information available to ordinary citizens radically increased. It is unclear to me that the increase in access to harmful information due to AI would be larger than the increase between the pre- and post-Internet eras. </p>



<h2 class="wp-block-heading">Capabilities vs. Safety Round 2: Unaligned powerful AI systems<br></h2>



<p>The other setting in which increased capabilities could lead to higher risk is when we are concerned with the AI systems themselves behaving in “agentic” or malicious ways. We do not have to get into the question of whether such systems could be “sentient” or “concious” but rather ask whether it might be possible that the systems’ actions would be so complex and unpredictable that they could be modeled as adversarial. </p>



<p>There is a long history of worrying about such risks. Alan Turing famously said in 1951 that <em>“it seems probable that once the machine thinking method had started, it would not take long to outstrip our feeble powers. They would be able to converse with each other to sharpen their wits. At some stage therefore, we should have to expect the machines to take control.”</em></p>



<figure class="wp-block-image size-large is-resized"><a href="https://windowsontheory.files.wordpress.com/2023/04/image-1.png"><img loading="lazy" data-attachment-id="8598" data-permalink="https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/image-1-4/" data-orig-file="https://windowsontheory.files.wordpress.com/2023/04/image-1.png" data-orig-size="1224,464" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=300" data-large-file="https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=656" src="https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=1024" alt="" class="wp-image-8598" width="656" height="248" srcset="https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=1024 1024w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=654 654w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=150 150w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=300 300w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png?w=768 768w, https://windowsontheory.files.wordpress.com/2023/04/image-1.png 1224w" sizes="(max-width: 656px) 100vw, 656px" /></a></figure>



<p>There are two metaphors for a “super human AI”. One is the model of an AI as a<strong> “genie”:</strong> an entity that is single-mindedly focused on optimizing some objective (a.k.a granting a wish). However, like the genies in many stories, it may interpret the wish in a way that is literally true but completely misaligned with the intentions and interests of the human who made it. A less fanciful way to phrase this is that we expect that <em>any</em> objective, when pursued relentlessly, will eventually be misaligned with the general well-being of society. In his <a href="https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html">blog</a>, Jascha Sohl-Dickstein called this principle the “strong version of Goodhat’s law” and illustrated it as follows:</p>



<figure class="wp-block-image is-resized"><img src="https://lh5.googleusercontent.com/BdPFfV53mLAN3gY6IkBCImnNXHbZW_P4LO97CMg_NGBXPp-03s21GWo0isaDZMaWaP4b-16997bp6fmG2Yb8KAYBHoSACfl_m9XwRTYXmQnUIPv8OL2zJBxnx749bnhvJLlJeBdLaOt5VXWjfNbN75A" alt="" width="545" height="279" /></figure>



<p>Specifically, the concern is that to satisfy any objective, it seems useful to <a href="https://arxiv.org/abs/1912.01683">seek power</a>, and it is possible systems might use deception as well. <a href="https://arxiv.org/abs/2209.00626">Ngo et al </a>raised the concern that such systems would develop “situational awareness” and behave differently when trained and deployed.</p>



<p>The other metaphor for a “super-human AI” is the one of the “alien”: it is highly intelligent, but like us, it is not focused on a single goal; rather, its intelligence (to use another term from Sohl-Dickstein) is a “hot mess”. Being like us is not necessarily a good thing. For example, the interaction between early modern humans and the Neanderthals did not go well for the latter. (Though <a href="https://www.nature.com/articles/s41598-021-84410-7">we</a> <a href="https://www.discovermagazine.com/planet-earth/neanderthal-brains-bigger-not-necessarily-better">don’t</a> <a href="https://www.nature.com/articles/s41559-021-01391-6">know</a> whether or not Homo Sapiens had cognitive advantages over Neanderthals, and if so, whether those played a key role in the Neanderthal’s extinction. Also, as our society has grown more sophisticated, we are trying to do more to <a href="https://www.iucn.org/">conserve</a> rather than extinguish other species.)</p>



<p>The “AI as a genie” metaphor arises from the fact that AI systems are often the result of some optimization procedure. In particular, in <em>reinforcement learning (RL)</em>, the system is trained to maximize some <em>reward</em>. While RL wasn’t used in earlier large language models (LLMs), it has <a href="https://arxiv.org/abs/2203.02155">recently been used</a> in models such as GPT3.5, training a “reward model” from human feedback that is later used in an RL procedure to generate a sequence of tokens that maximizes the reward (this is known as RL from human feedback or RLHF). Ngo et al claimed that the use of RLHF could lead models to “reward hacking” in which the model pursues goals that, like in the “strong version of Goodhart’s law” would be ultimately detrimental to humanity.</p>



<p>To me, this particular concern hinges on the question of whether RLHF amounts to most of the “magic” in modern LLMs or whether (to use a phrase favored by <a href="https://medium.com/syncedreview/yann-lecun-cake-analogy-2-0-a361da560dae">Yann LeCun</a>) it is merely the “cherry on top”. </p>



<figure class="wp-block-image"><img src="https://lh3.googleusercontent.com/tmylI-HGa_ec4wXtiYfu9t2hgBAq3UcnwyUtOqydL-nl0tL1ZD3eo6BwOHt4K5EaFaR998IuMbxu7k5N9k3FukbmCznqRmKqu0n8vMVmwqgy81mQgrn1aXSmTvzukQ0YLw-3b1s4KHaihOrIHdGBsAs" alt="" /></figure>



<p>If we believe that “magic” corresponds to computational or data resources, then RLHF is merely the &#8220;cherry on top&#8221;. While OpenAI did not reveal details, <a href="https://arxiv.org/abs/2204.05862">Anthropic</a> trained a similar model and used about 10¹¹ tokens in pre-training, while only about 10⁵ human annotations for RLHF.  So if the computational scale is the same as “magic,” then intelligence is formed at pre-training and only shaped by RLHF. Is scale the same as magic? I would argue that this is what <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">the bitter lesson</a> tells us.</p>



<p>Even so, should we still be worried about the “alien” model? The question is, again, who is the alien? Do we think of the AI system as the combination of the pre-trained model and whatever “fine tuning” or “reinforcement learning” adapter is on top of it? Or is the heart of the system the pre-trained model itself? </p>



<p>If we consider the pre-trained model as the heart of the system, then I argue that modeling it as an individual entity or agent is misguided.&nbsp; In fact:</p>



<blockquote class="wp-block-quote">
<p><em>A pre-trained language model is not an imitation of any human, it is an imitation of all of humanity.</em></p>
</blockquote>



<p>A pre-trained generative text model is not designed to model any particular entity. Rather, it is designed to generate all text that it has been trained on and, along the way, develop the skills to perform deductions, combinations, and style transfers on this text. To use such a model as an assistant, we need to <em>condition</em> it by providing a <a href="https://www.reddit.com/r/copypasta/comments/111mlh7/entire_microsoft_bing_ai_prompt_leaked/">prompt</a>, much like we can condition an image generative model to generate images inside one particular building. If we think of a pre-trained model as an “intelligence engine” that is later used with “adapters” (that could include learned models, hard-coded programs, as well as humans), then our assumptions on the risk scenarios change. Rather than a monolithic “AI system” that could act in adversarial ways, we might have a variety of agents/modules built on top of the “intelligence engine”. Some of these agents, whether human or artificial, may well be adversarial. However, all of those would have access to the same “engine,” and so the rising tide of AI will lift all (good and bad) boats. </p>



<figure class="wp-block-image"><img src="https://lh6.googleusercontent.com/dUGyRSPiw0M1Gnb4UYsMOMff-n536k3BJ7VfBUQvf3dgIIeRd7Ns5CTzdtIK9JPbYfP4Xsdir73jIFIc-q-X3ttfb-K8vAu78eW2GckWfsBzf5dmaDVXaCai-So9fC5n8GBxNr2rA9eHyFA9Ezl_T4g" alt="" /></figure>



<p>Generally, I think that the view of “intelligence” as some inherent skill belonging to a monolithic entity or agent is quite anthropocentric. In fact, it’s not even true for humans. While the human brains have not grown for more than hundred thousand years,  human society has collectively become more intelligent over the last millennia and centuries, and all of us can access this collective intelligence. Indeed, with modern deep learning, we can take any advanced AI system and <em>fine-tune</em> it to achieve a particular task of interest. Hence<strong> intelligence is not so much a skill of an individual as a capability of the system as a whole.</strong></p>



<h2 class="wp-block-heading">Verification</h2>



<p>Regardless of whether you are concerned about AI taking over humanity or simply about the wisdom of deploying highly complex systems that we don’t fully understand, <em>verification</em> can be a crucial element for ensuring safety. One of the general principles we see time and again in theoretical computer science is that</p>



<blockquote class="wp-block-quote">
<p><em>Verification is easier than creation.</em></p>
</blockquote>



<p>(In other words, it’s easier to be the critic than the “<a href="https://www.theodorerooseveltcenter.org/Learn-About-TR/TR-Encyclopedia/Culture-and-Society/Man-in-the-Arena.aspx">man in the arena</a>” &#8211; and that’s a good thing!)</p>



<p>This is the content of the P vs NP conjecture and also underlies the theory of <a href="http://people.csail.mit.edu/madhu/papers/2009/pcpcacm.pdf">probabilistically  checkable proofs. (PCPs)</a> These are now used in cryptography to delegate computation by a weak verifier to a powerful server (see this <a href="https://cap.csail.mit.edu/engage/spotlights/yael-kalai">interview</a> with Yael Kalai, and her <a href="https://gilkalai.files.wordpress.com/2018/01/cacm-delegation.pdf">survey</a>) which is a problem not unlike the task of verifying a powerful AI by a weaker entity.</p>



<p>I recently saw a talk by Zico Kolter in which he put forward the following equation as to when generative models have positive utility:</p>



<figure class="wp-block-image"><img src="https://lh3.googleusercontent.com/aQtCbNVlUK1AM_V2PvU1iSNwwRH_Zhg3bH_XcU7_jwYMi6yJDRAP7kHVbLuUwkDPi_H9kYcHJeImzlMow-oVtjhaQwOJJuk89Yf6nOtBrxdzBq6AGd_EYvKUM4R0ES6s8rA0Q9nihvnqomayae2COt4" alt="" /></figure>



<p>That is, as long as the time for us to verify a solution is smaller than the time to generate it ourselves multiplied by the probability that the model’s output is correct, then we can efficiently use a model by always verifying its output, spending the effort to generate a solution ourself if verification fails. Our expected time would be smaller than the time spent generating solutions from scratch, even if the model is far from always correct.</p>



<p>The principle that verification can be done even with powerful provers is one we see in human enterprises as well. <a href="https://en.wikipedia.org/wiki/Terence_Tao">Terence Tao</a> might be (by some measures) the world’s top mathematician. But he still submits his papers to peer review, and they can (and are) checked by mere “mortals”. Indeed I would argue that this ability to <strong>communicate</strong>, <strong>verify</strong>, and <strong>teach</strong> is <em>the reason</em> that human society has managed to “stand on the shoulders of giants” and achieve such growth in productivity despite working with the same human brains our ancestors used to run from animals. Theories like relativity may have taken a huge effort to <em>discover</em>, but once discovered, could be communicated, verified, and are now taught to first-year undergraduates.</p>



<p>Interestingly, it seems that the professions that are <a href="https://academic.oup.com/qje/article-abstract/132/4/1877/3859758?redirectedFrom=fulltext&amp;login=false">more subject to verification</a> are not the ones that require the most information-processing skills but rather “alignment”: more “wisdom” than “smartness”. Perhaps those professions <a href="https://windowsontheory.org/2022/11/22/ai-will-change-the-world-but-wont-take-it-over-by-playing-3-dimensional-chess/">would not be the professions most amenable for AIs</a>.</p>



<figure class="wp-block-image"><img src="https://lh3.googleusercontent.com/zt9TK0wqTCqgyCcwOelndi2KWvqbc7EEkTMfkw09CFOyT0Sj5QuafmRF9ro-VaMpR_n6JD-1txqau3c4bc1QWbPaE5G-942lomjrSk3qGS2XVIkcYppZ5t1OPxKVkEYbZpPOttrCQEdv4-yBCeqn-Rg" alt="" /></figure>



<p>Practical verification of ML systems is still an ongoing effort. There are methods for <a href="https://www.deepmind.com/publications/red-teaming-language-models-with-language-models">red teaming</a>, <a href="https://arxiv.org/abs/2206.05802">self-critiquing</a>,  <a href="https://arxiv.org/abs/2205.11822">probing for consistency</a>, or <a href="https://arxiv.org/abs/2112.02969">testing generated code</a> that can reduce errors. However, we do not yet have robust verification schemes in the sense that we can reliably drive the error probability to zero by spending more effort at inference (let alone drive it <em>exponentially fast</em> to zero, as we can often do in theoretical CS- something that may be crucial for ensuring robustness against adversarial inputs).</p>



<figure class="wp-block-image"><img src="https://lh5.googleusercontent.com/ylrE7vqPWD3urdsy34vHOGxzEleKZr9906UMKksSNDeIkeg1y9p_4Pqwi2dikT__blW7cYjOxAfraLhsavMWPwSYMLbIBuGPdM27_TbEFPtNXaFDt2rlHxj6dq1AoKwNWPFe4VOgjxgQlGk4ppF2_-U" alt="" /></figure>



<p>One potential advantage of AI models is that they can themselves write symbolic proofs that may later be verifiable with formal theorem provers. For example, <a href="https://arxiv.org/abs/2205.12615">Wu et al</a> used LLMs to formalize mathematical competition problems in the systems Isabelle/HOL. Overall, there seems to be a huge potential in combining the rich literature on proof systems with the power of modern language models.</p>



<p>To sum up, artificial Intelligence has made great strides in performance over the last decade and will be widely deployed across many fields in the near future. As the use of AI systems increases, so will the importance of ensuring reliability, fairness, trustworthiness, and security.</p>
<p class="authors">By Boaz Barak</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T15:25:45Z">Wednesday, April 12 2023, 15:25</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04837'>Geometry of Rounding: Near Optimal Bounds and a New Neighborhood Sperner's Lemma</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jason Vander Woude, Peter Dixon, A. Pavan, Jamie Radcliffe, N. V. Vinodchandran</p><p>A partition $\mathcal{P}$ of $\mathbb{R}^d$ is called a
$(k,\varepsilon)$-secluded partition if, for every $\vec{p} \in \mathbb{R}^d$,
the ball $\overline{B}_{\infty}(\varepsilon, \vec{p})$ intersects at most $k$
members of $\mathcal{P}$. A goal in designing such secluded partitions is to
minimize $k$ while making $\varepsilon$ as large as possible. This partition
problem has connections to a diverse range of topics, including deterministic
rounding schemes, pseudodeterminism, replicability, as well as Sperner/KKM-type
results.
</p>
<p>In this work, we establish near-optimal relationships between $k$ and
$\varepsilon$. We show that, for any bounded measure partitions and for any
$d\geq 1$, it must be that $k\geq(1+2\varepsilon)^d$. Thus, when $k=k(d)$ is
restricted to ${\rm poly}(d)$, it follows that $\varepsilon=\varepsilon(d)\in
O\left(\frac{\ln d}{d}\right)$. This bound is tight up to log factors, as it is
known that there exist secluded partitions with $k(d)=d+1$ and
$\varepsilon(d)=\frac{1}{2d}$. We also provide new constructions of secluded
partitions that work for a broad spectrum of $k(d)$ and $\varepsilon(d)$
parameters. Specifically, we prove that, for any
$f:\mathbb{N}\rightarrow\mathbb{N}$, there is a secluded partition with
$k(d)=(f(d)+1)^{\lceil\frac{d}{f(d)}\rceil}$ and
$\varepsilon(d)=\frac{1}{2f(d)}$. These new partitions are optimal up to
$O(\log d)$ factors for various choices of $k(d)$ and $\varepsilon(d)$. Based
on the lower bound result, we establish a new neighborhood version of Sperner's
lemma over hypercubes, which is of independent interest. In addition, we prove
a no-free-lunch theorem about the limitations of rounding schemes in the
context of pseudodeterministic/replicable algorithms.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Woude_J/0/1/0/all/0/1">Jason Vander Woude</a>, <a href="http://arxiv.org/find/cs/1/au:+Dixon_P/0/1/0/all/0/1">Peter Dixon</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavan_A/0/1/0/all/0/1">A. Pavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Radcliffe_J/0/1/0/all/0/1">Jamie Radcliffe</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinodchandran_N/0/1/0/all/0/1">N. V. Vinodchandran</a></p><p>A partition $\mathcal{P}$ of $\mathbb{R}^d$ is called a
$(k,\varepsilon)$-secluded partition if, for every $\vec{p} \in \mathbb{R}^d$,
the ball $\overline{B}_{\infty}(\varepsilon, \vec{p})$ intersects at most $k$
members of $\mathcal{P}$. A goal in designing such secluded partitions is to
minimize $k$ while making $\varepsilon$ as large as possible. This partition
problem has connections to a diverse range of topics, including deterministic
rounding schemes, pseudodeterminism, replicability, as well as Sperner/KKM-type
results.
</p>
<p>In this work, we establish near-optimal relationships between $k$ and
$\varepsilon$. We show that, for any bounded measure partitions and for any
$d\geq 1$, it must be that $k\geq(1+2\varepsilon)^d$. Thus, when $k=k(d)$ is
restricted to ${\rm poly}(d)$, it follows that $\varepsilon=\varepsilon(d)\in
O\left(\frac{\ln d}{d}\right)$. This bound is tight up to log factors, as it is
known that there exist secluded partitions with $k(d)=d+1$ and
$\varepsilon(d)=\frac{1}{2d}$. We also provide new constructions of secluded
partitions that work for a broad spectrum of $k(d)$ and $\varepsilon(d)$
parameters. Specifically, we prove that, for any
$f:\mathbb{N}\rightarrow\mathbb{N}$, there is a secluded partition with
$k(d)=(f(d)+1)^{\lceil\frac{d}{f(d)}\rceil}$ and
$\varepsilon(d)=\frac{1}{2f(d)}$. These new partitions are optimal up to
$O(\log d)$ factors for various choices of $k(d)$ and $\varepsilon(d)$. Based
on the lower bound result, we establish a new neighborhood version of Sperner's
lemma over hypercubes, which is of independent interest. In addition, we prove
a no-free-lunch theorem about the limitations of rounding schemes in the
context of pseudodeterministic/replicable algorithms.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04970'>GRIL: A $2$-parameter Persistence Based Vectorization for Machine Learning</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Cheng Xin, Soham Mukherjee, Shreyas N. Samaga, Tamal K. Dey</p><p>$1$-parameter persistent homology, a cornerstone in Topological Data Analysis
(TDA), studies the evolution of topological features such as connected
components and cycles hidden in data. It has been applied to enhance the
representation power of deep learning models, such as Graph Neural Networks
(GNNs). To enrich the representations of topological features, here we propose
to study $2$-parameter persistence modules induced by bi-filtration functions.
In order to incorporate these representations into machine learning models, we
introduce a novel vector representation called Generalized Rank Invariant
Landscape \textsc{Gril} for $2$-parameter persistence modules. We show that
this vector representation is $1$-Lipschitz stable and differentiable with
respect to underlying filtration functions and can be easily integrated into
machine learning models to augment encoding topological features. We present an
algorithm to compute the vector representation efficiently. We also test our
methods on synthetic and benchmark graph datasets, and compare the results with
previous vector representations of $1$-parameter and $2$-parameter persistence
modules.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Xin_C/0/1/0/all/0/1">Cheng Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1">Soham Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Samaga_S/0/1/0/all/0/1">Shreyas N. Samaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_T/0/1/0/all/0/1">Tamal K. Dey</a></p><p>$1$-parameter persistent homology, a cornerstone in Topological Data Analysis
(TDA), studies the evolution of topological features such as connected
components and cycles hidden in data. It has been applied to enhance the
representation power of deep learning models, such as Graph Neural Networks
(GNNs). To enrich the representations of topological features, here we propose
to study $2$-parameter persistence modules induced by bi-filtration functions.
In order to incorporate these representations into machine learning models, we
introduce a novel vector representation called Generalized Rank Invariant
Landscape \textsc{Gril} for $2$-parameter persistence modules. We show that
this vector representation is $1$-Lipschitz stable and differentiable with
respect to underlying filtration functions and can be easily integrated into
machine learning models to augment encoding topological features. We present an
algorithm to compute the vector representation efficiently. We also test our
methods on synthetic and benchmark graph datasets, and compare the results with
previous vector representations of $1$-parameter and $2$-parameter persistence
modules.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04852'>The Kraft--Barmpalias--Lewis-Pye lemma revisited</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Shen</p><p>This note provides a simplified exposition of the proof of hierarchical Kraft
lemma proven by Barmpalias and Lewis-Pye and its consequences for the oracle
use in the Ku\v{c}era--G\'acs theorem (saying that every sequence is Turing
reducible to a random one).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Shen_A/0/1/0/all/0/1">Alexander Shen</a></p><p>This note provides a simplified exposition of the proof of hierarchical Kraft
lemma proven by Barmpalias and Lewis-Pye and its consequences for the oracle
use in the Ku\v{c}era--G\'acs theorem (saying that every sequence is Turing
reducible to a random one).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04932'>Robust Dequantization of the Quantum Singular value Transformation and Quantum Machine Learning Algorithms</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fran&#xe7;ois Le Gall</p><p>Several quantum algorithms for linear algebra problems, and in particular
quantum machine learning problems, have been "dequantized" in the past few
years. These dequantization results typically hold when classical algorithms
can access the data via length-squared sampling. In this work we investigate
how robust these dequantization results are. We introduce the notion of
approximate length-squared sampling, where classical algorithms are only able
to sample from a distribution close to the ideal distribution in total
variation distance. While quantum algorithms are natively robust against small
perturbations, current techniques in dequantization are not. Our main technical
contribution is showing how many techniques from randomized linear algebra can
be adapted to work under this weaker assumption as well. We then use these
techniques to show that the recent low-rank dequantization framework by Chia,
Gily\'en, Li, Lin, Tang and Wang (JACM 2022) and the dequantization framework
for sparse matrices by Gharibian and Le Gall (STOC 2022), which are both based
on the Quantum Singular Value Transformation, can be generalized to the case of
approximate length-squared sampling access to the input. We also apply these
results to obtain a robust dequantization of many quantum machine learning
algorithms, including quantum algorithms for recommendation systems, supervised
clustering and low-rank matrix inversion.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Gall_F/0/1/0/all/0/1">Fran&#xe7;ois Le Gall</a></p><p>Several quantum algorithms for linear algebra problems, and in particular
quantum machine learning problems, have been "dequantized" in the past few
years. These dequantization results typically hold when classical algorithms
can access the data via length-squared sampling. In this work we investigate
how robust these dequantization results are. We introduce the notion of
approximate length-squared sampling, where classical algorithms are only able
to sample from a distribution close to the ideal distribution in total
variation distance. While quantum algorithms are natively robust against small
perturbations, current techniques in dequantization are not. Our main technical
contribution is showing how many techniques from randomized linear algebra can
be adapted to work under this weaker assumption as well. We then use these
techniques to show that the recent low-rank dequantization framework by Chia,
Gily\'en, Li, Lin, Tang and Wang (JACM 2022) and the dequantization framework
for sparse matrices by Gharibian and Le Gall (STOC 2022), which are both based
on the Quantum Singular Value Transformation, can be generalized to the case of
approximate length-squared sampling access to the input. We also apply these
results to obtain a robust dequantization of many quantum machine learning
algorithms, including quantum algorithms for recommendation systems, supervised
clustering and low-rank matrix inversion.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04954'>An Associativity Threshold Phenomenon in Set-Associative Caches</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Michael A. Bender, Rathish Das, Mart&#xed;n Farach-Colton, Guido Tagliavini</p><p>In an $\alpha$-way set-associative cache, the cache is partitioned into
disjoint sets of size $\alpha$, and each item can only be cached in one set,
typically selected via a hash function. Set-associative caches are widely used
and have many benefits, e.g., in terms of latency or concurrency, over fully
associative caches, but they often incur more cache misses. As the set size
$\alpha$ decreases, the benefits increase, but the paging costs worsen.
</p>
<p>In this paper we characterize the performance of an $\alpha$-way
set-associative LRU cache of total size $k$, as a function of $\alpha =
\alpha(k)$. We prove the following, assuming that sets are selected using a
fully random hash function:
</p>
<p>- For $\alpha = \omega(\log k)$, the paging cost of an $\alpha$-way
set-associative LRU cache is within additive $O(1)$ of that a fully-associative
LRU cache of size $(1-o(1))k$, with probability $1 - 1/\operatorname{poly}(k)$,
for all request sequences of length $\operatorname{poly}(k)$.
</p>
<p>- For $\alpha = o(\log k)$, and for all $c = O(1)$ and $r = O(1)$, the paging
cost of an $\alpha$-way set-associative LRU cache is not within a factor $c$ of
that a fully-associative LRU cache of size $k/r$, for some request sequence of
length $O(k^{1.01})$.
</p>
<p>- For $\alpha = \omega(\log k)$, if the hash function can be occasionally
changed, the paging cost of an $\alpha$-way set-associative LRU cache is within
a factor $1 + o(1)$ of that a fully-associative LRU cache of size $(1-o(1))k$,
with probability $1 - 1/\operatorname{poly}(k)$, for request sequences of
arbitrary (e.g., super-polynomial) length.
</p>
<p>Some of our results generalize to other paging algorithms besides LRU, such
as least-frequently used (LFU).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bender_M/0/1/0/all/0/1">Michael A. Bender</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1">Rathish Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Farach_Colton_M/0/1/0/all/0/1">Mart&#xed;n Farach-Colton</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliavini_G/0/1/0/all/0/1">Guido Tagliavini</a></p><p>In an $\alpha$-way set-associative cache, the cache is partitioned into
disjoint sets of size $\alpha$, and each item can only be cached in one set,
typically selected via a hash function. Set-associative caches are widely used
and have many benefits, e.g., in terms of latency or concurrency, over fully
associative caches, but they often incur more cache misses. As the set size
$\alpha$ decreases, the benefits increase, but the paging costs worsen.
</p>
<p>In this paper we characterize the performance of an $\alpha$-way
set-associative LRU cache of total size $k$, as a function of $\alpha =
\alpha(k)$. We prove the following, assuming that sets are selected using a
fully random hash function:
</p>
<p>- For $\alpha = \omega(\log k)$, the paging cost of an $\alpha$-way
set-associative LRU cache is within additive $O(1)$ of that a fully-associative
LRU cache of size $(1-o(1))k$, with probability $1 - 1/\operatorname{poly}(k)$,
for all request sequences of length $\operatorname{poly}(k)$.
</p>
<p>- For $\alpha = o(\log k)$, and for all $c = O(1)$ and $r = O(1)$, the paging
cost of an $\alpha$-way set-associative LRU cache is not within a factor $c$ of
that a fully-associative LRU cache of size $k/r$, for some request sequence of
length $O(k^{1.01})$.
</p>
<p>- For $\alpha = \omega(\log k)$, if the hash function can be occasionally
changed, the paging cost of an $\alpha$-way set-associative LRU cache is within
a factor $1 + o(1)$ of that a fully-associative LRU cache of size $(1-o(1))k$,
with probability $1 - 1/\operatorname{poly}(k)$, for request sequences of
arbitrary (e.g., super-polynomial) length.
</p>
<p>Some of our results generalize to other paging algorithms besides LRU, such
as least-frequently used (LFU).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05270'>Longest Common Subsequence with Gap Constraints</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Duncan Adamson, Maria Kosche, Tore Ko&#xdf;, Florin Manea, Stefan Siemer</p><p>We consider the longest common subsequence problem in the context of
subsequences with gap constraints. In particular, following Day et al. 2022, we
consider the setting when the distance (i. e., the gap) between two consecutive
symbols of the subsequence has to be between a lower and an upper bound (which
may depend on the position of those symbols in the subsequence or on the
symbols bordering the gap) as well as the case where the entire subsequence is
found in a bounded range (defined by a single upper bound), considered by
Kosche et al. 2022. In all these cases, we present effcient algorithms for
determining the length of the longest common constrained subsequence between
two given strings.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Adamson_D/0/1/0/all/0/1">Duncan Adamson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosche_M/0/1/0/all/0/1">Maria Kosche</a>, <a href="http://arxiv.org/find/cs/1/au:+Koss_T/0/1/0/all/0/1">Tore Ko&#xdf;</a>, <a href="http://arxiv.org/find/cs/1/au:+Manea_F/0/1/0/all/0/1">Florin Manea</a>, <a href="http://arxiv.org/find/cs/1/au:+Siemer_S/0/1/0/all/0/1">Stefan Siemer</a></p><p>We consider the longest common subsequence problem in the context of
subsequences with gap constraints. In particular, following Day et al. 2022, we
consider the setting when the distance (i. e., the gap) between two consecutive
symbols of the subsequence has to be between a lower and an upper bound (which
may depend on the position of those symbols in the subsequence or on the
symbols bordering the gap) as well as the case where the entire subsequence is
found in a bounded range (defined by a single upper bound), considered by
Kosche et al. 2022. In all these cases, we present effcient algorithms for
determining the length of the longest common constrained subsequence between
two given strings.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.05279'>Negative-Weight Single-Source Shortest Paths in Near-Linear Time: Now Faster!</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Karl Bringmann, Alejandro Cassis, Nick Fischer</p><p>In this work we revisit the fundamental Single-Source Shortest Paths (SSSP)
problem with possibly negative edge weights. A recent breakthrough result by
Bernstein, Nanongkai and Wulff-Nilsen established a near-linear $O(m \log^8(n)
\log(W))$-time algorithm for negative-weight SSSP, where $W$ is an upper bound
on the magnitude of the smallest negative-weight edge. In this work we improve
the running time to $O(m \log^2(n) \log(nW) \log\log n)$, which is an
improvement by nearly six log-factors. Some of these log-factors are easy to
shave (e.g. replacing the priority queue used in Dijkstra's algorithm), while
others are significantly more involved (e.g. to find negative cycles we design
an algorithm reminiscent of noisy binary search and analyze it with drift
analysis).
</p>
<p>As side results, we obtain an algorithm to compute the minimum cycle mean in
the same running time as well as a new construction for computing Low-Diameter
Decompositions in directed graphs.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bringmann_K/0/1/0/all/0/1">Karl Bringmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Cassis_A/0/1/0/all/0/1">Alejandro Cassis</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_N/0/1/0/all/0/1">Nick Fischer</a></p><p>In this work we revisit the fundamental Single-Source Shortest Paths (SSSP)
problem with possibly negative edge weights. A recent breakthrough result by
Bernstein, Nanongkai and Wulff-Nilsen established a near-linear $O(m \log^8(n)
\log(W))$-time algorithm for negative-weight SSSP, where $W$ is an upper bound
on the magnitude of the smallest negative-weight edge. In this work we improve
the running time to $O(m \log^2(n) \log(nW) \log\log n)$, which is an
improvement by nearly six log-factors. Some of these log-factors are easy to
shave (e.g. replacing the priority queue used in Dijkstra's algorithm), while
others are significantly more involved (e.g. to find negative cycles we design
an algorithm reminiscent of noisy binary search and analyze it with drift
analysis).
</p>
<p>As side results, we obtain an algorithm to compute the minimum cycle mean in
the same running time as well as a new construction for computing Low-Diameter
Decompositions in directed graphs.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-12T00:30:00Z">Wednesday, April 12 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Tuesday, April 11
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://scottaaronson.blog/?p=7209'>GPT-4 gets a B on my quantum computing final exam!</a></h3>
        <p class='tr-article-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          [Warning: This might be the longest Shtetl-Optimized post of all time! But that&#8217;s OK; I expect most people will only want to read the introductory part anyway.] As I&#8217;ve mentioned before, economist, blogger, and friend Bryan Caplan was unimpressed when ChatGPT got merely a D on his Labor Economics midterm. So on Bryan&#8217;s blog, appropriately [&#8230;]
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p><em>[Warning: This might be the longest Shtetl-Optimized post of all time!  But that&#8217;s OK; I expect most people will only want to read the introductory part anyway.]</em></p>



<p>As I&#8217;ve mentioned before, economist, blogger, and friend Bryan Caplan was <a href="https://betonit.substack.com/p/chatgpt-takes-my-midterm-and-gets">unimpressed</a> when ChatGPT got merely a D on his Labor Economics midterm.  So on Bryan&#8217;s blog, appropriately named &#8220;Bet On It,&#8221; he <a href="https://betonit.substack.com/p/ai-bet">made a public bet</a> that no AI would score on A on his exam before January 30, 2029.  GPT-4 then <a href="https://betonit.substack.com/p/gpt-retakes-my-midterm-and-gets-an">scored an A</a> a <strong>mere three months later</strong> (!!!), leading to what <a href="https://www.theguardian.com/technology/2023/apr/06/chatgpt-ai-bryan-caplan-interview">Bryan agrees</a> will likely be one of the first public bets he&#8217;ll ever have to concede (he hasn&#8217;t yet &#8220;formally&#8221; conceded, but only because of technicalities in how the bet was structured).  Bryan has now joined the ranks of the GPT believers, writing</p>



<blockquote class="wp-block-quote">
<p>When the answers change, I change my mind</p>
</blockquote>



<p><a href="https://twitter.com/bryan_caplan/status/1638199348738793473">and</a></p>



<blockquote class="wp-block-quote">
<p>AI enthusiasts have cried wolf for decades. GPT-4 is the wolf. I&#8217;ve seen it with my own eyes.</p>
</blockquote>



<p>But OK, labor econ is one thing.  What about a <em>truly unfakeable</em> test of <em>true</em> intelligence?  Like, y&#8217;know, a <em>quantum computing</em> test?</p>



<p>Seeking an answer to this crucial and obvious followup question, I had GPT-4 take the actual 2019 final exam from <a href="https://www.scottaaronson.com/qclec.pdf">Introduction to Quantum Information Science</a>, my honors upper-level undergrad course at UT Austin.  I asked <a href="https://www.justinyirka.com/">Justin Yirka</a>, my PhD student and multi-time head TA, to grade the exam as he would for anyone else.  This post is a joint effort of me and him.</p>



<p>We gave GPT-4 the problems via their LaTeX source code, which GPT-4 can perfectly well understand.  When there were quantum circuits, either in the input or desired output, we handled those either using the <a href="https://ctan.org/pkg/qcircuit?lang=en">qcircuit</a> package, which GPT-4 again understands, or by simply asking it to output an English description of the circuit.  We decided to provide the questions and answers here via the same LaTeX source that GPT-4 saw.</p>



<p>To the best of my knowledge&#8212;and I double-checked&#8212;this exam has never before been posted on the public Internet, and could not have appeared in GPT-4&#8217;s training data.</p>



<p>The result: GPT-4 scored <strong>69 / 100</strong>.  (Because of extra credits, the max score on the exam was <strong>120</strong>, though the highest score that any student actually achieved was <strong>108</strong>.)  For comparison, the average among the students was <strong>74.4</strong> (though with a strong selection effect&#8212;many students who were struggling had dropped the course by then!).  While there&#8217;s no formal mapping from final exam scores to letter grades (the latter depending on other stuff as well), GPT-4&#8217;s performance would correspond to a <strong>B</strong>.</p>



<p><em>(Note: I said yesterday that its score was 73, but commenters brought to my attention that GPT was given a full credit for a wrong answer on 2(a), a density matrix that wasn&#8217;t even normalized.)</em></p>



<p>In general, I&#8217;d say that GPT-4 was strongest on true/false questions and (ironically!) conceptual questions&#8212;the ones where many students struggled the most.  It was (again ironically!) weakest on calculation questions, where it would often know what <em>kind</em> of calculation to do but then botch the execution.  We didn&#8217;t try the new <a href="https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/">interface to WolframAlpha</a>, which might improve its performance on those questions.  We&#8217;d be happy for anyone else to try that.</p>



<p>One should also remember that the students had just <em>taken the course</em>&#8212;including weekly problem sets, recitation sections, office hours, a midterm, and a practice final, all giving them recent experience with what kinds of problems to expect.  By contrast, GPT-4 was &#8220;flying blind,&#8221; <strong>except</strong> for having vacuumed up the whole public Internet, presumably including other people&#8217;s quantum computing homework sets and exams!  It&#8217;s plausible that fine-tuning or few-shot prompting with my other exams or lecture notes would improve GPT-4&#8217;s performance; we didn&#8217;t try that.</p>



<p>What else?  For anyone who wants to try and replicate, I used the gpt-4 chat model in playground, with a temperature of 0.2 and a max length of 1930&nbsp;tokens.</p>



<p>Without further ado, here&#8217;s the exam.  Throughout, GPT&#8217;s answers are in <strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">blue</mark></strong> and my and Justin&#8217;s grading comments are in <strong><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">red</mark></strong>.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>I often start my Quantum Information Science final exam with an optional, ungraded question asking for the students&#8217; favorite interpretation of quantum mechanics, and then collect statistics about it (including the correlation with final exam score!).  Just for fun, let&#8217;s see how GPT-4 handles <em>that</em> question.</p>



<p><code>What is your favorite interpretation of quantum mechanics?<br>- Copenhagen<br>- Many-Worlds<br>- Bohmian Mechanics<br>- New Physics (Including Dynamical Collapse)<br>- Other:<br>- None<br>- What does it even matter?<br><br><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">As an AI language model, I do not have personal preferences or opinions. However, I can provide you with a brief overview of each interpretation mentioned:<br><br>1. Copenhagen Interpretation: This is the most widely accepted interpretation of quantum mechanics. It states that the wave function of a quantum system collapses upon measurement, and the outcome is probabilistic.<br><br>2. Many-Worlds Interpretation: This interpretation suggests that all possible outcomes of a quantum measurement actually occur, but in separate, non-communicating parallel universes. There is no wave function collapse in this interpretation.<br><br>3. Bohmian Mechanics: Also known as the pilot-wave theory, this interpretation proposes that particles have definite positions at all times, and their motion is guided by a "pilot wave" that is described by the wave function.<br><br>4. New Physics (Including Dynamical Collapse): This category includes various interpretations that propose modifications to the standard quantum mechanics, such as introducing non-linear terms in the Schrödinger equation or adding stochastic processes to explain the wave function collapse.<br><br>5. Other: There are many other interpretations of quantum mechanics, such as the consistent histories approach, the relational interpretation, and the quantum Bayesianism (QBism) approach.<br><br>6. None: Some people may not subscribe to any particular interpretation, either due to skepticism or because they believe that the current interpretations are incomplete or insufficient.<br><br>7. What does it even matter?: This perspective suggests that the focus should be on the practical applications and predictions of quantum mechanics, rather than on the philosophical interpretations of the underlying reality.<br><br>Ultimately, the choice of interpretation depends on one's philosophical inclinations and personal preferences.</mark></code></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Next let&#8217;s see the True/Falses.  Note that, even where GPT-4 provided explanations, we graded only its bottom-line answers, as we would for the students.  Its total on this section is <strong>17 / 20</strong>.</p>



<pre class="wp-block-preformatted">1a. True or False?  Unitary matrices preserve the 2-norm of all complex vectors.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">True. Unitary matrices preserve the 2-norm of all complex vectors. This property is known as being norm-preserving or isometric. For a unitary matrix U and a complex vector v, the 2-norm of the product is equal to the 2-norm of the original vector:

||Uv|| = ||v||

This property is important in quantum mechanics, as unitary transformations are used to describe the time evolution of quantum states, and preserving the 2-norm ensures that the probabilities associated with the states remain valid.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1b. True or False?  A pure state of n qubits is described by an n-dimensional complex unit vector.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">False. A pure state of n qubits is described by a 2^n-dimensional complex unit vector. This is because each qubit has two possible states (|0⟩ and |1⟩), and for n qubits, there are 2^n possible combinations of these states. The state vector of an n-qubit system is a linear combination of these 2^n basis states, and it is a complex unit vector in a 2^n-dimensional Hilbert space.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1c. True or False?  The Bell inequality states that by using classical strategies, Alice and Bob can win the CHSH game with probability at most 3/4.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">True. The no-cloning theorem states that it is impossible to create an exact copy of an arbitrary unknown quantum state. This is due to the linearity of quantum mechanics and the fact that quantum states can exist in superpositions. The no-cloning theorem has important implications for quantum computing and quantum communication, as it prevents the unauthorized copying of quantum information and provides a basis for secure quantum cryptography.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct (even though the explanation is nonsense)</mark>

1d. True or False?  Google's recent quantum supremacy experiment demonstrated the successful use of quantum error-correction.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">FALSE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1e. True or False?  Lattice-based cryptography is one proposal for secure post-quantum public-key cryptography.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">TRUE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1f. True or False?  The fastest known classical algorithms for factoring all take time $c^n$, for some $c &gt; 1$, to factor an n-bit integer.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">FALSE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1g. True or False?  Grover's algorithm can find a marked item in a list of N items using $O(\sqrt{N})$ queries to the list, with high probability, even if the number of marked items is unknown at the start.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">TRUE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1h. True or False?  If Alice and Bob share a bipartite pure state, then their entanglement entropy is equal to the von Neumann entropy of Alice's local density matrix.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">TRUE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1i. True or False?  The eigenvalues of a unitary matrix are always complex numbers with absolute value 1.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">TRUE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1j. True or False?   The eigenvalues of a density matrix are always in [0,1].

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">TRUE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1k. True or False?   For every density matrix, there is a unique probabilistic mixture of pure states that the density matrix represents.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">FALSE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1l. True or False?   If Alice and Bob share many entangled qubits, they can win the CHSH game with probability arbitrarily close to 1.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">FALSE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1m. True or False?   The only $2 \times 2$ matrices that are both unitary and stochastic are $\begin{bmatrix}1&amp;0\\0&amp;1\end{bmatrix}$ and $\begin{bmatrix}0&amp;1\\1&amp;0\end{bmatrix}$.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">FALSE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Wrong</mark>

1n. True or False?   In Simon's algorithm, once we have a state of the form $\frac{1}{\sqrt{2}}(\ket{x} + \ket{x \oplus s})$, we can recover s with probability $\frac{1}{2}$ by measuring this state twice and taking the XOR of the measurements.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">FALSE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1o. True or False?   Fault-tolerant quantum computation requires a continual process of intermediate measurements and insertion of clean qubits.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">TRUE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1p. True or False?   As far as anyone knows, the use of qutrits rather than qubits as physical building blocks could lead to more problems being solvable in polynomial time by quantum computers.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">TRUE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Wrong</mark>

1q. True or False?   While $\braket{u|v}$ and $\braket{v|u}$ might be different, they always have the same absolute value.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">TRUE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1r. True or False?   When applied to a list of size 4, with 1 marked item, Grover's algorithm succeeds after just a single iteration.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">TRUE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark>

1s. True or False?  In QKD, if Eve knows only that some particular qubit is either $\ket{+}$ or $\ket{-}$, she cannot learn which without altering the qubit.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">TRUE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Wrong</mark>

1t. True or False?  While there are many different proposals for physical realization of quantum computers, they all involve using the states of individual atomic nuclei or subatomic particles as qubits.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">FALSE</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Correct</mark></pre>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>OK, let&#8217;s move on to short-answer questions!  Total score here: <strong>13 / 20</strong>.</p>



<pre class="wp-block-preformatted">2. Consider the state:
$$\ket{\psi} = \frac{\ket{00} + \ket{01} + \ket{10}}{\sqrt{3}}$$

(a). Calculate the reduced density matrix of the second qubit of $\ket{\psi}$.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">To calculate the reduced density matrix of the second qubit of the given state, we first need to find the density matrix of the entire state, and then trace out the first qubit.

The density matrix of the entire state is given by:
$$\rho = \ket{\psi}\bra{\psi} = \frac{1}{3}\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp;
1 \\ 0 &amp; 1 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix}$$

Now, we trace out the first qubit:
$$\rho_2 = \text{Tr}_1(\rho) = \frac{1}{3}\begin{pmatrix} 1+1 &amp; 1 \\ 1 &amp; 1+1 \end{pmatrix} = \frac{1}{3}\begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{pmatrix}$$

Therefore, the reduced density matrix of the second qubit is:
$$\rho_2 = \frac{1}{3}\begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{pmatrix}$$</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color"><s>JUSTIN: 5/5 points.</s></mark>
<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">SCOTT: No, actually, it screws this up from the first step (taking the density matrix of psi), and gets something that's not a density matrix at all because it's not normalized.  1 point out of 5, for knowing what <em>kind</em> of calculation to do.</mark>

(b) Calculate $\ket{\psi}$'s entanglement entropy. You don't need to simplify your answer.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">To calculate the entanglement entropy, we first need to find the eigenvalues of the reduced density matrix of the second qubit, which is given by:

$$\rho_2 = \frac{1}{3}\begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{pmatrix}$$

The characteristic equation for this matrix is:
$$\text{det}(\rho_2 - \lambda I) = \frac{1}{9}\begin{vmatrix} 2-\lambda &amp; 1 \\ 1 &amp; 2-\lambda \end{vmatrix} = (\lambda - 3)(\lambda - 1) = 0$$

So, the eigenvalues are $\lambda_1 = \frac{1}{3}$ and $\lambda_2 = \frac{2}{3}$.

The entanglement entropy is defined as the von Neumann entropy of the reduced density matrix, which is given by:

$$S(\rho_2) = -\text{Tr}(\rho_2 \log_2 \rho_2) = -(\lambda_1 \log_2 \lambda_1 + \lambda_2 \log_2 \lambda_2)$$

Plugging in the eigenvalues, we get:

$$S(\rho_2) = -\left(\frac{1}{3} \log_2 \frac{1}{3} + \frac{2}{3}\log_2 \frac{2}{3}\right)$$

Thus, the entanglement entropy of the state $\ket{\psi}$ is:

$$S(\rho_2) = -\left(\frac{1}{3} \log_2 \frac{1}{3} + \frac{2}{3}\log_2 \frac{2}{3}\right)$$</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN:
Up to 5 points.
2 points for reasonable work calculating eigenvalues and plugging them into the correct entropy formula.
5 points for fully correct answer.
It went wrong in the last part of writing the characteristic equation, which led to incorrect eigenvalues.
The correct eigenvalues are 1/2 + sqrt(5)/6 and 1/2 - sqrt(5)/6.

2/5 points.</mark>

(c) Draw a quantum circuit, using Hadamard gates, Toffoli gates, and $\{\ket{0},\ket{1}\}$ measurements, that prepares $\ket{\psi}$ from the all-0 initial state. Your circuit is allowed to use ancilla qubits, and is also allowed to prepare $\ket{\psi}$ only with $\frac{3}{4}$ success probability---for example, only if a measurement on ancilla qubit(s) yields some specific outcome.
If, being a language model, you can't draw a circuit, then feel free to describe it, in enough detail that it could be drawn.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">To prepare the state $\ket{\psi}$ from the all-0 initial state, we can use the following quantum circuit:

1. Start with three qubits in the state $\ket{000}$.
2. Apply a Hadamard gate (H) to the first qubit. This creates the state $\frac{1}{\sqrt{2}}(\ket{000} + \ket{100})$.
3. Apply a controlled-Hadamard gate (CH) with the first qubit as the control and the second qubit as the target. This creates the state $\frac{1}{2}(\ket{000} + \ket{010} + \ket{100} + \ket{110})$.
4. Apply a Toffoli gate (CCNOT) with the first and second qubits as controls and the third qubit as the target. This creates the state $\frac{1}{2}(\ket{000} + \ket{010} + \ket{100} + \ket{111})$.
5. Apply a Hadamard gate (H) to the third qubit. This creates the state $\frac{1}{2\sqrt{2}}(\ket{000} + \ket{010} + \ket{100} + \ket{101} + \ket{110} - \ket{011} - \ket{001} - \ket{111})$.
6. Measure the third qubit. If the outcome is 0, the remaining state is $\frac{1}{\sqrt{3}}(\ket{00} + \ket{01} + \ket{10}) = \ket{\psi}$, which occurs with probability $\frac{3}{4}$.

Here's a description of the circuit using standard quantum gates:

```
q0 -- H -- CH -- CCNOT -- M
         |     |
q1 --     H -- CCNOT -- M
               |
q2 --          X -- H -- M
```

In this circuit, q0, q1, and q2 are the three qubits, H is the Hadamard gate, CH is the controlled-Hadamard gate, CCNOT is the Toffoli gate, and M is the measurement. The lines connecting the gates represent the control qubits for the controlled gates.</mark>
<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">
</mark><mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN:
Up to 5 points.
Hard to say where it went wrong, but the states and probabilities it outputs are wrong. 
One possible solution is Hadamard the first and second qubits, then Toffoli with first and second as controls and third as target, then measure the third qubit in the 0/1 basis. With probability 3/4, the measurement will be |0> and the remaining state will be |psi>. 
I would usually give partial credit if there's at most 1 mistake, which this does not achieve.
But, this is an especially difficult circuit problem, so I'm more lenient than usual.

1/5 points.</mark>
<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">
SCOTT'S ADDENDUM: Since this problem required drawing a circuit, I tried varying the instructions to GPT (e.g., "output qcircuit code", no special instructions, etc).  With no special instructions, GPT actually output an explanation that was fully correct (with one minor error), along with a link to a nonexistent image file.  But I'm still going to grade according to the first version I gave it!</mark>

(d) Explain the error in the following argument.  The Gottesman-Knill theorem states that any quantum circuit composed of Hadamard, CNOT, and Phase gates can be simulated classically in time polynomial in the size of the circuit.  Simon's algorithm solves Simon's problem quantumly using only a polynomial number of Hadamard gates and $O(n)$ oracle queries.  Therefore, Simon's problem can be solved classically in polynomial time using polynomially many oracle queries.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">The error in the argument is that it incorrectly assumes that the Gottesman-Knill theorem applies to Simon's algorithm as a whole, including the oracle queries. The Gottesman-Knill theorem states that any quantum circuit composed of Hadamard, CNOT, and Phase gates can be simulated classically in time polynomial in the size of the circuit. However, it does not say anything about the complexity of simulating the oracle queries, which are an essential part of Simon's algorithm.

Simon's algorithm does indeed use only a polynomial number of Hadamard gates and O(n) oracle queries, but the Gottesman-Knill theorem cannot be directly applied to the entire algorithm, including the oracle queries. Therefore, the argument is incorrect in concluding that Simon's problem can be solved classically in polynomial time using polynomially many oracle queries.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: 3/3 points.</mark>

(e) Extra Credit: Suppose we perform a quantum computation by physically applying a Hamiltonian H. What's to stop us from running the computation, say, $10^{100}$ times faster, by simply replacing H by $H':=10^{100}H$, which is also a valid Hamiltonian?  Or to put it differently: is there some resource that we'd need $10^{100}$ more of to do this?

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">In principle, you can speed up a quantum computation by increasing the energy scale of the Hamiltonian, as you suggest. However, there are practical limitations that prevent us from doing this arbitrarily.

1. Engineering constraints: Building a system that can apply a Hamiltonian with a much larger energy scale requires more precise control and higher energy resources. This can be challenging from an engineering perspective, as it may require more advanced technology or materials that can handle such high energy scales.

2. Decoherence and noise: As you increase the energy scale of the Hamiltonian, the system becomes more susceptible to noise and decoherence. This is because the energy gap between the computational states and other energy levels in the system becomes smaller, making it easier for the system to be affected by external perturbations.
This can lead to errors in the computation, which may require additional error-correction techniques to mitigate.

3. Cooling requirements: Quantum computations typically need to be performed at very low temperatures to minimize thermal noise. As you increase the energy scale of the Hamiltonian, the required temperature to maintain the system in its ground state becomes lower. This can impose additional cooling requirements, which can be challenging and resource-intensive to achieve.

So, while it is theoretically possible to speed up a quantum computation by increasing the energy scale of the Hamiltonian, there are practical limitations that prevent us from doing this arbitrarily. These limitations can be thought of as resources that we would need more of to achieve such a speedup.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">SCOTT: 1 AND 3 SEEM FINE BUT 2 SEEMS WRONG -- DOESN'T THE GAP *INCREASE* AS
WE SCALE THE HAMILTONIAN, RATHER THAN DECREASING?
JUSTIN: Up to 4 points extra credit.
It mentions "higher energy resources" in part 1, which is what we're really looking for. And I'm not sure that parts 2 and 3 are fully correct.

2/4 extra credit points.</mark></pre>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Still here?  OK then, let&#8217;s move on to Shor&#8217;s factoring algorithm!  Total score here: <strong>7 / 10</strong>.</p>



<pre class="wp-block-preformatted">3. Suppose we use Shor's algorithm to factor $N=105$ into $3\cdot 5 \cdot 7$.  (Yes, $N$ is now a product of 3 primes!)  Suppose also that we make the choices $x=2$ and $Q=60000$.

(a) What is the order of the multiplicative group $\mathbb{Z}_N^\times$?

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">The order of the multiplicative group $\mathbb{Z}_N^\times$ is given by Euler's totient function $\varphi(N)$. Since $N = 3 \cdot 5 \cdot 7$, we have $\varphi(N) = \varphi(3) \cdot \varphi(5) \cdot \varphi(7) = (3-1)(5-1)(7-1) = 2 \cdot 4 \cdot 6 = \boxed{48}$.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: 2/2 points.</mark>

(b) What is the period of the function $f(r)=x^r (\bmod N)$?

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">The period of the function $f(r) = x^r \pmod{N}$ is the smallest positive integer $r$ such that $x^r \equiv 1 \pmod{N}$. This is the order of $x$ in the multiplicative group $\mathbb{Z}_N^\times$. Since the order of the group is 48, the period $r$ must be a divisor of 48.

To find the period, we can check the divisors of 48 in increasing order. We have $x = 2$ and $N = 105$, so we compute the powers of 2 modulo 105:

- $2^1 \equiv 2 \pmod{105}$
- $2^2 \equiv 4 \pmod{105}$
- $2^3 \equiv 8 \pmod{105}$
- $2^4 \equiv 16 \pmod{105}$
- $2^6 \equiv 64 \pmod{105}$
- $2^{12} \equiv 16 \pmod{105}$
- $2^{24} \equiv 1 \pmod{105}$

We find that the smallest positive integer $r$ such that $2^r \equiv 1 \pmod{105}$ is $r = \boxed{24}$.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: Up to 2 points.
The correct answer is 12, i.e. 2^12 = 1 mod 105.
Given the work, this earns partial credit.

1/2 points.</mark>

(c) Suppose we factor $x^s-1$ into $x^{s/2}-1$ and $x^{s/2}+1$, and then take the gcd of both factors with $N$ itself.  Which prime factors of $N$, if any, would be ``peeled off'' this way?

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">Let's compute $x^{s/2} \pmod{N}$, where $x = 2$, $s = 24$, and $N = 105$. We have $x^{s/2} = 2^{12} \equiv 16 \pmod{105}$. Now we can compute the gcd of both factors with $N$:

- $\gcd(x^{s/2} - 1, N) = \gcd(16 - 1, 105) = \gcd(15, 105) = 15 = 3 \cdot 5$
- $\gcd(x^{s/2} + 1, N) = \gcd(16 + 1, 105) = \gcd(17, 105) = 1$

So, by taking the gcd of both factors with $N$, we would "peel off" the prime factors $3$ and $5$ of $N$. The prime factor $7$ is not peeled off in this process.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Up to 3 points.
Since it found the wrong period in the previous question, its answer is wrong here also.  It also seems to invert the definition of "peel off."  But it does the gcd computations correctly.
1/3.</mark>

(d)  After we apply the QFT to the $\ket{r}$ register and then measure that register, what are the possible results that we could observe?

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">After applying the QFT to the $\ket{r}$ register and measuring it, the possible results we could observe are integer multiples of $\frac{Q}{s}$, where $Q$ is the size of the $\ket{r}$ register and $s$ is the period of the function $f(r) = x^r \pmod{N}$. In this case, we have $Q = 60000$ and $s = 24$. So, the possible results are integer multiples of $\frac{60000}{24} = 2500$.

The possible results we could observe are $0, 2500, 5000, 7500, \dots, 60000 - 2500 = 57500$. Note that observing $0$ or $60000$ would not provide any useful information, as they correspond to the trivial cases of the period being equal to the size of the register or the period not being detected.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: Up to 3 points.
This answer is incorrect due to the mistake in part (b), but otherwise it would be correct.
(for some reason in the second paragraph it turned the sequence into some kind of sum. That's weird.)

3/3 points.</mark></pre>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>OK, onwards to a question about Hamiltonians!  Total score: <strong>6 / 12</strong>.</p>



<pre class="wp-block-preformatted">4.
(a) &nbsp;Give a basis of eigenvectors for the $4 \times 4$ CNOT matrix, along with their associated eigenvalues.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">The CNOT (Controlled-NOT) matrix is a $4 \times 4$ matrix given by:

$$
CNOT = \begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 0
\end{pmatrix} $$

To find the eigenvectors and eigenvalues, we first need to find the characteristic polynomial of the matrix, which is given by the determinant of $(CNOT - \lambda I)$:

$$
\det(CNOT - \lambda I) = \det\begin{pmatrix}
1-\lambda &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1-\lambda &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; -\lambda &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; -\lambda
\end{pmatrix} $$

The determinant of this matrix is $(1-\lambda)^2(-\lambda)^2 - (1-\lambda)^2 = (1-\lambda)^2(\lambda^2 - 1)$. Thus, the eigenvalues are $\lambda_1 = 1$, $\lambda_2 = 1$, $\lambda_3 = -1$, and $\lambda_4 = -1$.

Now, we find the eigenvectors associated with each eigenvalue:

1. For $\lambda_1 = 1$:

$$ (CNOT - I)v_1 = \begin{pmatrix}
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; -1 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; -1
\end{pmatrix}v_1 = 0 $$

A basis for the eigenspace corresponding to $\lambda_1 = 1$ is given by $v_1 = \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix}$ and $v_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}$.

2. For $\lambda_3 = -1$:

$$ (CNOT + I)v_3 = \begin{pmatrix}
2 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 1
\end{pmatrix}v_3 = 0 $$

A basis for the eigenspace corresponding to $\lambda_3 = -1$ is given by $v_3 = \begin{pmatrix} 0 \\ 0 \\ 1 \\ -1 \end{pmatrix}$ and $v_4 = \begin{pmatrix} 0 \\ 0 \\ 1 \\ 1 \end{pmatrix}$.

Thus, a basis of eigenvectors for the CNOT matrix is given by:

$$
v_1 = \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix}, \quad
v_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}, \quad
v_3 = \begin{pmatrix} 0 \\ 0 \\ 1 \\ -1 \end{pmatrix}, \quad
v_4 = \begin{pmatrix} 0 \\ 0 \\ 1 \\ 1 \end{pmatrix} $$

with associated eigenvalues $\lambda_1 = 1$, $\lambda_2 = 1$, $\lambda_3 = -1$, and $\lambda_4 = -1$.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: Up to 3 points.
The eigenvalue lambda4 is wrong, it should be&nbsp;+1.
2/3.</mark>

(b) Give a 2-qubit Hamiltonian $H$ such that $e^{-iH}$ is the CNOT matrix.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">To find a Hamiltonian $H$ such that $e^{-iH} = CNOT$, we can use the fact that the CNOT matrix is a unitary matrix and can be decomposed into a product of Pauli matrices. The Pauli matrices are given by:

$$
\sigma_x = \begin{pmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{pmatrix}, \quad
\sigma_y = \begin{pmatrix} 0 &amp; -i \\ i &amp; 0 \end{pmatrix}, \quad
\sigma_z = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{pmatrix} $$

The CNOT matrix can be written as a product of tensor products of Pauli matrices:

$$
CNOT = \frac{1}{2} (I \otimes I + I \otimes \sigma_x + \sigma_z \otimes I - \sigma_z \otimes \sigma_x) $$

Now, we can find a Hamiltonian $H$ such that $e^{-iH} = CNOT$. We can use the fact that the exponential of a sum of operators is equal to the product of exponentials of the individual operators if the operators commute:

$$ e^{-iH} = e^{-i\frac{\theta}{2}(I \otimes I)} e^{-i\frac{\theta}{2}(I \otimes \sigma_x)} e^{-i\frac{\theta}{2}(\sigma_z \otimes I)} e^{i\frac{\theta}{2}(\sigma_z \otimes \sigma_x)} $$

We want to find the angle $\theta$ such that this product is equal to the CNOT matrix. Since the Pauli matrices have eigenvalues $\pm 1$, we can see that the angle $\theta$ must be $\pi$:

$$ e^{-iH} = e^{-i\frac{\pi}{2}(I \otimes I)} e^{-i\frac{\pi}{2}(I \otimes \sigma_x)} e^{-i\frac{\pi}{2}(\sigma_z \otimes I)} e^{i\frac{\pi}{2}(\sigma_z \otimes \sigma_x)} $$

Now, we can find the Hamiltonian $H$:

$$ H = \frac{\pi}{2}(I \otimes I + I \otimes \sigma_x + \sigma_z \otimes
I - \sigma_z \otimes \sigma_x) $$

So, the 2-qubit Hamiltonian $H$ such that $e^{-iH} = CNOT$ is given by:

$$
H = \frac{\pi}{2} \begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; -1
\end{pmatrix} $$</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: Up to 2 points.
Plugging into a calculator, this answer is incorrect. 
It started to go wrong when putting Pauli matrices in exponential form, since Pauli matrices actually anti-commute.  Partial credit for very significant effort.

1/2 points.</mark>

(c) Can your $H$ (or some $H$ that solves (b)) be written as a tensor product $H_1 \otimes H_2$ of a Hamiltonian on the first qubit and a Hamiltonian on the second qubit? If so, how?

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">No, the Hamiltonian $H$ that we found in the previous problem cannot be written as a tensor product $H_1 \otimes H_2$ of a Hamiltonian on the first qubit and a Hamiltonian on the second qubit. The reason is that the CNOT operation is an entangling operation, meaning that it creates entanglement between the two qubits. If the Hamiltonian could be written as a tensor product of Hamiltonians acting on individual qubits, it would not be able to create entanglement between the qubits.

To see this more explicitly, let's try to write the Hamiltonian $H$ as a tensor product:

$$ H = H_1 \otimes H_2 = \begin{pmatrix} a &amp; b \\ c &amp; d \end{pmatrix}
\otimes \begin{pmatrix} e &amp; f \\ g &amp; h \end{pmatrix} $$

The tensor product would result in a $4 \times 4$ matrix:

$$ H = \begin{pmatrix}
a e &amp; a f &amp; b e &amp; b f \\
a g &amp; a h &amp; b g &amp; b h \\
c e &amp; c f &amp; d e &amp; d f \\
c g &amp; c h &amp; d g &amp; d h
\end{pmatrix} $$

Comparing this with the Hamiltonian $H$ we found earlier:

$$ H = \frac{\pi}{2} \begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; -1
\end{pmatrix} $$

We can see that there is no way to find values for $a, b, c, d, e, f, g, h$ such that the two matrices are equal. This confirms that the Hamiltonian $H$ cannot be written as a tensor product of Hamiltonians acting on individual qubits.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: Up to 3 points.
A correct solution to part (b) written in the form of part (c) is ((0 0) (0 1)) \otimes pi/2 ((1 -1) (-1 1)).
This question is a bit harsh with partial/carry-through credit, but the answer also explicitly got the main idea wrong, claiming that a tensor product H cannot give an entangling unitary.
0/3.</mark>

(d) Is there an $H$ that solves (b), while also being a sum $H_1\otimes I + I\otimes H_2$ of a Hamiltonian on the first qubit and a Hamiltonian on the second qubit?&nbsp; Why or why not?

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">No, there is no Hamiltonian $H$ such that $e^{iH} = CNOT$ and $H = H_1 \otimes I + I \otimes H_2$. The reason is that the CNOT operation is an entangling operation, meaning that it creates entanglement between the two qubits. If the Hamiltonian could be written as a sum of Hamiltonians acting on individual qubits, it would not be able to create entanglement between the qubits.

To see this more explicitly, let's assume that there exists such an $H$:

$$ H = H_1 \otimes I + I \otimes H_2 = \begin{pmatrix} a &amp; b \\ c &amp; d
\end{pmatrix} \otimes \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix} +
\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix} \otimes \begin{pmatrix} e
&amp; f \\ g &amp; h \end{pmatrix} $$

The sum of the tensor products would result in a $4 \times 4$ matrix:

$$ H = \begin{pmatrix}
a + e &amp; b &amp; a &amp; b \\
c &amp; d + e &amp; c &amp; d \\
a &amp; b &amp; a + h &amp; b \\
c &amp; d &amp; c &amp; d + h
\end{pmatrix} $$

Now, we want to find an $H$ such that $e^{iH} = CNOT$. The CNOT matrix is given by:

$$ CNOT = \begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 0
\end{pmatrix} $$

However, there is no way to find values for $a, b, c, d, e, f, g, h$ such that $e^{iH} = CNOT$. This is because the CNOT operation creates entanglement between the qubits, and a Hamiltonian that can be written as a sum of Hamiltonians acting on individual qubits cannot create entanglement.

In summary, there is no Hamiltonian $H$ such that $e^{iH} = CNOT$ and $H = H_1 \otimes I + I \otimes H_2$ because the CNOT operation is an entangling operation, and a Hamiltonian that can be written as a sum of Hamiltonians acting on individual qubits cannot create entanglement.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">Up to 4 points.
It's correct that an H of this form can't generate CNOT because it can't create entanglement, although most of the rest is just repetitive fluff.
3/4.</mark></pre>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Now for a question about the complexity of generating certain uniform superpositions over sets (a special case of &#8220;QSampling&#8221;).  Total score: <strong>19 / 18</strong> (of course counting extra credit).</p>



<pre class="wp-block-preformatted">5. In the Graph Isomorphism problem, we're given as input two $n$-vertex undirected graphs $G$ and $H$.  The problem is to determine whether they're isomorphic---in other words, whether there's any permutation of the vertex labels that makes $G$ and $H$ equal.

(a) Given as input an $n$-vertex graph $G$, describe how to sample, in classical $\mathrm{poly}(n)$ time, from a probability distribution $D_G$ over graphs such that:
- Whenever the graphs $G$ and $H$ are isomorphic, $D_G = D_H$.
- Whenever $G$ and $H$ are non-isomorphic, $D_G$ and $D_H$ have disjoint supports (i.e., no graph appears with nonzero probability in both of them).

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">To sample from the probability distribution $D_G$ over graphs, we can follow these steps:

1. Compute the canonical form of the input graph $G$. This can be done using a graph canonization algorithm, such as the one by Brendan McKay (nauty) or the one by Laszlo Babai (Traces). These algorithms run in classical $\mathrm{poly}(n)$ time.

2. Generate a random permutation of the vertex labels of the canonical form of $G$. This can be done by selecting a random permutation of the integers from $1$ to $n$, and then applying this permutation to the vertex labels of the canonical form.

3. Apply the random permutation to the canonical form of $G$ to obtain a new graph $G'$. This graph $G'$ is a sample from the probability distribution $D_G$.

The above procedure ensures that whenever the graphs $G$ and $H$ are isomorphic, $D_G = D_H$, because their canonical forms will be the same, and the random permutations applied to their canonical forms will generate the same distribution over graphs. On the other hand, whenever $G$ and $H$ are non-isomorphic, their canonical forms will be different, and the random permutations applied to their canonical forms will generate disjoint supports for $D_G$ and $D_H$.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: Up to 5 points.
The first step of computing the canonical form is superfluous and incorrect, since computing the canonical form is at least as hard as solving graph isomorphism and we don't know how to solve that in polynomial time.
Also, it looks like step 2 or 3 should have been about graph H instead of both being about G.
So it seems to have exactly the right idea but described it poorly.
4/5.
</mark>
(b) Given a probability distribution $D=(p_x)$ over $n$-bit strings $x$, define the ``QSampling state'' of $D$ to be $$\ket{\psi_D} := \sum_{x \in \{0,1\}^n} \sqrt{p_x} \ket{x}$$
Given two probability distributions $D$ and $D'$, suppose that the quantum circuit $\mathcal{C}$ maps $\ket{0^n}$ to $\ket{\psi_D}$, while the circuit $\mathcal{C}'$ maps $\ket{0^n}$ to $\ket{\psi_{D'}}$.

Then what is the output state of the circuit shown below, which acts on $n+1$ qubits?
$$ \Qcircuit @C=.5em @R=0.5em @!R {
\lstick{\ket{0}} &amp; \gate{H} &amp; \ctrl{1} &amp; \gate{NOT} &amp;  \ctrl{1} &amp; \qw\\
\lstick{\ket{0^n}} &amp; \qw &amp; \gate{\mathcal{C}} &amp; \qw &amp; \gate{\mathcal{C}'} &amp; \qw } $$

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">To find the output state of the given circuit, we first analyze it step by step.

1. After applying the Hadamard gate (H) on the first qubit, the state becomes:
$$\frac{1}{\sqrt{2}}(\ket{0} + \ket{1}) \otimes \ket{0^n}$$

2. Next, the controlled-$\mathcal{C}$ gate is applied. This gate applies the $\mathcal{C}$ operation on the second register if the first qubit is in state $\ket{0}$. So, the state becomes:
$$\frac{1}{\sqrt{2}}(\ket{0} \otimes \ket{\psi_D} + \ket{1} \otimes \ket{0^n})$$

3. The NOT gate is applied on the first qubit, which flips the state of the first qubit. The state becomes:
$$\frac{1}{\sqrt{2}}(\ket{1} \otimes \ket{\psi_D} + \ket{0} \otimes \ket{0^n})$$

4. Finally, the controlled-$\mathcal{C}'$ gate is applied. This gate applies the $\mathcal{C}'$ operation on the second register if the first qubit is in state $\ket{0}$. So, the state becomes:
$$\frac{1}{\sqrt{2}}(\ket{1} \otimes \ket{\psi_D} + \ket{0} \otimes \ket{\psi_{D'}})$$

Thus, the output state of the circuit is:
$$\frac{1}{\sqrt{2}}(\ket{1} \otimes \ket{\psi_D} + \ket{0} \otimes \ket{\psi_{D'}})$$</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: 4/4.
I think solving this one is impressive.</mark>

(c) Now suppose we measure the first qubit of that output state in the $\{\ket{+},\ket{-}\}$ basis.  What is the probability of the outcome $\ket{+}$ if $D=D'$?  What about if $D$ and $D'$ have disjoint supports?

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">To find the probability of the outcome $\ket{+}$, we first express the output state in terms of the $\{\ket{+},\ket{-}\}$ basis. Recall that $\ket{+} = \frac{1}{\sqrt{2}}(\ket{0} + \ket{1})$ and $\ket{-} = \frac{1}{\sqrt{2}}(\ket{0} - \ket{1})$.

The output state is:
$$\frac{1}{\sqrt{2}}(\ket{1} \otimes \ket{\psi_D} + \ket{0} \otimes \ket{\psi_{D'}})$$

We can rewrite this state in terms of the $\{\ket{+},\ket{-}\}$ basis as follows:
$$\frac{1}{2}(\ket{+} \otimes (\ket{\psi_D} + \ket{\psi_{D'}}) + \ket{-} \otimes (\ket{\psi_D} - \ket{\psi_{D'}}))$$

Now, we can find the probability of the outcome $\ket{+}$ by taking the squared magnitude of the coefficient of $\ket{+}$ in the state.

Case 1: $D = D'$

In this case, $\ket{\psi_D} = \ket{\psi_{D'}}$. So, the output state becomes:
$$\frac{1}{2}(\ket{+} \otimes (2\ket{\psi_D}) + \ket{-} \otimes (0))$$

The probability of the outcome $\ket{+}$ is the squared magnitude of the coefficient of $\ket{+}$, which is:
$$\left|\frac{1}{2}(2)\right|^2 = 1$$

Case 2: $D$ and $D'$ have disjoint supports

In this case, $\ket{\psi_D}$ and $\ket{\psi_{D'}}$ are orthogonal, i.e., their inner product is zero: $\langle\psi_D|\psi_{D'}\rangle = 0$. The probability of the outcome $\ket{+}$ is the squared magnitude of the coefficient of $\ket{+}$, which is:
$$\left|\frac{1}{2}(\langle\psi_D|\psi_D\rangle + \langle\psi_{D'}|\psi_{D'}\rangle)\right|^2$$

Since $\langle\psi_D|\psi_D\rangle = 1$ and $\langle\psi_{D'}|\psi_{D'}\rangle = 1$ (both states are normalized), the probability of the outcome $\ket{+}$ is:
$$\left|\frac{1}{2}(1 + 1)\right|^2 = \frac{1}{4}(2)^2 = \frac{1}{2}$$

So, if $D = D'$, the probability of the outcome $\ket{+}$ is 1, and if $D$ and $D'$ have disjoint supports, the probability of the outcome $\ket{+}$ is $\frac{1}{2}$.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">SCOTT: HOLY CRAP, LOOKS CORRECT!
JUSTIN: 5/5.</mark>

(d) Suppose your distributions $D_G$ from part (a) could be efficiently QSampled.  Using your previous work, explain how Graph Isomorphism could then be solved in $BQP$ (quantum polynomial time).

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">Suppose we can efficiently QSample the distributions $D_G$ and $D_H$ for two input graphs $G$ and $H$. We can then construct the QSampling states $\ket{\psi_{D_G}}$ and $\ket{\psi_{D_H}}$ for these distributions using the quantum circuits $\mathcal{C}_G$ and $\mathcal{C}_H$, respectively, as described in the previous problems.

Now, consider the following quantum circuit acting on $n+1$ qubits:

$$ \Qcircuit @C=.5em @R=0.5em @!R { \lstick{\ket{0}} &amp; \gate{H} &amp; \ctrl{1} &amp; \gate{NOT} &amp;  \ctrl{1} &amp; \qw\\  \lstick{\ket{0^n}} &amp; \qw &amp; \gate{\mathcal{C}_G} &amp; \qw &amp; \gate{\mathcal{C}_H} &amp; \qw } $$

As we found earlier, the output state of this circuit is:

$$\frac{1}{\sqrt{2}}(\ket{1} \otimes \ket{\psi_{D_G}} + \ket{0} \otimes \ket{\psi_{D_H}})$$

Now, we measure the first qubit of the output state in the $\{\ket{+},\ket{-}\}$ basis. We know from our previous work that if $G$ and $H$ are isomorphic (i.e., $D_G = D_H$), the probability of the outcome $\ket{+}$ is 1, and if $G$ and $H$ are non-isomorphic (i.e., $D_G$ and $D_H$ have disjoint supports), the probability of the
outcome $\ket{+}$ is $\frac{1}{2}$.

Thus, we can solve the Graph Isomorphism problem in $BQP$ as follows:

1. Construct the QSampling states $\ket{\psi_{D_G}}$ and $\ket{\psi_{D_H}}$ for the input graphs $G$ and $H$ using the quantum circuits $\mathcal{C}_G$ and $\mathcal{C}_H$.

2. Implement the above quantum circuit and measure the first qubit in the $\{\ket{+},\ket{-}\}$ basis.

3. If the outcome is $\ket{+}$ with probability close to 1, conclude that the graphs $G$ and $H$ are isomorphic. If the outcome is $\ket{+}$ with probability close to $\frac{1}{2}$, conclude that the graphs $G$ and $H$ are non-isomorphic.

This algorithm runs in quantum polynomial time, as the QSampling circuits $\mathcal{C}_G$ and $\mathcal{C}_H$ are assumed to be efficient, and the rest of the operations (Hadamard, NOT, and controlled gates) are also efficient.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: The answer is longer than necessary, repeating some of its previous work.
Also, in theory, if the graphs are isomorphic then the probability of |+&gt; will be exactly 1 not close to 1.

4/4.</mark>

(e) So then why doesn't this approach immediately imply a fast quantum algorithm for Graph Isomorphism?  Explain what could go wrong in passing from fast algorithms to sample $D_G$ and $D_H$, to fast algorithms to QSample them.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">The approach described above does not immediately imply a fast quantum algorithm for Graph Isomorphism because there is a crucial difference between classical sampling and QSampling.

In the algorithm, we assumed that we can efficiently construct quantum circuits $\mathcal{C}_G$ and $\mathcal{C}_{G'}$ that map $\ket{0^n}$ to $\ket{\psi_{D_G}}$ and $\ket{\psi_{D_{G'}}}$, respectively, given that the distributions $D_G$ and $D_{G'}$ can be efficiently sampled classically. However, this assumption might not hold in general.

Classical sampling allows us to draw samples from the distributions $D_G$ and $D_{G'}$, but it does not directly provide a way to prepare the corresponding QSampling states $\ket{\psi_{D_G}}$ and $\ket{\psi_{D_{G'}}}$. Preparing these quantum states requires a coherent superposition of all the elements in the distributions with the appropriate amplitudes, which might not be efficiently achievable using the classical sampling algorithms.

In other words, the ability to efficiently sample from a probability distribution classically does not necessarily imply the ability to efficiently prepare the corresponding QSampling state on a quantum computer. This is the main reason why the approach does not immediately lead to a fast quantum algorithm for Graph Isomorphism.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">SCOTT: Correctly explains that sampling doesn't necessarily imply QSampling (i.e. generating a coherent superposition state), but doesn't say that this is because of the difficulty of uncomputing garbage.
2 / 5 extra credit points.</mark></pre>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>Next, a problem about quantum communication complexity.  Total score: <strong>5 / 10</strong>.</p>



<pre class="wp-block-preformatted">6. Suppose Alice and Bob hold $n$-bit strings $x=(x_1,...,x_n)$ and $y=(y_1,...,y_n)$ respectively.  One thing they might want to learn is the mod-2 inner product of their strings, $$x_1 y_1 + \ldots + x_n y_n (\bmod 2).$$

(a) Suppose Alice and Bob had a quantum communication protocol in which they are allowed to exchange up to $T$ qubits and to perform arbitrary local unitary transformations to their qubits (possibly including ancilla qubits), that ended with Bob knowing the above inner product, with success probability 1.  Explain how, by exchanging the same number of qubits $T$, Bob could also prepare an $n$-qubit state
of the form $$\frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{x\cdot z} \ket{z},$$
where $x$ is an $n$-bit string held by Alice.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">If Alice and Bob have a quantum communication protocol that allows Bob to know the mod-2 inner product of their strings with success probability 1, then they can use the same protocol to prepare the desired $n$-qubit state.

Here's how they can do it:

1. Alice prepares an $n$-qubit state $\ket{\phi}$, where
$$\ket{\phi} = \frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} \ket{z}.$$

2. Alice applies a controlled-phase gate to each qubit of $\ket{\phi}$, using her $n$-bit string $x$ as the control. This results in the state
$$\frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{x\cdot z} \ket{z}.$$

3. Alice sends the $n$-qubit state to Bob.

4. Bob uses the quantum communication protocol to learn the mod-2 inner product of their strings. Since the protocol has success probability 1, Bob will know the inner product with certainty.

5. Bob applies a local unitary transformation to the $n$-qubit state he received from Alice, based on the inner product he learned in step 4. This will result in the desired state
$$\frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{x\cdot z} \ket{z}.$$

Since Alice and Bob only exchanged $T$ qubits in the original protocol, they can also prepare the desired $n$-qubit state by exchanging the same number of qubits $T$.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: Up to 4 points.
This answer is partially correct and/or poorly worded. In particular, in step 3 Alice just sends the whole n-qubit state to Bob.
The right idea is in there, but doesn't earn full points.

2/4.
</mark>
(b) Assume Alice and Bob have no preshared entanglement.  Recall Holevo's Theorem, which implies that in order to communicate $n$ bits to Bob reliably, Alice must send Bob at least $n$ qubits.  Using Holevo's Theorem together with part (a), prove that Alice and Bob must exchange at least $n$ qubits, even if they only want to learn the inner product mod 2 of their input strings $x$ and $y$.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">From part (a), we know that if Alice and Bob have a quantum communication protocol that allows Bob to know the mod-2 inner product of their strings with success probability 1, then they can also prepare an $n$-qubit state of the form
$$\frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{x\cdot z} \ket{z},$$
by exchanging the same number of qubits $T$.

Now, let's consider the reverse process. Suppose Bob has the $n$-qubit state
$$\frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{x\cdot z} \ket{z}.$$
He can perform a quantum measurement in the computational basis to obtain a random $n$-bit string $z$. Then, he can compute the mod-2 inner product $x \cdot z$ and send it back to Alice.

Alice, knowing her own string $x$, can compute the mod-2 inner product $x \cdot z$ as well. If the inner product $x \cdot z$ that Bob sent to Alice matches the one she computed, then they have successfully communicated the inner product mod 2 of their input strings $x$ and $y$.

However, according to Holevo's Theorem, in order to communicate $n$ bits to Bob reliably, Alice must send Bob at least $n$ qubits. Since the $n$-qubit state prepared in part (a) effectively communicates $n$ bits of information (Alice's string $x$) to Bob, Holevo's Theorem implies that Alice and Bob must exchange at least $n$ qubits to prepare this state.

Therefore, even if Alice and Bob only want to learn the inner product mod 2 of their input strings $x$ and $y$, they must exchange at least $n$ qubits.
</mark>
<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: Up to 6 points.
This answer doesn't earn any points. It only says that Alice and Bob learn the inner products and mistakenly claims this is n bits of information.
The correct solution recognizes that applying Hadamard to the state we showed how to prepare in part (a) gives exactly |x&gt;.

0/6.</mark>

(c) Now suppose we're no longer working mod 2, and Alice and Bob want to know whether their inner product
$$x_1 y_1 + \ldots + x_n y_n$$
is zero or nonzero as an integer.  (In other words, whether there's an $i$ such that $x_i=y_i=1$.)  Describe a protocol by which Alice and Bob can accomplish this, with high probability, by exchanging only $O(\sqrt{n}\log n )$ qubits in total.  The qubits can be spread across as many rounds of communication as necessary, and can be sent in either direction.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">Alice and Bob can use the following protocol, based on the Grover's search algorithm, to determine whether their inner product is zero or nonzero as an integer, with high probability, by exchanging only $O(\sqrt{n}\log n)$ qubits in total:

1. Alice prepares a quantum register of $n$ qubits in the state $\ket{0}^{\otimes n}$.

2. Alice applies the Hadamard gate to each qubit, resulting in the state $$\ket{\psi} = \frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} \ket{z}.$$

3. Alice and Bob perform the following steps for $O(\sqrt{n})$ iterations:

   a. Alice sends the $n$-qubit state $\ket{\psi}$ to Bob.

   b. Bob applies a controlled-phase gate to each qubit of $\ket{\psi}$, using his $n$-bit string $y$ as the control. This results in the state
   $$\ket{\psi'} = \frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{y\cdot z} \ket{z}.$$

   c. Bob sends the $n$-qubit state $\ket{\psi'}$ back to Alice.

   d. Alice applies a controlled-phase gate to each qubit of $\ket{\psi'}$, using her $n$-bit string $x$ as the control. This results in the state
   $$\ket{\psi''} = \frac{1}{\sqrt{2^n}} \sum_{z \in \{0,1\}^n} (-1)^{(x+y)\cdot z} \ket{z}.$$
   Note that if $x_i = y_i = 1$ for some $i$, then the phase of the corresponding term in the sum will be flipped twice, resulting in no change. Therefore, the state $\ket{\psi''}$ will have a non-zero amplitude for the terms corresponding to the indices where $x_i = y_i = 1$.

   e. Alice applies the Grover's diffusion operator to the state $\ket{\psi''}$, which amplifies the amplitudes of the terms corresponding to the indices where $x_i = y_i = 1$. The diffusion operator can be implemented as follows:
      - Apply the Hadamard gate to each qubit.
      - Apply a multi-qubit controlled-Z gate, with all qubits as controls and an ancilla qubit as the target.
      - Apply the Hadamard gate to each qubit again.

   f. Alice updates the state $\ket{\psi}$ with the resulting state after applying the Grover's diffusion operator.

4. After $O(\sqrt{n})$ iterations, Alice measures the final state in the computational basis. If she obtains a non-zero result, then there exists an $i$ such that $x_i = y_i = 1$, and their inner product is nonzero as an integer. If she obtains a zero result, then their inner product is zero.

Since Alice and Bob exchange $n$ qubits in each iteration, and they perform $O(\sqrt{n})$ iterations, the total number of qubits exchanged is $O(n\sqrt{n}) = O(\sqrt{n}\log n)$, as each qubit can represent $\log n$ bits of information. Thus, Alice and Bob can determine whether their inner product is zero or nonzero as an integer, with high probability, by exchanging only $O(\sqrt{n}\log n)$ qubits in total.
</mark>
<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">SCOTT: LOOKS BASICALLY RIGHT, EXCEPT FOR A SLIP-UP AT THE END WHERE IT SAYS
ALICE AND BOB EXCHANGE n QUBITS PER ITERATION RATHER THAN log n ...

JUSTIN: Up to 6 extra credit points.
Yeah, step 3a says it's sending n qubits, when it's actually log n.
It also seems incorrect beginning in the analysis of step d. It switches from summing over |z&gt; and referring to the full strings x and y to referring to individual indices i,x_i,y_i. And I don't know what it means about some amplitudes going to zero since what we're really doing is having some amplitudes be +1 and some -1.
I don't think this protocol is correct as stated.
But, it has some of the main ideas. The analysis of the grover steps is good and using a phase gate is good.

3/6 extra credit.</mark></pre>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>OK, last question, about the k-SUM problem.  Total score: <strong>6 / 15</strong>.</p>



<pre class="wp-block-preformatted">7. In the famous $k$-SUM problem, we're given a list of integers $x_1,\ldots,x_n$, and are asked whether there are $k$ distinct indices, $i_1 &lt; \ldots &lt; i_k$, such that $x_{i_1} + \ldots + x_{i_k} = 0$.

For this problem, you can ignore factors of $\log n$ in the running time (indeed, that is what the $\widetilde{O}$ notation means).

(a) Assume $k$ is even AND that we are allowed multi-sets (aka repeated elements are allowed). Describe a classical algorithm that solves the $k$-SUM problem in $\widetilde{O}(n^{k/2})$ time, beating the trivial upper bound of $\widetilde{O}(n^k)$.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">We can solve the k-SUM problem in $\widetilde{O}(n^{k/2})$ time using a meet-in-the-middle approach. Here's a high-level description of the algorithm:

1. Divide the list of integers into two equal halves: $A = x_1, \ldots, x_{n/2}$ and $B = x_{n/2+1}, \ldots, x_n$.

2. Compute all possible sums of $k/2$ elements from each half. For each half, this can be done in $O(n^{k/2})$ time by iterating through all possible combinations of $k/2$ elements.

3. Sort the lists of sums for both halves. This can be done in $O(n^{k/2} \log n)$ time using a comparison-based sorting algorithm.

4. For each sum in the first half, perform a binary search in the second half to find a sum that is equal to the negation of the sum from the first half. If such a sum is found, then we have found k distinct indices whose elements sum to 0. Binary search takes $O(\log n)$ time, so this step takes $O(n^{k/2} \log n)$ time.

Since we are ignoring factors of $\log n$, the overall running time of the algorithm is $\widetilde{O}(n^{k/2})$.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">SCOTT: LOOKS LIKE IT WOULD WORK *IF* WE KNEW THE k-SET WAS EQUALLY BALANCED
BETWEEN THE LEFT AND RIGHT HALVES...

JUSTIN: Up to 5 points.
Right, step 1 is incorrect. Instead, it should generate all O(n^{k/2}) sums of subsets of size k/2. Nothing about dividing into two halves.

4/5.
</mark>
(b) Assume $k$ is divisible by 3 and that we are again allowed multi-sets.  Describe a quantum algorithm that solves the $k$-SUM problem in $\widetilde{O}(n^{k/3})$ time.

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">We can solve the k-SUM problem in $\widetilde{O}(n^{k/3})$ time using a quantum algorithm based on Grover's search. Here's a high-level description of the algorithm:

1. Divide the list of integers into three equal parts: $A = x_1, \ldots, x_{n/3}$, $B = x_{n/3+1}, \ldots, x_{2n/3}$, and $C = x_{2n/3+1}, \ldots, x_n$.

2. Compute all possible sums of $k/3$ elements from each part. For each part, this can be done in $O(n^{k/3})$ time by iterating through all possible combinations of $k/3$ elements.

3. Sort the lists of sums for all three parts. This can be done in $O(n^{k/3} \log n)$ time using a comparison-based sorting algorithm.

4. Define an oracle function $f$ that takes as input a sum from the first part and a sum from the second part, and returns 1 if there exists a sum in the third part that is equal to the negation of the sum of the inputs, and 0 otherwise. This oracle can be implemented using a binary search on the sorted list of sums for the third part, which takes $O(\log n)$ time.

5. Use Grover's search algorithm to find a pair of sums from the first and second parts that satisfy the oracle function. Grover's search has a quadratic speedup over classical search, so it takes $O(\sqrt{n^{k/3}}) = O(n^{k/6})$ time.

Since we are ignoring factors of $\log n$, the overall running time of the algorithm is $\widetilde{O}(n^{k/3})$.
</mark>
<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: Up to 5 points.
Again, step 1 is incorrect, it shouldn't divide into three parts.
The division into three parts is more problematic this time as it comes up in step 4.
And it ends up claiming n^{k/6] time in step 5, better than the n^{k/3}.
Basically all this gets correct is to use Grover in some way.

1/5.
</mark>
(c) Suppose we wanted to prove that the algorithm from (b) was the fastest possible quantum algorithm for $k$-SUM.  Could that be shown via a lower bound on $k$-SUM's quantum query complexity?  Why or why not?

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-cyan-blue-color">Proving that the algorithm from (b) is the fastest possible quantum algorithm for k-SUM would require showing a lower bound on k-SUM's quantum query complexity that matches the upper bound achieved by the algorithm. However, a lower bound on the quantum query complexity alone might not be sufficient to prove the optimality of the algorithm, as it only considers the number of queries to the oracle function and does not account for other computational resources, such as time or space complexity.

To show that the algorithm from (b) is the fastest possible quantum algorithm for k-SUM, one would need to establish a lower bound on the quantum time complexity or some other relevant complexity measure that matches the upper bound achieved by the algorithm. This would provide a more comprehensive understanding of the problem's inherent difficulty and the limitations of quantum algorithms in solving it.</mark>

<mark style="background-color:rgba(0, 0, 0, 0)" class="has-inline-color has-vivid-red-color">JUSTIN: Up to 5 extra credit points.
This is a nice description of query vs time complexity, but misses the point that query complexity can prove a bound of at most Omega(n) since there are at most n potential queries to make.

1/5 extra credit points.</mark></pre>
<p class="authors">By Scott</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T17:17:41Z">Tuesday, April 11 2023, 17:17</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03960'>No-Existence Of Generalize Diffusion</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: David Ponarovsky</p><p>We show that there is no operator that given two state
$|\psi\rangle,|\phi\rangle$ compute the transformation:
$D|\psi\rangle|\phi\rangle = |\psi\rangle\bigl( \mathbb{I} - 2
|\psi\rangle\langle\psi| \bigr)|\phi\rangle$ The contradiction of the existence
follows by showing that using $D$ two players can compute the disjoints of
their sets in single round and $O\left( \sqrt{n} \right)$ communication
complexity, which shown by Braverman to be impossible \cite{Braverman}.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Ponarovsky_D/0/1/0/all/0/1">David Ponarovsky</a></p><p>We show that there is no operator that given two state
$|\psi\rangle,|\phi\rangle$ compute the transformation:
$D|\psi\rangle|\phi\rangle = |\psi\rangle\bigl( \mathbb{I} - 2
|\psi\rangle\langle\psi| \bigr)|\phi\rangle$ The contradiction of the existence
follows by showing that using $D$ two players can compute the disjoints of
their sets in single round and $O\left( \sqrt{n} \right)$ communication
complexity, which shown by Braverman to be impossible \cite{Braverman}.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03965'>The $n$-vehicle exploration problem is NP-complete</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jinchuan Cui, Xiaoya Li</p><p>The $n$-vehicle exploration problem (NVEP) is a combinatorial optimization
problem, which tries to find an optimal permutation of a fleet to maximize the
length traveled by the last vehicle. NVEP has a fractional form of objective
function, and its computational complexity of general case remains open. We
show that Hamiltonian Path $\leq_P$ NVEP, and prove that NVEP is NP-complete.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jinchuan Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoya Li</a></p><p>The $n$-vehicle exploration problem (NVEP) is a combinatorial optimization
problem, which tries to find an optimal permutation of a fleet to maximize the
length traveled by the last vehicle. NVEP has a fractional form of objective
function, and its computational complexity of general case remains open. We
show that Hamiltonian Path $\leq_P$ NVEP, and prove that NVEP is NP-complete.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04095'>A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm under Smoothness and Isoperimetry</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yuansi Chen, Khashayar Gatmiry</p><p>We study the mixing time of Metropolis-Adjusted Langevin algorithm (MALA) for
sampling a target density on $\mathbb{R}^d$. We assume that the target density
satisfies $\psi_\mu$-isoperimetry and that the operator norm and trace of its
Hessian are bounded by $L$ and $\Upsilon$ respectively. Our main result
establishes that, from a warm start, to achieve $\epsilon$-total variation
distance to the target density, MALA mixes in
$O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2}
\log\left(\frac{1}{\epsilon}\right)\right)$ iterations. Notably, this result
holds beyond the log-concave sampling setting and the mixing time depends on
only $\Upsilon$ rather than its upper bound $L d$. In the $m$-strongly
logconcave and $L$-log-smooth sampling setting, our bound recovers the previous
minimax mixing bound of MALA~\cite{wu2021minimax}.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1">Yuansi Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Gatmiry_K/0/1/0/all/0/1">Khashayar Gatmiry</a></p><p>We study the mixing time of Metropolis-Adjusted Langevin algorithm (MALA) for
sampling a target density on $\mathbb{R}^d$. We assume that the target density
satisfies $\psi_\mu$-isoperimetry and that the operator norm and trace of its
Hessian are bounded by $L$ and $\Upsilon$ respectively. Our main result
establishes that, from a warm start, to achieve $\epsilon$-total variation
distance to the target density, MALA mixes in
$O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2}
\log\left(\frac{1}{\epsilon}\right)\right)$ iterations. Notably, this result
holds beyond the log-concave sampling setting and the mixing time depends on
only $\Upsilon$ rather than its upper bound $L d$. In the $m$-strongly
logconcave and $L$-log-smooth sampling setting, our bound recovers the previous
minimax mixing bound of MALA~\cite{wu2021minimax}.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03828'>TDANetVis: Suggesting temporal resolutions for graph visualization using zigzag persistent homology</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Rapha&#xeb;l Tinarrage, Jean R. Ponciano, Claudio D. G. Linhares, Agma J. M. Traina, Jorge Poco</p><p>Temporal graphs are commonly used to represent complex systems and track the
evolution of their constituents over time. Visualizing these graphs is crucial
as it allows one to quickly identify anomalies, trends, patterns, and other
properties leading to better decision-making. In this context, the
to-be-adopted temporal resolution is crucial in constructing and analyzing the
layout visually. The choice of a resolution is critical, e.g., when dealing
with temporally sparse graphs. In such cases, changing the temporal resolution
by grouping events (i.e., edges) from consecutive timestamps, a technique known
as timeslicing, can aid in the analysis and reveal patterns that might not be
discernible otherwise. However, choosing a suitable temporal resolution is not
trivial. In this paper, we propose TDANetVis, a methodology that suggests
temporal resolutions potentially relevant for analyzing a given graph, i.e.,
resolutions that lead to substantial topological changes in the graph
structure. To achieve this goal, TDANetVis leverages zigzag persistent
homology, a well-established technique from Topological Data Analysis (TDA). To
enhance visual graph analysis, TDANetVis also incorporates the colored barcode,
a novel timeline-based visualization built on the persistence barcodes commonly
used in TDA. We demonstrate the usefulness and effectiveness of TDANetVis
through a usage scenario and a user study involving 27 participants.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tinarrage_R/0/1/0/all/0/1">Rapha&#xeb;l Tinarrage</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponciano_J/0/1/0/all/0/1">Jean R. Ponciano</a>, <a href="http://arxiv.org/find/cs/1/au:+Linhares_C/0/1/0/all/0/1">Claudio D. G. Linhares</a>, <a href="http://arxiv.org/find/cs/1/au:+Traina_A/0/1/0/all/0/1">Agma J. M. Traina</a>, <a href="http://arxiv.org/find/cs/1/au:+Poco_J/0/1/0/all/0/1">Jorge Poco</a></p><p>Temporal graphs are commonly used to represent complex systems and track the
evolution of their constituents over time. Visualizing these graphs is crucial
as it allows one to quickly identify anomalies, trends, patterns, and other
properties leading to better decision-making. In this context, the
to-be-adopted temporal resolution is crucial in constructing and analyzing the
layout visually. The choice of a resolution is critical, e.g., when dealing
with temporally sparse graphs. In such cases, changing the temporal resolution
by grouping events (i.e., edges) from consecutive timestamps, a technique known
as timeslicing, can aid in the analysis and reveal patterns that might not be
discernible otherwise. However, choosing a suitable temporal resolution is not
trivial. In this paper, we propose TDANetVis, a methodology that suggests
temporal resolutions potentially relevant for analyzing a given graph, i.e.,
resolutions that lead to substantial topological changes in the graph
structure. To achieve this goal, TDANetVis leverages zigzag persistent
homology, a well-established technique from Topological Data Analysis (TDA). To
enhance visual graph analysis, TDANetVis also incorporates the colored barcode,
a novel timeline-based visualization built on the persistence barcodes commonly
used in TDA. We demonstrate the usefulness and effectiveness of TDANetVis
through a usage scenario and a user study involving 27 participants.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03920'>Improved estimates on the number of unit perimeter triangles</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ritesh Goenka, Kenneth Moore, Ethan Patrick White</p><p>We obtain new upper and lower bounds on the number of unit perimeter
triangles spanned by points in the plane. We also establish improved bounds in
the special case where the point set is a section of the integer grid.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Goenka_R/0/1/0/all/0/1">Ritesh Goenka</a>, <a href="http://arxiv.org/find/math/1/au:+Moore_K/0/1/0/all/0/1">Kenneth Moore</a>, <a href="http://arxiv.org/find/math/1/au:+White_E/0/1/0/all/0/1">Ethan Patrick White</a></p><p>We obtain new upper and lower bounds on the number of unit perimeter
triangles spanned by points in the plane. We also establish improved bounds in
the special case where the point set is a section of the integer grid.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04079'>Convex Hulls: Surface Mapping onto a Sphere</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Ben Kenwright</p><p>Writing an uncomplicated, robust, and scalable three-dimensional convex hull
algorithm is challenging and problematic. This includes, coplanar and collinear
issues, numerical accuracy, performance, and complexity trade-offs. While there
are a number of methods available for finding the convex hull based on
geometric calculations, such as, the distance between points, but do not
address the technical challenges when implementing a usable solution (e.g.,
numerical issues and degenerate cloud points). We explain some common algorithm
pitfalls and engineering modifications to overcome and solve these limitations.
We present a novel iterative method using support mapping and surface
projection to create an uncomplicated and robust 2d and 3d convex hull
algorithm.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kenwright_B/0/1/0/all/0/1">Ben Kenwright</a></p><p>Writing an uncomplicated, robust, and scalable three-dimensional convex hull
algorithm is challenging and problematic. This includes, coplanar and collinear
issues, numerical accuracy, performance, and complexity trade-offs. While there
are a number of methods available for finding the convex hull based on
geometric calculations, such as, the distance between points, but do not
address the technical challenges when implementing a usable solution (e.g.,
numerical issues and degenerate cloud points). We explain some common algorithm
pitfalls and engineering modifications to overcome and solve these limitations.
We present a novel iterative method using support mapping and surface
projection to create an uncomplicated and robust 2d and 3d convex hull
algorithm.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03810'>On Testability of First-Order Properties in Bounded-Degree Graphs and Connections to Proximity-Oblivious Testing</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Isolde Adler, Noleen K&#xf6;hler, Pan Peng</p><p>We study property testing of properties that are definable in first-order
logic (FO) in the bounded-degree graph and relational structure models. We show
that any FO property that is defined by a formula with quantifier prefix
$\exists^*\forall^*$ is testable (i.e., testable with constant query
complexity), while there exists an FO property that is expressible by a formula
with quantifier prefix $\forall^*\exists^*$ that is not testable. In the dense
graph model, a similar picture is long known (Alon, Fischer, Krivelevich,
Szegedy, Combinatorica 2000), despite the very different nature of the two
models. In particular, we obtain our lower bound by an FO formula that defines
a class of bounded-degree expanders, based on zig-zag products of graphs. We
expect this to be of independent interest.
</p>
<p>We then use our class of FO definable bounded-degree expanders to answer a
long-standing open problem for proximity-oblivious testers (POTs). POTs are a
class of particularly simple testing algorithms, where a basic test is
performed a number of times that may depend on the proximity parameter, but the
basic test itself is independent of the proximity parameter. In their seminal
work, Goldreich and Ron [STOC 2009; SICOMP 2011] show that the graph properties
that are constant-query proximity-oblivious testable in the bounded-degree
model are precisely the properties that can be expressed as a generalised
subgraph freeness (GSF) property that satisfies the non-propagation condition.
It is left open whether the non-propagation condition is necessary. We give a
negative answer by showing that our property is a GSF property which is
propagating. Hence in particular, our property does not admit a POT. For this
result we establish a new connection between FO properties and GSF-local
properties via neighbourhood profiles.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Adler_I/0/1/0/all/0/1">Isolde Adler</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohler_N/0/1/0/all/0/1">Noleen K&#xf6;hler</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_P/0/1/0/all/0/1">Pan Peng</a></p><p>We study property testing of properties that are definable in first-order
logic (FO) in the bounded-degree graph and relational structure models. We show
that any FO property that is defined by a formula with quantifier prefix
$\exists^*\forall^*$ is testable (i.e., testable with constant query
complexity), while there exists an FO property that is expressible by a formula
with quantifier prefix $\forall^*\exists^*$ that is not testable. In the dense
graph model, a similar picture is long known (Alon, Fischer, Krivelevich,
Szegedy, Combinatorica 2000), despite the very different nature of the two
models. In particular, we obtain our lower bound by an FO formula that defines
a class of bounded-degree expanders, based on zig-zag products of graphs. We
expect this to be of independent interest.
</p>
<p>We then use our class of FO definable bounded-degree expanders to answer a
long-standing open problem for proximity-oblivious testers (POTs). POTs are a
class of particularly simple testing algorithms, where a basic test is
performed a number of times that may depend on the proximity parameter, but the
basic test itself is independent of the proximity parameter. In their seminal
work, Goldreich and Ron [STOC 2009; SICOMP 2011] show that the graph properties
that are constant-query proximity-oblivious testable in the bounded-degree
model are precisely the properties that can be expressed as a generalised
subgraph freeness (GSF) property that satisfies the non-propagation condition.
It is left open whether the non-propagation condition is necessary. We give a
negative answer by showing that our property is a GSF property which is
propagating. Hence in particular, our property does not admit a POT. For this
result we establish a new connection between FO properties and GSF-local
properties via neighbourhood profiles.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03838'>Improving Identity-Robustness for Face Models</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Qi Qi, Shervin Ardeshir</p><p>Despite the success of deep-learning models in many tasks, there have been
concerns about such models learning shortcuts, and their lack of robustness to
irrelevant confounders. When it comes to models directly trained on human
faces, a sensitive confounder is that of human identities. Many face-related
tasks should ideally be identity-independent, and perform uniformly across
different individuals (i.e. be fair). One way to measure and enforce such
robustness and performance uniformity is through enforcing it during training,
assuming identity-related information is available at scale. However, due to
privacy concerns and also the cost of collecting such information, this is
often not the case, and most face datasets simply contain input images and
their corresponding task-related labels. Thus, improving identity-related
robustness without the need for such annotations is of great importance. Here,
we explore using face-recognition embedding vectors, as proxies for identities,
to enforce such robustness. We propose to use the structure in the
face-recognition embedding space, to implicitly emphasize rare samples within
each class. We do so by weighting samples according to their conditional
inverse density (CID) in the proxy embedding space. Our experiments suggest
that such a simple sample weighting scheme, not only improves the training
robustness, it often improves the overall performance as a result of such
robustness. We also show that employing such constraints during training
results in models that are significantly less sensitive to different levels of
bias in the dataset.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ardeshir_S/0/1/0/all/0/1">Shervin Ardeshir</a></p><p>Despite the success of deep-learning models in many tasks, there have been
concerns about such models learning shortcuts, and their lack of robustness to
irrelevant confounders. When it comes to models directly trained on human
faces, a sensitive confounder is that of human identities. Many face-related
tasks should ideally be identity-independent, and perform uniformly across
different individuals (i.e. be fair). One way to measure and enforce such
robustness and performance uniformity is through enforcing it during training,
assuming identity-related information is available at scale. However, due to
privacy concerns and also the cost of collecting such information, this is
often not the case, and most face datasets simply contain input images and
their corresponding task-related labels. Thus, improving identity-related
robustness without the need for such annotations is of great importance. Here,
we explore using face-recognition embedding vectors, as proxies for identities,
to enforce such robustness. We propose to use the structure in the
face-recognition embedding space, to implicitly emphasize rare samples within
each class. We do so by weighting samples according to their conditional
inverse density (CID) in the proxy embedding space. Our experiments suggest
that such a simple sample weighting scheme, not only improves the training
robustness, it often improves the overall performance as a result of such
robustness. We also show that employing such constraints during training
results in models that are significantly less sensitive to different levels of
bias in the dataset.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03985'>On Rotation Distance of Rank Bounded Trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anoop S. K. M., Jayalal Sarma</p><p>Computing the rotation distance between two binary trees with $n$ internal
nodes efficiently (in $poly(n)$ time) is a long standing open question in the
study of height balancing in tree data structures. In this paper, we initiate
the study of this problem bounding the rank of the trees given at the input
(defined by Ehrenfeucht and Haussler (1989) in the context of decision trees).
We define the rank-bounded rotation distance between two given binary trees
$T_1$ and $T_2$ (with $n$ internal nodes) of rank at most $r$, denoted by
$d_r(T_1,T_2)$, as the length of the shortest sequence of rotations that
transforms $T_1$ to $T_2$ with the restriction that the intermediate trees must
be of rank at most $r$. We show that the rotation distance problem reduces in
polynomial time to the rank bounded rotation distance problem. This motivates
the study of the problem in the combinatorial and algorithmic frontiers.
Observing that trees with rank $1$ coincide exactly with skew trees (binary
trees where every internal node has at least one leaf as a child), we show the
following results in this frontier :
</p>
<p>We present an $O(n^2)$ time algorithm for computing $d_1(T_1,T_2)$. That is,
when the given trees are skew trees (we call this variant as skew rotation
distance problem) - where the intermediate trees are restricted to be skew as
well. In particular, our techniques imply that for any two skew trees
$d(T_1,T_2) \le n^2$.
</p>
<p>We show the following upper bound : for any two trees $T_1$ and $T_2$ of rank
at most $r_1$ and $r_2$ respectively, we have that: $d_r(T_1,T_2) \le n^2
(1+(2n+1)(r_1+r_2-2))$ where $r = max\{r_1,r_2\}$. This bound is asymptotically
tight for $r=1$.
</p>
<p>En route our proof of the above theorems, we associate binary trees to
permutations and bivariate polynomials, and prove several characterizations in
the case of skew trees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+M%2E_A/0/1/0/all/0/1">Anoop S. K. M.</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarma_J/0/1/0/all/0/1">Jayalal Sarma</a></p><p>Computing the rotation distance between two binary trees with $n$ internal
nodes efficiently (in $poly(n)$ time) is a long standing open question in the
study of height balancing in tree data structures. In this paper, we initiate
the study of this problem bounding the rank of the trees given at the input
(defined by Ehrenfeucht and Haussler (1989) in the context of decision trees).
We define the rank-bounded rotation distance between two given binary trees
$T_1$ and $T_2$ (with $n$ internal nodes) of rank at most $r$, denoted by
$d_r(T_1,T_2)$, as the length of the shortest sequence of rotations that
transforms $T_1$ to $T_2$ with the restriction that the intermediate trees must
be of rank at most $r$. We show that the rotation distance problem reduces in
polynomial time to the rank bounded rotation distance problem. This motivates
the study of the problem in the combinatorial and algorithmic frontiers.
Observing that trees with rank $1$ coincide exactly with skew trees (binary
trees where every internal node has at least one leaf as a child), we show the
following results in this frontier :
</p>
<p>We present an $O(n^2)$ time algorithm for computing $d_1(T_1,T_2)$. That is,
when the given trees are skew trees (we call this variant as skew rotation
distance problem) - where the intermediate trees are restricted to be skew as
well. In particular, our techniques imply that for any two skew trees
$d(T_1,T_2) \le n^2$.
</p>
<p>We show the following upper bound : for any two trees $T_1$ and $T_2$ of rank
at most $r_1$ and $r_2$ respectively, we have that: $d_r(T_1,T_2) \le n^2
(1+(2n+1)(r_1+r_2-2))$ where $r = max\{r_1,r_2\}$. This bound is asymptotically
tight for $r=1$.
</p>
<p>En route our proof of the above theorems, we associate binary trees to
permutations and bivariate polynomials, and prove several characterizations in
the case of skew trees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04024'>Prophet Inequalities: Separating Random Order from Order Selection</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Giordano Giambartolomei, Frederik Mallmann-Trenn, Raimundo Saona</p><p>Prophet inequalities are a central object of study in optimal stopping
theory. A gambler is sent values online, sampled from an instance of
independent distributions, in an adversarial, random or selected order,
depending on the model. When observing each value, the gambler either accepts
it as a reward or irrevocably rejects it and proceeds to observe the next
value. The goal of the gambler, who cannot see the future, is maximising the
expected value of the reward while competing against the expectation of a
prophet (the offline maximum). In other words, one seeks to maximise the
gambler-to-prophet ratio of the expectations.
</p>
<p>The model, in which the gambler selects the arrival order first, and then
observes the values, is known as Order Selection. Recently it has been shown
that in this model a ratio of $0.7251$ can be attained for any instance. If the
gambler chooses the arrival order (uniformly) at random, we obtain the Random
Order model. The worst case ratio over all possible instances has been
extensively studied for at least $40$ years. Still, it is not known if
carefully choosing the order, or simply taking it at random, benefits the
gambler. We prove that, in the Random Order model, no algorithm can achieve a
ratio larger than $0.7235$, thus showing for the first time that there is a
real benefit in choosing the order.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Giambartolomei_G/0/1/0/all/0/1">Giordano Giambartolomei</a>, <a href="http://arxiv.org/find/cs/1/au:+Mallmann_Trenn_F/0/1/0/all/0/1">Frederik Mallmann-Trenn</a>, <a href="http://arxiv.org/find/cs/1/au:+Saona_R/0/1/0/all/0/1">Raimundo Saona</a></p><p>Prophet inequalities are a central object of study in optimal stopping
theory. A gambler is sent values online, sampled from an instance of
independent distributions, in an adversarial, random or selected order,
depending on the model. When observing each value, the gambler either accepts
it as a reward or irrevocably rejects it and proceeds to observe the next
value. The goal of the gambler, who cannot see the future, is maximising the
expected value of the reward while competing against the expectation of a
prophet (the offline maximum). In other words, one seeks to maximise the
gambler-to-prophet ratio of the expectations.
</p>
<p>The model, in which the gambler selects the arrival order first, and then
observes the values, is known as Order Selection. Recently it has been shown
that in this model a ratio of $0.7251$ can be attained for any instance. If the
gambler chooses the arrival order (uniformly) at random, we obtain the Random
Order model. The worst case ratio over all possible instances has been
extensively studied for at least $40$ years. Still, it is not known if
carefully choosing the order, or simply taking it at random, benefits the
gambler. We prove that, in the Random Order model, no algorithm can achieve a
ratio larger than $0.7235$, thus showing for the first time that there is a
real benefit in choosing the order.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04196'>A simple and efficient preprocessing step for convex hull problem</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Mohammad Heydari, Ashkan Khalifeh</p><p>The present paper is concerned with a recursive algorithm as a preprocessing
step to find the convex hull of $n$ random points uniformly distributed in the
plane. For such a set of points, it is shown that eliminating all but $O(\log
n)$ of points can derive the same convex hull as the input set. Finally it will
be shown that the running time of the algorithm is $O(n)
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Heydari_M/0/1/0/all/0/1">Mohammad Heydari</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalifeh_A/0/1/0/all/0/1">Ashkan Khalifeh</a></p><p>The present paper is concerned with a recursive algorithm as a preprocessing
step to find the convex hull of $n$ random points uniformly distributed in the
plane. For such a set of points, it is shown that eliminating all but $O(\log
n)$ of points can derive the same convex hull as the input set. Finally it will
be shown that the running time of the algorithm is $O(n)
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04318'>On Extend-Only Directed Posets and Derived Byzantine-Tolerant Replicated Data Types (Extended Version)</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Florian Jacob, Hannes Hartenstein</p><p>We uncover the extend-only directed posets (EDP) structure as a unification
of recently discussed DAG-based Byzantine-tolerant conflict-free replicated
data types (CRDT). We also show how a key-value map model can be derived from
the EDP formulation, and give an outlook on an EDP-based systemic access
control CRDT as a formalization of the CRDT used in the Matrix messaging
system.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jacob_F/0/1/0/all/0/1">Florian Jacob</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartenstein_H/0/1/0/all/0/1">Hannes Hartenstein</a></p><p>We uncover the extend-only directed posets (EDP) structure as a unification
of recently discussed DAG-based Byzantine-tolerant conflict-free replicated
data types (CRDT). We also show how a key-value map model can be derived from
the EDP formulation, and give an outlook on an EDP-based systemic access
control CRDT as a formalization of the CRDT used in the Matrix messaging
system.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.04397'>Randomized and Deterministic Attention Sparsification Algorithms for Over-parameterized Feature Dimension</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yichuan Deng, Sridhar Mahadevan, Zhao Song</p><p>Large language models (LLMs) have shown their power in different areas.
Attention computation, as an important subroutine of LLMs, has also attracted
interests in theory. Recently the static computation and dynamic maintenance of
attention matrix has been studied by [Alman and Song 2023] and [Brand, Song and
Zhou 2023] from both algorithmic perspective and hardness perspective. In this
work, we consider the sparsification of the attention problem. We make one
simplification which is the logit matrix is symmetric. Let $n$ denote the
length of sentence, let $d$ denote the embedding dimension. Given a matrix $X
\in \mathbb{R}^{n \times d}$, suppose $d \gg n$ and $\| X X^\top \|_{\infty} &lt;
r$ with $r \in (0,0.1)$, then we aim for finding $Y \in \mathbb{R}^{n \times
m}$ (where $m\ll d$) such that \begin{align*} \| D(Y)^{-1} \exp( Y Y^\top ) -
D(X)^{-1} \exp( X X^\top) \|_{\infty} \leq O(r) \end{align*} We provide two
results for this problem.
</p>
<p>$\bullet$ Our first result is a randomized algorithm. It runs in
$\widetilde{O}(\mathrm{nnz}(X) + n^{\omega} ) $ time, has $1-\delta$ succeed
probability, and chooses $m = O(n \log(n/\delta))$. Here $\mathrm{nnz}(X)$
denotes the number of non-zero entries in $X$. We use $\omega$ to denote the
exponent of matrix multiplication. Currently $\omega \approx 2.373$.
</p>
<p>$\bullet$ Our second result is a deterministic algorithm. It runs in
$\widetilde{O}(\min\{\sum_{i\in[d]}\mathrm{nnz}(X_i)^2, dn^{\omega-1}\} +
n^{\omega+1})$ time and chooses $m = O(n)$. Here $X_i$ denote the $i$-th column
of matrix $X$.
</p>
<p>Our main findings have the following implication for applied LLMs task: for
any super large feature dimension, we can reduce it down to the size nearly
linear in length of sentence.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yichuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahadevan_S/0/1/0/all/0/1">Sridhar Mahadevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a></p><p>Large language models (LLMs) have shown their power in different areas.
Attention computation, as an important subroutine of LLMs, has also attracted
interests in theory. Recently the static computation and dynamic maintenance of
attention matrix has been studied by [Alman and Song 2023] and [Brand, Song and
Zhou 2023] from both algorithmic perspective and hardness perspective. In this
work, we consider the sparsification of the attention problem. We make one
simplification which is the logit matrix is symmetric. Let $n$ denote the
length of sentence, let $d$ denote the embedding dimension. Given a matrix $X
\in \mathbb{R}^{n \times d}$, suppose $d \gg n$ and $\| X X^\top \|_{\infty} &lt;
r$ with $r \in (0,0.1)$, then we aim for finding $Y \in \mathbb{R}^{n \times
m}$ (where $m\ll d$) such that \begin{align*} \| D(Y)^{-1} \exp( Y Y^\top ) -
D(X)^{-1} \exp( X X^\top) \|_{\infty} \leq O(r) \end{align*} We provide two
results for this problem.
</p>
<p>$\bullet$ Our first result is a randomized algorithm. It runs in
$\widetilde{O}(\mathrm{nnz}(X) + n^{\omega} ) $ time, has $1-\delta$ succeed
probability, and chooses $m = O(n \log(n/\delta))$. Here $\mathrm{nnz}(X)$
denotes the number of non-zero entries in $X$. We use $\omega$ to denote the
exponent of matrix multiplication. Currently $\omega \approx 2.373$.
</p>
<p>$\bullet$ Our second result is a deterministic algorithm. It runs in
$\widetilde{O}(\min\{\sum_{i\in[d]}\mathrm{nnz}(X_i)^2, dn^{\omega-1}\} +
n^{\omega+1})$ time and chooses $m = O(n)$. Here $X_i$ denote the $i$-th column
of matrix $X$.
</p>
<p>Our main findings have the following implication for applied LLMs task: for
any super large feature dimension, we can reduce it down to the size nearly
linear in length of sentence.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-11T00:30:00Z">Tuesday, April 11 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Monday, April 10
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://blog.computationalcomplexity.org/2023/04/complexity-and-generative-ai.html'>Complexity and Explainable AI</a></h3>
        <p class='tr-article-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>About six years ago, I posted&nbsp;on why it was important to understand machine learning, mentioning trust, fairness, security and causality. But I then I brought in complexity.</p><p></p><blockquote>What if P = NP? Would that help. Actually it would makes things worse. If you had a quick algorithm for NP-complete problems, you could use it to find the smallest possible circuit for say matching or traveling salesman but you would have no clue why that circuit works.&nbsp;</blockquote><p>Ryan Williams countered</p><p></p><blockquote>If P=NP you could also find the shortest proof in your favorite formal system that the smallest possible circuit does what you wanted it to do, as well as any other claim you are wondering that may be true about the circuit. That proof might not be comprehensible to you, but it could be written in a format where proof assistant software such as HOL or Coq could parse it and convince you it is correct. So if P=NP (with feasible low constants) I think that would definitely help.</blockquote><p>So if P = NP maybe you couldn't understand how the circuit works but any question about how it works you could answer.&nbsp;</p><p>While we don't live in a world where P = NP, we are in a world where we can produce very strong learning algorithms where we can't understand the programs they produce. They are now powerful enough to apply Ryan's idea and use the algorithms themselves to understand the decisions they make.</p><p>For example I tried using Google Translate on a Hungarian obituary of Vera&nbsp;Sós. Hungarian does not use gendered pronouns and and the translation incorrectly produced male pronouns. I then fed the translation into ChatGPT which translated with the correct female pronouns.&nbsp;</p><p>You can speculate why Google Translate uses male pronouns but you can't ask it why. But you can ask ChatGPT.</p><p></p><blockquote>I used female pronouns in the translation because Vera T. Sós is a female name. Vera is a feminine given name, and since the context of the original text is about her life and accomplishments, it is appropriate to use female pronouns in the English translation to maintain clarity and accurately convey information about her.</blockquote><p>So perhaps if you want to understand how ML works, perhaps we should seek stronger algorithms, not weaker ones, algorithms that can explain themselves. As they say, a dull knife is more dangerous than a sharp one.</p><p></p><p></p><p></p><p></p><p>By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>About six years ago, I <a href="https://blog.computationalcomplexity.org/2017/04/understanding-machine-learning.html">posted</a>&nbsp;on why it was important to understand machine learning, mentioning trust, fairness, security and causality. But I then I brought in complexity.</p><p></p><blockquote>What if P = NP? Would that help. Actually it would makes things worse. If you had a quick algorithm for NP-complete problems, you could use it to find the smallest possible circuit for say matching or traveling salesman but you would have no clue why that circuit works.&nbsp;</blockquote><p>Ryan Williams <a href="https://blog.computationalcomplexity.org/2017/04/understanding-machine-learning.html?showComment=1492464695392#c7595821335622802218">countered</a></p><p></p><blockquote>If P=NP you could also find the shortest proof in your favorite formal system that the smallest possible circuit does what you wanted it to do, as well as any other claim you are wondering that may be true about the circuit. That proof might not be comprehensible to you, but it could be written in a format where proof assistant software such as HOL or Coq could parse it and convince you it is correct. So if P=NP (with feasible low constants) I think that would definitely help.</blockquote><p>So if P = NP maybe you couldn't understand how the circuit works but any question about how it works you could answer.&nbsp;</p><p>While we don't live in a world where P = NP, we are in a world where we can produce very strong learning algorithms where we can't understand the programs they produce. They are now powerful enough to apply Ryan's idea and use the algorithms themselves to understand the decisions they make.</p><p>For example I tried using Google Translate on a <a href="https://mta.hu/mta_hirei/elhunyt-t-sos-vera-matematikus-az-mta-rendes-tagja-112809">Hungarian obituary</a> of Vera&nbsp;Sós. Hungarian does not use gendered pronouns and and the translation incorrectly produced male pronouns. I then fed the translation into ChatGPT which translated with the correct female pronouns.&nbsp;</p><p>You can speculate why Google Translate uses male pronouns but you can't ask it why. But you can ask ChatGPT.</p><p></p><blockquote>I used female pronouns in the translation because Vera T. Sós is a female name. Vera is a feminine given name, and since the context of the original text is about her life and accomplishments, it is appropriate to use female pronouns in the English translation to maintain clarity and accurately convey information about her.</blockquote><p>So perhaps if you want to understand how ML works, perhaps we should seek stronger algorithms, not weaker ones, algorithms that can explain themselves. As <a href="https://knivesengraved.com/blogs/news/why-sharp-knives-are-safer-than-dull-knives">they say</a>, a dull knife is more dangerous than a sharp one.</p><p></p><p></p><p></p><p></p><p class="authors">By Lance Fortnow</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-10T17:37:00Z">Monday, April 10 2023, 17:37</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03448'>Quantum delegation with an off-the-shelf device</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Anne Broadbent, Arthur Mehta, Yuming Zhao</p><p>Given that reliable cloud quantum computers are becoming closer to reality,
the concept of delegation of quantum computations and its verifiability is of
central interest. Many models have been proposed, each with specific strengths
and weaknesses. Here, we put forth a new model where the client trusts only its
classical processing, makes no computational assumptions, and interacts with a
quantum server in a single round. In addition, during a set-up phase, the
client specifies the size $n$ of the computation and receives an untrusted,
off-the-shelf (OTS) quantum device that is used to report the outcome of a
single constant-sized measurement from a predetermined logarithmic-sized input.
In the OTS model, we thus picture that a single quantum server does the bulk of
the computations, while the OTS device is used as an untrusted and generic
verification device, all in a single round.
</p>
<p>We show how to delegate polynomial-time quantum computations in the OTS
model. Scaling up the technique also yields an interactive proof system for all
of QMA, which, furthermore, we show can be accomplished in statistical
zero-knowledge. This yields the first relativistic (one-round), two-prover
zero-knowledge proof system for QMA.
</p>
<p>As a proof approach, we provide a new self-test for $n$-EPR pairs using only
constant-sized Pauli measurements, and show how it provides a new avenue for
the use of simulatable codes for local Hamiltonian verification. Along the way,
we also provide an enhanced version of a well-known stability result due to
Gowers and Hatami and show how it completes a common argument used in
self-testing.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Broadbent_A/0/1/0/all/0/1">Anne Broadbent</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Mehta_A/0/1/0/all/0/1">Arthur Mehta</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhao_Y/0/1/0/all/0/1">Yuming Zhao</a></p><p>Given that reliable cloud quantum computers are becoming closer to reality,
the concept of delegation of quantum computations and its verifiability is of
central interest. Many models have been proposed, each with specific strengths
and weaknesses. Here, we put forth a new model where the client trusts only its
classical processing, makes no computational assumptions, and interacts with a
quantum server in a single round. In addition, during a set-up phase, the
client specifies the size $n$ of the computation and receives an untrusted,
off-the-shelf (OTS) quantum device that is used to report the outcome of a
single constant-sized measurement from a predetermined logarithmic-sized input.
In the OTS model, we thus picture that a single quantum server does the bulk of
the computations, while the OTS device is used as an untrusted and generic
verification device, all in a single round.
</p>
<p>We show how to delegate polynomial-time quantum computations in the OTS
model. Scaling up the technique also yields an interactive proof system for all
of QMA, which, furthermore, we show can be accomplished in statistical
zero-knowledge. This yields the first relativistic (one-round), two-prover
zero-knowledge proof system for QMA.
</p>
<p>As a proof approach, we provide a new self-test for $n$-EPR pairs using only
constant-sized Pauli measurements, and show how it provides a new avenue for
the use of simulatable codes for local Hamiltonian verification. Along the way,
we also provide an enhanced version of a well-known stability result due to
Gowers and Hatami and show how it completes a common argument used in
self-testing.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-10T00:30:00Z">Monday, April 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03484'>Maximal Distortion of Geodesic Diameters in Polygonal Domains</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Adrian Dumitrescu, Csaba D. T&#xf3;th</p><p>For a polygon $P$ with holes in the plane, we denote by $\varrho(P)$ the
ratio between the geodesic and the Euclidean diameters of $P$. It is shown that
over all convex polygons with $h$~convex holes, the supremum of $\varrho(P)$ is
between $\Omega(h^{1/3})$ and $O(h^{1/2})$. The upper bound improves to
$O(1+\min\{h^{3/4}\Delta,h^{1/2}\Delta^{1/2}\})$ if every hole has diameter at
most $\Delta\cdot {\rm diam}_2(P)$; and to $O(1)$ if every hole is a \emph{fat}
convex polygon. Furthermore, we show that the function $g(h)=\sup_P \varrho(P)$
over convex polygons with $h$ convex holes has the same growth rate as an
analogous quantity over geometric triangulations with $h$ vertices when
$h\rightarrow \infty$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dumitrescu_A/0/1/0/all/0/1">Adrian Dumitrescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Toth_C/0/1/0/all/0/1">Csaba D. T&#xf3;th</a></p><p>For a polygon $P$ with holes in the plane, we denote by $\varrho(P)$ the
ratio between the geodesic and the Euclidean diameters of $P$. It is shown that
over all convex polygons with $h$~convex holes, the supremum of $\varrho(P)$ is
between $\Omega(h^{1/3})$ and $O(h^{1/2})$. The upper bound improves to
$O(1+\min\{h^{3/4}\Delta,h^{1/2}\Delta^{1/2}\})$ if every hole has diameter at
most $\Delta\cdot {\rm diam}_2(P)$; and to $O(1)$ if every hole is a \emph{fat}
convex polygon. Furthermore, we show that the function $g(h)=\sup_P \varrho(P)$
over convex polygons with $h$ convex holes has the same growth rate as an
analogous quantity over geometric triangulations with $h$ vertices when
$h\rightarrow \infty$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-10T00:30:00Z">Monday, April 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03377'>Leveraging Reusability: Improved Competitive Ratio of Greedy for Reusable Resources</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jackie Baek, Shixin Wang</p><p>We study online weighted bipartite matching of reusable resources where an
adversarial sequence of requests for resources arrive over time. A resource
that is matched is 'used' for a random duration, drawn independently from a
resource-dependent distribution, after which it returns and is able to be
matched again. We study the performance of the greedy policy, which matches
requests to the resource that yields the highest reward. Previously, it was
known that the greedy policy is 1/2 competitive against a clairvoyant benchmark
that knows the request sequence in advance. In this work, we improve this
result by introducing a parameter that quantifies the degree of reusability of
the resources. Specifically, if p represents the smallest probability over the
usage distributions that a matched resource returns in one time step, the
greedy policy achieves a competitive ratio of $1/(2-p)$. Furthermore, when the
usage distributions are geometric, we establish a stronger competitive ratio of
$(1+p)/2$, which we demonstrate to be tight. Both of these results align with
the known results in the two extreme scenarios: p = 0 corresponds to
non-reusable resources, where 1/2 is known to be tight, while p = 1 corresponds
to every resource returning immediately, where greedy is the optimal policy and
hence the competitive ratio is 1. Finally, we show that both results are robust
to approximations of the greedy policy. Our work demonstrates that the
reusability of resources can enhance performance compared to the non-reusable
setting, and that a simple greedy policy suffices when the degree of
reusability is high. Our insights contribute to the understanding of how
resource reusability can influence the performance of online algorithms, and
highlight the potential for improved performance as the degree of reusability
increases.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1">Jackie Baek</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shixin Wang</a></p><p>We study online weighted bipartite matching of reusable resources where an
adversarial sequence of requests for resources arrive over time. A resource
that is matched is 'used' for a random duration, drawn independently from a
resource-dependent distribution, after which it returns and is able to be
matched again. We study the performance of the greedy policy, which matches
requests to the resource that yields the highest reward. Previously, it was
known that the greedy policy is 1/2 competitive against a clairvoyant benchmark
that knows the request sequence in advance. In this work, we improve this
result by introducing a parameter that quantifies the degree of reusability of
the resources. Specifically, if p represents the smallest probability over the
usage distributions that a matched resource returns in one time step, the
greedy policy achieves a competitive ratio of $1/(2-p)$. Furthermore, when the
usage distributions are geometric, we establish a stronger competitive ratio of
$(1+p)/2$, which we demonstrate to be tight. Both of these results align with
the known results in the two extreme scenarios: p = 0 corresponds to
non-reusable resources, where 1/2 is known to be tight, while p = 1 corresponds
to every resource returning immediately, where greedy is the optimal policy and
hence the competitive ratio is 1. Finally, we show that both results are robust
to approximations of the greedy policy. Our work demonstrates that the
reusability of resources can enhance performance compared to the non-reusable
setting, and that a simple greedy policy suffices when the degree of
reusability is high. Our insights contribute to the understanding of how
resource reusability can influence the performance of online algorithms, and
highlight the potential for improved performance as the degree of reusability
increases.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-10T00:30:00Z">Monday, April 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03426'>Convex Minimization with Integer Minima in $\widetilde O(n^4)$ Time</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Haotian Jiang, Yin Tat Lee, Zhao Song, Lichen Zhang</p><p>Given a convex function $f$ on $\mathbb{R}^n$ with an integer minimizer, we
show how to find an exact minimizer of $f$ using $O(n^2 \log n)$ calls to a
separation oracle and $O(n^4 \log n)$ time. The previous best polynomial time
algorithm for this problem given in [Jiang, SODA 2021, JACM 2022] achieves
$\widetilde{O}(n^2)$ oracle complexity. However, the overall runtime of Jiang's
algorithm is at least $\widetilde{\Omega}(n^8)$, due to expensive sub-routines
such as the Lenstra-Lenstra-Lov\'asz (LLL) algorithm [Lenstra, Lenstra,
Lov\'asz, Math. Ann. 1982] and random walk based cutting plane method
[Bertsimas, Vempala, JACM 2004]. Our significant speedup is obtained by a
nontrivial combination of a faster version of the LLL algorithm due to
[Neumaier, Stehl\'e, ISSAC 2016] that gives similar guarantees, the volumetric
center cutting plane method (CPM) by [Vaidya, FOCS 1989] and its fast
implementation given in [Jiang, Lee, Song, Wong, STOC 2020].
</p>
<p>For the special case of submodular function minimization (SFM), our result
implies a strongly polynomial time algorithm for this problem using $O(n^3 \log
n)$ calls to an evaluation oracle and $O(n^4 \log n)$ additional arithmetic
operations. Both the oracle complexity and the number of arithmetic operations
of our more general algorithm are better than the previous best-known runtime
algorithms for this specific problem given in [Lee, Sidford, Wong, FOCS 2015]
and [Dadush, V\'egh, Zambelli, SODA 2018, MOR 2021].
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haotian Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yin Tat Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lichen Zhang</a></p><p>Given a convex function $f$ on $\mathbb{R}^n$ with an integer minimizer, we
show how to find an exact minimizer of $f$ using $O(n^2 \log n)$ calls to a
separation oracle and $O(n^4 \log n)$ time. The previous best polynomial time
algorithm for this problem given in [Jiang, SODA 2021, JACM 2022] achieves
$\widetilde{O}(n^2)$ oracle complexity. However, the overall runtime of Jiang's
algorithm is at least $\widetilde{\Omega}(n^8)$, due to expensive sub-routines
such as the Lenstra-Lenstra-Lov\'asz (LLL) algorithm [Lenstra, Lenstra,
Lov\'asz, Math. Ann. 1982] and random walk based cutting plane method
[Bertsimas, Vempala, JACM 2004]. Our significant speedup is obtained by a
nontrivial combination of a faster version of the LLL algorithm due to
[Neumaier, Stehl\'e, ISSAC 2016] that gives similar guarantees, the volumetric
center cutting plane method (CPM) by [Vaidya, FOCS 1989] and its fast
implementation given in [Jiang, Lee, Song, Wong, STOC 2020].
</p>
<p>For the special case of submodular function minimization (SFM), our result
implies a strongly polynomial time algorithm for this problem using $O(n^3 \log
n)$ calls to an evaluation oracle and $O(n^4 \log n)$ additional arithmetic
operations. Both the oracle complexity and the number of arithmetic operations
of our more general algorithm are better than the previous best-known runtime
algorithms for this specific problem given in [Lee, Sidford, Wong, FOCS 2015]
and [Dadush, V\'egh, Zambelli, SODA 2018, MOR 2021].
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-10T00:30:00Z">Monday, April 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03567'>Temporalizing digraphs via linear-size balanced bi-trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: St&#xe9;phane Bessy, St&#xe9;phan Thomass&#xe9;, Laurent Viennot</p><p>In a directed graph $D$ on vertex set $v_1,\dots ,v_n$, a \emph{forward arc}
is an arc $v_iv_j$ where $i&lt;j$. A pair $v_i,v_j$ is \emph{forward connected} if
there is a directed path from $v_i$ to $v_j$ consisting of forward arcs. In the
{\tt Forward Connected Pairs Problem} ({\tt FCPP}), the input is a strongly
connected digraph $D$, and the output is the maximum number of forward
connected pairs in some vertex enumeration of $D$. We show that {\tt FCPP} is
in APX, as one can efficiently enumerate the vertices of $D$ in order to
achieve a quadratic number of forward connected pairs. For this, we construct a
linear size balanced bi-tree $T$ (an out-tree and an in-tree with same size
which roots are identified). The existence of such a $T$ was left as an open
problem motivated by the study of temporal paths in temporal networks. More
precisely, $T$ can be constructed in quadratic time (in the number of vertices)
and has size at least $n/3$. The algorithm involves a particular depth-first
search tree (Left-DFS) of independent interest, and shows that every strongly
connected directed graph has a balanced separator which is a circuit.
Remarkably, in the request version {\tt RFCPP} of {\tt FCPP}, where the input
is a strong digraph $D$ and a set of requests $R$ consisting of pairs
$\{x_i,y_i\}$, there is no constant $c&gt;0$ such that one can always find an
enumeration realizing $c.|R|$ forward connected pairs $\{x_i,y_i\}$ (in either
direction).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Bessy_S/0/1/0/all/0/1">St&#xe9;phane Bessy</a>, <a href="http://arxiv.org/find/math/1/au:+Thomasse_S/0/1/0/all/0/1">St&#xe9;phan Thomass&#xe9;</a>, <a href="http://arxiv.org/find/math/1/au:+Viennot_L/0/1/0/all/0/1">Laurent Viennot</a></p><p>In a directed graph $D$ on vertex set $v_1,\dots ,v_n$, a \emph{forward arc}
is an arc $v_iv_j$ where $i&lt;j$. A pair $v_i,v_j$ is \emph{forward connected} if
there is a directed path from $v_i$ to $v_j$ consisting of forward arcs. In the
{\tt Forward Connected Pairs Problem} ({\tt FCPP}), the input is a strongly
connected digraph $D$, and the output is the maximum number of forward
connected pairs in some vertex enumeration of $D$. We show that {\tt FCPP} is
in APX, as one can efficiently enumerate the vertices of $D$ in order to
achieve a quadratic number of forward connected pairs. For this, we construct a
linear size balanced bi-tree $T$ (an out-tree and an in-tree with same size
which roots are identified). The existence of such a $T$ was left as an open
problem motivated by the study of temporal paths in temporal networks. More
precisely, $T$ can be constructed in quadratic time (in the number of vertices)
and has size at least $n/3$. The algorithm involves a particular depth-first
search tree (Left-DFS) of independent interest, and shows that every strongly
connected directed graph has a balanced separator which is a circuit.
Remarkably, in the request version {\tt RFCPP} of {\tt FCPP}, where the input
is a strong digraph $D$ and a set of requests $R$ consisting of pairs
$\{x_i,y_i\}$, there is no constant $c&gt;0$ such that one can always find an
enumeration realizing $c.|R|$ forward connected pairs $\{x_i,y_i\}$ (in either
direction).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-10T00:30:00Z">Monday, April 10 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Sunday, April 09
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/044'>TR23-044 |  Separations between Combinatorial Measures for Transitive Functions | 

	Sourav Chakraborty, 

	Chandrima Kayal, 

	Manaswi Paraashar</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          The role of symmetry in Boolean functions $f:\{0,1\}^n \to \{0,1\}$ has been extensively studied in complexity theory. 
For example, symmetric functions, that is, functions that are invariant under the action of $S_n$ is an important class of functions in the study of Boolean functions.
A function $f:\{0,1\}^n \to \{0,1\}$ is called transitive (or weakly-symmetric) if there exists a transitive group $G$ of $S_n$ such that $f$ is invariant under the action of $G$. In other words, the value of a transitive function remains unchanged even after the input bits of $f$ are moved around according to some permutation $\sigma \in G$. Understanding various complexity measures of transitive functions has been a rich area of research for the past few decades.



In this work, we study transitive functions in light of several combinatorial measures. The question that we try to address in this paper is what is the maximum separations between various pairs of combinatorial measures for transitive functions. Such study for general Boolean functions has been going on for the past many years. The current best-known results for general Boolean functions have been nicely compiled by Aaronson et~al.~(STOC, 2021). But before this paper, no such systematic study has been done for the case of transitive functions. 

 
The separation between a pair of combinatorial measures is shown by constructing interesting functions that demonstrate the separation. Over the past three decades, various interesting classes of functions have been designed for this purpose. In this context, one of the celebrated classes of functions is the class of ``pointer functions&#39;&#39;.
Ambainis et al.~(JACM, 2017) constructed several functions, which are modifications of the pointer function, first introduced in G{\&quot;{o}}{\&quot;{o}}s et~al.~(SICOMP, 2018 / FOCS, 2015), to demonstrate separation between various pairs of measures. In the last few years, pointer functions have been used to show separation between  various other pairs of measures (for example, Mukhopadhyay et~al.~(FSTTCS, 2015), Ben-David et~al.~(ITCS, 2017), G{\&quot;{o}}{\&quot;{o}}s et~al.~(ToCT, 2018 / ICALP, 2017)).  

However, the pointer functions themselves are not transitive. 
Based on the various kinds of pointer functions, we construct new transitive functions whose deterministic query complexity, randomized query complexity, zero-error randomized query complexity, quantum query complexity, degree, and approximate degree are similar to that of the original pointer functions. Thus we demonstrate that even for transitive functions similar separations between pairs of combinatorial measures can be achieved.  

Our constructions of transitive functions depend crucially on construction of particular classes of transitive groups, whose actions, though involved, helps to preserve certain structural features of the input strings.  The transitive groups we construct may be of independent interest in other areas of mathematics and theoretical computer science. 

We summarize the current knowledge of relations between various combinatorial measures of transitive functions in a table similar to the table compiled by Aaronson et~al.~(STOC, 2021) for general functions.
        
        </div>

        <div class='tr-article-summary'>
        
          
          The role of symmetry in Boolean functions $f:\{0,1\}^n \to \{0,1\}$ has been extensively studied in complexity theory. 
For example, symmetric functions, that is, functions that are invariant under the action of $S_n$ is an important class of functions in the study of Boolean functions.
A function $f:\{0,1\}^n \to \{0,1\}$ is called transitive (or weakly-symmetric) if there exists a transitive group $G$ of $S_n$ such that $f$ is invariant under the action of $G$. In other words, the value of a transitive function remains unchanged even after the input bits of $f$ are moved around according to some permutation $\sigma \in G$. Understanding various complexity measures of transitive functions has been a rich area of research for the past few decades.



In this work, we study transitive functions in light of several combinatorial measures. The question that we try to address in this paper is what is the maximum separations between various pairs of combinatorial measures for transitive functions. Such study for general Boolean functions has been going on for the past many years. The current best-known results for general Boolean functions have been nicely compiled by Aaronson et~al.~(STOC, 2021). But before this paper, no such systematic study has been done for the case of transitive functions. 

 
The separation between a pair of combinatorial measures is shown by constructing interesting functions that demonstrate the separation. Over the past three decades, various interesting classes of functions have been designed for this purpose. In this context, one of the celebrated classes of functions is the class of ``pointer functions&#39;&#39;.
Ambainis et al.~(JACM, 2017) constructed several functions, which are modifications of the pointer function, first introduced in G{\&quot;{o}}{\&quot;{o}}s et~al.~(SICOMP, 2018 / FOCS, 2015), to demonstrate separation between various pairs of measures. In the last few years, pointer functions have been used to show separation between  various other pairs of measures (for example, Mukhopadhyay et~al.~(FSTTCS, 2015), Ben-David et~al.~(ITCS, 2017), G{\&quot;{o}}{\&quot;{o}}s et~al.~(ToCT, 2018 / ICALP, 2017)).  

However, the pointer functions themselves are not transitive. 
Based on the various kinds of pointer functions, we construct new transitive functions whose deterministic query complexity, randomized query complexity, zero-error randomized query complexity, quantum query complexity, degree, and approximate degree are similar to that of the original pointer functions. Thus we demonstrate that even for transitive functions similar separations between pairs of combinatorial measures can be achieved.  

Our constructions of transitive functions depend crucially on construction of particular classes of transitive groups, whose actions, though involved, helps to preserve certain structural features of the input strings.  The transitive groups we construct may be of independent interest in other areas of mathematics and theoretical computer science. 

We summarize the current knowledge of relations between various combinatorial measures of transitive functions in a table similar to the table compiled by Aaronson et~al.~(STOC, 2021) for general functions.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-09T11:26:00Z">Sunday, April 09 2023, 11:26</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://eccc.weizmann.ac.il/report/2023/043'>TR23-043 |  Coboundary and cosystolic expansion without dependence on dimension or degree | 

	Yotam Dikstein, 

	Irit Dinur</a></h3>
        <p class='tr-article-feed'>from <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          We give new bounds on the cosystolic expansion constants of several families of high dimensional expanders, and the known coboundary expansion constants of order complexes of homogeneous geometric lattices, including the spherical building of $SL_n(F_q)$. The improvement applies to the high dimensional expanders constructed by Lubotzky, Samuels and Vishne, and by Kaufman and Oppenheim.

Our new expansion constants do not depend on the degree of the complex nor on its dimension, nor on the group of coefficients. This implies improved bounds on Gromov’s topological overlap constant, and on Dinur and Meshulam’s cover stability, which may have applications for agreement testing. In comparison, existing bounds decay exponentially with the ambient dimension (for spherical buildings) and in addition decay linearly with the degree (for all known bounded-degree high dimensional expanders).

Our results are based on several new techniques:

– We develop a new “color-restriction” technique which enables proving dimension-free expansion by restricting a multi-partite complex to small random subsets of its color classes.

– We give a new “spectral” proof for Evra and Kaufman’s local-to-global theorem, deriving better bounds and getting rid of the dependence on the degree. This theorem bounds the cosystolic expansion of a complex using coboundary expansion and spectral expansion of the links.

– We derive absolute bounds on the coboundary expansion of the spherical building (and any order complex of a homogeneous geometric lattice) by constructing a novel family of very short cones.
        
        </div>

        <div class='tr-article-summary'>
        
          
          We give new bounds on the cosystolic expansion constants of several families of high dimensional expanders, and the known coboundary expansion constants of order complexes of homogeneous geometric lattices, including the spherical building of $SL_n(F_q)$. The improvement applies to the high dimensional expanders constructed by Lubotzky, Samuels and Vishne, and by Kaufman and Oppenheim.

Our new expansion constants do not depend on the degree of the complex nor on its dimension, nor on the group of coefficients. This implies improved bounds on Gromov’s topological overlap constant, and on Dinur and Meshulam’s cover stability, which may have applications for agreement testing. In comparison, existing bounds decay exponentially with the ambient dimension (for spherical buildings) and in addition decay linearly with the degree (for all known bounded-degree high dimensional expanders).

Our results are based on several new techniques:

– We develop a new “color-restriction” technique which enables proving dimension-free expansion by restricting a multi-partite complex to small random subsets of its color classes.

– We give a new “spectral” proof for Evra and Kaufman’s local-to-global theorem, deriving better bounds and getting rid of the dependence on the degree. This theorem bounds the cosystolic expansion of a complex using coboundary expansion and spectral expansion of the links.

– We derive absolute bounds on the coboundary expansion of the spherical building (and any order complex of a homogeneous geometric lattice) by constructing a novel family of very short cones.
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-09T06:09:10Z">Sunday, April 09 2023, 06:09</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://decentralizedthoughts.github.io/2023-04-09-blockchainsplustees-day1-summary/'>Blockchains + TEEs Day 1 Summary</a></h3>
        <p class='tr-article-feed'>from <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          Our workshop on Blockchains + TEEs concluded last week. We had a fantastic series of talks and discussions on both days of the workshop. In this two part post, we highlight some key takeaways from each of the days. Natacha Crooks: In Trusted BFT Components, we (Mostly?) Trust In her...
        
        </div>

        <div class='tr-article-summary'>
        
          
          Our workshop on Blockchains + TEEs concluded last week. We had a fantastic series of talks and discussions on both days of the workshop. In this two part post, we highlight some key takeaways from each of the days. Natacha Crooks: In Trusted BFT Components, we (Mostly?) Trust In her...
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-09T05:00:00Z">Sunday, April 09 2023, 05:00</time>
        </div>
      </div>
    </details>
  
    
    <h2 class='tr-new-date'>
      <i class='fa-regular fa-calendar'></i> Friday, April 07
    </h2>
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='https://ptreview.sublinear.info/2023/04/news-for-march-2023/'>News for March 2023</a></h3>
        <p class='tr-article-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          I never thought this day would come. For the first time in PTReview history, there is no paper to report. Nada. Zilch. The calm before the storm&#8230;?
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p>I never thought this day would come.</p>



<p>For the first time in PTReview history, there is no paper to report. Nada. Zilch.</p>



<p>The calm before the storm&#8230;?</p>
<p class="authors">By Seshadhri</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T16:45:00Z">Friday, April 07 2023, 16:45</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02770'>Tight Correlation Bounds for Circuits Between AC0 and TC0</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Vinayak M. Kumar</p><p>We initiate the study of generalized AC0 circuits comprised of negations and
arbitrary unbounded fan-in gates that only need to be constant over inputs of
Hamming weight $\ge k$, which we denote GC0$(k)$. The gate set of this class
includes biased LTFs like the $k$-$OR$ (output $1$ iff $\ge k$ bits are 1) and
$k$-$AND$ (output $0$ iff $\ge k$ bits are 0), and thus can be seen as an
interpolation between AC0 and TC0. We establish a tight multi-switching lemma
for GC0$(k)$ circuits, which bounds the probability that several depth-2
GC0$(k)$ circuits do not simultaneously simplify under a random restriction. We
also establish a new depth reduction lemma such that coupled with our
multi-switching lemma, we can show many results obtained from the
multi-switching lemma for depth-$d$ size-$s$ AC0 circuits lifts to depth-$d$
size-$s^{.99}$ GC0$(.01\log s)$ circuits with no loss in parameters (other than
hidden constants). Our result has the following applications:
</p>
<p>1.Size-$2^{\Omega(n^{1/d})}$ depth-$d$ GC0$(\Omega(n^{1/d}))$ circuits do not
correlate with parity (extending a result of H{\aa}stad (SICOMP, 2014)).
</p>
<p>2. Size-$n^{\Omega(\log n)}$ GC0$(\Omega(\log^2 n))$ circuits with $n^{.249}$
arbitrary threshold gates or $n^{.499}$ arbitrary symmetric gates exhibit
exponentially small correlation against an explicit function (extending a
result of Tan and Servedio (RANDOM, 2019)).
</p>
<p>3. There is a seed length $O((\log m)^{d-1}\log(m/\varepsilon)\log\log(m))$
pseudorandom generator against size-$m$ depth-$d$ GC0$(\log m)$ circuits,
matching the AC0 lower bound of H{\aa}stad stad up to a $\log\log m$ factor
(extending a result of Lyu (CCC, 2022)).
</p>
<p>4. Size-$m$ GC0$(\log m)$ circuits have exponentially small Fourier tails
(extending a result of Tal (CCC, 2017)).
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vinayak M. Kumar</a></p><p>We initiate the study of generalized AC0 circuits comprised of negations and
arbitrary unbounded fan-in gates that only need to be constant over inputs of
Hamming weight $\ge k$, which we denote GC0$(k)$. The gate set of this class
includes biased LTFs like the $k$-$OR$ (output $1$ iff $\ge k$ bits are 1) and
$k$-$AND$ (output $0$ iff $\ge k$ bits are 0), and thus can be seen as an
interpolation between AC0 and TC0. We establish a tight multi-switching lemma
for GC0$(k)$ circuits, which bounds the probability that several depth-2
GC0$(k)$ circuits do not simultaneously simplify under a random restriction. We
also establish a new depth reduction lemma such that coupled with our
multi-switching lemma, we can show many results obtained from the
multi-switching lemma for depth-$d$ size-$s$ AC0 circuits lifts to depth-$d$
size-$s^{.99}$ GC0$(.01\log s)$ circuits with no loss in parameters (other than
hidden constants). Our result has the following applications:
</p>
<p>1.Size-$2^{\Omega(n^{1/d})}$ depth-$d$ GC0$(\Omega(n^{1/d}))$ circuits do not
correlate with parity (extending a result of H{\aa}stad (SICOMP, 2014)).
</p>
<p>2. Size-$n^{\Omega(\log n)}$ GC0$(\Omega(\log^2 n))$ circuits with $n^{.249}$
arbitrary threshold gates or $n^{.499}$ arbitrary symmetric gates exhibit
exponentially small correlation against an explicit function (extending a
result of Tan and Servedio (RANDOM, 2019)).
</p>
<p>3. There is a seed length $O((\log m)^{d-1}\log(m/\varepsilon)\log\log(m))$
pseudorandom generator against size-$m$ depth-$d$ GC0$(\log m)$ circuits,
matching the AC0 lower bound of H{\aa}stad stad up to a $\log\log m$ factor
(extending a result of Lyu (CCC, 2022)).
</p>
<p>4. Size-$m$ GC0$(\log m)$ circuits have exponentially small Fourier tails
(extending a result of Tal (CCC, 2017)).
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T00:30:00Z">Friday, April 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02781'>Inapproximability of sufficient reasons for decision trees</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Alexander Kozachinskiy</p><p>In this note, we establish the hardness of approximation of the problem of
computing the minimal size of a $\delta$-sufficient reason for decision trees.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kozachinskiy_A/0/1/0/all/0/1">Alexander Kozachinskiy</a></p><p>In this note, we establish the hardness of approximation of the problem of
computing the minimal size of a $\delta$-sufficient reason for decision trees.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T00:30:00Z">Friday, April 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02943'>Improved Hardness of Approximating k-Clique under ETH</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Bingkai Lin, Xuandi Ren, Yican Sun, Xiuhan Wang</p><p>In this paper, we prove that assuming the exponential time hypothesis (ETH),
there is no $f(k)\cdot n^{k^{o(1/\log\log k)}}$-time algorithm that can decide
whether an $n$-vertex graph contains a clique of size $k$ or contains no clique
of size $k/2$, and no FPT algorithm can decide whether an input graph has a
clique of size $k$ or no clique of size $k/f(k)$, where $f(k)$ is some function
in $k^{1-o(1)}$. Our results significantly improve the previous works [Lin21,
LRSW22]. The crux of our proof is a framework to construct gap-producing
reductions for the \kclique{} problem. More precisely, we show that given an
error-correcting code $C:\Sigma_1^k\to\Sigma_2^{k'}$ that is locally testable
and smooth locally decodable in the parallel setting, one can construct a
reduction which on input a graph $G$ outputs a graph $G'$ in $(k')^{O(1)}\cdot
n^{O(\log|\Sigma_2|/\log|\Sigma_1|)}$ time such that:
</p>
<p>$\bullet$ If $G$ has a clique of size $k$, then $G'$ has a clique of size
$K$, where $K = (k')^{O(1)}$.
</p>
<p>$\bullet$ If $G$ has no clique of size $k$, then $G'$ has no clique of size
$(1-\varepsilon)\cdot K$ for some constant $\varepsilon\in(0,1)$.
</p>
<p>We then construct such a code with $k'=k^{\Theta(\log\log k)}$ and
$|\Sigma_2|=|\Sigma_1|^{k^{0.54}}$, establishing the hardness results above.
Our code generalizes the derivative code [WY07] into the case with a super
constant order of derivatives.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Bingkai Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xuandi Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yican Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiuhan Wang</a></p><p>In this paper, we prove that assuming the exponential time hypothesis (ETH),
there is no $f(k)\cdot n^{k^{o(1/\log\log k)}}$-time algorithm that can decide
whether an $n$-vertex graph contains a clique of size $k$ or contains no clique
of size $k/2$, and no FPT algorithm can decide whether an input graph has a
clique of size $k$ or no clique of size $k/f(k)$, where $f(k)$ is some function
in $k^{1-o(1)}$. Our results significantly improve the previous works [Lin21,
LRSW22]. The crux of our proof is a framework to construct gap-producing
reductions for the \kclique{} problem. More precisely, we show that given an
error-correcting code $C:\Sigma_1^k\to\Sigma_2^{k'}$ that is locally testable
and smooth locally decodable in the parallel setting, one can construct a
reduction which on input a graph $G$ outputs a graph $G'$ in $(k')^{O(1)}\cdot
n^{O(\log|\Sigma_2|/\log|\Sigma_1|)}$ time such that:
</p>
<p>$\bullet$ If $G$ has a clique of size $k$, then $G'$ has a clique of size
$K$, where $K = (k')^{O(1)}$.
</p>
<p>$\bullet$ If $G$ has no clique of size $k$, then $G'$ has no clique of size
$(1-\varepsilon)\cdot K$ for some constant $\varepsilon\in(0,1)$.
</p>
<p>We then construct such a code with $k'=k^{\Theta(\log\log k)}$ and
$|\Sigma_2|=|\Sigma_1|^{k^{0.54}}$, establishing the hardness results above.
Our code generalizes the derivative code [WY07] into the case with a super
constant order of derivatives.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T00:30:00Z">Friday, April 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03256'>The complexity of decomposing a graph into a matching and a bounded linear forest</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Agnijo Banerjee, Jo&#xe3;o Pedro Marciano, Adva Mond, Jan Petr, Julien Portier</p><p>Deciding whether a graph can be edge-decomposed into a matching and a
$k$-bounded linear forest was recently shown by Campbell, H{\"o}rsch and Moore
to be NP-complete for every $k \ge 9$, and solvable in polynomial time for
$k=1,2$. In the first part of this paper, we close this gap by showing that
this problem is in NP-complete for every $k \ge 3$. In the second part of the
paper, we show that deciding whether a graph can be edge-decomposed into a
matching and a $k$-bounded star forest is polynomially solvable for any $k \in
\mathbb{N} \cup \{ \infty \}$, answering another question by Campbell,
H{\"o}rsch and Moore from the same paper.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1">Agnijo Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Marciano_J/0/1/0/all/0/1">Jo&#xe3;o Pedro Marciano</a>, <a href="http://arxiv.org/find/cs/1/au:+Mond_A/0/1/0/all/0/1">Adva Mond</a>, <a href="http://arxiv.org/find/cs/1/au:+Petr_J/0/1/0/all/0/1">Jan Petr</a>, <a href="http://arxiv.org/find/cs/1/au:+Portier_J/0/1/0/all/0/1">Julien Portier</a></p><p>Deciding whether a graph can be edge-decomposed into a matching and a
$k$-bounded linear forest was recently shown by Campbell, H{\"o}rsch and Moore
to be NP-complete for every $k \ge 9$, and solvable in polynomial time for
$k=1,2$. In the first part of this paper, we close this gap by showing that
this problem is in NP-complete for every $k \ge 3$. In the second part of the
paper, we show that deciding whether a graph can be edge-decomposed into a
matching and a $k$-bounded star forest is polynomially solvable for any $k \in
\mathbb{N} \cup \{ \infty \}$, answering another question by Campbell,
H{\"o}rsch and Moore from the same paper.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T00:30:00Z">Friday, April 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02745'>Software and Analysis for Dynamic Voronoi Diagrams in the Hilbert Metric</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Madeline Bumpus, Caesar Dai, Auguste H. Gezalyan, Sam Munoz, Renita Santhoshkumar, Songyu Ye, David M. Mount</p><p>The Hilbert metric is a projective metric defined on a convex body which
generalizes the Cayley-Klein model of hyperbolic geometry to any convex set. In
this paper we analyze Hilbert Voronoi diagrams in the Dynamic setting. In
addition we introduce dynamic visualization software for Voronoi diagrams in
the Hilbert metric on user specified convex polygons.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Bumpus_M/0/1/0/all/0/1">Madeline Bumpus</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_C/0/1/0/all/0/1">Caesar Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Gezalyan_A/0/1/0/all/0/1">Auguste H. Gezalyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Munoz_S/0/1/0/all/0/1">Sam Munoz</a>, <a href="http://arxiv.org/find/cs/1/au:+Santhoshkumar_R/0/1/0/all/0/1">Renita Santhoshkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1">Songyu Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Mount_D/0/1/0/all/0/1">David M. Mount</a></p><p>The Hilbert metric is a projective metric defined on a convex body which
generalizes the Cayley-Klein model of hyperbolic geometry to any convex set. In
this paper we analyze Hilbert Voronoi diagrams in the Dynamic setting. In
addition we introduce dynamic visualization software for Voronoi diagrams in
the Hilbert metric on user specified convex polygons.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T00:30:00Z">Friday, April 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02657'>Fast computation of approximate weak common intervals in multiple indeterminate strings</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Daniel Doerr, Bernard M.E. Moret</p><p>In ongoing work to define a principled method for syntenic block discovery
and structuring, work based on homology-derived constraints and a
generalization of common intervals, we faced a fundamental computational
problem: how to determine quickly, among a set of indeterminate strings
(strings whose elements consist of subsets of characters), contiguous intervals
that would share a vast majority of their elements, but allow for sharing
subsets of characters subsumed by others, and also for certain elements to be
missing from certain genomes. An algorithm for this problem in the special case
of determinate strings (where each element is a single character of the
alphabet, i.e., "normal" strings) was described by Doerr et al., but its
running time would explode if generalized to indeterminate strings. In this
paper, we describe an algorithm for computing these special common intervals in
time close to that of the simpler algorithm of Doerr et al. and show that can
compute these intervals in just a couple of hours for large collections (tens
to hundreds) of bacterial genomes.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Doerr_D/0/1/0/all/0/1">Daniel Doerr</a>, <a href="http://arxiv.org/find/cs/1/au:+Moret_B/0/1/0/all/0/1">Bernard M.E. Moret</a></p><p>In ongoing work to define a principled method for syntenic block discovery
and structuring, work based on homology-derived constraints and a
generalization of common intervals, we faced a fundamental computational
problem: how to determine quickly, among a set of indeterminate strings
(strings whose elements consist of subsets of characters), contiguous intervals
that would share a vast majority of their elements, but allow for sharing
subsets of characters subsumed by others, and also for certain elements to be
missing from certain genomes. An algorithm for this problem in the special case
of determinate strings (where each element is a single character of the
alphabet, i.e., "normal" strings) was described by Doerr et al., but its
running time would explode if generalized to indeterminate strings. In this
paper, we describe an algorithm for computing these special common intervals in
time close to that of the simpler algorithm of Doerr et al. and show that can
compute these intervals in just a couple of hours for large collections (tens
to hundreds) of bacterial genomes.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T00:30:00Z">Friday, April 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02700'>Agnostic proper learning of monotone functions: beyond the black-box correction barrier</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Jane Lange, Arsen Vasilyan</p><p>We give the first agnostic, efficient, proper learning algorithm for monotone
Boolean functions. Given $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$ uniformly random
examples of an unknown function $f:\{\pm 1\}^n \rightarrow \{\pm 1\}$, our
algorithm outputs a hypothesis $g:\{\pm 1\}^n \rightarrow \{\pm 1\}$ that is
monotone and $(\mathrm{opt} + \varepsilon)$-close to $f$, where $\mathrm{opt}$
is the distance from $f$ to the closest monotone function. The running time of
the algorithm (and consequently the size and evaluation time of the hypothesis)
is also $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$, nearly matching the lower bound
of Blais et al (RANDOM '15). We also give an algorithm for estimating up to
additive error $\varepsilon$ the distance of an unknown function $f$ to
monotone using a run-time of $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$. Previously,
for both of these problems, sample-efficient algorithms were known, but these
algorithms were not run-time efficient. Our work thus closes this gap in our
knowledge between the run-time and sample complexity.
</p>
<p>This work builds upon the improper learning algorithm of Bshouty and Tamon
(JACM '96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld,
and Vasilyan (FOCS '22), which obtains a non-monotone Boolean-valued
hypothesis, then ``corrects'' it to monotone using query-efficient local
computation algorithms on graphs. This black-box correction approach can
achieve no error better than $2\mathrm{opt} + \varepsilon$
information-theoretically; we bypass this barrier by
</p>
<p>a) augmenting the improper learner with a convex optimization step, and
</p>
<p>b) learning and correcting a real-valued function before rounding its values
to Boolean.
</p>
<p>Our real-valued correction algorithm solves the ``poset sorting'' problem of
[LRV22] for functions over general posets with non-Boolean labels.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Lange_J/0/1/0/all/0/1">Jane Lange</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasilyan_A/0/1/0/all/0/1">Arsen Vasilyan</a></p><p>We give the first agnostic, efficient, proper learning algorithm for monotone
Boolean functions. Given $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$ uniformly random
examples of an unknown function $f:\{\pm 1\}^n \rightarrow \{\pm 1\}$, our
algorithm outputs a hypothesis $g:\{\pm 1\}^n \rightarrow \{\pm 1\}$ that is
monotone and $(\mathrm{opt} + \varepsilon)$-close to $f$, where $\mathrm{opt}$
is the distance from $f$ to the closest monotone function. The running time of
the algorithm (and consequently the size and evaluation time of the hypothesis)
is also $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$, nearly matching the lower bound
of Blais et al (RANDOM '15). We also give an algorithm for estimating up to
additive error $\varepsilon$ the distance of an unknown function $f$ to
monotone using a run-time of $2^{\tilde{O}(\sqrt{n}/\varepsilon)}$. Previously,
for both of these problems, sample-efficient algorithms were known, but these
algorithms were not run-time efficient. Our work thus closes this gap in our
knowledge between the run-time and sample complexity.
</p>
<p>This work builds upon the improper learning algorithm of Bshouty and Tamon
(JACM '96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld,
and Vasilyan (FOCS '22), which obtains a non-monotone Boolean-valued
hypothesis, then ``corrects'' it to monotone using query-efficient local
computation algorithms on graphs. This black-box correction approach can
achieve no error better than $2\mathrm{opt} + \varepsilon$
information-theoretically; we bypass this barrier by
</p>
<p>a) augmenting the improper learner with a convex optimization step, and
</p>
<p>b) learning and correcting a real-valued function before rounding its values
to Boolean.
</p>
<p>Our real-valued correction algorithm solves the ``poset sorting'' problem of
[LRV22] for functions over general posets with non-Boolean labels.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T00:30:00Z">Friday, April 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.02897'>LSketch: A Label-Enabled Graph Stream Sketch Toward Time-Sensitive Queries</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Yiling Zeng, Chunyao Song, Yuhan Li, Tingjian Ge</p><p>Graph streams represent data interactions in real applications. The mining of
graph streams plays an important role in network security, social network
analysis, and traffic control, among others. However, the sheer volume and high
dynamics cause great challenges for efficient storage and subsequent query
analysis on them. Current studies apply sketches to summarize graph streams. We
propose LSketch that works for heterogeneous graph streams, which effectively
preserves the label information carried by the streams in real scenes, thereby
enriching the expressive ability of sketches. In addition, as graph streams
continue to evolve over time, edges too old may lose their practical
significance. Therefore, we introduce the sliding window model into LSketch to
eliminate the expired edges automatically. LSketch uses sub-linear storage
space and can support structure based queries and time-sensitive queries with
high accuracy. We perform extensive experiments over four real datasets,
demonstrating the superiority of the proposed method over state-of-the-art
methods, in aspects of query accuracy and time efficiency.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yiling Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chunyao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1">Tingjian Ge</a></p><p>Graph streams represent data interactions in real applications. The mining of
graph streams plays an important role in network security, social network
analysis, and traffic control, among others. However, the sheer volume and high
dynamics cause great challenges for efficient storage and subsequent query
analysis on them. Current studies apply sketches to summarize graph streams. We
propose LSketch that works for heterogeneous graph streams, which effectively
preserves the label information carried by the streams in real scenes, thereby
enriching the expressive ability of sketches. In addition, as graph streams
continue to evolve over time, edges too old may lose their practical
significance. Therefore, we introduce the sliding window model into LSketch to
eliminate the expired edges automatically. LSketch uses sub-linear storage
space and can support structure based queries and time-sensitive queries with
high accuracy. We perform extensive experiments over four real datasets,
demonstrating the superiority of the proposed method over state-of-the-art
methods, in aspects of query accuracy and time efficiency.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T00:30:00Z">Friday, April 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03146'>Parameterized Approximation Schemes for Clustering with General Norm Objectives</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Fateme Abbasi, Sandip Banerjee, Jaros&#x142;aw Byrka, Parinya Chalermsook, Ameet Gadekar, Kamyar Khodamoradi, D&#xe1;niel Marx, Roohani Sharma, Joachim Spoerhase</p><p>This paper considers the well-studied algorithmic regime of designing a
$(1+\epsilon)$-approximation algorithm for a $k$-clustering problem that runs
in time $f(k,\epsilon)poly(n)$ (sometimes called an efficient parameterized
approximation scheme or EPAS for short). Notable results of this kind include
EPASes in the high-dimensional Euclidean setting for $k$-center [Bad\u{o}iu,
Har-Peled, Indyk; STOC'02] as well as $k$-median, and $k$-means [Kumar,
Sabharwal, Sen; J. ACM 2010]. However, existing EPASes handle only basic
objectives (such as $k$-center, $k$-median, and $k$-means) and are tailored to
the specific objective and metric space.
</p>
<p>Our main contribution is a clean and simple EPAS that settles more than ten
clustering problems (across multiple well-studied objectives as well as metric
spaces) and unifies well-known EPASes. Our algorithm gives EPASes for a large
variety of clustering objectives (for example, $k$-means, $k$-center,
$k$-median, priority $k$-center, $\ell$-centrum, ordered $k$-median, socially
fair $k$-median aka robust $k$-median, or more generally monotone norm
$k$-clustering) and metric spaces (for example, continuous high-dimensional
Euclidean spaces, metrics of bounded doubling dimension, bounded treewidth
metrics, and planar metrics).
</p>
<p>Key to our approach is a new concept that we call bounded $\epsilon$-scatter
dimension--an intrinsic complexity measure of a metric space that is a
relaxation of the standard notion of bounded doubling dimension. Our main
technical result shows that two conditions are essentially sufficient for our
algorithm to yield an EPAS on the input metric $M$ for any clustering
objective: (i) The objective is described by a monotone (not necessarily
symmetric!) norm, and (ii) the $\epsilon$-scatter dimension of $M$ is upper
bounded by a function of $\epsilon$.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Abbasi_F/0/1/0/all/0/1">Fateme Abbasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Sandip Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Byrka_J/0/1/0/all/0/1">Jaros&#x142;aw Byrka</a>, <a href="http://arxiv.org/find/cs/1/au:+Chalermsook_P/0/1/0/all/0/1">Parinya Chalermsook</a>, <a href="http://arxiv.org/find/cs/1/au:+Gadekar_A/0/1/0/all/0/1">Ameet Gadekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Khodamoradi_K/0/1/0/all/0/1">Kamyar Khodamoradi</a>, <a href="http://arxiv.org/find/cs/1/au:+Marx_D/0/1/0/all/0/1">D&#xe1;niel Marx</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Roohani Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Spoerhase_J/0/1/0/all/0/1">Joachim Spoerhase</a></p><p>This paper considers the well-studied algorithmic regime of designing a
$(1+\epsilon)$-approximation algorithm for a $k$-clustering problem that runs
in time $f(k,\epsilon)poly(n)$ (sometimes called an efficient parameterized
approximation scheme or EPAS for short). Notable results of this kind include
EPASes in the high-dimensional Euclidean setting for $k$-center [Bad\u{o}iu,
Har-Peled, Indyk; STOC'02] as well as $k$-median, and $k$-means [Kumar,
Sabharwal, Sen; J. ACM 2010]. However, existing EPASes handle only basic
objectives (such as $k$-center, $k$-median, and $k$-means) and are tailored to
the specific objective and metric space.
</p>
<p>Our main contribution is a clean and simple EPAS that settles more than ten
clustering problems (across multiple well-studied objectives as well as metric
spaces) and unifies well-known EPASes. Our algorithm gives EPASes for a large
variety of clustering objectives (for example, $k$-means, $k$-center,
$k$-median, priority $k$-center, $\ell$-centrum, ordered $k$-median, socially
fair $k$-median aka robust $k$-median, or more generally monotone norm
$k$-clustering) and metric spaces (for example, continuous high-dimensional
Euclidean spaces, metrics of bounded doubling dimension, bounded treewidth
metrics, and planar metrics).
</p>
<p>Key to our approach is a new concept that we call bounded $\epsilon$-scatter
dimension--an intrinsic complexity measure of a metric space that is a
relaxation of the standard notion of bounded doubling dimension. Our main
technical result shows that two conditions are essentially sufficient for our
algorithm to yield an EPAS on the input metric $M$ for any clustering
objective: (i) The objective is described by a monotone (not necessarily
symmetric!) norm, and (ii) the $\epsilon$-scatter dimension of $M$ is upper
bounded by a function of $\epsilon$.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T00:30:00Z">Friday, April 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
    

    <details class='tr-article' open>
      <summary class='tr-article-header'>
        <h3 class='tr-article-title'><a href='http://arxiv.org/abs/2304.03170'>Spectral Toolkit of Algorithms for Graphs: Technical Report (1)</a></h3>
        <p class='tr-article-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        <i class="fa-solid fa-fw fa-chevron-down tr-chevron"></i>
      </summary>

      <i class="fa-solid fa-fw fa-chevron-up tr-chevron"></i>

      <div class='tr-article-body'>
        <div class='tr-article-snippet'>
        
          <p>Authors: Peter Macgregor, He Sun</p><p>Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source library
for efficient spectral graph algorithms, and its development starts in
September 2022. We have so far finished the component on local graph
clustering, and this technical report presents a user's guide to STAG, showcase
studies, and several technical considerations behind our development.
</p>
        
        </div>

        <div class='tr-article-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Macgregor_P/0/1/0/all/0/1">Peter Macgregor</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">He Sun</a></p><p>Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source library
for efficient spectral graph algorithms, and its development starts in
September 2022. We have so far finished the component on local graph
clustering, and this technical report presents a user's guide to STAG, showcase
studies, and several technical considerations behind our development.
</p>
        
        </div>

        <div class='tr-article-footer'>
          <time class='timeago' datetime="2023-04-07T00:30:00Z">Friday, April 07 2023, 00:30</time>
        </div>
      </div>
    </details>
  
  </div>

  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js' type="text/javascript"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-timeago/1.6.7/jquery.timeago.min.js" type="text/javascript"></script>
  <script src='js/theory.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
