<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0RQ5M78VX5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0RQ5M78VX5');
  </script>
  <meta charset='utf-8'>
  <meta name='generator' content='Pluto 1.6.2 on Ruby 3.0.4 (2022-04-12) [x86_64-linux]'>

  <title>Theory of Computing Report</title>

  <link rel="alternate" type="application/rss+xml" title="Posts (RSS)" href="rss20.xml" />
  <link rel="alternate" type="application/atom+xml" title="Posts (Atom)" href="atom.xml" />
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel='stylesheet' type='text/css' href='css/font-awesome.css'>
  <link rel='stylesheet' type='text/css' href='css/blank.css'>
</head>
<body>
  <div id='navwrap'>
    <div id='nav'>
      <p>
        Last Update
      </p>
      <p class='small'>
        
          <time class='timeago' datetime="2022-10-13T01:52:10Z">Thursday, October 13 2022, 01:52</time>
        
      </p>

      <p>Feeds</p>
      <ul class='subscriptions small' >
      
        <li>
          <a href='http://arxiv.org/rss/cs.CC'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.CG'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a>
          
        </li>
      
        <li>
          <a href='http://arxiv.org/rss/cs.DS'><img src='i/feed.png'></a>
          <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a>
          
        </li>
      
        <li>
          <a href='http://aaronsadventures.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://aaronsadventures.blogspot.com/'>Aaron Roth</a>
          
        </li>
      
        <li>
          <a href='https://adamsheffer.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamsheffer.wordpress.com'>Adam Sheffer</a>
          
        </li>
      
        <li>
          <a href='https://adamdsmith.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://adamdsmith.wordpress.com'>Adam Smith</a>
          
        </li>
      
        <li>
          <a href='https://polylogblog.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://polylogblog.wordpress.com'>Andrew McGregor</a>
          
        </li>
      
        <li>
          <a href='https://corner.mimuw.edu.pl/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://corner.mimuw.edu.pl'>Banach's Algorithmic Corner</a>
          
        </li>
      
        <li>
          <a href='http://www.argmin.net/feed.xml'><img src='i/feed.png'></a>
          <a href='http://benjamin-recht.github.io/'>Ben Recht</a>
          
        </li>
      
        <li>
          <a href='http://bit-player.org/feed/atom/'><img src='i/feed.png'></a>
          <a href='http://bit-player.org'>bit-player</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-jobs.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-jobs.org'>CCI: jobs</a>
          
        </li>
      
        <li>
          <a href='https://cstheory-events.org/feed/'><img src='i/feed.png'></a>
          <a href='https://cstheory-events.org'>CS Theory Events</a>
          
        </li>
      
        <li>
          <a href='http://blog.computationalcomplexity.org/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a>
          
        </li>
      
        <li>
          <a href='https://11011110.github.io/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='https://11011110.github.io/blog/'>David Eppstein</a>
          
        </li>
      
        <li>
          <a href='https://daveagp.wordpress.com/category/toc/feed/'><img src='i/feed.png'></a>
          <a href='https://daveagp.wordpress.com'>David Pritchard</a>
          
        </li>
      
        <li>
          <a href='https://decentdescent.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://decentdescent.org/'>Decent Descent</a>
          
        </li>
      
        <li>
          <a href='https://decentralizedthoughts.github.io/feed'><img src='i/feed.png'></a>
          <a href='https://decentralizedthoughts.github.io'>Decentralized Thoughts</a>
          
        </li>
      
        <li>
          <a href='https://differentialprivacy.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://differentialprivacy.org'>DifferentialPrivacy.org</a>
          
        </li>
      
        <li>
          <a href='https://eccc.weizmann.ac.il//feeds/reports/'><img src='i/feed.png'></a>
          <a href='https://eccc.weizmann.ac.il/'>ECCC Papers</a>
          
        </li>
      
        <li>
          <a href='https://emanueleviola.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://emanueleviola.wordpress.com'>Emanuele Viola</a>
          
        </li>
      
        <li>
          <a href='https://3dpancakes.typepad.com/ernie/atom.xml'><img src='i/feed.png'></a>
          <a href='https://3dpancakes.typepad.com/ernie/'>Ernie's 3D Pancakes</a>
          
        </li>
      
        <li>
          <a href='https://dstheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://dstheory.wordpress.com'>Foundation of Data Science - Virtual Talk Series</a>
          
        </li>
      
        <li>
          <a href='https://francisbach.com/feed/'><img src='i/feed.png'></a>
          <a href='https://francisbach.com'>Francis Bach</a>
          
        </li>
      
        <li>
          <a href='https://gilkalai.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://gilkalai.wordpress.com'>Gil Kalai</a>
          
        </li>
      
        <li>
          <a href='https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.oregonstate.edu/glencora'>Glencora Borradaile</a>
          
        </li>
      
        <li>
          <a href='https://research.googleblog.com/feeds/posts/default/-/Algorithms'><img src='i/feed.png'></a>
          <a href='https://research.googleblog.com/search/label/Algorithms'>Google Research Blog: Algorithms</a>
          
        </li>
      
        <li>
          <a href='https://gradientscience.org/feed.xml'><img src='i/feed.png'></a>
          <a href='https://gradientscience.org/'>Gradient Science</a>
          
        </li>
      
        <li>
          <a href='http://grigory.us/blog/feed.xml'><img src='i/feed.png'></a>
          <a href='http://grigory.github.io/blog'>Grigory Yaroslavtsev</a>
          
        </li>
      
        <li>
          <a href='https://tcsmath.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsmath.wordpress.com'>James R. Lee</a>
          
        </li>
      
        <li>
          <a href='https://kamathematics.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://kamathematics.wordpress.com'>Kamathematics</a>
          
        </li>
      
        <li>
          <a href='http://processalgebra.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://processalgebra.blogspot.com/'>Luca Aceto</a>
          
        </li>
      
        <li>
          <a href='https://lucatrevisan.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://lucatrevisan.wordpress.com'>Luca Trevisan</a>
          
        </li>
      
        <li>
          <a href='https://mittheory.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mittheory.wordpress.com'>MIT CSAIL Student Blog</a>
          
        </li>
      
        <li>
          <a href='http://mybiasedcoin.blogspot.com/feeds/posts/default'><img src='i/feed.png'></a>
          <a href='http://mybiasedcoin.blogspot.com/'>Michael Mitzenmacher</a>
          
        </li>
      
        <li>
          <a href='http://blog.mrtz.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://blog.mrtz.org/'>Moritz Hardt</a>
          
        </li>
      
        <li>
          <a href='http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://mysliceofpizza.blogspot.com/search/label/aggregator'>Muthu Muthukrishnan</a>
          
        </li>
      
        <li>
          <a href='https://nisheethvishnoi.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://nisheethvishnoi.wordpress.com'>Nisheeth Vishnoi</a>
          
        </li>
      
        <li>
          <a href='http://www.solipsistslog.com/feed/'><img src='i/feed.png'></a>
          <a href='http://www.solipsistslog.com'>Noah Stephens-Davidowitz</a>
          
        </li>
      
        <li>
          <a href='http://www.offconvex.org/feed.xml'><img src='i/feed.png'></a>
          <a href='http://offconvex.github.io/'>Off the Convex Path</a>
          
        </li>
      
        <li>
          <a href='http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator'><img src='i/feed.png'></a>
          <a href='http://paulwgoldberg.blogspot.com/search/label/aggregator'>Paul Goldberg</a>
          
        </li>
      
        <li>
          <a href='https://ptreview.sublinear.info/?feed=rss2'><img src='i/feed.png'></a>
          <a href='https://ptreview.sublinear.info'>Property Testing Review</a>
          
        </li>
      
        <li>
          <a href='https://rjlipton.wpcomstaging.com/feed/'><img src='i/feed.png'></a>
          <a href='https://rjlipton.wpcomstaging.com'>Richard Lipton</a>
          
        </li>
      
        <li>
          <a href='https://blogs.princeton.edu/imabandit/feed/'><img src='i/feed.png'></a>
          <a href='https://blogs.princeton.edu/imabandit'>SÃ©bastien Bubeck</a>
          
        </li>
      
        <li>
          <a href='https://scottaaronson.blog/?feed=atom'><img src='i/feed.png'></a>
          <a href='https://scottaaronson.blog'>Scott Aaronson</a>
          
        </li>
      
        <li>
          <a href='https://blog.simons.berkeley.edu/feed/'><img src='i/feed.png'></a>
          <a href='https://blog.simons.berkeley.edu'>Simons Institute Blog</a>
          
        </li>
      
        <li>
          <a href='https://tcsplus.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://tcsplus.wordpress.com'>TCS+ Seminar Series</a>
          
        </li>
      
        <li>
          <a href='https://toc4fairness.org/feed/'><img src='i/feed.png'></a>
          <a href='https://toc4fairness.org'>TOC for Fairness</a>
          
        </li>
      
        <li>
          <a href='http://www.blogger.com/feeds/6555947/posts/default?alt=atom'><img src='i/feed.png'></a>
          <a href='http://blog.geomblog.org/'>The Geomblog</a>
          
        </li>
      
        <li>
          <a href='https://www.let-all.com/blog/feed/'><img src='i/feed.png'></a>
          <a href='https://www.let-all.com/blog'>The Learning Theory Alliance Blog</a>
          
        </li>
      
        <li>
          <a href='https://theorydish.blog/feed/'><img src='i/feed.png'></a>
          <a href='https://theorydish.blog'>Theory Dish: Stanford Blog</a>
          
        </li>
      
        <li>
          <a href='https://thmatters.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://thmatters.wordpress.com'>Theory Matters</a>
          
        </li>
      
        <li>
          <a href='https://mycqstate.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://mycqstate.wordpress.com'>Thomas Vidick</a>
          
        </li>
      
        <li>
          <a href='https://agtb.wordpress.com/feed/'><img src='i/feed.png'></a>
          <a href='https://agtb.wordpress.com'>Turing's Invisible Hand</a>
          
        </li>
      
        <li>
          <a href='https://windowsontheory.org/feed/'><img src='i/feed.png'></a>
          <a href='https://windowsontheory.org'>Windows on Theory</a>
          
        </li>
      
      </ul>

      <p class='small'><a href="opml.xml">OPML feed</a> of all feeds.</p>
      <p class='small'>Subscribe to the <a href="atom.xml">Atom feed</a> or <a href="rss20.xml">RSS feed</a> to stay up to date.</p>
      <p class='small'>Source on <a href="https://github.com/nimaanari/theory.report">GitHub</a>.</p>
      <p class='small'>Maintained by Nima Anari, Arnab Bhattacharyya, Gautam Kamath.</p>
      <p class='small'>Powered by <a href='https://github.com/feedreader'>Pluto</a>.</p>
    </div>
  </div>

  <div id='opts'>
    <div style='width: 100%; text-align: right;'>
    <img src='i/view-headlines.png' id='show-headlines' title='Show Headlines Only' width='24' height='24'>
    <img src='i/view-snippets.png' id='show-snippets' title='Show Snippets' width='24' height='24'>
    <img src='i/view-standard.png' id='show-fulltext' title='Show Full Text' width='24' height='24'>
    </div>
  </div>

  <h1>
    Theory of Computing Report
  </h1>

  <div id="articles">
    
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Thursday, October 13
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05885'>Unitary property testing lower bounds by polynomials</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Adrian She, Henry Yuen</p><p>We study unitary property testing, where a quantum algorithm is given query
access to a black-box unitary and has to decide whether it satisfies some
property. In addition to containing the standard quantum query complexity model
(where the unitary encodes a binary string) as a special case, this model
contains "inherently quantum" problems that have no classical analogue.
Characterizing the query complexity of these problems requires new algorithmic
techniques and lower bound methods.
</p>
<p>Our main contribution is a generalized polynomial method for unitary property
testing problems. By leveraging connections with invariant theory, we apply
this method to obtain lower bounds on problems such as determining recurrence
times of unitaries, approximating the dimension of a marked subspace, and
approximating the entanglement entropy of a marked state. We also present a
unitary property testing-based approach towards an oracle separation between
$\mathsf{QMA}$ and $\mathsf{QMA(2)}$, a long standing question in quantum
complexity theory.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+She_A/0/1/0/all/0/1">Adrian She</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yuen_H/0/1/0/all/0/1">Henry Yuen</a></p><p>We study unitary property testing, where a quantum algorithm is given query
access to a black-box unitary and has to decide whether it satisfies some
property. In addition to containing the standard quantum query complexity model
(where the unitary encodes a binary string) as a special case, this model
contains "inherently quantum" problems that have no classical analogue.
Characterizing the query complexity of these problems requires new algorithmic
techniques and lower bound methods.
</p>
<p>Our main contribution is a generalized polynomial method for unitary property
testing problems. By leveraging connections with invariant theory, we apply
this method to obtain lower bounds on problems such as determining recurrence
times of unitaries, approximating the dimension of a marked subspace, and
approximating the entanglement entropy of a marked state. We also present a
unitary property testing-based approach towards an oracle separation between
$\mathsf{QMA}$ and $\mathsf{QMA(2)}$, a long standing question in quantum
complexity theory.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05788'>A Note on Reachability and Distance Oracles for Transmission Graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Mark de Berg</p><p>Let $P$ be a set of $n$ points in the plane, where each point $p\in P$ has a
transmission radius $r(p)&gt;0$. The transmission graph defined by $P$ and the
given radii, denoted by $\mathcal{G}_{\mathrm{tr}}(P)$, is the directed graph
whose nodes are the points in $P$ and that contains the arcs $(p,q)$ such that
$|pq|\leq r(p)$.
</p>
<p>An and Oh [Algorithmica 2022] presented a reachability oracle for
transmission graphs. Their oracle uses $O(n^{5/3})$ storage and, given two
query points $s,t\in P$, can decide in $O(n^{2/3})$ time if there is a path
from $s$ to $t$ in $\mathcal{G}_{\mathrm{tr}}(P)$. We show that the
clique-based separators introduced by De Berg \emph{et al.} [SICOMP 2020] can
be used to improve the storage of the oracle to $O(n\sqrt{n})$ and the query
time to $O(\sqrt{n})$. Our oracle can be extended to approximate distance
queries: we can construct, for a given parameter $\varepsilon&gt;0$, an oracle
that uses $O((n/\varepsilon)\sqrt{n}\log n)$ storage and that can report in
$O((\sqrt{n}/\varepsilon)\log n)$ time a value $d_{\mathrm{hop}}^*(s,t)$
satisfying $d_{\mathrm{hop}}(s,t) \leq d_{\mathrm{hop}}^*(s,t) &lt;
(1+\varepsilon)\cdot d_{\mathrm{hop}}(s,t) + 1$, where $d_{\mathrm{hop}}(s,t)$
is the hop-distance from $s$ to $t$. We also show how to extend the oracle to
so-called continuous queries, where the target point $t$ can be any point in
the plane.
</p>
<p>To obtain an efficient preprocessing algorithm, we show that a clique-based
separator of a set~$F$ of convex fat objects in $\Bbb{R}^d$ can be constructed
in $O(n\log n)$ time.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Berg_M/0/1/0/all/0/1">Mark de Berg</a></p><p>Let $P$ be a set of $n$ points in the plane, where each point $p\in P$ has a
transmission radius $r(p)&gt;0$. The transmission graph defined by $P$ and the
given radii, denoted by $\mathcal{G}_{\mathrm{tr}}(P)$, is the directed graph
whose nodes are the points in $P$ and that contains the arcs $(p,q)$ such that
$|pq|\leq r(p)$.
</p>
<p>An and Oh [Algorithmica 2022] presented a reachability oracle for
transmission graphs. Their oracle uses $O(n^{5/3})$ storage and, given two
query points $s,t\in P$, can decide in $O(n^{2/3})$ time if there is a path
from $s$ to $t$ in $\mathcal{G}_{\mathrm{tr}}(P)$. We show that the
clique-based separators introduced by De Berg \emph{et al.} [SICOMP 2020] can
be used to improve the storage of the oracle to $O(n\sqrt{n})$ and the query
time to $O(\sqrt{n})$. Our oracle can be extended to approximate distance
queries: we can construct, for a given parameter $\varepsilon&gt;0$, an oracle
that uses $O((n/\varepsilon)\sqrt{n}\log n)$ storage and that can report in
$O((\sqrt{n}/\varepsilon)\log n)$ time a value $d_{\mathrm{hop}}^*(s,t)$
satisfying $d_{\mathrm{hop}}(s,t) \leq d_{\mathrm{hop}}^*(s,t) &lt;
(1+\varepsilon)\cdot d_{\mathrm{hop}}(s,t) + 1$, where $d_{\mathrm{hop}}(s,t)$
is the hop-distance from $s$ to $t$. We also show how to extend the oracle to
so-called continuous queries, where the target point $t$ can be any point in
the plane.
</p>
<p>To obtain an efficient preprocessing algorithm, we show that a clique-based
separator of a set~$F$ of convex fat objects in $\Bbb{R}^d$ can be constructed
in $O(n\log n)$ time.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06333'>Pattern Characterization Using Topological Data Analysis: Application to Piezo Vibration Striking Treatment</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Max M. Chumley, Melih C. Yesilli, Jisheng Chen, Firas A. Khasawneh, Yang Guo</p><p>Quantifying patterns in visual or tactile textures provides important
information about the process or phenomena that generated these patterns. In
manufacturing, these patterns can be intentionally introduced as a design
feature, or they can be a byproduct of a specific process. Since surface
texture has significant impact on the mechanical properties and the longevity
of the workpiece, it is important to develop tools for quantifying surface
patterns and, when applicable, comparing them to their nominal counterparts.
While existing tools may be able to indicate the existence of a pattern, they
typically do not provide more information about the pattern structure, or how
much it deviates from a nominal pattern. Further, prior works do not provide
automatic or algorithmic approaches for quantifying other pattern
characteristics such as depths' consistency, and variations in the pattern
motifs at different level sets. This paper leverages persistent homology from
Topological Data Analysis (TDA) to derive noise-robust scores for quantifying
motifs' depth and roundness in a pattern. Specifically, sublevel persistence is
used to derive scores that quantify the consistency of indentation depths at
any level set in Piezo Vibration Striking Treatment (PVST) surfaces. Moreover,
we combine sublevel persistence with the distance transform to quantify the
consistency of the indentation radii, and to compare them with the nominal
ones. Although the tool in our PVST experiments had a semi-spherical profile,
we present a generalization of our approach to tools/motifs of arbitrary shapes
thus making our method applicable to other pattern-generating manufacturing
processes.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Chumley_M/0/1/0/all/0/1">Max M. Chumley</a>, <a href="http://arxiv.org/find/cs/1/au:+Yesilli_M/0/1/0/all/0/1">Melih C. Yesilli</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jisheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Khasawneh_F/0/1/0/all/0/1">Firas A. Khasawneh</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yang Guo</a></p><p>Quantifying patterns in visual or tactile textures provides important
information about the process or phenomena that generated these patterns. In
manufacturing, these patterns can be intentionally introduced as a design
feature, or they can be a byproduct of a specific process. Since surface
texture has significant impact on the mechanical properties and the longevity
of the workpiece, it is important to develop tools for quantifying surface
patterns and, when applicable, comparing them to their nominal counterparts.
While existing tools may be able to indicate the existence of a pattern, they
typically do not provide more information about the pattern structure, or how
much it deviates from a nominal pattern. Further, prior works do not provide
automatic or algorithmic approaches for quantifying other pattern
characteristics such as depths' consistency, and variations in the pattern
motifs at different level sets. This paper leverages persistent homology from
Topological Data Analysis (TDA) to derive noise-robust scores for quantifying
motifs' depth and roundness in a pattern. Specifically, sublevel persistence is
used to derive scores that quantify the consistency of indentation depths at
any level set in Piezo Vibration Striking Treatment (PVST) surfaces. Moreover,
we combine sublevel persistence with the distance transform to quantify the
consistency of the indentation radii, and to compare them with the nominal
ones. Although the tool in our PVST experiments had a semi-spherical profile,
we present a generalization of our approach to tools/motifs of arbitrary shapes
thus making our method applicable to other pattern-generating manufacturing
processes.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05893'>The Power of Two Matrices in Spectral Algorithms</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Souvik Dhara, Julia Gaudio, Elchanan Mossel, Colin Sandon</p><p>Spectral algorithms are some of the main tools in optimization and inference
problems on graphs. Typically, the graph is encoded as a matrix and
eigenvectors and eigenvalues of the matrix are then used to solve the given
graph problem. Spectral algorithms have been successfully used for graph
partitioning, hidden clique recovery and graph coloring. In this paper, we
study the power of spectral algorithms using two matrices in a graph
partitioning problem. We use two different matrices resulting from two
different encodings of the same graph and then combine the spectral information
coming from these two matrices.
</p>
<p>We analyze a two matrix spectral algorithm for the problem of identifying
latent community structure in large random graphs. In particular, we consider
the problem of recovering community assignments exactly in the censored
stochastic block model, where each edge status is revealed independently with
some probability. We show that spectral algorithms based on two matrices are
optimal and succeed in recovering communities up to the information theory
threshold. On the other hand, we show that for most choices of the parameters,
any spectral algorithm based on one matrix is suboptimal. This is in contrast
to our prior works (2022a, 2022b) which showed that for the symmetric
Stochastic Block Model and the Planted Dense Subgraph problem, spectral
algorithm based on one matrix achieve the information theory threshold. Of
independent interest, we provide more general geometric conditions for the
(sub)-optimality of spectral algorithms, that are also applicable to cases when
there are more than two communities.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Dhara_S/0/1/0/all/0/1">Souvik Dhara</a>, <a href="http://arxiv.org/find/math/1/au:+Gaudio_J/0/1/0/all/0/1">Julia Gaudio</a>, <a href="http://arxiv.org/find/math/1/au:+Mossel_E/0/1/0/all/0/1">Elchanan Mossel</a>, <a href="http://arxiv.org/find/math/1/au:+Sandon_C/0/1/0/all/0/1">Colin Sandon</a></p><p>Spectral algorithms are some of the main tools in optimization and inference
problems on graphs. Typically, the graph is encoded as a matrix and
eigenvectors and eigenvalues of the matrix are then used to solve the given
graph problem. Spectral algorithms have been successfully used for graph
partitioning, hidden clique recovery and graph coloring. In this paper, we
study the power of spectral algorithms using two matrices in a graph
partitioning problem. We use two different matrices resulting from two
different encodings of the same graph and then combine the spectral information
coming from these two matrices.
</p>
<p>We analyze a two matrix spectral algorithm for the problem of identifying
latent community structure in large random graphs. In particular, we consider
the problem of recovering community assignments exactly in the censored
stochastic block model, where each edge status is revealed independently with
some probability. We show that spectral algorithms based on two matrices are
optimal and succeed in recovering communities up to the information theory
threshold. On the other hand, we show that for most choices of the parameters,
any spectral algorithm based on one matrix is suboptimal. This is in contrast
to our prior works (2022a, 2022b) which showed that for the symmetric
Stochastic Block Model and the Planted Dense Subgraph problem, spectral
algorithm based on one matrix achieve the information theory threshold. Of
independent interest, we provide more general geometric conditions for the
(sub)-optimality of spectral algorithms, that are also applicable to cases when
there are more than two communities.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05965'>Resolving the Approximability of Offline and Online Non-monotone DR-Submodular Maximization over General Convex Sets</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Loay Mualem, Moran Feldman</p><p>In recent years, maximization of DR-submodular continuous functions became an
important research field, with many real-worlds applications in the domains of
machine learning, communication systems, operation research and economics. Most
of the works in this field study maximization subject to down-closed convex set
constraints due to an inapproximability result by Vondr\'ak (2013). However,
Durr et al. (2021) showed that one can bypass this inapproximability by proving
approximation ratios that are functions of $m$, the minimum
$\ell_{\infty}$-norm of any feasible vector. Given this observation, it is
possible to get results for maximizing a DR-submodular function subject to
general convex set constraints, which has led to multiple works on this
problem. The most recent of which is a polynomial time $\tfrac{1}{4}(1 -
m)$-approximation offline algorithm due to Du (2022). However, only a
sub-exponential time $\tfrac{1}{3\sqrt{3}}(1 - m)$-approximation algorithm is
known for the corresponding online problem. In this work, we present a
polynomial time online algorithm matching the $\tfrac{1}{4}(1 -
m)$-approximation of the state-of-the-art offline algorithm. We also present an
inapproximability result showing that our online algorithm and Du's (2022)
offline algorithm are both optimal in a strong sense. Finally, we study the
empirical performance of our algorithm and the algorithm of Du (which was only
theoretically studied previously), and show that they consistently outperform
previously suggested algorithms on revenue maximization, location summarization
and quadratic programming applications.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Mualem_L/0/1/0/all/0/1">Loay Mualem</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldman_M/0/1/0/all/0/1">Moran Feldman</a></p><p>In recent years, maximization of DR-submodular continuous functions became an
important research field, with many real-worlds applications in the domains of
machine learning, communication systems, operation research and economics. Most
of the works in this field study maximization subject to down-closed convex set
constraints due to an inapproximability result by Vondr\'ak (2013). However,
Durr et al. (2021) showed that one can bypass this inapproximability by proving
approximation ratios that are functions of $m$, the minimum
$\ell_{\infty}$-norm of any feasible vector. Given this observation, it is
possible to get results for maximizing a DR-submodular function subject to
general convex set constraints, which has led to multiple works on this
problem. The most recent of which is a polynomial time $\tfrac{1}{4}(1 -
m)$-approximation offline algorithm due to Du (2022). However, only a
sub-exponential time $\tfrac{1}{3\sqrt{3}}(1 - m)$-approximation algorithm is
known for the corresponding online problem. In this work, we present a
polynomial time online algorithm matching the $\tfrac{1}{4}(1 -
m)$-approximation of the state-of-the-art offline algorithm. We also present an
inapproximability result showing that our online algorithm and Du's (2022)
offline algorithm are both optimal in a strong sense. Finally, we study the
empirical performance of our algorithm and the algorithm of Du (which was only
theoretically studied previously), and show that they consistently outperform
previously suggested algorithms on revenue maximization, location summarization
and quadratic programming applications.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05974'>Clustering Embedding Tables, Without First Learning Them</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Henry Ling-Hei Tsang, Thomas Dybdahl Ahle</p><p>To work with categorical features, machine learning systems employ embedding
tables. These tables can become exceedingly large in modern recommendation
systems, necessitating the development of new methods for fitting them in
memory, even during training.
</p>
<p>Some of the most successful methods for table compression are Product- and
Residual Vector Quantization (Gray &amp; Neuhoff, 1998). These methods replace
table rows with references to k-means clustered "codewords." Unfortunately,
this means they must first know the table before compressing it, so they can
only save memory during inference, not training. Recent work has used
hashing-based approaches to minimize memory usage during training, but the
compression obtained is inferior to that obtained by "post-training"
quantization.
</p>
<p>We show that the best of both worlds may be obtained by combining techniques
based on hashing and clustering. By first training a hashing-based "sketch",
then clustering it, and then training the clustered quantization, our method
achieves compression ratios close to those of post-training quantization with
the training time memory reductions of hashing-based methods.
</p>
<p>We show experimentally that our method provides better compression and/or
accuracy that previous methods, and we prove that our method always converges
to the optimal embedding table for least-squares training.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tsang_H/0/1/0/all/0/1">Henry Ling-Hei Tsang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahle_T/0/1/0/all/0/1">Thomas Dybdahl Ahle</a></p><p>To work with categorical features, machine learning systems employ embedding
tables. These tables can become exceedingly large in modern recommendation
systems, necessitating the development of new methods for fitting them in
memory, even during training.
</p>
<p>Some of the most successful methods for table compression are Product- and
Residual Vector Quantization (Gray &amp; Neuhoff, 1998). These methods replace
table rows with references to k-means clustered "codewords." Unfortunately,
this means they must first know the table before compressing it, so they can
only save memory during inference, not training. Recent work has used
hashing-based approaches to minimize memory usage during training, but the
compression obtained is inferior to that obtained by "post-training"
quantization.
</p>
<p>We show that the best of both worlds may be obtained by combining techniques
based on hashing and clustering. By first training a hashing-based "sketch",
then clustering it, and then training the clustered quantization, our method
achieves compression ratios close to those of post-training quantization with
the training time memory reductions of hashing-based methods.
</p>
<p>We show experimentally that our method provides better compression and/or
accuracy that previous methods, and we prove that our method always converges
to the optimal embedding table for least-squares training.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05982'>A nearly optimal randomized algorithm for explorable heap selection</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Sander Borst, Daniel Dadush, Sophie Huiberts, Danish Kashaev</p><p>Explorable heap selection is the problem of selecting the $n$th smallest
value in a binary heap. The key values can only be accessed by traversing
through the underlying infinite binary tree, and the complexity of the
algorithm is measured by the total distance traveled in the tree (each edge has
unit cost). This problem was originally proposed as a model to study search
strategies for the branch-and-bound algorithm with storage restrictions by
Karp, Saks and Widgerson (FOCS '86), who gave deterministic and randomized
$n\cdot \exp(O(\sqrt{\log{n}}))$ time algorithms using $O(\log(n)^{2.5})$ and
$O(\sqrt{\log n})$ space respectively. We present a new randomized algorithm
with running time $O(n\log(n)^3)$ using $O(\log n)$ space, substantially
improving the previous best randomized running time at the expense of slightly
increased space usage. We also show an $\Omega(\log(n)n/\log(\log(n)))$ for any
algorithm that solves the problem in the same amount of space, indicating that
our algorithm is nearly optimal.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Borst_S/0/1/0/all/0/1">Sander Borst</a>, <a href="http://arxiv.org/find/cs/1/au:+Dadush_D/0/1/0/all/0/1">Daniel Dadush</a>, <a href="http://arxiv.org/find/cs/1/au:+Huiberts_S/0/1/0/all/0/1">Sophie Huiberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashaev_D/0/1/0/all/0/1">Danish Kashaev</a></p><p>Explorable heap selection is the problem of selecting the $n$th smallest
value in a binary heap. The key values can only be accessed by traversing
through the underlying infinite binary tree, and the complexity of the
algorithm is measured by the total distance traveled in the tree (each edge has
unit cost). This problem was originally proposed as a model to study search
strategies for the branch-and-bound algorithm with storage restrictions by
Karp, Saks and Widgerson (FOCS '86), who gave deterministic and randomized
$n\cdot \exp(O(\sqrt{\log{n}}))$ time algorithms using $O(\log(n)^{2.5})$ and
$O(\sqrt{\log n})$ space respectively. We present a new randomized algorithm
with running time $O(n\log(n)^3)$ using $O(\log n)$ space, substantially
improving the previous best randomized running time at the expense of slightly
increased space usage. We also show an $\Omega(\log(n)n/\log(\log(n)))$ for any
algorithm that solves the problem in the same amount of space, indicating that
our algorithm is nearly optimal.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05992'>Fast Convergence to Unanimity in Dense Erd\H{o}s-R\'enyi Graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Ran Tamir</p><p>Majority dynamics on the binomial Erd\H{o}s-R\'enyi graph $\mathsf{G}(n,p)$
with $p=\lambda/\sqrt{n}$ is studied. In this process, each vertex has a state
in $\{0,1\}$ and at each round, every vertex adopts the state of the majority
of its neighbors, retaining its state in the case of a tie. It was conjectured
by Benjamini et al. and proved by Fountoulakis et al. that this process reaches
unanimity with high probability in at most four rounds. By adding some extra
randomness and allowing the underlying graph to be drawn anew in each
communication round, we improve on their result and prove that this process
reaches consensus in only three communication rounds with probability
approaching $1$ as $n$ grows to infinity. We also provide a converse result,
showing that three rounds are not only sufficient, but also necessary.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Tamir_R/0/1/0/all/0/1">Ran Tamir</a></p><p>Majority dynamics on the binomial Erd\H{o}s-R\'enyi graph $\mathsf{G}(n,p)$
with $p=\lambda/\sqrt{n}$ is studied. In this process, each vertex has a state
in $\{0,1\}$ and at each round, every vertex adopts the state of the majority
of its neighbors, retaining its state in the case of a tie. It was conjectured
by Benjamini et al. and proved by Fountoulakis et al. that this process reaches
unanimity with high probability in at most four rounds. By adding some extra
randomness and allowing the underlying graph to be drawn anew in each
communication round, we improve on their result and prove that this process
reaches consensus in only three communication rounds with probability
approaching $1$ as $n$ grows to infinity. We also provide a converse result,
showing that three rounds are not only sufficient, but also necessary.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06061'>Non-smooth and H\"older-smooth Submodular Maximization</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Duksang Lee, Nam Ho-Nguyen, Dabeen Lee</p><p>We study the problem of maximizing a continuous DR-submodular function that
is not necessarily smooth. We prove that the continuous greedy algorithm
achieves an $[(1-1/e)\text{OPT}-\epsilon]$ guarantee when the function is
monotone and H\"older-smooth, meaning that it admits a H\"older-continuous
gradient. For functions that are non-differentiable or non-smooth, we propose a
variant of the mirror-prox algorithm that attains an
$[(1/2)\text{OPT}-\epsilon]$ guarantee. We apply our algorithmic frameworks to
robust submodular maximization and distrbituionally robust submodular
maximization under Wasserstein ambiguity. In particular, the mirror-prox method
applies to robust submodular maximization to obtain a single feasible solution
whose value is at least $(1/2)\text{OPT}-\epsilon$. For distributionally robust
maximization under Wasserstein ambiguity, we deduce and work over a
submodular-convex maximin reformulation whose objective function is
H\"older-smooth, for which we may apply both the continuous greedy method and
the mirror-prox method.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Lee_D/0/1/0/all/0/1">Duksang Lee</a>, <a href="http://arxiv.org/find/math/1/au:+Ho_Nguyen_N/0/1/0/all/0/1">Nam Ho-Nguyen</a>, <a href="http://arxiv.org/find/math/1/au:+Lee_D/0/1/0/all/0/1">Dabeen Lee</a></p><p>We study the problem of maximizing a continuous DR-submodular function that
is not necessarily smooth. We prove that the continuous greedy algorithm
achieves an $[(1-1/e)\text{OPT}-\epsilon]$ guarantee when the function is
monotone and H\"older-smooth, meaning that it admits a H\"older-continuous
gradient. For functions that are non-differentiable or non-smooth, we propose a
variant of the mirror-prox algorithm that attains an
$[(1/2)\text{OPT}-\epsilon]$ guarantee. We apply our algorithmic frameworks to
robust submodular maximization and distrbituionally robust submodular
maximization under Wasserstein ambiguity. In particular, the mirror-prox method
applies to robust submodular maximization to obtain a single feasible solution
whose value is at least $(1/2)\text{OPT}-\epsilon$. For distributionally robust
maximization under Wasserstein ambiguity, we deduce and work over a
submodular-convex maximin reformulation whose objective function is
H\"older-smooth, for which we may apply both the continuous greedy method and
the mirror-prox method.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06140'>Differentially Private Bootstrap: New Privacy Analysis and Inference Strategies</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Zhanyu Wang, Guang Cheng, Jordan Awan</p><p>Differential private (DP) mechanisms protect individual-level information by
introducing randomness into the statistical analysis procedure. While there are
now many DP tools for various statistical problems, there is still a lack of
general techniques to understand the sampling distribution of a DP estimator,
which is crucial for uncertainty quantification in statistical inference. We
analyze a DP bootstrap procedure that releases multiple private bootstrap
estimates to infer the sampling distribution and construct confidence
intervals. Our privacy analysis includes new results on the privacy cost of a
single DP bootstrap estimate applicable to incorporate arbitrary DP mechanisms
and identifies some misuses of the bootstrap in the existing literature. We
show that the release of $B$ DP bootstrap estimates from mechanisms satisfying
$(\mu/\sqrt{(2-2/\mathrm{e})B})$-Gaussian DP asymptotically satisfies
$\mu$-Gaussian DP as $B$ goes to infinity. We also develop a statistical
procedure based on the DP bootstrap estimates to correctly infer the sampling
distribution using techniques related to the deconvolution of probability
measures, an approach which is novel in analyzing DP procedures. From our
density estimate, we construct confidence intervals and compare them to
existing methods through simulations and real-world experiments using the 2016
Canada Census Public Use Microdata. The coverage of our private confidence
intervals achieves the nominal confidence level, while other methods fail to
meet this guarantee.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1">Zhanyu Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1">Guang Cheng</a>, <a href="http://arxiv.org/find/stat/1/au:+Awan_J/0/1/0/all/0/1">Jordan Awan</a></p><p>Differential private (DP) mechanisms protect individual-level information by
introducing randomness into the statistical analysis procedure. While there are
now many DP tools for various statistical problems, there is still a lack of
general techniques to understand the sampling distribution of a DP estimator,
which is crucial for uncertainty quantification in statistical inference. We
analyze a DP bootstrap procedure that releases multiple private bootstrap
estimates to infer the sampling distribution and construct confidence
intervals. Our privacy analysis includes new results on the privacy cost of a
single DP bootstrap estimate applicable to incorporate arbitrary DP mechanisms
and identifies some misuses of the bootstrap in the existing literature. We
show that the release of $B$ DP bootstrap estimates from mechanisms satisfying
$(\mu/\sqrt{(2-2/\mathrm{e})B})$-Gaussian DP asymptotically satisfies
$\mu$-Gaussian DP as $B$ goes to infinity. We also develop a statistical
procedure based on the DP bootstrap estimates to correctly infer the sampling
distribution using techniques related to the deconvolution of probability
measures, an approach which is novel in analyzing DP procedures. From our
density estimate, we construct confidence intervals and compare them to
existing methods through simulations and real-world experiments using the 2016
Canada Census Public Use Microdata. The coverage of our private confidence
intervals achieves the nominal confidence level, while other methods fail to
meet this guarantee.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.06227'>Quantum Optimisation for Continuous Multivariable Functions by a Structured Search</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Edric Matwiejew, Jason Pye, Jingbo B. Wang</p><p>Solving optimisation problems is a promising near-term application of quantum
computers. Quantum variational algorithms leverage quantum superposition and
entanglement to optimise over exponentially large solution spaces using an
alternating sequence of classically tunable unitaries. However, prior work has
primarily addressed discrete optimisation problems. In addition, these
algorithms have been designed generally under the assumption of an unstructured
solution space, which constrains their speedup to the theoretical limits for
the unstructured Grover's quantum search algorithm. In this paper, we show that
quantum variational algorithms can efficiently optimise continuous
multivariable functions by exploiting general structural properties of a
discretised continuous solution space with a convergence that exceeds the
limits of an unstructured quantum search. We introduce the Quantum
Multivariable Optimisation Algorithm (QMOA) and demonstrate its advantage over
pre-existing methods, particularly when optimising high-dimensional and
oscillatory functions.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/quant-ph/1/au:+Matwiejew_E/0/1/0/all/0/1">Edric Matwiejew</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pye_J/0/1/0/all/0/1">Jason Pye</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wang_J/0/1/0/all/0/1">Jingbo B. Wang</a></p><p>Solving optimisation problems is a promising near-term application of quantum
computers. Quantum variational algorithms leverage quantum superposition and
entanglement to optimise over exponentially large solution spaces using an
alternating sequence of classically tunable unitaries. However, prior work has
primarily addressed discrete optimisation problems. In addition, these
algorithms have been designed generally under the assumption of an unstructured
solution space, which constrains their speedup to the theoretical limits for
the unstructured Grover's quantum search algorithm. In this paper, we show that
quantum variational algorithms can efficiently optimise continuous
multivariable functions by exploiting general structural properties of a
discretised continuous solution space with a convergence that exceeds the
limits of an unstructured quantum search. We introduce the Quantum
Multivariable Optimisation Algorithm (QMOA) and demonstrate its advantage over
pre-existing methods, particularly when optimising high-dimensional and
oscillatory functions.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-13T00:30:00Z">Thursday, October 13 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Wednesday, October 12
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://scottaaronson.blog/?p=6754'>Explanation-GÃ¶del and Plausibility-GÃ¶del</a></h3>
          <p class='item-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Here&#8217;s an observation that&#8217;s mathematically trivial but might not be widely appreciated. In kindergarten, we all learned GÃ¶del&#8217;s First Incompleteness Theorem, which given a formal system F, constructs an arithmetical encoding of G(F) = &#8220;This sentence is not provable in F.&#8221; If G(F) is true, then it&#8217;s an example of a true arithmetical sentence that&#8217;s [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Here&#8217;s an observation that&#8217;s mathematically trivial but might not be widely appreciated.  In kindergarten, we all learned GÃ¶del&#8217;s First <a href="https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems">Incompleteness Theorem</a>, which given a formal system F, constructs an arithmetical encoding of</p>



<p>G(F) = &#8220;This sentence is not provable in F.&#8221;</p>



<p>If G(F) is true, then it&#8217;s an example of a true arithmetical sentence that&#8217;s unprovable in F.  If, on the other hand, G(F) is false, then it&#8217;s provable, which means that F isn&#8217;t arithmetically sound.  Therefore F is either incomplete or unsound.</p>



<p>Many have objected: &#8220;but despite GÃ¶del&#8217;s Theorem, it&#8217;s still easy to <em>explain </em>why G(F) is true.  In fact, the argument above basically already did it!&#8221;  You might make a more general point: there are many, many mathematical statements for which we currently lack a proof, but we do seem to have a fully convincing heuristic explanation: one that &#8220;proves the statement to physics standards of rigor.&#8221;  For example:</p>



<ul><li>The <a href="https://en.wikipedia.org/wiki/Twin_prime">Twin Primes Conjecture</a> (there are infinitely many primes p for which p+2 is also prime).  </li><li>The <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz Conjecture</a> (the iterative process that maps each positive integer n to n/2 if n is even, or to 3n+1 if n is odd, eventually reaches 1 regardless of which n you start at).  </li><li>Ï is a <a href="https://en.wikipedia.org/wiki/Normal_number">normal number</a> (or even just: the digits 0-9 all occur with equal limiting frequencies in the decimal expansion of Ï).</li><li><a href="https://math.stackexchange.com/questions/159350/why-is-it-hard-to-prove-whether-pie-is-an-irrational-number">Ï+e</a> is irrational.</li></ul>



<p>And so on.  No one has any idea how to prove any of the above statements&#8212;and yet, just on statistical grounds, it seems clear that it would require a ludicrous conspiracy to make any of them false.</p>



<p>Conversely, one could argue that there are statements for which we <em>do</em> have a proof, even though we lack a &#8220;convincing explanation&#8221; for the statements&#8217; truth.  Maybe the <a href="https://en.wikipedia.org/wiki/Four_color_theorem">Four-Color Theorem</a> or <a href="https://en.wikipedia.org/wiki/Kepler_conjecture">Hales&#8217;s Theorem</a>, for which every known proof requires a massive computer enumeration of cases, belong to this class.  Other people might argue that, given a proof, an explanation could always be extracted with enough time and effort, though resolving this dispute won&#8217;t matter for what follows.</p>



<p>You might hope that, even if some true mathematical statements can&#8217;t be <em>proved</em>, every true statement might nevertheless have a <em>convincing heuristic explanation</em>.  Alas, a trivial adaptation of GÃ¶del&#8217;s Theorem shows that, if (1) heuristic explanations are to be checkable by computer, and (2) only true statements are to have convincing heuristic explanations, then this isn&#8217;t possible either.  I mean, let E be a program that accepts or rejects proposed heuristic explanations, for statements like the Twin Prime Conjecture or the Collatz Conjecture.  Then construct the sentence</p>



<p>S(E) = &#8220;This sentence has no convincing heuristic explanation accepted by E.&#8221;</p>



<p>If S(E) is true, then it&#8217;s an example of a true arithmetical statement without <em>even</em> a convincing heuristic explanation for its truth (!).  If, on the other hand, S(E) is false, then there&#8217;s a convincing heuristic explanation of its truth, which means that something has gone wrong.</p>



<p>What&#8217;s happening, of course, is that given the two conditions we imposed, our &#8220;heuristic explanation system&#8221; <em>was</em> a proof system, even though we didn&#8217;t call it one.  This is my point, though: when we use the word &#8220;proof,&#8221; it normally invokes a specific image, of a sequence of statements that marches from axioms to a theorem, with each statement following from the preceding ones by rigid inference rules like those of first-order logic.  None of that, however, plays any direct role in the proof of the Incompleteness Theorem, which cares only about soundness (inability to prove falsehoods) and checkability by a computer (what, with hindsight, GÃ¶del&#8217;s &#8220;arithmetization of syntax&#8221; was all about).  The logic works for &#8220;heuristic explanations&#8221; too.</p>



<p>Now we come to something that I picked up from my former student (and now AI alignment leader) <a href="https://paulfchristiano.com/">Paul Christiano</a>, on a recent trip to the Bay Area, and which I share with Paul&#8217;s kind permission.  Having learned that there&#8217;s no way to mechanize even heuristic explanations for all the true statements of arithmetic, we could set our sights lower still, and ask about mere <em>plausibility arguments</em>&#8212;arguments that might be overturned on further reflection.  Is there some sense in which every true mathematical statement at least has a good plausibility argument?</p>



<p>Maybe you see where this is going.  Letting P be a program that accepts or rejects proposed plausibility arguments, we can construct</p>



<p>S(P) = &#8220;This sentence has no argument for its plausibility accepted by P.&#8221;</p>



<p>If S(P) is true, then it&#8217;s an example of a true arithmetical statement without even a plausibility argument for its truth (!).  If, on the other hand, S(P) is false, then there <em>is</em> a plausibility argument for it.  By itself, this is <em>not at all</em> a fatal problem: all sorts of false statements (IPâ PSPACE, switching doors doesn&#8217;t matter in <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">Monty Hall</a>, Trump couldn&#8217;t possibly become president&#8230;) have had decent plausibility arguments.  Having said that, it&#8217;s pretty strange that you can have a plausibility argument that&#8217;s immediately contradicted by its own existence!  This rules out some properties that you might want your &#8220;plausibility system&#8221; to have, although maybe a plausibility system exists that&#8217;s still nontrivial and that has weaker properties.</p>



<p>Anyway, I don&#8217;t know where I&#8217;m going with this, or even why I posted it, but I hope you enjoyed it!  And maybe there&#8217;s something to be discovered in this direction.</p>
<p class="authors">By Scott</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T21:52:31Z">Wednesday, October 12 2022, 21:52</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/10/12/postdoc-researcher-at-ens-paris-apply-by-october-31-2022/'>Postdoc researcher at ENS Paris (apply by October 31, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The PARSe project funded by ANR (France) opens one postdoc position at ENS Paris, hosted by Tatiana Starikovskaya. The postdoc researcher will contribute efficient tools for processing large-scale, noisy string data. The post will require a high level of expertise in areas which may include but not be limited to string algorithms and streaming / [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The PARSe project funded by ANR (France) opens one postdoc position at ENS Paris, hosted by Tatiana Starikovskaya. The postdoc researcher will contribute efficient tools for processing large-scale, noisy string data. The post will require a high level of expertise in areas which may include but not be limited to string algorithms and streaming / property testing algorithms.</p>
<p>Website: <a href="https://euraxess.ec.europa.eu/jobs/842793">https://euraxess.ec.europa.eu/jobs/842793</a><br />
Email: starikovskaya@di.ens.fr</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T14:44:31Z">Wednesday, October 12 2022, 14:44</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05019'>Parameterized Approaches to Orthogonal Compaction</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Walter Didimo, Siddharth Gupta, Philipp Kindermann, Giuseppe Liotta, Alexander Wolff, Meirav Zehavi</p><p>Orthogonal graph drawings are used in applications such as UML diagrams, VLSI
layout, cable plans, and metro maps. We focus on drawing planar graphs and
assume that we are given an \emph{orthogonal representation} that describes the
desired shape, but not the exact coordinates of a drawing. Our aim is to
compute an orthogonal drawing on the grid that has minimum area among all grid
drawings that adhere to the given orthogonal representation.
</p>
<p>This problem is called orthogonal compaction (OC) and is known to be NP-hard,
even for orthogonal representations of cycles [Evans et al., 2022]. We
investigate the complexity of OC with respect to several parameters. Among
others, we show that OC is fixed-parameter tractable with respect to the most
natural of these parameters, namely, the number of \emph{kitty corners} of the
orthogonal representation: the presence of pairs of kitty corners in an
orthogonal representation makes the OC problem hard. Informally speaking, a
pair of kitty corners is a pair of reflex corners of a face that point at each
other. Accordingly, the number of kitty corners is the number of corners that
are involved in some pair of kitty corners.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Didimo_W/0/1/0/all/0/1">Walter Didimo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Siddharth Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kindermann_P/0/1/0/all/0/1">Philipp Kindermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Liotta_G/0/1/0/all/0/1">Giuseppe Liotta</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolff_A/0/1/0/all/0/1">Alexander Wolff</a>, <a href="http://arxiv.org/find/cs/1/au:+Zehavi_M/0/1/0/all/0/1">Meirav Zehavi</a></p><p>Orthogonal graph drawings are used in applications such as UML diagrams, VLSI
layout, cable plans, and metro maps. We focus on drawing planar graphs and
assume that we are given an \emph{orthogonal representation} that describes the
desired shape, but not the exact coordinates of a drawing. Our aim is to
compute an orthogonal drawing on the grid that has minimum area among all grid
drawings that adhere to the given orthogonal representation.
</p>
<p>This problem is called orthogonal compaction (OC) and is known to be NP-hard,
even for orthogonal representations of cycles [Evans et al., 2022]. We
investigate the complexity of OC with respect to several parameters. Among
others, we show that OC is fixed-parameter tractable with respect to the most
natural of these parameters, namely, the number of \emph{kitty corners} of the
orthogonal representation: the presence of pairs of kitty corners in an
orthogonal representation makes the OC problem hard. Informally speaking, a
pair of kitty corners is a pair of reflex corners of a face that point at each
other. Accordingly, the number of kitty corners is the number of corners that
are involved in some pair of kitty corners.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T00:30:00Z">Wednesday, October 12 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05093'>Crack Modeling via Minimum-Weight Surfaces in 3d Voronoi Diagrams</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Christian Jung, Claudia Redenbach</p><p>Shortest paths play an important role in mathematical modeling and image
processing. Usually, shortest path problems are formulated on planar graphs
that consist of vertices and weighted arcs. In this context, one is interested
in finding a path of minimum weight from a start vertex to an end vertex. The
concept of minimum-weight surfaces extends shortest paths to 3d. The
minimum-weight surface problem is formulated on a cellular complex with
weighted facets. A cycle on the arcs of the complex serves as input and one is
interested in finding a surface of minimum weight bounded by that cycle. In
practice, minimum-weight surfaces can be used to segment 3d images. Vice versa,
it is possible to use them as a modeling tool for geometric structures such as
cracks. In this work, we present an approach for using minimum-weight surfaces
in bounded Voronoi diagrams to generate synthetic 3d images of cracks.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1">Christian Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Redenbach_C/0/1/0/all/0/1">Claudia Redenbach</a></p><p>Shortest paths play an important role in mathematical modeling and image
processing. Usually, shortest path problems are formulated on planar graphs
that consist of vertices and weighted arcs. In this context, one is interested
in finding a path of minimum weight from a start vertex to an end vertex. The
concept of minimum-weight surfaces extends shortest paths to 3d. The
minimum-weight surface problem is formulated on a cellular complex with
weighted facets. A cycle on the arcs of the complex serves as input and one is
interested in finding a surface of minimum weight bounded by that cycle. In
practice, minimum-weight surfaces can be used to segment 3d images. Vice versa,
it is possible to use them as a modeling tool for geometric structures such as
cracks. In this work, we present an approach for using minimum-weight surfaces
in bounded Voronoi diagrams to generate synthetic 3d images of cracks.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T00:30:00Z">Wednesday, October 12 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05124'>Persistence Diagram Bundles: A Multidimensional Generalization of Vineyards</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Abigail Hickok</p><p>A persistence diagram (PD) summarizes the persistent homology of a
filtration. I introduce the concept of a persistence diagram bundle, which is
the space of PDs associated with a fibered filtration function (a set $\{f_t:
\mathcal{K}^t \to \mathbb{R}\}_{t \in \mathcal{T}}$ of filtrations
parameterized by a topological space $\mathcal{T}$). Special cases include
vineyards, the persistent homology transform, and fibered barcodes of
multiparameter persistence modules. I prove that if $\mathcal{T}$ is a compact
$n$-dimensional manifold, then for generic fibered filtration functions,
$\mathcal{T}$ is stratified such that within each $n$-dimensional stratum $S$,
there is a single PD "template" (a list of birth and death simplices) that can
be used to obtain $PD(f_t)$ for any $t \in S$. I also show that not every local
section can be extended to a global section. Consequently, the points in the
PDs do not typically trace out separate manifolds as $t \in \mathcal{T}$
varies; this is unlike a vineyard, in which the points in the PDs trace out
curves ("vines").
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/math/1/au:+Hickok_A/0/1/0/all/0/1">Abigail Hickok</a></p><p>A persistence diagram (PD) summarizes the persistent homology of a
filtration. I introduce the concept of a persistence diagram bundle, which is
the space of PDs associated with a fibered filtration function (a set $\{f_t:
\mathcal{K}^t \to \mathbb{R}\}_{t \in \mathcal{T}}$ of filtrations
parameterized by a topological space $\mathcal{T}$). Special cases include
vineyards, the persistent homology transform, and fibered barcodes of
multiparameter persistence modules. I prove that if $\mathcal{T}$ is a compact
$n$-dimensional manifold, then for generic fibered filtration functions,
$\mathcal{T}$ is stratified such that within each $n$-dimensional stratum $S$,
there is a single PD "template" (a list of birth and death simplices) that can
be used to obtain $PD(f_t)$ for any $t \in S$. I also show that not every local
section can be extended to a global section. Consequently, the points in the
PDs do not typically trace out separate manifolds as $t \in \mathcal{T}$
varies; this is unlike a vineyard, in which the points in the PDs trace out
curves ("vines").
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T00:30:00Z">Wednesday, October 12 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05384'>Morphing Planar Graph Drawings Through 3D</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Kevin Buchin, Will Evans, Fabrizio Frati, Irina Kostitsyna, Maarten L&#xf6;ffler, Tim Ophelders, Alexander Wolff</p><p>In this paper, we investigate crossing-free 3D morphs between planar
straight-line drawings. We show that, for any two (not necessarily
topologically equivalent) planar straight-line drawings of an $n$-vertex planar
graph, there exists a piecewise-linear crossing-free 3D morph with $O(n^2)$
steps that transforms one drawing into the other. We also give some evidence
why it is difficult to obtain a linear lower bound (which exists in 2D) for the
number of steps of a crossing-free 3D morph.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Buchin_K/0/1/0/all/0/1">Kevin Buchin</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_W/0/1/0/all/0/1">Will Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Frati_F/0/1/0/all/0/1">Fabrizio Frati</a>, <a href="http://arxiv.org/find/cs/1/au:+Kostitsyna_I/0/1/0/all/0/1">Irina Kostitsyna</a>, <a href="http://arxiv.org/find/cs/1/au:+Loffler_M/0/1/0/all/0/1">Maarten L&#xf6;ffler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ophelders_T/0/1/0/all/0/1">Tim Ophelders</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolff_A/0/1/0/all/0/1">Alexander Wolff</a></p><p>In this paper, we investigate crossing-free 3D morphs between planar
straight-line drawings. We show that, for any two (not necessarily
topologically equivalent) planar straight-line drawings of an $n$-vertex planar
graph, there exists a piecewise-linear crossing-free 3D morph with $O(n^2)$
steps that transforms one drawing into the other. We also give some evidence
why it is difficult to obtain a linear lower bound (which exists in 2D) for the
number of steps of a crossing-free 3D morph.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T00:30:00Z">Wednesday, October 12 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05403'>Hierarchical Categories in Colored Searching</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Peyman Afshani, Rasmus Killman, Kasper Green Larsen</p><p>In colored range counting (CRC), the input is a set of points where each
point is assigned a ``color'' (or a ``category'') and the goal is to store them
in a data structure such that the number of distinct categories inside a given
query range can be counted efficiently. CRC has strong motivations as it allows
data structure to deal with categorical data. However, colors (i.e., the
categories) in the CRC problem do not have any internal structure, whereas this
is not the case for many datasets in practice where hierarchical categories
exists or where a single input belongs to multiple categories. Motivated by
these, we consider variants of the problem where such structures can be
represented. We define two variants of the problem called hierarchical range
counting (HCC) and sub-category colored range counting (SCRC) and consider
hierarchical structures that can either be a DAG or a tree. We show that the
two problems on some special trees are in fact equivalent to other well-known
problems in the literature. Based on these, we also give efficient data
structures when the underlying hierarchy can be represented as a tree. We show
a conditional lower bound for the general case when the existing hierarchy can
be any DAG, through reductions from the orthogonal vectors problem.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Afshani_P/0/1/0/all/0/1">Peyman Afshani</a>, <a href="http://arxiv.org/find/cs/1/au:+Killman_R/0/1/0/all/0/1">Rasmus Killman</a>, <a href="http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1">Kasper Green Larsen</a></p><p>In colored range counting (CRC), the input is a set of points where each
point is assigned a ``color'' (or a ``category'') and the goal is to store them
in a data structure such that the number of distinct categories inside a given
query range can be counted efficiently. CRC has strong motivations as it allows
data structure to deal with categorical data. However, colors (i.e., the
categories) in the CRC problem do not have any internal structure, whereas this
is not the case for many datasets in practice where hierarchical categories
exists or where a single input belongs to multiple categories. Motivated by
these, we consider variants of the problem where such structures can be
represented. We define two variants of the problem called hierarchical range
counting (HCC) and sub-category colored range counting (SCRC) and consider
hierarchical structures that can either be a DAG or a tree. We show that the
two problems on some special trees are in fact equivalent to other well-known
problems in the literature. Based on these, we also give efficient data
structures when the underlying hierarchy can be represented as a tree. We show
a conditional lower bound for the general case when the existing hierarchy can
be any DAG, through reductions from the orthogonal vectors problem.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T00:30:00Z">Wednesday, October 12 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05000'>A Hierarchical Grouping Algorithm for the Multi-Vehicle Dial-a-Ride Problem</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Kelin Luo, Alexandre M. Florio, Syamantak Das, Xiangyu Guo</p><p>Ride-sharing is an essential aspect of modern urban mobility. In this paper,
we consider a classical problem in ride-sharing - the Multi-Vehicle Dial-a-Ride
Problem (Multi-Vehicle DaRP). Given a fleet of vehicles with a fixed capacity
stationed at various locations and a set of ride requests specified by origins
and destinations, the goal is to serve all requests such that no vehicle is
assigned more passengers than its capacity at any point along its trip. We
propose an algorithm HRA, which is the first non-trivial approximation
algorithm for the Multi-Vehicle DaRP. The main technical contribution is to
reduce the Multi-Vehicle DaRP to a certain capacitated partitioning problem,
which we solve using a novel hierarchical grouping algorithm. Experimental
results show that the vehicle routes produced by our algorithm not only exhibit
less total travel distance compared to state-of-the-art baselines, but also
enjoy a small in-transit latency, which crucially relates to riders' traveling
times. This suggests that HRA enhances rider experience while being
energy-efficient.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1">Kelin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Florio_A/0/1/0/all/0/1">Alexandre M. Florio</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Syamantak Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiangyu Guo</a></p><p>Ride-sharing is an essential aspect of modern urban mobility. In this paper,
we consider a classical problem in ride-sharing - the Multi-Vehicle Dial-a-Ride
Problem (Multi-Vehicle DaRP). Given a fleet of vehicles with a fixed capacity
stationed at various locations and a set of ride requests specified by origins
and destinations, the goal is to serve all requests such that no vehicle is
assigned more passengers than its capacity at any point along its trip. We
propose an algorithm HRA, which is the first non-trivial approximation
algorithm for the Multi-Vehicle DaRP. The main technical contribution is to
reduce the Multi-Vehicle DaRP to a certain capacitated partitioning problem,
which we solve using a novel hierarchical grouping algorithm. Experimental
results show that the vehicle routes produced by our algorithm not only exhibit
less total travel distance compared to state-of-the-art baselines, but also
enjoy a small in-transit latency, which crucially relates to riders' traveling
times. This suggests that HRA enhances rider experience while being
energy-efficient.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T00:30:00Z">Wednesday, October 12 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05294'>Evaluation of the Quality of Exercises for the Data Structures' eTextbook and Find the Difficult Topics Using Item Response Theory and Logged Data Analysis</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Ahmed Abd Elrahman, Taysir Hassan A Soliman, Mohammed F. Farghally, Ahmed I. Taloba</p><p>The growing dependence on eTextbooks and Massive Open Online Courses (MOOCs)
has led to an increase in the amount of students' learning data. By carefully
analyzing this data, educators can identify difficult exercises, and evaluate
the quality of the exercises when teaching a particular topic. In this study,
an analysis of log data from the use of a semester of the OpenDSA eTextbook was
offered to identify the most difficult data structure course exercises and to
evaluate the quality of the course exercises. Our study is based on analyzing
students' responses to the course exercises. To identify the difficult
exercises, we applied two different approaches, the first of which involved
analyzing student responses to exercises using item response theory (IRT)
analysis and a latent trait model (LTM) technique, and the second involved
determining which exercises were more difficult based on how students
interacted with them. We computed different measures for every exercise such
that difficulty level, trial and error, and hint ratio. We generated an item
characteristics curve, item information curve, and test information function
for each exercise. To evaluate the quality of the exercises, we applied the IRT
analysis to the students' responses to the exercises and, we computed the
difficulty and discrimination index for each exercise. We classified whether
the exercise is good or poor based on these two measures. Our findings showed
that the exercises that related to algorithm analysis topics represented most
of the difficult exercises that students struggle with, and there existing six
exercises out of 56 exercises are classified as poor exercises which could be
rejected or improved. Some of these poor exercises do not differentiate between
students with different abilities; the others give preference to low-ability
students to answer these exercises over high-ability students.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Elrahman_A/0/1/0/all/0/1">Ahmed Abd Elrahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Soliman_T/0/1/0/all/0/1">Taysir Hassan A Soliman</a>, <a href="http://arxiv.org/find/cs/1/au:+Farghally_M/0/1/0/all/0/1">Mohammed F. Farghally</a>, <a href="http://arxiv.org/find/cs/1/au:+Taloba_A/0/1/0/all/0/1">Ahmed I. Taloba</a></p><p>The growing dependence on eTextbooks and Massive Open Online Courses (MOOCs)
has led to an increase in the amount of students' learning data. By carefully
analyzing this data, educators can identify difficult exercises, and evaluate
the quality of the exercises when teaching a particular topic. In this study,
an analysis of log data from the use of a semester of the OpenDSA eTextbook was
offered to identify the most difficult data structure course exercises and to
evaluate the quality of the course exercises. Our study is based on analyzing
students' responses to the course exercises. To identify the difficult
exercises, we applied two different approaches, the first of which involved
analyzing student responses to exercises using item response theory (IRT)
analysis and a latent trait model (LTM) technique, and the second involved
determining which exercises were more difficult based on how students
interacted with them. We computed different measures for every exercise such
that difficulty level, trial and error, and hint ratio. We generated an item
characteristics curve, item information curve, and test information function
for each exercise. To evaluate the quality of the exercises, we applied the IRT
analysis to the students' responses to the exercises and, we computed the
difficulty and discrimination index for each exercise. We classified whether
the exercise is good or poor based on these two measures. Our findings showed
that the exercises that related to algorithm analysis topics represented most
of the difficult exercises that students struggle with, and there existing six
exercises out of 56 exercises are classified as poor exercises which could be
rejected or improved. Some of these poor exercises do not differentiate between
students with different abilities; the others give preference to low-ability
students to answer these exercises over high-ability students.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T00:30:00Z">Wednesday, October 12 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05385'>Enhancing Branch-and-Bound for Multi-Objective 0-1 Programming</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Nicolas Forget, Sophie N. Parragh</p><p>In the bi-objective branch-and-bound literature, a key ingredient is
objective branching, i.e. to create smaller and disjoint sub-problems in the
objective space, obtained from the partial dominance of the lower bound set by
the upper bound set. When considering three or more objective functions,
however, applying objective branching becomes more complex, and its benefit has
so far been unclear. In this paper, we investigate several ingredients which
allow to better exploit objective branching in a multi-objective setting. We
extend the idea of probing to multiple objectives, enhance it in several ways,
and show that when coupled with objective branching, it results in significant
speed-ups in terms of CPU times. We also investigate cut generation based on
the objective branching constraints. Besides, we generalize the best-bound idea
for node selection to multiple objectives and we show that the proposed rules
outperform the, in the multi-objective literature, commonly employed
depth-first and breadth-first strategies. We also analyze problem specific
branching rules. We test the proposed ideas on available benchmark instances
for three problem classes with three and four objectives, namely the
capacitated facility location problem, the uncapacitated facility location
problem, and the knapsack problem. Our enhanced multi-objective
branch-and-bound algorithm outperforms the best existing branch-and-bound based
approach and is the first to obtain competitive and even slightly better
results than a state-of-the-art objective space search method on a subset of
the problem classes.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Forget_N/0/1/0/all/0/1">Nicolas Forget</a>, <a href="http://arxiv.org/find/cs/1/au:+Parragh_S/0/1/0/all/0/1">Sophie N. Parragh</a></p><p>In the bi-objective branch-and-bound literature, a key ingredient is
objective branching, i.e. to create smaller and disjoint sub-problems in the
objective space, obtained from the partial dominance of the lower bound set by
the upper bound set. When considering three or more objective functions,
however, applying objective branching becomes more complex, and its benefit has
so far been unclear. In this paper, we investigate several ingredients which
allow to better exploit objective branching in a multi-objective setting. We
extend the idea of probing to multiple objectives, enhance it in several ways,
and show that when coupled with objective branching, it results in significant
speed-ups in terms of CPU times. We also investigate cut generation based on
the objective branching constraints. Besides, we generalize the best-bound idea
for node selection to multiple objectives and we show that the proposed rules
outperform the, in the multi-objective literature, commonly employed
depth-first and breadth-first strategies. We also analyze problem specific
branching rules. We test the proposed ideas on available benchmark instances
for three problem classes with three and four objectives, namely the
capacitated facility location problem, the uncapacitated facility location
problem, and the knapsack problem. Our enhanced multi-objective
branch-and-bound algorithm outperforms the best existing branch-and-bound based
approach and is the first to obtain competitive and even slightly better
results than a state-of-the-art objective space search method on a subset of
the problem classes.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T00:30:00Z">Wednesday, October 12 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.05543'>Parallel solutions for preemptive makespan scheduling on two identical machines</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Leah Epstein</p><p>We consider online preemptive scheduling of jobs arriving one by one, to be
assigned to two identical machines, with the goal of makespan minimization. We
study the effect of selecting the best solution out of two independent
solutions constructed in parallel in an online fashion. Two cases are analyzed,
where one case is purely online, and in the other one jobs are presented sorted
by non-increasing sizes. We show that using two solutions rather than one
improves the performance significantly, but that an optimal solution cannot be
obtained for any constant number of solutions constructed in parallel. Our
algorithms have the best possible competitive ratios out of algorithms for each
one of the classes.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_L/0/1/0/all/0/1">Leah Epstein</a></p><p>We consider online preemptive scheduling of jobs arriving one by one, to be
assigned to two identical machines, with the goal of makespan minimization. We
study the effect of selecting the best solution out of two independent
solutions constructed in parallel in an online fashion. Two cases are analyzed,
where one case is purely online, and in the other one jobs are presented sorted
by non-increasing sizes. We show that using two solutions rather than one
improves the performance significantly, but that an optimal solution cannot be
obtained for any constant number of solutions constructed in parallel. Our
algorithms have the best possible competitive ratios out of algorithms for each
one of the classes.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-12T00:30:00Z">Wednesday, October 12 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Tuesday, October 11
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://ptreview.sublinear.info/2022/10/news-for-september-2022/'>News for September 2022</a></h3>
          <p class='item-feed'>from <a href='https://ptreview.sublinear.info'>Property Testing Review</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Apologies for the delay! Another quiet month in the property testing world, with only one paper (that we found). If we missed any, let us know in the comments! On Interactive Proofs of Proximity with Proof-Oblivious Queries, by Oded Goldreich, Guy Rothblum, and Tal Skverer (ECCC). Interactive Proofs of Proximity (IPPs) are the &#8220;interactive&#8221; version [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Apologies for the delay! Another quiet month in the property testing world, with only one paper (that we found). If we missed any, let us know in the comments!</p>



<p><strong>On Interactive Proofs of Proximity with Proof-Oblivious Queries</strong>, by Oded Goldreich, Guy Rothblum, and Tal Skverer (<a href="https://eccc.weizmann.ac.il/report/2022/124/">ECCC</a>). Interactive Proofs of Proximity (IPPs) are the &#8220;interactive&#8221; version of property testers, where the algorithm can both query the input and interact with an all-knowing (but untrusted) prover. In this work, the authors study the power of a specific and natural type of &#8220;adaptivity&#8221; for IPPs, asking what happens when the choice of queries and the interaction with the prover are independent, or restricted. That is, what happens when these two aspects of the IPP algorithm are in separate &#8220;modules&#8221;? Can we still test various properties as efficiently? The paper proves various results in under several models (=restrictions between the two &#8220;modules&#8221;), focusing on the intermediate restriction where the two modules (queries to the input and interaction with the prover) are separate (no interaction), but have access to shared randomness.</p>



<p></p>
<p class="authors">By Clement Canonne</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T23:31:03Z">Tuesday, October 11 2022, 23:31</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/10/11/principal-researcher-postdoctoral-at-the-university-of-chicago-apply-by-january-14-2023/'>Principal Researcher (postdoctoral) at The University of Chicago (apply by January 14, 2023)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The candidate will be given the opportunity to pursue a broad research agenda with Prof. Bryon Aragam at the intersection of statistics and machine learning and will ideally have a background in at least one of the following areas: latent variable models, deep generative models, causal inference, nonparametric statistics, learning theory, or graphical models. Website: [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The candidate will be given the opportunity to pursue a broad research agenda with Prof. Bryon Aragam at the intersection of statistics and machine learning and will ideally have a background in at least one of the following areas: latent variable models, deep generative models, causal inference, nonparametric statistics, learning theory, or graphical models.</p>
<p>Website: <a href="https://www.chicagobooth.edu/-/media/faculty/research-professional-program/job-ads/2022-23/principal_researcher_aragam_announcement_2022.pdf">https://www.chicagobooth.edu/-/media/faculty/research-professional-program/job-ads/2022-23/principal_researcher_aragam_announcement_2022.pdf</a><br />
Email: bryon@chicagobooth.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T19:39:19Z">Tuesday, October 11 2022, 19:39</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://gilkalai.wordpress.com/2022/10/11/test-your-intuition-51/'>Test Your intuition 51</a></h3>
          <p class='item-feed'>from <a href='https://gilkalai.wordpress.com'>Gil Kalai</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Suppose that and are two compact convex sets in space. Suppose that contains . Now consider two quantities is the average volume of a simplex forms by four points in drawn uniformly at random. is the average volume of a &#8230; Continue reading &#8594;
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p></p>



<p></p>


<p>Suppose that <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> are two compact convex sets in space. Suppose that <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> <span style="color:#0000ff;"><strong>contains</strong></span> <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" />. Now consider two quantities</p>
<ul>
<li><img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="X" class="latex" /> is the average volume of a simplex forms by four points in <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="K" class="latex" /> drawn uniformly at random.</li>
<li><img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="Y" class="latex" /> is the average volume of a simplex forms by four points in <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" srcset="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002 1x, https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002&#038;zoom=4.5 4x" alt="L" class="latex" /> drawn uniformly at random.</li>
</ul>
<h3>TYI: Is it always the case that X â¥ Y?</h3><p class="authors">By Gil Kalai</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T09:05:53Z">Tuesday, October 11 2022, 09:05</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/10/11/postdoc-at-technion-apply-by-december-31-2022/'>Postdoc  at Technion (apply by December 31, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          Candidates with a strong publication record in top venues in distributed computing (broadly interpreted) or algorithms in general are welcome to apply. To apply, send the following to Mrs. Hila Mizrahi at hilamiz@cs.technion.ac.il: 1. CV (PDF) 2. 1-2 page research statement (PDF) 3. Contact details of 3 references (email plaintext) 4. Expected graduation date, if [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>Candidates with a strong publication record in top venues in distributed computing (broadly interpreted) or algorithms in general are welcome to apply. To apply, send the following to Mrs. Hila Mizrahi at hilamiz@cs.technion.ac.il: 1. CV (PDF)<br />
2. 1-2 page research statement (PDF)<br />
3. Contact details of 3 references (email plaintext)<br />
4. Expected graduation date, if applicable (email plaintext)</p>
<p>Website: <a href="https://ckeren.net.technion.ac.il/">https://ckeren.net.technion.ac.il/</a><br />
Email: hilamiz@cs.technion.ac.il</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T08:13:20Z">Tuesday, October 11 2022, 08:13</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03839'>Edge deletion to tree-like graph classes</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Ivo Koch, Nina Pardal, Vinicius Fernandes dos Santos</p><p>For a fixed property (graph class) $\Pi$, given a graph $G$ and an integer
$k$, the $\Pi$-deletion problem consists in deciding if we can turn $G$ into a
graph with the property $\Pi$ by deleting at most $k$ edges of $G$. The
$\Pi$-deletion problem is known to be NP-hard for most of the well-studied
graph classes (such as chordal, interval, bipartite, planar, comparability and
permutation graphs, among others), with the notable exception of trees.
Motivated by this fact, in this work we study the deletion problem for some
classes close to trees. We obtain NP-hardness results for several classes of
sparse graphs, for which we prove that deletion is hard even when the input is
a bipartite graph. In addition, we give sufficient structural conditions for
the graph class $\Pi$ for NP-hardness. In the case of deletion to cactus, we
show that the problem becomes tractable when the input is chordal, and we give
polynomial-time algorithms for quasi-threshold graphs.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Koch_I/0/1/0/all/0/1">Ivo Koch</a>, <a href="http://arxiv.org/find/cs/1/au:+Pardal_N/0/1/0/all/0/1">Nina Pardal</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_V/0/1/0/all/0/1">Vinicius Fernandes dos Santos</a></p><p>For a fixed property (graph class) $\Pi$, given a graph $G$ and an integer
$k$, the $\Pi$-deletion problem consists in deciding if we can turn $G$ into a
graph with the property $\Pi$ by deleting at most $k$ edges of $G$. The
$\Pi$-deletion problem is known to be NP-hard for most of the well-studied
graph classes (such as chordal, interval, bipartite, planar, comparability and
permutation graphs, among others), with the notable exception of trees.
Motivated by this fact, in this work we study the deletion problem for some
classes close to trees. We obtain NP-hardness results for several classes of
sparse graphs, for which we prove that deletion is hard even when the input is
a bipartite graph. In addition, we give sufficient structural conditions for
the graph class $\Pi$ for NP-hardness. In the case of deletion to cactus, we
show that the problem becomes tractable when the input is chordal, and we give
polynomial-time algorithms for quasi-threshold graphs.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03934'>Automata Equipped with Auxiliary Data Structures and Regular Realizability Problems</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Alexander Rubtsov, Mikhail Vyalyi</p><p>We consider general computational models: one-way and two-way finite
automata, and logarithmic space Turing machines, all equipped with an auxiliary
data structure (ADS). The definition of an ADS is based on the language of
protocols of work with the ADS. We describe the connection of automata-based
models with ``Balloon automata'' that are another general formalization of
automata equipped with an ADS presented by Hopcroft and Ullman in 1967.
</p>
<p>This definition establishes the connection between the non-emptiness problem
for one-way automata with ADS, languages recognizable by nondeterministic
log-space Turing machines equipped with the same ADS, and a regular
realizability problem (NRR) for the language of ADS' protocols. The NRR problem
is to verify whether the regular language on the input has a non-empty
intersection with the language of protocols. The computational complexity of
these problems (and languages) is the same up to log-space reductions.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Rubtsov_A/0/1/0/all/0/1">Alexander Rubtsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Vyalyi_M/0/1/0/all/0/1">Mikhail Vyalyi</a></p><p>We consider general computational models: one-way and two-way finite
automata, and logarithmic space Turing machines, all equipped with an auxiliary
data structure (ADS). The definition of an ADS is based on the language of
protocols of work with the ADS. We describe the connection of automata-based
models with ``Balloon automata'' that are another general formalization of
automata equipped with an ADS presented by Hopcroft and Ullman in 1967.
</p>
<p>This definition establishes the connection between the non-emptiness problem
for one-way automata with ADS, languages recognizable by nondeterministic
log-space Turing machines equipped with the same ADS, and a regular
realizability problem (NRR) for the language of ADS' protocols. The NRR problem
is to verify whether the regular language on the input has a non-empty
intersection with the language of protocols. The computational complexity of
these problems (and languages) is the same up to log-space reductions.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.04045'>The FBHHRBNRSSSHK-Algorithm for Multiplication in $\mathbb{Z}_2^{5\times5}$ is still not the end of the story 2</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Manuel Kauers, Jakob Moosbauer</p><p>In response to a recent Nature article which announced an algorithm for
multiplying $5\times5$-matrices over $\mathbb{Z}_2$ with only 96
multiplications, two fewer than the previous record, we present an algorithm
that does the job with only 95 multiplications.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Kauers_M/0/1/0/all/0/1">Manuel Kauers</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosbauer_J/0/1/0/all/0/1">Jakob Moosbauer</a></p><p>In response to a recent Nature article which announced an algorithm for
multiplying $5\times5$-matrices over $\mathbb{Z}_2$ with only 96
multiplications, two fewer than the previous record, we present an algorithm
that does the job with only 95 multiplications.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03964'>An Efficient and Continuous Voronoi Density Estimator</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Giovanni Luca Marchetti, Vladislav Polianskii, Anastasiia Varava, Florian T. Pokorny, Danica Kragic</p><p>We introduce a non-parametric density estimator deemed Radial Voronoi Density
Estimator (RVDE). RVDE is grounded in the geometry of Voronoi tessellations and
as such benefits from local geometric adaptiveness and broad convergence
properties. Due to its radial definition RVDE is moreover continuous and
computable in linear time with respect to the dataset size. This amends for the
main shortcomings of previously studied VDEs, which are highly discontinuous
and computationally expensive. We provide a theoretical study of the modes of
RVDE as well as an empirical investigation of its performance on
high-dimensional data. Results show that RVDE outperforms other non-parametric
density estimators, including recently introduced VDEs.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/stat/1/au:+Marchetti_G/0/1/0/all/0/1">Giovanni Luca Marchetti</a>, <a href="http://arxiv.org/find/stat/1/au:+Polianskii_V/0/1/0/all/0/1">Vladislav Polianskii</a>, <a href="http://arxiv.org/find/stat/1/au:+Varava_A/0/1/0/all/0/1">Anastasiia Varava</a>, <a href="http://arxiv.org/find/stat/1/au:+Pokorny_F/0/1/0/all/0/1">Florian T. Pokorny</a>, <a href="http://arxiv.org/find/stat/1/au:+Kragic_D/0/1/0/all/0/1">Danica Kragic</a></p><p>We introduce a non-parametric density estimator deemed Radial Voronoi Density
Estimator (RVDE). RVDE is grounded in the geometry of Voronoi tessellations and
as such benefits from local geometric adaptiveness and broad convergence
properties. Due to its radial definition RVDE is moreover continuous and
computable in linear time with respect to the dataset size. This amends for the
main shortcomings of previously studied VDEs, which are highly discontinuous
and computationally expensive. We provide a theoretical study of the modes of
RVDE as well as an empirical investigation of its performance on
high-dimensional data. Results show that RVDE outperforms other non-parametric
density estimators, including recently introduced VDEs.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.04090'>APUD(1,1) Recognition in Polynomial Time</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Deniz A&#x11f;ao&#x11f;lu &#xc7;a&#x11f;&#x131;r&#x131;c&#x131;, Onur &#xc7;a&#x11f;&#x131;r&#x131;c&#x131;</p><p>A unit disk graph is the intersection graph of a set of disk of unit radius
in the Euclidean plane. In 1998, Breu and Kirkpatrick showed that the
recognition problem for unit disk graphs is NP-hard. Given $k$ horizontal and
$m$ vertical lines, an APUD($k,m$) is a unit disk graph such that each unit
disk is centered either on a given horizontal or vertical line.
\c{C}a\u{g}{\i}r{\i}c{\i} showed in 2020 that APUD($k,m$) recognition is
NP-hard. In this paper, we show that APUD($1,1$) recognition is polynomial time
solvable.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Cagirici_D/0/1/0/all/0/1">Deniz A&#x11f;ao&#x11f;lu &#xc7;a&#x11f;&#x131;r&#x131;c&#x131;</a>, <a href="http://arxiv.org/find/cs/1/au:+Cagirici_O/0/1/0/all/0/1">Onur &#xc7;a&#x11f;&#x131;r&#x131;c&#x131;</a></p><p>A unit disk graph is the intersection graph of a set of disk of unit radius
in the Euclidean plane. In 1998, Breu and Kirkpatrick showed that the
recognition problem for unit disk graphs is NP-hard. Given $k$ horizontal and
$m$ vertical lines, an APUD($k,m$) is a unit disk graph such that each unit
disk is centered either on a given horizontal or vertical line.
\c{C}a\u{g}{\i}r{\i}c{\i} showed in 2020 that APUD($k,m$) recognition is
NP-hard. In this paper, we show that APUD($1,1$) recognition is polynomial time
solvable.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.04099'>Developable Quad Meshes</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CG/recent'>arXiv: Computational Geometry</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Victor Ceballos Inza, Florian Rist, Johannes Wallner, Helmut Pottmann</p><p>There are different ways to capture the property of a surface being
developable, i.e., it can be mapped to a planar domain without stretching or
tearing. Contributions range from special parametrizations to
discrete-isometric mappings. So far, a local criterion expressing the
developability of general quad meshes has been lacking. In this paper, we
propose a new and efficient discrete developability criterion that is based on
a property well-known from differential geometry, namely a rank-deficient
second fundamental form. This criterion is expressed in terms of the canonical
checkerboard patterns inscribed in a quad mesh which already was successful in
describing discrete-isometric mappings. In combination with standard global
optimization procedures, we are able to perform developable lofting,
approximation, and design. The meshes we employ are combinatorially regular
quad meshes with isolated singularities but are otherwise not required to
follow any special curves. They are thus easily embedded into a design workflow
involving standard operations like re-meshing, trimming, and merging
operations.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Inza_V/0/1/0/all/0/1">Victor Ceballos Inza</a>, <a href="http://arxiv.org/find/cs/1/au:+Rist_F/0/1/0/all/0/1">Florian Rist</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallner_J/0/1/0/all/0/1">Johannes Wallner</a>, <a href="http://arxiv.org/find/cs/1/au:+Pottmann_H/0/1/0/all/0/1">Helmut Pottmann</a></p><p>There are different ways to capture the property of a surface being
developable, i.e., it can be mapped to a planar domain without stretching or
tearing. Contributions range from special parametrizations to
discrete-isometric mappings. So far, a local criterion expressing the
developability of general quad meshes has been lacking. In this paper, we
propose a new and efficient discrete developability criterion that is based on
a property well-known from differential geometry, namely a rank-deficient
second fundamental form. This criterion is expressed in terms of the canonical
checkerboard patterns inscribed in a quad mesh which already was successful in
describing discrete-isometric mappings. In combination with standard global
optimization procedures, we are able to perform developable lofting,
approximation, and design. The meshes we employ are combinatorially regular
quad meshes with isolated singularities but are otherwise not required to
follow any special curves. They are thus easily embedded into a design workflow
involving standard operations like re-meshing, trimming, and merging
operations.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03932'>A Finite Algorithm for the Realizabilty of a Delaunay Triangulation</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Akanksha Agrawal, Saket Saurabh, Meirav Zehavi</p><p>The \emph{Delaunay graph} of a point set $P \subseteq \mathbb{R}^2$ is the
plane graph with the vertex-set $P$ and the edge-set that contains $\{p,p'\}$
if there exists a disc whose intersection with $P$ is exactly $\{p,p'\}$.
Accordingly, a triangulated graph $G$ is \emph{Delaunay realizable} if there
exists a triangulation of the Delaunay graph of some $P \subseteq
\mathbb{R}^2$, called a \emph{Delaunay triangulation} of $P$, that is
isomorphic to $G$. The objective of \textsc{Delaunay Realization} is to compute
a point set $P \subseteq \mathbb{R}^2$ that realizes a given graph $G$ (if such
a $P$ exists). Known algorithms do not solve \textsc{Delaunay Realization} as
they are non-constructive. Obtaining a constructive algorithm for
\textsc{Delaunay Realization} was mentioned as an open problem by Hiroshima et
al.~\cite{hiroshima2000}. We design an $n^{\mathcal{O}(n)}$-time constructive
algorithm for \textsc{Delaunay Realization}. In fact, our algorithm outputs
sets of points with {\em integer} coordinates.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Akanksha Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Saurabh_S/0/1/0/all/0/1">Saket Saurabh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zehavi_M/0/1/0/all/0/1">Meirav Zehavi</a></p><p>The \emph{Delaunay graph} of a point set $P \subseteq \mathbb{R}^2$ is the
plane graph with the vertex-set $P$ and the edge-set that contains $\{p,p'\}$
if there exists a disc whose intersection with $P$ is exactly $\{p,p'\}$.
Accordingly, a triangulated graph $G$ is \emph{Delaunay realizable} if there
exists a triangulation of the Delaunay graph of some $P \subseteq
\mathbb{R}^2$, called a \emph{Delaunay triangulation} of $P$, that is
isomorphic to $G$. The objective of \textsc{Delaunay Realization} is to compute
a point set $P \subseteq \mathbb{R}^2$ that realizes a given graph $G$ (if such
a $P$ exists). Known algorithms do not solve \textsc{Delaunay Realization} as
they are non-constructive. Obtaining a constructive algorithm for
\textsc{Delaunay Realization} was mentioned as an open problem by Hiroshima et
al.~\cite{hiroshima2000}. We design an $n^{\mathcal{O}(n)}$-time constructive
algorithm for \textsc{Delaunay Realization}. In fact, our algorithm outputs
sets of points with {\em integer} coordinates.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03811'>An Approximation Algorithm for Distance-Constrained Vehicle Routing on Trees</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Marc Dufay, Claire Mathieu, Hang Zhou</p><p>In the Distance-constrained Vehicle Routing Problem (DVRP), we are given a
graph with integer edge weights, a depot, a set of $n$ terminals, and a
distance constraint $D$. The goal is to find a minimum number of tours starting
and ending at the depot such that those tours together cover all the terminals
and the length of each tour is at most $D$.
</p>
<p>The DVRP on trees is of independent interest, because it is equivalent to the
virtual machine packing problem on trees studied by Sindelar et al. [SPAA'11].
We design a simple and natural approximation algorithm for the tree DVRP,
parameterized by $\varepsilon &gt;0$. We show that its approximation ratio is
$\alpha + \varepsilon$, where $\alpha \approx 1.691$, and in addition, that our
analysis is essentially tight. The running time is polynomial in $n$ and $D$.
The approximation ratio improves on the ratio of 2 due to Nagarajan and Ravi
[Networks'12].
</p>
<p>The main novelty of this paper lies in the analysis of the algorithm. It
relies on a reduction from the tree DVRP to the bounded space online bin
packing problem via a new notion of reduced length.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Dufay_M/0/1/0/all/0/1">Marc Dufay</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathieu_C/0/1/0/all/0/1">Claire Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hang Zhou</a></p><p>In the Distance-constrained Vehicle Routing Problem (DVRP), we are given a
graph with integer edge weights, a depot, a set of $n$ terminals, and a
distance constraint $D$. The goal is to find a minimum number of tours starting
and ending at the depot such that those tours together cover all the terminals
and the length of each tour is at most $D$.
</p>
<p>The DVRP on trees is of independent interest, because it is equivalent to the
virtual machine packing problem on trees studied by Sindelar et al. [SPAA'11].
We design a simple and natural approximation algorithm for the tree DVRP,
parameterized by $\varepsilon &gt;0$. We show that its approximation ratio is
$\alpha + \varepsilon$, where $\alpha \approx 1.691$, and in addition, that our
analysis is essentially tight. The running time is polynomial in $n$ and $D$.
The approximation ratio improves on the ratio of 2 due to Nagarajan and Ravi
[Networks'12].
</p>
<p>The main novelty of this paper lies in the analysis of the algorithm. It
relies on a reduction from the tree DVRP to the bounded space online bin
packing problem via a new notion of reduced length.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03831'>How to Make Your Approximation Algorithm Private: A Black-Box Differentially-Private Transformation for Tunable Approximation Algorithms of Functions with Low Sensitivity</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Jeremiah Blocki, Elena Grigorescu, Tamalika Mukherjee, Samson Zhou</p><p>We develop a framework for efficiently transforming certain approximation
algorithms into differentially-private variants, in a black-box manner. Our
results focus on algorithms A that output an approximation to a function f of
the form $(1-a)f(x)-k &lt;= A(x) &lt;= (1+a)f(x)+k$, where 0&lt;=a &lt;1 is a parameter
that can be``tuned" to small-enough values while incurring only a poly blowup
in the running time/space. We show that such algorithms can be made DP without
sacrificing accuracy, as long as the function f has small global sensitivity.
We achieve these results by applying the smooth sensitivity framework developed
by Nissim, Raskhodnikova, and Smith (STOC 2007).
</p>
<p>Our framework naturally applies to transform non-private FPRAS (resp. FPTAS)
algorithms into $(\epsilon,\delta)$-DP (resp. $\epsilon$-DP) approximation
algorithms. We apply our framework in the context of sublinear-time and
sublinear-space algorithms, while preserving the nature of the algorithm in
meaningful ranges of the parameters. Our results include the first (to the best
of our knowledge) $(\epsilon,\delta)$-edge DP sublinear-time algorithm for
estimating the number of triangles, the number of connected components, and the
weight of a MST of a graph, as well as a more efficient algorithm (while
sacrificing pure DP in contrast to previous results) for estimating the average
degree of a graph. In the area of streaming algorithms, our results include
$(\epsilon,\delta)$-DP algorithms for estimating L_p-norms, distinct elements,
and weighted MST for both insertion-only and turnstile streams. Our
transformation also provides a private version of the smooth histogram
framework, which is commonly used for converting streaming algorithms into
sliding window variants, and achieves a multiplicative approximation to many
problems, such as estimating L_p-norms, distinct elements, and the length of
the longest increasing subsequence.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Blocki_J/0/1/0/all/0/1">Jeremiah Blocki</a>, <a href="http://arxiv.org/find/cs/1/au:+Grigorescu_E/0/1/0/all/0/1">Elena Grigorescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_T/0/1/0/all/0/1">Tamalika Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Samson Zhou</a></p><p>We develop a framework for efficiently transforming certain approximation
algorithms into differentially-private variants, in a black-box manner. Our
results focus on algorithms A that output an approximation to a function f of
the form $(1-a)f(x)-k &lt;= A(x) &lt;= (1+a)f(x)+k$, where 0&lt;=a &lt;1 is a parameter
that can be``tuned" to small-enough values while incurring only a poly blowup
in the running time/space. We show that such algorithms can be made DP without
sacrificing accuracy, as long as the function f has small global sensitivity.
We achieve these results by applying the smooth sensitivity framework developed
by Nissim, Raskhodnikova, and Smith (STOC 2007).
</p>
<p>Our framework naturally applies to transform non-private FPRAS (resp. FPTAS)
algorithms into $(\epsilon,\delta)$-DP (resp. $\epsilon$-DP) approximation
algorithms. We apply our framework in the context of sublinear-time and
sublinear-space algorithms, while preserving the nature of the algorithm in
meaningful ranges of the parameters. Our results include the first (to the best
of our knowledge) $(\epsilon,\delta)$-edge DP sublinear-time algorithm for
estimating the number of triangles, the number of connected components, and the
weight of a MST of a graph, as well as a more efficient algorithm (while
sacrificing pure DP in contrast to previous results) for estimating the average
degree of a graph. In the area of streaming algorithms, our results include
$(\epsilon,\delta)$-DP algorithms for estimating L_p-norms, distinct elements,
and weighted MST for both insertion-only and turnstile streams. Our
transformation also provides a private version of the smooth histogram
framework, which is commonly used for converting streaming algorithms into
sliding window variants, and achieves a multiplicative approximation to many
problems, such as estimating L_p-norms, distinct elements, and the length of
the longest increasing subsequence.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03961'>Dynamic Tensor Product Regression</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Aravind Reddy, Zhao Song, Lichen Zhang</p><p>In this work, we initiate the study of \emph{Dynamic Tensor Product
Regression}. One has matrices $A_1\in \mathbb{R}^{n_1\times d_1},\ldots,A_q\in
\mathbb{R}^{n_q\times d_q}$ and a label vector $b\in \mathbb{R}^{n_1\ldots
n_q}$, and the goal is to solve the regression problem with the design matrix
$A$ being the tensor product of the matrices $A_1, A_2, \dots, A_q$ i.e.
$\min_{x\in \mathbb{R}^{d_1\ldots d_q}}~\|(A_1\otimes \ldots\otimes
A_q)x-b\|_2$. At each time step, one matrix $A_i$ receives a sparse change, and
the goal is to maintain a sketch of the tensor product $A_1\otimes\ldots
\otimes A_q$ so that the regression solution can be updated quickly.
Recomputing the solution from scratch for each round is very slow and so it is
important to develop algorithms which can quickly update the solution with the
new design matrix. Our main result is a dynamic tree data structure where any
update to a single matrix can be propagated quickly throughout the tree. We
show that our data structure can be used to solve dynamic versions of not only
Tensor Product Regression, but also Tensor Product Spline regression (which is
a generalization of ridge regression) and for maintaining Low Rank
Approximations for the tensor product.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Reddy_A/0/1/0/all/0/1">Aravind Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lichen Zhang</a></p><p>In this work, we initiate the study of \emph{Dynamic Tensor Product
Regression}. One has matrices $A_1\in \mathbb{R}^{n_1\times d_1},\ldots,A_q\in
\mathbb{R}^{n_q\times d_q}$ and a label vector $b\in \mathbb{R}^{n_1\ldots
n_q}$, and the goal is to solve the regression problem with the design matrix
$A$ being the tensor product of the matrices $A_1, A_2, \dots, A_q$ i.e.
$\min_{x\in \mathbb{R}^{d_1\ldots d_q}}~\|(A_1\otimes \ldots\otimes
A_q)x-b\|_2$. At each time step, one matrix $A_i$ receives a sparse change, and
the goal is to maintain a sketch of the tensor product $A_1\otimes\ldots
\otimes A_q$ so that the regression solution can be updated quickly.
Recomputing the solution from scratch for each round is very slow and so it is
important to develop algorithms which can quickly update the solution with the
new design matrix. Our main result is a dynamic tree data structure where any
update to a single matrix can be propagated quickly throughout the tree. We
show that our data structure can be used to solve dynamic versions of not only
Tensor Product Regression, but also Tensor Product Spline regression (which is
a generalization of ridge regression) and for maintaining Low Rank
Approximations for the tensor product.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.04059'>Order Selection Problems in Hiring Pipelines</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Boris Epstein, Will Ma (Columbia University)</p><p>Motivated by hiring pipelines, we study two order selection problems in which
applicants for a finite set of positions must be interviewed or made offers
sequentially. There is a finite time budget for interviewing or making offers,
and a stochastic realization after each decision, leading to
computationally-challenging problems. In the first problem we study sequential
interviewing, and show that a computationally-tractable, non-adaptive policy
that must make offers immediately after interviewing is approximately optimal,
assuming offerees always accept their offers. In the second problem, we assume
that applicants have already been interviewed but only accept offers with some
probability; we develop a computationally-tractable policy that makes offers
for the different positions in parallel, which is approximately optimal even
relative to a policy that does not need to make parallel offers. Our two
results both generalize and improve the guarantees in the work of Purohit et
al. on hiring algorithms, from 1/2 and 1/4 to approximation factors that are at
least 1-1/e.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Epstein_B/0/1/0/all/0/1">Boris Epstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Will Ma</a> (Columbia University)</p><p>Motivated by hiring pipelines, we study two order selection problems in which
applicants for a finite set of positions must be interviewed or made offers
sequentially. There is a finite time budget for interviewing or making offers,
and a stochastic realization after each decision, leading to
computationally-challenging problems. In the first problem we study sequential
interviewing, and show that a computationally-tractable, non-adaptive policy
that must make offers immediately after interviewing is approximately optimal,
assuming offerees always accept their offers. In the second problem, we assume
that applicants have already been interviewed but only accept offers with some
probability; we develop a computationally-tractable policy that makes offers
for the different positions in parallel, which is approximately optimal even
relative to a policy that does not need to make parallel offers. Our two
results both generalize and improve the guarantees in the work of Purohit et
al. on hiring algorithms, from 1/2 and 1/4 to approximation factors that are at
least 1-1/e.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.04068'>IcebergHT: High Performance PMEM Hash Tables Through Stability and Low Associativity</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Prashant Pandey, Michael A. Bender, Alex Conway, Mart&#xed;n Farach-Colton, William Kuszmaul, Guido Tagliavini, Rob Johnson</p><p>Modern hash table designs strive to minimize space while maximizing speed.
The most important factor in speed is the number of cache lines accessed during
updates and queries. This is especially important on PMEM, which is slower than
DRAM and in which writes are more expensive than reads. This paper proposes two
stronger design objectives: stability and low-associativity. A stable hash
table doesn't move items around, and a hash table has low associativity if
there are only a few locations where an item can be stored. Low associativity
ensures that queries need to examine only a few memory locations, and stability
ensures that insertions write to very few cache lines. Stability also
simplifies scaling and crash safety.
</p>
<p>We present IcebergHT, a fast, crash-safe, concurrent, and space-efficient
hash table for PMEM based on the design principles of stability and low
associativity. IcebergHT combines in-memory metadata with a new hashing
technique, iceberg hashing, that is (1) space efficient, (2) stable, and (3)
supports low associativity. In contrast, existing hash-tables either modify
numerous cache lines during insertions (e.g. cuckoo hashing), access numerous
cache lines during queries (e.g. linear probing), or waste space (e.g.
chaining). Moreover, the combination of (1)-(3) yields several emergent
benefits: IcebergHT scales better than other hash tables, supports
crash-safety, and has excellent performance on PMEM (where writes are
particularly expensive).
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Pandey_P/0/1/0/all/0/1">Prashant Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Bender_M/0/1/0/all/0/1">Michael A. Bender</a>, <a href="http://arxiv.org/find/cs/1/au:+Conway_A/0/1/0/all/0/1">Alex Conway</a>, <a href="http://arxiv.org/find/cs/1/au:+Farach_Colton_M/0/1/0/all/0/1">Mart&#xed;n Farach-Colton</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuszmaul_W/0/1/0/all/0/1">William Kuszmaul</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliavini_G/0/1/0/all/0/1">Guido Tagliavini</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_R/0/1/0/all/0/1">Rob Johnson</a></p><p>Modern hash table designs strive to minimize space while maximizing speed.
The most important factor in speed is the number of cache lines accessed during
updates and queries. This is especially important on PMEM, which is slower than
DRAM and in which writes are more expensive than reads. This paper proposes two
stronger design objectives: stability and low-associativity. A stable hash
table doesn't move items around, and a hash table has low associativity if
there are only a few locations where an item can be stored. Low associativity
ensures that queries need to examine only a few memory locations, and stability
ensures that insertions write to very few cache lines. Stability also
simplifies scaling and crash safety.
</p>
<p>We present IcebergHT, a fast, crash-safe, concurrent, and space-efficient
hash table for PMEM based on the design principles of stability and low
associativity. IcebergHT combines in-memory metadata with a new hashing
technique, iceberg hashing, that is (1) space efficient, (2) stable, and (3)
supports low associativity. In contrast, existing hash-tables either modify
numerous cache lines during insertions (e.g. cuckoo hashing), access numerous
cache lines during queries (e.g. linear probing), or waste space (e.g.
chaining). Moreover, the combination of (1)-(3) yields several emergent
benefits: IcebergHT scales better than other hash tables, supports
crash-safety, and has excellent performance on PMEM (where writes are
particularly expensive).
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-11T00:30:00Z">Tuesday, October 11 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Monday, October 10
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/10/10/three-year-and-tenure-track-positions-at-ttic-apply-by-december-1-2022/'>THREE-YEAR AND TENURE-TRACK POSITIONS at TTIC (apply by December 1, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          TTIC invites applications for the following faculty positions: research assistant professor (3-year term), tenure-track assistant professor, full or associate professor, and visiting professor. Applicants for research assistant professor positions (RAPs) are encouraged to simultaneously apply for the TTIC RAP program and the Simons-Berkeley Research Fellowship. Website: www.ttic.edu/faculty-hiring/ Email: recruiting@ttic.edu
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>TTIC invites applications for the following faculty positions: research assistant professor (3-year term), tenure-track assistant professor, full or associate professor, and visiting professor. Applicants for research assistant professor positions (RAPs) are encouraged to simultaneously apply for the TTIC RAP program and the Simons-Berkeley Research Fellowship.</p>
<p>Website: <a href="https://www.ttic.edu/faculty-hiring/">https://www.ttic.edu/faculty-hiring/</a><br />
Email: recruiting@ttic.edu</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-10T18:07:37Z">Monday, October 10 2022, 18:07</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/10/10/lecturer-in-verification-at-university-of-sheffield-apply-by-october-14-2022/'>Lecturer in Verification at University of Sheffield (apply by October 14, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          We seek candidates with an outstanding record in the logical and mathematical foundations of computing, including hardware and software verification. You will work within the Verification Group, a well-established group in the Department of Computer Science. Our research range from the mathematical and logical foundations of computing to practical verification methods and tools to support [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>We seek candidates with an outstanding record in the logical and mathematical foundations of computing, including hardware and software verification. You will work within the Verification Group, a well-established group in the Department of Computer Science. Our research range from the mathematical and logical foundations of computing to practical verification methods and tools to support these.</p>
<p>Website: <a href="https://www.jobs.ac.uk/job/CTU424/lecturer-in-verification">https://www.jobs.ac.uk/job/CTU424/lecturer-in-verification</a><br />
Email: g.j.brown@sheffield.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-10T12:26:03Z">Monday, October 10 2022, 12:26</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://blog.computationalcomplexity.org/2022/10/will-strassens-matrix-mult-alg-ever-be.html'>Will Strassen's Matrix Mult Alg ever be practical?</a></h3>
          <p class='item-feed'>from <a href='http://blog.computationalcomplexity.org/'>Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>All time bounds are asymptotic and really O-of.</p><p>Recall that Strassen found a clever way to multiply&nbsp; two 2x2 matrices with 7 mults (and lots of adds)&nbsp; leading to a matrix mult alg in n^{\log_2 7} = n^{2.87...}</p><p><br></p><p>Recently (see&nbsp;here) a deep-mind-AI found a way to multiply&nbsp; two 4x4 matrices with 47 mults (and lots of adds) leading to a matrix mult alg in n^{\log_4 47} = n^{2.777...}&nbsp;</p><p>Much better is known, see our blog posts&nbsp;here&nbsp;and&nbsp;here.</p><p><br></p><p>The more advanced algorithms are complicated and have large constants so will never be practical. But Strassen's result, and now the new algorithm, SEEM to me they could be practical.</p><p>(ADDED LATER- many of the comments inform me that Strassen IS practical and IS being used. Great! Now we know!)</p><p>Thoughts about Strassen that also apply to the&nbsp; new algorithm.&nbsp;</p><p>1) n has to be large for Strassen to given an improvement. But as we deal with larger data sets the value of n is getting larger.&nbsp;</p><p>2) People are mostly interested in sparse matrices for which there are better methods. I've heard that for a while- but is it still true? I thought ML used dense matrices.&nbsp;</p><p>3) Strassen is hard to code up. Actually it doesn't look that hard to code up. However, I have never tried to code it up, so maybe there are subtle points there.</p><p>4) Strassen only works on matrices of size 2^n x 2^n. You can pad matrices out but that might kill whatever time advantage you get. (The new alg only works on&nbsp; 4^n x 4^n).&nbsp;</p><p>5) Strassen uses recursion and there is the hidden cost of recursion. I think that is a think of the past and our younger readers do not know what I am talking about.&nbsp;</p><p>6) (This is obvious) the recursion would only go down to a certain level and THEN you would use ordinary Matrix Mult. This may also add time.&nbsp;</p><p><br></p><p>I suspect that 2 and 4 are the most important reasons Strassen (or the new algorithm) is not practical BUT I would like to hear your thoughts?</p><p>Does any package NOW use Strassen's Algorithm?</p><p>Side Note: I like to ask students if they think there is a better-than-cubic algorithm for Matrix Mult. They do not. Then I show it to them and tell them THIS is why LOWER BOUNDS are hard. You have to show that NO, nobody clever will find a trick you hadn't thought of.&nbsp;</p><p><br></p><p>By gasarch</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>All time bounds are asymptotic and really O-of.</p><p>Recall that Strassen found a clever way to multiply&nbsp; two 2x2 matrices with 7 mults (and lots of adds)&nbsp; leading to a matrix mult alg in n^{\log_2 7} = n^{2.87...}</p><p><br /></p><p>Recently (see&nbsp;<a href="https://www.newscientist.com/article/2340343-deepmind-ai-finds-new-way-to-multiply-numbers-and-speed-up-computers/">here</a>) a deep-mind-AI found a way to multiply&nbsp; two 4x4 matrices with 47 mults (and lots of adds) leading to a matrix mult alg in n^{\log_4 47} = n^{2.777...}&nbsp;</p><p>Much better is known, see our blog posts&nbsp;<a href="https://blog.computationalcomplexity.org/2011/11/matrix-mult-you-heard-it-here-third.html">here</a>&nbsp;and&nbsp;<a href="https://blog.computationalcomplexity.org/2015/06/when-do-we-care-about-small-improvements.html">here</a>.</p><p><br /></p><p>The more advanced algorithms are complicated and have large constants so will never be practical. But Strassen's result, and now the new algorithm, SEEM to me they could be practical.</p><p>(ADDED LATER- many of the comments inform me that Strassen IS practical and IS being used. Great! Now we know!)</p><p>Thoughts about Strassen that also apply to the&nbsp; new algorithm.&nbsp;</p><p>1) n has to be large for Strassen to given an improvement. But as we deal with larger data sets the value of n is getting larger.&nbsp;</p><p>2) People are mostly interested in sparse matrices for which there are better methods. I've heard that for a while- but is it still true? I thought ML used dense matrices.&nbsp;</p><p>3) Strassen is hard to code up. Actually it doesn't look that hard to code up. However, I have never tried to code it up, so maybe there are subtle points there.</p><p>4) Strassen only works on matrices of size 2^n x 2^n. You can pad matrices out but that might kill whatever time advantage you get. (The new alg only works on&nbsp; 4^n x 4^n).&nbsp;</p><p>5) Strassen uses recursion and there is <i>the hidden cost of recursion</i>. I think that is a think of the past and our younger readers do not know what I am talking about.&nbsp;</p><p>6) (This is obvious) the recursion would only go down to a certain level and THEN you would use ordinary Matrix Mult. This may also add time.&nbsp;</p><p><br /></p><p>I suspect that 2 and 4 are the most important reasons Strassen (or the new algorithm) is not practical BUT I would like to hear your thoughts?</p><p>Does any package NOW use Strassen's Algorithm?</p><p>Side Note: I like to ask students if they think there is a better-than-cubic algorithm for Matrix Mult. They do not. Then I show it to them and tell them THIS is why LOWER BOUNDS are hard. You have to show that NO, nobody clever will find a trick you hadn't thought of.&nbsp;</p><p><br /></p><p class="authors">By gasarch</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-10T04:03:00Z">Monday, October 10 2022, 04:03</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03553'>Treewidth-aware Reductions of Normal ASP to SAT -- Is Normal ASP Harder than SAT after All?</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Markus Hecher</p><p>Answer Set Programming (ASP) is a paradigm for modeling and solving problems
for knowledge representation and reasoning. There are plenty of results
dedicated to studying the hardness of (fragments of) ASP. So far, these studies
resulted in characterizations in terms of computational complexity as well as
in fine-grained insights presented in form of dichotomy-style results, lower
bounds when translating to other formalisms like propositional satisfiability
(SAT), and even detailed parameterized complexity landscapes. A generic
parameter in parameterized complexity originating from graph theory is the
so-called treewidth, which in a sense captures structural density of a program.
Recently, there was an increase in the number of treewidth-based solvers
related to SAT. While there are translations from (normal) ASP to SAT, no
reduction that preserves treewidth or at least keeps track of the treewidth
increase is known. In this paper we propose a novel reduction from normal ASP
to SAT that is aware of the treewidth, and guarantees that a slight increase of
treewidth is indeed sufficient. Further, we show a new result establishing
that, when considering treewidth, already the fragment of normal ASP is
slightly harder than SAT (under reasonable assumptions in computational
complexity). This also confirms that our reduction probably cannot be
significantly improved and that the slight increase of treewidth is
unavoidable. Finally, we present an empirical study of our novel reduction from
normal ASP to SAT, where we compare treewidth upper bounds that are obtained
via known decomposition heuristics. Overall, our reduction works better with
these heuristics than existing translations.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Hecher_M/0/1/0/all/0/1">Markus Hecher</a></p><p>Answer Set Programming (ASP) is a paradigm for modeling and solving problems
for knowledge representation and reasoning. There are plenty of results
dedicated to studying the hardness of (fragments of) ASP. So far, these studies
resulted in characterizations in terms of computational complexity as well as
in fine-grained insights presented in form of dichotomy-style results, lower
bounds when translating to other formalisms like propositional satisfiability
(SAT), and even detailed parameterized complexity landscapes. A generic
parameter in parameterized complexity originating from graph theory is the
so-called treewidth, which in a sense captures structural density of a program.
Recently, there was an increase in the number of treewidth-based solvers
related to SAT. While there are translations from (normal) ASP to SAT, no
reduction that preserves treewidth or at least keeps track of the treewidth
increase is known. In this paper we propose a novel reduction from normal ASP
to SAT that is aware of the treewidth, and guarantees that a slight increase of
treewidth is indeed sufficient. Further, we show a new result establishing
that, when considering treewidth, already the fragment of normal ASP is
slightly harder than SAT (under reasonable assumptions in computational
complexity). This also confirms that our reduction probably cannot be
significantly improved and that the slight increase of treewidth is
unavoidable. Finally, we present an empirical study of our novel reduction from
normal ASP to SAT, where we compare treewidth upper bounds that are obtained
via known decomposition heuristics. Overall, our reduction works better with
these heuristics than existing translations.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-10T00:30:00Z">Monday, October 10 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03343'>Boolean symmetric vs. functional PCSP dichotomy</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Tamio-Vesa Nakajima, Stanislav &#x17d;ivn&#xfd;</p><p>Given a 3-uniform hypergraph $(V,E)$ that is promised to admit a
$\{0,1\}$-colouring such that every edge contains exactly one $1$, can one find
a $d$-colouring $h:V\to \{0,1,\ldots,d-1\}$ such that $h(e)\in R$ for every
$e\in E$? This can be cast as a promise constraint satisfaction problem (PCSP)
of the form $\operatorname{PCSP}(1-in-3,\mathbf{B})$, where $\mathbf{B}$
defines the relation $R$, and is an example of
$\operatorname{PCSP}(\mathbf{A},\mathbf{B})$, where $\mathbf{A}$ (and thus wlog
also $\mathbf{B}$) is symmetric. The computational complexity of such problems
is understood for $\mathbf{A}$ and $\mathbf{B}$ on Boolean domains by the work
of Ficak, Kozik, Ol\v{s}\'{a}k, and Stankiewicz [ICALP'19].
</p>
<p>As our first result, we establish a dichotomy for
$\operatorname{PCSP}(\mathbf{A},\mathbf{B})$, where $\mathbf{A}$ is Boolean and
symmetric and $\mathbf{B}$ is functional (on a domain of any size); i.e, all
but one element of any tuple in a relation in $\mathbf{B}$ determine the last
element. This includes PCSPs of the form
$\operatorname{PCSP}(q-in-r,\mathbf{B})$, where $\mathbf{B}$ is functional,
thus making progress towards a classification of
$\operatorname{PCSP}(1-in-3,\mathbf{B})$, which were studied by Barto,
Battistelli, and Berg [STACS'21] for $\mathbf{B}$ on three-element domains.
</p>
<p>As our second result, we show that for
$\operatorname{PCSP}(\mathbf{A},\mathbf{B})$, where $\mathbf{A}$ contains a
single Boolean symmetric relation and $\mathbf{B}$ is arbitrary (and thus not
necessarily functional), the combined basic linear programmin relaxation (BLP)
and the affine integer programming relaxation (AIP) of Brakensiek et al.
[SICOMP'20] is no more powerful than the (in general strictly weaker) AIP
relaxation of Brakensiek and Guruswami [SICOMP'21].
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Nakajima_T/0/1/0/all/0/1">Tamio-Vesa Nakajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Zivny_S/0/1/0/all/0/1">Stanislav &#x17d;ivn&#xfd;</a></p><p>Given a 3-uniform hypergraph $(V,E)$ that is promised to admit a
$\{0,1\}$-colouring such that every edge contains exactly one $1$, can one find
a $d$-colouring $h:V\to \{0,1,\ldots,d-1\}$ such that $h(e)\in R$ for every
$e\in E$? This can be cast as a promise constraint satisfaction problem (PCSP)
of the form $\operatorname{PCSP}(1-in-3,\mathbf{B})$, where $\mathbf{B}$
defines the relation $R$, and is an example of
$\operatorname{PCSP}(\mathbf{A},\mathbf{B})$, where $\mathbf{A}$ (and thus wlog
also $\mathbf{B}$) is symmetric. The computational complexity of such problems
is understood for $\mathbf{A}$ and $\mathbf{B}$ on Boolean domains by the work
of Ficak, Kozik, Ol\v{s}\'{a}k, and Stankiewicz [ICALP'19].
</p>
<p>As our first result, we establish a dichotomy for
$\operatorname{PCSP}(\mathbf{A},\mathbf{B})$, where $\mathbf{A}$ is Boolean and
symmetric and $\mathbf{B}$ is functional (on a domain of any size); i.e, all
but one element of any tuple in a relation in $\mathbf{B}$ determine the last
element. This includes PCSPs of the form
$\operatorname{PCSP}(q-in-r,\mathbf{B})$, where $\mathbf{B}$ is functional,
thus making progress towards a classification of
$\operatorname{PCSP}(1-in-3,\mathbf{B})$, which were studied by Barto,
Battistelli, and Berg [STACS'21] for $\mathbf{B}$ on three-element domains.
</p>
<p>As our second result, we show that for
$\operatorname{PCSP}(\mathbf{A},\mathbf{B})$, where $\mathbf{A}$ contains a
single Boolean symmetric relation and $\mathbf{B}$ is arbitrary (and thus not
necessarily functional), the combined basic linear programmin relaxation (BLP)
and the affine integer programming relaxation (AIP) of Brakensiek et al.
[SICOMP'20] is no more powerful than the (in general strictly weaker) AIP
relaxation of Brakensiek and Guruswami [SICOMP'21].
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-10T00:30:00Z">Monday, October 10 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03166'>The Power of Greedy for Online Minimum Cost Matching on the Line</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Eric Balkanksi, Yuri Faenza, Noemie Perivier</p><p>We consider the online minimum cost matching problem on the line, in which
there are $n$ servers and, at each of $n$ time steps, a request arrives and
must be irrevocably matched to a server that has not yet been matched to, with
the goal of minimizing the sum of the distances between the matched pairs.
Despite achieving a worst-case competitive ratio that is exponential in $n$,
the simple greedy algorithm, which matches each request to its nearest
available free server, performs very well in practice. A major question is thus
to explain greedy's strong empirical performance. In this paper, we aim to
understand the performance of greedy over instances that are at least partially
random. When both the requests and the servers are drawn uniformly and
independently from $[0,1]$, we show that greedy is constant competitive, which
improves over the previously best-known $O(\sqrt{n})$ bound. We extend this
constant competitive ratio to a setting with a linear excess of servers, which
improves over the previously best-known $O(\log^3{n})$ bound. We moreover show
that in the semi-random model where the requests are still drawn uniformly and
independently but where the servers are chosen adversarially, greedy achieves
an $O(\log{n})$ competitive ratio. When the requests arrive in a random order
but are chosen adversarially, it was previously known that greedy is
$O(n)$-competitive. Even though this one-sided randomness allows a large
improvement in greedy's competitive ratio compared to the model where requests
are adversarial and arrive in a random order, we show that it is not sufficient
to obtain a constant competitive ratio by giving a tight $\Omega(\log{n})$
lower bound. These results invite further investigation about how much
randomness is necessary and sufficient to obtain strong theoretical guarantees
for the greedy algorithm for online minimum cost matching, on the line and
beyond.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Balkanksi_E/0/1/0/all/0/1">Eric Balkanksi</a>, <a href="http://arxiv.org/find/cs/1/au:+Faenza_Y/0/1/0/all/0/1">Yuri Faenza</a>, <a href="http://arxiv.org/find/cs/1/au:+Perivier_N/0/1/0/all/0/1">Noemie Perivier</a></p><p>We consider the online minimum cost matching problem on the line, in which
there are $n$ servers and, at each of $n$ time steps, a request arrives and
must be irrevocably matched to a server that has not yet been matched to, with
the goal of minimizing the sum of the distances between the matched pairs.
Despite achieving a worst-case competitive ratio that is exponential in $n$,
the simple greedy algorithm, which matches each request to its nearest
available free server, performs very well in practice. A major question is thus
to explain greedy's strong empirical performance. In this paper, we aim to
understand the performance of greedy over instances that are at least partially
random. When both the requests and the servers are drawn uniformly and
independently from $[0,1]$, we show that greedy is constant competitive, which
improves over the previously best-known $O(\sqrt{n})$ bound. We extend this
constant competitive ratio to a setting with a linear excess of servers, which
improves over the previously best-known $O(\log^3{n})$ bound. We moreover show
that in the semi-random model where the requests are still drawn uniformly and
independently but where the servers are chosen adversarially, greedy achieves
an $O(\log{n})$ competitive ratio. When the requests arrive in a random order
but are chosen adversarially, it was previously known that greedy is
$O(n)$-competitive. Even though this one-sided randomness allows a large
improvement in greedy's competitive ratio compared to the model where requests
are adversarial and arrive in a random order, we show that it is not sufficient
to obtain a constant competitive ratio by giving a tight $\Omega(\log{n})$
lower bound. These results invite further investigation about how much
randomness is necessary and sufficient to obtain strong theoretical guarantees
for the greedy algorithm for online minimum cost matching, on the line and
beyond.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-10T00:30:00Z">Monday, October 10 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03211'>LazyFox: Fast and parallelized overlapping community detection in large graphs</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Tim Garrels, Athar Khodabakhsh, Bernhard Y. Renard, Katharina Baum</p><p>The detection of communities in graph datasets provides insight about a
graph's underlying structure and is an important tool for various domains such
as social sciences, marketing, traffic forecast, and drug discovery. While most
existing algorithms provide fast approaches for community detection, their
results usually contain strictly separated communities. However, most datasets
would semantically allow for or even require overlapping communities that can
only be determined at much higher computational cost. We build on an efficient
algorithm, Fox, that detects such overlapping communities. Fox measures the
closeness of a node to a community by approximating the count of triangles
which that node forms with that community. We propose LazyFox, a multi-threaded
version of the Fox algorithm, which provides even faster detection without an
impact on community quality. This allows for the analyses of significantly
larger and more complex datasets. LazyFox enables overlapping community
detection on complex graph datasets with millions of nodes and billions of
edges in days instead of weeks. As part of this work, LazyFox's implementation
was published and is available as a tool under an MIT licence at
github.com/TimGarrels/LazyFox.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Garrels_T/0/1/0/all/0/1">Tim Garrels</a>, <a href="http://arxiv.org/find/cs/1/au:+Khodabakhsh_A/0/1/0/all/0/1">Athar Khodabakhsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Renard_B/0/1/0/all/0/1">Bernhard Y. Renard</a>, <a href="http://arxiv.org/find/cs/1/au:+Baum_K/0/1/0/all/0/1">Katharina Baum</a></p><p>The detection of communities in graph datasets provides insight about a
graph's underlying structure and is an important tool for various domains such
as social sciences, marketing, traffic forecast, and drug discovery. While most
existing algorithms provide fast approaches for community detection, their
results usually contain strictly separated communities. However, most datasets
would semantically allow for or even require overlapping communities that can
only be determined at much higher computational cost. We build on an efficient
algorithm, Fox, that detects such overlapping communities. Fox measures the
closeness of a node to a community by approximating the count of triangles
which that node forms with that community. We propose LazyFox, a multi-threaded
version of the Fox algorithm, which provides even faster detection without an
impact on community quality. This allows for the analyses of significantly
larger and more complex datasets. LazyFox enables overlapping community
detection on complex graph datasets with millions of nodes and billions of
edges in days instead of weeks. As part of this work, LazyFox's implementation
was published and is available as a tool under an MIT licence at
https://github.com/TimGarrels/LazyFox.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-10T00:30:00Z">Monday, October 10 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.03392'>Latent Matrices for Tensor Network Decomposition and to Tensor Completion</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.DS/recent'>arXiv: Data Structures and Algorithms</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: Peilin Yang, Weijun Sun, Qinbin Zhao, Guoxu Zhou</p><p>The prevalent fully-connected tensor network (FCTN) has achieved excellent
success to compress data. However, the FCTN decomposition suffers from slow
computational speed when facing higher-order and large-scale data. Naturally,
there arises an interesting question: can a new model be proposed that
decomposes the tensor into smaller ones and speeds up the computation of the
algorithm? This work gives a positive answer by formulating a novel
higher-order tensor decomposition model that utilizes latent matrices based on
the tensor network structure, which can decompose a tensor into smaller-scale
data than the FCTN decomposition, hence we named it Latent Matrices for Tensor
Network Decomposition (LMTN). Furthermore, three optimization algorithms,
LMTN-PAM, LMTN-SVD and LMTN-AR, have been developed and applied to the
tensor-completion task. In addition, we provide proofs of theoretical
convergence and complexity analysis for these algorithms. Experimental results
show that our algorithm has the effectiveness in both deep learning dataset
compression and higher-order tensor completion, and that our LMTN-SVD algorithm
is 3-6 times faster than the FCTN-PAM algorithm and only a 1.8 points accuracy
drop.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1">Peilin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Weijun Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qinbin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1">Guoxu Zhou</a></p><p>The prevalent fully-connected tensor network (FCTN) has achieved excellent
success to compress data. However, the FCTN decomposition suffers from slow
computational speed when facing higher-order and large-scale data. Naturally,
there arises an interesting question: can a new model be proposed that
decomposes the tensor into smaller ones and speeds up the computation of the
algorithm? This work gives a positive answer by formulating a novel
higher-order tensor decomposition model that utilizes latent matrices based on
the tensor network structure, which can decompose a tensor into smaller-scale
data than the FCTN decomposition, hence we named it Latent Matrices for Tensor
Network Decomposition (LMTN). Furthermore, three optimization algorithms,
LMTN-PAM, LMTN-SVD and LMTN-AR, have been developed and applied to the
tensor-completion task. In addition, we provide proofs of theoretical
convergence and complexity analysis for these algorithms. Experimental results
show that our algorithm has the effectiveness in both deep learning dataset
compression and higher-order tensor completion, and that our LMTN-SVD algorithm
is 3-6 times faster than the FCTN-PAM algorithm and only a 1.8 points accuracy
drop.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-10T00:30:00Z">Monday, October 10 2022, 00:30</time>
        </div>
      </div>
    </article>
  
    
    <h2 class='new-date'>
      <i class='icon-calendar-empty'></i> Friday, October 07
    </h2>
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://scottaaronson.blog/?p=6745'>Postdocs, matrix multiplication, and WSJ: yet more shorties</a></h3>
          <p class='item-feed'>from <a href='https://scottaaronson.blog'>Scott Aaronson</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          I&#8217;m proud to say that Nick Hunter-Jones and Matteo Ippoliti&#8212;both of whom work at the interface between quantum information science and condensed-matter physics (Nick closer to the former and Matteo to the latter)&#8212;have joined the physics faculty at UT Austin this year. And Nick, Matteo, and I are jointly seeking postdocs to start in Fall [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>I&#8217;m proud to say that <a href="https://twitter.com/nickrhj">Nick Hunter-Jones</a> and <a href="https://matteoippoliti.com/">Matteo Ippoliti</a>&#8212;both of whom work at the interface between quantum information science and condensed-matter physics (Nick closer to the former and Matteo to the latter)&#8212;have joined the physics faculty at UT Austin this year.  And Nick, Matteo, and I are jointly seeking postdocs to start in Fall 2023!  <a href="https://academicjobsonline.org/ajo/jobs/23104">Please check out our call for applications here.</a>  The deadline is December 1; you apply through AcademicJobsOnline rather than by emailing me as in past years.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>The big news in AI and complexity theory this week was DeepMind&#8217;s <a href="https://www.deepmind.com/blog/discovering-novel-algorithms-with-alphatensor">AlphaTensor</a>, and its automated discovery of new algorithms for matrix multiplication.  (<a href="https://www.nature.com/articles/s41586-022-05172-4">See here for the <em>Nature</em> paper.</a>)  More concretely, they&#8217;ve used AI to discover (among other things) an algorithm for multiplying 4Ã4 matrices, over finite fields of characteristic 2, using only 47 scalar multiplications.  This beats the 49=7Ã7 that you&#8217;d get from <a href="https://en.wikipedia.org/wiki/Strassen_algorithm">Strassen&#8217;s algorithm</a>.  There are other improvements for other matrix dimensions, many of which work over fields of other characteristics.</p>



<p>Since I&#8217;ve seen confusion about the point on social media: this does <em>not</em> improve over the best known asymptotic exponent for matrix multiplication, which over any field, still stands at the human-discovered 2.373 (meaning, we know how to multiply two NÃN matrices in O(N<sup>2.373</sup>) time, but not faster).  But it <em>does</em> asymptotically improve over Strassen&#8217;s O(N<sup>2.81</sup>) algorithm from 1968, conceivably even in a way that could have practical relevance for multiplying hundreds-by-hundreds or thousands-by-thousands matrices over F<sub>2</sub>.</p>



<p>Way back in 2007, I <a href="http://www.scottaaronson.com/talks/wildidea.ppt">gave a talk</a> at MIT CSAIL&#8217;s &#8220;Wild and Crazy Ideas Session,&#8221; where I explicitly proposed to use computer search to look for faster algorithms for 4Ã4 and 5Ã5 matrix multiplication.  The response I got at the time was that it was hopeless, since the search space was already too huge.  Of course, that was before the deep learning revolution.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>This morning, the <em>Wall Street Journal</em> published an <a href="https://www.wsj.com/articles/china-competing-us-quantum-computing-11664997892">article by Karen Hao</a> about competition between China and the US in quantum computing.  Unfortunately paywalled, but includes the following passage:</p>



<blockquote class="wp-block-quote"><p>Meanwhile, American academics say itâs gotten harder for Chinese students to obtain visas to conduct quantum research in the U.S. âItâs become common knowledge that when Chinese students or postdocs come to the U.S., they canât say theyâre doing quantum computing,â says Scott Aaronson, director of the Quantum Information Center at the University of Texas, Austin.</p></blockquote>
<p class="authors">By Scott</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-07T16:01:53Z">Friday, October 07 2022, 16:01</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/10/07/faculty-at-university-of-cambridge-apply-by-november-28-2022/'>Faculty at University of Cambridge (apply by November 28, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The Department of Computer Science and Technology at the University of Cambridge is seeking to recruit a new faculty member at the Assistant or Associate Professor level who can contribute to research and teaching in the area of Algorithms and Complexity. The appointment will be from 1 September 2023 or as soon as possible thereafter. [&#8230;]
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The Department of Computer Science and Technology at the University of Cambridge is seeking to recruit a new faculty member at the Assistant or Associate Professor level who can contribute to research and teaching in the area of Algorithms and Complexity.</p>
<p>The appointment will be from 1 September 2023 or as soon as possible thereafter.</p>
<p>Website: <a href="https://www.jobs.cam.ac.uk/job/37368/">https://www.jobs.cam.ac.uk/job/37368/</a><br />
Email: anuj.dawar@cl.cam.ac.uk</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-07T10:57:47Z">Friday, October 07 2022, 10:57</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='https://cstheory-jobs.org/2022/10/07/postdoc-positions-in-algorithms-and-complexity-at-algorithms-and-compleixty-group-irif-paris-france-apply-by-november-1-2022/'>postdoc positions in Algorithms and Complexity at Algorithms and Compleixty Group, IRIF, Paris, France (apply by November 1, 2022)</a></h3>
          <p class='item-feed'>from <a href='https://cstheory-jobs.org'>CCI: jobs</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          The Algorithms and Complexity group of IRIF ( www.irif.fr/en/equipes/algocomp/index ), Paris, France, is seeking excellent candidates for one or more postdoctoral positions in classical and quantum computing, with a usual starting date of September-October 2023 (but possibly negotiable). Knowledge of French is not necessary. Website: www.irif.fr/en/postes/postdoc Email: adiro@irif.fr
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p>The Algorithms and Complexity group of IRIF ( <a href="https://www.irif.fr/en/equipes/algocomp/index">https://www.irif.fr/en/equipes/algocomp/index</a> ), Paris, France, is seeking excellent candidates for one or more postdoctoral positions in classical and quantum computing, with a usual starting date of September-October 2023 (but possibly negotiable). Knowledge of French is not necessary.</p>
<p>Website: <a href="https://www.irif.fr/en/postes/postdoc">https://www.irif.fr/en/postes/postdoc</a><br />
Email: adiro@irif.fr</p>
<p class="authors">By shacharlovett</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-07T08:36:39Z">Friday, October 07 2022, 08:36</time>
        </div>
      </div>
    </article>
  
    

    <article class='item'>
      <div class='item-header'>
        <span class='item-caret'>
          <i class='icon-large icon-caret-down item-collapse item-close item-opened'></i>
          <i class='icon-large icon-caret-right item-expand item-open item-closed'></i>
        </span>
        <span class='item-info'>
          <h3 class='item-title'><a href='http://arxiv.org/abs/2210.02671'>Transformers Implement First-Order Logic with Majority Quantifiers</a></h3>
          <p class='item-feed'>from <a href='https://arxiv.org/list/cs.CC/recent'>arXiv: Computational Complexity</a></p>
        </span>
      </div>

      <div class='item-body'>
        <div class='item-snippet'>
        
          <p>Authors: William Merrill, Ashish Sabharwal</p><p>Characterizing the implicit structure of the computation within neural
networks is a foundational problem in the area of deep learning
interpretability. Can their inner decision process be captured symbolically in
some familiar logic? We show that any transformer neural network can be
translated into an equivalent fixed-size first-order logic formula which may
also use majority quantifiers. The idea is to simulate transformers with highly
uniform threshold circuits and leverage known theoretical connections between
circuits and logic. Our findings also reveal the surprising fact that the
entire transformer computation can be reduced merely to the division of two
(large) integers. While our results are most pertinent for transformers, they
apply equally to a broader class of neural network architectures, namely those
with a fixed-depth uniform computation graph made up of standard neural net
components, which includes feedforward and convolutional networks.
</p>
        
        </div>

        <div class='item-content item-summary'>
        
          
          <p class="arxiv-authors"><b>Authors:</b> <a href="http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1">William Merrill</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1">Ashish Sabharwal</a></p><p>Characterizing the implicit structure of the computation within neural
networks is a foundational problem in the area of deep learning
interpretability. Can their inner decision process be captured symbolically in
some familiar logic? We show that any transformer neural network can be
translated into an equivalent fixed-size first-order logic formula which may
also use majority quantifiers. The idea is to simulate transformers with highly
uniform threshold circuits and leverage known theoretical connections between
circuits and logic. Our findings also reveal the surprising fact that the
entire transformer computation can be reduced merely to the division of two
(large) integers. While our results are most pertinent for transformers, they
apply equally to a broader class of neural network architectures, namely those
with a fixed-depth uniform computation graph made up of standard neural net
components, which includes feedforward and convolutional networks.
</p>
        
        </div>

        <div class='item-footer'>
          <time class='timeago' datetime="2022-10-07T00:30:00Z">Friday, October 07 2022, 00:30</time>
        </div>
      </div>
    </article>
  
  </div>

  <script src='js/jquery-2.0.3.min.js'></script>
  <script src="js/jquery.timeago.js" type="text/javascript"></script>
  <script>
    jQuery(document).ready(function() {
      jQuery("time.timeago").timeago();
    });
  </script>
  <script src='js/blank.js'></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
